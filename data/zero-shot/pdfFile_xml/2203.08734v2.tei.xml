<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Where To Look - Generative NAS is Surprisingly Efficient</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jovita</forename><surname>Lukasik</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Mannheim</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Max Planck Institute for Informatics</orgName>
								<orgName type="department" key="dep2">Saarland Informatics Campus</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Jung</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Max Planck Institute for Informatics</orgName>
								<orgName type="department" key="dep2">Saarland Informatics Campus</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margret</forename><surname>Keuper</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Max Planck Institute for Informatics</orgName>
								<orgName type="department" key="dep2">Saarland Informatics Campus</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Siegen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Where To Look - Generative NAS is Surprisingly Efficient</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T14:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>neural architecture search, generative model</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The efficient, automated search for well-performing neural architectures (NAS) has drawn increasing attention in the recent past. Thereby, the predominant research objective is to reduce the necessity of costly evaluations of neural architectures while efficiently exploring large search spaces. To this aim, surrogate models embed architectures in a latent space and predict their performance, while generative models for neural architectures enable optimization-based search within the latent space the generator draws from. Both, surrogate and generative models, have the aim of facilitating query-efficient search in a well-structured latent space. In this paper, we further improve the trade-off between query-efficiency and promising architecture generation by leveraging advantages from both, efficient surrogate models and generative design. To this end, we propose a generative model, paired with a surrogate predictor, that iteratively learns to generate samples from increasingly promising latent subspaces. This approach leads to very effective and efficient architecture search, while keeping the query amount low. In addition, our approach allows in a straightforward manner to jointly optimize for multiple objectives such as accuracy and hardware latency. We show the benefit of this approach not only w.r.t. the optimization of architectures for highest classification accuracy but also in the context of hardware constraints and outperform state-of-the-art methods on several NAS benchmarks for single and multiple objectives. We also achieve state-of-the-art performance on ImageNet. The code is available at https://github.com/jovitalukasik/AG-Net.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The first image classification network <ref type="bibr">[29]</ref> applied to the large-scale visual recognition challenge ImageNet <ref type="bibr" target="#b12">[15]</ref> achieved unprecedented results. Since then, the main driver of improvement on this challenge are new architecture designs <ref type="bibr" target="#b25">[49,</ref><ref type="bibr" target="#b27">51]</ref>, <ref type="bibr" target="#b28">[52,</ref><ref type="bibr" target="#b19">22]</ref> that, ultimately, lead to architectures surpassing human performance <ref type="bibr" target="#b18">[21]</ref>. Since manual architecture design requires good intuition and a huge amount of trial-and-error, the automated approach of neural architecture search (NAS) receives growing interest <ref type="bibr">[43,</ref><ref type="bibr">70,</ref><ref type="bibr" target="#b42">66,</ref><ref type="bibr" target="#b14">17,</ref><ref type="bibr">27,</ref><ref type="bibr">30]</ref>. Well-performing architectures can be found by applying common search practices like random search <ref type="bibr" target="#b5">[8]</ref>, evolutionary search <ref type="bibr">[43,</ref><ref type="bibr">42]</ref>, Bayesian optimization (BO) [24, <ref type="bibr" target="#b22">46,</ref><ref type="bibr" target="#b32">56]</ref>, or local search <ref type="bibr" target="#b33">[57]</ref> on discrete architecture search spaces, such as NAS-Bench-101, NAS-Bench-201, DARTS and NAS-Bench-NLP <ref type="bibr" target="#b42">[66,</ref><ref type="bibr" target="#b14">17,</ref><ref type="bibr">34,</ref><ref type="bibr">27]</ref>. However, these methods are inefficient because they require to evaluate thousands of architectures, resulting in impracticable search times. Recent approaches avoid this problem of immense computation costs by either training surrogate models to approximate the performance of an architecture <ref type="bibr">[34,</ref><ref type="bibr" target="#b6">9]</ref> or by generating architectures based on learned architecture representation spaces <ref type="bibr">[68,</ref><ref type="bibr">35]</ref>. Both methods aim to improve the query efficiency, which is crucial in NAS, since every query implies a full training and evaluation of the neural architecture on the underlying target dataset.</p><p>This trade-off between query efficiency and resulting high-scoring architectures is an active research field. Yet, no attempts were made so far to leverage the advantages of both search paradigms. Therefore, we propose a model that incorporates the focus of promising architectures already in the architecture generation process by optimizing the latent space directly: We let the generator learn in which areas of the data distribution to look for promising architectures. This way, we reduce the query amount even further, resulting in a query efficient and very effective NAS method. Our proposed method is inspired by a latent space optimization (LSO) technique <ref type="bibr" target="#b29">[53]</ref>, originally used in the context of variational autoencoders [26] to optimize generated images or arithmetic expressions using BO. We adapt this concept to NAS and pair it with an architecture performance predictor in an end-to-end learning setting, so that it allows us to iteratively reshape the architecture representation space. Thereby, we promote desired properties of generated architectures in a highly query-efficient way, i.e. by learning expert generators for promising architectures. Since we couple the generation process with a surrogate model to predict desired properties such as high accuracy or low latency of generated architectures, there is no need in our method for BO in the generated latent space, making our method even more efficient.</p><p>In practice, we pretrain, on a target space of neural architectures, a GNNbased generator network, which does not rely on any architecture evaluation and is therefore fast and query-free. The generator is trained in a novel generative setting that directly compares generated architectures to randomly sampled architectures using a reconstruction loss without the need of a discriminator network as in generative adversarial networks (GANs) <ref type="bibr" target="#b17">[20]</ref> or an encoder as in variational autoencoders (VAEs) <ref type="bibr">[26]</ref>. We use an MLP as a surrogate to rank performances and hardware properties of generated architectures. In contrast, previous generative methods either rely on training and evaluating supernets <ref type="bibr">[23]</ref>, which are expensive to train and dataset specific, or pretrain a latent space and search within this space directly using BO [68, <ref type="bibr" target="#b41">65,</ref><ref type="bibr">35]</ref>, reinforcement learning (RL) <ref type="bibr" target="#b20">[44]</ref> or gradient based methods <ref type="bibr">[36]</ref>. These methods incorporate either GANs, which can be hard to train or VAEs, which are biased by the regularization, whereas our plain generative model is easy to train. In addition we enable backpropagation from the performance predictor to the generator. Thereby, the generator can efficiently learn which part of the architecture search space is promising with only few evaluated architectures.</p><p>By extensive experiments on common NAS benchmarks <ref type="bibr" target="#b42">[66,</ref><ref type="bibr" target="#b14">17,</ref><ref type="bibr" target="#b24">48,</ref><ref type="bibr">27,</ref><ref type="bibr">30]</ref> as well as ImageNet <ref type="bibr" target="#b12">[15]</ref>, we show that our method is effective and sample-efficient. It reinforces the generator network to produce architectures with improving validation accuracy (see <ref type="figure" target="#fig_0">Figure 1</ref>), as well as in improving on hardware-dependent latency constraints (see <ref type="figure" target="#fig_3">Figure 4</ref>) while keeping the number of architecture evaluations small. In summary, we make the following contributions:</p><p>-We propose a simple model that learns to focus on promising regions of the architecture space. It can thus learn to generate high-scoring architectures from only a few queries. -We learn architecture representation spaces via a novel generative design that is able to generate architectures stochastically while being trained with a simple reconstruction loss. Unlike VAEs <ref type="bibr">[26]</ref> or GANs <ref type="bibr" target="#b17">[20]</ref>, no encoder network nor discriminator network is necessary. -Our model allows sample-efficient search and achieves state-of-the-art results on several NAS benchmarks as well as on ImageNet. It allows joint optimization w.r.t. hardware properties in a straightforward way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Neural Architecture Search Intrinsically, Neural Architecture Search (NAS) is a discrete optimization problem seeking the optimal configuration of operations (such as convolutions, poolings and skip connections) in a constrained search space of computational graphs.  <ref type="bibr" target="#b33">[57]</ref>, and Bayesian optimization (BO) <ref type="bibr">[24,</ref><ref type="bibr" target="#b22">46]</ref>. Recent NAS methods shift from discrete optimization to faster weight-sharing approaches, resulting in differentiable optimization methods <ref type="bibr">[41,</ref><ref type="bibr">34,</ref><ref type="bibr" target="#b4">7,</ref><ref type="bibr" target="#b6">9,</ref><ref type="bibr" target="#b37">61,</ref><ref type="bibr">67]</ref>. Several approaches map the discrete search space into a continuous architecture representation space <ref type="bibr">[36,</ref><ref type="bibr">68,</ref><ref type="bibr" target="#b41">65,</ref><ref type="bibr">35]</ref> and search or optimize within this space using for example BO (e.g. <ref type="bibr" target="#b41">[65]</ref>) or gradient-based point operation <ref type="bibr">[36]</ref>. In this paper, we also learn continuous architecture representation spaces. However, in contrast to former works, we propose to optimize the representation space, instead of performing point optimization within a fixed space such as e.g. <ref type="bibr">[36]</ref>. A survey of different strategies can be found in <ref type="bibr" target="#b15">[18]</ref>.</p><p>All NAS approaches are dependent on performance estimation of intermediate architectures. To avoid the computation heavy training and evaluation of queries on the target dataset, methods to approximate the performance have been explored <ref type="bibr" target="#b34">[58]</ref>. Common approaches include neural predictors that take path encodings <ref type="bibr" target="#b32">[56]</ref> or graph embeddings learned by GNNs <ref type="bibr" target="#b23">[47,</ref><ref type="bibr" target="#b30">54]</ref> as input. Weak-NAS <ref type="bibr" target="#b36">[60]</ref> proposes to progressively evaluate the search space towards finding high-performing architectures using a set of weak predictors. In our method, we integrate a weak expert predictor with a generator to yield an efficient interplay between predicting for high-performing architectures and generating them. Graph Generative Models Most graph generation models in NAS employ variational autoencoders (VAE) <ref type="bibr">[26]</ref>. <ref type="bibr">[36]</ref> uses an LSTM-based VAE, coupled with performance prediction for gradient-based architecture optimization. Note that [36] optimizes the latent point in a fixed latent space while our approach optimizes the latent space itself.</p><p>[68] use GNNs with asynchronous message-passing to train a VAE for BO. [23] combines a generator with a supernet and searches for neural architectures for different device information. <ref type="bibr" target="#b41">[65]</ref> facilitates <ref type="bibr" target="#b38">[62]</ref> with an MLP decoder. <ref type="bibr">[35]</ref> proposes smooth variational graph embeddings (SVGe) using two-sided GNNs to capture the information flow within a neural architecture.</p><p>Our proposed model's generator is inspired by SVGe with the aim to inherit its flexible applicability to various search spaces. Yet, similar to <ref type="bibr" target="#b41">[65]</ref>, due to the intrinsic discretization and training setting, SVGe does not allow for backpropagation. Recently, <ref type="bibr" target="#b20">[44]</ref> facilitates GNNs in a GAN <ref type="bibr" target="#b17">[20]</ref> setting, where the backpropagation issue is circumvented using reinforcement learning. In contrast, our proposed GNN generator circumvents the intermediate architecture discretization and can therefore be trained by a single reconstruction loss using backpropagation. Its iterative optimization is inspired by <ref type="bibr" target="#b29">[53]</ref>, who proposes to use a VAE with weighted retraining w.r.t. a target function to adapt the latent space for the optimization of images and arithmetic functions using BO. Our The input is a randomly sampled latent vector z ? R d . First, the input node is generated, initialized and input to a GNN to generate a partial graph representation. The learning process iteratively generates node scores and edge scores using z and the partial graph representation until the output node is generated. The target for this generated graph is a randomly sampled architecture.</p><p>model transfers the idea of weighted retraining to NAS. It uses our plain generator and improves sample efficiency by employing a differentiable surrogate model on the target function such that, in contrast to <ref type="bibr" target="#b29">[53]</ref>, no further black-box optimization step is needed. Next, we describe the proposed generator network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Architecture Generative Model</head><p>Preliminaries We aim to generate neural networks represented as directed acyclic graphs (DAG). This representation is in line with the cell-based architecture search spaces commonly used as tabular benchmarks <ref type="bibr" target="#b42">[66,</ref><ref type="bibr" target="#b14">17]</ref>. Each cell is a DAG G = (V, E), with nodes v ? V and edges e ? E. The graph representations differ between the various benchmarks in terms of their labeling of operations. For example in NAS-Bench-101 <ref type="bibr" target="#b42">[66]</ref> each node is associated with an operation, whereas in NAS-Bench-201 <ref type="bibr" target="#b14">[17]</ref> each edge is associated with an operation. Generative Network Commonly used graph generative networks are based on variational autoencoders (VAE) <ref type="bibr">[26]</ref>. In contrast, our proposed network is a purely generative network, p G (see <ref type="figure" target="#fig_1">Figure 2</ref>). To generate valid graphs, we build our model similar to the graph decoder from the VAE approach SVGe <ref type="bibr">[35]</ref>. The generator takes a randomly sampled variable z ? N (0, 1) as input and reconstructs a randomly sampled graph from the cell-based search space. The model iteratively builds the graph: it starts with generating the input node v 0 , followed by adding subsequent nodes v i and their labels and connecting them with edges e (j,i) , j &lt; i, until the end node v T with the label output is generated. Additionally, we want to learn a surrogate for performance prediction on the generated data and allow for end-to-end training of both. To allow for backpropagation, we need to adapt several details of the generator model. We initialize the nodeattributes for each node by one-hot encoded vectors, which are initialized during training using a 2-layer MLP to replace the learnable look-up table proposed in SVGe. The output of our generator is a vector graph representation consisting of a concatenation of generated node scores and edge scores. It is important to note that the iterative generation process is independent of the ground truth data, which are only used as a target for the reconstruction loss. Note that the end-to-end trainability of the proposed generator is a prerequisite for our model: It allows to pair the generator with a learnable performance predictor such that information on the expected architectures' accuracy can be learned by the generator. This enables a stronger coupling with the predictor's target for the generation process and higher query efficiency (see subsection 4.4). In contrast, previous models such as <ref type="bibr">[23,</ref><ref type="bibr">35,</ref><ref type="bibr" target="#b41">65]</ref> are not fully differentiable and do not allow such optimization. Our generative model is pretrained on the task of reconstructing neural architectures, where for each randomly drawn latent space sample, we evaluate the reconstruction loss to a randomly drawn architecture. This simple procedure is facilitated by the heavily constrained search spaces of neural architectures, making it easy for the model to learn to generate valid architectures without being supported by a discriminator model as in generative adversarial networks (GANs) <ref type="bibr" target="#b17">[20]</ref>. An evaluation of the generation ability of our model and implementation details are provided in the supp. mat. section D.</p><p>Performance Predictor This generative model is coupled with a simple surrogate model, a 4-layer MLP with ReLU non-linearities, for target predictions C. These targets can be validation or test accuracy of the generated graph, or the latency with respect to a certain hardware. For comparison, we also include a tree-based method, XGBoost (XGB) <ref type="bibr" target="#b7">[10]</ref> as an alternative prediction model. XGB <ref type="bibr" target="#b7">[10]</ref> is used as a surrogate model in NAS-Bench-301 <ref type="bibr" target="#b24">[48]</ref> and shows high prediction abilities. The input to XGB is the vector representation of the architectures. Since this method is non-differentiable, we additionally include a gradient estimation for rank-based metrics <ref type="bibr" target="#b21">[45]</ref>. This way, we are able to include gradient information to the generator. Yet, it is important to note, that this approach is not fully differentiable. This comparison will allow us to measure the trade-off between using supposedly stronger predictors over the capability to allow for full end-to-end learning.</p><p>Training Objectives The generative model p G learns to reconstruct a randomly sampled architecture G from search space p D given a randomly sampled latent vector z ? N (0, 1). The objective function for this generation process can be formulated as the sum of node-level loss L V and edge-level loss L E :</p><formula xml:id="formula_0">L G (G, G) = L V + L E ;G ? p G (z); G ? p D ,<label>(1)</label></formula><p>where L V is the Cross-Entropy loss between the predicted and the ground truth nodes and L E is the Binary-Cross Entropy loss between the predicted and ground truth edges of the generated graphG. This training step is completely unsupervised. <ref type="figure" target="#fig_1">Figure 2</ref> presents an overview of the training process. To include the training of the surrogate model, the objective function is reformulated to:</p><formula xml:id="formula_1">L(G, G) = (1 ? ?)L G (G, G) + ?L C (G, G),<label>(2)</label></formula><p>where ? is a hyperparameter to trade-off generator loss L G and prediction loss L C for the prediction targets C of graph G. We set the predictor loss as an MSE. Furthermore, each loss is optimized using mini-batch gradient descent.</p><p>Generative Latent Space Optimization (LSO) To facilitate the generation process, we optimize the architecture representation space via weighted retraining <ref type="bibr" target="#b29">[53]</ref>, resulting in a sample efficient search algorithm. The intuition of this approach is to place more probability mass on high-scoring latent points, (e.g. high performing or low latency architectures) and less mass on low-scoring points. Thus, this strategy does not discard low-scoring architectures completely, which would be inadequate for proper learning. The generative model is therefore trained on a data distribution that systematically increases the probability of high-scoring latent points. This can be done by simply assigning a weight w i to each data point G i ? p D , indicating its likelihood to occur during batch-wise training. In addition, the training objective is weighted via a weighted empirical mean Gi?p D w i L for each data point. As for the weights itself, <ref type="bibr" target="#b29">[53]</ref> proposed a rank-based weight function</p><formula xml:id="formula_2">w(G; p D , k) ? 1 kN + rank f,p D (G) rank f,p D (x) = |{G i : f (G i ) &gt; f (G), G i ? p D }|,<label>(3)</label></formula><p>where f (?) is the evaluation function of the architecture G i ; for NAS-Bench-101 <ref type="bibr" target="#b42">[66]</ref> and NAS-Bench-201 <ref type="bibr" target="#b14">[17]</ref> it is the tabular benchmark entry, for NAS-Bench-301 <ref type="bibr" target="#b24">[48]</ref> and NAS-Bench-NLP [27] it is the surrogate benchmark prediction. Similar to <ref type="bibr" target="#b29">[53]</ref>, we set k = 10e ? 3. The retraining procedure itself then consists of finetuning the pretrained generative model coupled with the surrogate model, where loss functions and data points are both weighted by w(G; p D , k).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate the proposed simple architecture generative network (AG-Net) on the two commonly used tabular benchmarks NAS-Bench-101 <ref type="bibr" target="#b42">[66]</ref> and NAS-Bench-201 <ref type="bibr" target="#b14">[17]</ref>, the surrogate benchmarks NAS-Bench-301 <ref type="bibr" target="#b24">[48]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiments on Tabular Benchmarks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NAS-Bench-101</head><p>For our experiments on NAS-Bench-101, we first pretrain our generator for generating valid graphs on the NAS-Bench-101 search space. This step does not require information about the performance of architectures and is therefore inexpensive. The pretrained generator is then used for all experiments on NAS-Bench-101. Our NAS algorithm is initialized by randomly sampling 16 architectures from the search space, which are then weighted by the weighting function W = w(G) G?p D . Then, latent space optimized architecture search is performed by iteratively retraining the generator coupled with the MLP surrogate model for 15 epochs and generating 100 architectures of which the top 16 (according to their accuracy prediction) are evaluated and added to the training data. This step is repeated until the desired number of queries is reached. When generating architectures, we sample from a grid, containing the 99%-quantiles from N (0, 1) uniformly distributed. This way, we sample more distributed latent variables for better latent space coverage. We compare our method to the VAE-based search method Arch2vec <ref type="bibr" target="#b41">[65]</ref> and predictor based model WeakNAS <ref type="bibr" target="#b36">[60]</ref>, as well as state-of-the-art methods, such as NAO [36] ? , random search [31], local search <ref type="bibr" target="#b33">[57]</ref>, Bayesian optimization <ref type="bibr" target="#b26">[50]</ref>, regularized evolution [42] and BA-NANAS <ref type="bibr" target="#b32">[56]</ref> ? . Additionally, we compare the proposed AG-Net to the model using an XGBoost Predictor (see section C). The results of this comparison are listed in <ref type="table" target="#tab_2">Table 1</ref>. Here, we report the mean over 10 runs. Results including the standard deviation can be found in the supp. mat. Note, we search for the architecture with the best validation accuracy and report the corresponding test accuracy. Furthermore, we plot the search progress in <ref type="figure" target="#fig_2">Figure 3</ref> (bottom left). As we can see, our model AG-Net improves over all state-of-the-art methods, not only at the last query of 300 data points, reaching a top 1 test accuracy of 94.2%, but is also almost any time better during the search process.</p><p>A direct comparison to the recently proposed GANAS <ref type="bibr" target="#b20">[44]</ref> on NAS-Bench-101 is difficult, since GANAS searches on NAS-Bench-101 until they find the best architecture in terms of validation accuracy, whereas we limit our search to a maximal amount of 192 queries and are able to find high-performing architectures already in this small query setting. The comparison of AG-Net to the generator paired with an XGBoost <ref type="bibr" target="#b7">[10]</ref> predictor shows that our end-to-end learnable approach is favorable even over potentially stronger predictors. NAS-Bench-201 This benchmark contains three different image classification tasks: CIFAR-10, CIFAR-100 [28] and ImageNet16-120 <ref type="bibr" target="#b11">[14]</ref>. For the experiments on NAS-Bench-201 <ref type="bibr" target="#b14">[17]</ref> we retrain AG-Net in the weighted manner for 30 epochs. In this setting, we also compare AG-Net to two recent generative models <ref type="bibr" target="#b20">[44,</ref><ref type="bibr">23]</ref>. SGNAS [23] trains a supernet by uniform sampling, following SETN <ref type="bibr" target="#b13">[16]</ref>. Additionally a CNN based architecture generator is trained to search architectures on the supernet. When comparing with <ref type="bibr" target="#b41">[65]</ref>, we also adopt their evaluation scheme of adding only the best-performing architecture (top-1) to the training data instead of top-16 as in our other experiments.</p><p>We report the search results for different numbers of queries for the NAS-Bench-201 dataset in <ref type="table" target="#tab_3">Table 2</ref>. In addition, we plot the search progress in terms of queries in <ref type="figure" target="#fig_2">Figure 3</ref> (top). Our method provides state-of-the-art results on all datasets for a varying number of queries. Most importantly, AG-Net shows strong performance in the few-query regime compared to <ref type="bibr" target="#b41">[65]</ref> with the exception of CIFAR-100, proving its high query efficiency. ? We reran this experiment using the implementation from <ref type="bibr" target="#b34">[58]</ref>.</p><p>? We reran these experiments using the official implementation from <ref type="bibr" target="#b31">[55,</ref><ref type="bibr" target="#b32">56,</ref><ref type="bibr" target="#b33">57]</ref>, with the same initial training data and amount of top k architectures as for AG-Net.  <ref type="bibr" target="#b24">[48]</ref> for the CIFAR-10 [28] image classification task. The exact search procedure using the cells individually is described in the supp. mat. subsection C.5. The results are described in <ref type="table" target="#tab_4">Table 3</ref> (left) and visualized in <ref type="figure" target="#fig_2">Figure 3</ref> (bottom middle). Our method is comparable to other state-of-the-art methods in this search space. NAS-Bench-NLP Next, we evaluate AG-Net on NAS-Bench-NLP [27] for the language modeling task on Penn TreeBank <ref type="bibr">[38]</ref>. We retrain AG-Net coupled with the surrogate model for 30 epochs to predict the validation perplexity. Note, since the search space considered in NAS-Bench-NLP is too large for a full tabular benchmark evaluation, we make use of the surrogate benchmark NAS-Bench-X11 <ref type="bibr" target="#b40">[64]</ref> and NAS-Bench-Suite [37] instead of tabular entries. For fair comparison we compare our methods to the same state-of-the-art methods as in previous experiments. The results are reported in <ref type="table" target="#tab_4">Table 3</ref> (right) and visualized in <ref type="figure" target="#fig_2">Figure 3</ref> (bottom right). Our AG-Net improves over all stateof-the-art methods by a substantial margin and using XGB as a predictor even improves the search further. ImageNet Experiments The previous experiment on NAS-Bench-301 <ref type="bibr" target="#b24">[48]</ref> shows the ability of our generator to generate valid architectures and to perform well in the DARTS [34] search space. This allows for searching a well-performing architecture on ImageNet <ref type="bibr" target="#b12">[15]</ref>. Yet evaluating up to 300 different found archi-  tectures on ImageNet is extremely expensive. Our first approach is to retrain the best found architectures on the CIFAR-10 [28] image classification task from the previous experiment on NAS-Bench-301 (AG-Net and the XGBoost adaptions) on ImageNet <ref type="bibr" target="#b12">[15]</ref>. Our second approach is based on a training-free neural architecture search approach. The recently proposed TE-NAS <ref type="bibr" target="#b8">[11]</ref> provides a training-free neural architecture search approach, by ranking architectures by analysing the neural tangent kernel (NTK) and the number of linear regions (NLR) of each architecture. These two measurements are training free and do not need any labels. The intuition between those two measurements is their implication towards trainability and expressivity of a neural architecture and also their correlation with the neural architecture's accuracy; NTK is negatively correlated and NLR positively correlated with the architecture's test accuracy. We adapt this idea for our search on ImageNet and search architectures in terms of their NTK value and their number of linear regions instead of their validation accuracy. We describe the detailed search process in the supp. mat. subsection C.5.    <ref type="table" target="#tab_6">Table 4</ref> shows the results. Note that our latter described search method on ImageNet is training-free (as TE-NAS <ref type="bibr" target="#b8">[11]</ref>) and the amount of queries displays the amount of data we evaluated for the zero cost measurements. Other query information include the amount of (partly) trained architectures. Furthermore, the displayed differentiable methods are based on training supernets which can lead to expensive training times. The best found architectures on NAS-Bench-301 <ref type="bibr" target="#b24">[48]</ref> (CIFAR-10) result in comparable error rates on ImageNet to former approaches. As a result, our search method approach is highly efficient and outperforms previous methods in terms of needed GPU days. The result in terms of top-1 and top-5 error rates are even improving over the one from previous approaches when using the training free approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiments on Hardware-Aware Benchmark</head><p>Next, we apply AG-Net to the Hardware-Aware NAS-Benchmark <ref type="bibr">[30]</ref>. We demonstrate in two settings that AG-Net can be used for multi-objective learning. The first setting (Joint=1 ) is formulated as constrained joint optimization: </p><formula xml:id="formula_3">max G?p D f (G) ? min G?p D , g h (G) s.t. g h (G) ? L, ? h ? H,<label>(4)</label></formula><p>where f (?) evaluates architecture G for accuracy and g h (?) evaluates for latency given a hardware h ? H and a user-defined latency constraint L. The second setting (Joint=0 ) is formulated as constraint objective:</p><p>max</p><formula xml:id="formula_4">G?p D f (G) s.t. g h (G) ? L, ? h ? H,<label>(5)</label></formula><p>where we drop the optimization on latency and only optimize accuracy given the latency constraint. The loss function to train our generator in these settings is updated from Equation 2 to:</p><formula xml:id="formula_5">L(G, G) =(1 ? ?)L G (G, G) + ? ?L C1 (G, G) + (1 ? ?)L C2 (G, G) ,<label>(6)</label></formula><p>where ? is a hyperparameter trading off generation and prediction loss, and ? is a hyperparameter trading off both prediction targets C 1 (accuracy) and C 2 (latency).</p><p>To perform LSO in the joint objective setting from Equation 4, we rank the training data D for both accuracy and latency jointly by summing both <ref type="table">Table 5</ref>: Results for searches with at most 200 queries on HW-NAS-Bench <ref type="bibr">[30]</ref> with varying devices and latency (Lat.) constraints in two multi-objective settings: Joint=0 optimizes accuracy under latency constraint, while Joint=1 optimizes for accuracy and latency jointly. We report the best found architecture out of 10 runs with their corresponding latency, as well as the mean of these runs. We compare to random search as a strong baseline <ref type="bibr">[31]</ref>. Feasibility (Feas.) is the proportion of evaluated architectures during the search that satisfy the latency constraint (larger is better). The optimal architecture (*) is the architecture with the highest accuracy satisfying the latency constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Settings</head><p>Best individual rankings. To fulfill the optimization constraint, we further penalize the ranks via a multiplicative penalty if the latency does not fulfill the constraint. This overall ranking is then used for the weight calculation in Equation 3. The LSO for the constraint objective setting from Equation 5 only ranks architectures by accuracy and penalizes architectures with infeasible latency property. We choose random search as a baseline in this setting as it is generally regarded as a strong baseline in NAS <ref type="bibr">[31]</ref>. <ref type="figure" target="#fig_3">Figure 4</ref> depicts searches with our model in both optimization settings on Pixel 3 with different latency conditions. More results on different hardware and latency constraints are shown in <ref type="table">Table 5</ref>. We observe that either optimization setting outperforms the random search baseline in almost all tasks. Additionally, our method is able to find the optimal architecture for a task regularly (in 15 out of 20 tasks), which random search was not able to provide. When considering mean accuracy and feasibility of the best architectures of all runs, we see that Joint=1 is able to improve the ratio of feasible architectures found during the search substantially. This is to be expected given that the latent space is explicitly optimized for latency in this setting. Consequently, Joint=1 is able to find better-performing architectures compared to Joint=0 if the constraint restricts the space of feasible architectures strongly (see results on Raspi 4). The feasibility ratio of random search is an indicator on how restricted the space is. In most cases, the latency penalization seems to be sufficient to find enough well-performing and feasible architectures, as can be seen by the feasibility of Joint=0 which is greatly improved compared to random search. We show the development of feasibility over time from <ref type="table">Table 5</ref> in <ref type="figure" target="#fig_3">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Studies</head><p>In this section we analyse the impact of the LSO technique and the backpropagation ability to the search efficiency. Therefore, we compare our AG-Net with the latter named adaptions on the tabular benchmarks NAS-Bench-101 <ref type="bibr" target="#b42">[66]</ref> and NAS-Bench-201 <ref type="bibr" target="#b14">[17]</ref>. The results of our ablation study are reported in <ref type="table" target="#tab_8">Table 6</ref>.</p><p>As we can see, the lack of weighted retraining decreases the search substantially.</p><p>In addition the results without backpropagation support that the coupling of the predictor's target and the generation process enables a more efficient architecture search over different search spaces. Thus, the combination of LSO and a fully differentiable approach improves the effectiveness of the search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We propose a simple architecture generative network (AG-Net), which allows us to directly generate architectures without any additional encoder or discriminator. AG-Net is fully differentiable, allowing to couple it with surrogate models for different target predictions. In contrast to former works, it enables to backpropagate the target information from the surrogate predictor into the generator. By iteratively optimizing the latent space of the generator, our model learns to focus on promising regions of the architecture space, so that it can generate high-scoring architectures directly in a query and sample-efficient manner. Extensive experiments on common NAS benchmarks demonstrate that our model outperforms state-of-the-art methods at almost any time during architecture search and achieves state-of-the-art performance on ImageNet. It also allows for multi-objective optimization on the Hardware-Aware NAS-Benchmark. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices</head><p>Section A provides an overview about the graph representations for each search space, we consider in the main paper. In section B we show additional ablation studies. In section C, we provide more details about the experimental settings. In subsection C.5 we provide additional details for our search method on the DARTS search space. In section D we describe details about the generator network, and in section E we list all hyperparameter settings of our experiments. Lastly, we include a visual intuition of the latent space optimization technique in section F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Search Space Representations</head><p>In this section we give more details about the search spaces we consider in the main paper.</p><p>A.1 NAS-Bench-101 For visualization purposes, we present in <ref type="figure" target="#fig_5">Figure 5</ref> exemplary a DAG from the NAS-Bench-101 search space, with its corresponding node attribute matrix and its adjacency matrix. Note, a concatenation of the flatted node attribute matrix and the flatted upper triangular adjacency matrix is the representation our generator model is trained to learn; this holds for all search spaces. NAS-Bench-201 <ref type="bibr" target="#b14">[17]</ref> is another cell-structured search space, which consists of 15, 625 architectures. Each architecture is trained for 200 training epochs on CIFAR-10 [28], CIFAR-100 [28], and ImageNet16-120 <ref type="bibr" target="#b11">[14]</ref>. This benchmark provides validation and test accuracy information for each of the three datasets. The cell structure is different compared to NAS-Bench-101: Each cell has |V | = 4 nodes and |E| = 6 edges, where the former represent feature maps and the latter denote operations chosen from the set O = {1 ? 1 conv., 3 ? 3 conv., 3 ? 3 avg pooling, skip, zero}. <ref type="figure" target="#fig_6">Figure 6</ref> visualizes a DAG in the true variant in the NAS-Bench-201 search space with edge attributes, as well as our adapted representation, where the edge attributes are changed to node attributes. This is similar to the represen-tation in <ref type="bibr" target="#b41">[65]</ref>. We show experiments on NAS-Bench-101 and NAS-Bench-201 in subsection 4.1. NAS-Bench-301 <ref type="bibr" target="#b24">[48]</ref> is the first surrogate benchmark, which evaluates several surrogate models on in total 60, 000 sampled architectures from the DARTS [34] search space on the CIFAR-10 [28] image classification task. The DARTS search space consists of 10 18 neural networks, where each network consists of two cells; a normal cell and a reduction cell. Each cell is limited by the number of nodes |N | = 7 and the number of edges |E| = 12, where 4 of these edges connect the intermediate nodes (excluding the input nodes) to the output node. Each edge denotes an operation from the set O = {3 ? 3 sep. conv., 5 ? 5 sep. conv., 3 ? 3 dil. conv., 5 ? 5 dil. conv., 3 ? 3 avg pooling, 3 ? 3 max pooling, identity, zero}. Each intermediate edge is connected to two predecessor nodes. Each cell also contains two input nodes, which are the output nodes from the previous two cells. The overall network is created by stacking the normal and reduction cell.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 DARTS Search Space</head><p>In order to train our generative model to generate valid cells, we additionally randomly sample 500k architectures from the DARTS search space. We train our generative model to learn to generate valid cells independently of being a normal or reduction cell. In <ref type="figure" target="#fig_7">Figure 7</ref> we visualize the adapted node attribute matrix and the adapted adjacency matrix to an exemplary DAG in the DARTS search space <ref type="bibr">[34]</ref>. This is similar to the representation in <ref type="bibr" target="#b41">[65]</ref>.</p><p>A.4 NAS-Bench-NLP For the experiments on NAS-Bench-NLP [27] we make use of the surrogate benchmark NAS-Bench-X11 <ref type="bibr" target="#b40">[64]</ref> and the additional implementation in NAS-Bench-Suite [37]. Note, for the NAS-Bench-X11 evaluations, each architecture from the NAS-Bench-NLP search space must be trained for three epochs to use the surrogate model, whereas NAS-Bench-Suite provides the surrogate model for NAS-Bench-NLP without learning curve information, but also accompanying a lower Kendall Tau rank correlation. For fast evaluations we use the latter surrogate for our experiments. In order to use the surrogate benchmark, the architecture representation is the same used in <ref type="bibr" target="#b40">[64]</ref> with the modification that each hidden node is connected to the output node. An exemplary architecture representation is visualized in <ref type="figure" target="#fig_8">Figure 8</ref>. A next step is to analyse the 14, 332 provided architectures on uniqueness, which leads to 12, 107 unique architectures. Furthermore, since <ref type="bibr" target="#b40">[64]</ref> and <ref type="bibr">[37]</ref> only provide a surrogate model, which only considers architectures with up to 12 nodes, we also restrict our training data to this subset leading to a total of 7, 258 architectures.</p><p>We show experiments in the DARTs search space and on NAS-Bench-NLP in subsection 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Hardware-Aware-NAS-Bench</head><p>The recently introduced HW-NAS-Bench [30] is the first public dataset for hardware NAS. It extends two representative NAS search spaces, NAS-Bench-201 <ref type="bibr" target="#b14">[17]</ref> and FBNet <ref type="bibr" target="#b35">[59]</ref>, by providing measured and estimated hardware costs (i.e. latency and/or energy) for each device for all architectures in both search spaces. For this, HW-NAS-Bench considers six hardware devices: Edge GPU <ref type="bibr" target="#b1">[3]</ref>, Raspi 4 [4], Edge TPU [1], Pixel 3 <ref type="bibr" target="#b0">[2]</ref>, ASIC-Eyeriss <ref type="bibr" target="#b10">[13]</ref> and FPGA <ref type="bibr" target="#b2">[5,</ref><ref type="bibr" target="#b3">6]</ref>.</p><p>In our experiments in subsection 4.3 we consider the latency information on the NAS-Bench-201 search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Ablation Studies</head><p>In this section we give an overview of different ablation studies with respect to the proposed AG-Net. <ref type="figure">Fig. 9</ref>: Architecture search on NAS-Bench-101. Reported is the mean over 10 trials for the search of the best architecture in terms of validation accuracy on the CIFAR-10 image classification task compared to strong predictor models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Oracle Ablation</head><p>As we have seen in the previous section, our model AG-Net is able to find high-scoring architectures in various search spaces of different sizes and with different objectives. In addition, including the supposedly stronger predictor XGB  <ref type="bibr" target="#b7">[10]</ref> leads to improvements for the search on NAS-Bench-NLP <ref type="bibr">[27]</ref>. In this section, we include an even stronger architecture accuracy evaluation model, i.e. the benchmark query input itself (oracle). The comparison of the oracle benchmark (also including the ranking metric as for XGB in the main paper) to our AG-Net and XGB modifications are visualized in <ref type="figure">Figure 9</ref>. This figure demonstrates the high performance of our model in the low query area. The more queries are evaluated for the search, the better the oracle becomes, outperforming all other methods after 150 queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Latent Space Ablations</head><p>As we have seen in subsection 4.1, AG-Net improves over state-of-the art methods. For additional comparisons, we investigate different search methods in the latent space of the generative model, with samples z from a grid and also include baselines using the LSO approach. For the first experiment we use the generator solely as a data sampler from the generator's latent space without any retraining, for the latter baseline we retrain the generator during the search. For the optimization, we use Bayesian optimization, local search and random search.</p><p>Bayesian Optimization We use DNGO <ref type="bibr" target="#b26">[50]</ref> as our uncertainty prediction model for the Bayesian optimization search strategy, with the basis regression network being a one-layer MLP with a hidden dimensionality of 128, which is trained for 100 epochs and expected improvement (EI) [39] as our acquisition function, which is mostly used in NAS. We set the best function value for the EI evaluation as the best validation accuracy of the training data. We sample 16 initial random latent space variables z ? U[?3, 3] and decode them to graph data using our pretrained generative model. These latent space variables and their corresponding validation architecture performances are then the inputs for the DNGO model for training. Again, the best 16 architectures are selected using EI in each round to be evaluated and added to the training data. This search ends when the total query amount of 300 is reached. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random and Local Search</head><p>In addition to Bayesian Optimization as a comparison, we also include a random search [31] and local search investigation. Recently, <ref type="bibr" target="#b33">[57]</ref> show that local search is a powerful NAS baseline, resulting in competitive results. Local search <ref type="bibr" target="#b33">[57]</ref> evaluates samples and their neighborhood uniformly at random. An option to define the neighborhood is the set of architectures which differ from a sampled architecture by one node or edge. This can be done only in the discrete search space, given for example by the tabular NAS-Benchmarks. We have to adapt the neighborhood definition in our latent space for local search in this space. We sample a latent space variable z ? U[?3, 3], decode it and evaluate the generated neural architecture. Here, we define neighborhood as the Euclidean space around the sampled latent variable U ? (z) = {y ? U[?3, 3]|d(z, y) &lt; ?}, with ? being sufficiently small. This neighborhood is then investigated until a local optimum in terms of validation accuracy is reached. Furthermore, we include a random search and local search comparison using weighted retraining. Here, we retrain the generative model in each search iteration for 1 epoch with the weighted objective function, ceteris paribus.</p><p>To compare with weight-sharing approaches, we also compare to the supernet from [23] for the NAS-Bench-201 search space. To compare our AG-Net with SGNAS, we use the supernet as our surrogate model to predict the architectures performance while retraining the generative model in the weighted manner. The results of our ablation studies are reported in <ref type="table" target="#tab_9">Table 7</ref>. AG-Net improves over search methods on the latent space with and without LSO on both benchmarks, demonstrating that our generator in combination with our MLP surrogate model learns to adapt the distribution shift constructed by the weighted retraining best.</p><p>For further visualizations we also plot different ablation search methods over different query numbers in <ref type="figure" target="#fig_0">Figure 10</ref> for both benchmarks NAS-Bench-101 and NAS-Bench-201. This figure demonstrates the high any-time performance of our method on both search spaces. For any number of available queries, our model is better in finding high-performing architectures from the latent space than other latent space based methods. Our proposed method, consisting of the generative and surrogate model combined with the latent space optimization, makes the architecture search focus on promising regions in the search space. This method could be trapped in local solutions, which we investigate experimentally in the following. First, the previous section already points out that our proposed method AG-Net improves over both local search methods with and without the latent space optimization approach. Thus, we assume that the latent space optimization learns properties of high-scoring architectures without being easily trapped in poor local solutions. The amount of samples drawn in each search iteration also provides a trade-off between diversity versus specificity. To investigate further how easily AG-Net could be trapped in a local solution, we test our method when it only uses in total the best k (predicted) architectures from our test samples and the training data as a new training set for the next search iteration (degenerative) and is thereby encouraged to forget about worse performing architectures. <ref type="figure" target="#fig_0">Figure 11</ref> shows the search behaviour of the degenerative model with k = 16 and k = 32. Even in this case, AG-Net is not easily trapped in poor solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Predictor Ablation -Local Solution</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Experiments: Implementation Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Surrogate Model</head><p>In this section, we present details about the surrogate models used in the main paper. The MLP surrogate model used for our AG-Net is a 4-layer MLP with ReLU non-activation functions. The hidden size equals the input size. The input to the MLP surrogate model is the vector representation ? R n of our graphs: a concatenation of the flatted node attribute matrix and flatted upper triangular matrix of the adjacency matrix, which presents the edge scores, see section A for visualizations. Note, the vector dimension n differs across the search spaces due to the different maximal amount of nodes. Our AG-Net passes the output of our generator, i.e. a generated vector representation, as the direct input to our MLP surrogate model.</p><p>We consider as an alternative surrogate model the XGB <ref type="bibr" target="#b7">[10]</ref> prediction model. The input to this prediction model is the vector representation of the architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Search Algorithm</head><p>High-level descriptions of the unconstrained (subsection 4.1) and constrained (subsection 4.3) versions of our search algorithm are depicted in algorithm 1 and algorithm 2 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 NAS-Bench-101</head><p>In this section, we give more information about the NAS-Bench-101 experiments from the main paper. <ref type="table" target="#tab_10">Table 8</ref> is the detailed version of <ref type="table" target="#tab_2">Table 1</ref> including the standard deviation.</p><p>C.4 NAS-Bench-201 <ref type="table" target="#tab_11">Table 9</ref> is the detailed version of <ref type="table" target="#tab_3">Table 2</ref> including the standard deviation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 DARTS Search Space</head><p>Additional Results <ref type="table" target="#tab_2">Table 10</ref> is the detailed version of <ref type="table" target="#tab_4">Table 3</ref> including the standard deviation.</p><p>Search Process using NAS-Bench-301 For experiments in the DARTS [34] search space, we first train our generative model on generating valid cells, as visualized in <ref type="figure" target="#fig_7">Figure 7</ref>; here we do not distinguish between generating a normal or a reduction cell. Having a pretrained generative model for generating valid cell representations in the DARTS search space allows for searching well-performing architectures. Here we describe the search process for architectures evaluated on CIFAR-10 using the surrogate benchmark NAS-Bench-301 <ref type="bibr" target="#b24">[48]</ref>. Since the DARTS search space is defined by a normal and reduction cell, we have to adapt the search process, compared to the search in the tabular benchmark search spaces, where the architectures differ between the DAG. We begin the search by randomly sampling 16 architectures from NAS-Bench-301. Next, we generate one normal cell. This cell is used to search for the best reduction cell in terms of the accuracy given by the surrogate benchmark NAS-Bench-301, in combination with the randomly sampled cell. This search procedure then follows the same steps as for the tabular benchmarks and stops after we reach a query amount of 155. Now, we can use the best found reduction cell as a fixed starting point to search for the best normal cell in the same manner as before. The overall search stops after a maximal amount of 310 queries. The search outcome differs between starting with a reduction or the normal cell. The search procedure starting with a random reduction cell is analogous. In the main paper, we report the search outcome for NAS-Bench-301 <ref type="bibr" target="#b24">[48]</ref> starting with a random reduction cell.</p><p>Search Process using TENAS As we described in the previous section, the search in the DARTS [34] search space needs adaptions in the search procedure. Here we describe the further adaption of using training free measurements instead of the NAS-Bench-301 prediction. The training free measurements are based on the recent paper TE-NAS <ref type="bibr" target="#b8">[11]</ref>, which ranks architectures by analysing the neural tangent kernel, by its condition number (KN), and the number of linear regions (NLR) of each architecture. Concretely, for the search on ImageNet <ref type="bibr" target="#b12">[15]</ref> we search for architectures in terms of their KN value and their number of linear regions instead of their validation accuracy. In the beginning of our search we generate three random normal cells. These cells are used to search for an optimal reduction cell optimizing both KN and NLR measurements. In each search iteration we generate reduction cells and calculate the KN and NLR for each combination of normal cell and reduction cell. The reduction cells are ranked according to their mean KN and their mean NLR (mean in terms of all three normal cells). The 16 best ranked reduction cells are then used for the next iteration of reduction cell search. The reduction cell search stops, when a maximum of 104 queries is reached. After that we use the best found reduction cell in terms of the lowest KN and the highest NLR for the next search for a normal cell. The next steps use this best found reduction cell as a starting point and searches for the best normal cell in the same manner as before. The search stops after a total of 208 queries and outputs an overall normal and reduction cell combination, leading to a DARTS [34] architecture, which we train on ImageNet <ref type="bibr" target="#b12">[15]</ref> using the same training pipeline as <ref type="bibr" target="#b8">[11]</ref>.</p><p>C.6 NAS-Bench-NLP <ref type="table" target="#tab_2">Table 11</ref> is the detailed version of <ref type="table" target="#tab_4">Table 3</ref> including the standard deviation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.7 Hardware-Aware NAS-Bench</head><p>In comparison to the experiments for NAS-Bench-101 <ref type="bibr" target="#b42">[66]</ref> and NAS-Bench-201 <ref type="bibr" target="#b14">[17]</ref> image benchmarks, the search on the Hardware-Aware NAS-Bench <ref type="bibr">[30]</ref> changes to be a multi-objective learning procedure. We compare two different objective settings: i) a joint constrained optimization in Equation 4 and ii) a constrained optimization in <ref type="bibr">Equation 5</ref>. For both settings we need to adapt the surrogate model by including an additional predictor g(?) for latency. We implement g(?) equally to the performance predictor f (?), whereas both predictors  share weights in our experiments. We give a detailed overview of the hyperparameter settings in section E. Since we include an additional predictor, the training objective needs to be updated, as seen in <ref type="figure" target="#fig_6">Equation 6</ref> with multiple targets. The risk of including multiple targets to the training objective is an exploding loss leading to reduced valid generation ability of our generative network. In order to overcome this problem, we scale each loss term by the largest one, such that each term is at most 1. This way, we have a more stable training.</p><p>Exemplary Searches for Other Devices In <ref type="figure" target="#fig_3">Figure 4</ref> we showed an exemplary search result comparing random search with both of our constrained algorithm settings in the case of different latency constraints on a Pixel3. In the following, we show more examples on different devices in <ref type="figure" target="#fig_0">Figure 12</ref>. These plots show that both methods Joint=1 and Joint=0 outperform the random search baseline in all different device experiments. The same results as in the main paper holds Search Progress and Baselines Local search <ref type="bibr" target="#b33">[57]</ref> is considered a strong baseline in NAS. In the case of constrained searches (as in HW-NAS-Bench), we noticed that it cannot perform well without adaptation. The vanilla local search algorithm expects as input a single randomly drawn architecture from the search space. However, this architecture is not guaranteed to be feasible in this setting, as its latency can be larger than the latency constraint. To circumvent this, we performed local search in the following settings: (a) local search vanilla setting with one randomly drawn architecture, and (b) local search initialized with 16 randomly drawn architectures. In each setting, local search continues to search the neighborhood of the next best architecture in terms of accuracy that satisfies the latency constraint. We noticed that initializing local search with 16 randomly drawn architectures improves its performance substantially, however, it is still not on par with random search [31] in this constrained search space. Consequently, we only show random search as the baseline in <ref type="table">Table 5</ref> to improve readability. In <ref type="figure" target="#fig_0">Figure 13</ref> we show the progress of our algorithms (Joint=0 and Joint=1 ) compared to random search and local search in settings (a) and (b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Generator Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Generator Evaluation</head><p>Based on an investigation of autoencoder abilities from <ref type="bibr" target="#b41">[65]</ref> and [35], we can examine the generation ability of our generative model. For that we train our generator on 90% of the overall dataset, and thus have a hold-out dataset of 10% for the tabular benchmarks. The generative model training on the surrogate benchmarks is a priori only on a subset of the overall dataset. Additionally, we sample 10, 000 random variables z ? N (0, 1) and decode them to graphs. We report the results of this investigation in <ref type="table" target="#tab_2">Table 12</ref>. Here, validity describes the ratio of valid graphs our generator model generates, uniqueness describes the portion of unique graphs from the valid generated graphs, and novelty is the portion of generated graphs not in the training set. It is not surprising for the NAS-Bench-301 and NAS-Bench-NLP search spaces, that our model is able to generate 100% unique and novel graphs, given the large size of both search spaces. This demonstrates that our simple generator model is able to generate valid graphs with high novelty and consequently is able to cover a substantial part of the search space. <ref type="table" target="#tab_2">Table 12</ref> also reports the training costs of the generative model on the complete dataset as described in section A on a single Tesla V100. We used for the experiments the OMNI cluster from the University of Siegen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Generator Implementation Details</head><p>In this section we present more details about the generation model SVGe from <ref type="bibr">[35]</ref>. The pseudo algorithm is described in algorithm 3. The modules f initNode , f addNode , f addEdges , f Embedding used in this code are two-layer MLPs with ReLU activation functions. Note, in contrast to SVGe, we don't sample within the   <ref type="table">Table 5</ref> at any time during the search progress in terms of the number of evaluated architectures (up to 320). Optimality is the mean validation accuracy of 10 runs per algorithm, normalized by the optimal value for each parameter setting (hence, optimum is at 1.0). (right) zoomed y-axis generation process, in order to allow for end-to-end learning with the prediction model for AG-Net.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Hyperparameters</head><p>In this section we give a detailed overview about the hyperparameter for our generative network. We use pytorch [40] and pytorch geometric <ref type="bibr" target="#b16">[19]</ref> for all our implementations. <ref type="table" target="#tab_2">Table 13</ref> presents all used hyperparameters for the generation training. We train our generator in a ticked manner; after every 5.000 train data, we evaluate our generator for validity ability. The used pretrained state dict for our search is then, the one, which the highest validation measurement, which is defined by randomly sample 10, 000 latent vectors z ? R 32 and generate architectures. The training is the same for all different search spaces.    <ref type="figure" target="#fig_0">Fig. 14:</ref> The latent space is reshaped in a way that promotes desired properties of generated architectures (in this example: accuracy). Consequently, it becomes more likely for the generator to generate architectures satisfying this property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Generator</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>(left) Our search method generates architectures from points in an architecture representation space that is iteratively optimized. (right) The architecture representation space is biased towards better-performing architectures with each search iteration. After only 48 evaluated architectures, our generator produces state-of-the-art performing architectures on NAS-Bench-101.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Representation of the training procedure for our generator in AG-Net.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Architecture search evaluations on NAS-Bench-201, NAS-Bench-101, NAS-Bench-301 and NAS-Bench-NLP for different search methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>(left) Exemplary searches on HW-NAS-Bench for image classification on ImageNet16 with 192 queries on Pixel 3 and latency conditions L ? {2, 4, 6, 8, 10} (y-axis zoomed for visibility). (right) Amount of architectures generated and selected in each search iteration (at most 16) that satisfy the latency constraint. In this example we searched on Edge GPU with L = 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>23. Huang, S., Chu, W.: Searching by generating: Flexible and efficient one-shot NAS with architecture generator. In: CVPR (2021) 24. Kandasamy, K., Neiswanger, W., Schneider, J., P?czos, B., Xing, E.P.: Neural architecture search with bayesian optimisation and optimal transport. In: NIPS (2018) 25. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In: ICLR(2015) 26. Kingma, D.P., Welling, M.: Auto-encoding variational bayes. In: ICLR (2014) 27. Klyuchnikov, N., Trofimov, I., Artemova, E., Salnikov, M., Fedorov, M., Burnaev, E.: Nas-bench-nlp: Neural architecture search benchmark for natural language processing. CoRR abs/2006.07116 (2020) 28. Krizhevsky, A.: Learning multiple layers of features from tiny images (2009) 29. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: NIPS (2012) 30. Li, C., Yu, Z., Fu, Y., Zhang, Y., Zhao, Y., You, H., Yu, Q., Wang, Y., Hao, C., Lin, Y.: Hw-nas-bench: Hardware-aware neural architecture search benchmark. In: ICLR (2021) 31. Li, L., Talwalkar, A.: Random search and reproducibility for neural architecture search. In: UAI (2019) 32. Li, Y., Vinyals, O., Dyer, C., Pascanu, R., Battaglia, P.W.: Learning deep generative models of graphs. CoRR abs/1803.03324 (2018) 33. Liu, C., Zoph, B., Neumann, M., Shlens, J., Hua, W., Li, L., Fei-Fei, L., Yuille, A.L., Huang, J., Murphy, K.: Progressive neural architecture search. In: ECCV (2018) 34. Liu, H., Simonyan, K., Yang, Y.: DARTS: differentiable architecture search (2019) 35. Lukasik, J., Friede, D., Zela, A., Hutter, F., Keuper, M.: Smooth variational graph embeddings for efficient neural architecture search. In: IJCNN (2021) 36. Luo, R., Tian, F., Qin, T., Chen, E., Liu, T.: Neural architecture optimization. In: NeurIPS (2018) 37. Mehta, Y., White, C., Zela, A., Krishnakumar, A., Zabergja, G., Moradian, S., Safari, M., Yu, K., Hutter, F.: Nas-bench-suite: NAS evaluation is (now) surprisingly easy. CoRR abs/2201.13396 (2022) 38. Mikolov, T., Karafi?t, M., Burget, L., Cernock?, J., Khudanpur, S.: Recurrent neural network based language model. In: Kobayashi, T., Hirose, K., Nakamura, S. (eds.) INTERSPEECH 2010, 11th Annual Conference of the International Speech Communication Association, Makuhari, Chiba, Japan, September 26-30, 2010 (2010) 39. Mockus, J.: On bayesian methods for seeking the extremum. In: Optimization Techniques, IFIP Technical Conference, Novosibirsk, USSR, July 1-7, 1974. Springer (1974) 40. Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., Chintala, S.: Pytorch: An imperative style, high-performance deep learning library. In: NeurIPS, pp. 8024-8035 (2019) 41. Pham, H., Guan, M.Y., Zoph, B., Le, Q.V., Dean, J.: Efficient neural architecture search via parameter sharing. In: ICML (2018) 42. Real, E., Aggarwal, A., Huang, Y., Le, Q.V.: Regularized evolution for image classifier architecture search. In: AAAI (2019) 43. Real, E., Moore, S., Selle, A., Saxena, S., Suematsu, Y.L., Tan, J., Le, Q.V., Kurakin, A.: Large-scale evolution of image classifiers. In: ICML (2017) 67. Zela, A., Elsken, T., Saikia, T., Marrakchi, Y., Brox, T., Hutter, F.: Understanding and robustifying differentiable architecture search. In: ICLR (2020) 68. Zhang, M., Jiang, S., Cui, Z., Garnett, R., Chen, Y.: D-vae: A variational autoencoder for directed acyclic graphs. In: NIPS (2019) 69. Zoph, B., Le, Q.V.: Neural architecture search with reinforcement learning. In: ICLR (2017) 70. Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V.: Learning transferable architectures for scalable image recognition. In: CVPR (2018)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Exemplary cell representation from the NAS-Bench-101 search space. (left) DAG representation of a graph with 7 nodes. (right) The top part shows the node attribute matrix to the DAG and the bottom part shows its adjacency matrix. NAS-Bench-101 is the first tabular benchmark designed for benchmarking NAS methods. This search space is a cell-based search space and contains 423, 624 unique neural networks. Each architecture is trained 3 times on CIFAR-10 [28] for image classification. The cell topology is limited to the number of nodes |V | ? 7 (including input and output nodes) and edges |E| ? 9. The nodes represent the architecture layers and intermediate nodes can take any operation from the operation set O = {1 ? 1 conv., 3 ? 3 conv., 3 ? 3 max pooling}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 :</head><label>6</label><figDesc>Exemplary cell representation from the NAS-Bench-201 search space. (top) The left part visualizes the DAG representation with node attributes instead of edge attributes. The right part shows the true DAG representation in the NAS-Bench-201 search space. (bottom) The left part shows the node attribute matrix to the DAG and the right part shows its adjacency matrix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 :</head><label>7</label><figDesc>Exemplary cell representation from the DARTS search space. (top) Visualization of the DAG representation in the DARTS search space. (bottom) The left part shows the node attribute matrix to the DAG and the right part shows its adjacency matrix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 :</head><label>8</label><figDesc>Exemplary cell representation from the NAS-Bench-NLP search space. (left) DAG representation of a graph with 12 nodes. (right) The top part shows the node attribute matrix to the DAG and the bottom part shows its adjacency matrix. NAS-Bench-NLP [27] is the first RNN-derived benchmark for language modeling tasks. From the total 10 53 possible architectures in the complete search space, 14, 322 architectures are trained on Penn TreeBank [38] (PTB) and provided in this benchmark. The cell search space is constrained by the number of nodes |V | ? 24, the number of hidden states |H| ? 3 and the number of linear input vectors ? 3. The nodes represent the architecture operational layer and are chosen from the set O = {linear, element wise blending, element wise product, element wise sum, Tanh activation, Sigmoid activation, LeakyReLU activation}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 :</head><label>10</label><figDesc>Ablation: neural architecture search on NAS-Bench-101 and NAS-Bench-201 over 10 trials.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 :</head><label>11</label><figDesc>Architecture search on NAS-Bench-101 in the degenerate setting. Reported is the mean over 10 trials.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 :</head><label>12</label><figDesc>0.25 0.50 0.75 1.00 1.25 1.50 1.75 2Exemplary searches on HW-NAS-Bench for image classification on Im-ageNet16 with 192 queries on Edge GPU, Raspi4, Eyeriss, FPGA and latency conditions L ? {2, 4, 6, 8, 10}, L ? {2, 4, 6, 8, 10, 12, 14} and L ? {1, 2} (y-axis zoomed for visibility).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 :</head><label>13</label><figDesc>(left) Optimality for all search parameters in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>To enable benchmarking within the NAS community, different search spaces have been proposed. The tabular benchmarks NAS-Bench-101<ref type="bibr" target="#b42">[66]</ref> and NAS-Bench-201<ref type="bibr" target="#b14">[17]</ref> provide both an exhaustive covering of metrics and performances. NAS-bench-NLP [27] provides a search space for natural language processing. In addition to these tabular benchmarks NAS-Bench-301<ref type="bibr" target="#b24">[48]</ref> provides a surrogate benchmark, which allows for fast evaluation of NAS methods on the DARTS [34] search space by querying the validation accuracy. NAS-Bench-x11<ref type="bibr" target="#b40">[64]</ref> is another surrogate benchmark. It outputs full training information for each architecture in all four mentioned benchmarks. NAS-Bench-Suite [37] facilitates reproducible search on these NAS benchmarks.Early NAS approaches are based on discrete encodings of search spaces, such as in the form of adjacency matrices, and can be distinguished by their search strategy. Examples are random search<ref type="bibr" target="#b5">[8,</ref>31], reinforcement learning (RL)[69,32], evolutionary methods[43,42], local search</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Details about all hyperparameters are given in the supp. mat. section E.</figDesc><table><row><cell>evaluated on the</cell></row><row><cell>DARTS search space [34], NAS-Bench-NLP [27] and the first hardware device</cell></row><row><cell>induced benchmark [30]. Additionally we perform experiments on the ImageNet</cell></row><row><cell>[15] classification task and show state-of-the-art performance on the DARTS</cell></row><row><cell>search space. In our experiments in subsection 4.3 for the Hardware-Aware</cell></row><row><cell>Benchmark we consider the latency information on the NAS-Bench-201 search</cell></row><row><cell>space.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Results on NAS-Bench-101 for the search of the best architecture in terms of validation accuracy on CIFAR-10 to state-of-the-art methods (mean over 10 trials).</figDesc><table><row><cell>NAS Method</cell><cell cols="3">Val. Acc (%) Test Acc (%) Queries</cell></row><row><cell>Optimum*</cell><cell>95.06</cell><cell>94.32</cell><cell></cell></row><row><cell>Arch2vec + RL [65]</cell><cell>-</cell><cell>94.10</cell><cell>400</cell></row><row><cell>Arch2vec + BO [65]</cell><cell>-</cell><cell>94.05</cell><cell>400</cell></row><row><cell>NAO  ? [36]</cell><cell>94.66</cell><cell>93.49</cell><cell>192</cell></row><row><cell>BANANAS  ? [56]</cell><cell>94.73</cell><cell>94.09</cell><cell>192</cell></row><row><cell>Bayesian Optimization  ? [50]</cell><cell>94.57</cell><cell>93.96</cell><cell>192</cell></row><row><cell>Local Search  ? [57]</cell><cell>94.57</cell><cell>93.97</cell><cell>192</cell></row><row><cell>Random Search  ? [31]</cell><cell>94.31</cell><cell>93.61</cell><cell>192</cell></row><row><cell>Regularized Evolution  ? [42]</cell><cell>94.47</cell><cell>93.89</cell><cell>192</cell></row><row><cell>WeakNAS [60]</cell><cell>-</cell><cell>94.18</cell><cell>200</cell></row><row><cell>XGB (ours)</cell><cell>94.61</cell><cell>94.13</cell><cell>192</cell></row><row><cell>XGB + ranking (ours)</cell><cell>94.60</cell><cell>94.14</cell><cell>192</cell></row><row><cell>AG-Net (ours)</cell><cell>94.90</cell><cell>94.18</cell><cell>192</cell></row></table><note>4.2 Experiments on Surrogate Benchmarks We furthermore apply our search method on larger search spaces as DARTS [34] and NAS-Bench-NLP [27] without ground truth evaluations for the whole search space, making use of surrogate benchmarks as NAS-Bench-301 [48], NAS-Bench- X11 [64] and NAS-Bench-Suite [37]. NAS-Bench-301 Here, we report experiments on the cell-based DARTS [34] search space using the surrogate benchmark NAS-Bench-301</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Architecture Search on NAS-Bench-201. We report the mean over 10 trials for the search of the architecture with the highest validation accuracy. Acc Test Acc Val. Acc Test Acc Val. Acc Test Acc</figDesc><table><row><cell>NAS Method</cell><cell cols="2">CIFAR-10</cell><cell cols="2">CIFAR-100</cell><cell cols="3">ImageNet16-120 Queries</cell><cell>Search Method</cell></row><row><cell cols="2">Val. Optimum* 91.61</cell><cell>94.37</cell><cell>73.49</cell><cell>73.51</cell><cell>46.77</cell><cell>47.31</cell><cell></cell><cell></cell></row><row><cell>SGNAS [23]</cell><cell>90.18</cell><cell>93.53</cell><cell>70.28</cell><cell>70.31</cell><cell>44.65</cell><cell>44.98</cell><cell></cell><cell>Supernet</cell></row><row><cell>Arch2vec + BO [65]</cell><cell>91.41</cell><cell>94.18</cell><cell>73.35</cell><cell>73.37</cell><cell>46.34</cell><cell>46.27</cell><cell>100</cell><cell>Bayesian Optimization</cell></row><row><cell>AG-Net (ours)</cell><cell>91.55</cell><cell>94.24</cell><cell>73.2</cell><cell>73.12</cell><cell>46.31</cell><cell>46.2</cell><cell>96</cell><cell>Generative LSO</cell></row><row><cell>AG-Net (ours, topk=1)</cell><cell>91.41</cell><cell>94.16</cell><cell>73.14</cell><cell>73.15</cell><cell>46.42</cell><cell>46.43</cell><cell>100</cell><cell>Generative LSO</cell></row><row><cell>BANANAS  ? [56]</cell><cell>91.56</cell><cell>94.3</cell><cell>73.49*</cell><cell>73.50</cell><cell>46.65</cell><cell>46.51</cell><cell>192</cell><cell>Bayesian Optimization</cell></row><row><cell>BO  ? [50]</cell><cell>91.54</cell><cell>94.22</cell><cell>73.26</cell><cell>73.22</cell><cell>46.43</cell><cell>46.40</cell><cell>192</cell><cell>Bayesian Optimization</cell></row><row><cell>RS  ? [31]</cell><cell>91.12</cell><cell>93.89</cell><cell>72.08</cell><cell>72.07</cell><cell>45.87</cell><cell>45.98</cell><cell>192</cell><cell>Random</cell></row><row><cell>XGB (ours)</cell><cell>91.54</cell><cell>94.34</cell><cell>73.10</cell><cell>72.93</cell><cell>46.48</cell><cell>46.08</cell><cell>192</cell><cell>Generative LSO</cell></row><row><cell>XGB + Ranking (ours)</cell><cell>91.48</cell><cell>94.25</cell><cell>73.20</cell><cell>73.24</cell><cell>46.40</cell><cell>46.16</cell><cell>192</cell><cell>Generative LSO</cell></row><row><cell>AG-Net (ours)</cell><cell cols="4">91.60 94.37* 73.49* 73.51*</cell><cell>46.64</cell><cell>46.43</cell><cell>192</cell><cell>Generative LSO</cell></row><row><cell>GANAS [44]</cell><cell>-</cell><cell>94.34</cell><cell>-</cell><cell>73.28</cell><cell>-</cell><cell>46.80</cell><cell>444</cell><cell>Generative Reinforcement Learning</cell></row><row><cell>AG-Net (ours)</cell><cell cols="4">91.61* 94.37* 73.49* 73.51*</cell><cell>46.73</cell><cell>46.42</cell><cell>400</cell><cell>Generative LSO</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell>NAS Method</cell><cell cols="2">NAS-Bench-301</cell><cell cols="2">NAS-Bench-NLP</cell></row><row><cell></cell><cell cols="2">Val. Acc (%) Queries</cell><cell cols="2">Val. Perplexity (%) Queries</cell></row><row><cell>BANANAS  ? [56]</cell><cell>94.77</cell><cell>192</cell><cell>95.68</cell><cell>304</cell></row><row><cell>Bayesian Optimization  ? [50]</cell><cell>94.71</cell><cell>192</cell><cell>-</cell><cell>-</cell></row><row><cell>Local Search  ? [57]</cell><cell>95.02</cell><cell>192</cell><cell>95.69</cell><cell>304</cell></row><row><cell>Random Search  ? [31]</cell><cell>94.31</cell><cell>192</cell><cell>95.64</cell><cell>304</cell></row><row><cell>Regularized Evolution  ? [42]</cell><cell>94.75</cell><cell>192</cell><cell>95.66</cell><cell>304</cell></row><row><cell>XGB (ours)</cell><cell>94.79</cell><cell>192</cell><cell>95.95</cell><cell>304</cell></row><row><cell>XGB + Ranking (ours)</cell><cell>94.76</cell><cell>192</cell><cell>95.92</cell><cell>304</cell></row><row><cell>AG-Net (ours)</cell><cell>94.79</cell><cell>192</cell><cell>95.86</cell><cell>304</cell></row></table><note>Results on: (left) NAS-Bench-301 (mean validation accuracy over 50 trials). (right) NAS-Bench-NLP (mean validation perplexity over 100 trials).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>ImageNet error of neural architecture search on DARTS.</figDesc><table><row><cell>NAS Method</cell><cell cols="2">Top-1? Top-5?</cell><cell># Queries</cell><cell>Search GPU days</cell></row><row><cell>Mixed Methods</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>NASNET-A (CIFAR-10) [70]</cell><cell>26.0</cell><cell>8.4</cell><cell>20000</cell><cell>2000</cell></row><row><cell>PNAS (CIFAR-10) [33]</cell><cell>25.8</cell><cell>8.1</cell><cell>1160</cell><cell>225</cell></row><row><cell>NAO (CIFAR-10) [36]</cell><cell>24.5</cell><cell>7.8</cell><cell>1000</cell><cell>200</cell></row><row><cell>Differentiable Methods</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DARTS (CIFAR-10) [34]</cell><cell>26.7</cell><cell>8.7</cell><cell>-</cell><cell>4.0</cell></row><row><cell>SNAS (CIFAR-10)[61]</cell><cell>27.3</cell><cell>9.2</cell><cell>-</cell><cell>1.5</cell></row><row><cell>PDARTS (CIFAR-10) [12]</cell><cell>24.4</cell><cell>7.4</cell><cell>-</cell><cell>0.3</cell></row><row><cell>PC-DARTS (CIFAR-10) [63]</cell><cell>25.1</cell><cell>7.8</cell><cell>-</cell><cell>0.1</cell></row><row><cell>PC-DARTS (ImageNet) [63]</cell><cell>24.2</cell><cell>7.3</cell><cell>-</cell><cell>3.8</cell></row><row><cell>Predictor Based Methods</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>WeakNAS (ImageNet) [60]</cell><cell>23.5</cell><cell>6.8</cell><cell>800</cell><cell>2.5</cell></row><row><cell>XGB (NB-301)(CIFAR-10) (ours)</cell><cell>24.1</cell><cell>7.4</cell><cell>304</cell><cell>0.02</cell></row><row><cell>XGB + Ranking (NB-301)(CIFAR-10) (ours)</cell><cell>24.1</cell><cell>7.2</cell><cell>304</cell><cell>0.02</cell></row><row><cell>AG-Net (NB-301)(CIFAR-10) (ours)</cell><cell>24.3</cell><cell>7.3</cell><cell>304</cell><cell>0.21</cell></row><row><cell>Training-Free Methods</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TE-NAS (CIFAR-10)[11]</cell><cell>26.2</cell><cell>8.3</cell><cell>-</cell><cell>0.05</cell></row><row><cell>TE-NAS (ImageNet)[11]</cell><cell>24.5</cell><cell>7.5</cell><cell>-</cell><cell>0.17</cell></row><row><cell>AG-Net (CIFAR-10) (ours)</cell><cell>23.5</cell><cell>7.1</cell><cell>208</cell><cell>0.02</cell></row><row><cell>AG-Net (ImageNet) (ours)</cell><cell>23.5</cell><cell>6.9</cell><cell>208</cell><cell>0.09</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Ablation: Search results on NAS-Bench-101 and NAS-Bench-201 using AG-Net (mean over 10 trials with a maximal query amount of 192).</figDesc><table><row><cell></cell><cell cols="2">NAS-Bench-101</cell><cell></cell><cell></cell><cell cols="2">NAS-Bench-201</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">CIFAR-10</cell><cell cols="2">CIFAR-10</cell><cell cols="2">CIFAR-100</cell><cell cols="2">ImageNet16-120</cell></row><row><cell></cell><cell cols="2">Val. Acc Test Acc</cell><cell cols="6">Val. Acc Test Acc Val. Acc Test Acc Val. Acc Test Acc</cell></row><row><cell>Optimum*</cell><cell>95.06</cell><cell>94.32</cell><cell>91.61</cell><cell>94.37</cell><cell>73.49</cell><cell>73.51</cell><cell>46.77</cell><cell>47.31</cell></row><row><cell>AG-Net (ours) w/o LSO</cell><cell>94.38</cell><cell>93.78</cell><cell>91.15</cell><cell>93.84</cell><cell>71.72</cell><cell>71.83</cell><cell>45.33</cell><cell>45.04</cell></row><row><cell>AG-Net (ours) w/o backprop</cell><cell>94.71</cell><cell>94.12</cell><cell>91.60</cell><cell>94.30</cell><cell>73.38</cell><cell>73.22</cell><cell>46.62</cell><cell>46.13</cell></row><row><cell>AG-Net (ours)</cell><cell>94.90</cell><cell>94.18</cell><cell>91.60</cell><cell>94.37*</cell><cell>73.49*</cell><cell>73.51*</cell><cell>46.64</cell><cell>46.43</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Ablation: Search results on NAS-Bench-101 and NAS-Bench-201 on the AG-Net latent space (mean over 10 trials with a maximal query amount of 300).</figDesc><table><row><cell></cell><cell cols="2">NAS-Bench-101</cell><cell></cell><cell></cell><cell cols="2">NAS-Bench-201</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">CIFAR-10</cell><cell cols="2">CIFAR-10</cell><cell cols="2">CIFAR-100</cell><cell cols="2">ImageNet16-120</cell></row><row><cell></cell><cell cols="2">Val. Acc Test Acc</cell><cell cols="6">Val. Acc Test Acc Val. Acc Test Acc Val. Acc Test Acc</cell></row><row><cell>Optimum*</cell><cell>95.06</cell><cell>94.32</cell><cell>91.61</cell><cell>94.37</cell><cell>73.49</cell><cell>73.51</cell><cell>46.77</cell><cell>47.31</cell></row><row><cell>Random Search</cell><cell>94.27</cell><cell>93.65</cell><cell>91.37</cell><cell>93.92</cell><cell>72.55</cell><cell>72.49</cell><cell>46.09</cell><cell>46.05</cell></row><row><cell>Local Search</cell><cell>94.31</cell><cell>93.66</cell><cell>91.28</cell><cell>94.01</cell><cell>72.52</cell><cell>72.59</cell><cell>45.89</cell><cell>46.07</cell></row><row><cell>Bayesian Optimization</cell><cell>94.27</cell><cell>93.62</cell><cell>91.30</cell><cell>93.99</cell><cell>72.23</cell><cell>72.35</cell><cell>46.09</cell><cell>46.01</cell></row><row><cell>Random Search + LSO</cell><cell>94.64</cell><cell>94.20</cell><cell>91.61*</cell><cell>94.37*</cell><cell>73.49*</cell><cell>73.51*</cell><cell>46.77*</cell><cell>45.47</cell></row><row><cell>Local Search + LSO</cell><cell>94.17</cell><cell>93.50</cell><cell>91.30</cell><cell>93.96</cell><cell>72.43</cell><cell>72.58</cell><cell>45.83</cell><cell>45.95</cell></row><row><cell>Bayesian Optimization +LSO</cell><cell>94.50</cell><cell>93.96</cell><cell>91.43</cell><cell>94.17</cell><cell>72.64</cell><cell>72.67</cell><cell>46.30</cell><cell>45.91</cell></row><row><cell>SGNAS [23] + LSO</cell><cell>-</cell><cell>-</cell><cell>91.61*</cell><cell>94.37*</cell><cell>73.04</cell><cell>73.12</cell><cell>46.56</cell><cell>46.32</cell></row><row><cell>AG-Net (ours)</cell><cell>94.96</cell><cell>94.20</cell><cell>91.61*</cell><cell>94.37*</cell><cell>73.49*</cell><cell>73.51*</cell><cell>46.67</cell><cell>46.22</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>Architecture search on NAS-Bench-101. Reported is the mean and the standard deviation over 10 trials for the search of the best architecture in terms of validation accuracy on the CIFAR-10 image classification task compared to state-of-the-art methods.</figDesc><table><row><cell>NAS Method</cell><cell cols="4">Val. Acc (%) StD (%) Test Acc (%) StD</cell><cell>(%)Queries</cell></row><row><cell>Optimum*</cell><cell>95.06</cell><cell>-</cell><cell>94.32</cell><cell>-</cell><cell></cell></row><row><cell>Arch2vec + RL [65]</cell><cell>-</cell><cell>-</cell><cell>94.10</cell><cell>-</cell><cell>400</cell></row><row><cell>Arch2vec + BO [65]</cell><cell>-</cell><cell>-</cell><cell>94.05</cell><cell>-</cell><cell>400</cell></row><row><cell>NAO  ? [36]</cell><cell>94.66</cell><cell>0.14</cell><cell>93.49</cell><cell>0.59</cell><cell>192</cell></row><row><cell>BANANAS  ? [56]</cell><cell>94.73</cell><cell>0.17</cell><cell>94.09</cell><cell>0.19</cell><cell>192</cell></row><row><cell>Bayesian Optimization  ? [50]</cell><cell>94.57</cell><cell>0.2</cell><cell>93.96</cell><cell>0.21</cell><cell>192</cell></row><row><cell>Local Search  ? [57]</cell><cell>94.57</cell><cell>0.15</cell><cell>93.97</cell><cell>0.13</cell><cell>192</cell></row><row><cell>Random Search  ? [31]</cell><cell>94.31</cell><cell>0.15</cell><cell>93.61</cell><cell>0.27</cell><cell>192</cell></row><row><cell>Regularized Evolution * [42]</cell><cell>94.47</cell><cell>0.11</cell><cell>93.89</cell><cell>0.2</cell><cell>192</cell></row><row><cell>WeakNAS [60]</cell><cell>-</cell><cell>-</cell><cell>94.18</cell><cell>0.14</cell><cell>200</cell></row><row><cell>XGB (ours)</cell><cell>94.61</cell><cell>0.04</cell><cell>94.13</cell><cell>0.11</cell><cell>192</cell></row><row><cell>XGB + ranking (ours)</cell><cell>94.60</cell><cell>0.08</cell><cell>94.14</cell><cell>0.19</cell><cell>192</cell></row><row><cell>AG-Net (ours)</cell><cell>94.90</cell><cell>0.22</cell><cell>94.18</cell><cell>0.10</cell><cell>192</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Architecture Search on NAS-Bench-201. We report the mean and standard deviation over 10 trials for the search of the architecture with the highest validation accuracy. For comparable numbers of queries, AG-Net performs similarly or better than the previous state of the art.</figDesc><table><row><cell>NAS Method</cell><cell></cell><cell cols="2">CIFAR-10</cell><cell></cell><cell></cell><cell cols="2">CIFAR-100</cell><cell></cell><cell cols="3">ImageNet16-120</cell><cell></cell><cell>Queries</cell></row><row><cell></cell><cell cols="4">Val. Acc StD Test Acc StD</cell><cell cols="4">Val. Acc StD Test Acc StD</cell><cell cols="4">Val. Acc StD Test Acc StD</cell><cell></cell></row><row><cell>Optimum*</cell><cell>91.61</cell><cell></cell><cell>94.37</cell><cell></cell><cell>73.49</cell><cell></cell><cell>73.51</cell><cell></cell><cell>46.73</cell><cell></cell><cell>47.31</cell><cell></cell><cell></cell></row><row><cell>SGNAS [23]</cell><cell>90.18</cell><cell>0.31</cell><cell>93.53</cell><cell>0.12</cell><cell>70.28</cell><cell>1.2</cell><cell>70.31</cell><cell>1.09</cell><cell>44.65</cell><cell>2.32</cell><cell>44.98</cell><cell>2.10</cell><cell></cell></row><row><cell>Arch2vec + BO [65]</cell><cell>91.41</cell><cell>0.22</cell><cell>94.18</cell><cell>0.24</cell><cell>73.35</cell><cell>0.32</cell><cell>73.37</cell><cell>0.30</cell><cell>46.34</cell><cell>0.18</cell><cell>46.27</cell><cell>0.37</cell><cell>100</cell></row><row><cell>AG-Net (ours)</cell><cell>91.55</cell><cell>0.08</cell><cell>94.24</cell><cell>0.19</cell><cell>73.2</cell><cell>0.34</cell><cell>73.12</cell><cell>0.40</cell><cell>46.31</cell><cell>0.33</cell><cell>46.2</cell><cell>0.47</cell><cell>96</cell></row><row><cell>AG-Net (ours with topk=1)</cell><cell>91.41</cell><cell>0.30</cell><cell>94.16</cell><cell>0.31</cell><cell>73.14</cell><cell>0.56</cell><cell>73.15</cell><cell>0.54</cell><cell>46.42</cell><cell>0.14</cell><cell>46.43</cell><cell>0.30</cell><cell>100</cell></row><row><cell>BANANAS  ? [56]</cell><cell>91.56</cell><cell>0.14</cell><cell>94.3</cell><cell>0.22</cell><cell>73.49*</cell><cell>0.00</cell><cell>73.50</cell><cell>0.00</cell><cell>46.65</cell><cell>0.13</cell><cell>46.51</cell><cell>0.11</cell><cell>192</cell></row><row><cell>BO  ? [50]</cell><cell>91.54</cell><cell>0.06</cell><cell>94.22</cell><cell>0.18</cell><cell>73.26</cell><cell>0.19</cell><cell>73.22</cell><cell>0.27</cell><cell>46.43</cell><cell>0.35</cell><cell>46.40</cell><cell>0.35</cell><cell>192</cell></row><row><cell>RS  ? [31]</cell><cell>91.12</cell><cell>0.26</cell><cell>93.89</cell><cell>0.27</cell><cell>72.08</cell><cell>0.53</cell><cell>72.07</cell><cell>0.61</cell><cell>45.87</cell><cell>0.39</cell><cell>45.98</cell><cell>0.41</cell><cell>192</cell></row><row><cell>XGB (ours)</cell><cell>91.54</cell><cell>0.09</cell><cell>94.34</cell><cell>0.10</cell><cell>73.10</cell><cell>0.51</cell><cell>72.93</cell><cell>0.74</cell><cell>46.48</cell><cell>0.13</cell><cell>46.08</cell><cell>0.79</cell><cell>192</cell></row><row><cell>XGB + Ranking (ours)</cell><cell>91.48</cell><cell>0.12</cell><cell>94.25</cell><cell>0.15</cell><cell>73.20</cell><cell>0.36</cell><cell>73.24</cell><cell>0.34</cell><cell>46.40</cell><cell>0.28</cell><cell>46.16</cell><cell>0.64</cell><cell>192</cell></row><row><cell>AG-Net (ours)</cell><cell>91.60</cell><cell>0.02</cell><cell>94.37*</cell><cell>0.00</cell><cell>73.49*</cell><cell>0.00</cell><cell>73.51*</cell><cell>0.00</cell><cell>46.64</cell><cell>0.12</cell><cell>46.43</cell><cell>0.34</cell><cell>192</cell></row><row><cell>GANAS [44]</cell><cell>-</cell><cell>-</cell><cell>94.34</cell><cell>0.05</cell><cell>-</cell><cell>-</cell><cell>73.28</cell><cell>0.17</cell><cell>-</cell><cell>-</cell><cell>46.80</cell><cell>0.29</cell><cell>444</cell></row><row><cell>AG-Net (ours)</cell><cell>91.61*</cell><cell>0.00</cell><cell>94.37*</cell><cell>0.00</cell><cell>73.49*</cell><cell>0.00</cell><cell>73.51*</cell><cell>0.00</cell><cell>46.73*</cell><cell>0.00</cell><cell>46.42</cell><cell>0.00</cell><cell>400</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 :</head><label>10</label><figDesc>Results on NAS-Bench-301 (mean and standard deviation over 50 trials) for the search of the best architecture in terms of validation accuracy compared to state-of-the-art methods.</figDesc><table><row><cell>NAS Method</cell><cell cols="2">Val. Acc (%) StD (%)</cell><cell>Queries</cell></row><row><cell>BANANAS  ? [56]</cell><cell>94.77</cell><cell>0.10</cell><cell>192</cell></row><row><cell>Bayesian Optimization  ? [50]</cell><cell>94.71</cell><cell>0.10</cell><cell>192</cell></row><row><cell>Local Search  ? [57]</cell><cell>95.02</cell><cell>0.10</cell><cell>192</cell></row><row><cell>Random Search  ? [31]</cell><cell>94.31</cell><cell>0.12</cell><cell>192</cell></row><row><cell>Regularized Evolution  ? [42]</cell><cell>94.75</cell><cell>0.11</cell><cell>192</cell></row><row><cell>XGB (ours)</cell><cell>94.79</cell><cell>0.13</cell><cell>192</cell></row><row><cell>XGR + Ranking (ours)</cell><cell>94.76</cell><cell>0.14</cell><cell>192</cell></row><row><cell>AG-Net (ours)</cell><cell>94.79</cell><cell>0.12</cell><cell>192</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 11 :</head><label>11</label><figDesc>Results on NAS-Bench-NLP (mean and standard deviation over 100 trials) for the search of the best architecture in terms of validation perplexity compared to state-of-the-art methods. Joint=1 is able to find better performing architectures compared to Joint=0 if the latency constraint L restricts the feasible search space strongly.</figDesc><table><row><cell>NAS Method</cell><cell cols="2">Val. Perplexity (%) StD (%)</cell><cell>Queries</cell></row><row><cell>BANANAS  ? [56]</cell><cell>95.68</cell><cell>0.16</cell><cell>304</cell></row><row><cell>Local Search  ? [57]</cell><cell>95.69</cell><cell>0.18</cell><cell>304</cell></row><row><cell>Random Search  ? [31]</cell><cell>95.64</cell><cell>0.19</cell><cell>304</cell></row><row><cell>Regularized Evolution  ? [42]</cell><cell>95.66</cell><cell>0.21</cell><cell>304</cell></row><row><cell>XGB (ours)</cell><cell>95.95</cell><cell>0.20</cell><cell>304</cell></row><row><cell>XGR + Ranking (ours)</cell><cell>95.92</cell><cell>0.19</cell><cell>304</cell></row><row><cell>AG-Net (ours)</cell><cell>95.86</cell><cell>0.18</cell><cell>304</cell></row><row><cell>therefore for all other devices too;</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 12 :</head><label>12</label><figDesc>Generator Abilities and training costs. The proposed generator generates architectures with high validity and uniqueness scores. The novelty scores are in a similar range as for previous methods [35].</figDesc><table><row><cell>Search Space</cell><cell cols="4">Validity (in %) Uniqueness in (%) Novelty in (%) Training (in GPU days)</cell></row><row><cell>NAS-Bench-101</cell><cell>71.69</cell><cell>97.92</cell><cell>62.30</cell><cell>0.4</cell></row><row><cell>NAS-Bench-201</cell><cell>99.97</cell><cell>73.61</cell><cell>10.03</cell><cell>0.3</cell></row><row><cell>NAS-Bench-301</cell><cell>42.27</cell><cell>100</cell><cell>100</cell><cell>0.9</cell></row><row><cell>NAS-Bench-NLP</cell><cell>57.95</cell><cell>100</cell><cell>100</cell><cell>0.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 13 :</head><label>13</label><figDesc>Hyperparameters of the generator model.</figDesc><table><row><cell>Hyperparameter</cell><cell>Default Value</cell></row><row><cell>Node Embedding</cell><cell>32</cell></row><row><cell>Latent Vector</cell><cell>32</cell></row><row><cell>MLP Node Embedding layer</cell><cell>2</cell></row><row><cell>GNN layer</cell><cell>2</cell></row><row><cell>Batch Size</cell><cell>32</cell></row><row><cell>Optimizer</cell><cell>Adam [25]</cell></row><row><cell>Learning Rate</cell><cell>0.0002</cell></row><row><cell>Betas</cell><cell>(0.5, 0.999)</cell></row><row><cell>Ticks</cell><cell>500</cell></row><row><cell>Tick Size</cell><cell>5,000</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 14 :</head><label>14</label><figDesc>Hyperparameters for the performance surrogate model f (?)</figDesc><table><row><cell>Hyperparameter</cell><cell></cell><cell cols="2">Dataset</cell><cell></cell></row><row><cell></cell><cell cols="4">NB101 NB201 NB301 NBNLP</cell></row><row><cell>?</cell><cell></cell><cell>0.9</cell><cell></cell><cell></cell></row><row><cell>MLP Layers</cell><cell></cell><cell>4</cell><cell></cell><cell></cell></row><row><cell>MLP Hidden</cell><cell>56</cell><cell>84</cell><cell>176</cell><cell>559</cell></row><row><cell>Epochs</cell><cell>15</cell><cell>30</cell><cell>15</cell><cell>30</cell></row><row><cell>Optimizer</cell><cell></cell><cell cols="2">Adam [25]</cell><cell></cell></row><row><cell>LR</cell><cell></cell><cell cols="2">0.001</cell><cell></cell></row><row><cell>Betas</cell><cell></cell><cell cols="2">(0.5, 0.999)</cell><cell></cell></row><row><cell>weight factor</cell><cell></cell><cell cols="2">10 e-3</cell><cell></cell></row><row><cell>batch size</cell><cell></cell><cell>16</cell><cell></cell><cell></cell></row><row><cell>loss</cell><cell></cell><cell>L2</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 15 :</head><label>15</label><figDesc>Hyperparameters for both surrogate models f (?) and g(?) for the multiobjective search in the Hardware-Aware Benchmark</figDesc><table><row><cell>Hyperparameter</cell><cell>Hardware-Aware NASBench</cell></row><row><cell>?</cell><cell>0.95</cell></row><row><cell>?</cell><cell>0.5</cell></row><row><cell>MLP Layers</cell><cell>4</cell></row><row><cell>MLP Hidden</cell><cell>82</cell></row><row><cell>Epochs</cell><cell>30</cell></row><row><cell>Optimizer</cell><cell>Adam [25]</cell></row><row><cell>LR</cell><cell>0.002</cell></row><row><cell>Betas</cell><cell>(0.5, 0.999)</cell></row><row><cell>weight factor</cell><cell>10 e-3</cell></row><row><cell>penalty term</cell><cell>1000</cell></row><row><cell>batch size</cell><cell>16</cell></row><row><cell>loss</cell><cell>L2</cell></row><row><cell>Latent space</cell><cell>Latent space</cell></row><row><cell>before LSO</cell><cell>after LSO</cell></row><row><cell></cell><cell>LSO</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments. JL and MK acknowledge the German Federal Ministry of Education and Research Foundation via the project DeToL.</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3: Graph Generation</head><p>for vj ? V \ vt+1 do 8 s addEdges (j, t + 1) ? f addEdges (ht+1, ht, hG, z) 9 e (j,t+1) ? Eval(s addEdges (j, t + 1)) ; ? evaluate whether to add edge </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Surrogate Model</head><p>The overall surrogate is an MLP with ReLU activations. <ref type="table">Table 14</ref> and <ref type="table">Table 15</ref> list all hyperparameters for the search experiments in the main paper for the simple performance surrogate model and the multi-objective surrogate model for the additional hardware objective. The hyperparameters for XGB <ref type="bibr" target="#b7">[10]</ref> are the same as in <ref type="bibr">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Latent Space Optimization Visualization</head><p>A more descriptive visualization of the latent space optimization technique used for our AG-Net neural architecture search is displayed in <ref type="figure">Figure 14</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Google llc</title>
		<ptr target="https://g.co/kgs/pVRc1Y" />
		<imprint>
			<biblScope unit="page" from="2021" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<idno>accessed: 2021-11-17 4</idno>
		<ptr target="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/" />
		<title level="m">Nvidia jetson tx2</title>
		<imprint>
			<biblScope unit="page" from="2021" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Xilinx inc. vivado high-level synthesis</title>
		<ptr target="https://https://www.xilinx.com/products/design-tools/vivado/integration/esl-design.html" />
		<imprint>
			<biblScope unit="page" from="2021" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Xilinx zynq-7000 soc zc706 evaluation kit</title>
		<ptr target="https://www.xilinx.com/products/boards-and-kits/ek-z7-zc706-g.html" />
		<imprint>
			<biblScope unit="page" from="2021" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Understanding and simplifying one-shot architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Neural architecture search on imagenet in four GPU hours: A theoretically inspired perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">14.5 eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Emer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Solid-State Circuits Conference, ISSCC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A downsampled variant of imagenet as an alternative to the CIFAR datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chrabaszcz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno>abs/1707.08819</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">One-shot neural architecture search via self-evaluated template network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Nas-bench-201: Extending the scope of reproducible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural architecture search: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2661</idno>
		<title level="m">Generative adversarial networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Generative adversarial neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S C</forename><surname>Rezaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salameh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>IJCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Optimizing rank-based metrics with blackbox differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rol?nek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Musil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Martius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Interpretable neural architecture search via bayesian optimisation with weisfeiler-lehman kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Osborne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Multi-objective neural architecture search via predictive network performance optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<idno>abs/1911.09336</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Nas-bench-301 and the case for surrogate benchmarks for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Siems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno>abs/2008.09777</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Rippel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Satish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sundaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M A</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Prabhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<title level="m">Scalable bayesian optimization using deep neural networks. In: ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Rethinking the Inception Architecture for Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Sample-efficient optimization in the latent space of deep generative models via weighted retraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tripp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Daxberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hern?ndez-Lobato</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Neural predictor for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kindermans</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">A study on encodings for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nolen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Savani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Bananas: Bayesian optimization with neural architectures for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Savani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Exploring the loss landscape in neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nolen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Savani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">How powerful are performance predictors in neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<title level="m">Stronger nas with weaker predictors</title>
		<imprint>
			<publisher>NeurIPS</publisher>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">SNAS: stochastic neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<title level="m">How powerful are graph neural networks? In: ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">PC-DARTS: partial channel connections for memory-efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Nas-bench-x11 and the power of learning curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Savani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Does unsupervised architecture representation learning help neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Nas-bench-101: Towards reproducible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
