<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CLUSTERING-FRIENDLY REPRESENTATION LEARN- ING VIA INSTANCE DISCRIMINATION AND FEATURE DECORRELATION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaling</forename><surname>Tao</surname></persName>
							<email>yaling1.tao@toshiba.co.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Corporate R&amp;D Center</orgName>
								<address>
									<addrLine>Toshiba 1, Komukai Toshiba-cho, Saiwai-ku</addrLine>
									<settlement>Kawasaki</settlement>
									<region>Kanagawa</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Takagi</surname></persName>
							<email>kentaro1.takagi@toshiba.co.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Corporate R&amp;D Center</orgName>
								<address>
									<addrLine>Toshiba 1, Komukai Toshiba-cho, Saiwai-ku</addrLine>
									<settlement>Kawasaki</settlement>
									<region>Kanagawa</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kouta</forename><surname>Nakata</surname></persName>
							<email>kouta.nakata@toshiba.co.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Corporate R&amp;D Center</orgName>
								<address>
									<addrLine>Toshiba 1, Komukai Toshiba-cho, Saiwai-ku</addrLine>
									<settlement>Kawasaki</settlement>
									<region>Kanagawa</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CLUSTERING-FRIENDLY REPRESENTATION LEARN- ING VIA INSTANCE DISCRIMINATION AND FEATURE DECORRELATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T02:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Clustering is one of the most fundamental tasks in machine learning. Recently, deep clustering has become a major trend in clustering techniques. Representation learning often plays an important role in the effectiveness of deep clustering, and thus can be a principal cause of performance degradation. In this paper, we propose a clustering-friendly representation learning method using instance discrimination and feature decorrelation. Our deep-learning-based representation learning method is motivated by the properties of classical spectral clustering. Instance discrimination learns similarities among data and feature decorrelation removes redundant correlation among features. We utilize an instance discrimination method in which learning individual instance classes leads to learning similarity among instances. Through detailed experiments and examination, we show that the approach can be adapted to learning a latent space for clustering. We design novel softmax-formulated decorrelation constraints for learning. In evaluations of image clustering using CIFAR-10 and ImageNet-10, our method achieves accuracy of 81.5% and 95.4%, respectively. We also show that the softmax-formulated constraints are compatible with various neural networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Clustering is one of the most fundamental tasks in machine learning. Recently, deep clustering has become a major trend in clustering techniques. In a fundamental form, autoencoders are used for feature extraction, and classical clustering techniques such as k-means are serially applied to the features. Recent deep clustering techniques integrate learning processes of feature extraction and clustering, yielding high performance for large-scale datasets such as handwritten digits <ref type="bibr" target="#b14">Hu et al. (2017)</ref>; ; <ref type="bibr" target="#b35">Xie et al. (2016)</ref>; <ref type="bibr" target="#b27">Tao et al. (2018)</ref>. However, those methods have fallen short when targets become more complex, as in the case of real-world photograph dataset CIFAR-10 <ref type="bibr" target="#b17">Krizhevsky et al. (2009)</ref>. Several works report powerful representation learning leads to improvement of clustering performance on complex datasets <ref type="bibr" target="#b2">Chang et al. (2017)</ref>; <ref type="bibr" target="#b32">Wu et al. (2019)</ref>. Learning representation is a key challenge to unsupervised clustering.</p><p>In order to learn representations for clustering, recent works utilize metric learning which automatically learns similarity functions from data <ref type="bibr" target="#b2">Chang et al. (2017)</ref>; <ref type="bibr" target="#b32">Wu et al. (2019)</ref>. They assign pseudo-labels or pseudo-graph to unlabeled data by similarity measures in latent space, and learn discriminative representations to cluster data. These works improve clustering performance on real world images such as CIFAR-10 and ImageNet-10, and indicate the impact of representation learning on clustering. Although features from learned similarity function and pseudo-labels work well for clustering, algorithms still seem to be heuristic; we design a novel algorithm which is based on knowledge from established clustering techniques. In this work, we exploit a core idea of spectral clustering which uses eigenvectors derived from similarities.</p><p>Spectral clustering has been theoretically and experimentally investigated, and known to outperform other traditional clustering <ref type="bibr">methods Von Luxburg (2007)</ref>. The algorithm involves similarity matrix construction, transformation from similarity matrix to Laplacian, and eigendecomposition. Based on Published as a conference paper at ICLR 2021 eigenvectors, data points are mapped into a lower dimensional representation which carries information of similarities and is preferable for clustering. We bring this idea of eigenvector representation into deep representation learning.</p><p>We design the representation learning with two aims: 1) learning similarities among instances; and 2) reducing correlations within features. The first corresponds to Laplacian, and the second corresponds to feature orthogonality constrains in the spectral clustering algorithm. Learning process integrating both is relevant to eigendecomposition of Laplacian matrix in the spectral clustering.</p><p>For the first aim, we adopt the instance discrimination method presented in <ref type="bibr" target="#b33">Wu et al. (2018)</ref>, where each unlabeled instance is treated as its own distinct class, and discriminative representations are learned to distinguish between individual instance classes. This numerous-class discriminative learning enables learning partial but important features, such as small foreground objects in natural images. <ref type="bibr" target="#b33">Wu et al. (2018)</ref> showed that the representation features retain apparent similarity among images and improve the performance of image classification by the nearest neighbor method. We extend their work to the clustering tasks. We clarify their softmax formulation works like similarity matrix in spectral clustering under the condition that temperature parameter ? , which was underexplored in <ref type="bibr" target="#b33">Wu et al. (2018)</ref>, is set to be a larger value .</p><p>For the second aim, we introduce constraints which have the effect of making latent features orthogonal. Orthogonality is often an essential idea in dimension reduction methods such as principal components analysis, and it is preferable for latent features to be independent to ensure that redundant information is reduced. Orthogonality is also essential to a connection between proposed method and spectral clustering, as stated in Section 3.4. In addition to a simple soft orthogonal constraint, we design a novel softmax-formulated decorrelation constraint. Our softmax constraint is "softer" than the soft orthogonal constraint for learning independent feature spaces, but realizes stable improvement of clustering performance.</p><p>Finally, we combine instance discrimination and feature decorrelation into learning representation to improve the performance of complex image clustering. For the CIFAR-10 and ImageNet-10 datasets, our method achieves accuracy of 81.5% and 95.4%, respectively. Our PyTorch <ref type="bibr" target="#b21">Paszke et al. (2019)</ref> implementation of IDFD is available at https://github.com/TTN-YKK/Clustering_ friendly_representation_learning.</p><p>Our main contributions are as follows:</p><p>? We propose a clustering-friendly representation learning method combining instance discrimination and feature decorrelation based on spectral clustering properties.</p><p>? We adapt deep representation learning by instance discrimination to clustering and clarify the essential properties of the temperature parameter.</p><p>? We design a softmax-formulated orthogonal constraint for learning latent features and realize stable improvement of clustering performance.</p><p>? Our representation learning method achieves performance comparable to state-of-the-art levels for image clustering tasks with simple k-means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Deep clustering methods offer state-of-the-art performance in various fields. Most early deep clustering methods, such as <ref type="bibr" target="#b30">Vincent et al. (2010)</ref>; <ref type="bibr" target="#b28">Tian et al. (2014)</ref>, are two-stage methods that apply clustering after learning low-dimensional representations of data in a nonlinear latent space. The autoencoder method proposed in <ref type="bibr" target="#b12">Hinton &amp; Salakhutdinov (2006)</ref> is one of the most effective methods for learning representations. Recent works have simultaneously performed representation learning and clustering <ref type="bibr" target="#b26">Song et al. (2013)</ref>; <ref type="bibr" target="#b35">Xie et al. (2016)</ref>; <ref type="bibr" target="#b36">Yang et al. (2017)</ref>; <ref type="bibr" target="#b8">Guo et al. (2017)</ref>; <ref type="bibr" target="#b27">Tao et al. (2018)</ref>. Several methods based on generative models have also been proposed <ref type="bibr" target="#b16">Jiang et al. (2016)</ref>; <ref type="bibr" target="#b6">Dilokthanakul et al. (2016)</ref>. These methods outperform conventional methods, and sometimes offer performance comparable to that of supervised learning for simple datasets. Deep-learning-based unsupervised image clustering is also being developed Chang et al. Several approaches focus on learning discriminative representations via deep learning. <ref type="bibr" target="#b0">Bojanowski &amp; Joulin (2017)</ref> found a mapping between images on a uniformly discretized target space, and enforced their representations to resemble a distribution of pairwise relationships. <ref type="bibr" target="#b1">Caron et al. (2018)</ref> applied pseudo-labels to output as supervision by k-means and then trained a deep neural network. <ref type="bibr" target="#b7">Donahue et al. (2016)</ref> proposed bidirectional generative adversarial networks for learning generative models that map simple latent distributions to complex real distributions, in order for generators to capture semantic representations. <ref type="bibr" target="#b13">Hjelm et al. (2018)</ref> proposed deep infomax to maximize mutual information between the input and output of an encoder. <ref type="bibr" target="#b33">Wu et al. (2018)</ref> was motivated by observations in supervised learning that the probabilities of similar image classes become simultaneously high. They showed that discriminating individual instance classes leads to learning representations that retain similarities among data. Our method exploits the idea of spectral clustering <ref type="bibr" target="#b24">Shi &amp; Malik (2000)</ref>; <ref type="bibr" target="#b19">Meila &amp; Shi (2001);</ref><ref type="bibr" target="#b31">Von Luxburg (2007);</ref><ref type="bibr" target="#b20">Ng et al. (2002)</ref>. From one perspective, spectral clustering finds a low dimensional embedding of data in the eigenspace of the Laplacian matrix, which is derived from pairwise similarities between data. By using the embedded representations, we can proceed to cluster the data by the k-means algorithm in the low-dimensional space. Spectral clustering often outperforms earlier algorithms such as k-means once pair similarities are properly calculated.  incorporated the concept of spectral clustering into deep a neural network structure. Similarities were calculated by learning a Siamese net <ref type="bibr" target="#b22">Shaham &amp; Lederman (2018)</ref> where the input positive and negative pairs were constructed according to the Euclidean distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROPOSED METHOD</head><p>Given an unlabeled dataset X = {x i } n i=1 and a predefined number of clusters k, where x i denotes the ith sample, we perform the clustering task in two phases, namely, representation learning and clustering. This work focuses on the first phase, which aims to learn an embedding function v = f ? (x) mapping data x to representation v so that v is preferable for clustering. f ? is modeled as a deep neural network with parameter ?. We use V = {v i } n i=1 to denote the whole representation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">INSTANCE DISCRIMINATION</head><p>We apply the instance discrimination method proposed by <ref type="bibr" target="#b33">Wu et al. (2018)</ref> to learn clustering-friendly representations that capture similarity between instances. The objective function is formulated based on the softmax criterion. Each instance is assumed to represent a distinct class. For given data x 1 , . . . , x n , the corresponding representations are v 1 , . . . , v n , and data x i is classified into the ith class. Accordingly, the weight vector for the ith class can be approximated by a vector v i . The probability of representation v being assigned into the ith class is</p><formula xml:id="formula_0">P (i|v) = exp(v T i v/? ) n j=1 exp(v T j v/? ) ,<label>(1)</label></formula><p>where v T j v measures how well v matches the jth class, ? is a temperature parameter that controls the concentration of the distribution <ref type="bibr" target="#b11">Hinton et al. (2015)</ref>, and v is normalized to ||v|| = 1.</p><p>The objective maximizes the joint probability</p><formula xml:id="formula_1">n i=1 P ? (i|f ? (x i )) as L I = ? n i=1 log P (i|f ? (x i )) = ? n i log( exp(v T i v i /? ) n j=1 exp(v T j v i /? )</formula><p>).</p><p>(2) <ref type="bibr" target="#b33">Wu et al. (2018)</ref> shows that features obtained by minimizing the objective retain similarity between image instances and improve the performance of nearest neighbor classification. For clustering, we note that the parameter ? , which is underexplored in <ref type="bibr" target="#b33">Wu et al. (2018)</ref>, has a large impact on clustering performance. The effect of ? is discussed later and experimental results are shown in 4.2.1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">FEATURE DECORRELATION</head><p>We define a set of latent feature vectors f and use f l to denote the lth feature vector. Transposition of latent vectors V coincides with {f l } d l=1 , where d is the dimensionality of representations. The simple constraint for orthogonal features is,</p><formula xml:id="formula_2">L F O = ||V V T ? I|| 2 = d l=1 (f T l f l ? 1) 2 + n j=1,j =l (f T j f l ) 2 .<label>(3)</label></formula><p>Our novel constraint is based on a softmax formulation of</p><formula xml:id="formula_3">Q(l|f ) = exp(f T l f /? 2 ) d m=1 exp(f T m f /? 2 ) ,<label>(4)</label></formula><p>Q(l|f ) is analogous to P (i|v). Q(l|f ) measures how correlated a feature vector is to itself and how dissimilar it is to others. ? 2 is the temperature parameter. We formulate the feature decorrelation constraint as</p><formula xml:id="formula_4">L F = ? d l=1 log Q(l|f ) = d l=1 ? f T l f l /? 2 + log d j exp(f T j f l /? 2 ) .<label>(5)</label></formula><p>Both constrains in Eq.</p><p>(3) and Eq. (5) aim to construct independent features. Conventionally, it is preferable for features to be independent to ensure that redundant information is reduced, and orthogonality is a common technique. Compare Eq.</p><p>(3) and Eq. (5), we can see that minimizing L F and L F O can result in a similar effect, f T l f l ? 1 and f T j f l ? ?1 or 0(l = j), and both try to decorrelate latent features.</p><p>Our softmax constraint in Eq. (5) shows practical advantages in flexibility and stability. Eq. (3) is called a soft orthogonal constraint, but is still strict enough to force the features to be orthogonal. If d is larger than underlying structures that are hidden and unknown, all features are forcibly orthogonalized and the resultant features may not be appropriate. Softmax formulation allows off-diagonal elements to be non-zero and alleviates the problem of strict orthogonality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Partial derivatives of L</head><formula xml:id="formula_5">F and L F O with respect to z jl = f T j f l are calculated as ?L F ?z jl = ? 1 ?2 ? jl + 1 ?2 exp(z jl /?2) d j exp(z jl /?2) and ?L F O ?z jl = ?2? jl + 2z jl ,</formula><p>where ? jl is an indicator function. Since the derivatives nearly equal zero due to z jl = 1 in the case of j = l, we focus on the case of j = l. When j = l, the ranges of partial derivatives are 0 ? ?L F ?z jl ? 1 ?2 and ?2 ? ?L F O ?z jl ? 2. The monotonicity of L F can lead to more stable convergence. The advantages of L F are confirmed by experiments in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">OBJECTIVE FUNCTION AND LEARNING MODEL</head><p>Combining instance discrimination and feature decorrelation learning, we formulate our objective function L IDF D as follows:</p><formula xml:id="formula_6">L IDF D = L I + ?L F ,<label>(6)</label></formula><p>Where ? is a weight that balances the contributions of two terms L I and L F . <ref type="figure" target="#fig_2">Figure 1</ref> shows the learning process for the motif of image clustering. We combine L I and L F O to formulate an alternative loss L IDF O in E.q. <ref type="formula" target="#formula_7">(7)</ref>,</p><formula xml:id="formula_7">L IDF O = L I + ?L F O .<label>(7)</label></formula><p>We refer to representation learning using L IDF D , L IDF O , and L I loss as instance discrimination and feature decorrelation (IDFD), instance discrimination and feature orthogonalization (IDFO), and instance discrimination (ID), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">CONNECTION WITH SPECTRAL CLUSTERING</head><p>We explain the connection between IDFD and spectral clustering. We consider a fully connected graph consisting of all representation points, and the similarity matrix W and degree matrix D can be written as</p><formula xml:id="formula_8">W ij = exp(v T i v j /? ) and D ii = n m exp(v T i v m /? ).</formula><p>The loss function of spectral clustering  can be reformulated as</p><formula xml:id="formula_9">L SP = (T r)(f Lf ) = 1 2 k n ij w ij (f k i ? f k j ) 2 = 1 2 k n ij exp v T i v j ? ||v i ? v j || 2 ,<label>(8)</label></formula><p>where L is Laplacian matrix, f are feature vectors. Spectral clustering is performed by minimizing L SP subject to orthogonal condition of f , and when L SP takes minimum value f become eigenvectors of Laplacian L. According to Section 3.2, minimizing L F can approximate the orthogonal condition. Under this condition, minimizing L I can approximate the minimizing L SP , which is explained as follows.</p><p>According to Eq.(2), minimizing loss L I means maximizing v T i v i and minimizing v T i v j . When i = j, we have ||v i ? v j || 2 = 0, L SP becomes zero. We need consider only the influence on L SP from minimizing v T i v j . As v are normalized, L SP can be rewritten using cosine metric as</p><formula xml:id="formula_10">L SP = n ij exp cos ? ? sin 2 ? 2 ,<label>(9)</label></formula><p>then ?L SP ?? can be calculated as</p><formula xml:id="formula_11">?L SP ?? = 1 ? sin ?(? ? 1 + cos ?) exp cos ? ? .<label>(10)</label></formula><p>According to Eq.(10), we get ?L SP ?? ? 0 when ? ? 2. This means L SP monotonically decreases when we minimize v T i v j . Therefore, the impact from minimizing v T i v j is good for minimizing L SP . Even if ? is a little smaller than 2, because ? controls the scale of derivatives and the range of ? where the derivative is negative, large ? decreases the scale and narrows the range, resulting in a small influence on the total loss. From this viewpoint, the effectiveness of minimizing L I using large ? is approximately the same as that of L SP . By adding feature decorrelation constraints, IDFD becomes analogous to spectral clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We conducted experiments using five datasets: CIFAR-10  <ref type="bibr">(2009)</ref>. We adopted ResNet18 <ref type="bibr" target="#b10">He et al. (2016)</ref> as the neural network architecture in our main experiments. The same architecture is used for all datasets. Our experimental settings are in accordance with that of <ref type="bibr" target="#b33">Wu et al. (2018)</ref>. Data augmentation strategies often used on images are also adopted in experiments. Details about datasets and experimental setup are given in Appendix A.</p><p>For IDFD, the weight ? is simply fixed at 1. Orthogonality constraint weights for IDFO were ? = 10 on CIFAR-10 and CIFAR-100, and ? = 0.5 on STL-10 and ImageNet subsets. The weight ? was set according to the orders of magnitudes of losses. In the main experiments, we set temperature parameter ? = 1 for IDFO and IDFD, and ? 2 = 2 for IDFD. In order to fully investigate our work, we also constructed two versions of instance discrimination (ID) that uses only L I loss, ID(original) with small ? = 0.07 and ID(tuned) with large ? = 1.</p><p>We compared ID(tuned), IDFO, and IDFD with ID(original) and six other competitive methods, clustering with an autoencoder (AE) <ref type="bibr" target="#b12">Hinton &amp; Salakhutdinov (2006)</ref>  <ref type="bibr">(2020)</ref> .We use three metrics to measure clustering performance: standard clustering accuracy (ACC), normalized mutual information (NMI), and adjusted rand index (ARI). These metrics give values in [0, 1], with higher scores indicating more accurate clustering assignments. <ref type="table" target="#tab_1">Table 1</ref> lists the best performances for each method. The results for the four methods AE, DEC, DAC, and DCCM are cited from <ref type="bibr" target="#b32">Wu et al. (2019)</ref>, and results for two methods IIC and SCAN are cited from <ref type="bibr" target="#b29">Van Gansbeke et al. (2020)</ref>. Comparing these results, we conclude that ID(tuned), IDFO, and IDFD, clearly outperform these methods excluding SCAN for all datasets, according to the metrics ACC, NMI, and ARI. For dataset CIFAR-10, ID(tuned), IDFO, and IDFD yielded ACC values of 77.6%, 82.8%, and 81.5%, respectively. For dataset ImageNet-10, ID(tuned), IDFO, and IDFD achieved ACC values of 93.7%, 94.2%, and 95.4%. The high performance is comparable with that of supervised and semi-supervised methods. Gaps between the results of ID(tuned) and those of IDFO and IDFD reflect the effect of the feature constraint term. The performance is improved for all datasets by introducing feature orthogonalization and decorrelation. Impressively, ID(tuned) significantly outperformed ID(original) on all datasets, showing strong impact of temperature parameter. This will be discussed separately in section 4.2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">MAIN RESULTS</head><p>In addition, we note that IDFD differs from SCAN in that IDFD focuses on the representation leaning while SCAN focuses on clustering by given a representation learning. Both SCAN and IDFD demonstrate significant improvement on performance compared with other methods. Results of IDFD and SCAN showed effectiveness of efforts on both representation learning and clustering phases of deep clustering.</p><p>We also examine the learning stability of ID(tuned), IDFO, and IDFD. <ref type="figure">Figure 2</ref> illustrates the accuracy on CIFAR-10 running each of ID(tuned), IDFO, and IDFD. We can see that both IDFO and IDFD obtained higher peak ACC values than ID(tuned). In particular, IDFD yielded higher performance than ID over the entire learning process. IDFO performed better than the other two methods and obtained the highest ACC value in earlier epochs. However, the ACC widely fluctuated over the learning process and dropped in later epochs. As analyzed in 3.2, our proposed IDFD makes performance higher than ID and more stable than IDFO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">ANALYSIS ON TEMPERATURE PARAMETER</head><p>Gaps between results of ID(original) and ID(tuned) in <ref type="table" target="#tab_1">Table 1</ref> show strong impact of temperature parameter. We theoretically and intuitively analyze the essential change caused by the temperature parameter in this subsection.</p><p>First, we consider why instance-level discrimination works and under what conditions. Difference in the performance of ID(original) and ID(tuned) suggests optimal distribution in latent space changes with the magnitude of ? . According to empirical investigation and theoretical analysis, we find that a large ? in L I encourages data points to follow a compact distribution when minimizing the loss, while a small ? drives them to follow a uniform distribution. This means minimizing L I with a large ? can reach a good clustering-friendly solution. This property was explained by demonstrating examples and calculation, details are given in Appendix B.</p><p>In the definition of P (i|v) in Eq. (1), when ? is small, we compute softmax on larger logits, resulting in higher prediction, and obtain a more confident model. From this viewpoint, we can leverage a small ? to decrease class entanglement if we can learn an accurate class-weight vector. In the general classification problem, since the weight of each class can be learned according to the real labels, it is preferable for models to be more confident. Most works therefore recommend setting a small value, such as ? = 0.07 <ref type="bibr" target="#b33">Wu et al. (2018)</ref>. In clustering, however, instance-level discrimination is used to learn similarity among samples, with only one sample in each class. Because the model is highly confident, each sample tends to be completely independent from each other. Similarity among samples is seemingly encouraged to approach close to zero, even for samples from the same class. This clearly deviates from the original intent of adopting instance-level discrimination to learn sample entanglements under the condition that each sample can be discriminative. A larger ? than that used for classification is thus needed.</p><p>More experiments over different temperature settings on ID and IDFD were conducted on CIFAR-10. <ref type="figure" target="#fig_6">Figure 3</ref> shows the accuracy of ID for ? = {0.07, 0.2, 0.5, 0.8, 1, 2, 5, 10}. We calculated the mean and standard deviation of ACC values over the last 500 epochs for each experiment. From the results, we can see that ID can suffer significant performance degradation when ? is too small or too large. This agrees with our analysis above. We also investigate the impact of ? 2 by fixing ? = 1. <ref type="figure" target="#fig_7">Figure 4</ref> shows the accuracy of the IDFD for ? 2 = {0.1, 0.5, 1, 2, 3, 4, 5, 10}. Experimental results show that IDFD is relatively robust to the parameter ? 2 and enables stable representation learning.   them. Data distribution when ? = 1 is apparently more clustering-friendly than when ? = 0.07. Furthermore, compared with ID(tuned), IDFO and IDFD can separate samples from different classes with certain margins. IDFO tended to construct a patch-like distribution within one class. In contrast, IDFD maintained a tighter connection among samples of the same class and more distinct borders between different classes.  <ref type="figure">Figure 6</ref> shows distribution of feature representations on ImageNet-10 learned by IDFD. We can see that representations of ImageNet-10 are clustering-friendly and even better than that of CIFAR-10. This is consistent with the results in <ref type="table" target="#tab_1">Table 1</ref> evaluated by metrics ACC, NMI, and ARI. In addition to that, we also plot sample images corresponding to points lying near the border between clusters. We can see that these samples are certainly similar in appearance. <ref type="figure">Figure 6</ref>: Distribution of feature representations on ImageNet-10 learned by IDFD and samples corresponding to points in some areas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">REPRESENTATION DISTRIBUTION AND FEATURE BEHAVIOR</head><p>We investigate the effects of orthogonal and decorrelation constraints L F O and L F . <ref type="figure" target="#fig_9">Figure 7</ref> illustrates the feature correlations of ID(tuned), IDFO, and IDFD on dataset CIFAR-10. We see that IDFO clearly decorrelates features and IDFD retains a moderate level of feature correlation between ID and IDFD. Taken together with <ref type="figure">Figure 2</ref>, these results suggest that the softmax formulation of IDFD alleviates the problem of strict orthogonality and enables stable representation learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">INVESTIGATION FOR PRACTICAL USE</head><p>We investigate the dependencies of our method on networks through experiments on other networks: ConvNet <ref type="bibr" target="#b32">Wu et al. (2019)</ref>, <ref type="bibr">VGG16 Simonyan &amp; Zisserman (2014)</ref>, and ResNet34 <ref type="bibr" target="#b10">He et al. (2016)</ref>. Performance was evaluated using the CIFAR-10 dataset. Results listed in <ref type="table" target="#tab_2">Table 2</ref> show that IDFD can work on various networks. IDFD outperforms ID(tuned), and FD term shows more obvious effect on these networks. We also confirm the effect of cooperation between L I and L F from the viewpoint of spectral clustering, combinations of AE and L F were evaluated in terms of clustering performance. We found that AE cannot benefit from L F as L I did. This result verified that L F has a deep relation with L I , and IDFD is not a simple combination. We also investigate the importance of data augmentation in performance through experiments. Due to the page limit, our extended experiments are given in Appendix C. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We present a clustering-friendly representation learning method combining instance discrimination and feature decorrelation based on spectral clustering properties. Instance discrimination learns similarities among data and feature decorrelation removes redundant correlation among features. We analyzed why instance discrimination works for clustering and clarified the conditions. We designed a softmax-formulated feature decorrelation constraint for learning the latent space to realize stable improvement of clustering performance. We also explained the connection between our method and spectral clustering. The proposed representation learning method achieves accuracies comparable to state-of-the-art values on the CIFAR-10 and ImageNet-10 datasets with simple k-means. We also verified IDFD loss works on multiple neural network structures, and our method is expected to be effective for various kinds of problems.  <ref type="table" target="#tab_3">Table 3</ref> lists the numbers of images, number of clusters, and image sizes of these datasets. Specifically, the training and testing sets of dataset STL-10 were jointly used in our experiments. Images from the three ImageNet subsets were resized to 96 ? 96 ? 3. We adopted ResNet <ref type="bibr" target="#b10">He et al. (2016)</ref> as the neural network architecture in our main experiments. For simplicity, we used ResNet18, which according to our preliminary experiments yields sufficiently high performance. The same architecture was used for all datasets except the input layer. In accordance with the experimental settings of <ref type="bibr" target="#b33">Wu et al. (2018)</ref>, the dimension of latent feature vectors was set to d = 128, and a stochastic gradient descent optimizer with momentum ? = 0.9 was used. The learning rate lr was initialized to 0.03, then gradually scaled down after the first 600 epochs using a coefficient of 0.1 every 350 epochs. The total number of epochs was set to 2000, and the batch size was set to B = 128. Orthogonality constraint weights for IDFO were ? = 10 for CIFAR-10 and CIFAR-100 and ? = 0.5 for the STL-10 and ImageNet subsets. The weight for IDFO ? was set according to the orders of magnitudes of the two losses L I and L F O . For IDFD, the weight ? was simply fixed at 1. In the main experiments, we set the default temperature parameter value ? = 1 for ID(tuned), IDFO, and IDFD, and ? 2 = 2 for IDFD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDICES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B OPTIMAL SOLUTIONS OF CLUSTERING AND INSTANCE DISCRIMINATION</head><p>In Section 4.2.1, we concluded that minimizing L I under the condition that ? is large can reach a clustering-friendly solution. Details about the analysis and calculation was demonstrated by a two-dimensional toy model as follows.</p><p>Empirically, we observe that visually similar images tend to get similar assignment probabilities. Similar images can thus be projected to close locations in the latent space. This also motivated ID <ref type="bibr" target="#b33">Wu et al. (2018)</ref>. In the case of ID, similar images x i and x j yield respective highest probabilities p ii and p jj , and also receive relatively high p ij and p ji values. This property can retain over the process of approximation to the optimal solution. Because instance-level discrimination tries to maximally scatter embedded features of instances over the unit sphere <ref type="bibr" target="#b33">Wu et al. (2018)</ref>, all representations are thus uniformly spread over the latent space with each representation relatively similar to its surroundings, we call this uniform case. We also consider another case that yields an optimal clustering solution where all samples from the same class are compacted to one point and k clusters are uniformly spread over the space. We call this compact case. <ref type="figure" target="#fig_11">Figure 8</ref> shows the representation distributions in the two cases. Because we normalize v, two-dimensional representations form a circle.</p><p>In the uniform case, n representations are uniformly located on a circle with an angular interval of ? = 2?/n, and the inner product between two neighboring representations is cos ?. Without loss of generality, we can start with an arbitrary point v i and orderly mark all samples as v i+j . The cosine similarity between v i and v i+j can then be calculated by v T i+j v i = cos j?. Accordingly, the loss  </p><p>Similarly, in the compact case, n/k data from the same class are exactly compacted to a point and k corresponding points located on a circle at an angular interval of ? = 2?/k. The inner product between an arbitrary start sample v i and the j-th sample can be calculated as v T i v i+j = cos l? , where l = j mod n/k. The probability of assigning i to the cluster with j becomes p ij = exp(cos ? /? ) k?1 c=0 n k exp(cos c? /? ) . Accordingly, the loss contributed by sample i in the compact case can be calculated as </p><p>Comparing Eq. <ref type="formula" target="#formula_0">(11)</ref> and <ref type="formula" target="#formula_0">(12)</ref>, we see that the difference between L i unif orm and L i compact comes only from the denominator part of the logarithm. These are two discrete forms of the same integral exp(cos ?/? )d?. Clearly, L i unif orm equals L i compact when k, n ? +?. We therefore need to consider only the general case where n is sufficiently large and k n. <ref type="figure" target="#fig_12">Figure 9</ref> shows a plot of function values exp( cos ? ? ) with different ? settings over the domain ? ? [0, 2?]. We can see that the curve becomes flatter as ? increases. A flat function f means that for an arbitrary (?, ? ) pair in its domain of definition, we have f (?) ? f (? ). In this situation even k n, the difference between the summations of these two discrete functions is not large. Accordingly, we can say L i compact is approximate to L i unif orm for a large ? . In other words, minimizing L I can approach the compact situation where same-class samples assemble and differing samples separate. Learning instance-level discrimination for clustering is therefore reasonable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C EXTENDED EXPERIMENTS</head><p>In Section 4.2.3, we have reported some investigations of our method for practical use. Details about several important experiments are supplemented as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 IMPACT OF NETWORK ARCHITECTURE</head><p>As <ref type="table" target="#tab_2">Table 2</ref> shows, IDFD can be applied to various networks, and the performance gaps between IDFD and ID(turned) on networks like ConvNet <ref type="bibr" target="#b32">Wu et al. (2019)</ref> and <ref type="bibr">VGG16 Simonyan &amp; Zisserman (2014)</ref> are more significant than on ResNet <ref type="bibr" target="#b10">He et al. (2016)</ref>. We added the feature correlation matrix of VGG16 in <ref type="figure" target="#fig_2">Figure 10</ref>. IDFD on VGG16 obtained sparse correlations similar to the case of ResNet18 in <ref type="figure" target="#fig_9">Figure 7</ref>, while ID on VGG16 obtained denser and stronger correlations than ResNet18, presumably constructing redundant features that degraded clustering. In the case of VGG16, the feature decorrelation term L F exhibits a larger effect on clustering performance than that of ResNet.</p><p>Our proposed losses work on all network architectures, and we expect to introduce the losses to various networks that are suitable for individual problems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 COMBINATION OF AUTOENCODER AND FEATURE DECORRELATION</head><p>In order to further confirm the cooperation effect of instance discrimination and feature decorrelation from the viewpoint of spectral clustering, a combination of autoencoder and feature decorrelation was evaluated in terms of clustering performance. Autoencoder has been verified by datasets such as handwritten digits to be an effective method for deep clustering. In this experiment, we used ConvNet <ref type="bibr" target="#b32">Wu et al. (2019)</ref> for the autoencoder architecture and trained it on the CIFAR-10 dataset. We applied k-means to representations learned from autoencoder only and autoencoder combined with feature decorrelation, which are called AE and AEFD, respectively. According to our experiments, the ACC value of AE was 26.0%, and the ACC value of AEFD was 22.4%. Compared to the improvement from ID to IDFD (from 26.8% to 42.0% as shown in <ref type="table" target="#tab_2">Table 2</ref>), we see that AE cannot benefit from FD as ID. This result again indicates that FD has a deep relation with ID as we analyzed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 IMPACT OF DATA AUGMENTATION</head><p>For reproduction of our results and practical use, we note that data augmentation (DA) has strong impact on the performance. DA is known to have impact on image classification and representation learning. Like in <ref type="bibr" target="#b33">Wu et al. (2018)</ref>, several generic and accepted techniques, such as cropping and grayscale, were used for data augmenting in this work. The details of the augmentation in the original code can be linked to <ref type="bibr" target="#b33">Wu et al. (2018)</ref>. In order to investigate the impact of DA, we conducted experiments on five datasets with and without DA and compared their clustering results. <ref type="table" target="#tab_4">Table 4</ref> shows the results. We can see that methods without DA suffered significant performance degradations for clustering, as well as for classification <ref type="bibr" target="#b3">Chen et al. (2020)</ref>. This reminds us not to ignore the effects of DA in practical use. To further find out main factors affecting the performance, we also executed experiments by removing each technique used for DA. Take the example of CIFAR-10, techniques used for data augmentation include: ColorJitter, RandomResizedCrop, RandomGrayscale, and RandomHorizontalFlip. All these techniques are generic and easy to be implemented. They have been integrated into general deep learning frameworks such as PyTorch. According to our experimental results as shown in <ref type="figure" target="#fig_2">Figure 11</ref>, we find that RandomResizedCrop, RandomGrayscale, and ColorJitter have strong effect on image clustering. For practice, we also applied IDFD to our private images produced by manufacturing process. Generic DA like above were used to these images. IDFD showed good performance on these images according to our experiments. This indicates that our method can be simply applied to practical images. For other types of data such as text and time series, corresponding data augmentation techniques are needed to cooperate with our method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(2017); Wu et al. (2019); Ji et al. (2019); Gupta et al. (2020); Van Gansbeke et al. (2020).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>IIC</head><label></label><figDesc><ref type="bibr" target="#b15">Ji et al. (2019)</ref> andSCAN Van Gansbeke et al. (2020)  are two recent works focusing on image clustering and obtained high performance.IIC Ji et al. (2019)  directly learns semantic labels without learning representations based on mutual information between image pairs. SCAN Van Gansbeke et al. (2020) focuses on the clustering phase and largely improved performance based on a given pre-designed representation learning. By contrast, we focus on learning a clusteringfriendly representation space where objects can be simply clustered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Pipeline of our method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Krizhevsky et al. (2009), CIFAR-100 Krizhevsky et al. (2009), STL-10 Coates et al. (2011), ImageNet-10 Deng et al. (2009), and ImageNet-Dog Deng et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>, deep embedded clustering (DEC) Xie et al. (2016), deep adaptive image clustering (DAC) Chang et al. (2017), deep comprehensive correlation mining (DCCM) Wu et al. (2019), invariant information clustering (IIC) Ji et al. (2019), and semantic clustering by adopting nearest neighbors (SCAN) Van Gansbeke et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5</head><label>5</label><figDesc>visualizes the results of representations learned in four experiments: (a) ID(original), (b) ID(tuned), (c) IDFO with ? = 1 and ? = 10, and (d) IDFD with ? = 1, ? 2 = 2, and ? = 1 on CIFAR-10. 128-dimension representations were embedded into two dimensions by t-SNE (t-distributed stochastic neighbor embedding) Maaten &amp; Hinton (2008). Colors indicate ground truth classes. The distributions for the ID(original) and ID(tuned) again show the significant difference betweenFigure 2: ACC values over learning process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Accuracy of ID for various ? settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Accuracy of IDFD for various ? 2 settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Distribution of feature representations on CIFAR-10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>Feature correlation matrix on CIFAR-10 with ResNet18</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>A</head><label></label><figDesc>DATASETS AND EXPERIMENTAL SETUP Five datasets were used to conduct experiments: CIFAR-10 Krizhevsky et al. (2009), CIFAR-100 Krizhevsky et al. (2009), STL-10 Coates et al. (2011), ImageNet-10 Deng et al. (2009), and ImageNet-Dog Deng et al. (2009).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 :</head><label>8</label><figDesc>Two extreme cases of representation distributions over two-dimensional space. Left: uniform. Right: compact.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 9 :</head><label>9</label><figDesc>exp(cos ?/? ) with different ? settings. contributed by sample i in the uniform case can be calculated as L i unif orm = ? log exp(1/? ) exp(cos m?/? ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 10 :</head><label>10</label><figDesc>Feature correlation matrix learned by VGG16 on CIFAR-10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 11 :</head><label>11</label><figDesc>Effect of each technique used for DA on CIFAR-10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Input images X are converted into feature representations V in a lower d-dimensional latent space, via nonlinear mapping with deep neural networks such as ResNet<ref type="bibr" target="#b10">He et al. (2016)</ref>. The d-dimensional vectors are simultaneously learned through instance discrimination and feature decorrelation. A clustering method, such as classical k-means clustering, is then used on the learned representations to obtain the clustering results.</figDesc><table /><note>Optimization can be performed by mini-batch training. To compute the probability P (i|v) in Eq. (1), {v j } is needed for all images. Like Wu et al. (2018); Xiao et al. (2017), we maintain a feature memory bank for storing them. For Q(l|f ) in Eq. (4), all {f m } of d dimensions in the current mini-batch can be obtained, we simply calculate the Q(l|f ) within the mini-batches.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Clustering results (%) of various methods on five datasets.</figDesc><table><row><cell>Dataset</cell><cell>CIFAR-10</cell><cell>CIFAR-100</cell><cell></cell><cell>STL-10</cell><cell></cell><cell>ImageNet-10</cell><cell></cell><cell>ImageNet-Dog</cell></row><row><cell>Metric</cell><cell cols="8">ACC NMI ARI ACC NMI ARI ACC NMI ARI ACC NMI ARI ACC NMI ARI</cell></row><row><cell>AE</cell><cell cols="2">31.4 23.9 16.9 16.5 10.0</cell><cell>4.8</cell><cell cols="5">30.3 25.0 16.1 31.7 21.0 15.2 18.5 10.4</cell><cell>7.3</cell></row><row><cell>DEC</cell><cell cols="2">30.1 25.7 16.1 18.5 13.6</cell><cell>5.0</cell><cell cols="5">35.9 27.6 18.6 38.1 28.2 20.3 19.5 12.2</cell><cell>7.9</cell></row><row><cell>DAC</cell><cell cols="2">52.2 39.6 30.6 23.8 18.5</cell><cell>8.8</cell><cell cols="5">47.0 36.6 25.7 52.7 39.4 30.2 27.5 21.9 11.1</cell></row><row><cell>DCCM</cell><cell cols="8">62.3 49.6 40.8 32.7 28.5 17.3 48.2 37.6 26.2 71.0 60.8 55.5 38.3 32.1 18.2</cell></row><row><cell cols="9">ID(original) 44.0 30.9 22.1 26.7 22.1 10.8 51.4 36.2 28.5 63.2 47.8 42.0 36.5 24.8 17.2</cell></row><row><cell>IIC</cell><cell cols="4">61.7 51.1 41.1 25.7 22.5 11.7 59.6 49.6 39.7</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>SCAN</cell><cell cols="4">88.3 79.7 77.2 50.7 48.6 33.3 80.9 69.8 64.6</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>ID(tuned)</cell><cell cols="8">77.6 68.2 61.6 40.9 39.2 24.3 72.6 64.0 52.6 93.7 86.7 86.5 47.6 47.0 33.5</cell></row><row><cell>IDFO</cell><cell cols="8">82.8 71.4 67.9 42.5 43.2 24.4 75.6 63.6 56.9 94.2 87.1 87.6 61.2 57.9 41.4</cell></row><row><cell>IDFD</cell><cell cols="8">81.5 71.1 66.3 42.5 42.6 26.4 75.6 64.3 57.5 95.4 89.8 90.1 59.1 54.6 41.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Clustering results (%) on various network architectures.</figDesc><table><row><cell>Network</cell><cell>ConvNet</cell><cell></cell><cell>VGG16</cell><cell>ResNet18</cell><cell>ResNet34</cell></row><row><cell>Metric</cell><cell cols="5">ACC NMI ARI ACC NMI ARI ACC NMI ARI ACC NMI ARI</cell></row><row><cell cols="2">ID(tuned) 26.8 15.0</cell><cell>8.9</cell><cell cols="3">39.3 31.6 20.9 77.6 68.2 61.6 80.2 71.1 64.6</cell></row><row><cell>IDFD</cell><cell cols="5">42.0 32.7 23.2 56.8 46.7 36.5 81.5 71.1 66.3 82.7 73.4 68.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Image datasets used in experiments.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Images Clusters Image size</cell></row><row><cell>CIFAR-10 Krizhevsky et al. (2009)</cell><cell>50,000</cell><cell>10</cell><cell>32 ? 32 ? 3</cell></row><row><cell cols="2">CIFAR-100 Krizhevsky et al. (2009) 50,000</cell><cell>20</cell><cell>32 ? 32 ? 3</cell></row><row><cell>STL-10 Coates et al. (2011)</cell><cell>13,000</cell><cell>10</cell><cell>96 ? 96 ? 3</cell></row><row><cell>Imagenet-10 Deng et al. (2009)</cell><cell>13,000</cell><cell>10</cell><cell>96 ? 96 ? 3</cell></row><row><cell>Imagenet-Dog Deng et al. (2009)</cell><cell>19,500</cell><cell>15</cell><cell>96 ? 96 ? 3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Clustering results (%) with or without data augmentation on five datasets. 65.7 58.3 36.7 35.7 21.9 57.1 49.0 36.8 85.8 79.1 70.5 29.4 16.0 28.5 IDFD With DA 81.5 71.1 66.3 42.5 42.6 26.4 75.6 64.3 57.5 95.4 89.8 90.1 59.1 54.6 41.3</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>CIFAR-10</cell><cell></cell><cell>CIFAR-100</cell><cell></cell><cell></cell><cell>STL-10</cell><cell></cell><cell cols="2">ImageNet-10</cell><cell cols="3">ImageNet-Dog</cell></row><row><cell>Metric</cell><cell cols="13">ACC NMI ARI ACC NMI ARI ACC NMI ARI ACC NMI ARI ACC NMI ARI</cell></row><row><cell>ID W/O DA</cell><cell>18.7</cell><cell>9.5</cell><cell>4.1</cell><cell>14.8 10.7</cell><cell>3.2</cell><cell>19.6</cell><cell>9.0</cell><cell>3.7</cell><cell>23.6 14.1</cell><cell>6.2</cell><cell>12.7</cell><cell>4.6</cell><cell>1.9</cell></row><row><cell cols="3">IDFD W/O DA 23.6 12.1</cell><cell>6.0</cell><cell>16.2 11.6</cell><cell>4.4</cell><cell cols="2">24.8 17.6</cell><cell>8.3</cell><cell cols="3">37.2 23.8 15.6 15.5</cell><cell>5.5</cell><cell>2.5</cell></row><row><cell>ID With DA</cell><cell>76.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised learning by predicting noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="132" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Shiming Xiang, and Chunhong Pan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
	<note>Deep adaptive image clustering</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics</title>
		<meeting>the fourteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Deep unsupervised clustering with gaussian mixture variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nat</forename><surname>Dilokthanakul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Pedro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugh</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Salimbeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Arulkumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shanahan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02648</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.09782</idno>
		<title level="m">Adversarial feature learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improved deep embedded clustering with local structure preservation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1753" to="1759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised clustering using pseudo-semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Divam</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramachandran</forename><surname>Ramjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nipun</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muthian</forename><surname>Sivathanu</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJlnxkSYPS" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Reducing the dimensionality of data with neural networks. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan R</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page" from="504" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>R Devon Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.06670</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning discrete representations via information maximizing self-augmented training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiya</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichi</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1558" to="1567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jo?o</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9865" to="9874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Variational deep embedding: An unsupervised and generative approach to clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuxi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huachun</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bangsheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanning</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05148</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning segmentation by random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marina</forename><surname>Meila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="873" to="879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, highperformance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<ptr target="http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning by coincidence: Siamese networks and common variable learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roy R Lederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="52" to="63" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelly</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boaz</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronen</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Kluger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Spectralnet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.01587</idno>
		<title level="m">Spectral clustering using deep neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Auto-encoder based data clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongzhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Iberoamerican Congress on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="117" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Rdec: Integrating regularization into deep embedded clustering for imbalanced datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaling</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Takagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kouta</forename><surname>Nakata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="49" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning deep representations for graph clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Eighth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Scan: Learning to classify images without labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Wouter Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrike</forename><surname>Von</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luxburg</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep comprehensive correlation mining for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyu</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8150" to="8159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via nonparametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Joint detection and identification feature learning for person search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bochao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3415" to="3424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Towards k-means-friendly spaces: Simultaneous deep learning and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyi</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="3861" to="3870" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
