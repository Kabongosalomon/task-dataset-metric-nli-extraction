<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Malinin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Band</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">J F</forename><surname>Gales</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ganshin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Chesnokov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Noskov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Ploskonosov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liudmila</forename><surname>Prokhorenkova</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Provilkov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vatsal</forename><surname>Raina</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vyas</forename><surname>Raina</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Roginskiy</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariya</forename><surname>Shmatova</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panos</forename><surname>Tigas</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Yangel</surname></persName>
						</author>
						<title level="a" type="main">Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There has been significant research done on developing methods for improving robustness to distributional shift and uncertainty estimation. In contrast, only limited work has examined developing standard datasets and benchmarks for assessing these approaches. Additionally, most work on uncertainty estimation and robustness has developed new techniques based on small-scale regression or image classification tasks. However, many tasks of practical interest have different modalities, such as tabular data, audio, text, or sensor data, which offer significant challenges involving regression and discrete or continuous structured prediction. Thus, given the current state of the field, a standardized large-scale dataset of tasks across a range of modalities affected by distributional shifts is necessary. This will enable researchers to meaningfully evaluate the plethora of recently developed uncertainty quantification methods, as well as assessment criteria and state-ofthe-art baselines. In this work, we propose the Shifts Dataset for evaluation of uncertainty estimates and robustness to distributional shift. The dataset, which has been collected from industrial sources and services, is composed of three tasks, with each corresponding to a particular data modality: tabular weather prediction, machine translation, and self-driving car (SDC) vehicle motion prediction. All of these data modalities and tasks are affected by real, "in-the-wild" distributional shifts and pose interesting challenges with respect to uncertainty estimation. In this work we provide a description of the dataset and baseline results for all tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine learning models are being applied to numerous areas <ref type="bibr">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref> and are widely deployed in production. An assumption which pervades all of machine learning is that the training, validation, and deployment data are independent and identically distributed (i.i.d.). Thus, good performance and generalization on validation data imply that the model will perform well in deployment. Unfortunately, this assumption seldom holds in real, "in the wild", applications. In practice, data are subject to a wide range of possible distributional shifts -mismatches between the training data, and test or deployment data <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>. In general, the greater the degree of shift, the poorer is the model's performance. The problem of distributional shift is of relevance not only to academic researchers, but to the machine learning community at-large. Indeed, all ML practitioners have faced the issue of mismatch between the training and test sets. This is especially important in high-risk applications of machine learning, such as finance, medicine, and autonomous vehicles. In such applications a mistake on part of an ML system may incur financial or reputational loss, or possible loss of life. It is therefore increasingly important to assess both a model's robustness to distribution shift and its estimates of predictive uncertainty, which enable it to detect distributional shifts <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>The area of uncertainty estimation and robustness has developed rapidly in recent years. Model averaging <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref> has emerged as the de-facto standard approach to uncertainty estimation. Ensemble-and sampling-based uncertainty estimates have been successfully applied in detecting misclassifications, out-of-distribution inputs, adversarial attacks <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, and for active learning <ref type="bibr" target="#b18">[19]</ref>. Recently, such approaches have been extended to structured prediction tasks such as machine translation and speech recognition <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref>. However, these approaches require large computational and memory budgets. Works using temperature scaling <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> and other recent approaches in deterministic uncertainty estimation <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref> aim to tackle this issue, but have only recently become comparable to ensemble methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>. Prior Networks <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref> models which emulate the mechanics of an ensemble -have been proposed as a deterministic single model approach to uncertainty estimation which are competitive with ensembles. However, they require distributionally shifted training data, which may not be feasible in many applications. Prior Networks have also been used for Ensemble Distribution Distillation <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36</ref>] -a distillation approach through which the predictive performance and uncertainty estimates of an ensemble are captured within a single Prior Network, reducing the inference cost to that of a single model.</p><p>While much work has been done on developing methods, limited work has focused on new datasets and benchmarks. In <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref>, the authors introduced benchmarks for uncertainty quantification in Bayesian deep learning but only considered the image-based task of classifying diabetic retinopathy. Recently, a range of works by Hendrycks et al. <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref> proposed a set of datasets based on ImageNet <ref type="bibr" target="#b41">[42]</ref> for evaluating model robustness to various types of distributional shifts. These datasets -ImageNet C, A, R, and O -include synthetically added noise, natural adversarial attacks, renderings, and previously unseen classes of objects. <ref type="bibr">1</ref> The release of WILDS, a collection of datasets containing real-world distributional shifts <ref type="bibr" target="#b7">[8]</ref>, similarly represents a significant step forward, but again mostly focuses on images. Finally, the MTNT dataset <ref type="bibr" target="#b42">[43]</ref>, which contains many examples of highly atypical usage of language, such as acronyms, profanity, emojis, slang, and code-switching, has been used at the Workshop on Machine Translation (WMT) robustness track. However, it has not been considered by the uncertainty community in the context of detecting distributional shift.</p><p>Unfortunately, with few exceptions, most work on uncertainty estimation and robustness has focused on developing new methods on small-scale tabular regression or image classification tasks, such as UCI, MNIST <ref type="bibr" target="#b43">[44]</ref>, Omniglot <ref type="bibr" target="#b44">[45]</ref>, SVHN <ref type="bibr" target="#b45">[46]</ref>, and CIFAR10/100 <ref type="bibr" target="#b46">[47]</ref>. Few works have been evaluated on the ImageNet variations A, R, C, and O, or WILDS. However, even evaluation on these datasets is limited, as they mainly focus on image classification, and sometimes text. In contrast, many tasks of practical interest have different modalities, such as tabular data (in medicine and finance), audio, text, or sensor data. Furthermore, these tasks are not always classification; they often involve regression and discrete or continuous structured prediction. Given the current state of the field, we aim to draw the attention of the community to the evaluation of uncertainty estimation and robustness to distributional shift on a realistic set of large-scale tasks across a range of modalities. This is necessary to meaningfully evaluate the plethora of methods for uncertainty quantification and improved robustness, and to accelerate the development of this area and safe ML in general.</p><p>In this work, we propose the Shifts Dataset 2 for evaluation of uncertainty estimates and robustness to distributional shift. This dataset consists of data taken directly from large-scale industrial sources and services where distributional shift is ubiquitous -settings as close to "in the wild" as possible. The dataset is composed of three parts, with each corresponding to a particular data modality: tabular weather prediction data provided by the Yandex Weather service; machine translation data taken from the WMT robustness track and mined from Reddit, and annotated in-house by Yandex Translate; and, self-driving car (SDC) data provided by Yandex SDG, for the task of vehicle motion prediction. All of these data modalities and tasks are affected by distributional shift and pose interesting challenges with respect to uncertainty estimation. This paper provides a detailed analysis of the data as well as baseline uncertainty estimation and robustness results using ensemble methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Evaluation Paradigm, Metrics, and Baselines</head><p>Paradigm In most prior work, uncertainty estimation and robustness have been assessed separately. Robustness to distributional shift is usually assessed via metrics of predictive performance on a particular task -given two (or more) evaluation sets, where one is considered matched to the training data and the other(s) shifted, models which have a smaller degradation in performance on the shifted data are considered more robust. Uncertainty quality is often assessed via the ability to classify whether an example came from the "in-domain" dataset or a shifted dataset using uncertainty estimates. Here, performance is assessed via Area under a Receiver-Operator Curve (ROC-AUC %) or Precision-Recall curve (AUPR %). While these evaluation paradigms are meaningful, we believe that they are two halves of a common whole. Instead, we consider the following paradigm:</p><p>As the degree of distributional shift increases, so does the likelihood that a model makes an error and the degree of this error. Models should yield uncertainty estimates which correlate with the degree of distributional shift, and therefore are indicative of the likelihood and the degree of the error.</p><p>This paradigm is more general, as a model may be robust to certain examples of distributional shift and yield accurate, low uncertainty predictions. A model may also perform poorly and yield high estimates of uncertainty on underrepresented data matched to the training set. Thus, splitting a dataset into "in-domain" and "out-of-distribution" may not yield partitions on which a model strictly performs well or poorly, respectively. Instead, it is necessary to jointly assess robustness and uncertainty estimation, in order to see whether uncertainty estimates at the level of a single prediction correlate well with the likelihood or degree of error. Thus, we view the problems of robustness and uncertainty estimation as having equal importance -models should be robust, but where they are not, they should yield high estimates of uncertainty, which enables risk-mitigating actions to be taken (e.g., transferring control of a self-driving vehicle to a human operator).</p><p>We assume that at training or test time we do not know a priori about alternative domains and whether or how our data is shifted. This setup aims to emulate real-world deployments in which the variation of conditions is vast and one can never collect enough data to cover all situations. It is for this reason we view robustness and uncertainty as equally important -we assume that one can never be fully robust in all situations, and it is in these situations that high-quality uncertainty estimation is crucial. This is a strictly more challenging setting than one in which auxiliary information about the degree or nature of shift is available at training or test time (e.g., in WILDS <ref type="bibr" target="#b7">[8]</ref>).</p><p>We have constructed the Shifts Dataset within the context of this paradigm. Specifically, the dataset is constructed with the following attributes. First, the annotations of distributional shift are meant to be used for analysis rather than model construction. Second, we have "canonically" partitioned the datasets such that the shifts are realistic but significant and to which it is challenging to be fully robust -this allows us to assess the quality of uncertainty estimates. However, the weather and motion prediction datasets can be repartitioned in alternative ways which are different from our canonical partitioning, such that alternative robustness paradigms can be evaluated. <ref type="bibr" target="#b2">3</ref> Assessment Metrics We jointly assess robustness and uncertainty via error-retention curves <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14]</ref> and F1-retention curves. Given an error metric, such as MSE, error-retention curves trace the error over a dataset as a model's predictions are replaced by ground-truth labels in order of decreasing uncertainty. F1-retention curves depict the F1 for predicting whether a model's predictions are sufficiently good based on uncertainties (here we vary retention fraction, i.e., the fraction of data with the smallest uncertainty values that we classify as acceptable). Both assess the performance of a hybrid human-AI system, where a model can consult an oracle (human) for assistance in difficult situations. The area under this curve can be decreased (error retention) or increased (F1 retention) either by improving the predictive performance of the model, such that it has lower overall error, or by providing better estimates of uncertainty, such that more errorful predictions are rejected earlier. Thus, the area under the error (R-AUC) and F1 (F1-AUC) retention curves are metrics which jointly assess robustness to distributional shift and the quality of uncertainty estimates. We also quote F1 at 95% retention rate. These metrics, detailed in Appendix A, are used for all tasks in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choice of Baselines</head><p>In this work we consider ensemble-based baselines. This was done for several reasons. First, ensemble-based approaches are a standard way to obtain both improved robustness versus single models and interpretable uncertainty estimates. Ensembles improve robustness because each model represents a functionally different explanation of the data. Thus, even if each individual model in an ensemble is subject to spurious correlations, the models will have different spurious correlations. When the models are combined, the effects of spurious correlations are cancelled out to a certain degree, improving generalization performance. Second, ensemble methods are easy to apply to any task of choice and require little adaptation. Uncertainty estimates can be obtained from measures of ensemble diversity -if the predictions are diverse, then the ensemble members cannot agree on what the prediction should be and therefore are uncertain. Other than ensemble methods, there are few alternative approaches which are known to yield improved robustness and interpretable uncertainty estimates, can be easily applied to a broad range of large-scale tasks without significant adaptation, and do not require information about the nature of distributional shift at training or test time. We leave the exploration of these alternatives and the development of new ones to future work. We do not examine robust learning methods, such as IRM <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b7">8]</ref>, as they require domain annotations at training time and do not yield uncertainty estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Tabular Weather Prediction</head><p>Uncertainty estimation and robustness are essential in applications like medical diagnostics and financial forecasting. In such applications, data is often represented in a heterogeneous tabular form. While it is challenging to obtain either a large medical or financial dataset, the Yandex Weather service has provided a large tabular Weather Prediction dataset that features a natural tendency for the data distribution to drift over time (concept drift <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50]</ref>). Furthermore, the locations are non-uniformly distributed around the globe based on population density, land coverage, and observation network development, which means that certain climate zones, like the Polar regions or the Sahara, are under-represented. We argue that this tabular Weather Prediction data represents similar challenges to the ones faced on financial and medical data, which is often combined from different hospitals/labs, consists of population-groups that are non-uniformly represented, and has a tendency to drift over time. Thus, the data we consider in this paper can be used as an appropriate benchmark for developing more robust models and uncertainty estimation methods for tabular data.</p><p>Dataset The Shifts Weather Prediction dataset contains a scalar regression and a multi-class classification tasks: at a particular latitude, longitude, and timestamp, one must predict either the air temperature at two meters above the ground or the precipitation class, given targets and features derived from weather station measurements and weather forecast models. The data consists of 10 million 129-column entries: 123 meteorological features, 4 meta-data attributes (time, latitude, longitude and climate type) and 2 targets -temperature (target for regression task) and precipitation class (target for classification task). The full feature list is provided in Section C.2. It is important to note that the features are highly heterogeneous, i.e., they are of different types and scales. The full data is distributed uniformly between September 1 st , 2018, and September 1 st , 2019, with samples across all climate types. This data is used by Yandex for real-time weather forecasts and represents a real industrial application.</p><p>To provide a standard benchmark that contains both in-domain and shifted data, we use a particular "canonical partitioning" 4 of the full dataset into training, development (dev), and evaluation (eval) datasets. The training, in-domain dev (dev_in) and in-domain eval (eval_in) data consist of measurements made from September 2018 till April 8 th , 2019 for climate types Tropical, Dry, and Mild Temperate. The shifted dev (dev_out) data consists of measurements made from 8 th July till 1 st September 2019 for the climate type Snow. 50K data points are sub-sampled for the climate type Snow within this time range to construct dev_out. The shifted eval data is further shifted than the out-of-domain development data; measurements are taken from 14 th May till 8 th July 2019, which is more distant in terms of the time of the year from the in-domain data compared to the out-of-domain development data. The climate types are restricted to Snow and Polar. Further details are provided in Appendix C.1. Details on use and support plan are in Appendix B.</p><p>Baselines To build baseline models for the temperature prediction and precipitation classification tasks, we use the open-source CatBoost gradient boosting library that is known to achieve state-of-the-art results on tabular datasets <ref type="bibr" target="#b50">[51]</ref>. We use an ensemble-based approach to uncertainty estimation for GBDT models <ref type="bibr" target="#b51">[52]</ref>. For each task, an ensemble of ten models is trained on the training data with different random seeds. For regression, the models predict the mean and variance of the normal distribution by optimizing the negative log-likelihood. For classification, the models predict a probability distribution over precipitation classes. Training details are provided in Appendix C.4. Additional ensemble-based baselines and results are provided in Appendix C.5.</p><p>We first compare the predictive performance of ensembles and single models; the results are shown in <ref type="table" target="#tab_0">Table 1</ref>. Firstly, we observe that all models perform worse on shifted data than on in-domain data. For regression, we observe that the RMSE of the ensemble (on the eval set) is about two degrees Celsius. Note that ensembling allows us to reduce RMSE by about 0.16 ? compared to a single model. Similarly, ensembling reduces the MAE by approximately 0.12 ? . For classification, ensembling boosts the accuracy by about 2% and macro-averaged F1 by about 1%. Note that the classification task is unbalanced (see Appendix C.1 for details), so for better interpretability, we also report the accuracy and Macro-F1 of the classifier always predicting the majority class.  <ref type="bibr">35.5</ref> We jointly evaluate the robustness and uncertainty estimates for ensembles and single models. For the regression task, we use the predicted variance as the uncertainty measure of a single model. For ensembles, we use the total variance (tvar) that is the sum of the variance of the predicted mean and the mean of the predicted variance <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b51">52</ref>]. For the classification task, we use the entropy of the prediction as the uncertainty measure of a single model. For ensembles, we use the (negated) confidence. We measure the area under the error-retention and F1-retention curves as described in Appendices A and C.3. These two performance metrics are denoted as R-AUC and F1-AUC, respectively. A good uncertainty measure is expected to achieve low R-AUC and high F1-AUC. Additionally, we report the F1 score at a retention rate of 95% of the most certain samples (F1@95%). All these measures jointly assess the predictive performance and uncertainty quality. The results are shown in <ref type="table" target="#tab_1">Table 2</ref>. Here, as expected, ensembles significantly outperform single models. This observation is consistent over all considered evaluation measures. The associated retention curves are provided in <ref type="figure" target="#fig_1">Figure 1</ref> for eval and <ref type="figure" target="#fig_1">Figure 11</ref> in Appendix C for dev.</p><p>Finally, we conduct a comparison of different uncertainty measures. For this, we measure F1-AUC discussed above and ROC-AUC that evaluates uncertainty-based out-of-distribution (OOD) data detection. The results are shown in <ref type="table" target="#tab_2">Table 3</ref>. In this experiment, we do not evaluate single models. For regression, we consider the following uncertainty measures: total variance (tvar) discussed above that is a measure of total uncertainty, variance of the mean predictions across the ensemble models (varm) and the expected pairwise KL-divergence (EPKL) that are measures of knowledge uncertainty.   The results show that uncertainty measures that capture knowledge uncertainty perform best at OOD detection, as suggested by the high ROC-AUC values, while the measure of total uncertainty performs best for detecting errors (F1-AUC). Thus, as expected, the choice of a metric to use depends heavily on the task. Among measures of knowledge uncertainty, EPKL has better performance. For classification, the measures of total uncertainty are the negative confidence (Conf) and the entropy of the average prediction (Entropy). The measures of knowledge uncertainty are mutual information (MI), EPKL, and reverse mutual information (RMI). Similar to regression, uncertainty measures that capture knowledge uncertainty are better in terms of ROC-AUC. Among them, reverse mutual information performs best. The measures of total uncertainty are better for F1-AUC, and the best results are achieved with negative confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Machine Translation</head><p>As part of the Shifts Dataset we examine the task of machine translation for the text modality. Translation services, such as Google Translate or Yandex Translate, often encounter atypical and unusual use of language in their translation queries. This typically includes slang, profanities, poor grammar, orthography and punctuation, as well as emojis. This poses a challenge to modern translation systems, which are typically trained on corpora with a more "standard" use of language. Therefore, it is important for models to both be robust to atypical language use to provide high-quality translations, as well as to indicate when they are unable to provide a quality translation.</p><p>Translation is inherently a structured prediction task, as there are dependencies between the tokens in the output sequence. Often we must make assumptions about the form of these dependencies; for example, most modern translation systems are left-to-right autoregressive. However, we could consider conditionally independent predictions or other factorization orders. The nature of these assumptions makes it challenging to obtain a theoretically sound measure of uncertainty. Only recently has work been done on developing principled uncertainty measures for structured prediction <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b52">53]</ref>. Nevertheless, this remains an unsolved task and a fruitful area for research.</p><p>Dataset The dataset contains training, development (dev) and evaluation (eval) data, where each set consists of pairs of source and target sentences in English and Russian, respectively. As most production Neural Machine Translation (NMT) systems are built using a variety of general purpose corpora, we use the freely available WMT'20 En-Ru corpus as training data. This dataset primarily focuses on parliamentary and news data that is, for the most part, grammatically and orthographically correct with formal language use. The dev and eval datasets consist of an "in-domain" partition matched to the training data, and an "out-of-distribution" or shifted partition, which contains examples of atypical language usage. The in-domain dev and eval sets are Newstest'19 En-Ru and a newly collected news corpus from GlobalVoices <ref type="bibr" target="#b53">[54]</ref>, respectively. For the shifted development data we use the Reddit corpus prepared for the WMT'19 robustness challenge <ref type="bibr" target="#b42">[43]</ref>. This data contains examples of slang, acronyms, lack of punctuation, poor orthography, concatenations, profanity, and poor grammar, among other forms of atypical language usage. This data is representative of the types of inputs that machine translation services find challenging. As Russian target annotations are not available, we pass the data through a two-stage process, where orthographic, grammatical, and punctuation mistakes are corrected, and the source-side English sentences are translated into Russian by expert in-house Yandex translators. The development set is constructed from the same 1400-sentence test-set used for the WMT'19 robustness challenge. For the evaluation set we use the open-source MTNT crawler which connects to the Reddit API to collect a further set of 3,000 English sentences from Reddit, which is similarly corrected and translated. The shifted dev and eval data are also annotated with 7 non-exclusive anomaly flags. Details on pre-processing, annotations and licenses are available in Appendix D.1. Details on use and support plan are in Appendix B.</p><p>Metrics To evaluate the performance of our models we will consider corpus-level BLEU <ref type="bibr" target="#b54">[55]</ref> and sentence-level GLEU <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58]</ref>. As machine translation is a multi-modal task and translation systems often yield multiple translation hypothesis we will consider two GLEU-based metrics for evaluating translation quality. First is the expected GLEU or eGLEU across all translation hypotheses, where each hypothesis is weighted by a confidence score, and confidences across all hypotheses sum to one. Second is the maximum GLEU maxGLEU across all hypotheses in the beam. Details of these metrics can be found in Appendix D.2. These metrics are then used to compute the error-and F1-retention curves which jointly assess uncertainty and robustness, as discussed in Appendix A.</p><p>Baselines In this work we considered an ensemble baseline based on <ref type="bibr" target="#b23">[24]</ref>. Here, we use an ensemble of 3 Transformer-Big <ref type="bibr" target="#b4">[5]</ref> models trained on the WMT'20 En-Ru corpus. Models were trained using a fork of FairSeq <ref type="bibr" target="#b58">[59]</ref> with a large-batch training set. Beam-Search decoding with a beam-width of 5 is used to obtain translation hypotheses. Hypotheses confidence weights are obtained by exponentiating the negative log-likelihood of each hypothesis and then normalizing across all hypotheses in the beam. Individual models in the ensemble are used as a single-model baseline. <ref type="table" target="#tab_3">Table 4</ref> presents the predictive performance on the dev and eval sets as well as on their in-domain and shifted subsets. There is a performance difference of nearly 10 BLEU and GLEU points between the in-domain news and shifted Reddit data, which shows the degradation in quality due to atypical language usage. The ensemble is able to outperform the individual models, which is expected. These results also show that BLEU correlates quite well with eGLEU. maxGLEU shows that significantly better performance is obtainable if we were better at ranking the hypotheses in the beam. Having evaluated the baselines' predictive performance, we now jointly assess their uncertainty and robustness using the area under the error-retention curve (R-AUC), area under the F1-retention curve (F1-AUC) and F1 at 95% retention, as detailed in Appendices A and D.2. Additionally, we evaluate in terms of % ROC-AUC whether it is possible to discriminate between the in-domain data and the shifted data based on uncertainty estimates by the models. As the measure of uncertainty we use the negative log-likelihood, averaged across all 5 hypotheses. In the case of individual models, this is a measure of data or aleatoric uncertainty, and in the case of the ensemble, it is a measure of total uncertainty <ref type="bibr" target="#b23">[24]</ref>. Here, the ensemble consistently outperforms the single-model baseline.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Vehicle Motion Prediction</head><p>We present the Shifts Vehicle Motion Prediction dataset to examine the implications of distributional shift in self-driving vehicles. The area of autonomous vehicle (AV) technology is highly relevant for uncertainty and robustness research, as the safety requirements and the risks associated with any errors are high. Furthermore, distributional shift is ubiquitous in the autonomous driving domain. During technology development, most self-driving companies concentrate their fleet in a limited number of locations and routes due to the large cost of operating in a new location. Therefore, fleets often face distributional shift when they begin operation in new locations. It is thus important to transfer as much knowledge as possible from the old locations to new ones. It is also critical for a planning model to recognize when this transferred knowledge is insufficient upon encountering unfamiliar data, which could risk unpredictable and unsafe behavior. <ref type="bibr" target="#b4">5</ref> Uncertainty quantification therefore has potentially life-critical application in this domain. For example, when the model's uncertainty is high, the vehicle can exercise extra caution or request assistance from a remote operator.</p><p>Motion prediction is among the most important problems in the autonomous driving domain and has recently drawn significant attention from both academia and industry <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr">63,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b70">71]</ref>. It involves predicting the distribution over possible future states of agents around the self-driving car at a number of moments in time. A model of possible futures is needed because a self-driving vehicle needs a certain amount of time to change its speed, and sudden changes may be uncomfortable or even dangerous for its passengers. Therefore, in order to ensure a safe and comfortable ride, the motion planning module of a self-driving vehicle must reason about where other agents might end up in a few seconds to avoid planning a potential collision. This problem is complicated by the fact that the future is inherently uncertain. For example, we cannot know the high-level navigational goals of other agents, or even their low-level tendency to turn right or left at a T-junction if they fail to indicate one way or another. <ref type="bibr" target="#b5">6</ref> In order for the planning module to make the right decision, this uncertainty must be precisely quantified. Finally, motion prediction is also interesting because the predictions are both structured and continuous. This poses further challenges in uncertainty estimation. Recently, ensemble-based uncertainty estimation for the related task of autonomous vehicle planning was examined <ref type="bibr" target="#b71">[72]</ref>, where a variance-based measure was proposed. However, there is still much potential for further development of informative measures of uncertainty in continuous structured prediction tasks such as motion prediction.</p><p>Dataset The dataset for the Vehicle Motion Prediction task was collected by the Yandex Self-Driving Group (SDG) fleet and is the largest vehicle motion prediction dataset released to date, containing 600,000 scenes. These scenes span six locations, three seasons, three times of day, and four weather conditions. Each scene includes information about the state of dynamic objects and an HD map. Each scene is 10 seconds long and is divided into 5 seconds of context features and 5 seconds of ground truth targets for prediction, separated by the time T = 0. The goal is to predict the movement trajectory of vehicles at time T ? (0, 5] based on the information available for time T ? [?5, 0]. The data contains training, development (dev) and evaluation (eval) sets.</p><p>In order to study the effects of distributional shift, we partition the data such that the dev and eval sets have in-domain partitions which match the location and precipitation type of the training set, and out-of-domain or shifted partitions which do not match the training data along one or more of those axes. As in the other Shifts tasks, we define a canonical partitioning which is used throughout benchmarking. <ref type="bibr" target="#b6">7</ref> The training set and in-domain partition of the dev and eval sets are taken from Moscow. Distributionally shifted dev data is taken from Skolkovo, Modiin, and Innopolis. Distributionally shifted eval data is taken from Tel Aviv and Ann Arbor. We also remove all cases of precipitation from the in-domain sets, while distributionally shifted datasets include precipitation. A full description of the dataset is available in Appendix E, the support plan is detailed in Appendix B.</p><p>Metrics Here we consider five different performance metrics -minimum Average Displacement Error (minADE), minimum Final Displacement Error (minFDE), confidence-weighed ADE and FDE, and corrected Negative Log-Likelihood (cNLL). cNLL is a new metric we introduce that is particilarly well-suited for assessing how models handle multi-modal situations. The minimum or weighting is done across up to 5 trajectories predicted by the baseline models. See Appendix E.3 for detailed explanations of the metrics.</p><p>Baselines We consider two variants of Robust Imitative Planning (RIP) <ref type="bibr" target="#b71">[72]</ref> as baselines. We use an ensemble of probabilistic models to stochastically generate multiple predictions for a given prediction request. Predictions are aggregated across ensemble members via a model averaging (MA) approach. We consider a simple RNN-based behavioral cloning network (RIP-BC) <ref type="bibr" target="#b72">[73]</ref> and autoregressive flow-based Deep Imitative Model (RIP-DIM) <ref type="bibr" target="#b73">[74]</ref> as backbone models. We adapt RIP to produce uncertainty estimates at two levels of granularity: per-trajectory and per-prediction request. Finally, we vary the number of ensemble members K ? {1, 3, 5} and the uncertainty estimation method between Deep Ensembles <ref type="bibr" target="#b13">[14]</ref> and Dropout Ensembles <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b74">75]</ref>. See Appendix E for details on RIP, uncertainty estimation methods, backbone models, experimental setup, and full results. Additional results using Dropout Ensembles are provided in Appendix E.5. Predictive performance results for the RIP variants are presented in <ref type="table" target="#tab_5">Table 6</ref>. Performance is assessed on the in-distribution (In), distributionally shifted (Shifted), and combined (Full) dev and eval datasets. We observe that across all model configurations, performance on the shifted data is worse than that on the in-distribution data. We also observe that RIP-BC consistently outperforms RIP-DIM on the per-trajectory confidence weighted metrics (weightedADE and weightedFDE), and RIP (DIM) outperforms RIP (BC) on minADE and minFDE. This result might occur if DIM has higher predictive variance. In such a case, DIM might be more effective in modeling multimodality, and therefore would tend to produce at least one high accuracy trajectory on more scenes, improving performance on min aggregation metrics. This is supported by DIM models yielding the best cNLL, which is a metric particularly sensitive to correct treatment of multi-modal situations. In contrast, for "obvious" scenes, DIM might then produce unnecessarily complicated trajectories which would be reflected in poor performance on weightedADE. <ref type="table">Table 7</ref>: Uncertainty and robustness performance for motion prediction. The error metric for computing the area under the F1 curve (F1-AUC) and F1 at 95% retention rate (F1@95%) is cNLL.  <ref type="table">Table 7</ref> presents a joint evaluation of the uncertainty quantification and robustness of our baselines. We compute R-AUC with respect to cNLL and weightedADE, and the F1-AUC and F1@95% metrics with respect to the cNLL metric, as detailed in Appendices A and E.3. We observe that an ensemble of RIP-BC models outperforms RIP-DIM on these metrics. These results strongly suggest that RIP-BC has more informative uncertainty estimates than RIP-DIM, because RIP-BC achieves better R-AUC cNLL despite having greater overall error in terms of cNLL (in addition to minADE and minFDE). <ref type="figure" target="#fig_4">Figure 3</ref> depicts, for cNLL, error-and F1-retention curves on the full eval dataset which reflect the trends observed in <ref type="table">Table 7</ref>. Additionally, we find that across model configurations the perprediction request uncertainty scores do not perform particularly well in detecting distribution shift (ROC-AUC). This may occur due to significant data uncertainty in all cases. Future work on detecting distributional shift on this dataset could, for example, inspect the distribution of log-likelihood scores on the in-distribution and shifted partitions in order to devise a metric for this task, aside from the uncertainty scores U used for the retention analysis.  </p><formula xml:id="formula_0">Data Ensemble R-AUC cNLL ? R-AUC weightedADE ? F1-AUC (%) ? F1@95% ? ROC-AUC (%) ? Size (K) RIP-BC RIP-DIM RIP-BC RIP-DIM RIP-BC RIP-DIM RIP-BC RIP-DIM RIP-BC RIP-DIM</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we proposed the Shifts Dataset: a large, standardized dataset for evaluation of uncertainty estimates and robustness to realistic, curated distributional shift. The dataset -sourced from industrial services -is composed of three tasks, with each corresponding to a particular data modality: tabular weather prediction, machine translation, and self-driving car (SDC) vehicle motion prediction. This paper describes this data and provides baseline results using ensemble methods. Given the current state of the field, where most methods are developed on small-scale classification tasks, we aim to draw the attention of the community to the evaluation of uncertainty estimation and robustness to distributional shift on large-scale industrial tasks across multiple modalities. We believe this work is a necessary step towards meaningful evaluation of uncertainty quantification methods, and hope for it to accelerate the development of this area and safe ML in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices A Assessment Metrics</head><p>As discussed in Section 2, in this work we consider robustness and uncertainty estimation to be two equally important factors in assessing the reliability of a model. We assume that as the degree of distributional shift increases, so should a model's errors; in other words, a model's uncertainty estimates should be correlated with the degree of its error. This informs our choice of assessment metrics, which must jointly assess robustness and uncertainty estimation.</p><p>One standard approach to jointly assess robustness and uncertainty are error-retention curves <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14]</ref>, which plot a model's mean error over a dataset, as measured using a metric such as error-rate, MSE, eGLEU, cNLL, etc., with respect to the fraction of the dataset for which the model's predictions are used. These retention curves are traced by replacing a model's predictions with ground-truth labels obtained from an oracle in order of decreasing uncertainty, thereby decreasing error. Ideally, a model's uncertainty is correlated with its error, and therefore the most errorful predictions would be replaced first, which would yield the greatest reduction in mean error as more predictions are replaced. This represents a hybrid human-AI scenario, where a model can consult an oracle (human) for assistance in difficult situations and obtain from the oracle a perfect prediction on those examples.</p><p>The area under the retention curve (R-AUC) is a metric for jointly assessing robustness to distributional shift and the quality of the uncertainty estimates. R-AUC can be reduced either by improving the predictions of the model, such that it has lower overall error at any given retention rate, or by providing estimates of uncertainty which better correlate with error, such that the most incorrect predictions are rejected first. It is important that the dataset in question contains both a subset "matched" to the training data, and a distributionally shifted subset. <ref type="figure" target="#fig_5">Figure 4</ref> provides example retention curves for the three tasks of the Shifts Dataset. In each figure, in addition to the uncertainty-based ranking, we included curves which represent "random" ranking, where uncertainty estimates are entirely non-informative, and "optimal" ranking, where uncertainty estimates perfectly correlate with error. These represent the lower and upper bounds on R-AUC performance as a function of uncertainty quality. While clearly interpretable and intuitive, one concern that can be raised regarding error-retention curves is that they can be more sensitive to predictive performance than to the quality of uncertainty estimates, which can be seen in <ref type="figure" target="#fig_5">Figure 4b</ref>. This occurs on tasks where most errors have similar magnitude. Furthermore, for regression tasks, retention curves are dominated by noise in the targets (aleatoric uncertainty) at low retention fractions, when most systematic errors have already been detected. Therefore, in this work we propose another metric which jointly assesses robustness and uncertainty estimation.</p><p>First, we introduce the notion of an "acceptable prediction", which is a prediction whose error is acceptably small. This concept is natural for tasks with a non-binary notion of error, e.g., regression problems. For classification tasks, where predictions are already either correct or incorrect (acceptable/non-acceptable), this concept can be introduced by considering different levels of risk for different misclassifications. Formally, we say that a prediction is acceptable if an appropriate metric of error or risk E is below a fixed task-dependent error threshold T e . For example, if temperature is predicted to within a degree of the ground truth, then it is acceptable. This allows us to mitigate the issue of errors having similar magnitudes. This is expressed using via an indicator function as follows:</p><formula xml:id="formula_1">A Te (x) = 1, E(x) ? T e 0, E(x) &gt; T e (1)</formula><p>For a given dataset D and model, we first set an error threshold and determine which predictions are acceptable -this yields a set of "ground-truth" acceptability labels A N i=1 . We can now use these acceptability labels to assess whether the model's estimates of uncertainty U(x) can be used to indicate whether a prediction is acceptable. If the uncertainty score is greater than a threshold T u , then we consider the prediction to be poor, if the uncertainty score is lower than this threshold, the prediction is considered to be acceptable.</p><formula xml:id="formula_2">A Tu (x) = 1, U(x) ? T u 0, U(x) &gt; T u<label>(2)</label></formula><p>Next, given the true acceptability labels</p><formula xml:id="formula_3">{A Te (x i )} N i=1 and the threshold-conditional indicators {? Tu (x)} N i=1 we sweep through all uncertainty scores in a dataset {U(x i )} N i=1</formula><p>in decreasing order and use them as thresholds to F1 for classifying whether a prediction is actually acceptable or not based on the uncertainty. Formally, this is done as follows:</p><formula xml:id="formula_4">P i = N j=1 A Te (x j ) ?? Ui (x j ) N ? i , R i = N j=1 A Te (x j ) ?? Ui (x j ) N j=1 A Te (x j ) , F1 i = 2 ? P i ? R i P i + R i<label>(3)</label></formula><p>where we use N ? i because we sort uncertainties from largest (U 1 ) to smallest (U N ). We then plot</p><formula xml:id="formula_5">{F1 i } N i=1 against 1 ? i N , i.e.</formula><p>, the fraction of data we are classifying as acceptable, which we refer to as the retention fraction. This yields the following curves for the three Shifts tasks: Here we plot the uncertainty-based F1-retention curves for all datasets. On each figure, we plot both the uncertainty-derived curves as well as the "random" and "optimal" baselines, where uncertainties are either completely uncorrelated or perfectly correlated with errors, respectively. Better models have a higher area under this F1-retention curve (F1-AUC). The predictive performance of the model defines the starting point at 100% retention -better models start higher. Thus, area under the F1 curve can be increased by having a model which yield better predictions or by improving the correlation between uncertainty and error. Note, in contrast to <ref type="figure" target="#fig_5">Figure 4b</ref>, the quality of the ranking affects area under the curve far more than for error-retention curves. Thus, this metric is especially useful when errors have similar magnitudes.</p><p>Finally, it is necessary to point out that area under the error-retention curve and F1-retention curve is a summary statistic which describes possible operating points. We can specify a particular operating point, such as 95% retention, and evaluate the error or F1 at that point for comparison. This is also an important figure, as all models work at a particular operating point which satisfies task-specific desiderata. In this work the desiderata for all tasks will be to not reject more than 5% of the input data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Shifts Dataset General Datasheet</head><p>Here we describe the motivation, uses, distribution as well as the maintenance and support plan for the Shifts Dataset as whole in the datasheet for datasets format <ref type="bibr" target="#b75">[76]</ref>. The details of the composition, collection and pre-prossessing of each component dataset are provided in appendices C-E Motivation As discussed at length in the main body of the paper, the primary goal for the creation of the Shifts Dataset was the evaluation of uncertainty quantification models and robustness to distributional shift on a range of large-scale, industrial tasks spanning multiple modalities. To this end, Yandex Research, in collaboration with the Yandex.Translate, Yandex.Weather services and Yandex Self-Driving Group created the Shifts Dataset. As the dataset creation was done by Yandex teams, it was therefore funded by Yandex.</p><p>Uses The dataset is used as part of the Shifts Challenge which was organized as part of NeurIPS2021, which was organized around this dataset <ref type="bibr" target="#b7">8</ref> . The Shifts Challenge consists of three tracks organized around each of the consituent datasets within Shifts. The dataset, baseline models and code to reproduce it all is provided in a GitHub repository <ref type="bibr" target="#b8">9</ref> . Other than uncertainty and robustness research the dataset could be used for developing better models for each of the separate tasks -tabular data, translation and vehicle motion prediction. It is our intention that the dataset be freely available for research purposes. The dataset is available as a tarball download from GitHub. Currently, as the Shifts Challenge is still underway, only the training and development sets are available. However, the full dataset, with full accompanying metadata, will be available once the challenge concludes on November 1st, 2021. Licence details for each constituent dataset in Shifts are described in appendices C-E.</p><p>Maintenance The dataset is being actively maintained by Yandex Research, with support from the weather, translation and self-driving teams, and the teams can be contacted by raising an issue on GitHub and by writing to the first author of this paper. The dataset is currently hosted on Yandex S3 storage and will be hosted there permanently for the foreseeable future. The dataset can be updated at the discretion of the dataset creators, though regular updates are not planned. Updates which expand the evaluation sets or add new ones will mean that the previous dev/eval sets are supported. Updates which fix errors in dev/eval sets mean that the prior ones are obsolete and unsupported. If any update is to occur, we will make an announcement via GitHub, twitter, and the Shifts challenge mailing list. Currently, as the data comes directly from Yandex, we do not allows other parties to update the Shifts Dataset. However, any issues found can be logged by raising an issue on GitHub or contacting the first author of this paper so that we can address them. Furthermore, as we are releasing the data under an open-source CC BY NC SA 4.0 license which allows modifications, we are happy for people to create derivative datasets using ours, provided the modifications are documents and the original dataset references.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Societal Consequences and Guidelines for Ethical Use</head><p>Research on uncertainty estimation and robustness aims to make AI safer and more reliable, and therefore has limited negative societal consequences overall. Users of this dataset are encouraged to use it for the purpose of improving the reliability and safety of large-scale applications of machine learning. Furthermore, we encourage users of out dataset to develop compute and memory efficient methods for improving safety and reliability.</p><p>Responsibility The authors confirm that, to the best of our knowledge, the released dataset does not violate any prior licenses or rights. However, if such a violation were to exist, we are responsible for resolving this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Tabular Weather</head><p>The current appendix contains a description of the composition, collection, pre-processing and partitioning of the Shifts Tabular Weather Prediction dataset. Additionally, it contains a description of the metrics used for assessment and an expanded set of experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Dataset Description</head><p>Composition The data consists of pairs of meteorological features and target values at a particular latitude/longitude and time. The target value is air temperature measurements at 2 metres above the ground for regression and precipitation and cloudiness class from weather station measurements for classification. The feature vectors include both weather-related features such as sun evaluation at the current location, climate values of temperature, pressure and topography, and meteorological parameters on different pressure and surface levels from weather forecast model predictions. Weather forecast model predictions are values produced by the following weather forecast models: Global Forecast System (GFS), <ref type="bibr" target="#b9">10</ref> Global Deterministic Forecast System from the Canadian Meteorological Center (CMC), <ref type="bibr" target="#b10">11</ref> and the Weather Research and Forecasting (WRF) Model. <ref type="bibr" target="#b11">12</ref> Each model returns the following predicted values: wind, humidity, pressure, clouds, precipitation, dew point, snow depth, air and soil temperature characteristics. Where applicable, the predictions are given at different isobaric levels from 50 hPa (? 20 km above ground) to the ground level. The GFS and WRF models run 4 times a day (0, 6, 12 and 18 GMT), and the CMC model runs twice a day (0 and 12 GMT). Model spatial grid resolution is 0.25 ? ? 0.25 ? for GFS and 0.24 ? ? 0.24 ? for CMC. The WRF model is calculated for over 60 domains all over the globe, spatial resolution for each domain is 6 ? 6 km. Altogether, there are 123 features in total. It is important to note that the features are highly heterogeneous, i.e., they are of different types and scales. The target air temperature values at different locations are taken from about 8K weather stations located across the globe, each of which periodically (? each 3 hours) reports a set of measurements. In total, the dataset has 129 columns: 123 features, 4 meta-data attributes including time, latitude, longitude, and 2 targets -temperature (target for regression task), precipitation class (target for classification task) and climate type. The full feature list is provided in Section C.2.</p><p>Collection Process The data for features from GFS and CMC weather forecast models was downloaded in the GRIB file format from the web resources https://www.ncdc.noaa.gov and https://weather.gc.ca/, respectively. The GRIB files were decoded and collected by the production system of the Yandex Weather forecast service. MD5 hashes for files were checked after downloading the data. The parameters from WRF model were obtained from WRF model v3.6.1 computation on Yandex Weather servers. The data was checked for mistakes and outliers. Some parameters were converted to different units (for example degrees from K to C). We selected a subset of 123 weather parameters from the full dataset based on expertise and research of feature importance for weather forecasts of temperature and precipitation for the Yandex Weather production system. The data for weather station observations was downloaded from https://www.ncdc.noaa.gov and was decoded from SYNOP code. We filtered missed values and outliers by comparing with previous observations on the same weather station, and by comparing observation with nearby weather stations. Scripts and program codes for data collection and processing were prepared by in-house Yandex Weather software engineers. The period of data collection is from September 2018 to September 2019.</p><p>Preprocessing, Cleaning and Labelling The data was logged during applying trained CatBoost models for weather forecast prediction of the Yandex Weather service and was validated on Yandex Weather users by providing actual weather forecasts and accessing its mistakes on users and station measurements. We labeled data to match the timestamp of features and targets from these logs. Also we selected features only for latitudes and longitudes of weather observation stations to match with the measurements. Targets for air temperature were converted to degrees Celsius. Targets for precipitation class were constructed from cloudiness and precipitation measurements to create 9 classes and labeled as follows: 0 -no precipitation, no clouds, 1 -no precipitation, partly cloudy, 2 -rain, partly cloudy, 3 -sleet, partly cloudy, 4 -snow, partly cloudy, 5 -no precipitation, cloudy, 6 -rain, cloudy, 7 -sleet, cloudy, 8 -snow, cloudy. The "raw" data was not saved, because it requires large amount of disk space. It was deleted after processing the data.</p><p>Partitioning into train, development, and evaluation sets To analyze the robustness of learned models to climate shifts, we use the Koppen climate classification <ref type="bibr" target="#b76">[77]</ref> that provides publicly available data <ref type="bibr" target="#b12">13</ref> that maps latitudes and longitudes at a 0.5 ? resolution to one of five main climate types: Tropical, Dry, Mild Temperate, Snow and Polar. This information is available over the years 1901 to 2010. The Weather Prediction dataset is augmented such that each sample has an associated climate type. The climate type is determined by minimizing the 1-norm between the longitudes/latitudes in the weather data and the Koppen climate classification for the most recent year available, 2010. The climate type is not used as a training feature.</p><p>There are 10M records in the full dataset distributed uniformly between September 1 st , 2018, and September 1 st , 2019, with samples across all five climate types. To test the robustness of the models, we evaluate how well they perform on time-shifted and climate-shifted data. Model performance is expected to decrease with time and climate shifts. However, a robust model is expected to be stable with these shifts.</p><p>In order to provide a standard benchmark which contains data which is both matched and shifted relative to the training set, we split the full dataset into 'canonically partitioned' <ref type="bibr" target="#b13">14</ref> training, development, and evaluation datasets as follows (see <ref type="figure" target="#fig_8">Figure 6</ref>):     <ref type="figure" target="#fig_10">Figure 7</ref> depicts the shift in the target temperatures between the training, development, and evaluation datasets. It is clear that the temperature distribution is different for dev_out and eval_out compared to the in-domain sets. The higher average temperature in the out of domain sets is perhaps due to the out of domain data being sourced from the Summer regions (for the northern hemisphere) while the in-domain data is largely sourced from the Winter time period. <ref type="figure" target="#fig_12">Figure 8</ref> further shows the shift in the samples' locations (latitudes/longitudes) between training, development, and evaluation datasets. The location shift is a natural result of the climate shifts present in the datasets where the training data tends to correspond to warmer parts of the world, whereas the development and evaluation datasets include colder climates too.</p><p>Format This dataset is provided in CSV format.     Licence This dataset is provided under the CC BY NC SA 4.0 license.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Detailed description of features and targets</head><p>Meta-Data Features </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Metrics</head><p>We aim at comparing different models in terms of uncertainty estimation and robustness to distributional shifts. Several performance metrics are considered.</p><p>Predictive Performance For temperature prediction, predictive performance and robustness to distributional shifts are evaluated by measuring RMSE and MAE between predictions and targets: lower the RMSE/MAE score on the test sets, greater the robustness of the models to the distributional shift. For classification, we use accuracy and macro-averaged F1 (one-vs-all averaged with no weighting). More robust models are expected to have higher values of these metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Joint assessment of Uncertainty and Robustness</head><p>We jointly assess robustness and uncertainty estimation via error-retention and F1-retention curves, described in Section 2 and detailed in Appendix A. For regression, we use MSE as the error metric instead of RMSE as it is linear with respect to the error for each datapoint. For the F1-retention curve an acceptable prediction is defined as one where MSE &lt; 1.0. This corresponds to an error of 1 degree or less, which most people cannot feel. Typically people are sensitive to differences in surrounding temperature of over a degree. These two performance metrics are respectively denoted as R-AUC and F1-AUC. For classification, we use the error rate to compute R-AUC. For both classification and regression, a good uncertainty measure is expected to achieve low R-AUC and high F1-AUC. Additionally, the F1 score at a retention rate of 95% of the most certain samples is also quoted and is denoted as F1@95%, which is a single point summary jointly of the uncertainty and robustness. Finally, ROC-AUC is used as a summary statistic for evaluating uncertainty-based out-of-distribution data detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Training details</head><p>The regression models are optimized with the loss function RMSEWithUncertainty [52] that predicts mean and variance of the normal distribution by optimizing the negative log-likelihood. Each model is constructed with a depth of 8 and then is trained for 20,000 iterations at a learning rate of 0.3. The classification models are optimized with the loss function MultiClass that predicts a discrete probability distribution over all classes. Each model is constructed with a depth of 6 and then is trained for 10,000 iterations at a learning rate of 0.4. Hyperparameter tuning is performed on the dev_in data for both tasks. All models were trained within under 8 hours using a normal laptop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Additional experiments</head><p>In addition to considering ensembles of GBDT models implemented in CatBoost, we additionally consider ensembles of neural models. Specifically, we consider the FT-Transformer model <ref type="bibr" target="#b77">[78]</ref>.</p><p>We use FT-Transformers as the basis for Monte-Carlo Dropout Ensembles (MCDP) <ref type="bibr" target="#b12">[13]</ref> as well as Deep Ensembles <ref type="bibr" target="#b13">[14]</ref>. Additionally, we consider combining ensembles of CatBoost models with a Deep Ensemble of FT-Transformer models. Predictive performance figures are presented in <ref type="table" target="#tab_10">table 9</ref>. Here, we can see that ensembles of CatBoost models and Deep ensembles of FT-Transformer models have very similar performance, with the latter marginally outperforming the former. However, their combination yields the most competitive figures. These results are consistent for both the classification and regression tasks. We jointly assess robustness and uncertainty quality for the additional baselines in the table below. Again, the result show that combining all models yields the best results. Curiously, the results also show that Monte-Carlo dropout ensembles are now competitive with CatBoost ensembles. This suggests that the uncertainty quality of MCDP is better than for CatBoost ensembles, even if CatBoost has the better raw predictive quality.</p><p>Finally, we examine the quality of different uncertainty measures which are derivable from all of the baseline models. The results are provided in <ref type="table" target="#tab_0">Table 11</ref>. The results show an interesting trend, where the model which has the best joint uncertainty and robustness performance is a combination of CatBoost and FT-Transformer ensembles, and the best measure of uncertainty is total variance and confidence for regression and classification, respectively. Both are measures of total uncertainty. At the same time, the best model for anomaly detection is a catboost ensemble using measures of knowledge uncertainty. This highlights how the best model and uncertainty measure to use greatly depends on the task.  <ref type="figure" target="#fig_1">Figure 13</ref> depicts additional splits beyond the canonical partition of the tabular weather data. <ref type="table" target="#tab_0">Table  12</ref> summarises the experiments to be performed with a brief description of what each experiment involves. All experiments are to be performed using CatBoost for both the regression and classification tasks. These experiments aim to better understand whether time or climate shift in the data leads to a greater performance drop from in-domain to shifted datasets. Hence, the focus here is on robustness only. The corresponding results for each experiment are given in <ref type="table" target="#tab_0">Table 13</ref>.       </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5.1 Further experiments</head><formula xml:id="formula_6">Regression Classification RMSE ? MAE ? Accuracy (%) ? Macro F1 (%) ? A B C D A B C D A B C D A B C D dev_in</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Machine Translation</head><p>The current appendix contains a description of the composition, collection, pre-processing and partitioning of the Shifts Machine Translation dataset. Additionally, it contains a description of the metrics used for assessment and an expanded set of experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Dataset Description</head><p>Composition The Shifts Machine Translation datasets consists of a training, development (dev) and evaluation (eval) set. Each set consists of pairs of source and target sentences in English and Russian, respectively. As most production NMT systems are built using a variety of general purpose corpora, we do not provide a new training corpus, rather, we will use the freely available WMT'20 English-Russian corpus. This data covers a variety of domains, but primarily focuses on parliamentary and news data. For the most part, this data is grammatically and orthographically correct and language use is formal. This is representative of the type of data used, for example, to build the Yandex.Translate NMT system. The composition of the WMT'20 En-Ru corpus is detailed on the workshop for machine translation website here: http://www.statmt.org/wmt20/translation-task.html. For simplicity of access and archiving purposes we downloaded the WMT'20 En-Ru training data set and also made it available on the Shifts Dataset and Challenge GitHub here: https: //github.com/yandex-research/shifts.</p><p>The dev and eval datasets consist of an "in-domain" partition matched to the training data, and an "out-of-distribution", or shifted partition, which contains examples of atypical language usage. We select the English-Russian Newstest'19 as the in-domain development set and will use a new corpus of news data collected from GlobalVoices News service <ref type="bibr" target="#b53">[54]</ref> and manually annotated using expert human translators as the in-domain evaluation set. For the shifted development and evaluation data we use the Reddit corpus prepared for the WMT'19 robustness challenge <ref type="bibr" target="#b42">[43]</ref>. This data contains examples of slang, acronyms, lack of punctuation, poor orthography, concatenations, profanity, and poor grammar, among other forms of atypical language usage. This data is representative of the types of inputs that machine translation services find challenging. As Russian target annotations are not available, we pass the data through a two-stage process, where orthographic, grammatical and punctuation mistakes are corrected, and the source-side English sentences are translated into Russian by expert in-house Yandex translators. The development set is constructed from the same 1400-sentence test-set used for the WMT'19 robustness challenge. For the heldout evaluation set we use the open-source MTNT crawler which connects to the Reddit API to collect a further set of 3,000 English sentences from Reddit, which is similarly corrected and translated. Note that the Reddit data has comments made by users, but no personal identification data (login, name, etc...) or other user identification data was recorded or stored -the dataset only only contains the raw comments made on a public discussion platform. In terms of size, these development and evaluation sets are comparable or larger to the ones used in the WMT challenges and for evaluating productions systems. Both the development and evaluation Reddit data was manually annotated by members of the Yandex.Translate team with the following 7 non-exclusive anomaly flags:</p><p>? Punctuation anomalies: Some punctuation marks are missed or used incorrectly or some formatting (like Wiki markup) is used in the sentence. ? Spelling anomalies: The sentence contains spelling errors, including incorrect concatenation of two words as well as incorrect use of hyphens. ? Capitalization anomalies: Words that should be capitalized according to the language rules are written in lower case or vice versa. ? Fluency anomalies: The sentence is non-fluent due to wrong or missing prepositions, pronouns or ungrammatical form choice. ? Slang anomalies: In the sentence there are slang words of abbreviations like "idk" for "I don't know" or "cuz" for "because". ? Emoji anomalies: The sentence contains emojis either at the end of it, or instead of some words. ? Tags anomalies: The sentence contains markup for usernames or code like "r/username".</p><p>An analysis of the occurrence and co-occurrence of these anomalies is provided in <ref type="figure" target="#fig_1">figure 14</ref>.</p><p>Collection Process GlobalVoices <ref type="bibr" target="#b53">[54]</ref> data was crawled for parallel news articles in English and Russian using internal Yandex tools. The raw articles were manually split into sentence-pairs by in-house Yandex assessors. A full set of 30000 sentence pairs was produced, from which a subset of 3000 sentences was uniformly randomly sampled. Reddit data was crawled using the open-source MTNT <ref type="bibr" target="#b42">[43]</ref> crawler from https://github.com/pmichel31415/mtnt. This crawler links in with the Reddit API to allow mining and crawling Reddit for data. The crawler collected a set of 100K user comments which were then split into sentences using the NLTK toolkit. Then a set of 3500 sentences was randomly uniformly selected. After pre-processing and cleaning a set of 3065 sentences was produced.</p><p>Preprocessing and Cleaning For the GlobalVoices data parallel sentences markup was done manually by in-house Yandex assessors; non-parallel sentences were removed from dataset. For Reddit data 1-word phrases and sentences consisting only of non-alphabetical symbols were removed. Professional editors were used to manually correct grammatical and orthographic mistakes prior to translating into Russian, but were explicitly told to maintain the non-formal style as much as possible. This error correction was used only for obtaining target-side Russian translation.</p><p>Guidelines on ethical use Users are discouraged from attempting to discover to which Reddit users the comments belong by manually or automatically crawling through Reddit to find the comments.</p><p>Format This dataset is provided in raw text format and a TSV with metadata for the dev and eval reddit data.</p><p>License The Shifts Machine Translation dataset is released under a mixed licence. GlobalVoices evaluation data is released under CC BY NC SA 4.0 . The source-side text for the Reddit development and evaluation datasets exist under terms of the Reddit API. The target side Russian sentences were obtained by Yandex via in-house professional translators and are released under CC BY NC SA 4.0. We highlight that the development set source sentences are the same ones as used in the MTNT dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Metrics</head><p>To evaluate the performance of our models we will consider the following two metrics : corpus-level BLEU <ref type="bibr" target="#b54">[55]</ref> and sentence-level GLEU <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58]</ref>. GLEU is an analogue of BLEU which is stable when computed at the level of individual sentences. Thus, it is far more useful at evaluating system performance on a per-sample basis, rather than at the level of an entire corpus. Note that GLEU correlates strongly with BLEU at the corpus level.</p><p>Machine translation is inherently a multi-modal task, as a sentence can be translated in multiple equally valid ways. Furthermore, translation systems often yield multiple translation hypothesis. To account for this we will consider two GLEU-based metrics for evaluating translation quality. First is the expected GLEU or eGLEU across all translation hypotheses returned by a translation models. Each hypothesis is assumed to be assigned a confidence score, and confidences across each hypotheses by sum to one. This is our primary assessment metric:</p><formula xml:id="formula_7">eGLEU = 1 N N i=1 H h=1 GLEU i,h ? w i,h , w i,h &gt; 0, H h=1 w h = 1<label>(4)</label></formula><p>Additionally, we will consider the maximum GLEU or maxGLEU across all hypothesis, which represents an upper bound on performance, given a model can appropriately rank it's hypotheses:</p><formula xml:id="formula_8">maxGLEU = 1 N N i=1 max h GLEU i,h<label>(5)</label></formula><p>Finally, in order to calculate area under the error retention curve we need to introduce an error metric, where lower error is better. This is trivially done by introducing eGLEU error, which defined as: eGLEU Error = 100 ? eGLEU</p><p>Thus, in section 4, area under the error retention curve (R-AUC), as well as the F1 metric for detecting 'valid predictions' will be calculated using eGLEU Error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Training details</head><p>Training data was standard used the standard perl-based script provided in Fairseq <ref type="bibr" target="#b58">[59]</ref> examples. Duplicate sentence pairs as well as sentence pairs where source and target text matched were removed. Models were trained using Fairseq version 0.8. A full description and for from preprocessing and training is provided here. All models were trained used 8xV100 GPUs over roughly 48 hours. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4 Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Vehicle Motion Prediction</head><p>The current appendix contains a description of the composition, collection, pre-processing and partitioning of the Shifts Vehicle Motion Prediction dataset. Additionally, it contains a description of the metrics used for assessment and an expanded set of experimental results. Composition The dataset for the Vehicle Motion Prediction task was collected by the Yandex Self-Driving Group (SDG) fleet. This is the largest vehicle motion prediction dataset released to date, containing 600,000 scenes (see <ref type="table" target="#tab_0">Table 15</ref> for a comparison to other public datasets). The dataset consists of scenes spanning six locations, three seasons, three times of day, and four weather conditions (cf. <ref type="table" target="#tab_0">Table 16</ref> and 17). Each of these conditions is available in the form of tags associated with every scene. Each scene is 10 seconds long and is divided into 5 seconds of context features and 5 seconds of ground truth targets for prediction, separated by the time T = 0. The goal of the task is to predict the movement trajectory of vehicles at time T ? (0, 5] based on the information available for time T ? [?5, 0]. Each scene includes information about the state of dynamic objects (i.e., vehicles, pedestrians) and an HD map. Each vehicle is described by its position, velocity, linear acceleration, and orientation (yaw, known up to ??). A pedestrian state consists of a position vector and a velocity vector. All state components are represented in a common coordinate frame and sampled at 5Hz frequency by the perception stack running on the Yandex SDG fleet. The HD map includes lane information (e.g., traffic direction, lane priority, speed limit, traffic light association), road boundaries, crosswalks, and traffic light states, which are also sampled at 5Hz. To facilitate easy use of this dataset, we provide utilities to render scene information as a feature map, which can be used as an input to a standard vision model (e.g., a ResNet <ref type="bibr" target="#b78">[79]</ref>). Our utilities represent each scene as a birds-eye-view image with each channel corresponding to a particular feature (e.g., a vehicle occupancy map) at a particular timestep. We also provide pre-rendered feature maps for every prediction request (cf. Appendix E.2) in the dataset, which are used to train the baseline models. The maps are 128 ? 128 pixels in size with each pixel covering 1 square meter, have 17 channels describing both HD map information and dynamic object states at time T = 0, and are centered with respect to the agent for which a prediction is being made. Researchers working with the dataset are free to use these feature maps, use the provided utilities to render another set of feature maps at different (earlier) timesteps, or construct their own scene representations from the raw data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Dataset Description</head><p>The ground truth part of a scene contains future states of dynamic objects sampled at 5Hz for a total of 25 state samples. Some objects might not have all 25 states available due to occlusions or imperfections of the on-board perception system. A number of vehicles in the scene are labeled as prediction requests. These are the vehicles that are visible at the most recent time T = 0 in the context features part of a scene, and therefore would call for a prediction in a deployed system. For such vehicles we provide not only their future trajectories, but also a number of non-mutually exclusive tags (detailed in <ref type="table" target="#tab_0">Table 18</ref>) describing the associated maneuver in more detail -whether the vehicle is turning, accelerating, slowing down, etc. -for a total of 10 maneuver types. Note that some prediction requests may not have all 25 state samples available. We call prediction requests with fully-observed state valid prediction requests and propose to evaluate predictions only on those. In order to study the effects of distributional shift, as well as assess the robustness and uncertainty estimation of baseline models, we divide the Vehicle Motion Prediction dataset such that there are in-domain partitions which match the location and precipitation type of the training set, and out-of-domain or shifted partitions which do not match the training data along one or more of those axes. Furthermore, we provide a development set which acts as a validation set, and an evaluation set which acts as the test set. For standardized benchmarking we define a canonical partitioning of the full dataset (cf. <ref type="figure" target="#fig_1">Figure 16</ref>, <ref type="table" target="#tab_0">Table 19</ref>) as the following. The training, in-domain development, and in-domain evaluation data are taken from Moscow. Distributionally shifted development data is taken from Skolkovo, Modiin, and Innopolis. Distributionally shifted evaluation data is taken from Tel Aviv and Ann Arbor. In addition, we remove all cases of precipitation from the in-domain training, development, and evaluation sets, while distributionally shifted datasets include precipitation. The canonical partitioning is fully described in <ref type="figure" target="#fig_1">Figure 16</ref>. This partitioning is also the one used in the Shifts Challenge.</p><p>Collection Process The Vehicle Motion Prediction data was collected by the perception system running onboard a number of self-driving vehicles equipped with LiDAR sensors, radars, and cameras. This perception system consists of a number of neural network-based detectors followed by an object tracker that fuses detections across sensor modalities and time. The provided HD map for each location has been constructed and validated by cartographers employed by Yandex SDG. The provided dataset was sampled from a much larger dataset collected over a course of 8 months. The sampling procedure was biased towards sampling scenes on which the motion prediction system currently used  by the SDC fleet makes mistakes, as well as sampling more scenes from locations where the fleet drives less frequently.</p><p>Preprocessing and Cleaning The collected dataset has been cleaned from scenes in which:</p><p>? any kind of onboard system failure was detected, as the perception system output can potentially be unreliable in such scenes;</p><p>? the perception system has produced outputs that clearly violate physical constraints, such as actors having unrealistic acceleration or colliding with one other.</p><p>Format This dataset is provided in protobuf format.</p><p>License We release this dataset under the CC BY NC SA 4.0 license.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Task Setup</head><p>Vehicle Motion Prediction is a complex task and therefore must be described in detail. We provide a training dataset D train = {(x i , y i )} N i=1 of time-profiled ground truth trajectories (i.e., plans) y paired with high-dimensional observations (features) x of the corresponding scenes. Each y = (s 1 , . . . , s T ) corresponds to the trajectory of a given vehicle observed through the SDG perception stack. Each state s t corresponds to the x-and y-displacement of the vehicle at timestep t, s.t. y ? R T ?2 . We consider the performance of models on development and evaluation datasets D j</p><formula xml:id="formula_10">dev = {(x i , y i )} Mj i=1 . and D j eval = {(x i , y i )} Mj i=1</formula><p>. See <ref type="figure" target="#fig_1">Figure 17</ref> for a depiction of the task.</p><p>Prediction Requests. There are N (M j ) prediction requests in the training dataset (evaluation datasets), with many requests for each scene corresponding to the many different vehicle trajectories observed. For example, in the canonical partition of the data, there are 388,406 scenes in the training dataset (Moscow, no precipitation), and 5,649,675 valid prediction requests.</p><p>Models can be trained to make use of ground truth trajectories that contain occlusions (i.e., prediction requests that are not valid) during training, such as through linear interpolation of missing steps. However, for the baseline methods considered in this work, both training and evaluation are done using only the fully observed ground truth trajectories.</p><p>Next, we describe the two levels of uncertainty quantification that we consider for each prediction request in the proposed task: per-trajectory and per-prediction request uncertainty scores. Per-Trajectory Confidence Scores. Like machine translation, motion prediction is an inherently multimodal task. A motion prediction model can produce a different number of sampled trajectories (plans) D i for each input x i ; in other words, for two inputs x i , x j with i = j, D i and D j can differ. As a justification, consider that in a certain context, multiple trajectories may be desirable to capture multimodality (e.g., the vehicle of interest is at a T-junction), and in others a single or fewer trajectories would be sufficient (e.g., the vehicle is clearly proceeding straight). In our task, we expect a stochastic model to accompany its D i predicted trajectories on a given input x i with scalar per-trajectory confidence scores c</p><formula xml:id="formula_11">(d) i , d ? {1, . . . D i }.</formula><p>These provide an ordering of the plausibility of the various trajectories predicted for a given input. The scores must be non-negative and sum to 1 (i.e., form a valid probability distribution).</p><p>Per-Prediction Request Uncertainty Score. We also expect models to produce scalar uncertainty estimates corresponding to each prediction request input x i . For example, on evaluation dataset D j eval , we have M j per-prediction request uncertainty scores {U i | i ? 1, . . . , M j }. These correspond to the model's uncertainty in making any trajectory prediction for the agent of interest. In a real-world deployment setting, a self-driving vehicle would associate a high per-prediction request uncertainty score with a scene context that is particularly unfamiliar or high-risk.</p><p>Next, we will describe standard motion prediction performance metrics, followed by confidence-aware metrics which reward models with well-calibrated uncertainty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 Performance Metrics</head><p>Standard Performance Metrics. We assess the performance of a motion prediction system using several standard metrics.</p><p>The average displacement error (ADE) measures the quality of a predicted trajectory y with respect to the ground truth trajectory y * as ADE(y) :</p><formula xml:id="formula_12">= 1 T T t=1 s t ? s * t 2 ,<label>(7)</label></formula><p>where y = (s 1 , . . . , s T ). Analogously, the final displacement error</p><formula xml:id="formula_13">FDE(y) := s T ? s * T 2 ,<label>(8)</label></formula><p>measures the quality at the last timestep.</p><p>Stochastic models define a predictive distribution q(y | x; ?), and can therefore be evaluated over the D trajectories sampled for a given input x. For example, we can measure an aggregated ADE over D samples with</p><formula xml:id="formula_14">aggADE D (q) := ? {y} D d=1 ?q(y|x) ADE(y d ),<label>(9)</label></formula><p>where ? is an aggregation operator, e.g., ? = min recovers the minimum ADE (minADE D ) commonly used in evaluation of stochastic motion prediction models <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b65">66]</ref>. We consider minimum and mean aggregation of the average displacement error (minADE, avgADE), as well as of the final displacement error (minFDE, avgFDE).</p><p>Per-Trajectory Confidence-Aware Metrics. A stochastic model used in practice for motion prediction must ultimately decide on a particular predicted trajectory for a given prediction request. We may make this decision by selecting for evaluation the predicted trajectory with the highest per-trajectory confidence score. In other words, given per-trajectory confidence scores {c (d) | d ? 1, . . . , D} we select the top trajectory y (d * ) , d * = arg max d c (d) , and measure the decision quality using top1 ADE and FDE metrics, e.g., top1ADE D (q) := ADE(y (d * ) ).</p><p>We may also wish to assess the quality of the relative weighting of the D trajectories with their corresponding per-trajectory confidence scores c <ref type="bibr">(d)</ref> . For this the following weighted metric can be considered:</p><formula xml:id="formula_16">weightedADE D (q) := d?D c (d) ? ADE(y (d) ).<label>(11)</label></formula><p>The top1FDE and weightedFDE metrics follow analogously to the above. Unfortunately, these metrics, while highly intuitive, have a conceptual limitation. Consider the following loss:</p><formula xml:id="formula_17">L p(y|x), {? (1:D) i ,? (1:D) } = E p(y|x) D d=1 c d ADE(? d , y) , {? (1:D) i ,? (1:D) } = f (x; ?) (12)</formula><p>which is the expected weightedADE given a set of trajectories and weights from a model. If we wish to minimize this loss with respect to the predicted trajectories and weights, then:</p><formula xml:id="formula_18">L min = min {? (1:D) i ,? (1:D) } E p(y|x) D d=1 c d ADE(? d , y) = min {? (1:D) i } D d=1? d min {? (d) } E p(y|x) ADE(? d , y) = min {? (1:D) i } E p(y|x) [ADE(? * , y)] D d=1? d = E p(y|x) [ADE(? * , y)]<label>(13)</label></formula><p>where? * is the weighted geometric median</p><formula xml:id="formula_19">y * = arg {?} min E p(y|x) [ADE(?, y)]<label>(14)</label></formula><p>Thus, the optimal model would suffer from mode-collapse and always yields the weighted geometric median of the modes of the true distribution of trajectories. To put this concretely, at a T-junction, where trajectories can go either left or right, the optimal model will yield a trajectory going straight, which is clearly a fundamentally undesirable behaviour. Mathematically, the problem lies in the additive nature of the metric -each mode can be optimized independently of the others. This can be avoided by instead considering a likelihood based metric, such as the following one:</p><formula xml:id="formula_20">cNLL(D) := 1 N N n=1 ? ln D d=1 c (d) T t=1 N (y * t,i ; s (d) t (x i ; ?), ? = 1) ? T ln 2?<label>(15)</label></formula><p>Under the following metric, which assumes that each mode is modelled using a Normal distribution of fixed variance, an optimal model would place a Normal over each mode and weight them appropriately. This can be clearly demonstrated using the following numerical example: </p><p>(19) Where we have a bimodal Gaussian mixture distribution with modes at -10, 10. We assume we have a model which predicts the means of two trajectories with equal weight. We have two situations: either the model yields two distinct modes at -10, 10 or a collapsed mode at 0 (the median). We can see that predicting the median will yield a lower weightedADE and correctly predicting two distinct modes will yield the lower cNLL. It is important to highlight that this argument holds in expectation and is relevant to situations which contain inherent ambiguity and multi-modality. Note that the offset T ln 2? is used to make assure that the minimal value of this metric is 0, so that it can be used for error-retention and F1-retention plots.</p><p>Per-Prediction Request Confidence-Aware Metrics. In addition to making a decision amongst many possible trajectories in a particular situation, a motion planning agent should know when, in general, any trajectories it predicts will be inaccurate (e.g., due to unfamiliarity of the setting, or inherent ambiguity in the path of the vehicle for which a prediction is requested). We evaluate the quality of uncertainty quantification jointly with robustness to distributional shift using the retentionbased metrics described in Section 2, with the per-prediction request uncertainty scores determining retention order. Note that each retention curve is plotted with respect to a particular error metric above (e.g., we consider AUC for retention with respect to the cNLL metric introduced above, written as R-AUC). Additionally, we also assess whether the per-prediction uncertainty scores can be used to discriminate between in-domain and shifted scenes. In this case, quality is assessed via area under a ROC curve (ROC-AUC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.4 Experimental Setup</head><p>Robust Imitative Planning. In detail, we use the following approach for trajectory and confidence score generation.</p><p>1) Trajectory Generation. Given a scene input x, K ensemble members generate G trajectories. <ref type="bibr" target="#b14">15</ref> 2) Trajectory Scoring. We score each of the G trajectories by computing a log probability under each of the K trained likelihood models. 3) Per-Trajectory Confidence Scores. We aggregate the G ? K resulting log probabilities to G scores using a per-trajectory aggregation operator ? trajectory . <ref type="bibr" target="#b15">16</ref> By aggregating over the log-likelihood estimates sampled from the model posterior (i.e., contributed by each ensemble member), we obtain a robust score for each of the G trajectories <ref type="bibr" target="#b71">[72]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Trajectory Selection.</head><p>Among the G trajectories, the RIP ensemble produces the top D trajectories as determined by their corresponding G per-trajectory confidence scores, where D is a hyperparameter. 5) Per-Prediction Request Uncertainty Score. We aggregate the D top per-trajectory confidence scores to a single uncertainty score U using the aggregator ? pred-req . <ref type="bibr" target="#b16">17</ref> This value conveys the ensemble's estimated uncertainty for a given scene context and a particular prediction request.</p><p>6) Confidence Reporting. We obtain scores c (d) by applying a softmax to the D top pertrajectory confidence scores. We report these c (d) and U (computed in step 5) as our final per-trajectory confidence scores and per-prediction request uncertainty score, respectively.</p><p>To summarize, our implementation of RIP for motion prediction produces D trajectories and corresponding normalized per-trajectory scores {c (d) | d ? 1, . . . , D}, as well as an aggregated uncertainty score U for the overall prediction request.</p><p>Backbone Likelihood Model. We consider two different model classes as ensemble members: a simple behavioral cloning agent with a Gated Recurrent Unit decoder (BC) <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b72">73]</ref> and a Deep Imitative Model (DIM) <ref type="bibr" target="#b73">[74]</ref> with an autoregressive flow decoder <ref type="bibr" target="#b81">[82]</ref>, following <ref type="bibr" target="#b71">[72]</ref>. In both cases, we model the likelihood of a trajectory y in context x to come from an expert (i.e., from the distribution of ground truth trajectories), with learnable parameters ?, as</p><formula xml:id="formula_22">q(y | x; ?) = T t=1 p(s t | y &lt;t , x; ?) = T t=1 N (s t ; ?(y &lt;t , x; ?), ?(y &lt;t , x; ?)),<label>(20)</label></formula><p>where ?(?; ?) and ?(?; ?) are two heads of a recurrent neural network with shared torso. Hence we assume that the conditional densities are normally distributed, and learn those parameters through maximum likelihood estimation. Notably, for the BC model, we found that conditioning on sample? y &lt;t instead of ground truth values y &lt;t (where usage of ground truth is often referred to as teacher forcing in RNN literature) significantly improved performance across all datasets and metrics.</p><p>Uncertainty Estimation Methods. The above ensembling is done using multiple stochastic models trained with different random seeds, as introduced in Deep Ensembles <ref type="bibr" target="#b13">[14]</ref>. For each ensemble member, we generate Q trajectories. We can also use a Monte Carlo Dropout <ref type="bibr" target="#b12">[13]</ref> approach for each ensemble member, in which we sample new dropout masks at test time during each of the Q forward passes (and corresponding trajectory generations). Following <ref type="bibr" target="#b74">[75]</ref> we refer to the combination of this uncertainty estimation method with ensembling as Dropout Ensembles. Previous work has investigated the benefits of Deep Ensembles from a loss landscape perspective <ref type="bibr" target="#b82">[83]</ref>, and found that Deep Ensembles tend to explore diverse modes in function space, whereas approximate variational methods such as Monte Carlo Dropout explore around a particular mode. Dropout Ensembles are hence motivated as ensembles of variational methods which aim to consider a diverse set of modes, with local exploration around each mode.</p><p>Setup. We report performance of RIP across the two backbone models -Behavioral Cloning (BC) <ref type="bibr" target="#b72">[73]</ref> and Deep Imitative Model (DIM) <ref type="bibr" target="#b73">[74]</ref> -as well as the two uncertainty estimation methods -Deep Ensembles <ref type="bibr" target="#b13">[14]</ref> and Dropout Ensembles <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b74">75]</ref>. We evaluate RIP on development (dev) and evaluation (eval) datasets in in-distribution (In), distributionally shifted (Shifted), and combined in-distribution and shifted (Full) settings. With both backbone model classes we vary the number of ensemble members K ? {1, 3, 5}, train with learning rate 1e-4, use a cosine annealing LR schedule with 1 epoch warmup, and use gradient clipping at 1. We sample Q = 10 trajectories from each of the ensemble members. We consider two types of aggregation: "Lower Quartile" in which we compute the mean minus the standard deviation ? ? ? of the input scores, and "Model Averaging" (MA) in which we compute the mean ? of the input scores. LQ reflects the intuition to assign a high score to a trajectory when the ensemble members assign it a high score on average, and tend to be certain (have a low standard deviation) in their scoring; MA reflects only the prior intuition. This aggregation strategy (LQ or MA) is used as both the per-trajectory aggregation operator ? trajectory and the per-prediction request aggregation operator ? pred-req (where the latter is followed by negation to obtain an uncertainty, as opposed to a confidence). We fix the RIP ensemble at all K to produce the top D = 5 trajectories as ranked by their per-trajectory confidence score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.5 Additional Results</head><p>Below, we report predictive performance using standard-metrics, robustness and uncertainty quantification metrics, and retention plots across the RIP variants.  <ref type="figure" target="#fig_1">Figure 18</ref>: cNLL and F1-cNLL retention curves on the Full (i.e., containing both the in-distribution and distributionally shifted datapoints) dev (left column) and eval (right column) partitions of the Vehicle Motion Prediction dataset. Top row: retention on cNLL (lower ? AUC is better). Bottom row: retention on F1-cNLL (higher ? AUC is better). We vary the backbone model and number of ensemble members, fix the Model Averaging (MA) aggregation strategy for the per-trajectory aggregation operator ? trajectory and the per-prediction request aggregation operator ? pred-req (based on results from <ref type="table">Table 7)</ref>, and otherwise use the standard RIP settings enumerated in Appendix E.4. <ref type="table" target="#tab_1">Table 20</ref>: Predictive performance of RIP, across model backbones (behavioral cloning (BC) <ref type="bibr" target="#b72">[73]</ref> and Deep Imitative Model (DIM) <ref type="bibr" target="#b73">[74]</ref>) and uncertainty estimation methods (Deep Ensembles <ref type="bibr" target="#b13">[14]</ref> and Dropout Ensembles <ref type="bibr" target="#b74">[75]</ref>). Each section contains losses computed over the in-distribution (In), distributionally shifted (Shifted), and combined (Full) development and evaluation datasets. Altogether, we vary the backbone model, uncertainty estimation method, aggregation strategy (applied for both the per-trajectory aggregation operator ? trajectory and the per-prediction request aggregation operator ? pred-req ), and the number of ensemble members K. See Appendix E.4 for setup details.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Retention curves with CatBoost on eval for the Weather Prediction dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Retention curves using eGLEU on eval data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>, K=5) [AUC: 10.572] RIP (DIM, K=1) [AUC: 14.322] RIP (BC, K=1) [AUC: 12.909] RIP (DIM, K=5) [AUC: 15.160] (a) cNLL error-retention. , K=5) [AUC (%): 65.1] RIP (DIM, K=1) [AUC (%): 63.6] RIP (BC, K=1) [AUC (%): 65.0] RIP (DIM, K=5) [AUC (%): 63.5] (b) cNLL F1-retention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Retention curves for Vehicle Motion Prediction on full eval data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>, MA, K=5) Random [AUC: 0.513] RIP (BC, MA, K=5) [AUC: 0.236] RIP (BC, MA, K=5) Optimal [AUC: 0.173] (c) Vehicle Motion Prediction Example error retention curves for the three tasks of the Shifts Dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>RIP (BC, MA, K=5) Random [AUC: 0.534] RIP (BC, MA, K=5) [AUC: 0.674] RIP (BC, MA, K=5) Optimal [AUC: 0.699] (c) Motion Prediction Examples of F1-Retention curves for the three tasks of the Shifts Dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Distribution</head><label></label><figDesc>The parts of the dataset which were produced by Yandex are distributed under an open-source CC BY NC SA 4.0 license. All the code is available under an open-source Apache 2.0 licence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Canonical Partitioning of Weather Prediction dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>?</head><label></label><figDesc>The training data consists of measurements made from September 2018 till April 8 th , 2019 for climate types Tropical, Dry, and Mild Temperate. The training data includes two dummy rows in order to ensure there is at least one example of each of the precipitation classes (the targets for the classification task). The values for each of the features of the dummy examples are computed by averaging across the whole training dataset.? The development data is composed of in-domain (dev_in) and out-of-domain (dev_out)data. The in-domain data corresponds to the same time range and climate types as the training data. The out-of-domain development data consists of measurements made from 8 th July till 1 st September 2019 for the climate type Snow. 50K data points are subsampled for the climate type Snow within this time range to construct dev_out.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Temperature distributions on canonical partitions of Weather Prediction dataset.? The evaluation data is also composed of in-domain (eval_in) and out-of-domain (eval_out) data. As before, the in-domain data corresponds to the same time range and climate types as the training data. The out-of-domain evaluation data is further shifted than the out-of-domain development data; measurements are taken from 14 th May till 8 th July 2019, which is more distant in terms of the time of the year from the in-domain data compared to the out-of-domain development data. The climate types are restricted to Snow and Polar.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>dev_in. (c) eval_in. (d) dev_out.(e) eval_out.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 :</head><label>8</label><figDesc>Location of samples from canonical partitioning of Weather Prediction dataset. (a) train. (b) dev_in. (c) eval_in.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 9 :</head><label>9</label><figDesc>Distribution of climate types from canonical partitioning of Weather Prediction dataset.(a) train. (b) dev_in. (c) eval_in. (d) dev_out. (e) eval_out. (f) all.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 10 :</head><label>10</label><figDesc>Distribution of precipitation classes from canonical partitioning of Weather Prediction dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>(e) FT-Trans, Regression, MSE.(f) FT-Trans, Regression, F1.(g) FT-Trans, Classification, error rate. (h) FT-Trans, Classification, F1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 11 :</head><label>11</label><figDesc>Retention curves for CatBoost and FT-Transformer on dev for the canonical Weather prediction dataset. (c) CatBoost, Classification, error rate. (d) CatBoost, Classification, F1. (e) FT-Trans, Regression, MSE. (f) FT-Trans, Regression, F1. (g) FT-Trans, Classification, error rate. (h) FT-Trans, Classification, F1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 12 :</head><label>12</label><figDesc>Retention curves with CatBoost and FT-Transformer on eval for the canonical Weather prediction dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 13 :</head><label>13</label><figDesc>Extended splits of tabular weather data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 14 :</head><label>14</label><figDesc>Analysis of anomaly occurrence and co-occurrence in Reddit (shifted) development and evaluation data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 15 :</head><label>15</label><figDesc>Location of samples from canonical partitioning of Weather Prediction dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 16 :</head><label>16</label><figDesc>The canonical partitioning of the Vehicle Motion Prediction dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 17 :</head><label>17</label><figDesc>Diagram of the Vehicle Motion Prediction task. Models take as input a single scene context x composed of static (HD map) and time-dependent input features, and predict trajectories {y (d) | d ? 1, . . . , D} with corresponding per-trajectory confidence scores {c (d) | d ? 1, . . . , D}, as well as a single per-prediction request uncertainty score U .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>y 5 E</head><label>5</label><figDesc>? p(y) = 0.5 ? N (x, 10, 1) + 0.5 ? N (x, ?10, 1) E p (y)[wADE(y, s (1:2) = [10, ?10], c = [0.5, 0.5])] = 201.p (y)[wADE(y, s (1:2) = [0, 0], c = [0.5, 0.5])] = 101.50 E p (y)[cNLL(y, s (1:2) = [10, ?10], c = [0.5, 0.5])] = 1.09 E p (y)[cNLL(y, s (1:2) = [0, 0], c = [0.5, 0.5])] = 50.75 (16)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>, K=5) [AUC: 13.242] RIP (DIM, K=1) [AUC: 12.864] RIP (BC, K=5) [AUC: 9.077] RIP (BC, K=1) [AUC: 11.219] (a) Full dev cNLL retention. , K=5) [AUC: 10.572] RIP (DIM, K=1) [AUC: 14.322] RIP (BC, K=1) [AUC: 12.909] RIP (DIM, K=5) [AUC: 15.160] (b) Full eval cNLL retention. , K=5) [AUC (%): 63.7] RIP (DIM, K=1) [AUC (%): 63.8] RIP (BC, K=5) [AUC (%): 65.2] RIP (BC, K=1) [AUC (%): 65.1] (c) Full dev F1-cNLL retention. , K=5) [AUC (%): 65.1] RIP (DIM, K=1) [AUC (%): 63.6] RIP (BC, K=1) [AUC (%): 65.0] RIP (DIM, K=5) [AUC (%): 63.5] (d) Full eval F1-cNLL retention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Predictive performance for Weather Prediction. Mean ? ? is quoted for the single models. ?0.00 44.1 eval-out 2.60 ?0.03 2.37 1.91 ?0.01 1.75 30.0 44.5 ?0.184 46.7 17.4 21.5 ?0.00 22.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Regression</cell><cell></cell><cell cols="2">Classification</cell><cell></cell></row><row><cell>Data</cell><cell>RMSE ? Single</cell><cell>Ens</cell><cell>MAE ? Single</cell><cell>Ens Maj.</cell><cell>Accuracy (%) ? Single</cell><cell>Macro F1 (%) ? Ens Maj. Single</cell><cell>Ens</cell></row><row><cell>dev-in</cell><cell>1.59</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>?0.00 1.51 1.18 ?0.00 1.11 37.9 67.0 ?0.075 68.5 17.2 42.2 ?0.01 42.3 dev-out 2.30 ?0.01 2.12 1.75 ?0.01 1.61 35.7 47.5 ?0.249 50.3 19.4 20.2 ?0.01 21.3 dev 1.98 ?0.01 1.84 1.47 ?0.01 1.36 36.8 57.2 ?0.117 59.4 17.2 36.8 ?0.01 37.2 eval-in 1.60 ?0.00 1.52 1.19 ?0.00 1.11 37.9 66.7 ?0.060 68.2 17.2 42.92 eval 2.16 ?0.01 2.00 1.56 ?0.01 1.44 33.9 55.5 ?0.090 57.3 17.4 34.4 ?0.01</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Retention performance for Weather Prediction. Mean ? ? is quoted for the single models. ?0.017 1.227 44.35 ?0.2 52.20 62.72 ?0.1 65.83 eval 2.320 ?0.063 1.335 43.41 ?0.1 52.36 61.89 ?0.1 64.72 Classification dev 0.1666 ?0.001 0.1522 57.72 ?0.1 59.07 73.04 ?0.1 74.86 eval 0.1799 ?0.001 0.1640 56.25 ?0.1 58.22 71.56 ?0.1 73.17</figDesc><table><row><cell></cell><cell>Data</cell><cell>R-AUC ? Single</cell><cell>Ens</cell><cell>F1-AUC (%) ? Single Ens</cell><cell>F1@95% ? Single Ens</cell></row><row><cell>Regression</cell><cell>dev</cell><cell>1.894</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparing uncertainty measures of CatBoost ensembles for Weather Prediction.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Regression</cell><cell></cell><cell></cell><cell cols="3">Classification</cell></row><row><cell>Data</cell><cell></cell><cell cols="3">Total Unc. Knowledge Unc.</cell><cell cols="2">Total Unc.</cell><cell cols="2">Knowledge Unc.</cell></row><row><cell></cell><cell></cell><cell>tvar</cell><cell>varm</cell><cell>EPKL</cell><cell cols="2">Conf Entropy</cell><cell>MI</cell><cell>EPKL RMI</cell></row><row><cell>dev</cell><cell>F1-AUC (%) ? ROC-AUC (%) ?</cell><cell>52.20 62.96</cell><cell>50.12 82.31</cell><cell>50.51 85.29</cell><cell>59.07 63.98</cell><cell>58.86 65.00</cell><cell cols="2">57.72 57.69 57.66 83.75 83.96 84.12</cell></row><row><cell>eval</cell><cell>F1-AUC (%) ? ROC-AUC (%) ?</cell><cell>52.36 65.99</cell><cell>49.81 78.32</cell><cell>50.40 79.90</cell><cell>58.22 66.20</cell><cell>57.89 66.76</cell><cell cols="2">56.99 56.96 56.93 83.44 83.59 83.68</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Predictive performance for Machine Translation. Mean ? ? is quoted for the single models. 39?0.10 30.88 36.19 ?0.19 36.82 eval-out 21.00 ?0.12 21.54 23.19?0.07 23.60 29.</figDesc><table><row><cell>Data</cell><cell>BLEU ? Single</cell><cell>Ens</cell><cell>eGLEU ? Single</cell><cell>Ens</cell><cell cols="2">maxGLEU ? Single Ens</cell></row><row><cell>dev-in</cell><cell>32.04?0.23</cell><cell cols="4">32.73 34.45?0.10 35.09 41.08?0.09</cell><cell>42.00</cell></row><row><cell>dev-out</cell><cell>20.65?0.16</cell><cell cols="4">21.06 22.66?0.07 23.00 28.28?0.19</cell><cell>28.63</cell></row><row><cell>dev</cell><cell>28.89?0.20</cell><cell cols="4">29.52 29.67?0.09 30.19 35.89?0.12</cell><cell>36.58</cell></row><row><cell>eval-in</cell><cell>29.52?0.21</cell><cell cols="4">30.08 30.35?0.11</cell><cell>29.88</cell></row><row><cell>eval</cell><cell>26.39?0.17</cell><cell cols="4">26.92 26.76?0.06 27.20 32.74?0.14</cell><cell>33.31</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Uncertainty and robustness for Machine Translation. Mean ? ? is quoted for single models. ?0.48 32.87 0.43 ?0.00 0.44 0.42 ?0.01 0.43 68.90 ?0.28 69.30 eval 34.80 ?0.06 34.57 0.37 ?0.07 0.38 0.34 ?0.03 0.36 79.18 ?0.63 80.10</figDesc><table><row><cell>Data</cell><cell>R-AUC ? Single</cell><cell>Ens</cell><cell>F1-AUC ? Single Ens</cell><cell>F1@95% ? Single Ens</cell><cell>ROC-AUC (%) ? Single Ens</cell></row><row><cell>dev</cell><cell>33.22</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table><row><cell cols="2">Dataset Model</cell><cell>In</cell><cell>cNLL ? Shifted</cell><cell>Full</cell><cell>In</cell><cell>minADE ? Shifted</cell><cell>Full</cell><cell>In</cell><cell cols="3">weightedADE ? Shifted Full</cell><cell>In</cell><cell>minFDE ? Shifted</cell><cell>Full</cell><cell>In</cell><cell>weightedFDE ? Shifted Full</cell></row><row><cell></cell><cell>BC, MA, K=1</cell><cell>59.64</cell><cell>98.54</cell><cell cols="2">64.29 0.818</cell><cell>0.960</cell><cell cols="3">0.835 1.088</cell><cell>1.245</cell><cell cols="2">1.107 1.718</cell><cell>2.113</cell><cell>1.765 2.368</cell><cell>2.777</cell><cell>2.417</cell></row><row><cell>Dev</cell><cell cols="2">BC, MA, K=5 DIM, MA, K=1 50.66 56.86</cell><cell>91.54 73.00</cell><cell cols="2">61.01 0.765 53.34 0.750</cell><cell>0.887 0.818</cell><cell cols="3">0.779 1.012 0.758 1.523</cell><cell>1.133 1.583</cell><cell cols="2">1.026 1.617 1.530 1.497</cell><cell>1.976 1.720</cell><cell>1.660 2.210 1.524 3.472</cell><cell>2.551 3.639</cell><cell>2.251 3.492</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=5 50.85</cell><cell>72.45</cell><cell cols="2">53.43 0.719</cell><cell>0.786</cell><cell cols="3">0.727 1.399</cell><cell>1.469</cell><cell cols="2">1.408 1.482</cell><cell>1.698</cell><cell>1.508 3.202</cell><cell>3.393</cell><cell>3.225</cell></row><row><cell></cell><cell>BC, MA, K=1</cell><cell>60.20</cell><cell>98.82</cell><cell cols="2">67.93 0.829</cell><cell>1.084</cell><cell cols="3">0.880 1.104</cell><cell>1.407</cell><cell cols="2">1.164 1.733</cell><cell>2.420</cell><cell>1.870 2.394</cell><cell>3.197</cell><cell>2.555</cell></row><row><cell>Eval</cell><cell cols="2">BC, MA, K=5 DIM, MA, K=1 50.50 57.75</cell><cell>95.00 76.00</cell><cell cols="2">65.20 0.777 55.60 0.759</cell><cell>1.014 0.942</cell><cell cols="3">0.824 1.028 0.796 1.551</cell><cell>1.299 1.883</cell><cell cols="2">1.082 1.636 1.618 1.511</cell><cell>2.278 1.983</cell><cell>1.765 2.238 1.605 3.536</cell><cell>2.957 4.376</cell><cell>2.382 3.704</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=5 51.19</cell><cell>78.85</cell><cell cols="2">56.73 0.728</cell><cell>0.918</cell><cell cols="3">0.766 1.424</cell><cell>1.754</cell><cell cols="2">1.490 1.493</cell><cell>2.000</cell><cell>1.595 3.256</cell><cell>4.093</cell><cell>3.424</cell></row></table><note>Predictive performance of BC &amp; DIM RIP on in-domain, shifted, and full dev &amp; eval data.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Number of samples in the canonical partitioning of Weather Prediction dataset.</figDesc><table><row><cell></cell><cell>Data</cell><cell>Total</cell><cell>Tropical</cell><cell cols="2"># of samples Dry Mild Temperate</cell><cell>Snow</cell><cell>Polar</cell></row><row><cell>Training</cell><cell>train</cell><cell cols="3">3,129,592 416,310 690,284</cell><cell>2,022,998</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>dev_in</cell><cell>50,000</cell><cell>6,641</cell><cell>10,961</cell><cell>32,398</cell><cell>0</cell><cell>0</cell></row><row><cell>Development</cell><cell>dev_out</cell><cell>50,000</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>50,000</cell><cell>0</cell></row><row><cell></cell><cell>dev</cell><cell>100,000</cell><cell>6,641</cell><cell>10,961</cell><cell>32,398</cell><cell>50,000</cell><cell>0</cell></row><row><cell></cell><cell>eval_in</cell><cell>561,105</cell><cell cols="2">74,406 123,487</cell><cell>363,212</cell><cell>0</cell><cell>0</cell></row><row><cell>Evaluation</cell><cell>eval_out</cell><cell>576,626</cell><cell>0</cell><cell>0</cell><cell cols="3">0 525,967 50,659</cell></row><row><cell></cell><cell>eval</cell><cell>1,137,731</cell><cell cols="2">74,406 123,487</cell><cell cols="3">363,212 525,967 50,659</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 details</head><label>8</label><figDesc></figDesc><table /><note>the number of samples in the selected partition of the data. It also details the number of samples for each climate type for each part of the dataset. The in-domain data is split in approximately 83.7-1.3-15% ratio between training, development, and evaluation.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Predictive performance for Weather prediction. Mean is quoted for the single models.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Regression</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Classification</cell></row><row><cell cols="2">Dataset Model</cell><cell></cell><cell>RMSE ?</cell><cell></cell><cell></cell><cell>MAE ?</cell><cell></cell><cell cols="3">Accuracy (%) ?</cell><cell>Macro F1 (%) ?</cell></row><row><cell></cell><cell></cell><cell>In</cell><cell cols="2">Shifted Full</cell><cell>In</cell><cell cols="2">Shifted Full</cell><cell>In</cell><cell cols="2">Shifted Full</cell><cell>In</cell><cell>Shifted Full</cell></row><row><cell></cell><cell>CatBoost, Single</cell><cell>1.59</cell><cell>2.30</cell><cell cols="2">1.98 1.18</cell><cell>1.75</cell><cell cols="2">1.47 67.0</cell><cell>47.5</cell><cell cols="2">57.2 42.2</cell><cell>20.2</cell><cell>36.8</cell></row><row><cell></cell><cell>CatBoost, Ensemble</cell><cell>1.51</cell><cell>2.12</cell><cell cols="2">1.84 1.11</cell><cell>1.61</cell><cell cols="2">1.36 68.5</cell><cell>50.3</cell><cell cols="2">59.4 42.3</cell><cell>21.3</cell><cell>37.2</cell></row><row><cell>dev</cell><cell>FT-Transformer, Single</cell><cell>1.61</cell><cell>2.13</cell><cell cols="2">1.89 1.18</cell><cell>1.61</cell><cell cols="2">1.39 67.2</cell><cell>49.4</cell><cell cols="2">58.3 39.4</cell><cell>20.7</cell><cell>34.9</cell></row><row><cell></cell><cell>FT-Transformer, MCDP</cell><cell>1.59</cell><cell>2.09</cell><cell cols="2">1.84 1.16</cell><cell>1.58</cell><cell cols="2">1.37 67.2</cell><cell>50.0</cell><cell cols="2">58.6 39.3</cell><cell>21.4</cell><cell>34.9</cell></row><row><cell></cell><cell>FT-Transformer, Ensemble</cell><cell>1.50</cell><cell>2.01</cell><cell cols="2">1.77 1.10</cell><cell>1.52</cell><cell cols="2">1.31 68.8</cell><cell>51.5</cell><cell cols="2">60.2 40.5</cell><cell>21.6</cell><cell>36.0</cell></row><row><cell></cell><cell cols="2">CatBoost ? FT-Transformer 1.47</cell><cell>2.01</cell><cell cols="2">1.76 1.08</cell><cell>1.53</cell><cell cols="2">1.30 69.3</cell><cell>51.5</cell><cell cols="2">60.4 42.4</cell><cell>21.4</cell><cell>37.3</cell></row><row><cell></cell><cell>CatBoost, Single</cell><cell>1.60</cell><cell>2.60</cell><cell cols="2">2.16 1.19</cell><cell>1.91</cell><cell cols="2">1.56 66.7</cell><cell>44.5</cell><cell cols="2">55.5 42.9</cell><cell>21.5</cell><cell>34.4</cell></row><row><cell></cell><cell>CatBoost, Ensemble</cell><cell>1.52</cell><cell>2.37</cell><cell cols="2">2.00 1.11</cell><cell>1.75</cell><cell cols="2">1.44 68.2</cell><cell>46.7</cell><cell cols="2">57.3 44.1</cell><cell>22.2</cell><cell>35.5</cell></row><row><cell>eval</cell><cell>FT-Transformer, Single</cell><cell>1.62</cell><cell>2.40</cell><cell cols="2">2.05 1.18</cell><cell>1.77</cell><cell cols="2">1.48 67.0</cell><cell>45.9</cell><cell cols="2">56.3 37.6</cell><cell>23.0</cell><cell>31.4</cell></row><row><cell></cell><cell>FT-Transformer, MCDP</cell><cell>1.59</cell><cell>2.34</cell><cell cols="2">2.01 1.17</cell><cell>1.73</cell><cell cols="2">1.45 67.0</cell><cell>46.4</cell><cell cols="2">56.6 37.6</cell><cell>23.2</cell><cell>31.6</cell></row><row><cell></cell><cell>FT-Transformer, Ensemble</cell><cell>1.51</cell><cell>2.24</cell><cell cols="2">1.92 1.10</cell><cell>1.66</cell><cell cols="2">1.38 68.6</cell><cell>48.0</cell><cell cols="2">58.1 38.2</cell><cell>23.8</cell><cell>32.1</cell></row><row><cell></cell><cell cols="2">CatBoost ? FT-Transformer 1.48</cell><cell>2.25</cell><cell cols="2">1.91 1.08</cell><cell>1.66</cell><cell cols="2">1.38 69.0</cell><cell>48.0</cell><cell cols="2">58.4 44.2</cell><cell>22.3</cell><cell>35.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 :</head><label>10</label><figDesc>Retention performance for Weather prediction. Mean is quoted for the single models. F1-AUC (%) ? F1@95% ? R-AUC ? F1-AUC (%) ? F1@95% ?</figDesc><table><row><cell cols="2">Dataset Model</cell><cell></cell><cell>Regression</cell><cell></cell><cell></cell><cell>Classification</cell><cell></cell></row><row><cell cols="3">CatBoost, Single CatBoost, Ensemble R-AUC ? dev 1.894 1.227 FT-Transformer, Single 1.245</cell><cell>44.35 52.20 51.69</cell><cell>62.72 65.83 65.08</cell><cell>0.1666 0.1522 0.1592</cell><cell>57.72 59.07 58.51</cell><cell>73.04 74.86 73.80</cell></row><row><cell></cell><cell>FT-Transformer, MCDP</cell><cell>1.197</cell><cell>52.08</cell><cell>65.62</cell><cell>0.1565</cell><cell>58.80</cell><cell>74.16</cell></row><row><cell></cell><cell>FT-Transformer, Ensemble</cell><cell>1.051</cell><cell>53.66</cell><cell>67.56</cell><cell>0.1472</cell><cell>59.54</cell><cell>75.38</cell></row><row><cell></cell><cell>CatBoost ? FT-Transformer</cell><cell>1.035</cell><cell>54.04</cell><cell>67.47</cell><cell>0.1453</cell><cell>59.71</cell><cell>75.58</cell></row><row><cell></cell><cell>CatBoost, Single</cell><cell>2.320</cell><cell>43.41</cell><cell>61.89</cell><cell>0.1799</cell><cell>56.25</cell><cell>71.56</cell></row><row><cell></cell><cell>CatBoost, Ensemble</cell><cell>1.335</cell><cell>52.36</cell><cell>64.72</cell><cell>0.1640</cell><cell>58.22</cell><cell>73.17</cell></row><row><cell>eval</cell><cell>FT-Transformer, Single</cell><cell>1.386</cell><cell>51.86</cell><cell>63.96</cell><cell>0.1705</cell><cell>57.72</cell><cell>72.17</cell></row><row><cell></cell><cell>FT-Transformer, MCDP</cell><cell>1.321</cell><cell>52.29</cell><cell>64.57</cell><cell>0.1676</cell><cell>58.04</cell><cell>72.55</cell></row><row><cell></cell><cell>FT-Transformer, Ensemble</cell><cell>1.168</cell><cell>53.77</cell><cell>66.40</cell><cell>0.1576</cell><cell>58.95</cell><cell>73.84</cell></row><row><cell></cell><cell>CatBoost ? FT-Transformer</cell><cell>1.151</cell><cell>54.09</cell><cell>66.28</cell><cell>0.1561</cell><cell>59.07</cell><cell>74.02</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 :</head><label>11</label><figDesc>Comparing ensembled F1-AUC and ROC-AUC for various uncertainty measures on the tests sets from the canonical partitioning of Weather Prediction dataset for regression and classification.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Regression</cell><cell></cell><cell></cell><cell cols="3">Classification</cell></row><row><cell>Data Metric</cell><cell>Model</cell><cell cols="3">Total Unc. Knowledge Unc.</cell><cell cols="2">Total Unc.</cell><cell cols="2">Knowledge Unc.</cell></row><row><cell></cell><cell></cell><cell>tvar</cell><cell>varm</cell><cell>EPKL</cell><cell cols="2">Conf Entropy</cell><cell>MI</cell><cell>EPKL RMI</cell></row><row><cell></cell><cell>CatBoost</cell><cell>52.20</cell><cell>50.12</cell><cell>50.51</cell><cell>59.07</cell><cell>58.86</cell><cell cols="2">57.72 57.69 57.66</cell></row><row><cell>F1-AUC (%) ?</cell><cell>FT-Transformer</cell><cell>53.66</cell><cell>51.86</cell><cell>53.53</cell><cell>59.54</cell><cell>59.13</cell><cell cols="2">56.36 56.28 56.20</cell></row><row><cell>dev</cell><cell>CatBoost ? FT-Transformer</cell><cell>54.04</cell><cell>52.22</cell><cell>51.49</cell><cell>59.71</cell><cell>59.26</cell><cell cols="2">57.65 57.49 57.36</cell></row><row><cell></cell><cell>CatBoost</cell><cell>62.96</cell><cell>82.31</cell><cell>85.29</cell><cell>63.98</cell><cell>65.00</cell><cell cols="2">83.75 83.96 84.12</cell></row><row><cell>ROC-AUC (%) ?</cell><cell>FT-Transformer</cell><cell>58.10</cell><cell>65.89</cell><cell>61.63</cell><cell>35.46</cell><cell>65.48</cell><cell cols="2">71.89 71.85 71.79</cell></row><row><cell></cell><cell>CatBoost ? FT-Transformer</cell><cell>62.73</cell><cell>76.63</cell><cell>83.29</cell><cell>34.63</cell><cell>66.10</cell><cell cols="2">80.46 80.10 79.78</cell></row><row><cell></cell><cell>CatBoost</cell><cell>52.36</cell><cell>49.81</cell><cell>50.40</cell><cell>58.22</cell><cell>57.89</cell><cell cols="2">56.99 56.96 56.93</cell></row><row><cell>F1-AUC (%) ?</cell><cell>FT-Transformer</cell><cell>53.77</cell><cell>51.83</cell><cell>53.58</cell><cell>58.95</cell><cell>58.55</cell><cell cols="2">55.68 55.59 55.51</cell></row><row><cell>eval</cell><cell>CatBoost ? FT-Transformer</cell><cell>54.09</cell><cell>52.12</cell><cell>51.44</cell><cell>59.07</cell><cell>58.62</cell><cell cols="2">56.92 56.75 56.59</cell></row><row><cell></cell><cell>CatBoost</cell><cell>65.99</cell><cell>78.32</cell><cell>79.90</cell><cell>66.20</cell><cell>66.76</cell><cell cols="2">83.44 83.59 83.68</cell></row><row><cell>ROC-AUC (%) ?</cell><cell>FT-Transformer</cell><cell>65.03</cell><cell>68.78</cell><cell>67.67</cell><cell>30.68</cell><cell>70.37</cell><cell cols="2">76.46 76.43 76.36</cell></row><row><cell></cell><cell>CatBoost ? FT-Transformer</cell><cell>67.78</cell><cell>75.43</cell><cell>79.29</cell><cell>30.86</cell><cell>69.92</cell><cell cols="2">82.49 82.16 81.85</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 12 :</head><label>12</label><figDesc>Description of additional experiments.</figDesc><table><row><cell cols="2">Exp Training set</cell><cell>Development set</cell><cell>Description</cell></row><row><cell>A</cell><cell>train</cell><cell>dev_in</cell><cell>Time &amp; climate shifts</cell></row><row><cell>B</cell><cell>train ? train_xclim</cell><cell>dev_in ? dev_xclim</cell><cell>Time shift</cell></row><row><cell>C</cell><cell>train ? train_xtime</cell><cell>dev_in ? dev_xtime</cell><cell>Climate shift</cell></row><row><cell>D</cell><cell cols="3">train ? train_xclim ? train_xtime dev_in ? dev_xclim ? dev_xtime No shift</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 13 :</head><label>13</label><figDesc>Predictive performance for Weather prediction using different training sets. Mean is quoted for the single models.</figDesc><table><row><cell>Dataset</cell><cell>Model</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>CatBoost, Single 1.59 1.62 1.61 1.63 1.18 1.21 1.20 1.21 67.0 66.1 66.6 65.8 42.2 39.6 42.6 39.9 CatBoost, Ensemble 1.51 1.52 1.51 1.54 1.11 1.12 1.11 1.14 68.5 67.2 67.7 66.8 42.3 40.1 41.9 39.9 dev_out CatBoost, Single 2.30 2.30 2.04 1.95 1.75 1.75 1.54 1.48 47.5 50.9 51.8 54.0 20.2 21.2 21.4 22.7 CatBoost, Ensemble 2.12 2.05 1.93 1.85 1.61 1.55 1.45 1.40 50.3 53.4 53.0 55.4 21.3 22.2 21.8 22.9 eval_in CatBoost, Single 1.60 1.63 1.62 1.64 1.19 1.21 1.20 1.22 66.7 65.9 66.3 65.7 42.9 40.4 42.7 40.3 CatBoost, Ensemble 1.52 1.53 1.52 1.55 1.11 1.12 1.12 1.14 68.2 67.1 67.6 66.7 44.1 42.0 43.8 41.3 eval_out CatBoost, Single 2.60 2.62 2.28 2.15 1.91 1.93 1.69 1.62 44.5 48.3 48.6 51.5 21.5 23.8 23.5 25.6 CatBoost, Ensemble 2.37 2.26 2.16 2.04 1.75 1.69 1.60 1.53 46.7 50.4 50.2 53.0 22.2 24.1 24.1 26.0</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 14 :</head><label>14</label><figDesc>NMT Data Description -All Data is English-Russian</figDesc><table><row><cell>Data Set</cell><cell>N. Sentences</cell><cell cols="3">Avg. Sentence Length Type En Ru</cell></row><row><cell>WMT'20</cell><cell>62M</cell><cell>23,9</cell><cell>20.9</cell><cell>Train</cell></row><row><cell>NWT'19</cell><cell>1997</cell><cell>24.5</cell><cell>24.7</cell><cell>In-domain Dev</cell></row><row><cell>GlobalVoices</cell><cell>3,000</cell><cell>25.1</cell><cell>24.1</cell><cell>In-domain Eval</cell></row><row><cell>WMT'19 MTNT Reddit</cell><cell>1,362</cell><cell>17.2</cell><cell>16.5</cell><cell>Shifted Dev</cell></row><row><cell>Shifts Reddit</cell><cell>3,063</cell><cell>16.1</cell><cell>16.4</cell><cell>Shifted Eval</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 15 :</head><label>15</label><figDesc>A comparison of various motion prediction datasets. The Shifts Vehicle Motion Prediction dataset is the largest by number of scenes and total size in hours.</figDesc><table><row><cell>Dataset</cell><cell>Scene Length (s)</cell><cell>Train</cell><cell># Scenes Dev</cell><cell>Eval</cell><cell cols="2">Total Size (h) Avg. # Actors</cell></row><row><cell>Argoverse</cell><cell>5</cell><cell cols="3">205,942 39,472 78,143</cell><cell>320</cell><cell>50</cell></row><row><cell>Lyft</cell><cell>25</cell><cell cols="3">134,000 11,000 16,000</cell><cell>1,118</cell><cell>79</cell></row><row><cell>Waymo</cell><cell>20</cell><cell>72,347</cell><cell cols="2">15,503 15,503</cell><cell>574</cell><cell>-</cell></row><row><cell>Shifts</cell><cell>10</cell><cell cols="3">500,000 50,000 50,000</cell><cell>1,667</cell><cell>29</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 16 :</head><label>16</label><figDesc>The number of scenes in the Vehicle Motion Prediction dataset by location and season.</figDesc><table><row><cell>Location</cell><cell>Train</cell><cell>Dev</cell><cell>Eval</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Moscow</cell><cell cols="3">450,504 30,505 30,534</cell><cell>Season</cell><cell>Train</cell><cell>Dev</cell><cell>Eval</cell></row><row><cell>Skolkovo</cell><cell>6,283</cell><cell>2,218</cell><cell>2,956</cell><cell>Summer</cell><cell>85,698</cell><cell cols="2">10,634 10,481</cell></row><row><cell>Innopolis</cell><cell>15,086</cell><cell>5,164</cell><cell>5,016</cell><cell cols="4">Autumn 126,845 15,290 15,840</cell></row><row><cell>Ann Arbor</cell><cell>19,349</cell><cell>8,290</cell><cell>6,617</cell><cell>Winter</cell><cell cols="3">287,457 24,076 23,679</cell></row><row><cell>Modiin</cell><cell>3,502</cell><cell>2,262</cell><cell>1,555</cell><cell>Spring</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Tel Aviv</cell><cell>5,276</cell><cell>1,561</cell><cell>3,322</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 17 :</head><label>17</label><figDesc>The number of scenes in the Vehicle Motion Prediction dataset by precipitation and time of day.</figDesc><table><row><cell>Precipitation Type</cell><cell>Train</cell><cell>Dev</cell><cell>Eval</cell><cell>Sun Phase</cell><cell>Train</cell><cell>Dev</cell><cell>Eval</cell></row><row><cell>No Rain Sleet Snow</cell><cell cols="3">432,598 44,799 44,274 15,618 1,857 1,751 15,210 1,082 990 36,574 2,262 2,985</cell><cell cols="4">Astronomical Night 171,867 13,164 13,113 Daylight 299,065 33,879 33,979 Twilight 29,068 2,957 2,908</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 18 :</head><label>18</label><figDesc>Number of actor maneuvers of the respective type.</figDesc><table><row><cell>Maneuver Type</cell><cell>Train</cell><cell>Dev</cell><cell>Eval</cell></row><row><cell>Move Left</cell><cell>254,843</cell><cell>25,049</cell><cell>25,820</cell></row><row><cell>Move Right</cell><cell>322,231</cell><cell>30,074</cell><cell>30,633</cell></row><row><cell>Move Forward</cell><cell cols="3">5,032,724 395,467 413,920</cell></row><row><cell>Move Back</cell><cell>54,677</cell><cell>4,811</cell><cell>4,891</cell></row><row><cell>Acceleration</cell><cell cols="3">2,473,750 206,977 215,009</cell></row><row><cell>Deceleration</cell><cell cols="3">2,050,186 168,550 174,477</cell></row><row><cell cols="4">Uniform Movement 6,369,920 566,083 573,033</cell></row><row><cell>Stopping</cell><cell>441,619</cell><cell>38,411</cell><cell>39,336</cell></row><row><cell>Starting</cell><cell>739,143</cell><cell>64,986</cell><cell>65,759</cell></row><row><cell>Stationary</cell><cell cols="3">4,620,678 433,161 433,576</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 19 :</head><label>19</label><figDesc>The number of scenes in the canonical dataset partitioning.</figDesc><table><row><cell cols="3">Dataset Partition In-Distribution Distributionally Shifted</cell></row><row><cell>Train</cell><cell>388,406</cell><cell>-</cell></row><row><cell>Development</cell><cell>27,036</cell><cell>9,569</cell></row><row><cell>Evaluation</cell><cell>26,865</cell><cell>9,939</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 21 :</head><label>21</label><figDesc>Uncertainty and robustness performance of RIP across the two backbone models (BC and DIM) and uncertainty estimation methods (Deep Ensemble and Dropout Ensemble). The error metric for computing the area under the rejection curve (R-AUC) and area under the F1 curve (F1-AUC) is cNLL. We use a threshold of 25 for the F1 metrics, which approximately corresponds to a 1 meter deviation on all trajectories. See Appendix E.4 for setup details.</figDesc><table><row><cell>Dataset Method</cell><cell>Model</cell><cell>In</cell><cell>R-AUC ? Shifted</cell><cell>Full</cell><cell>In</cell><cell cols="3">F1-AUC (%) ? Shifted Full</cell><cell>In</cell><cell>F1@95% ? Shifted Full</cell><cell>ROC-AUC (%) ?</cell></row><row><cell></cell><cell>BC, LQ, K=1</cell><cell>11.06</cell><cell>13.91</cell><cell cols="3">11.22 64.9</cell><cell>66.7</cell><cell cols="2">65.1 89.1</cell><cell>90.2</cell><cell>89.3</cell><cell>51.0</cell></row><row><cell></cell><cell>BC, LQ, K=3</cell><cell>11.26</cell><cell>11.69</cell><cell cols="3">11.18 63.4</cell><cell>66.0</cell><cell cols="2">63.8 88.5</cell><cell>90.3</cell><cell>88.8</cell><cell>46.7</cell></row><row><cell></cell><cell>BC, LQ, K=5</cell><cell>9.68</cell><cell>10.38</cell><cell cols="3">9.62 64.3</cell><cell>66.4</cell><cell cols="2">64.6 89.7</cell><cell>91.0</cell><cell>90.0</cell><cell>47.3</cell></row><row><cell></cell><cell>BC, MA, K=1</cell><cell>11.06</cell><cell>13.91</cell><cell cols="3">11.22 64.9</cell><cell>66.7</cell><cell cols="2">65.1 89.1</cell><cell>90.2</cell><cell>89.3</cell><cell>51.0</cell></row><row><cell></cell><cell>BC, MA, K=3</cell><cell>9.31</cell><cell>10.73</cell><cell cols="3">9.31 64.8</cell><cell>66.5</cell><cell cols="2">65.0 90.3</cell><cell>91.3</cell><cell>90.6</cell><cell>48.6</cell></row><row><cell>Deep</cell><cell>BC, MA, K=5</cell><cell>9.07</cell><cell>10.47</cell><cell cols="3">9.08 64.9</cell><cell>66.5</cell><cell cols="2">65.2 90.4</cell><cell>91.3</cell><cell>90.6</cell><cell>49.2</cell></row><row><cell>Ensemble</cell><cell>DIM, LQ, K=1</cell><cell>12.54</cell><cell>15.28</cell><cell cols="3">12.86 63.6</cell><cell>64.8</cell><cell cols="2">63.8 87.2</cell><cell>88.8</cell><cell>87.4</cell><cell>51.8</cell></row><row><cell></cell><cell>DIM, LQ, K=3</cell><cell>12.30</cell><cell>14.51</cell><cell cols="3">12.57 63.7</cell><cell>64.9</cell><cell cols="2">63.8 89.3</cell><cell>89.9</cell><cell>89.3</cell><cell>51.4</cell></row><row><cell></cell><cell>DIM, LQ, K=5</cell><cell>12.87</cell><cell>15.01</cell><cell cols="3">13.14 63.5</cell><cell>64.8</cell><cell cols="2">63.7 89.7</cell><cell>90.2</cell><cell>89.7</cell><cell>51.4</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=1 12.57</cell><cell>15.10</cell><cell cols="3">12.86 63.7</cell><cell>64.9</cell><cell cols="2">63.8 87.2</cell><cell>88.8</cell><cell>87.4</cell><cell>51.8</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=3 12.38</cell><cell>14.46</cell><cell cols="3">12.64 63.7</cell><cell>64.9</cell><cell cols="2">63.8 89.2</cell><cell>89.9</cell><cell>89.3</cell><cell>51.4</cell></row><row><cell>Dev</cell><cell cols="2">DIM, MA, K=5 12.97</cell><cell>15.10</cell><cell cols="3">13.24 63.5</cell><cell>64.8</cell><cell cols="2">63.7 89.6</cell><cell>90.2</cell><cell>89.7</cell><cell>51.4</cell></row><row><cell></cell><cell>BC, LQ, K=1</cell><cell>8.87</cell><cell>10.00</cell><cell cols="3">8.87 65.3</cell><cell>67.1</cell><cell cols="2">65.6 89.7</cell><cell>90.4</cell><cell>89.9</cell><cell>51.2</cell></row><row><cell></cell><cell>BC, LQ, K=3</cell><cell>8.11</cell><cell>9.53</cell><cell cols="3">8.14 64.9</cell><cell>66.5</cell><cell cols="2">65.1 90.6</cell><cell>91.3</cell><cell>90.8</cell><cell>50.9</cell></row><row><cell></cell><cell>BC, LQ, K=5</cell><cell>8.28</cell><cell>9.60</cell><cell cols="3">8.28 65.0</cell><cell>66.6</cell><cell cols="2">65.2 90.5</cell><cell>91.3</cell><cell>90.7</cell><cell>50.7</cell></row><row><cell></cell><cell>BC, MA, K=1</cell><cell>8.87</cell><cell>9.99</cell><cell cols="3">8.87 65.3</cell><cell>67.1</cell><cell cols="2">65.6 89.7</cell><cell>90.4</cell><cell>89.9</cell><cell>51.2</cell></row><row><cell></cell><cell>BC, MA, K=3</cell><cell>8.53</cell><cell>9.79</cell><cell cols="3">8.54 64.9</cell><cell>66.5</cell><cell cols="2">65.1 90.7</cell><cell>91.4</cell><cell>90.8</cell><cell>50.3</cell></row><row><cell>Dropout</cell><cell>BC, MA, K=5</cell><cell>8.89</cell><cell>10.23</cell><cell cols="3">8.90 64.9</cell><cell>66.5</cell><cell cols="2">65.2 90.5</cell><cell>91.4</cell><cell>90.7</cell><cell>50.2</cell></row><row><cell>Ensemble</cell><cell>DIM, LQ, K=1</cell><cell>12.57</cell><cell>16.41</cell><cell cols="3">13.03 63.8</cell><cell>64.7</cell><cell cols="2">63.9 87.6</cell><cell>89.1</cell><cell>87.8</cell><cell>51.5</cell></row><row><cell></cell><cell>DIM, LQ, K=3</cell><cell>12.37</cell><cell>14.91</cell><cell cols="3">12.69 63.7</cell><cell>64.8</cell><cell cols="2">63.8 89.2</cell><cell>90.0</cell><cell>89.3</cell><cell>51.3</cell></row><row><cell></cell><cell>DIM, LQ, K=5</cell><cell>12.94</cell><cell>15.18</cell><cell cols="3">13.22 63.6</cell><cell>64.8</cell><cell cols="2">63.7 89.6</cell><cell>90.2</cell><cell>89.7</cell><cell>51.4</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=1 12.61</cell><cell>16.30</cell><cell cols="3">13.06 63.8</cell><cell>64.8</cell><cell cols="2">63.9 87.6</cell><cell>89.1</cell><cell>87.7</cell><cell>51.6</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=3 12.49</cell><cell>14.80</cell><cell cols="3">12.79 63.6</cell><cell>64.8</cell><cell cols="2">63.8 89.2</cell><cell>90.0</cell><cell>89.3</cell><cell>51.4</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=5 13.05</cell><cell>15.20</cell><cell cols="3">13.33 63.5</cell><cell>64.8</cell><cell cols="2">63.7 89.5</cell><cell>90.2</cell><cell>89.6</cell><cell>51.4</cell></row><row><cell></cell><cell>BC, LQ, K=1</cell><cell>11.16</cell><cell>20.84</cell><cell cols="3">12.91 64.9</cell><cell>65.5</cell><cell cols="2">65.0 88.9</cell><cell>85.6</cell><cell>88.4</cell><cell>52.8</cell></row><row><cell></cell><cell>BC, LQ, K=3</cell><cell>11.31</cell><cell>17.09</cell><cell cols="3">12.38 63.4</cell><cell>64.8</cell><cell cols="2">63.7 88.4</cell><cell>86.4</cell><cell>88.0</cell><cell>50.9</cell></row><row><cell></cell><cell>BC, LQ, K=5</cell><cell>9.77</cell><cell>15.95</cell><cell cols="3">10.88 64.3</cell><cell>65.4</cell><cell cols="2">64.5 89.5</cell><cell>87.1</cell><cell>89.1</cell><cell>51.4</cell></row><row><cell></cell><cell>BC, MA, K=1</cell><cell>11.17</cell><cell>20.84</cell><cell cols="3">12.91 64.9</cell><cell>65.5</cell><cell cols="2">65.0 88.9</cell><cell>85.6</cell><cell>88.4</cell><cell>52.8</cell></row><row><cell></cell><cell>BC, MA, K=3</cell><cell>9.40</cell><cell>16.76</cell><cell cols="3">10.73 64.8</cell><cell>65.6</cell><cell cols="2">65.0 90.2</cell><cell>87.5</cell><cell>89.7</cell><cell>51.3</cell></row><row><cell>Deep</cell><cell>BC, MA, K=5</cell><cell>9.20</cell><cell>16.85</cell><cell cols="3">10.57 65.0</cell><cell>65.6</cell><cell cols="2">65.1 90.2</cell><cell>87.5</cell><cell>89.7</cell><cell>52.1</cell></row><row><cell>Ensemble</cell><cell>DIM, LQ, K=1</cell><cell>12.78</cell><cell>20.78</cell><cell cols="3">14.28 63.5</cell><cell>63.7</cell><cell cols="2">63.6 86.9</cell><cell>83.9</cell><cell>86.3</cell><cell>52.0</cell></row><row><cell></cell><cell>DIM, LQ, K=3</cell><cell>12.66</cell><cell>21.40</cell><cell cols="3">14.32 63.6</cell><cell>63.9</cell><cell cols="2">63.7 89.1</cell><cell>86.0</cell><cell>88.5</cell><cell>51.4</cell></row><row><cell></cell><cell>DIM, LQ, K=5</cell><cell>13.26</cell><cell>22.59</cell><cell cols="3">15.05 63.5</cell><cell>63.8</cell><cell cols="2">63.6 89.5</cell><cell>86.5</cell><cell>88.9</cell><cell>51.2</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=1 12.81</cell><cell>20.83</cell><cell cols="3">14.32 63.6</cell><cell>63.8</cell><cell cols="2">63.6 86.9</cell><cell>83.9</cell><cell>86.3</cell><cell>51.8</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=3 12.74</cell><cell>21.51</cell><cell cols="3">14.42 63.6</cell><cell>63.9</cell><cell cols="2">63.7 89.1</cell><cell>86.0</cell><cell>88.5</cell><cell>51.1</cell></row><row><cell>Eval</cell><cell cols="2">DIM, MA, K=5 13.37</cell><cell>22.68</cell><cell cols="3">15.16 63.5</cell><cell>63.7</cell><cell cols="2">63.5 89.5</cell><cell>86.5</cell><cell>88.9</cell><cell>50.9</cell></row><row><cell></cell><cell>BC, LQ, K=1</cell><cell>9.06</cell><cell>15.49</cell><cell cols="3">10.22 65.3</cell><cell>66.1</cell><cell cols="2">65.5 89.5</cell><cell>86.4</cell><cell>89.0</cell><cell>53.7</cell></row><row><cell></cell><cell>BC, LQ, K=3</cell><cell>8.22</cell><cell>14.83</cell><cell cols="3">9.39 64.9</cell><cell>65.6</cell><cell cols="2">65.1 90.5</cell><cell>87.5</cell><cell>90.0</cell><cell>53.9</cell></row><row><cell></cell><cell>BC, LQ, K=5</cell><cell>8.39</cell><cell>15.16</cell><cell cols="3">9.57 65.0</cell><cell>65.7</cell><cell cols="2">65.2 90.4</cell><cell>87.6</cell><cell>89.9</cell><cell>54.5</cell></row><row><cell></cell><cell>BC, MA, K=1</cell><cell>9.07</cell><cell>15.50</cell><cell cols="3">10.22 65.3</cell><cell>66.1</cell><cell cols="2">65.5 89.5</cell><cell>86.4</cell><cell>89.0</cell><cell>53.7</cell></row><row><cell></cell><cell>BC, MA, K=3</cell><cell>8.69</cell><cell>15.90</cell><cell cols="3">9.99 64.9</cell><cell>65.6</cell><cell cols="2">65.1 90.5</cell><cell>87.7</cell><cell>90.0</cell><cell>53.0</cell></row><row><cell>Dropout</cell><cell>BC, MA, K=5</cell><cell>9.05</cell><cell>16.69</cell><cell cols="3">10.41 65.0</cell><cell>65.6</cell><cell cols="2">65.1 90.4</cell><cell>87.6</cell><cell>89.9</cell><cell>53.2</cell></row><row><cell>Ensemble</cell><cell>DIM, LQ, K=1</cell><cell>12.45</cell><cell>20.27</cell><cell cols="3">13.92 63.6</cell><cell>63.7</cell><cell cols="2">63.6 87.7</cell><cell>84.7</cell><cell>87.1</cell><cell>51.8</cell></row><row><cell></cell><cell>DIM, LQ, K=3</cell><cell>12.63</cell><cell>21.32</cell><cell cols="3">14.29 63.7</cell><cell>63.9</cell><cell cols="2">63.7 89.1</cell><cell>86.1</cell><cell>88.6</cell><cell>51.3</cell></row><row><cell></cell><cell>DIM, LQ, K=5</cell><cell>13.22</cell><cell>22.78</cell><cell cols="3">15.04 63.5</cell><cell>63.8</cell><cell cols="2">63.6 89.4</cell><cell>86.3</cell><cell>88.8</cell><cell>51.2</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=1 12.51</cell><cell>20.33</cell><cell cols="3">14.00 63.6</cell><cell>63.8</cell><cell cols="2">63.7 87.7</cell><cell>84.7</cell><cell>87.1</cell><cell>51.5</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=3 12.73</cell><cell>21.43</cell><cell cols="3">14.40 63.6</cell><cell>63.9</cell><cell cols="2">63.7 89.1</cell><cell>86.0</cell><cell>88.5</cell><cell>51.1</cell></row><row><cell></cell><cell cols="2">DIM, MA, K=5 13.36</cell><cell>22.85</cell><cell cols="3">15.19 63.5</cell><cell>63.8</cell><cell cols="2">63.6 89.4</cell><cell>86.3</cell><cell>88.8</cell><cell>50.9</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">ImageNet has only "natural" images; thus, renderings represent a shift in texture, but not content.<ref type="bibr" target="#b1">2</ref> Data and example code are available at https://github.com/yandex-research/shifts</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Tools for partitioning and repartitioning are provided in our GitHub repository.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Alternative partitionings can be made from the full data, but we use the canonical partitioning throughout this work, and also for the Shifts Challenge: http://research.yandex.com/shifts</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">A case of knowledge, or epistemic uncertainty<ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>.<ref type="bibr" target="#b5">6</ref> A case of data, or aleatoric uncertainty.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">This partitioning is also the one used in the Shifts Challenge: http://research.yandex.com/shifts</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">research.yandex.com/shifts 9 https://github.com/yandex-research/shifts</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/ global-forcast-system-gfs 11 https://weather.gc.ca/grib/grib2_glb_25km_e.html 12 https://www.mmm.ucar.edu/weather-research-and-forecasting-model</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">Available to download from http://hanschen.org/koppen 14 Alternative partitioning can be made from the full data, but we will use the canonical partition throughout this work.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">(a) CatBoost, Regression, MSE.(b) CatBoost, Regression, F1.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">In practice, each ensemble member generates the same number of trajectories Q, s.t. G = K ? Q.<ref type="bibr" target="#b15">16</ref> For example, applying a min aggregation is informed by robust control literature<ref type="bibr" target="#b79">[80]</ref> in which we aim to optimize for the worst-case scenario, as measured by the log-likelihood of the "most pessimistic" model for a given trajectory.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17">In practice, this is done by applying the aggregation (e.g., ?pred-req = mean) to the confidences c (d) , and then negating to obtain the uncertainty score U .</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments and Disclosure of Funding</head><p>We would like to thank Yandex for providing the data and resources necessary in benchmark creation. We thank Intel and the Turing Institute for funding the work of the OATML Group on this project. Finally, we thank Cambridge University Press and Cambridge Assessment for funding the work of the CUED Speech Group.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Linguistic Regularities in Continuous Space Word Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Recurrent Neural Network Based Language Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafi?t</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luk?s</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Cernock?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdel</forename><surname>Rahman Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing Magazine</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joaquin</forename><surname>Qui?onero-Candela</surname></persName>
		</author>
		<title level="m">Dataset Shift in Machine Learning</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Wilds: A benchmark of in-the-wild distribution shifts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Marklund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang</forename><forename type="middle">Michael</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Balsubramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>Richard Lanas Phillips, Sara Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn,</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Uncertainty baselines: Benchmarks for uncertainty &amp; robustness in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Nado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Band</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Collier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josip</forename><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Dusenberry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelos</forename><surname>Filos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marton</forename><surname>Havasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodolphe</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghassen</forename><surname>Jerfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremiah</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zelda</forename><surname>Mariet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Nixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreyas</forename><surname>Padhy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Tim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeming</forename><surname>Rudner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Wenzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tran</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Concrete problems in AI safety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">F</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Man?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06565</idno>
		<ptr target="http://arxiv.org/abs/1606.06565" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<title level="m">Yarin Gal, Uncertainty in Deep Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
		<respStmt>
			<orgName>University of Cambridge</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Uncertainty Estimation in Deep Learning with application to Spoken Language Assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Malinin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
		<respStmt>
			<orgName>University of Cambridge</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 33rd International Conference on Machine Learning (ICML-16)</title>
		<meeting>33rd International Conference on Machine Learning (ICML-16)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Neural Information Processing Systems (NIPS)</title>
		<meeting>Conference on Neural Information essing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Pitfalls of indomain uncertainty estimation and ensembling in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arsenii</forename><surname>Ashukha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Lyzhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Vetrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Can you trust your model&apos;s uncertainty? evaluating predictive uncertainty under dataset shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Ovadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Fertig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Nado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">V</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Adversarial examples are not easily detected: Bypassing ten detection methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Wagner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Understanding Measures of Uncertainty for Adversarial Example Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Batchbald: Efficient and diverse batch acquisition for deep bayesian active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kirsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van Amersfoort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="7026" to="7037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wat heb je gezegd? detecting out-of-distribution translations with variational transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bayesian Deep Learning Workshop (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Principled uncertainty estimation for high dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Notin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jos?</forename><surname>Miguel Hern?ndez-Lobato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty &amp; Robustness in Deep Learning Workshop, ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Unsupervised quality estimation for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marina</forename><surname>Fomicheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Yankovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Blain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzm?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Fishel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.10608</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Wat heb je gezegd? detecting out-of-distribution translations with variational transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Uncertainty estimation in autoregressive structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Malinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Gales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Enhancing the reliability of out-of-distribution image detection in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Generalized odin: Detecting out-of-distribution image without learning from out-of-distribution data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chang</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Uncertainty estimation using a single deep deterministic neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van Amersfoort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewis</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. PMLR, 2020</title>
		<imprint>
			<biblScope unit="page" from="9690" to="9700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Training independent subnetworks for robust prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marton</forename><surname>Havasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodolphe</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislav</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremiah</forename><forename type="middle">Zhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Tran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Simple and principled uncertainty estimation with deterministic deep learning via distance awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremiah</forename><forename type="middle">Zhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreyas</forename><surname>Padhy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tania</forename><surname>Bedrax-Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10108</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Improving deterministic uncertainty estimation in deep learning for classification and regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewis</forename><surname>Joost Van Amersfoort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Jesson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Key</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.11409</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Deterministic neural networks with appropriate inductive biases capture epistemic and aleatoric uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jishnu</forename><surname>Mukhoti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kirsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van Amersfoort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.11582</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Predictive uncertainty estimation via prior networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Malinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Gales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7047" to="7058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Reverse kl-divergence training of prior networks: Improved uncertainty and adversarial robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Malinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Malinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Chervontsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Provilkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Gales</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Regression prior networks,&quot; 2020</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Ensemble distribution distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Malinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Mlodozeniec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Scaling ensemble distribution distillation to many classes with proxy targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Ryabinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Malinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Gales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.06987</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A systematic comparison of bayesian deep learning robustness in diabetic retinopathy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelos</forename><surname>Filos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><forename type="middle">G J</forename><surname>Rudner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Kenton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewis</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Milad Alizadeh, Arnoud de Kroon, and Yarin Gal</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Benchmarking bayesian deep learning on diabetic retinopathy detection tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Band</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Tim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixuan</forename><surname>Rudner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelos</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Filos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Nado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghassen</forename><surname>Dusenberry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Jerfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">The many faces of robustness: A critical analysis of out-of-distribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Dorundo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samyak</forename><surname>Parajuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Natural adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">MTNT: A testbed for Machine Translation of Noisy Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brenden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Multidigit number recognition from street view imagery using deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Bulatov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Ibarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sacha</forename><surname>Arnoud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinay</forename><forename type="middle">D</forename><surname>Shet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6082</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Invariant risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A survey on concept drift adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><surname>Gama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Indr?</forename><surname>?liobait?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Bifet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykola</forename><surname>Pechenizkiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelhamid</forename><surname>Bouchachia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM computing surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The problem of concept drift: definitions and related work</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Tsymbal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science Department, Trinity College Dublin</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">58</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Catboost: unbiased boosting with categorical features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liudmila</forename><surname>Prokhorenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gleb</forename><surname>Gusev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><surname>Vorobev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><forename type="middle">Veronika</forename><surname>Dorogush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Gulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems (NeurIPS)</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6638" to="6648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Uncertainty in gradient boosting via ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Malinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liudmila</forename><surname>Prokhorenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksei</forename><surname>Ustimenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Improving backtranslation with uncertainty-based confidence estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.00157</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Globalvoices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Globalvoices</surname></persName>
		</author>
		<ptr target="https://globalvoices.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A call for clarity in reporting BLEU scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Research Papers</title>
		<meeting>the Third Conference on Machine Translation: Research Papers<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10" />
			<biblScope unit="page" from="186" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Ground truth for grammatical error correction metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="588" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">GLEU without tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.02592</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>cs.CL</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">fairseq: A fast, extensible toolkit for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2019: Demonstrations</title>
		<meeting>NAACL-HLT 2019: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Social lstm: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kratarth</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="961" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namhoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="336" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Multipath: Multiple probabilistic anchor trajectory hypotheses for behavior prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.05449</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Spatially-aware graph neural networks for relational behavior forecasting from sensor data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cole</forename><surname>Gulino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.08233</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Multimodal trajectory predictions for autonomous driving using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henggang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladan</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang-Chieh</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Han</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thi</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tzu-Kuo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nemanja</forename><surname>Djuric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2090" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Covernet: Multimodal behavior prediction using trajectory sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tung</forename><surname>Phan-Minh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><forename type="middle">Corina</forename><surname>Grigore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Freddy</forename><forename type="middle">A</forename><surname>Boulton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Beijbom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">M</forename><surname>Wolff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14074" to="14083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Vectornet: Encoding hd maps and agent dynamics from vectorized representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congcong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11525" to="11533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Prank: motion prediction based on ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuriy</forename><surname>Biktairov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Stebelev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Rudenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleh</forename><surname>Shliazhko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Yangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2553" to="2563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Implicit latent variable model for scene-consistent motion forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cole</forename><surname>Gulino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="624" to="641" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XXIII 16</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Learning lane graph representations for motion forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="541" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Multimodal motion prediction with stacked transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinghuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinhong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7577" to="7586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Can autonomous vehicles identify, recover from, and adapt to distribution shifts?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelos</forename><surname>Filos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panagiotis</forename><surname>Tigkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. PMLR, 2020</title>
		<imprint>
			<biblScope unit="page" from="3145" to="3153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">End-to-end driving via conditional imitation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felipe</forename><surname>Codevilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4693" to="4700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Deep imitative models for flexible inference, planning, and control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno>abs/1810.06544</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Understanding measures of uncertainty for adversarial example detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewis</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Datasheets for datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timnit</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Briana</forename><surname>Vecchione</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanna</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daum?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Crawford</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.09010</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Using the k?ppen classification to quantify climate variation and change: An example for 1901-2010</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans Weiteng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Environmental Development</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="69" to="79" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Revisiting deep learning models for tabular data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yury</forename><surname>Gorishniy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Rubachev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Khrulkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Babenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.11959</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Wald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contributions to the Theory of Statistical Estimation and Testing Hypotheses</title>
		<imprint>
			<date type="published" when="1939" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="299" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoderdecoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Deep ensembles: A loss landscape perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislav</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyi</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">climate_temperature -climate temperature, C 3. cmc_0_0_0_1000 -temperature at 1000 hPa isobaric level, K 4. cmc_0_0_0_2 -temperature at 2m, K 5. cmc_0_0_0_2_grad -difference between temperatures on adjacent horizons at 2m, K 6. cmc_0_0_0_2_interpolated -temperature at 2m interpolated between horizons, K 7. cmc_0_0_0_2_next -temperature at 2m for next horizon, K 8. cmc_0_0_0_500 -temperature at 500 hPa isobaric level, K 9. cmc_0_0_0_700 -temperature at 700 hPa isobaric level, K -cmc horizon, h 57. cmc_precipitations -avg precipitations rate between adjacent horizons, mm/h 58. cmc_timedelta_s -difference between cmc and forecast time, s 59. gfs_2m_dewpoint -dew point temperature at 2m, C 60. gfs_2m_dewpoint_grad -dew point temperature at 2m difference between horizons, C 61</title>
		<imprint/>
	</monogr>
	<note>fact_temperature -air temperature 2m above the ground, C 2. fact_cwsm_class -precipitation class Features 1. climate_pressure -climate pressure. gfs_2m_dewpoint_next -dew point temperature on next horizon, C 62. gfs_a_vorticity -absolute vorticity at height 1000 hPa, s-1</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">gfs_pressure -surface pressure, mmHg 71. gfs_r_velocity -vertical Velocity at 1000 hPa, Pa/s , C 73. gfs_soil_temperature_available -is there gfs soil temp data 74. gfs_temperature_10000 -temperature at vertical level at 100 hPa, C 75. gfs_temperature_15000 -temperature at vertical level at 150 hPa, C 76. gfs_temperature_20000 -temperature at vertical level at 200 hPa, C 77. gfs_temperature_25000 -temperature at vertical level at 250 hPa, C 78. gfs_temperature_30000 -temperature at vertical level at 300 hPa, C 79. gfs_temperature_35000 -temperature at vertical level at 350 hPa, C 80. gfs_temperature_40000 -temperature at vertical level at 400 hPa, C 81. gfs_temperature_45000 -temperature at vertical level at 450 hPa, C 82. gfs_temperature_5000 -temperature at vertical level at 50 hPa, C 83. gfs_temperature_50000 -temperature at vertical level at 500 hPa, C 84. gfs_temperature_55000 -temperature at vertical level at 550 hPa, C 85. gfs_temperature_60000 -temperature at vertical level at 600 hPa, C 86. gfs_temperature_65000 -temperature at vertical level at 650 hPa, C 87. gfs_temperature_7000 -temperature at vertical level at 70 hPa, C 88. gfs_temperature_70000 -temperature at vertical level at 700 hPa, C 89. gfs_temperature_75000 -temperature at vertical level at 750 hPa, C 90. gfs_temperature_80000 -temperature at vertical level at 800 hPa, C 91. gfs_temperature_85000 -temperature at vertical level at 850 hPa, C 92. gfs_temperature_90000 -temperature at vertical level at 900 hPa, C 93</title>
	</analytic>
	<monogr>
		<title level="m">-Cloud mixing ratio at level 1000 hPa, kg/kg 0.0 66. gfs_horizon_h -gfs horizon, h 67. gfs_humidity -relative humidity at 2m, % 68. gfs_precipitable_water -total precipitable water, kg m ? 2 69. gfs_precipitations -avg precipitations rate between adjacent horizons, mm/h 70</title>
		<imprint/>
	</monogr>
	<note>gfs_temperature_92500 -temperature at vertical level at 925 hPa, C 94. gfs_temperature_95000 -temperature at vertical level at 950 hPa, C 95. gfs_temperature_97500 -temperature at vertical level at 975 hPa</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
