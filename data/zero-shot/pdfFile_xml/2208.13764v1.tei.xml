<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Temporal Label Smoothing for Early Prediction of Adverse Events</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Y?che</surname></persName>
							<email>hyeche@inf.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">ETH Z?rich</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliz?e</forename><surname>Pace</surname></persName>
							<email>alpace@inf.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">ETH Z?rich</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">ETH AI Center</orgName>
								<orgName type="institution">ETH Z?rich</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>R?tsch</surname></persName>
							<email>raetsch@inf.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">ETH Z?rich</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Kuznetsova</surname></persName>
							<email>mkuznetsova@inf.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">ETH Z?rich</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Temporal Label Smoothing for Early Prediction of Adverse Events</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Models that can predict adverse events ahead of time with low false-alarm rates are critical to the acceptance of decision support systems in the medical community. This challenging machine learning task remains typically treated as simple binary classification, with few bespoke methods proposed to leverage temporal dependency across samples. We propose Temporal Label Smoothing (TLS), a novel learning strategy that modulates smoothing strength as a function of proximity to the event of interest. This regularization technique reduces model confidence at the class boundary, where the signal is often noisy or uninformative, thus allowing training to focus on clinically informative data points away from this boundary region. From a theoretical perspective, we also show that our method can be framed as an extension of multi-horizon prediction, a learning heuristic proposed in other early prediction work. TLS empirically matches or outperforms considered competing methods on various early prediction benchmark tasks. In particular, our approach significantly improves performance on clinically-relevant metrics such as event recall at low false-alarm rates. * Equal contribution ? Co-supervised Preprint. Under review.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Laboratory tests Vital signs Early prediction of adverse events is key to safetycritical operations such as clinical care <ref type="bibr" target="#b0">[1]</ref> or environmental monitoring <ref type="bibr" target="#b1">[2]</ref>. In particular, adverse event prediction is highly relevant to clinical decisionmaking, as the deployment of in-patient risk stratification models can significantly improve patient outcomes and facilitate resource planning <ref type="bibr" target="#b0">[1]</ref>. For instance, the National Early Warning Score (NEWS), a simple rule-based model predicting acute deterioration in critical care units, has been demonstrated to reduce in-patient mortality <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>Deteriorating patient signals are often identified by mining large quantities of existing medical data and associated patient outcomes, which has sparked a growing interest in machine learning and medical literature. Applications of such adverse event prediction models include alarm systems for delirium <ref type="bibr" target="#b4">[5]</ref>, septic shock <ref type="bibr" target="#b5">[6]</ref>, as well as circulatory or kidney failure in the intensive care unit (ICU) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>Adverse event prediction remains a challenging modelling task requiring specific technical solutions. Recent years have seen the development of deep learning architectures for electronic health records (EHR), which help tackle the high dimensionality, irregular sampling, and informative missingness patterns in patient covariates <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b7">8]</ref>. Still, adverse clinical events are often noisy, infrequent, and, as illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, must be predicted with enough anticipation to allow for appropriate physician response -yet early prediction remains largely considered a simple binary classification task <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>As a result, current decision support models often suffer from high false positive prediction rates, with associated risks of alarm fatigue and thus limited physician engagement <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b0">1]</ref>. As highlighted in <ref type="figure" target="#fig_2">Figure 2a</ref>, the traditional cross-entropy objective results in highest error rates near the class boundary, corresponding to the prediction horizon before the event. Data in this boundary region dominates the loss but may not be clinically discriminative of patient deterioration patterns. Motivated by this observation, we propose Temporal Label Smoothing (TLS), a novel regularization strategy making label smoothing <ref type="bibr" target="#b12">[13]</ref> time-dependent to better match prediction uncertainty patterns over time. As visualized in <ref type="figure" target="#fig_2">Figure 2b</ref>, our method is designed to reduce model confidence with stronger smoothing at the class boundary, allowing training to focus on more clinically informative data points away from this noisily labelled region.</p><p>Contributions. The contributions of our work are threefold: (i) In Section 3.2, we introduce a novel label smoothing method 1 , which leverages the temporal structure of early prediction tasks to focus training and model confidence on areas with stronger predictive signal. (ii) In Section 5, we show that our approach improves prediction performance over previously proposed objectives, particularly for clinically relevant criteria. (iii) In Section 3.3, we bridge the gap between prior work on multi-horizon prediction (MHP) <ref type="bibr" target="#b7">[8]</ref> and label smoothing <ref type="bibr" target="#b12">[13]</ref> by showing the former is equivalent to a special case of TLS under reasonable assumptions that we verify empirically.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Recent years have seen the development of custom machine learning methods to predict expected patient evolution and support clinical decision-making <ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b6">7]</ref>. Amongst these, early prediction of adverse clinical events is a particularly complex task due to their typically rare occurrence and noisy label definition, which induces challenging, highly imbalanced datasets for model training <ref type="bibr" target="#b7">[8]</ref>.</p><p>As a result, prediction systems often suffer from high false-alarm rates with limited usefulness in the clinical context <ref type="bibr" target="#b0">[1]</ref>. Prior works on early event prediction have adopted various approaches to tackle Cross-entropy loss ? y=c log(?) Balanced cross-entropy loss <ref type="bibr" target="#b17">[18]</ref> ? y ? y=c log(?) Focal loss <ref type="bibr" target="#b19">[20]</ref> ? y (1 ??) ? ? y=c log(?) Label smoothing <ref type="bibr" target="#b12">[13]</ref> q LS (c|y) log(?) Multi-horizon prediction <ref type="bibr" target="#b7">[8]</ref> h y h log(? h ) Temporal label smoothing q T LS (c|y, t) log(?)</p><p>this issue, which we compare in <ref type="table" target="#tab_0">Table 1</ref> and formalize in Appendix A.3. We also discuss similarities and distinctions between our task and the framework of survival analysis <ref type="bibr" target="#b16">[17]</ref> in Appendix A.2.</p><p>Learning objectives for imbalanced datasets. Class imbalance is often addressed through loss reweighting techniques. Static class reweighting was used for sepsis or circulatory failure prediction <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b6">7]</ref> through a balanced cross-entropy, which assigns a higher weight to samples from the minority class <ref type="bibr" target="#b17">[18]</ref>. Still, performance improvements with this objective remain limited on highly imbalanced prediction tasks <ref type="bibr" target="#b18">[19]</ref>. In contrast, dynamic reweighting methods such as focal loss and extensions <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> induce a learning bias towards samples with high model uncertainty, typically harder to classify. This approach can improve the prediction of disease progression from imbalanced datasets <ref type="bibr" target="#b21">[22]</ref> but does not consider patterns of sample informativeness over time.</p><p>Multi-horizon prediction. In contrast, other early prediction models learn to leverage temporal trends in the data by outputting event predictions over several horizons <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref>. This training heuristic improves prediction performance on the horizon of interest but scales poorly with the number of output horizons. In Section 3.3, we highlight that TLS can induce a similar temporal bias in learning while overcoming scalability limitations.</p><p>Label smoothing. For greater generalization of models applied to heterogeneous real-world data, another well-known training strategy is to avoid model overconfidence through label smoothing <ref type="bibr" target="#b12">[13]</ref>. This regularization technique improves both the calibration of deep learning models <ref type="bibr" target="#b24">[25]</ref> and their performance under noisy labelling <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b24">25]</ref>. Still, despite extensions including novel prior distributions over classes <ref type="bibr" target="#b26">[27]</ref> or modifications to the objective itself <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, label smoothing remains designed for classification problems with i.i.d. samples, ill-adapted to the time-dependent nature of our data.</p><p>To the best of our knowledge, we are the first work to explore adding a temporal dependence to label smoothing and empirically demonstrate the added value of this approach.</p><p>Whereas reweighted loss functions only bias learning towards minority or uncertain data points, multi-horizon prediction and label smoothing approaches alter the individual sample optimum. As a consequence, these approaches avoid model overconfidence and are thus more robust to noisy labelling <ref type="bibr" target="#b25">[26]</ref>. In this work, we propose to combine the respective advantages of these established methods in a novel way to improve early prediction of adverse events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>We first formalize the problem of early adverse event prediction and introduce temporal label smoothing. We then highlight how MHP can be framed as a special case of TLS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem formalism</head><p>We assume access to a dataset of N patient stays. These consist of irregular time series of highdimensional patient covariates X i,t = [x i,0 , . . . , x i,t ] and binary event labels e i,t encoding whether a patient of index i is undergoing an adverse event of interest at time t. For each patient, we thus have a sequence {(x i,1 , e i,1 ), . . . , (x i,Ti , e i,Ti )} of length T i .</p><p>Our early prediction task consists of modelling a binary target variable y i,t , which is positive if the event occurs within a given prediction horizon h. For labelling purposes, we define a time-to-event variable at each time point, t e (i, t) = arg min ? :? ?t {e i,? : e i,? = 1}. If patient i never undergoes any event, we set t e (i, t) = +?. Thus, we have:</p><formula xml:id="formula_0">y i,t = ? ? ? 0 if t &lt; t e ? h 1 if t e ? h &lt; t &lt; t e NaN if t e = t<label>(1)</label></formula><p>As our task focuses specifically on early modeling for clinical relevance, no prediction is carried out if the patient is currently undergoing the event. Then, as for any binary deep learning problem, we define a model f parameterized by ? with? i,t = f ? (X i,t ) = p ? (y i,t = 1). We denote the optimal set of parameters minimizing the objective function as ? * , giving y * i,t = f ? * (X i,t ).</p><p>Temporal structure. An important distinction must be made with the classification tasks typically addressed with label smoothing. In adverse event prediction, data is not independent and identically distributed (i.i.d.) as each sample x i,t depends on a timestep t and a patient stay indexed as i. Contiguous samples within a common stay are thus dependent in time:</p><formula xml:id="formula_1">p(y i,t+d = 1) ? p(y i,t = 1) ? d ? [0, t e (i, t) ? t[<label>(2)</label></formula><p>Our goal is to leverage this structure in our data to focus training on relevant timesteps and help address issues of noisy label boundaries and class imbalance, which are inherent to our choice of real-world medical datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Temporal label smoothing</head><p>As introduced by Szegedy et al. <ref type="bibr" target="#b12">[13]</ref>, label smoothing consists of substituting the original label distribution, ? yi=c for class c, with a smooth version q LS (c|y i ) in the cross-entropy objective L i = L CE (y i ,? i ). For binary tasks, label smoothing becomes a linear interpolation:</p><formula xml:id="formula_2">q LS (1|y i ) = (1 ? ?)y i + ?(1 ? y i )<label>(3)</label></formula><p>where parameter ? controls the smoothing strength.</p><p>By shifting the minimum of the objective function away from y * i = y i towards y * i = q LS , label smoothing prevents models from becoming overconfident during training. This approach should therefore help improve the robustness of early prediction models against the inherently noisy nature of the task <ref type="bibr" target="#b25">[26]</ref> but does not account for the time dependency between samples of a given stay. For this purpose, we propose temporal label smoothing, an approach to modulate smoothing based on time t to infuse this prior knowledge into the training objective. We define the corresponding surrogate distribution similarly to label smoothing:</p><formula xml:id="formula_3">q T LS (1|i, t) = 1 ? ?(i, t)<label>(4)</label></formula><p>For early prediction of events, to enforce the temporal inductive bias in Equation 2, we parametrize ?(i, t) as a monotonous decreasing function of t ? [0, t e (i, t)]. In practice, as illustrated in <ref type="figure" target="#fig_5">Figure 3a</ref>, this increases smoothing strength around the label boundary t = t e ? h, reducing prediction certainty in this region prone to high error rates, as shown in <ref type="figure" target="#fig_2">Figure 2a</ref>.</p><p>Smoothing parametrizations. We propose various temporal smoothing parametrizations for ?(i, t) in Appendix A.2. Experimental results suggest that an exponential parametrization, defined as follows, performs best on considered tasks. Corresponding smoothed labels q exp (1|i, t) can be visualized in <ref type="figure" target="#fig_2">Figure 2b</ref>.</p><formula xml:id="formula_4">? exp (i, t) = ? ? ? 1 ? e ??(te(i,t)?t?d) ? A if h min &lt; t e (i, t) ? t &lt; h max 0 if t e (i, t) ? t ? h min 1 if t e (i, t) ? t ? h max<label>(5)</label></formula><p>Parameters h min and h max define the time range over which we apply smoothing, namely [t e ? h max , t e ? h min ]. Under this constraint, parameters {d, A} are defined to enforce ?(i, t) to be continuous at boundary points (see Appendix A.2). Finally, ? controls the smoothing strength at a given time.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Link with multi-horizon prediction</head><p>As motivated above, temporal label smoothing adapts the contribution of each sample to reflect prior knowledge about the temporal structure of event prediction labels. In this section, we find that MHP leverages the same information in Equation 2 to teach the model to predict event over multiple horizons/ <ref type="bibr" target="#b7">[8]</ref>. Under simplifying assumptions justified empirically in Section 5.2, we show that this approach can be seen as a special case of temporal label smoothing with a 'staircase' parametrization.</p><p>In this framework, the unique label y i,t associated with patient covariates X i,t , for an horizon of interest h, is replaced by a vector</p><formula xml:id="formula_5">y i,t = [y h1 i,t , . . . , y h i,t , . . . , y h H i,t ] corresponding to H distinct horizons. The prediction model is thus adapted to output? i,t = [? h1 i,t , . . . ,? h i,t , . . . ,? h H i,t ].</formula><p>For temporal consistency between samples, Toma?ev et al. <ref type="bibr" target="#b7">[8]</ref> enforce predictions to be monotonically increasing over time, such that h u ? h v =?? hu i,t ?? hv i,t . With these additional components, the training objective for patient i becomes L M HP</p><formula xml:id="formula_6">i = ? 1 H H k=1 y h k i,t log(? h k i,t ) + (1 ? y h k i,t ) log(1 ?? h k i,t ). Proposition 1.</formula><p>Under the assumption that model outputs {? h k i,t } k are equal for all {h k } k (rather than monotonically increasing), MHP is equivalent to temporal label smoothing parameterized with ? step (i, t). This function, illustrated in <ref type="figure" target="#fig_5">Figure 3b</ref>, is defined as the following sequence of step functions in time:</p><formula xml:id="formula_7">? step (i, t) = ? ? ? k H if h k ? t e (i, t) ? t &lt; h k+1 ?k ? H ? 1 0 if t e (i, t) ? t ? h 1 1 if t e (i, t) ? t &gt; h H (6)</formula><p>Proof. See Appendix A.1. Proposition 1 frames MHP as a special case of TLS with step-function parametrization. We empirically justify the equal-output assumption through an ablation study in Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental setup 4.1 Early prediction tasks</head><p>We demonstrate the effectiveness of our method on three clinical early prediction tasks, inspired by existing literature and published benchmarks. All tasks deal with electronic health records from the ICU, where early prediction of organ failure or acute deterioration is critical to patient management <ref type="bibr" target="#b0">[1]</ref>.</p><p>Our work is first benchmarked on the prediction of acute circulatory failure and mild respiratory failure within the next h = 12 hours. These tasks are part of HiRID-ICU-Benchmark (HiB) <ref type="bibr" target="#b18">[19]</ref>, built on the publicly available HiRID dataset <ref type="bibr" target="#b6">[7]</ref>. The dataset contains high-resolution observations of over 33,000 ICU admissions. Our third evaluation task consists of early prediction of patient mortality, or decompensation, within a horizon of h = 24 hours. Although less clinically relevant, this task has been widely studied in the machine learning literature <ref type="bibr" target="#b29">[30]</ref>. Defined in the MIMIC-III Benchmark (M3B) <ref type="bibr" target="#b30">[31]</ref>, this task originates from the widely used MIMIC-III dataset <ref type="bibr" target="#b31">[32]</ref>, counting approximately 40,000 patient stays.</p><p>All three clinical events are labelled following internationally accepted criteria as in Harutyunyan et al. <ref type="bibr" target="#b30">[31]</ref> and Y?che et al. <ref type="bibr" target="#b18">[19]</ref>. Positive label prevalence is 4.3%, 38.6%, and 2.1% of timepoints for circulatory, respiratory failure, and decompensation prediction respectively -with rarer events associated with more severe states, in this instance. Further details on task definition and data pre-processing are provided in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Benchmarking strategy</head><p>Baselines. We quantify the added value of our method by comparing its performance to alternative learning approaches used for early event prediction, discussed in Section 2. Our first baselines consist of balanced cross-entropy <ref type="bibr" target="#b17">[18]</ref> and focal loss <ref type="bibr" target="#b19">[20]</ref>, popular sample reweigthing methods for imbalanced tasks. We also implement multi-horizon prediction as a multi-output model trained to predict event occurrence over different horizons between 0 and 2h. Note that for a fair comparison, we set (h min , h max ) = (0, 2h) in TLS. As in Toma?ev et al. <ref type="bibr" target="#b7">[8]</ref>, a cumulative distribution function layer on logits enforces monotonicity of predictions (Eq. 2). Finally, we also compare our method to conventional label smoothing <ref type="bibr" target="#b12">[13]</ref> to confirm that a temporal dependency does improve performance.</p><p>Hyperparameter tuning. Hyperparameters introduced by our method, such as strength term ? in smoothing parametrization ? exp (Equation 5), are optimized through grid searches on the validation set. The same approach is adopted for hyperparameters specific to each baseline, as shown in <ref type="figure">Figure 4</ref>.</p><p>Architecture choice. As our method and baselines are model-agnostic and only vary in terms of optimization objective, a unique model architecture is used for each task, selected through a random search on cross-entropy validation performance. Following a published benchmark on the HiRID dataset <ref type="bibr" target="#b18">[19]</ref>, we use a GRU <ref type="bibr" target="#b32">[33]</ref> and transformer <ref type="bibr" target="#b33">[34]</ref> architecture for the circulatory and respiratory failure tasks respectively. For decompensation prediction, transformers outperform the LSTM-based models <ref type="bibr" target="#b34">[35]</ref> originally proposed in the M3B benchmark <ref type="bibr" target="#b30">[31]</ref>, and are thus used in our work. As recommended by Toma?ev et al. <ref type="bibr" target="#b7">[8]</ref>, we apply l 1 -regularization to input embedding layers, which improves performance on all tasks. Further implementation details are provided in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation metrics</head><p>To account for the imbalanced nature of clinical early prediction tasks, model performance is often reported through the area under the receiver operating characteristic curve (AUROC). Although this widely-used metric can be informative for moderate imbalances, the area under the precision-recall curve (AUPRC) provides more insight for our tasks: under a low prevalence of positive samples, precision is more sensitive to false alarms than specificity <ref type="bibr" target="#b35">[36]</ref>. Still, "area under the curve" metrics can be poorly representative of clinical usefulness, as improvements in low precision regions can dominate such global metrics but remain incompatible with the low false alarm rates required for clinical deployment. Thus, to better assess model performance in this context, we also measure performance at a clinically motivated operating point through recall at 50% precision <ref type="bibr" target="#b22">[23]</ref>.</p><p>In addition to timestep-level metrics, which measure prediction performance at each data point, we also evaluate models in an event-based approach. Following Toma?ev et al. <ref type="bibr" target="#b7">[8]</ref>'s definition, an event prediction is positive if the model outputs a positive prediction at any time over the h hours before the event. The threshold defining a positive prediction is chosen based on a precision lower-bound: in practice, we use a 50% stepwise precision criterion. This allows us to measure the event recall of our approach in comparison to published baselines. Unless stated otherwise, we always report mean performance with 95% confidence intervals computed over ten training runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Prediction performance</head><p>Overall, our results highlight that TLS improves performance over other approaches proposed to address the challenges of early clinical prediction. In <ref type="table">Table 2</ref>, we find TLS to outperform other baselines across all metrics for both circulatory failure and decompensation. Despite overlapping confidence intervals between multi-horizon and TLS on decompensation due to individual training run variability, our method remains statistically superior under a <ref type="table">Table 2</ref>: Timestep-level performance on different early prediction tasks. Recall is reported at a 50% precision. Circulatory and respiratory failure are predicted on the HiB dataset, decompensation on M3B. In bold, we report methods within the confidence interval of the best performing one and statistically significant p-values (&lt; 0.05) from paired Student's t-tests <ref type="bibr" target="#b36">[37]</ref>.  <ref type="bibr" target="#b12">[13]</ref> 39.3 ? 0.4 29.9 ? 0.8 33.9 ? 0.3 27.7 ? 0.5 60.1 ? 0.2 76.6 ? 0.5 Multi-horizon <ref type="bibr" target="#b7">[8]</ref> 39</p><formula xml:id="formula_8">.6 ? 0.5 30.3 ? 1.0 34.9 ? 0.3 28.6 ? 0.5 60.3 ? 0.1 76.6 ? 0.5 Temporal Label Smoothing 40.6 ? 0.3 32.3 ? 0.7 35.5 ? 0.3 29.3 ? 0.4 60.4 ? 0.2 77.0 ? 0.3 p-value (H 0 : T LS &gt; M HP ) 0.00 0.00 0.00 0.02 0.15 0.14 t-test.</formula><p>Full precision-recall curves are given in <ref type="figure" target="#fig_0">Figures 5a and 13</ref>. We discuss the tradeoffs and limitations imposed by these custom objectives, as evidenced by the lack of improvement in respiratory failure task, in Section 5.3. In contrast, as illustrated in <ref type="figure">Figure 4</ref>,  <ref type="figure">Figure 4</ref>: Performance loss with class reweighting methods, on the validation set for circulatory failure prediction. Weighted cross-entropy corresponds to ? = 0.</p><p>loss reweighting methods designed to tackle class imbalance were found to reduce performance on all tasks over traditional cross-entropy. For weighted cross-entropy, we attribute it to the increase in false alarms resulting from the drive to improve recall. It further reduces the low precision of all models, thus negatively affecting the AUPRC (as visualized in Appendix D.3). On the other hand, focal loss downweighs confident samples in training, constraining the model to focus on samples with uncertain predictions.</p><p>In the context of noisy labeling, as is the case close to our class boundary, data points with ambiguous signals cannot be correctly predicted and thus dominate the loss, impeding improvements in other regions of input space. We analyze model performance over time in Section 5.2 to further support this hypothesis.</p><p>Clinically-relevant performance. We also compare the full precision-recall curve of models trained with these different objectives in <ref type="figure" target="#fig_8">Figure 5a</ref> -note that we obtain comparable results for decompensation prediction in Appendix D. In addition to visually confirming the numerical results in <ref type="table">Table 2</ref>, we find that our training objective affords particular performance improvements in the clinically-relevant region corresponding to high precision or low false-alarm rates <ref type="bibr" target="#b0">[1]</ref>.    Event-based analysis. Finally, as highlighted in <ref type="figure" target="#fig_8">Figure 5b</ref>, TLS improves performance in terms of predicting overall adverse event episodes throughout a stay on all prediction tasks. This suggests that performance improvements at the timestep level affect a large number of events and translate to better event detection. Indeed, we demonstrate in Section 5.2 that TLS affords larger performance gains close to the event time, thus leading to a better recall of imminent events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Illustrative insights</head><p>We propose ablations and analyses to build intuition around our proposed method. In particular, we aim to highlight how temporal smoothing works and why it outperforms other training approaches for early prediction tasks.   Performance over time. In <ref type="figure" target="#fig_11">Figure 6</ref>, we compare the performance difference between our method, TLS, and the regular cross-entropy objective over time -previously studied in <ref type="figure" target="#fig_2">Figure 2a</ref>. We perform the same analysis in Appendix D for other tasks. As expected, the prediction model trained with TLS is less competitive where label smoothing is strongest, near t e ? h, but this performance loss remains minor even with significant smoothing. This result validates our hypothesis that the signal is too noisy in the boundary region for any model to recover the original label distribution. In contrast, away from the label boundary, TLS results in a significant increase in true positive and negative rates. From a clinical perspective, errors made in the boundary region are less critical, as they result in the latest false positives or earliest false negatives. Consequently, TLS not only improves global event prediction performance but allows these gains to occur at more critical times for clinicians.</p><p>Empirical comparison to multi-horizon prediction. In our theoretical discussion in Section 3.3, we demonstrated how MHP is a restriction of label smoothing with a step function ? step (i, t). This claim relies on the constraint to produce a unique prediction across all considered horizons, reflecting the design of our method. We verify the impact of this assumption by measuring performance gains afforded by learning distinct predictions per horizon. As shown in <ref type="table" target="#tab_3">Table 3</ref>, with full precision-recall curves in <ref type="figure" target="#fig_0">Figure 18</ref>, we find no statistical evidence for performance gain over using ? step on all tasks and studied metrics. Thus, models do not appear to leverage this additional flexibility offered by MHP. With superior results on all timestep-and event-based experiments, and greater scalability thanks to the single prediction horizon modeled, we find temporal label smoothing to be a superior training objective to MHP in early prediction tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Trade-offs and limitations</head><p>Despite the demonstrated advantage of our training paradigm for two distinct early prediction tasks, we observed no performance gain over traditional cross-entropy when predicting respiratory failure on HiB in <ref type="table">Table 2</ref>. Although no other baseline improved learning on this task either, this observation motivated an analysis of the specific problem settings in which our objective helps.</p><p>Respiratory failure events are much more frequent than circulatory failure or decompensation, with the majority of ICU patients undergoing approximately two such events during their stay, as quantified in Appendix B.We hypothesize that this reduced class imbalance leads to sufficient discriminative information within the label boundary region. This belief is supported by the more significant performance loss close to t e ? h with TLS compared to the other tasks, with a 1% drop in true positive rate (TPR) in <ref type="figure" target="#fig_12">Figure 7</ref>. However, as expected by design, our method improves recall (+1% TPR) over cross-entropy close to the event. This also leads to a non-negligible 0.5% improvement in event recall, visualized in Appendix D.2. Overall, this analysis reveals that whereas TLS has little impact on global metrics for close-to-balanced tasks, which remain quite rare in clinical decision support efforts <ref type="bibr" target="#b7">[8]</ref>, it still results in clinically meaningful performance improvements along per-horizon and event-based metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Early prediction of adverse events is paramount to the development of clinical decision support systems, with a demonstrated potential to improve patient outcomes <ref type="bibr" target="#b2">[3]</ref>. Still, this task remains poorly studied in the machine learning literature, with few training solutions tailored to address its challenges. Based on typically rare and noisy labels, models must learn to discriminate a predictive signal in anticipation of events to allow an adequate medical response.</p><p>After highlighting the limitations of traditional classification objectives and methods designed to address class imbalance, we propose a novel training framework that leverages trends in event signals over time. We show that multi-horizon prediction, a heuristic used to improve early prediction, can be formalized as a restriction of our framework. Simple but effective, temporal label smoothing empirically matches or outperforms all considered baselines on various tasks and datasets, with significant improvements on clinically-relevant evaluation metrics. Performance gains are limited, as with other baselines, for respiratory failure prediction in which higher event prevalence provides sufficient informative data points for the model to learn through a conventional cross-entropy objective. In further work, we aim to explicitly adapt the temporal inductive bias to the task at hand and to combine temporal label smoothing with recent objectives designed to directly optimize AUPRC, such as minimum precision constraint <ref type="bibr" target="#b37">[38]</ref> or dice-based loss functions <ref type="bibr" target="#b38">[39]</ref>.</p><p>Looking ahead, we expect that temporal label smoothing will be leveraged to develop more clinically reliable systems for risk prediction of rare adverse events. Further research on tailored machine learning solutions to improve real-world decision support holds promise for better clinical care and operations management.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Theoretical details</head><p>A.1 Multi-Horizon prediction: proof of Proposition 1 Equivalency between MHP and TLS objectives. Recalling the formalism of multi-horizon prediction outlined in Section 3.3, true labels and model predictions can be rewritten as</p><formula xml:id="formula_9">y i,t = [y h1 i,t , . . . , y h i,t , . . . , y h H i,t ] and? i,t = [? h1 i,t , . . . ,? h i,t , . . . ,? h H i,t ],</formula><p>where H is the number of horizons considered. The training objective for patient i becomes:</p><formula xml:id="formula_10">L M HP (y i,t ,? i,t ) = ? 1 H H k=1 y h k i,t log(? h k i,t ) + (1 ? y h k i,t ) log(1 ?? h k i,t )</formula><p>The assumption that {? h k i,t } k is equal for all k allows to rewrite the objective as follows:</p><formula xml:id="formula_11">L M HP (y i,t ,? i,t ) = ? log(? i,t ) 1 H H k=1 y h k i,t + log(1 ?? i,t ) 1 H H k=1 (1 ? y h k i,t )</formula><p>with? i,t being the common prediction shared across all horizons. This equation can now be viewed as a temporal label smoothing objective with smoothed labels q step (1|i, t)</p><formula xml:id="formula_12">= 1 H H k=1 y h k i,t : L M HP (y i,t ,? i,t ) = ? log(? i,t ) ? q step (1|i, t) + log(1 ?? i,t ) ? 1 ? q step (1|i, t)</formula><p>Smoothing parametrization. Next, we aim to recover the explicit form of q step (1|i, t). Without loss of generality, we assume that horizons {h k } k are in ascending order. The temporal dependency between samples, formalized in Equation 2), results in the following relationship between predictions at horizons h u and h v :</p><p>v ? u and y hv i,t = 1 =? y hu i,t = 1</p><p>v ? u and y hv i,t = 0 =? y hu i,t = 0</p><p>Thanks to the above property, we can determine q step (1|i, t) by studying three cases of multi-horizon labels, illustrated in <ref type="figure">Figure 8</ref>. For notational simplicity, we define d e (i, t) = t e (i, t) ? t.  <ref type="figure">Figure 8</ref>: Label values for multi-horizon prediction, and conversion to smoothed labels q step (1|t).</p><formula xml:id="formula_15">Case 1: d e (i, t) ? h 1 . Label definition in Equation 1 implies that y h1 i,t = 1 if d e (i, t) ? h 1 .</formula><p>As h 1 is the smallest horizon, following Equation 7, we have y hc i,t = 1, ?c ? 1, H . We can rewrite the objective as:</p><formula xml:id="formula_16">L M HP (y i,t ,? i,t ) = ? log(? i,t ) = ?[q step (1|i, t) log(? i,t ) + (1 ? q step (1|i, t)) log(1 ?? i,t )]</formula><p>where q step (1|i, t) = 1. </p><formula xml:id="formula_17">L M HP (y i,t ,? i,t ) = ? log(1 ?? i,t ) = ?[q step (1|i, t) log(? i,t ) + (1 ? q step (1|i, t)) log(1 ?? i,t )]</formula><p>where q step (1|i, t) = 0.</p><formula xml:id="formula_18">Case 3: ?k ? 1, H ? 1 s.t h k &lt; d e (t) ? h k+1 .</formula><p>Following the same reasoning as in the first two cases, we now have a specific index k which separates positive and negative labels. We have y hc i,t = 0, ?c ? 1, k and y hc i,t = 1, ?c ? k + 1, H . This allows to rewrite the objective as follows:</p><formula xml:id="formula_19">L M HP (y i,t ,? i,t ) = ?[ H ? k H log(? i,t ) + k H log(1 ?? i,t )] = ?[q step (1|i, t) log(? i,t ) + (1 ? q step (1|i, t)) log(1 ?? i,t )] where q step (1|i, t) = H ? k H .</formula><p>Defining a new smoothing parametrisation ? step such that q step (1|i, t) = 1 ? ? step (i, t), we obtain: Motivated by prior work <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b16">17]</ref>, we compare the performance of various smoothing functions ?(i, t).</p><formula xml:id="formula_20">? step (i, t) = ? ? ? k H if h k ? d e (i, t) &lt; h k+1 ?k ? H ? 1 0 if d e (i, t) ? h 1 1 if d e (i, t) &gt; h H</formula><p>All proposed parametrizations are continuous and monotonous decreasing functions which satisfy boundary conditions ?(i, t e (i, t) ? 2h) = 1 and ?(i, t e (i, t)) = 0. As evidenced in <ref type="table" target="#tab_5">Table 4</ref>, we find exponential label smoothing to perform best or as well as others across all tasks and metrics. Performance as a function of hyperparameter setting can be visualized in <ref type="figure" target="#fig_0">Figure 10</ref>. All model and hyperparameter selection was carried out on the validation set, including the final choice of parametrization function.  Shifted boundary labels. Shifting the prediction horizon or label boundary in training can be viewed as a form of temporal label smoothing, in which class labels are inverted within a prediction window of interest. This defines the following smoothing parametrization ? shif t (i, t):   Linear label smoothing. The most straightforward extension to the step function ? step described in Section 3.3 is a linear label smoothing corresponding to the case H ? +?. Our parametrization ? linear (i, t) is thus defined as follows:</p><formula xml:id="formula_21">? shif t (i, t) = 1 [t e (i, t) ? t ? h shif t ]<label>(9)</label></formula><formula xml:id="formula_22">? linear (i, t) = te(i,t)?t 2h if t e (i, t) ? t &lt; 2h 1 if t e (i, t) ? t ? 2h<label>(10)</label></formula><p>We illustrate the impact of the number of steps H in <ref type="figure" target="#fig_14">Figure 9b</ref>.</p><p>Sigmoidal label smoothing. Another natural direction to explore is to smooth labels starting from the true distribution, a unique step function at t = t e (t) ? h. This can be achieved by defining ?(t) as a generalized logistic function <ref type="bibr" target="#b39">[40]</ref>:</p><formula xml:id="formula_23">? sigmoid (i, t) = 1 ? K?A 1+e te(i,t)?t?d ? ? A if t e (i, t) ? t &lt; 2h 1 if t e (i, t) ? t ? 2h<label>(11)</label></formula><p>where K, A and d are three constants fixed by imposing the boundary conditions at t = t e (i, t) ? 2h and t = t e (i, t), as well as ?(t e (i, t) ? 2h) = 1 2 . This yields:</p><formula xml:id="formula_24">K = ?Ae 2h?d ? A = e ?d ? + 1 e ?d ? ? e 2h?d ? d = h</formula><p>As shown in <ref type="figure" target="#fig_14">Figure 9d</ref>, ? controls the smoothing strength, interpolating between the true distribution ? yi=1 as ? ? 0 and q linear when ? ? +?.</p><p>Exponential label smoothing. The smoothing function we find to perform best is an exponential decay. This idea is motivated by survival analysis, where patient survival probability can be modeled as the exponential decay of a cumulative hazard function <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b40">41]</ref>. In practice, as defined in Section 3.2, our exponential smoothing function ? exp (i, t) is defined as follows:</p><formula xml:id="formula_25">? exp (i, t) = 1 ? e ??(te(i,t)?t?d) ? A if t e (i, t) ? t &lt; 2h 1 if t e (i, t) ? t ? 2h<label>(12)</label></formula><p>where parameters {d, A} are set to satisfy boundary conditions:</p><formula xml:id="formula_26">A = ?e ??(2h?d) d = ? 1 ? ln 1 ? e ??2h</formula><p>Here, ? also controls the smoothing strength between q linear when ? ? 0 and q(t) = 0 ?t &lt; t e when ? ? +?.</p><p>Overall, despite ? sigmoid and ? shif t achieving good results on respiratory and circulatory failure respectively, ? exp statistically outperforms these smoothing parametrizations across all tasks on validation metrics. An interesting avenue for further work would be to combine exponential smoothing with the boundary shift approach, or effectively changing (h min , h max ), which was fixed to (0, 2h) in our work for fair comparison to multi-horizon prediction.</p><p>Concave exponential label smoothing. Finally, to mirror the behavior of the exponential smoothing function away from linear interpolation and investigate its effect on performance, we designed the following concave smoothing function ? concave :</p><formula xml:id="formula_27">? concave (i, t) = e ??(d?te(i,t)+t) ? A if t e (i, t) ? t &lt; 2h 1 if t e (i, t) ? t ? 2h<label>(13)</label></formula><p>Parameters {d, A} are identical to the convex smoothing function parameters, set to satisfy boundary conditions. The strength of this concave smoothing function is illustrated <ref type="figure" target="#fig_14">Figure 9c</ref>.</p><p>No performance gains were obtained through temporal label smoothing with a concave function, as shown in <ref type="figure" target="#fig_0">Figure 10</ref>. This smoothing function effectively penalizes false positives harder than false negatives, which is less adapted to our tasks of interest (in contrast to the convex a exp ). As a result, the best-performing concave parametrization is consistently obtained with the lowest value of ?, closer to a linear function choice.</p><p>Comparison to survival analysis. Survival analysis consists of statistical methods concerned with predicting the probability of a certain event taking place over time <ref type="bibr" target="#b40">[41]</ref>. In our formalism outlined in Section 3.1, the corresponding task is to regress the time of the next event, t e (t, i), based on patient information accumulated up to time t. To recover early event prediction, a threshold on the hazard model can thus be applied to determine whether an event will happen within our horizon of interest h. Modelling constraints imposed in survival analysis improve time-to-event prediction performance over traditional regression methods, which supports our approach to leverage the temporal structure of our comparable task. Interestingly, recent developments in survival modelling to deal with dynamic predictions have been addressed with multi-horizon prediction <ref type="bibr" target="#b41">[42]</ref>.</p><p>Still, distinctions must be highlighted between our adverse event prediction problem and the typical experimental setup for survival analysis: in our case, multiple events can occur over the course of a patient's stay, with unknown patient states during and immediately after event occurrence. This results in complex, informative censoring patterns and challenges common assumptions in survival analysis, which can therefore not be directly applied to our task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Baseline objective functions</head><p>In this section, we clarify the mathematical formalism behind our baselines to facilitate comparison to temporal label smoothing. All baselines explored effectively propose a modification of the cross-entropy objective often used for binary classification tasks, L i = L CE (y i ,? i ).</p><p>Balanced cross-entropy. To facilitate learning from highly imbalanced datasets, balanced crossentropy relies on reweighting samples based on their class prevalence, as follows:</p><formula xml:id="formula_28">L CE = 1 N N i ? yi L(? i , y i )<label>(14)</label></formula><p>where C is the number of classes, ? yi = 1 C?b(yi) and b(c) defines the prevalence of class c such that c b(c) = 1. Regular cross-entropy corresponds to the case where b(c) = 1 C for all classes. In the binary setting, b(1) can be treated as a hyperparameter determining the contribution of the minority class to the loss.</p><p>Focal loss. Denoting our output prediction as? i = p ? (y i = 1), the focal loss objective for binary classification of target y i is a variant on the balanced cross-entropy loss:</p><formula xml:id="formula_29">L f ocal (y i ,? i ) = ?? 1 (1 ?? i ) ? y i log(? i ) ? ? 0? ? i (1 ? y i ) log(1 ?? i )</formula><p>where ? yi is a balancing weight for class y i and ? is the focal loss weight.</p><p>Multi-horizon prediction. As highlighted in Section 3.3, multi-horizon training can be formalized as the following objective:</p><formula xml:id="formula_30">L M HP (y i,t ,? i,t ) = ? 1 H H k=1 y h k i,t log(? h k i,t ) + (1 ? y h k i,t ) log(1 ?? h k i,t )</formula><p>where true labels and model predictions are given by</p><formula xml:id="formula_31">y i,t = [y h1 i,t , . . . , y h i,t , . . . , y h H i,t ] and? i,t = [? h1 i,t , . . . ,? h i,t , . . . ,? h H i,t ], for H distinct horizons.</formula><p>Label smoothing. As introduced by Szegedy et al. <ref type="bibr" target="#b12">[13]</ref>, label smoothing consists of substituting the original label distribution ? yi=c in the cross-entropy objective L i = L CE (y i ,? i ) by a smoothed version q LS (c|y i ). This surrogate distribution over classes c is defined as follows :</p><formula xml:id="formula_32">q LS (c|y i ) = ? yi=c (1 ? ?) + u(c)?<label>(15)</label></formula><p>In the original approach, u is uniform and ? ? [0, 1] controls the smoothing strength. By shifting the minimum of the objective function away from? i = 1, labels smoothing prevents the model from becoming overconfident during training. Alternative designs for u have been proposed <ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref> but are incompatible with the binary nature of adverse event prediction. In binary tasks, labeling is defined according to the positive class such that y i ? {0, 1} and? i = p ? (y i = 1). Label smoothing therefore becomes a linear interpolation with parameter ? such that q LS (1|y i ) = p(y i = 1):</p><formula xml:id="formula_33">q LS (1|y i ) = (1 ? ?)y i + ?(1 ? y i )<label>(16)</label></formula><p>As suggested by Lukasik et al. <ref type="bibr" target="#b25">[26]</ref>, label smoothing can be used to regularize early prediction models due to inherently noisy nature of the task. It does not, however, account for the time dependency between samples of a given stay -highlighted in our problem formalism (Section 3.1). In contrast, temporal label smoothing modulates smoothing based on time t to infuse this prior knowledge into the training objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Dataset details B.1 Task definition</head><p>In this section, we provide more details on the definition of our early prediction tasks for circulatory failure and respiratory failure from HiB <ref type="bibr" target="#b18">[19]</ref> and decompensation from M3B <ref type="bibr" target="#b30">[31]</ref>. A breakdown of event prevalence for each clinical endpoint is given in <ref type="table" target="#tab_6">Table 5</ref>. Circulatory failure is a failure of the cardiovascular system, detected in practice through elevated arterial lactate (&gt; 2 mmol/l) and either low mean arterial pressure (&lt; 65 mmHg) or administration of a vasopressor drug. Y?che et al. <ref type="bibr" target="#b18">[19]</ref> define a patient to be experiencing a circulatory failure event at a given time if those conditions are met for 2/3 of timepoints in a surrounding two-hour window. Early prediction labels are then derived from these event labels as outlined in Section 3.1.</p><p>Respiratory failure is defined by Y?che et al. <ref type="bibr" target="#b18">[19]</ref> as a P/F ratio (arterial pO 2 over FIO 2 ) below 300 mmHg. This definition includes mild respiratory failure, which explains higher event prevalence in <ref type="table" target="#tab_6">Table 5</ref>. As above, Y?che et al. <ref type="bibr" target="#b18">[19]</ref> consider a patient to be experiencing respiratory failure if 2/3 of timepoints are positive within a surrounding 2h window.</p><p>Decompensation refers to the death of a patient. Event labels are directly extracted from the MIMIC-III <ref type="bibr" target="#b31">[32]</ref> metadata about the time of death of a patient. Early prediction labels are also extracted following Section 3.1. Note that decompensation can occur outside of the ICU stay if a patient is sent to a palliative unit, for instance, which can result in patient stays with fewer than 24 positive samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Pre-processing</head><p>We describe the pre-processing steps we applied to both datasets, HiRID and MIMIC-III.</p><p>Imputation. Diverse imputation methods exist for ICU time series. For simplicity, we follow the approach of original benchmarks <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b18">19]</ref> by using forward imputation when a previous measure existed. Remaining missing values are zero-imputed them after scaling, corresponding to a mean imputation.</p><p>Scaling. Whereas prior work explored clipping the data to remove potential outliers <ref type="bibr" target="#b7">[8]</ref>, we do not adopt this approach as we found it to reduce performance on early prediction tasks. A possible explanation is that, due to the rareness of events, clipping extreme quantiles may remove parts of the signal rather than noise. Instead, we simply standard-scale data based on the training sets statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Implementation details</head><p>Training details. For all models, we set the batch size according to the available hardware capacity. Because transformers are memory-consuming, we train the models for respiratory failure and decompensation with a batch size of 8 stays. On the other hand, we train the GRU model for circulatory failure with a batch size of 64. We early stopped each model training according to their validation loss when no improvement was made after 10 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Libraries.</head><p>A full list of libraries and the version we used is provided in the environment.yml file. The main libraries on which we build our experiments are the following: pytorch 1.11.0 <ref type="bibr" target="#b42">[43]</ref>, scikit-learn 0.24.1 <ref type="bibr" target="#b43">[44]</ref>, ignite 0.4.4, CUDA 10.2.89 <ref type="bibr" target="#b44">[45]</ref>, cudNN 7.6.5 <ref type="bibr" target="#b45">[46]</ref>, gin-config 0.5.0 <ref type="bibr" target="#b46">[47]</ref>.</p><p>Infrastructure. We follow all guidelines provided by pytorch documentation to ensure reproducibility of our results. However, reproducibility across devices is not ensured. Thus we provide here the characteristics of our infrastructure. We trained all models on a single NVIDIA RTX2080Ti with a Xeon E5-2630v4 core. Training took between 3 and 10 hours for a single run.</p><p>Uncertainty estimation. We compute uncertainty estimate over a population of 10 training instances with different seeds. This widely-used approach has the advantage to account for the stochasticity of the training procedure, which we found to be predominant in early prediction tasks. This approach differs from other work <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b22">23]</ref> which computes uncertainty estimate over bootstrap of the test population for a single run. We then report 95% confidence interval over the population mean in all experiments.</p><p>Architecture choices We used the same architecture and hyperparameters reported to give best performance on respiratory and circulatory failure in Y?che et al. <ref type="bibr" target="#b18">[19]</ref>. For these tasks, we only optimized embedding regularization parameters <ref type="bibr" target="#b7">[8]</ref>. Exact parameters are reported in <ref type="table" target="#tab_7">Table 6 and  Table 7</ref>. For decompensation, as we found a transformer architecture to perform better than originally proposed models <ref type="bibr" target="#b30">[31]</ref>, we carried out our own random search on validation AUPRC performance. Exact parameters for this task are reported in <ref type="table" target="#tab_9">Table 8</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Baseline implementation</head><p>Balanced cross-entropy. In the binary setting, the only hyperparameter of balanced cross-entropy is the relative contribution of the minority class to the loss, ? 1 . As discussed in Section 5.2, no value of ? 1 was found to improve validation performance over the non-balanced case ? 1 = 1.</p><p>Focal loss. A grid search over focal loss hyperparameters was also carried out. Similarly to balanced cross-entropy, on all tasks, no values of focal loss weight ? or balancing weight ? 1 were found to outperform regular cross-entropy corresponding to ? = 0 and ? 1 = 1.</p><p>Multi-horizon prediction. Following Toma?ev et al. <ref type="bibr" target="#b7">[8]</ref>, we consider H horizons on both side of the true horizon h between 0 and 2h. As we didn't find H ?? +?, to increase performance, we selected H = 11 (including true horizon h) compared to H = 8 in Toma?ev et al. <ref type="bibr" target="#b7">[8]</ref>, which we found to perform slightly worse. This means we made prediction every 2 hours for HiB tasks, and every 4 hours for decompensation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Label</head><p>Smoothing. Label smoothing <ref type="bibr" target="#b12">[13]</ref>, as defined in Section 3.2, is normally used in multi-class setting. We still compared our method to it for two reasons. First, to explore if it can help when dealing with a noisy signal as we claim it is the case for early event detection. Second, to ablate the impact of adding a temporal dependency to the method. Again, we select the hyperparameter ? through a grid search. Interestingly, we found label smoothing to slightly improve performance over the validation set for all tasks as opposed to the results reported for the test set in <ref type="table">Table 2</ref>. We found ? = 0.05 to perform best for circulatory failure and decompensation. For respiratory failure, we found ? = 0.1 to have the best validation performance. TLS depends on two components, the temporal range over which we smooth labels, defined by h min and h max , and the smoothing function ?(i, t). Concerning the temporal range, for a fair comparison, we fix it to match MHP, thus for all experiments we set h min = 0 and h max = 2h. For the smoothing function, we perform a grid search over the type of function discussed in Appendix A.2 and the smoothing strength parameter ?. For all experiments we found ? exp to outperform other considered functions. Given validation performance, we used ? = 0.2 for circulatory failure and ? = 0.05 for respiratory failure and decompensation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 TLS implementation</head><p>As discussed in Section 3.2, contrary to MHP, TLS does not require any change to the architecture leading to a computational overhead. The smoothing of the labels can be easily integrated into the data loader, as shown in <ref type="figure" target="#fig_0">Figure 11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional experiments and ablation studies</head><p>This section provides additional results and experiments to complete our findings from the main manuscript. Unless otherwise stated, mean results are shown with 95% confidence interval shaded or in error bars.  <ref type="figure" target="#fig_0">Figure 12</ref>: Event recall at 50% timestep-level precison, for two additional tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Event-based metrics for other tasks</head><p>Event-level performance trends for decompensation and respiratory failure prediction were similar to those obtained for circulatory failure in <ref type="figure" target="#fig_8">Figure 5b</ref>. As discussed in Section 5.1, temporal label smoothing improves recall of adverse event episodes over cross-entropy and MHP.    Decompensation. Precision-recall curves obtained for timestep-level event prediction on respiratory failure and decompensation tasks are given in <ref type="figure" target="#fig_0">Figure 13</ref>. As for circulatory failure prediction, decompensation recall gains are concentrated in regions of low false-alarm rates (&gt;50% precision) which are most clinically relevant. Likewise, whereas recall near the label boundary t e ? h is slightly negatively affected by temporal label smoothing in <ref type="figure" target="#fig_0">Figure 14</ref>, true positive rates are significantly improved leading up to the event time t e . This mirrors the temporal smoothing pattern which favours higher model confidence away from the label boundary. As discussed in Section 5.2, this is aligned with clinical priorities in terms of model performance, as it ensures imminent events are better predicted.</p><p>Respiratory Failure. As discussed in Section 5.3, on respiratory failure, there is no clear advantage of using temporal label smoothing (or any baseline) over cross-entropy on timestep level metrics as in <ref type="figure" target="#fig_0">Figure 13</ref>. This can be attributed to the more balanced nature of this task. Still, we find that performance over time in <ref type="figure" target="#fig_0">Figure 15</ref> reflects the design of temporal label smoothing, as true positive rates are negatively affected near the highly smoothed label boundary but improve when approaching event time. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Loss reweighting methods</head><p>Hyperparameter grid search results for different loss reweighting methods are shown in <ref type="figure" target="#fig_0">Figures 4  and 16</ref>. For all three tasks, both weighted cross-entropy and focal loss were found to negatively affect performance in comparison to traditional cross-entropy. Likely explanations for these results are provided in Section 5.2: focal loss focuses training on noisily labelled samples, and weighted crossentropy largely reduces precision. We validate the latter hypothesis by visualising precision-recall curves of models trained with this objective in <ref type="figure" target="#fig_0">Figure 17</ref>.   Impact of weighted cross-entropy on precision. With a relative weight for the positive class ? 1 = 0.5 b(c=1) &gt; 1, weighted cross-entropy encourages a greater number of true positives to improve recall. Doing so also increases the of false positives, impairing precision. In <ref type="figure" target="#fig_0">Figure 17</ref>, as the starting precision of all cross-entropy models is poor, no discernible improvements in recall can be observed as class weights are increased, whereas precision is markedly reduced in low-recall regions. This explains the overall reduction in AUPRC with this method across all tasks.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4 Visual comparison of TLS with q step and MHP performance</head><p>In <ref type="figure" target="#fig_0">Figure 18</ref>, we compare the precision-recall curve of multi-horizon prediction and temporal label smoothing with q step smoothing, ensuring that there is no area where MHP is superior. In complement to <ref type="table" target="#tab_3">Table 3</ref> and to the analysis in Section 5.2, this confirms that predicting at single horizon with a step function smoothing is sufficient to match the performance of multi-horizon prediction.  <ref type="figure" target="#fig_0">Figure 18</ref>: Precision-recall curves of multi-horizon prediction and temporal label smoothing with q step . Both curves overlap, as suggested by metrics in <ref type="table" target="#tab_3">Table 3</ref>, further demonstrating that the multiple outputs of multi-horizon prediction do not lead to a superior performance, and supporting assumptions in Proposition 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.5 Combining TLS with other methods</head><p>Finally, we investigated whether temporal label smoothing could be combined with other objective functions to leverage their respective added value and further improve prediction performance. The performance of temporal label smoothing combined with a weighted cross-entropy objective is given in <ref type="figure" target="#fig_0">Figure 19</ref>. Balanced reweigthing per class results in a performance drop, as observed when applied to traditional cross-entropy (see Section 5.1, <ref type="figure">Figure 4</ref>). Another possible approach to combine these methods would be to leverage temporal information in sample re-weighting, and we reserve this investigation for further work.</p><p>Similarly, no additional performance gain were obtained from combining multi-horizon prediction or focal loss with temporal label smoothing over using TLS with cross-entropy loss.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Early prediction task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Timestep performance of regular cross-entropy training for decompensation on MIMIC-III. Comparison of temporally-smoothed and ground-truth labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of temporal label smoothing for early prediction of adverse events. Predictions are carried out over a horizon h and t e is the time of the next event, shaded in grey. True labels in black. (a) False positive (FPR) and true positive rates (TPR) are both poorest at the class boundary, motivating greater smoothing in this region. Metrics are computed over four-hour bins based on a 50% precision threshold. (b) ? controls the smoothing strength of surrogate labels q T LS .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Parametrization ? exp (Equation 5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Parametrization ? step (Equation 6).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Label smoothing strength over time under different parametrizations, with (h min , h max ) = (0, 2h). Note that |y ? q T LS | corresponds to the difference in optimum y * between the TLS objective and cross-entropy. Smoothing function ? step is equivalent to multi-horizon prediction with a unique output.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Precision-recall curve. Inset shows the clinically-applicable region with precision &gt; 50%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Event-level performance for a 50% timestep-level precision threshold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Clinically-oriented performance analysis of different training objectives on circulatory failure prediction. See Appendix D for results on other tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>True negative rate (TNR).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>(%) (b) True positive rate (TPR).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 6 :</head><label>6</label><figDesc>Performance improvement over time for TLS over traditional cross-entropy on circulatory failure prediction. Timestep-level metrics computed for a precision of 0.5 over two-hour bins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 7 :</head><label>7</label><figDesc>Performance improvement over time for TLS over traditional cross-entropy, for respiratory failure. True positive rates (TPR) are computed for a precision of 0.5 over 2-hour bins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>: y h = 0 ?h ? hk : y h = 0 ?h ? h k + 1 : y h = 1 ?h : y h = 1 t e ? t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 9 :</head><label>9</label><figDesc>Thus, ?d e (t) &gt; 0, we find that L M HP i = L T LS i when smoothed labels are defined as q step (1|i, t) = 1 ? ? step (i, t). This concludes our proof. Illustration of temporal label smoothing with alternative smoothing parametrizations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 10 :</head><label>10</label><figDesc>Validation AUPRC performance of temporal label smoothing as a function of smoothing hyperparameters, with different smoothing parametrizations. (Left) Performance for different smoothing strengths ? with ? exp , ? concave , ? sigmoid ; (Right) Performance for different prediction horizons h shif t with ? shif t smoothing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>? step 39 . 3 ?</head><label>393</label><figDesc>0.2 29.4 ? 0.8 35.2 ? 0.3 29.2 ? 0.4 60.5 ? 0.1 77.4 ? 0.5 ? shif t 40.1 ? 0.3 31.8 ? 0.6 34.5 ? 0.4 28.2 ? 0.5 60.5 ? 0.2 77.3 ? 0.5 ? linear 39.4 ? 0.3 29.7 ? 0.8 35.1 ? 0.4 29.2 ? 0.6 60.3 ? 0.3 77.0 ? 0.6 ? sigmoid 39.4 ? 0.3 29.7 ? 0.8 34.9 ? 0.4 28.8 ? 0.5 60.6 ? 0.2 77.3 ? 0.5 ? concave 39.4 ? 0.3 29.7 ? 0.8 35.1 ? 0.4 29.2 ? 0.6 60.3 ? 0.3 77.0 ? 0.6 ? exp 40.6 ? 0.3 32.3 ? 0.7 35.5 ? 0.3 29.3 ? 0.4 60.4 ? 0.2 77.0 ? 0.3 where h shif t is a hyperparameter controlling the horizon of the smoothed labels (h shif t = h corresponds to cross-entropy training). The strength of this smoothing function is illustrated Figure 9a.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 10</head><label>10</label><figDesc>outlines the performance of this alternative smoothing parametrization as a function of h shif t . For both decompensation and respiratory failure, shifting the label boundary closer to the event time decreases performance. On circulatory failure, performance does improve over traditional cross-entropy training as the label horizon is brought closer to the event of interest, which can be interpreted as an inductive bias similar to that induced by the exponential smoothing function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 11 :</head><label>11</label><figDesc>def get_smoothed_labels(event_label_patient, smoothing_fn, h_true, h_min, h_max, **kwargs): # Find when event label changes diffs = np.concatenate([np.zeros(1), event_label_patient[1:] -event_label_patient[:-1]], axis=-1) pos_event_change = np.where((diffs == 1) &amp; (event_label_patient == 1))[0] # Handle patient with no events if len(pos_event_change) == 0: pos_event_change = np.array([np.inf]) # Compute distance to closest event for each time point time_array = np.arange(len(event_label_patient)) dist_all_event = pos_event_change.reshape(-1, 1) -time_array dist_to_closest = np.where(dist_all_event &gt; 0, dist_all_event, np.inf).min(axis=0) return smoothing_fn(dist_to_closest, h_true=h_true, h_min=h_min, h_max=h_max, **kwargs) Temporal label smoothing algorithm. Python-style code to obtain smooth early prediction labels from event labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>D. 2</head><label>2</label><figDesc>Timestep-based metrics for other tasks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 13 :</head><label>13</label><figDesc>Precision-recall curves, for two additional tasks. Inset shows the clinically-applicable region with precision greater than 0.5. True negative rate (TNR).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>True positive rate (TPR).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 14 :</head><label>14</label><figDesc>Performance improvement over time for TLS over traditional cross-entropy on decompensation prediction. Timestep-level metrics computed for a precision of 0.5 over two-hour bins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 15 :</head><label>15</label><figDesc>True positive rate (TPR) Performance improvement over time for TLS over traditional cross-entropy on respiratory failure prediction. Timestep-level metrics computed for a precision of 0.5 over two-hour bins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 16 :</head><label>16</label><figDesc>Performance loss with class reweighting methods, on validation set. Balanced crossentropy corresponds to ? = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Figure 17 :</head><label>17</label><figDesc>Class reweigthing impact on AUPRC. Class reweighting does not improve AUPRC because it significantly reduces precision. Balance weights correspond to b(c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 19 :</head><label>19</label><figDesc>AUPRC performance of temporal label smoothing combined with weighted crossentropy. (Left) Test set performance. (Right) Validation set performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Related work. Comparison to different training objectives for binary early prediction tasks. y ? {0, 1} corresponds to a sample's true label at time t and? ? [0, 1] to the model's prediction.</figDesc><table><row><cell>Related work</cell><cell>Temporal inductive bias</cell><cell>Computationally Impacts sample scalable optimum</cell><cell>Loss for class c ? {0, 1}</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>? 0.4 29.3 ? 0.9 34.5 ? 0.4 28.2 ? 0.5 60.5 ? 0.2 77.3 ? 0.5 Label Smoothing</figDesc><table><row><cell>Task</cell><cell cols="2">Circulatory Failure</cell><cell cols="2">Decompensation</cell><cell cols="2">Respiratory Failure</cell></row><row><cell>Method</cell><cell>AUPRC</cell><cell>Recall</cell><cell>AUPRC</cell><cell>Recall</cell><cell>AUPRC</cell><cell>Recall</cell></row><row><cell>Cross-entropy</cell><cell>39.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Do MHP's multiple outputs improve performance over TLS with q step ? We provide p-values for the paired Student-t test [37] on the null hypothesis H 0 : ? M HP ? ? step . With no statistically significant improvements (p &lt; 0.05), we justify our assumption in Proposition 1. ? 0.5 30.3 ? 1.0 34.9 ? 0.3 28.6 ? 0.5 60.3 ? 0.1 76.6 ? 0.5 TLS (? step ) 39.3 ? 0.2 29.4 ? 0.8 35.2 ? 0.3 29.2 ? 0.4 60.5 ? 0.1 77.4 ? 0.5</figDesc><table><row><cell>Task</cell><cell cols="2">Circulatory Failure</cell><cell cols="2">Decompensation</cell><cell cols="2">Respiratory Failure</cell></row><row><cell>Method</cell><cell>AUPRC</cell><cell>Recall</cell><cell>AUPRC</cell><cell>Recall</cell><cell>AUPRC</cell><cell>Recall</cell></row><row><cell cols="2">MHP 39.6 p-value (H0) 0.11</cell><cell>0.10</cell><cell>0.95</cell><cell>0.97</cell><cell>0.99</cell><cell>0.98</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Case 2: d e (i, t) &gt; h H . Similarly, if d e (i, t) &gt; h H , then y h H i,t = 0 which implies y hc i,t = 0, ?c ? 1, H from Equation 8. The objective can be rewritten as:</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Performance of different smoothing functions on early prediction tasks. Recall is reported at a 50% precision.</figDesc><table><row><cell>Task</cell><cell cols="2">Circulatory Failure</cell><cell cols="2">Decompensation</cell><cell cols="2">Respiratory Failure</cell></row><row><cell>Method</cell><cell>AUPRC</cell><cell>Recall</cell><cell>AUPRC</cell><cell>Recall</cell><cell>AUPRC</cell><cell>Recall</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Event prevalence analysis, highlighting class imbalance. Positive timesteps are counted for 12-hour and 24-hour horizons for HiRID tasks and decompensation respectively. Statistics are computed on the training set.</figDesc><table><row><cell>Task</cell><cell>Positive timesteps (%)</cell><cell cols="2">Patients undergoing Number of events event (%) per positive patient</cell></row><row><cell>Circulatory Failure (HiRID)</cell><cell>4.3</cell><cell>25.6</cell><cell>1.9</cell></row><row><cell>Respiratory Failure (HiRID)</cell><cell>38.6</cell><cell>83.0</cell><cell>1.8</cell></row><row><cell>Decompensation (MIMIC)</cell><cell>2.1</cell><cell>8.3</cell><cell>1.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Hyperparameter search range for circulatory failure with GRU<ref type="bibr" target="#b32">[33]</ref> backbone. In bold are parameters selected by random search.</figDesc><table><row><cell>Hyperparameter</cell><cell>Values</cell></row><row><cell>Learning Rate</cell><cell>(1e-5, 3e-5, 1e-4, 3e-4)</cell></row><row><cell>Drop-out</cell><cell>(0.0, 0.1, 0.2, 0.3, 0.4)</cell></row><row><cell>Depth</cell><cell>(1, 2, 3)</cell></row><row><cell>Hidden Dimension</cell><cell>(32, 64, 128, 256)</cell></row><row><cell>L1 Regularization</cell><cell>(1e-2, 1e-1, 1, 10)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Hyperparameter search range for respiratory failure with Transformer<ref type="bibr" target="#b33">[34]</ref> backbone. In bold are parameters selected by random search.</figDesc><table><row><cell>Hyperparameter</cell><cell>Values</cell></row><row><cell>Learning Rate</cell><cell>(1e-5, 3e-5, 1e-4, 3e-4)</cell></row><row><cell>Drop-out</cell><cell>(0.0, 0.1, 0.2, 0.3, 0.4)</cell></row><row><cell cols="2">Attention Drop-out (0.0, 0.1, 0.2, 0.3, 0.4)</cell></row><row><cell>Depth</cell><cell>(1, 2, 3)</cell></row><row><cell>Heads</cell><cell>(1, 2, 4)</cell></row><row><cell>Hidden Dimension</cell><cell>(32, 64, 128, 256)</cell></row><row><cell>L1 Regularization</cell><cell>(1e-2, 1e-1, 1, 10)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Hyperparameter search range for decompensation with Transformer [34] backbone. In bold are parameters selected by random search.</figDesc><table><row><cell>Hyperparameter</cell><cell>Values</cell></row><row><cell>Learning Rate</cell><cell>(1e-5, 3e-5, 1e-4, 3e-4)</cell></row><row><cell>Drop-out</cell><cell>(0.0, 0.1, 0.2, 0.3, 0.4)</cell></row><row><cell cols="2">Attention Drop-out (0.0, 0.1, 0.2, 0.3, 0.4)</cell></row><row><cell>Depth</cell><cell>(1, 2, 3)</cell></row><row><cell>Heads</cell><cell>(1, 2, 4)</cell></row><row><cell>Hidden Dimension</cell><cell>(32, 64, 128, 256)</cell></row><row><cell>L1 Regularization</cell><cell>(1e-2, 1e-1, 1, 10)</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">All code is made publicly available at https://anonymous.4open.science/r/tls/.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">t e ? h H t e ? h k + 1 t e ? h k t e ? h 1 t e t 0</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An overview of clinical decision support systems: benefits, risks, and strategies for success</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pincock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baumgart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">N</forename><surname>Sadowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><forename type="middle">I</forename><surname>Fedorak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kroeker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ digital medicine</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The potential predictability of fire danger provided by numerical weather prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Di Giuseppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Pappenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fredrik</forename><surname>Wetterhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blazej</forename><surname>Krzeminski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Camia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Libert?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesus</forename><forename type="middle">San</forename><surname>Miguel</surname></persName>
		</author>
		<idno type="DOI">10.1175/JAMC-D-15-0297.1</idno>
		<ptr target="https://journals.ametsoc.org/view/journals/apme/55/11/jamc-d-15-0297.1.xml" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Meteorology and Climatology</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2469" to="2491" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The ability of the national early warning score (news) to discriminate patients at risk of early cardiac arrest, unanticipated intensive care unit admission, and death</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Prytherch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">E</forename><surname>Meredith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">I</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Featherstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Resuscitation</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="465" to="470" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Implementation of the national early warning score in patients with suspicion of sepsis: evaluation of a system-wide quality improvement project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Pullyblank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alison</forename><surname>Tavar?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Redfern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Hein Le Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Inada-Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Cheema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of General Practice</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">695</biblScope>
			<biblScope unit="page" from="381" to="388" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Development and validation of an electronic health record-based machine learning model to estimate delirium risk in newly hospitalized patients without known cognitive impairment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><forename type="middle">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">April</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Gonzales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vanja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dexter</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hadley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA network open</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="181018" to="181018" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Lisep lstm: a machine learning algorithm for early detection of septic shock</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Fagerstr?m</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magnus</forename><surname>B?ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Wilhelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><forename type="middle">S</forename><surname>Chew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Early prediction of circulatory failure in the intensive care unit using machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Stephanie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Hyland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Faltys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinrui</forename><surname>H?ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Crist?bal</forename><surname>Gumbsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Esteban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Bock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Moor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rieck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature medicine</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="364" to="373" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A clinically applicable approach to continuous prediction of future acute kidney injury</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenad</forename><surname>Toma?ev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Jack W Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harry</forename><surname>Zielinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Askham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Saraiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Mottram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suman</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Ravuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Protsyuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">572</biblScope>
			<biblScope unit="issue">7767</biblScope>
			<biblScope unit="page" from="116" to="119" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Set functions for time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Moor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Rieck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="http://proceedings.mlr.press/v119/horn20a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="4353" to="4363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-time attention networks for irregularly sampled time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">M</forename><surname>Satya Narayan Shukla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marlin</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=4c0J6lwQ4_" />
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Monitor alarm fatigue: an integrative review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Cvach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomedical instrumentation &amp; technology</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="268" to="277" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Alarm fatigue: a patient safety concern</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sue</forename><surname>Sendelbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjorie</forename><surname>Funk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AACN advanced critical care</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="378" to="386" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2016.308</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2016.308" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016-06-27" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Machine learning applications in cancer prognosis and prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantina</forename><surname>Kourou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Themis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><forename type="middle">P</forename><surname>Exarchos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michalis</forename><forename type="middle">V</forename><surname>Exarchos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><forename type="middle">I</forename><surname>Karamouzis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fotiadis</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.csbj.2014.11.005.URLhttps:/www.sciencedirect.com/science/article/pii/S2001037014000464</idno>
		<idno>2001-0370</idno>
		<ptr target="https://doi.org/10.1016/j.csbj.2014.11.005.URLhttps://www.sciencedirect.com/science/article/pii/S2001037014000464" />
	</analytic>
	<monogr>
		<title level="j">Computational and Structural Biotechnology Journal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="8" to="17" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Comparison and development of machine learning tools in the prediction of chronic kidney disease progression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiulin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haochen</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhui</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sibo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibin</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of translational medicine</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to detect sepsis with a multitask gaussian process RNN classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Futoma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Heller</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="http://proceedings.mlr.press/v70/futoma17a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>Doina Precup and Yee Whye Teh</editor>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-11" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1174" to="1182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Regression models and life-tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Cox</surname></persName>
		</author>
		<idno>00359246</idno>
		<ptr target="http://www.jstor.org/stable/2985181" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="220" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Logistic regression in rare events data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Langche</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political analysis</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="163" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Y?che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>H?ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinrui</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Faltys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>R?tsch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.08536</idno>
		<title level="m">Hirid-icu-benchmark-a comprehensive machine learning benchmark on high-resolution icu data</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Polyloss: A polynomial expansion perspective of classification loss functions. CoRR, abs/2204.12511</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoqi</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin</forename><surname>Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2204.12511</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2204.12511" />
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Disability prediction in multiple sclerosis using performance outcome measures and demographic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhrajit</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mincu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Proleev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Negar</forename><surname>Rostamzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chintan</forename><surname>Ghate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Schrouff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenad</forename><surname>Toma?ev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fletcher</forename><forename type="middle">Lee</forename><surname>Hartsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Health, Inference, and Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022" />
			<biblScope unit="page" from="375" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Use of deep learning to develop continuous-risk models for adverse event prediction from electronic health records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenad</forename><surname>Toma?ev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastien</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Mottram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Jack W Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harry</forename><surname>Zielinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Askham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saraiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Valerio Magliulo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Protocols</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2765" to="2787" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multitask prediction of organ dysfunction in the intensive care unit using sequential subnetwork routing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhrajit</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mincu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Loreaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Mottram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Protsyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Schrouff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugh</forename><surname>Montgomery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Connell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1936" to="1946" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">When does label smoothing help</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/hash/f1748d6b0fd9d439f71450117eba2725-Abstract.html" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<editor>Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d&apos;Alch?-Buc, Emily B. Fox, and Roman Garnett</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08" />
			<biblScope unit="page" from="4696" to="4705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Does label smoothing mitigate label noise?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinadh</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="http://proceedings.mlr.press/v119/lukasik20a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="6448" to="6458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Regularization via structural label smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautam</forename><surname>Dasarathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Visar</forename><surname>Berisha</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="http://proceedings.mlr.press/v108/li20e.html" />
	</analytic>
	<monogr>
		<title level="m">The 23rd International Conference on Artificial Intelligence and Statistics</title>
		<editor>Silvia Chiappa and Roberto Calandra</editor>
		<meeting><address><addrLine>Online [Palermo, Sicily, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-08-28" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="1453" to="1463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generalized entropy regularization or: There&apos;s nothing special about label smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Meister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Salesky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.615</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.acl-main.615" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel R. Tetreault</editor>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">From label smoothing to label relaxation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Lienen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyke</forename><surname>H?llermeier</surname></persName>
		</author>
		<ptr target="https://ojs.aaai.org/index.php/AAAI/article/view/17041" />
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8583" to="8591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Evaluating progress on machine learning for longitudinal electronic healthcare data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bellamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew L</forename><surname>Beam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.01149</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multitask learning and benchmarking with clinical time series data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrayr</forename><surname>Harutyunyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrant</forename><surname>Khachatrian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">Ver</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aram</forename><surname>Steeg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Galstyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mimic-iii, a freely accessible critical care database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Alistair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Wei H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengling</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><forename type="middle">Anthony</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger G</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling. CoRR, abs/1412</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?aglar</forename><surname>G?l?ehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.3555" />
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3555</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<editor>Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett</editor>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The precision-recall plot is more informative than the roc plot when evaluating binary classifiers on imbalanced datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaya</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Rehmsmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">118432</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The probable error of a mean</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Student</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="1908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Optimizing early warning classifiers to control false alarms via a minimum precision constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preetish</forename><surname>Rath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hughes</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v151/rath22a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 25th International Conference on Artificial Intelligence and Statistics</title>
		<editor>Francisco J. R. Ruiz, and Isabel Valera</editor>
		<meeting>The 25th International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2022-03-30" />
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="4895" to="4914" />
		</imprint>
	</monogr>
	<note>Gustau Camps-Valls</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Unified focal loss: Generalising dice and cross entropy-based losses to handle class imbalanced medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evis</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carola-Bibiane</forename><surname>Sch?nlieb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Rundo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page">102026</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A flexible growth function for empirical use</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fj Richards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental Botany</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="290" to="301" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Modelling survival data in medical research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Collett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dynamic prediction in clinical survival analysis using temporal convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsung</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihaela</forename><surname>Van Der Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE journal of biomedical and health informatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="424" to="436" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, highperformance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<ptr target="http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P?ter</forename><surname>Nvidia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><forename type="middle">H P</forename><surname>Vingelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fitzek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cuda</surname></persName>
		</author>
		<idno>release: 10.2.89</idno>
		<ptr target="https://developer.nvidia.com/cuda-toolkit" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Chetlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Woolley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Vandermersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.0759</idno>
		<title level="m">Efficient primitives for deep learning</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">The gin-config Team. gin-config python packaged</title>
		<ptr target="https://github.com/google/gin-config" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
