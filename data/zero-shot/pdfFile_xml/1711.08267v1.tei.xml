<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GraphGAN: Graph Representation Learning with Generative Adversarial Nets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
							<email>wanghongwei55@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Wang</surname></persName>
							<email>csjiawang@comp.polyu.edu.hk</email>
							<affiliation key="aff2">
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialin</forename><surname>Wang</surname></persName>
							<email>wangjialin@hust.edu.cn</email>
							<affiliation key="aff3">
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Zhao</surname></persName>
							<email>csmiaozhao@comp.polyu.edu.hk</email>
							<affiliation key="aff2">
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
							<email>fuzzhang@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
							<email>xing.xie@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minyi</forename><surname>Guo</surname></persName>
							<email>myguo@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">GraphGAN: Graph Representation Learning with Generative Adversarial Nets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The goal of graph representation learning is to embed each vertex in a graph into a low-dimensional vector space. Existing graph representation learning methods can be classified into two categories: generative models that learn the underlying connectivity distribution in the graph, and discriminative models that predict the probability of edge existence between a pair of vertices. In this paper, we propose Graph-GAN, an innovative graph representation learning framework unifying above two classes of methods, in which the generative model and discriminative model play a game-theoretical minimax game. Specifically, for a given vertex, the generative model tries to fit its underlying true connectivity distribution over all other vertices and produces "fake" samples to fool the discriminative model, while the discriminative model tries to detect whether the sampled vertex is from ground truth or generated by the generative model. With the competition between these two models, both of them can alternately and iteratively boost their performance. Moreover, when considering the implementation of generative model, we propose a novel graph softmax to overcome the limitations of traditional softmax function, which can be proven satisfying desirable properties of normalization, graph structure awareness, and computational efficiency. Through extensive experiments on real-world datasets, we demonstrate that Graph-GAN achieves substantial gains in a variety of applications, including link prediction, node classification, and recommendation, over state-of-the-art baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Graph representation learning, also known as network embedding, aims to represent each vertex in a graph (network) as a low-dimensional vector, which could facilitate tasks of network analysis and prediction over vertices and edges. Learned embeddings are capable to benefit a wide range of real-world applications such as link prediction <ref type="bibr" target="#b6">(Gao, Denoyer, and Gallinari 2011)</ref>, node classification <ref type="bibr" target="#b24">(Tang, Aggarwal, and Liu 2016)</ref>, recommendation <ref type="bibr" target="#b33">(Yu et al. 2014)</ref>, visualization <ref type="bibr" target="#b17">(Maaten and Hinton 2008)</ref>, knowledge graph representation <ref type="bibr" target="#b14">(Lin et al. 2015)</ref>, clustering <ref type="bibr" target="#b27">(Tian et al. 2014</ref>), text embedding , and social network analysis . Recently, researchers have examined applying representation learning methods to various types of graphs, such as weighted graphs <ref type="bibr" target="#b9">(Grover and Leskovec 2016)</ref>, directed graphs <ref type="bibr" target="#b36">(Zhou et al. 2017)</ref>, signed graphs , heterogeneous graphs <ref type="bibr" target="#b31">(Wang et al. 2018)</ref>, and attributed graphs <ref type="bibr" target="#b10">(Huang, Li, and Hu 2017)</ref>. In addition, several prior works also try to preserve specific properties during the learning process, such as global structures <ref type="bibr" target="#b32">(Wang, Cui, and Zhu 2016)</ref>, community structures <ref type="bibr" target="#b30">(Wang et al. 2017c</ref>), group information <ref type="bibr" target="#b2">(Chen, Zhang, and Huang 2016)</ref>, and asymmetric transitivity <ref type="bibr" target="#b20">(Ou et al. 2016)</ref>.</p><p>Arguably, most existing methods of graph representation learning can be classified into two categories. The first is generative graph representation learning model <ref type="bibr" target="#b21">(Perozzi, Al-Rfou, and Skiena 2014;</ref><ref type="bibr" target="#b9">Grover and Leskovec 2016;</ref><ref type="bibr" target="#b36">Zhou et al. 2017;</ref><ref type="bibr" target="#b5">Dong, Chawla, and Swami 2017;</ref><ref type="bibr" target="#b11">Li et al. 2017a</ref>). Similar to classic generative models such as Gaussian Mixture Model <ref type="bibr" target="#b15">(Lindsay 1995)</ref> or Latent Dirichlet Allocation <ref type="bibr" target="#b0">(Blei, Ng, and Jordan 2003)</ref>, generative graph representation learning models assume that, for each vertex v c , there exists an underlying true connectivity distribution p true (v|v c ), which implies v c 's connectivity preference (or relevance distribution) over all other vertices in the graph. The edges in the graph can thus be viewed as observed samples generated by these conditional distributions, and these generative models learn vertex embeddings by maximizing the likelihood of edges in the graph. For example, DeepWalk <ref type="bibr" target="#b21">(Perozzi, Al-Rfou, and Skiena 2014)</ref> uses random walk to sample "context" vertices for each vertex, and tries to maximize the log-likelihood of observing context vertices for the given vertex. Node2vec <ref type="bibr" target="#b9">(Grover and Leskovec 2016)</ref> further extends the idea by proposing a biased random walk procedure, which provides more flexibility when generating the context for a given vertex.</p><p>The second kind of graph representation learning method is the discriminative model <ref type="bibr" target="#b31">(Wang et al. 2018;</ref><ref type="bibr" target="#b1">Cao, Lu, and Xu 2016;</ref><ref type="bibr" target="#b32">Wang, Cui, and Zhu 2016;</ref><ref type="bibr" target="#b12">Li et al. 2017b</ref>). Different from generative models, discriminative graph representation learning models do not treat edges as generated from an underlying conditional distribution, but aim to learn a classifier for predicting the existence of edges directly. Typically, discriminative models consider two vertices v i and v j jointly as features, and predict the probability of an edge existing between the two vertices, i.e., p edge|(v i , v j ) , based on the training data in the graph. For instance, SDNE <ref type="bibr" target="#b32">(Wang, Cui, and Zhu 2016)</ref> uses the sparse adjacency vector of vertices as raw features for each vertex, and applies an autoencoder to extract short and condense features for vertices under the supervision of edge existence. PPNE <ref type="bibr" target="#b12">(Li et al. 2017b)</ref> directly learns vertex embeddings with supervised learning on positive samples (connected vertex pairs) and negative samples (disconnected vertex pairs), also preserving the inherent properties of vertices during the learning process.</p><p>Although generative and discriminative models are generally two disjoint classes of graph representation learning methods, they can be considered two sides of the same coin ). In fact, LINE  has done a preliminary trial on implicitly combining these two objectives (the first-order and second-order proximity, as called in LINE). Recently, Generative Adversarial Nets (GAN) <ref type="bibr">(Goodfellow et al. 2014)</ref> have received a great deal of attention. By designing a game-theoretical minimax game to combine generative and discriminative models, GAN and its variants achieve success in various applications, such as image generation <ref type="bibr" target="#b4">(Denton et al. 2015)</ref>, sequence generation <ref type="bibr" target="#b34">(Yu et al. 2017)</ref>, dialogue generation <ref type="bibr" target="#b13">(Li et al. 2017c</ref>), information retrieval , and domain adaption <ref type="bibr" target="#b35">(Zhang, Barzilay, and Jaakkola 2017)</ref>.</p><p>Inspired by GAN, in this paper we propose GraphGAN, a novel framework that unifies generative and discriminative thinking for graph representation learning. Specifically, we aim to train two models during the learning process of GraphGAN: 1) Generator G(v|v c ), which tries to fit the underlying true connectivity distribution p true (v|v c ) as much as possible, and generates the most likely vertices to be connected with v c ; 2) Discriminator D(v, v c ), which tries to distinguish well-connected vertex pairs from ill-connected ones, and calculates the probability of whether an edge exists between v and v c . In the proposed GraphGAN, the generator G and the discriminator D act as two players in a minimax game: the generator tries to produce the most indistinguishable "fake" vertices under guidance provided by the discriminator, while the discriminator tries to draw a clear line between the ground truth and "counterfeits" to avoid being fooled by the generator. Competition in this game drives both of them to improve their capability, until the generator is indistinguishable from the true connectivity distribution.</p><p>Under the GraphGAN framework, we study the choices of generator and discriminator. Unfortunately, we find that the traditional softmax function (and its variants) is not suitable for the generator for two reasons: 1) softmax treats all other vertices in the graph equally for a given vertex, lacking the consideration on graph structure and proximity information; 2) the calculation of softmax involves all vertices in the graph, which is time-consuming and computationally inefficient. To overcome these limitations, in GraphGAN we propose a new implementation of generator called Graph Softmax. Graph softmax provides a new definition of connectivity distribution in a graph. We prove graph softmax satisfying desirable properties of normalization, graph structure awareness, and computational efficiency. Accordingly, we propose a random-walk-based online generating strategy for generator, which is consistent with the definition of graph softmax and can greatly reduce computation complexity.</p><p>Empirically, we apply GraphGAN to three real-world scenarios, i.e., link prediction, node classification, and recommendation, using five real-world graph-structured datasets. The experiment results show that GraphGAN achieves substantial gains compared with state-of-the-art baselines in the field of graph representation learning. Specifically, Graph-GAN outperforms baselines by 0.59% to 11.13% in link prediction and by 0.95% to 21.71% in node classification both on Accuracy. Additionally, GraphGAN improves Pre-cision@20 by at least 38.56% and Recall@20 by at least 52.33% in recommendation. We attribute the superiority of GraphGAN to its unified adversarial learning framework as well as the design of the proximity-aware graph softmax that naturally captures structural information from graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Generative Adversarial Nets</head><p>In this section, we introduce the framework of GraphGAN and discuss the details of implementation and optimization of the generator and the discriminator. We then present the graph softmax implemented as the generator, and prove its superior properties over the traditional softmax function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GraphGAN Framework</head><p>We formulate the generative adversarial nets for graph representation learning as follows. Let G = (V, E) be a given graph, where V = {v 1 , ..., v V } represents the set of vertices and E = {e ij } V i,j=1 represents the set of edges. For a given vertex v c , we define N (v c ) as the set of vertices directly connected to v c , the size of which is typically much smaller than the total number of vertices V . We denote the underlying true connectivity distribution for vertex v c as conditional probability p true (v|v c ), which reflects v c 's connectivity preference distribution over all other vertices in V. From this point of view, N (v c ) can be seen as a set of observed samples drawn from p true (v|v c ). Given the graph G, we aim to learn the following two models:</p><p>Generator G(v|v c ; ? G ), which tries to approximate the underlying true connectivity distribution p true (v|v c ), and generates (or selects, if more precise) the most likely vertices to be connected with v c from vertex set V.</p><p>Discriminator D(v, v c ; ? D ), which aims to discriminate the connectivity for the vertex pair (v, v c ). D(v, v c ; ? D ) outputs a single scalar representing the probability of an edge existing between v and v c .</p><p>Generator G and discriminator D act as two opponents: generator G would try to fit p true (v|v c ) perfectly and generate relevant vertices similar to v c 's real immediate neighbors to deceive the discriminator, while discriminator D, on the contrary, would try to detect whether these vertices are ground-truth neighbors of v c or the ones generated by its counterpart G. Formally, G and D are playing the following two-player minimax game with value function V (G, D):</p><formula xml:id="formula_0">min ? G max ? D V (G, D) = V c=1 E v?ptrue(?|vc) log D(v, v c ; ? D ) + E v?G(?|vc;? G ) log 1 ? D(v, v c ; ? D ) .</formula><p>(1) Based on Eq.</p><p>(1), the optimal parameters of the generator and the discriminator can be learned by alternately maximizing and minimizing the value function V (G, D). The GraphGAN framework is illustrated as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. In each iteration, discriminator D is trained with positive samples from p true (?|v c ) (vertices in green) and negative samples from generator G(?|v c ; ? G ) (vertices with blue stripes), and generator G is updated with policy gradient under the guidance of D (detailed later in this section). Competition between G and D drives both of them to improve their methods until G is indistinguishable from the true connectivity distribution. We discuss the implementation and optimization of D and G as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discriminator Optimization</head><p>Given positive samples from true connectivity distribution and negative samples from the generator, the objective for the discriminator is to maximize the log-probability of assigning the correct labels to both positive and negative samples, which could be solved by stochastic gradient ascent if D is differentiable with respect to ? D . In GraphGAN, we define D as the sigmoid function of the inner product of two input vertices:</p><formula xml:id="formula_1">D(v, v c ) = ?(d v d vc ) = 1 1 + exp(?d v d vc ) ,<label>(2)</label></formula><p>where d v , d vc ? R k are the k-dimensional representation vectors of vertices v and v c respectively for discriminator D, and ? D is the union of all d v 's. Any discriminative model can serve as D here such as SDNE <ref type="bibr" target="#b32">(Wang, Cui, and Zhu 2016)</ref>, and we leave the further study of choice of discriminator for future work. Note that Eq.</p><p>(2) simply involves v and v c , which indicates that given a sample pair (v, v c ), we need to update only d v and d vc by ascending the gradient with respect to them:</p><formula xml:id="formula_2">? ? D V (G, D) = ? ? D log D(v, v c ), if v ? p true ; ? ? D 1 ? log D(v, v c ) , if v ? G.<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generator Optimization</head><p>In contrast to discriminator, the generator aims to minimize the log-probability that the discriminator correctly assigns negative labels to the samples generated by G. In other words, the generator shifts its approximated connectivity distribution (through its parameters ? G ) to increase the scores of its generated samples, as judged by D. Because the sampling of v is discrete, following <ref type="bibr" target="#b23">(Schulman et al. 2015;</ref><ref type="bibr" target="#b34">Yu et al. 2017)</ref>, we propose computing the gradient of V (G, D) with respect to ? G by policy gradient:</p><formula xml:id="formula_3">? ? G V (G, D) =? ? G V c=1 E v?G(?|vc) log 1 ? D(v, v c ) = V c=1 N i=1 ? ? G G(v i |v c ) log 1 ? D(v i , v c ) = V c=1 N i=1 G(v i |v c )? ? G log G(v i |v c ) log 1 ? D(v i , v c ) = V c=1 E v?G(?|vc) ? ? G log G(v|v c ) log 1 ? D(v, v c ) .<label>(4)</label></formula><p>To understand the above formula, it is worth noting that</p><formula xml:id="formula_4">gradient ? ? G V (G, D) is an expected summation over the gradients ? ? G log G(v|v c ; ? G ) weighted by log-probability log 1?D(v, v c ; ? D )</formula><p>, which, intuitively speaking, indicates that vertices with a higher probability of being negative samples will "tug" generator G stronger away from themselves, since we apply gradient descent on ? G . We now discuss the implementation of G. A straightforward way is to define the generator as a softmax function over all other vertices ), i.e.,</p><formula xml:id="formula_5">G(v|v c ) = exp(g v g vc ) v =vc exp(g v g vc ) ,<label>(5)</label></formula><p>where g v , g vc ? R k are the k-dimensional representation vectors of vertex v and v c respectively for generator G, and ? G is the union of all g v 's. Under this setting, to update ? G in each iteration, we calculate the approximated connectivity distribution G(v|v c ; ? G ) based on Eq. <ref type="formula" target="#formula_5">(5)</ref>, draw a set of samples (v, v c ) randomly according to G, and update ? G by stochastic gradient descent. Softmax provides a concise and intuitive definition for the connectivity distribution in G, but it has two limitations in graph representation learning: 1) The calculation of softmax in Eq. (5) involves all vertices in the graph, which implies that for each generated sample v, we need to calculate gradients ? ? G log G(v|v c ; ? G ) and update all vertices. This is computationally inefficient, especially for real-world large-scale graphs with millions of vertices.</p><p>2) The graph structure encodes rich information of proximity among vertices, but softmax completely ignores the utilization of structural information from graphs as it treats vertices without any discrimination. Recently, hierarchical softmax <ref type="bibr" target="#b19">(Morin and Bengio 2005)</ref> and negative sampling <ref type="bibr" target="#b18">(Mikolov et al. 2013)</ref> are popular alternatives to softmax. Although these methods can alleviate the computation to some extent, neither of them considers structural information of a graph, thereby being unable to achieve satisfactory performance when applied to graph representation learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Softmax for Generator</head><p>To address the aforementioned problems, in GraphGAN we propose a new alternative to softmax for the generator called graph softmax. The key idea of graph softmax is to define a new method of computing connectivity distribution in generator G(?|v c ; ? G ) that satisfies the following three desirable properties:</p><p>? Normalized. The generator should produce a valid probability distribution, i.e., v =vc G(v|v c ; ? G ) = 1.</p><p>? Graph-structure-aware. The generator should take advantage of the structural information of a graph to approximate the true connectivity distribution. Intuitively, for two vertices in a graph, their connectivity probability should decline with the increase of their shortest distance. ? Computationally efficient. Distinguishable from full softmax, the computation of G(v|v c ; ? G ) should only involve a small number of vertices in the graph. We discuss graph softmax in detail as follows. To calculate the connectivity distribution G(?|v c ; ? G ), we first perform Breadth First Search (BFS) on the original graph G starting from vertex v c , which provides us with a BFS-tree T c rooted at v c . Given T c , we denote N c (v) as the set of neighbors of v (i.e., vertices that are directly connected to v) in T c , including its parent vertex and all child vertices if exist. For a given vertex v and one of its neighbors v i ? N c (v), we define the relevance probability of v i given v as</p><formula xml:id="formula_6">p c (v i |v) = exp(g vi g v ) vj ?Nc(v) exp(g vj g v ) ,<label>(6)</label></formula><p>which is actually a softmax function over N c (v). To calculate G(v|v c ; ? G ), note that each vertex v can be reached by a unique path from the root v c in T c . Denote the path as</p><formula xml:id="formula_7">P vc?v = (v r0 , v r1 , ..., v rm ) where v r0 = v c and v rm = v.</formula><p>Then the graph softmax defines G(v|v c ; ? G ) as follows:</p><formula xml:id="formula_8">G(v|v c ) m j=1 p c (v rj |v rj?1 ) ? p c (v rm?1 |v rm ),<label>(7)</label></formula><p>where p c (?|?) is the relevance probability defined in Eq. (6). We prove that our proposed graph softmax satisfies the above three properties, i.e., graph softmax is normalized, graph-structure-aware, and computationally efficient. Theorem 1.</p><p>v =vc G(v|v c ; ? G ) = 1 in graph softmax. Proof. Before proving the theorem, we first give a proposition as follows. Denote ST v as the sub-tree rooted at</p><formula xml:id="formula_9">v in T c (v = v c ). Then we have vi?STv G(v i |v c ) = m j=1 p c (v rj |v rj?1 ),<label>(8)</label></formula><p>where (v r0 , v r1 , ..., v rm ) is on the path P vc?v , v r0 = v c and v rm = v. The proposition can be proved by bottom-up induction on the BFS-tree T c :</p><formula xml:id="formula_10">? For each leaf vertex v, we have vi?STv G(v i |v c ; ? G ) = G(v|v c ; ? G ) = m j=1 p c (v rj |v rj?1 ) ? p c (v rm?1 |v rm ) = m j=1 p c (v rj |v rj?1 )</formula><p>. The last step is due to the fact that leaf vertex v has only one neighbor (parent vertex v rm?1 ), therefore, p c (v rm?1 |v rm ) = p c (v rm?1 |v) = 1.</p><p>? For each non-leaf vertex v, we denote C c (v) as the set of children vertices of v in T c . By induction hypothesis, each children vertex v k ? C c (v) satisfies the proposition in Eq. </p><formula xml:id="formula_11">(8). Thus we have vi?STv G(v i |v c ) =G(v|v c ) + v k ?Cc(v) vi?STv k G(v i |v c ) = m j=1 p c (v rj |v rj?1 ) p c (v rm?1 |v rm ) + v k ?Cc(v) m j=1 p c (v rj |v rj?1 ) p c (v k |v rm ) = m j=1 p c (v rj |v rj?1 ) p c (v rm?1 |v) + v k ?Cc(v) p c (v k |v) = m j=1 p c (v rj |v rj?1 ).</formula><formula xml:id="formula_12">v =vc G(v|v c ; ? G ) = v k ?Cc(vc) v?STv k G(v|v c ; ? G ) = v k ?Cc(vc) p c (v k |v c ) = 1.</formula><p>Theorem 2. In graph softmax, G(v|v c ; ? G ) decreases exponentially with the increase of the shortest distance between v and v c in original graph G.</p><p>Proof. According to the definition of graph softmax, G(v|v c ; ? G ) is the product of m + 1 terms of relevance probability, where m is the length of path P vc?v . Note that m is also the shortest distance between v c and v in graph G, since BFS-tree T c preserves the shortest distances between v c and all other vertices in the original graph. Therefore, we conclude that G(v|v c ; ? G ) is exponentially proportional to the inverse of the shortest distance between v and v c in G.</p><p>Following Theorem 2, we further justify that graph softmax characterizes the real pattern of connectivity distribution precisely by conducting an empirical study in the experiment part. Theorem 3. In graph softmax, calculation of G(v|v c ; ? G ) depends on O(d log V ) vertices, where d is average degree of vertices and V is the number of vertices in graph G.</p><p>Proof. According to Eq. (6) and Eq. <ref type="formula" target="#formula_8">(7)</ref>, the calculation of G(v|v c ; ? G ) involves two types of vertices: vertices on the path P vc?v and vertices directly connected to the path (i.e., vertices whose distance from the path is 1). In general, the maximal length of the path is log V , which is the depth of the BFS-tree, and each vertex in the path is connected to d vertices on average. Therefore, the total number of involved vertices in G(v|v c ; ? G ) is O(d log V ).</p><p>Next, we discuss the generating (or sampling) strategy for generator G. A feasible way of generating vertices is to calculate G(v|v c ; ? G ) for all vertices v = v c , and perform random sampling proportionally to their approximated connectivity probabilities. Here we propose an online generating method, which is more computationally efficient and consistent with the definition of graph softmax. To generate a  <ref type="figure">Figure 2</ref>: Online generating strategy for generator G. The blue digits are the relevance probability p c (v i |v), and the blue solid arrow indicates the direction that G chooses to move in. Upon completion of sampling, the vertex with blue stripes is the sampled one, and all colored vertices in the rightmost tree require updating accordingly. if vi = vpre then 5:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Online generating strategy for the generator</head><p>vgen ? vcur; 6: return vgen 7: else 8:</p><p>vpre ? vcur, vcur ? vi; 9: end if 10: end while vertex, we perform a random walk starting at the root v c in T c with respect to the transition probability defined in Eq. (6). During the process of random walk, if the currently visited vertex is v and generator G decides to visit v's parent (i.e., turning around on the path) for the first time, then v is chosen as the generated vertex.</p><p>The online generating strategy for the generator is formally described in Algorithm 1. We denote the currently visited vertex as v cur and the previously visited one as v pre . Note that Algorithm 1 terminates in O(log V ) steps, since the random-walk path will turn around at the latest when reaching leaf vertices. Similar to the computation of graph softmax, the complexity of the above online generating method is O(d log V ), which is significantly lower than the offline method with a complexity of O(V ? d log V ). <ref type="figure">Figure 2</ref> gives an illustrative example of the generating strategy as well as the computation process of graph softmax. In each step of a random walk, a blue vertex v i is chosen out of all neighbors of v cur by random selection proportionally to the relevance probability p c (v i |v cur ) defined in Eq. (6). Once v i equals v pre , i.e., the random walk revisits v cur 's parent v pre , v cur would be sampled out (indicated as the vertex with blue stripes in the <ref type="figure">figure)</ref>, and all vertices along the path P vc?vcur as well as the vertices that are directly connected to this path need to be updated according to Eq. (4), (6) and <ref type="formula" target="#formula_8">(7)</ref>.</p><p>Finally, the overall logic of GraphGAN is summarized in Algorithm 2. We provide time complexity analysis of Graph-GAN as follows. The complexity of BFS-tree construction for all vertices in line 2 is O V (V + E) = O(dV 2 ) since the time complexity of BFS is O(V + E) <ref type="bibr" target="#b3">(Cormen 2009</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 GraphGAN framework</head><p>Require: dimension of embedding k, size of generating samples s, size of discriminating samples t Ensure: generator G(v|vc; ?G), discriminator D(v, vc; ?D) 1: Initialize and pre-train G(v|vc; ?G) and D(v, vc; ?D); 2: Construct BFS-tree Tc for all vc ? V; 3: while GraphGAN not converge do 4: for G-steps do 5:</p><p>G(v|vc; ?G) generates s vertices for each vertex vc according to Algorithm 1; 6:</p><p>Update ?G according to Eq. (4), (6) and <ref type="formula" target="#formula_8">(7)</ref>; 7:</p><p>end for 8:</p><p>for D-steps do 9:</p><p>Sample t positive vertices from ground truth and t negative vertices from G(v|vc; ?G) for each vertex vc; 10:</p><p>Update ?D according to Eq.</p><p>(2) and (3); 11: end for 12: end while 13: return G(v|vc; ?G) and D <ref type="bibr">(v, vc; ?D)</ref> In each iteration, the complexity of both line 5 and line 6 is O(sV ? d log V ? k), and the complexity of line 9 and line 10 is O(tV ? d log V ? k) and O(tV ? k), respectively. In general, if we treat k, s, t, and d as constants, the complexity of each iteration in GraphGAN is O(V log V ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In this section, we evaluate the performance of GraphGAN 1 on a series of real-world datasets. Specifically, we choose three application scenarios for experiments, i.e., link prediction, node classification, and recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Setup</head><p>We utilize the following five datasets in our experiments:</p><p>? arXiv-AstroPh 2 is from the e-print arXiv and covers scientific collaborations between authors with papers submitted to the Astro Physics category. The vertices represent authors and the edge indicates co-author relationship. This graph has 18,772 vertices and 198,110 edges. ? arXiv-GrQc 3 is also from arXiv and covers scientific collaborations between authors with papers submitted to the  <ref type="figure">Figure 3</ref>: The correlation between the probability of edge existence and the shortest distance for a given vertex pair.</p><p>General Relativity and Quantum Cosmology categories. This graph has 5,242 vertices and 14,496 edges. ? BlogCatalog 4 is a network of social relationships of the bloggers listed on the BlogCatalog website. The labels of vertices represent blogger interests inferred through the metadata provided by the bloggers. This graph has 10,312 vertices, 333,982 edges, and 39 different labels. ? Wikipedia 5 is a co-occurrence network of words appearing in the first 10 9 bytes of the Eglish Wikipedia dump. The labels represent the inferred Part-of-Speech (POS) tags of words. This graph has 4,777 vertices, 184,812 edges, and 40 different labels. ? MovieLens-1M 6 is a bipartite graph consisting of approximately 1 million ratings (edges) with 6,040 users and 3,706 movies in MovieLens website.</p><p>We compare our proposed GraphGAN with the following four baselines for graph representation learning:</p><p>? DeepWalk (Perozzi, Al-Rfou, and Skiena 2014) adopts random walk and Skip-Gram to learn vertex embeddings. ? LINE  preserves the first-order and second-order proximity among vertices in the graph. ? Node2vec (Grover and Leskovec 2016) is a variant of DeepWalk and designs a biased random walk to learn vertex embeddings. ? Struc2vec <ref type="bibr" target="#b22">(Ribeiro, Saverese, and Figueiredo 2017)</ref> captures the structural identity of vertices in a graph.</p><p>For all three experiment scenarios, we perform stochastic gradient descent to update parameters in GraphGAN with learning rate 0.001. In each iteration, we set s as 20 and t as the number of positive samples in the test set for each vertex, then run G-steps and D-steps for 30 times, respectively. The dimension of representation vectors k for all methods is set as 20. The above hyper-parameters are chosen by cross validation. The final learned vertex representations are g i 's. Parameter settings for all baselines are as default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Empirical Study</head><p>We conduct an empirical study to investigate the real pattern of connectivity distribution in graphs. Specifically, for a given vertex pair, we aim to reveal how the probability of edge existence changes with their shortest distance in the graph. To achieve this, we first randomly sample 1 million vertex pairs from arXiv-AstroPh and arXiv-GrQc datasets, respectively. For each selected vertex pair, we remove the edge between them if it exists (because it is treated as hidden ground truth), and calculate their shortest distance. We count the probability of edge existence for all possible shortest distances, and plot the results in <ref type="figure">Figure 3</ref> (the disconnected case is omitted). It is evident that the probability of edge existence between vertex pair drops dramatically with the increase of their shortest distance. We also plot the log probability curves in <ref type="figure">Figure 3</ref>, which generally trends towards linear decline with R 2 = 0.831 and 0.710. The above finding empirically demonstrates that the probability of edge existence between a pair of vertices is approximately exponentially proportional to the inverse of their shortest distance, which strongly proves that graph softmax captures the essence of real-world graphs according to Theorem 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Link Prediction</head><p>In link prediction, our goal is to predict whether there exists an edge between two given vertices. Therefore, this task shows the performance of edge predictability of different graph representation learning methods. We randomly hide 10% of edges in the original graph as ground truth, and use the left graph to train all graph representation learning models. After training, we obtain the representation vectors for all vertices and use logistic regression method to predict the probability of edge existence for a given vertex pair. Our test set consists of the hidden 10% vertex pairs (edges) in the original graph as the positive samples and randomly selected disconnected vertex pairs as negative samples with equal number. We use arXiv-AstroPh and arXiv-GrQc as datasets, and report the results of Accuracy and Macro-F1 in <ref type="table" target="#tab_2">Table 1</ref>. We have the following observations: 1) Performance of LINE and struc2vec is relatively poor in link prediction, as they cannot quite capture the pattern of edge existence in graphs. 2) DeepWalk and node2vec perform better than LINE and struc2vec. This is probably because Deep-Walk and node2vec both utilize the random-walk-based Skip-Gram model, which is better at extracting proximity information among vertices. 3) GraphGAN outperforms all the baselines in link prediction. Specifically, GraphGAN improves Accuracy on arXiv-AstroPh and arXiv-GrQc by 1.18% to 4.27% and 0.59% to 11.13%, respectively. Our explanation is that adversarial training provides GraphGAN a higher learning flexibility than the single-model training for baselines.</p><p>To intuitively understand the learning stability of Graph-GAN, we further illustrate the learning curves of the gener-  ator and the discriminator on arXiv-GrQc in <ref type="figure" target="#fig_3">Figure 4</ref>. From <ref type="figure" target="#fig_3">Figure 4</ref> we observe that the minimax game in GraphGAN arrives at an equilibrium where the generator performs outstandingly well after convergence, while performance of the discriminator boosts at first but gradually falls below 0.8. Note that the discriminator does not degrade to a randomguess level, because the generator still provides lots of true negative samples in practice. The result suggests that, different with IRGAN , the design of graph softmax enables the generator in GraphGAN to draw samples and learn vertex embeddings more efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Node Classification</head><p>In node classification, each vertex is assigned one or multiple labels. After we observe a fraction of vertices and their labels, we aim to predict labels for the remaining vertices. Therefore, the performance of node classification can reveal the distinguishability of vertices under different graph representation learning methods. To conduct the experiment, we train GraphGAN and baselines on the whole graph to obtain vertex representations, and use logistic regression as classifier to perform node classification with 9:1 train-test ratio. We use BlogCatalog and Wikipedia as datasets. The results of Accuracy and Macro-F1 are presented in <ref type="table" target="#tab_3">Table  2</ref>. As we can see, GraphGAN outperforms all baselines on both datasets. For example, GraphGAN achieves gains of 1.75% to 13.17% and 0.95% to 21.71% on Accuracy on two datasets, respectively. This indicates that though GraphGAN is directly designed to optimize the approximated connectivity distribution on edges, it can still effectively encode the information of vertices into the learned representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recommendation</head><p>We use Movielens-1M as dataset for recommendation. For each user, we aim to recommend a set of movies which have not been watched but may be liked by the user. We first treat all 4-star and 5-star ratings as edges to obtain a bipartite graph, then randomly hide 10% of edges in the original graph as the test set and construct a BFS-tree for each user. Note that different from the above two experiment scenarios where the connectivity distribution is defined on all other vertices for certain vertex, in recommendation the probability of connectivity for one user is only distributed over a fraction of vertices, i.e., all movies, in the graph. Therefore, we "shortcut" all user vertices in the BFS-tree (except the root) by adding direct edges within all movie pairs that are linked by a user vertex. After training and obtaining representations of users and movies, for each user, we select K of his unwatched movies with the highest inner product as the recommendation result. The results of Precision@K and Recall@K are shown in <ref type="figure" target="#fig_4">Figure 5</ref>, from which we can observe that GraphGAN is consistently above all baselines, and achieves statistically significant improvements on both metrics. Take Precision@20 as an example, GraphGAN outperforms DeepWalk, LINE, node2vec, and struc2vec by 38.56%, 59.60%, 124.95%, and 156.85%, respectively. Therefore, we can draw the conclusion that GraphGAN maintains a more decent performance in ranking-based tasks compared with other graph representation learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>In this paper, we propose GraphGAN that unifies two schools of graph representation learning methodologies, i.e., generative methods and discriminative methods, via adversarial training in a minimax game. Under the GraphGAN framework, both the generator and the discriminator could benefit from each other: the generator is guided by the signals from the discriminator and improves its generating performance, while the discriminator is pushed by the generator to better distinguish ground truth from generated samples. Moreover, we propose graph softmax as the implementation of the generator, which solves the inherent limitations of the traditional softmax. We conduct experiments on five real-world datasets in three scenarios, and the results demonstrate that GraphGAN significantly outperforms strong baselines in all experiments due to its adversarial framework and proximity-aware graph softmax.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of GraphGAN framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Learning curves of the generator and the discriminator of GraphGAN on arXiv-GrQc in link prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Precision@K and Recall@K on MovieLens-1M in recommendation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Accuracy and Macro-F1 on arXiv-AstroPh and arXiv-GrQc in link prediction.</figDesc><table><row><cell>Model</cell><cell cols="2">arXiv-AstroPh Acc Macro-F1</cell><cell cols="2">arXiv-GrQc Acc Macro-F1</cell></row><row><cell>DeepWalk</cell><cell>0.841</cell><cell>0.839</cell><cell>0.803</cell><cell>0.812</cell></row><row><cell>LINE</cell><cell>0.820</cell><cell>0.814</cell><cell>0.764</cell><cell>0.761</cell></row><row><cell>Node2vec</cell><cell>0.845</cell><cell>0.854</cell><cell>0.844</cell><cell>0.842</cell></row><row><cell>Struc2vec</cell><cell>0.821</cell><cell>0.810</cell><cell>0.780</cell><cell>0.776</cell></row><row><cell cols="2">GraphGAN 0.855</cell><cell>0.859</cell><cell>0.849</cell><cell>0.853</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Accuracy and Macro-F1 on BlogCatalog and Wikipedia in node classification.</figDesc><table><row><cell>Model</cell><cell cols="2">BlogCatalog Acc Macro-F1</cell><cell cols="2">Wikipedia Acc Macro-F1</cell></row><row><cell>DeepWalk</cell><cell>0.225</cell><cell>0.214</cell><cell>0.194</cell><cell>0.183</cell></row><row><cell>LINE</cell><cell>0.205</cell><cell>0.192</cell><cell>0.175</cell><cell>0.164</cell></row><row><cell>Node2vec</cell><cell>0.215</cell><cell>0.206</cell><cell>0.191</cell><cell>0.179</cell></row><row><cell>Struc2vec</cell><cell>0.228</cell><cell>0.216</cell><cell>0.211</cell><cell>0.190</cell></row><row><cell cols="2">GraphGAN 0.232</cell><cell>0.221</cell><cell>0.213</cell><cell>0.194</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/hwwang55/GraphGAN 2 https://snap.stanford.edu/data/ca-AstroPh.html 3 https://snap.stanford.edu/data/ca-GrQc.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://socialcomputing.asu.edu/datasets/BlogCatalog 5 http://www.mattmahoney.net/dc/textdata 6 https://grouplens.org/datasets/movielens/1m/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partially sponsored by the National Basic Research 973 Program of China under Grant 2015CB352403.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep neural networks for learning graph representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1145" to="1152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Incorporate group information to enhance network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1901" to="1904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Introduction to algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Cormen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep generative image models using a laplacian pyramid of adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1486" to="1494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">metap-ath2vec: Scalable representation learning for heterogeneous networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="135" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Temporal link prediction by integrating content and structure information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gallinari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1169" to="1174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Label informed attributed network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="731" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semi-supervised network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Database Systems for Advanced Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="131" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ppne: Property preserving network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Database Systems for Advanced Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="163" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06547</idno>
		<title level="m">Adversarial learning for neural dialogue generation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2181" to="2187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mixture models: theory, geometry and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">G</forename><surname>Lindsay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSF-CBMS regional conference series in probability and statistics</title>
		<imprint>
			<publisher>JSTOR</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page">163</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Aligning users across social networks using network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1774" to="1780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hierarchical probabilistic neural network language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Aistats</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="246" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Asymmetric transitivity preserving graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1105" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Saverese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Figueiredo</surname></persName>
		</author>
		<title level="m">struc2vec: Learning node representations from structural identity. In KDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="385" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gradient estimation using stochastic computation graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3528" to="3536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Node classification in signed social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 SIAM International Conference on Data Mining</title>
		<meeting>the 2016 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="54" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International World Wide Web Conferences Steering Committee</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
	<note>WWW</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pte: Predictive text embedding through large-scale heterogeneous text networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1165" to="1174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning deep representations for graph clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1293" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Irgan: A minimax game for unifying generative and discriminative information retrieval models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Signed network embedding in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 SIAM International Conference on Data Mining</title>
		<meeting>the 2017 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="327" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Community preserving network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="203" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Shine: Signed heterogeneous information network embedding for sentiment link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Structural deep network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1225" to="1234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Personalized entity recommendation: A heterogeneous information network approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sturt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Norick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="283" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Seqgan: Sequence generative adversarial nets with policy gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2852" to="2858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Aspectaugmented adversarial networks for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.00188</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Scalable graph embedding for asymmetric proximity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2942" to="2948" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
