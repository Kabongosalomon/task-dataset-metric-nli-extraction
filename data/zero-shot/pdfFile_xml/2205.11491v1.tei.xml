<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HyperTree Proof Search for Neural Theorem Proving</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amaury</forename><surname>Hayat</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Ebner</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aur?lien</forename><surname>Rodriguez</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timoth?e</forename><surname>Lacroix</surname></persName>
						</author>
						<title level="a" type="main">HyperTree Proof Search for Neural Theorem Proving</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose an online training procedure for a transformer-based automated theorem prover. Our approach leverages a new search algorithm, HyperTree Proof Search (HTPS), inspired by the recent success of AlphaZero. Our model learns from previous proof searches through online training, allowing it to generalize to domains far from the training distribution. We report detailed ablations of our pipeline's main components by studying performance on three environments of increasing complexity. In particular, we show that with HTPS alone, a model trained on annotated proofs manages to prove 65.4% of a held-out set of Metamath theorems, significantly outperforming the previous state of the art of 56.5% by GPT-f. Online training on these unproved theorems increases accuracy to 82.6%. With a similar computational budget, we improve the state of the art on the Lean-based miniF2F-curriculum dataset from 31% to 42% proving accuracy.</p><p>Automated theorem proving has been a long-standing goal of artificial intelligence, with the earliest work dating from the 1950s <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. Early approaches focused on simpler logics, culminating in extremely efficient first-order provers such as E <ref type="bibr" target="#b10">[11]</ref> or Vampire [12]. However, these approaches are insufficient when it comes to theorems written in modern proof assistants such as Isabelle [13], Coq [14], or Lean [4]. Recently, the rising success of deep language models [15] and model-guided search methods [7] has spurred a renewed interest in the problem of automated theorem proving.</p><p>Neural theorem provers. Recent work applying deep learning methods to theorem proving <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref> are the closest to this work and obtained impressive results on difficult held-out sets for Metamath and Lean. The main differences between their approach and ours are the proof-search algorithm we propose, the training data we extract from proof-searches and our use of online training compared to their expert iterations. We validate experimentally that these differences lead to improved performances as well as faster training times. Another similar approach is Holophrasm <ref type="bibr" target="#b18">[19]</ref>, which is based on a different tree exploration technique which expands paths in an AND/OR tree, while we expand entire proof subtrees in a proof hypergraph. Their model is only trained once from supervised data and does not benefit from online training or expert iteration, which we found to be critical. DeepHOL [20] focuses on the HOL-Light environment <ref type="bibr" target="#b20">[21]</ref>. Their model relies on a classifier that can select among a restricted set of tactics and arguments, while we rely on a seq2seq model that can generate arbitrary tactics. The suggested tactics are then used in a breadth-first search. TacticToe <ref type="bibr" target="#b21">[22]</ref> uses an MCTS without learned components, using ranking on predefined features to guide the search. Machine learning has also been used to improve classical provers by re-ranking clauses <ref type="bibr" target="#b22">[23]</ref>. Overall, previous studies always focus on a single proving environment (e.g. Metamath, Lean, or HOL-Light).</p><p>Reasoning abilities of language models. Impressive performance of large language models in one or few shot learning [15], machine translation <ref type="bibr" target="#b23">[24]</ref> or more recently code generation [25] spurred interest into the reasoning capabilities of large transformers. These model perform quite well on formal tasks such as expression simplification [26], solving differential equations <ref type="bibr" target="#b26">[27]</ref>, symbolic regression <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, or predicting complex properties of mathematical objects <ref type="bibr" target="#b29">[30]</ref>. These studies suggest that deep neural networks are well adapted to complex tasks, especially when coupled with a formal system for verification.</p><p>MCTS and two player games. Recently, AlphaZero [7] demonstrated good performances on two player games, replacing the Monte-Carlo evaluations of MCTS [6] with evaluations from a deep neural network and guiding the search with an additional deep policy. This recent success follows extensive literature into search methods for two player games, notably alpha-beta search <ref type="bibr" target="#b4">[5]</ref>. Theorem proving can be thought of as computing game-theoretic value for positions in a min/max tree: for a goal to be proven, we need one move (max) that leads to subgoals that are all proven (min). Noticing heterogeneity in the arities of min or max nodes, we propose a search method that goes down simultaneously in all children of min nodes, such that every simulation could potentially result in a full proof-tree.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over the course of history, the complexity of mathematical proofs has increased dramatically. The nineteenth century saw the emergence of proofs so involved that they could only be verified by a handful of specialists. This limited peer review process inevitably led to invalid proofs, with mistakes sometimes remaining undiscovered for years (e.g. the erroneous proof of the Four Colour Conjecture <ref type="bibr" target="#b0">[1]</ref>). Some mathematicians argue that the frontier of mathematics has reached such a level of complexity that the traditional review process is no longer sufficient, envisioning a future where research articles are submitted with formal proofs so that the correctness can be delegated to a computer <ref type="bibr" target="#b1">[2]</ref>.</p><p>Unfortunately, very few mathematicians have adopted formal systems in their work, and as of today, only a fraction of existing mathematics has been formalized. Several obstacles have hindered the widespread adoption of formal systems. First, formalized mathematics are quite dissimilar from traditional mathematics, rather closer to source code written in a programming language, which makes formal systems difficult to use, especially for newcomers. Second, formalizing an existing proof still involves significant effort and expertise (the formalization of the Kepler conjecture took over 20 person years to complete <ref type="bibr" target="#b2">[3]</ref>) and even seemingly simple statements sometimes remain frustratingly challenging to formalize.</p><p>To write a formal proof, mathematicians typically work with Interactive Theorem Provers (ITPs). The most popular ITPs provide high-level "tactics" that can be applied on an input theorem (e.g. the initial goal) to generate a set of subgoals, with the guarantee that proving all subgoals will result in a proof of the initial goal (reaching an empty set means the tactic solves the goal). An example of a proof in Lean <ref type="bibr" target="#b3">[4]</ref>, an interactive theorem prover, is given in <ref type="figure">Figure 1</ref> and the corresponding proof hypertree is illustrated in <ref type="figure">Figure 3</ref>. A tactic, induction k, is applied on the root goal (n + k ? m + k) to start a proof by induction 3 . The formal system returns two subgoals: n + 0 ? m + 0 (the initial case) and n + k ? m + k ? n + k + 1 ? m + k + 1 (the induction step). As the first subgoal is our initial hypothesis, it can be solved using the exact tactic. To prove the second subgoal, we first rewrite it using nat.succ_le_succ_iff, a theorem from the Lean library stating that m + 1 ? n + 1 ?? m ? n. The new subgoal then becomes our induction hypothesis n + k ? m + k, and can again be solved using the exact tactic, thereby solving the last remaining subgoal and completing the proof of the initial statement. Starting from a goal and reducing it to subgoals until these can be solved, is commonly referred to as backward proving. reduces the initial statement to two subgoals, that can be solved independently.</p><p>In this paper, we aim at creating a prover that can automatically solve input theorems by generating a sequence of suitable tactics without human interaction. Such a prover could significantly reduce the effort required to formalize existing mathematics. The backward procedure naturally suggests a simple approach where a machine learning model trained to map goals to tactics interacts with an ITP to build the proof of an input goal in a backward fashion. The automated prover builds a hypergraph with the theorem to be proved as the root node, tactics as edges and subgoals as nodes.</p><p>The prover recursively expands leaves by generating tactics with our model until we find a proof of the initial theorem. A proof in this setup is a hypertree rooted in the initial theorem whose leaves are empty sets. As many different tactics can be applied to a goal, and each tactic application can result in multiple subgoals, the number of goals in the graph grows exponentially and it is critical to reduce the search to the most promising branches. This can be done through techniques like alpha-beta pruning <ref type="bibr" target="#b4">[5]</ref> or Monte Carlo Tree Search (MCTS) <ref type="bibr" target="#b5">[6]</ref>, known for its recent successes in difficult two player games <ref type="bibr" target="#b6">[7]</ref>. However, challenges arise in search algorithms for theorem proving that do not occur in two player games. For instance:</p><p>? The action space, i.e. the amount of possible "moves" in a given state, is infinite (there is an unlimited number of tactics that can be applied to a given theorem). This requires sampling possible actions from a language model for which training data is scarce. Moreover, if all tactics sampled at a goal fail, we have no information on what region of the probability space to sample next.</p><p>? In the context of theorem proving, we need to provide a proof of all subgoals created by a tactic, whereas AlphaZero for two player games is allowed to focus on the most likely adversary moves.</p><p>? In Chess or Go, playing a sub-optimal move does not necessarily lead to losing the game, thus exploring these branches can provide information. In theorem proving, it is frequent to generate tactics that result in subgoals that can no longer be proved and on which the model will waste significant search budget.</p><p>This paper presents an in-depth study of our approach to overcome these difficulties and the resulting model, Evariste. In particular, we make the following contributions:</p><p>? A new MCTS-inspired search algorithm for finding proofs in unbalanced hypergraphs.</p><p>? A new environment (Equations) to easily prototype and understand the behavior of the models we train and our proof search.</p><p>? A detailed ablation study and analysis of the different components used in our approach on three different theorem proving environments. We study how data is selected for training the policy model after a successful or failed proof-search, what target should be used to train the critic model, and the impact of online training vs. expert iteration.</p><p>? State-of-the-art performance on all analyzed environments. In particular, our model manages to prove over 82.6% of proofs in a held-out set of theorems from set.mm in Metamath, as well as 58.6% on miniF2F-valid <ref type="bibr" target="#b7">[8]</ref> in Lean.</p><p>We begin by introducing related work in Section 2 and present the three theorem proving environments that we study in Section 3. Then, we present our proof-search algorithm in Section 4, our online training pipeline in Section 5, and all experimental details in Section 6. Finally, we describe our main results and ablation studies in Section 7 before concluding in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proving environments</head><p>In this paper, we develop and test our methods on three theorem proving environments: a) Metamath, b) Lean and c) Equations. Metamath <ref type="bibr" target="#b30">[31]</ref> comes with a database of 30k human-written theorems called set.mm. We also evaluate our methods on the Lean proving environment, which provides a level of automation that is helpful to solve more complex theorems. Lean comes with a human-written library of 27k theorems called Mathlib <ref type="bibr" target="#b31">[32]</ref>. Finally, since Metamath proofs can be quite difficult to understand and Lean requires more computing resources, we developed our own environment called Equations, restricted to proofs of mathematical identities. Its simplicity makes it ideal for prototyping and debugging. We briefly introduce these environments below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Metamath</head><p>Metamath's only rule is string substitution. Starting from a theorem to be proven, variables are substituted until we reach axioms. In our setup, we consider a tactic to be the label of a theorem in set.mm, along with the necessary substitutions. As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, to show that 2 + 2 = 4, the first step uses eqtr4i which states that A = B ? C = B ? A = C with substitutions: A = (2 + 2), B = (2 + (1 + 1)), and C = 4. We are then left with two subgoals to prove: (2 + 2) = (2 + (1 + 1)) and 4 = (2 + (1 + 1)). The simplicity of Metamath makes it a great test bed for our algorithms. However, its lack of automation leads to larger proof sizes and its syntax and naming conventions make each step difficult to interpret for neophytes. Similar to GPT-f, we implement a parser for Metamath in order to automatically prove the syntactic correctness of statements. Moreover, we use this parser to allow generating only substitutions that cannot be inferred from the goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Lean</head><p>Lean is a full-fledged programming language and benefits from more powerful automation than Metamath, with tactics such as ring (able to prove goals using manipulations in semirings), norm_num (able to prove numerical goals) or linarith (able to find contradictions in a set of inequalities). An example of a Lean proof-tree is shown in <ref type="figure">Figure 3</ref>.</p><p>States are more complex in Lean than in Metamath: metavariables can appear which are holes in the proof to be filled later. Subgoals sharing a metavariable cannot be solved in isolation. This is addressed in Polu and Sutskever <ref type="bibr" target="#b15">[16]</ref> by using as input the entire tactic state. Instead, we inspect tactic states to detect dependencies between subgoals, and split the tactic state into different subgoals where possible in order to maximize state re-use and parallelization in the proof search algorithm.</p><p>Finally, Lean's kernel type checker has to be called after each tactic application as tactics sometimes generate incorrect proofs and rely on the kernel for correctness. For every goal in the previous tactic state, we type check the proof term inserted by the tactic. Since the kernel does not support metavariables, we replace every metavariable by a lambda abstraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3:</head><p>A visualization of the proof-tree for the proof discussed in the introduction in Lean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Equations</head><p>We developed the Equations environment as a simpler analogue to existing proving environments. Its expressivity is restricted to manipulating mathematical expressions (e.g. equalities or inequalities) with simple rules (e.g.</p><formula xml:id="formula_0">A + B = B + A, or A &lt; B ? ?B &lt; ?A)</formula><p>. This reduced expressivity makes goals and tactics easy to understand, helping with interpretability and debugging: plotting the set of goals explored during a Metamath proof search does not give a lot of insights on whether it is on track to find a proof. In Section B of the appendix, we give an in-depth presentation of this environment, of how we represent goals (Section B.1), tactics (Section B.2) and how we prove statements (Section B.3).</p><p>Unlike in Metamath or Lean, we do not have access to a training set of human annotated proofs for this environment. Instead, we create a training set composed of randomly generated synthetic theorems and their proofs (see Sections B.6 and B.6 for details), and manually create an out-ofdomain set of non-trivial mathematical identities for which we do not provide proofs, e.g. cosh(3x) = 4 cosh(x) 3 ? 3 cosh(x) or sin(4x) = (4 sin(x) ? 8 sin(x) 3 ) cos(x). We refer to this evaluation split as Identities, a set of 160 mathematical expressions.</p><p>As synthetic theorems randomly generated are much simpler and significantly differ from statements in the Identities split, we can evaluate the ability of our model to generalize to complex and out of domains data. An example proof-tree in Equations is shown in <ref type="figure" target="#fig_2">Figure 4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">HyperTree Proof Search</head><p>Given a main goal g to automatically prove, proof search is the algorithm that interacts with our learned model and the theorem proving environment to find a proof hypertree for g. Proof search progressively grows a hypergraph starting from g. A proof is found when there exists a hypertree from the root to leaves that are empty sets.</p><formula xml:id="formula_1">Selection N(g,t2)=0 W(g,t2)=0.1 N(g,t1) =1 W(g,t1) =0.5 N(g,t0)=1 W(g,t0)=0.3 g g N(g,t1)=2 W(g,t1)=0.5+(1?0.1)?0.4</formula><p>vT(g)=(1?0.1)?0.4 <ref type="table" target="#tab_2">g4  g3  g3  g4  g2  g4  g3  g2  g2</ref> g5 g6 g7 <ref type="figure">Figure 5</ref>: HyperTree Proof Search. We aim at finding a proof of the root theorem g with HTPS. Proving either {g5}, {g0, g1}, or {g6, g7} would lead to a proof of g by tactic t0, t1, or t2. The figure represents the three steps of HTPS that are repeated until a proof is found. Guided by the search policy, we select a hypertree whose leaves are unexpanded nodes. The selected nodes are then expanded, adding new tactics and nodes to the hypergraph. Finally, during back-propagation we evaluate the node values of the hypertree, starting from the leaves back to the root, and update the visit counts and total action values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Back-propagation Expansion</head><formula xml:id="formula_2">g g g vT(g1)=0.4 N(g1,t0)=1 W(g1,t0)=0.4 N(g0,t0)=1 W(g0,t0)=1x0.1 vT(g0)=1?0.1 N(g0,t0)=0 W(g0,t0)=0 g0 g0 g1 g1 g0 g1 vT(g4)=0.4 N(g4,t1)=0 W(g4,t1)=0 g4 g2 g4 g2 vT(g2)=1 vT(g3)=0.1 g2</formula><p>In this section, we assume a policy model P ? and critic model c ? . Conditioned on a goal, the policy model allows the sampling of tactics, whereas the critic model estimates our ability to find a proof for this goal. Our proof search algorithm will be guided by these two models. Additionally, and similar to MCTS, we store the visit count N (g, t) (the number of times the tactic t has been selected at node g) and the total action value W (g, t) for each tactic t of a goal g. These statistics will be used in the selection phase and accumulated during the back-propagation phase of the proof search described in Section 4.1 and Section 4.3.</p><p>The algorithm iteratively repeats the three steps described below to grow the hypergraph until either a proof is found or we exceed our expansion budget. We show an example of these three steps of proof search in <ref type="figure">Figure 5</ref>. We refer to this algorithm as HyperTree Proof Search (HTPS) throughout this work. A more detailed comparison between HTPS, MCTS, and the best-first search algorithm of Polu and Sutskever <ref type="bibr" target="#b15">[16]</ref> can be found in Appendix A.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Selection</head><p>The number of nodes in the proof hypergraph grows exponentially with the distance to the root. Thus, naive breadth-first search is infeasible to find deep proofs and some prioritization criteria is required to balance depth and breadth. This is the family of best-first search algorithms, of which A* and MCTS are instances. Similar to MCTS, we balance the policy model's prior with current estimates from the critic. In particular, we experiment with two different search policies: PUCT <ref type="bibr" target="#b32">[33]</ref> and Regularized Policy (RP) <ref type="bibr" target="#b33">[34]</ref>, detailed in Appendix A.2. These search policies use the tactic prior from the policy model, the visit count N , and the estimated value of the tactic given by Q = W/N . A higher visit count will lead to a higher confidence in the estimated value than in the prior policy model, and vice-versa for low visit counts.</p><p>The key difference between previous work and ours is that our proof search operates on a hypergraph. Thus, whereas an algorithm like MCTS will go down a path from the root to an unexpanded node during its selection phase, our algorithm will instead create a partial proof hypertree, leading to a set of either solved or unexpanded nodes. The selection phase algorithm, described in more details in Appendix A.3, consists in recursively following the search policy from the root until we find leaves of the current hypergraph.</p><p>In <ref type="figure">Figure 5</ref>, we illustrate the selection step. We start at the root node g, which has three tactics t 0 , t 1 , t 2 . The search policy selects t 2 , leading to the set of subgoals {g 0 , g 1 }. Then, for both g 0 and g 1 , we again select the best tactic according to the search policy and finally reach the sets of unexpanded subgoals {g 2 , g 3 } and {g 4 }. The final selected proof hypertree T is composed of g, {g 0 , g 1 }, {g 2 , g 3 }, {g 4 } and is colored in dark blue in <ref type="figure">Figure 5</ref>.</p><p>In order to batch calls to the policy and critic models over more nodes to expand, we run several selections sequentially, using a virtual loss <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b6">7]</ref> to produce different partial proof-trees. Note that solving all unexpanded leaves of any of these trees would immediately lead to a full proof of the root. In the next section, we describe how nodes are expanded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Expansion</head><p>To expand a node g, we use the policy model to suggest tactics that would make progress on the goal, then evaluate these tactic suggestions in the theorem proving environment. Each valid tactic will lead to a set of new subgoals to solve, or to an empty set if the tactic solves the goal. Finally, we add a hyperedge for each valid tactic t i from the expanded node g to its (potentially empty) set of children for this tactic {g 0 i , ..., g k i }. Note that these children might already be part of the hypergraph. For new nodes, visit counts N (g, t) and total action values W (g, t) are initialized to zero. There are three types of nodes in the hypergraph:</p><p>? Solved: at least one tactic leads to an empty set, or has all its children solved.</p><p>? Invalid: all tactics sampled from the policy model were rejected by the environment, or lead to invalid nodes. ? Unsolved: neither solved nor invalid, some tactics have unexpanded descendants.</p><p>Note that the definitions for Solved or Invalid are recursive. These status are updated throughout the hypergraph anytime a hyperedge is added. Tactics leading to invalid nodes are removed to prevent simulations from reaching infeasible nodes. Once this is done, we back-propagate values from the expanded nodes up to the root, as described in the next section.</p><p>In <ref type="figure">Figure 5</ref>, we show an example of expansion. After selecting a hypertree T during the selection step, for each unexpanded leaf goal of T , we generate B = 2 tactics with our policy model and keep only the valid ones. This results in two tactics for g 2 and g 4 and one for g 3 . We apply these tactics in our formal environment and obtain new sets of subgoals and add them to the hypergraph. One tactic of g 2 solves g 2 , resulting in an empty set of subgoals. Note that because g 3 is not solved yet, g 0 remains unsolved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Back-propagation</head><p>For each expanded goal g in a simulated proof tree T , its value is set to v T (g) = 1 if it is solved, and v T (g) = 0 if it is invalid. Otherwise, its value is estimated by the critic model: v T (g) = c ? (g). This provides v T for all leaves of T and we can then back-propagate in topographic order (children before parents) through all nodes of T . Interpreting the value of a node as the probability that it can be solved, since solving a goal requires solving all of its children subgoals, the value of a parent is the product of values of its children (we assume that the solvability of subgoals is independent, for simplicity):</p><p>v</p><formula xml:id="formula_3">T (g) = c?children(g,t) v T (c)</formula><p>In particular, the value of a goal g is the product of the values of all leaves in T that remain to be solved to obtain a proof of g. Once all values in T are computed, we increment the corresponding visit count N (g, t) in the hypergraph as well as the total action values: W (g, t) += v T (g). For a goal g, the estimated value for tactic t is then the mean of the total action value:</p><formula xml:id="formula_4">Q(g, t) = W (g, t) N (g, t)</formula><p>We give an example of back-propagation in <ref type="figure">Figure 5</ref>. First, we evaluate the values of the leaf nodes of T . Because g 2 is solved, we set v T (g 2 ) = 1. The values of g 3 and g 4 are estimated with the critic model, e.g. v T (g 3 ) = c ? (g 3 ) = 0.1. The values of the internal nodes are obtained by computing the product of their children values. Thus, we first</p><formula xml:id="formula_5">compute v T (g 0 ) = v T (g 2 ) ? v T (g 3 ) and v T (g 1 ) = v T (g 4 ), then v T (g) = v T (g 0 ) ? v T (g 1 ) = (v T (g 2 ) ? v T (g 3 )) ? (v T (g 4 ))</formula><p>. Then, for every (goal, tactic) pair (g, t) in T , we increment the visit count, N (g, t) += 1 and update the total action value: W (g, t) += v T (g). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Online training from proof searches</head><p>In the previous section, we considered the policy and critic models as given. In this section, we explain how proof search is used to create training data for these two models. Provers are asynchronously running proof searches using a version of the models synchronized with the trainers, coupling training and data extraction in an online procedure that leads to continuous performance improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Training objectives</head><p>Both the policy model P ? and the critic model c ? are encoder-decoder transformers <ref type="bibr" target="#b35">[36]</ref> with shared weights ?, which are trained with a tactic objective and a critic objective respectively.</p><p>Tactic objective. The policy model P ? takes as input a tokenized goal and generates tactics. It is trained with a standard seq2seq objective <ref type="bibr" target="#b23">[24]</ref>, where we minimize the cross-entropy loss of predicted tactic tokens conditioned on an input goal.</p><p>Critic objective. In order to decode a floating point value with our seq2seq critic model c ? , we start decoding with a special token, restrict the output vocabulary to the two tokens PROVABLE and UNPROVABLE, and evaluate the critic with c ? (g) = P (PROVABLE|g, CRITIC). The critic objective is identical to a seq2seq objective where the cross-entropy is minimized over the two special tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Online training</head><p>We use a distributed learning architecture reminiscent of AlphaZero <ref type="bibr" target="#b32">[33]</ref> or distributed reinforcement learning setups <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b6">7]</ref>. A distributed data parallel trainer receives training data from a set of asynchronous provers that run proof searches on tasks chosen by a controller that also centralizes statistics. Provers, in turn, continuously retrieve the latest model versions produced by the trainers in order to improve the quality of their proof search. This set-up is represented in <ref type="figure" target="#fig_3">Figure 6</ref>. Once a prover finishes a proof-search, we extract two types of training samples from its hypergraph:</p><p>Tactic samples. At the end of a successful proof search, we extract (goal, tactic) pairs of a minimal proof hypertree of the root node as training samples for the policy model. This selection has a large impact on performances, other options such as selecting all solved nodes are investigated in Section 7.2.1. We use a different minimality criteria depending on the environment: total number of proof steps for Metamath and Equations, and total tactic CPU time for Lean (see Appendix E for details).</p><p>Critic samples. In the proof search hypergraph, we select all nodes that are either solved, invalid, or with a visit count higher than a threshold. Then, we use c(g) = 1 as the training target for solved nodes. For internal nodes, we use the final estimated action value c(g) = W (g, t * )/N (g, t * ) where t * is the tactic that maximizes the search policy at g. Finally, for invalid nodes, we use c(g) = 0.</p><p>The trainers receive training samples that are stored into two separate finite-size queues, one for each objective. When a queue is full, appending a new sample discards the oldest one. In order to create a batch for a task, we uniformly select samples in the corresponding queue. The two training objectives are weighted equally. Additionally, during online training, we continue sampling from the supervised tasks which provide high-quality data. Our proof-search depends on many hyper-parameters, and the optimal settings might not be the same for all statements, making tuning impractical. Thus, the controller samples these hyper-parameters from pre-defined ranges (see Appendix C for details) for each different proof-search attempt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Full training pipeline</head><p>In order to bootstrap our online learning procedure we require a policy model P ? that outputs coherent tactics. While the critic is left untrained, the policy model is fine-tuned on a pretrained transformer using a supervised dataset specific to the target environment. Overall, the full training pipeline can be summarized as follows:</p><p>? Pretraining of the encoder-decoder model on a large unsupervised corpus (c.f. Section 6.2).</p><p>? Fine-tuning of the policy model on supervised datasets detailed in (c.f. Section 6.1).</p><p>? Online training of both the policy and critic models on data extracted from proof search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>In this section, we provide details about our experimental training and evaluation protocols. We first describe the supervised datasets used to fine-tune our policy models, as well as the tokenization used. We then give practical details on pretraining and the model architecture. Finally, we discuss the evaluation datasets and methodology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Model fine-tuning and supervised datasets</head><p>Starting the HTPS procedure described in Section 5 from a randomly initialized model would be sub-optimal, as no valid tactic would ever be sampled from the policy model. Thus, starting the online training from a non-trivial model is critical. To this end, we first fine-tune our policy model P ? on a supervised dataset of theorems specific to each environment.</p><p>Metamath In Metamath, we extract all proofs from the set.mm library, composed of 37091 theorems (c.f. Section D for the version of set.mm). We first derive a graph of dependencies between statements, and generate a random train-valid-test split of theorems, with 1000 valid and test theorems. We use the DAG to ensure that each theorem in the valid or test set is not used to prove another theorem. Moreover, this DAG is used to build a table of forbidden tokens: if the proof of A depends on B, we set to zero the probability of generating the token A during a proof-search of B. We use a seq2seq training objective, where the model is conditioned on a goal to prove, and is trained to output a sequence of the following format:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LABEL MANDATORY_SUBSTS &lt;EOU&gt; LABEL_STATEMENT PREDICTABLE_SUBSTS &lt;EOS&gt;</head><p>LABEL is the label of the rule to apply, MANDATORY_SUBSTS is a serialized version of the substitutions in the rule that cannot be inferred from syntactic parsing of the input goal and the theorem statement. During proof-search, decoding is stopped at the &lt;EOU&gt; (End Of Useful) token and we do not generate predictable substitutions, as this would unnecessarily increase decoding time and the probability that our model generates invalid substitutions. Training the model to output predictable substitutions and the rule statement serves as a co-training task and helps reduce overfitting. The training set is composed of around 1M goal-tactic pairs; more statistics about the training data are provided in <ref type="table">Table 6</ref>.1. Tokenization in Metamath is trivial, as statements are composed of space-separated tokens.</p><p>Lean Following <ref type="bibr" target="#b17">[18]</ref>, we extract a supervised dataset from the Mathlib library. The training set is composed of 24k theorems and 144k goal-tactic pairs. In addition, we co-train with the dataset of proof-artifacts of Han et al. <ref type="bibr" target="#b16">[17]</ref> to reduce overfitting. To facilitate experimentation and reproducibility, we use fixed versions of Lean, Mathlib, and miniF2F (c.f. Appendix D). Finally, we add another supervised co-training task by converting to Lean a synthetic dataset of theorems generated by the Equations environment (c.f. Appendix B.7). In order to avoid hooking into the Lean parser, we tokenize goals and tactics using byte-pair encoding (BPE <ref type="bibr" target="#b37">[38]</ref>) following previous work <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref>. Statistics about the training set are available in <ref type="table">Table 6</ref>.1.</p><p>Equations Unlike Metamath or Lean, the Equations environment does not come with with a dataset of manually annotated proofs of theorems. Instead, we generate supervised data on the fly using the random graph generator described in Appendix B.6. As the model quickly reaches a 100% proving accuracy on these synthetic theorems, there would be no benefit in using them during online training. Thus, we fine-tune on the synthetic dataset, and only leverage statements from the Identities split during online training. As in Metamath, tokenization of statements for this environment is natural, as each statement can be tokenized using the list of symbols from its prefix decomposition <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Model pretraining</head><p>Model pretraining can be critical in low-resource scenarios where the amount of supervised data is limited <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref>. Thus, we do not immediately fine-tune our model but first pretrain it on a large dataset to reduce overfitting and improve generalization. In particular, we pretrain our model with a masked seq2seq objective (MASS <ref type="bibr" target="#b40">[41]</ref>) on the LaTeX source code of papers from the mathematical section of arXiv. After tokenization, our filtered arXiv dataset contains around 6 billion tokens for 40GB of data. Similar to Polu and Sutskever <ref type="bibr" target="#b15">[16]</ref>, we observed large performance gains using pretraining. However, we found that arXiv alone provides a better pretraining than when it is combined with other sources of data (e.g. GitHub, Math StackExchange, or CommonCrawl).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Model Architecture and Training</head><p>Model architecture. Our transformer architecture uses a 12-layer encoder and a 6-layer decoder in all experiments. We use an embedding dimension of 1600 in the encoder and 1024 in the decoder for both Metamath and Lean. For Equations, where we expect the model to require less decoding capacity, the decoding dimension is lowered to 512. We found that reducing the decoder capacity increases the decoding speed without impacting the performance, as previously observed by Kasai et al. <ref type="bibr" target="#b41">[42]</ref> in the context of machine translation. Our models are composed of 440M parameters for Equations and 600M parameters for Metamath and Lean (for comparison, GPT-f uses a 770M parameter, 36-layer model).</p><p>Supervised fine-tuning. During fine-tuning, we train our models with the Adam optimizer <ref type="bibr" target="#b42">[43]</ref> and an inverse square-root learning rate scheduler <ref type="bibr" target="#b35">[36]</ref>. We use a dropout of 0.2 <ref type="bibr" target="#b43">[44]</ref> to reduce the overfitting of our models. We also apply layer-dropout <ref type="bibr" target="#b44">[45]</ref> with a dropout rate of 0.1 to further reduce overfitting and stabilize training. We implement our models in PyTorch <ref type="bibr" target="#b45">[46]</ref> and use float16 operations to speed up training and to reduce the memory usage of our models.</p><p>Online training. During online training, we alternate between the goal-tactic objective, used during fine-tuning on the supervised dataset, and the goal-tactic and goal-critic objectives on data generated by the provers. As the model and the data generated by the provers are constantly evolving, we do not want the learning rate to decrease to 0, and we fix it to 3 ? 10 ?5 after the warm-up phase. Unless mentioned otherwise (e.g. for large experiments), we run all Metamath and Equations experiments with 16 trainers and 32 provers for a total of 48 V100 GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Evaluation settings and protocol</head><p>In Polu et al. <ref type="bibr" target="#b17">[18]</ref>, the model is fine-tuned on theorems from the training set and expert iteration is done on theorems from different sources: train theorems, synthetic statements, and an extra curriculum of statements without proofs (miniF2F-curriculum). The produced model is then evaluated on unseen statements, namely the validation and test splits of the miniF2F dataset <ref type="bibr" target="#b7">[8]</ref>.</p><p>In this work, we also consider the transductive setup: on a corpus of unproved statements available at train time, how many proofs can our method learn to generate? This protocol is also sensible, as allowing the model to learn from a failed proof-search can lead to more focused exploration on the next attempt, proving more statements overall than a model that would not be trained online.</p><p>Following <ref type="bibr" target="#b15">[16]</ref>, we also evaluate the pass@k by running k proof searches on the evaluated statements with the policy and critic obtained by online training. In the transductive setup, we also report the cumulative pass rate, i.e. the proportion of theorems solved at least once during online training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>In this section, we present our results and study the moving parts of our pipeline through ablations. Each experiment is run on a single environment (e.g. Lean, Metamath, or Equations). We compare our model with GPT-f <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref> which represents the state of the art on Metamath and Lean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Main Results</head><p>Supervised  For other evaluations, we depart from the set-up of Polu et al. <ref type="bibr" target="#b17">[18]</ref>, directly using the statements from the miniF2F-valid split in our online training, obtaining 58.6% cumulative pass rate. We then evaluate the final model on miniF2F-test, reaching 41% pass@64, against 36.6% for GPT-f.</p><p>Without the synthetic data co-training task, the performance drops to 54.9% cumulative pass rate on the miniF2F-valid split, and 38.5% pass@64 on the miniF2F-test split. Examples of proofs found by our model can be found in Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2">Metamath</head><p>On Metamath, we train our model on V100 GPUs, with 128 trainers and 256 provers, whereas ablations are run on 16 trainers and 32 provers. We report our results in <ref type="table">Table 3</ref> for the supervised model and for a model trained with online training. During online training, we sample equally statements from the training and from the validation splits of set.mm.</p><p>Online training dramatically improves performances on valid statements, going from a 61% pass@8 to a cumulative pass rate of 82.6% on this split. This improvement cannot solely be explained by the high number of attempts on validation theorems during training. Indeed, the ablation in <ref type="figure">Figure 7</ref> (right) shows that Evariste significantly outperforms a supervised model with the same number of attempts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 7:</head><p>Comparison between online setup, expert iteration, and fixed model. We report the cumulative pass rate on the Identities (resp. valid) split for the Equations (resp. Metamath) environment. Reloading the model more frequently converges faster and to a better performance. When "No training" is done (i.e. the model is the supervised one), the final performance is much lower despite using as many attempts. This shows that online training is able to learn from previous proof searches.  <ref type="table">Table 3</ref>: Results on Metamath for a supervised model and Evariste. We report the pass@8 and pass@32 scores on the validation and test splits. Additionally, for Evariste we also report the cumulative score on the validation set, i.e. the fraction of theorems proved at least one time during online training. Note that for Evariste on Valid, the cumulative and pass@k performances are close since these statements were seen during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.3">Equations</head><p>In Equations, we run our main experiment with 32 trainers and 64 provers, whereas ablations are run on 16 trainers and 32 provers. In this environment, the model easily learns the training distribution of our random generator, and solves all synthetically generated problems. Thus, online training is run on the Identities statements only. Our main experiment reaches a cumulative pass rate of 91.3% on the Identities split, while a supervised model never exceeds 36% even after a similar number of proof attempts. In Appendix B.8, we give examples of Identities statements proved during online training, as well as the size and depth of proofs found by the model.</p><p>In particular, Evariste managed to find the proof of complex mathematical statements, such as sinh(x/2) = sinh(x)/ 2(1 + cosh(x)) and tan(3x)(1 ? 3(tan(x)) 2 ) = 3 tan(x) ? (tan(x)) 2 tan(x) that required 82 and 117 proof steps respectively, showing the abilities of HTPS to prioritize subgoals and guide the search in very large proof graphs. This shows that online training is able to adapt our policy and critic models to a completely new domain, going from automatically generated statements to identities found in math books. Examples to understand the gap between these two domains can be found in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Ablation study</head><p>In this section, we present an ablation study on several components of our system. Since Lean experiments are CPU intensive, we run most of our ablations on the Equations and Metamath environments. On Lean, we ran experiments on a smaller subset of hyper-parameters that consistently performed well on the other environments.  <ref type="table">Table 4</ref>: Performance of our model for different online training data for tactic objective We report the pass@8 score for Metamath and cumulative pass rate for Equations. We try to keep all nodes and sample the tactics of these nodes according to the policy. We also try to extract proofs or minimal proofs of solved nodes, or the proofs or minimal proofs of the root theorem only. Selecting minimal proofs always improves performances and gives the best results in both environments.</p><p>The way we filter tactics sent to the trainers has a large impact on final performances. We investigated several filtering methods and report the results in <ref type="table">Table 4</ref>. The first method is similar to the one used in AlphaZero and exposed in <ref type="bibr" target="#b32">[33]</ref>: we select all nodes of the proof search hypergraph where the visit count is above a certain threshold and we filter tactics above a given search policy score. At training time, tactics are sampled according to the filtered search policy. With this method the model reaches 51.6% pass@8 on the valid set of Metamath and 37.5% cumulative pass rate on Equations.</p><p>We then experimented with other filtering criteria, selecting only goal-tactic pairs that are part of proofs: either a proof of the root node, or of any solved node in the hypergraph. Then, we learn from all possible proofs, or only from proofs that are minimal according to a criteria (number of proof steps for Equations and Metamath, cumulative CPU time for Lean).</p><p>Learning only from the minimal proofs always leads to improved performance, regardless of the selected roots. Learning from the minimal proofs of all solved nodes, we reach a cumulative pass rate of 78.1% on Equations, compared to 40.6% when learning from all proofs. On Metamath, only learning from the root's minimal proof gives the best result on the validation set, reaching a pass@8 of 68.6%.  <ref type="table">Table 5</ref>: Ablation study on the critic and search hyper-parameters in HTPS. We report the pass@8 score for Metamath, and the cumulative pass rate for Equations. Evariste, trained with a soft critic and stochastic hyper-parameters, obtains the best performance in both environments. Removing the critic, or using a hard critic (e.g. when the critic is trained to predict 1 on solved nodes and 0 on others) leads to reduced performances. In Equations, adding stochasticity in the proof search hyper-parameters increases the performance by 4.3% in Equations, and slightly improves performance in Metamath.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Critic</head><p>To measure the impact of our critic model, we run an experiment where the proof search is only guided by the policy model. During the back-propagation phase, we set v T (g) to 0.5 for the leaves of T . In that context, our model is no longer trained with a critic objective. We run this experiment for both Equations and Metamath, and report the results in <ref type="table">Table 5</ref>. In both environments, using a critic model improved the performance significantly, by 5.2% and 12.5% on Metamath and Equations respectively.</p><p>As mentioned in Section 5, to train the critic objective, we set the training targets as c(g) = 1 for solved nodes, c(g) = 0 for invalid nodes and c(g) = W (g, t * )/N (g, t * ) where t * is the tactic that maximizes the search policy at g., for internal nodes. We also tested a hard critic estimation of the target values, following Polu and Sutskever <ref type="bibr" target="#b15">[16]</ref>, where c(g) = 1 for solved nodes and c(g) = 0 for both invalid and internal nodes. We report results in <ref type="table">Table 5</ref>. For both Metamath and Equations, estimating the critic target of internal nodes with the HTPS action value estimate allows Evariste to reach its best performance. In Equations, the model reaches a cumulative pass rate of 78.1%, compared to 63.1% with hard critic estimates. In Equations, using hard critic targets gives worse performances than having no critic model at all, showing that these targets are a bad estimation: setting all internal nodes to zero is too pessimistic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.3">Fixed proof search parameters</head><p>We study the impact of sampling HTPS hyper-parameters for each attempt during online training. We run experiments with fixed, chosen search parameters for Equations and Metamath to compare with random sampling, and report results in <ref type="table">Table 5</ref>. Evariste achieves better performances than the model trained with fixed search parameters on Metamath test set and Equations Identities, reaching 78.1% pass rate compared to 73.8% in Equations Identities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.4">Model update frequency during online training</head><p>In our online training procedure, the policy and critic models are updated every five minutes on the provers. We measure the impact of the frequency of these updates by trying different refresh rates: 5 minutes, 1 hour, 6 hours for Equations, and no updates at all for both Equations and Metamath. We report the cumulative pass rate over training hours in <ref type="figure">Figure 7</ref>. The higher the refresh rate, the better the cumulative pass rate over time, confirming the benefits of online training over expert iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this work, we introduce HTPS, an AlphaZero-inspired proof search algorithm for automated theorem proving, along with an online training procedure. We run an extensive study of our pipeline, and present state-of-the-art results on multiple proving environments. We show that online training provides large speed-ups over expert iteration, and allows generalization of the policy and critic models to completely new domains. Despite large number of attempts per theorem, proving the entirety of datasets like miniF2F remains elusive, and generating data from proof-search on the currently available corpora will likely be insufficient in the long term. As manually annotated formal datasets are limited, another way of providing exploration and additional training data (in the spirit of self-play for two player games) is required. Automated generation of new theorems is likely to be one of the future milestones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proof search in more details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Hypergraph and definitions</head><p>We begin with some useful notations and concepts for our hypergraphs.</p><p>Formally, let G be a set of nodes, and T a set of tactics. A hypergraph is a tuple H = (G, r, T, U ) with G ? G the nodes, r ? G the root, and T ? G ? T ? P(G) the admissible tactics. An element of T is written (g, t, c) where g is the start goal, t is the applied tactic and c is the potentially empty set of children that the tactic creates when applied to g in the proving environment.</p><p>A hypertree is a hypergraph without cycles, i.e, such that we cannot find a path g 0 , . . . , g = g 0 with &gt; 0 and with g i+1 in the children of g i for all i's.</p><p>Let S ? G be the set of solved nodes. A node g ? G \ U is solved if one of its tactic leads to no subgoals, or one of its tactics leads to only solved nodes. Formally: ?(g, t, ?) ? T or ?(g, t, c) ? T such that c ? S. We say that a tactic t is solving for g if all the children it leads to are solved. Conversely, let U ? G be the set of invalid nodes. A node g ? G \ U is invalid if it has been expanded but has no tactics in the hypergraph, or all of its tactics have an invalid child. Formally: We can now reformulate the process of proof-search. Starting from a hypergraph that contains only the root theorem r, we produce a sequence of expandable subtrees. The unexpanded leaves of these subtrees are expanded in the hypergraph, then the new value estimates are backed-up. The hypergraph grows until we use all our expansion budget, or we find a proof of r.</p><formula xml:id="formula_6">{(g, t, c) ? T } = ? or ?(g, t, c) ? T , c ? I = ?.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Policies</head><p>When a goal g is added to the hypergraph, its visit count N (g, t) and total action value W (g, t) are initialized to zero. Its virtual visit count V C(g, t) are updated during proof search. Let C(g, t) = N (g, t) + V C(g, t) be the total counts. These values are used to define the value estimate with a constant first play urgency <ref type="bibr" target="#b46">[47]</ref>:</p><formula xml:id="formula_7">Q(g, t) = ? ? ? ? ? max(1,N (g,t)) max(1,C(g,t))</formula><p>if t is solving for g</p><formula xml:id="formula_8">0.5 max(1,C(g,t)) if N (g, t) = 0 W (g,t) C(g,t)</formula><p>otherwise.</p><p>Notice that the value of solving tactics decreases with virtual counts, allowing exploration of already solved subtrees.</p><p>Given the visit count N , the total counts C, value estimates Q, the model prior P ? and an exploration constant c. The policy used in Alpha-Zero is PUCT:</p><formula xml:id="formula_9">PUCT(g) = arg max t?A Q(g, t) + c ? P ? (t|g) ? N (g, ?) 1 + C(g, t)</formula><p>Notice that more weight is given to the value estimate Q as N grows which decreases the second term. Another work <ref type="bibr" target="#b33">[34]</ref> obtains good performances using as search policy the greedy policy regularized by the prior policy.</p><p>? RP (g) = arg max y?S Q(g) T y ? c ? C(g, ?) (C(g, ?) + 1) KL(? ? , y) with S the policy simplex at g Again, note that this policy balances the prior with the value estimates as the count grows, but does not account for individual disparities of visits of each tactics. In our experiments, we obtained better performances with ? RP on Equations, and better performances with P U CT on Metamath and Lean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Algorithms</head><p>Simulation During simulation, we only consider subtrees that could become proofs once expanded. This means we cannot consider any invalid nodes or consider subgraphs containing cycles. If we encounter a tactic that creates a cycle during a simulation, this tactic is removed from the hypergraph, virtual counts from this simulation are removed and we restart the search from the root. This may remove some valid proofs, but does not require a backup through the entire partial subtree which would lead to underestimating the value of all ancestors. Removing tactics from the hypergraph also invalidates computations of expandable tactics. This is dealt with by periodically calling MaintainExpandable if no valid simulation can be found. A full description of the algorithm that finds one expandable subtree is available in Algorithm 1. Selection of nodes to expand requires finding expandable subtrees until a maximum number of simulations is reached, or no expandable tactic exists at the root.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Finding an expandable subtree</head><p>Input: A hypergraph H and its root Output: A partial proof tree with unexpanded leaves :start T: hypertree(root) to_explore: list = [root] while to_explore do g = to_explore.pop() if g is internal then if expandable(g) = ? then tactic = arg max t ? expandable(g) ?(g, t) else continue { expandable nodes are in a sibling branch } end if if tactic leads to cycle then kill tactic remove virtual counts for elements of T goto start end if V C(g, tactic) += 1 T.add(g, tactic, children(g, tactic)) to_explore += [children(g, tactic)] end if end while Expansion The policy model produces tactics for an unexpanded node g. These tactics are evaluated in the proving environments. Valid tactics are filtered to keep a unique tactic (e.g. the fastest in Lean) among those leading to the same set of children. Finally, we add the filtered tactics and their children to the hypergraph. If no tactics are valid, the node is marked as invalid and we call MaintainInvalid. If a tactic solves g, the node is marked as solved and we call MaintainSolved.</p><p>Backup The backup follows topological order from the leaves of a simulated partial proof-tree T , updates W and N , and removes the added virtual count. The algorithm is described in Algorithm 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Comparison with other search algorithms</head><p>Best First Search <ref type="bibr" target="#b15">[16]</ref>. This best-first search expands goals one at a time according to a priorityqueue of either a value model or the cumulative log-prior from the language model. Since the priority is equal among siblings but strictly decreasing with depth, this means siblings will always be expanded together. However, nothing prevents the algorithm from jumping from one potential proof-tree to Algorithm 2 Back-propagation of total action value W Input: Partial proof-tree T and value estimates c ? (g) of its leaves.</p><formula xml:id="formula_10">to_backup = [] for g in leaves of T do v T (g) = c ? (g) to_backup.append(parent T (g)) end for while to_backup do g = to_backup.pop() to_update = c?children T (g) v T (c) W (g, t) += to_update N (g, t) += 1 V C(g, t) ?= 1 v(g, t) = to_update g.is_prop = true if all c.</formula><p>is_prop for c in siblings T (g) then to_backup.append(parent T (g)) end if end while another, and potentially favoring breadth over depth. In comparison, depth does not appear in the value estimate we compute, but rather the remaining number of nodes to solve a particular proof-tree. Moreover, our algorithm leads to value estimates that can be used to train our critic, which performs better than 0-1 estimates provided by best-first search (c.f. Section 7.2.2).</p><p>Monte Carlo Tree Search <ref type="bibr" target="#b5">[6]</ref>. MCTS has been famously used as part of AlphaZero <ref type="bibr" target="#b32">[33]</ref> to obtain great performances on two player games. This two player set-up can be mapped to theorem-proving by assigning one player to choosing the best tactics while the other player picks the most difficult goal to solve (a method explored in Holophrasm <ref type="bibr" target="#b18">[19]</ref>). However, since we need to provide a proof of the root theorem, we need to ensure that we can solve all goals that a tactic leads to. This set-up has been studied for two player games when attempting to compute the game-theoretical value of positions. Using MCTS in this set-up is suboptimal <ref type="bibr" target="#b47">[48]</ref>, ignoring unlikely but critical moves from the opponent (in our case, a subgoal that looks easy but is impossible to solve). We decided to exploit the highly asymmetrical arities of our two players (most tactics lead to one or two goals) which makes simulating partial proof-trees computationally feasible. Thus, the values we back-propagate always take into account all possible moves from the opponent, while only requiring a few expansions per simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Equations environment</head><p>In this section, we give additional details about the environment Equations. First, we described its main elements, theorems (resp. tactics) in Section B.1 (resp. B.2). Then, we describe a proof in this environment in Section B.3, how numerical expressions are evaluated in Section B.4 and what vulnerabilities this can lead to in Section B.5. Finally, we describe our random theorem generator in Section B.6 and how theorems and their proofs can be translated to Lean in Section B.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Theorems</head><p>Each theorem in Equations consists in proving mathematical expressions composed of functions of real numbers, by manipulating and rewriting expressions. A theorem to prove can be an inequality or an equality, conditioned to a set (potentially empty) of initial assumptions. For instance:</p><formula xml:id="formula_11">x 2 + 1 ? 2x or x &gt; y =? e y?x ? 1 &lt; 0</formula><p>In the first example, the goal does not have any hypothesis and consists in proving that for every x ? R, x 2 + 1 ? 2x. In the second example, the goal consists in proving that e y?x ? 1 &lt; 0 for every x, y ? R that satisfy the hypothesis x &gt; y.</p><p>Equalities and inequalities are represented as trees with the three following elements:</p><p>? Leaves: represent a variable, an integer, or a constant (e.g. ?).</p><p>? Internal nodes: represent unary or binary operators, e.g. +, ?, /, ?, exp, ln, cos, sin, sinh, cosh, etc. More advanced operators such as gcd, lcm, mod (the rest of an euclidean division) are possible when dealing with integers.</p><p>? A root node: represents a comparison operator, e.g. =, ?, &lt;, ?, &gt;, =. More advanced comparison operators such as | (divides) are possible when dealing with integers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Tactics</head><p>Equations allows to deduce equalities and inequalities from simpler subgoals, using elementary rules (i.e. tactics). The environment contains two types of rules: transformations, which consist in matching a pattern in an expression and replacing it by an equivalent expression; and assertions, which consist in asserting that an expression is true. Both types of rules can have assumptions.</p><p>Transformation rules A transformation rule (TRule) consists in a set of two expressions, L and R, equivalent under a set of assumptions S. For instance TRule <ref type="figure">(A + B, B + A)</ref> is the transformation rule stating the commutativity of the addition, namely that A + B = B + A for any expressions A and B. Note that in this case, the set of assumption S is empty as the equality always holds. Another example is TRule(</p><formula xml:id="formula_12">? A 2 , A, [A ? 0]) that states that ? A 2 = A provided that A ? 0.</formula><p>Applying such a rule to an existing equation works as follows:</p><p>? matching a term T in the expression that has the pattern of L Assertion rules do not always have hypotheses, for instance the reflexivity rule ARule(A = A), or the rule ARule(e A &gt; 0) stating that e A is positive, for any real value A. Note that the two subgoals generated in the previous paragraph (e x = e x and e x &gt; 0) can be respectively solved by these two assertion rules (i.e. by matching A = e x and A = x).</p><p>Unlike transformation rules that always result in at least one subgoal (the initial expression on which we applied the transformation), assertion rules will only generate N subgoals, where N is the number of hypotheses. As a result, being able to apply an assertion rule without hypotheses to an expression is enough to close (e.g. solve) the goal. Assertion rules are in fact very similar to rules in Metamath.</p><p>In <ref type="table">Table 6</ref>, we provide the number of Equations rules in different categories. Some examples of transformation and assertion rules are given in <ref type="table">Table 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rule type</head><p>Basic Exponential Trigonometry Hyperbolic All <ref type="table" target="#tab_0">Transformation  74  18  9  8  109  Assertion  90  11  9  0  110   Total  171  29  18  11  219   Table 6</ref>: Number of Equations rules in each category.</p><p>Transformation rules Assertion rules  <ref type="table">Table 7</ref>: Trigonometric rules accessible by the model. The model only has access to these elementary rules when proving statements from Identities. In particular, it cannot use more involved theorems such as cos 2 (x) + sin 2 (x) = 1 or sin(?) = 0.</p><formula xml:id="formula_13">sin(0) = 0 | cos(A)| ? 1 cos(0) = 1 | sin(A)| ? 1 sin( ? 2 ) = 1 | sin(A)| ? |A| cos( ? 2 ) = 0 A = B =?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Proving a statement with Equations</head><p>In order to prove a theorem with Equations, the user (or automated prover) has to apply tactics on the current expression. A tactic can correspond either to a transformation rule, or to an assertion rule.</p><p>For transformation rules, the model needs to provide:</p><p>? the rule (using a token identifier) ? the direction in which the rule is applied (a Boolean symbol, for forward or backward) ? an integer that represents the position where the rule is applied ? an optional list of variables to specify (c.f. paragraph below)</p><p>The direction of the rule indicates whether we want to transform L by R or R by L (e.g. replace A by ? A 2 , or the opposite). The position where the rule is applied is given by the prefix decomposition of the input expression. For instance, the prefix notation of (x + y) + 1 is given by + + x y 1. Applying the commutativity rule A + B = B + A to the expression in position 0 will result in 1 + (x + y). Applying it in position 1 will result in (y + x) + 1, since the rule was applied to (x + y). Note that for the commutativity rule, the direction in which we apply the rule does not matter. The list of variables to specify is required when variables in the target patterns are absent from the source pattern. For instance, applying the transformation rule TRule(A,A+B-B) in the forward direction will require to provide the value of B.</p><p>For assertion rules, the format is simpler. We no longer need to specify a direction or a position (the position is always 0 as the assertion statement must match the expression to prove), but only:</p><p>? the rule (using a token identifier) ? an optional list of variables to specify In this case, the list of variables to specify corresponds to variables that appear in hypotheses and that cannot be inferred from the main expression. For instance, to apply the assertion rule A ? B ? B ? C =? A ? C, we need to specify the value of B. We will then be left with two subgoals: A ? B and B ? C.</p><p>Proving a statement in Equations requires to recursively apply tactics to unproved subgoals, until we are left with no subgoals to prove. An example of proof-tree in Equations is shown in <ref type="figure" target="#fig_2">Figure 4</ref>. <ref type="figure" target="#fig_6">Figure 8</ref> shows an example of proof of the statement (x ? y) ? (x + y) + 2y = 0 using rules from the environment. Although simple, this statement already requires 22 proof steps and highlights the difficulty proving complex mathematical identities when using elementary proof steps. In the rest of this appendix, we give more details about how we represent expressions in Equations, how we generate random theorems to provide initial training data, the list of rules we provided to the environment, and the set of expressions we use to evaluate the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement to prove</head><p>Rule used In this example, we provide at each step the current goal and the rule that is used to obtain the next goal. This example shows how difficult it can be to prove even simple statements in Equations as they may require a significant number of proof steps (22 in that case). This explains that proving more involved statements from Identities such as cosh(3x) = 4 cosh(x) 3 ? 3 cosh(x) or even sin(2? + x) = sin(x) can require to generate very large proof trees.</p><formula xml:id="formula_14">(x ? y) ? (x + y) + 2y = 0 A ? B = A + (?B) (x ? y) + (?(x + y)) + 2y = 0 ? (A + B) = (?A) + (?B) (x ? y) + ((?x) + (?y)) + 2y = 0 A + (B + C) = A + B + C (x ? y) + (?x) + (?y) + 2y = 0 A + (?B) = A ? B (x ? y) + (?x) ? y + 2y = 0 A + (?B) = A ? B (x ? y) ? x ? y + 2y = 0 int(a + b) = int(a) + int(b) (x ? y) ? x ? y + (1 + 1) ? y = 0 A ? B = B ? A (x ? y) ? x ? y + y ? (1 + 1) = 0 A ? (B + C) = A ? B + A ? C (x ? y) ? x ? y + y ? 1 + y ? 1 = 0 A ? 1 = A (x ? y) ? x ? y + y + y ? 1 = 0 A ? B = A + (?B) (x ? y) ? x + (?y) + y + y ? 1 = 0 A + B = B + A (x ? y) ? x + y + (?y) + y ? 1 = 0 A + (?B) = A ? B (x ? y) ? x + y ? y + y ? 1 = 0 A ? A = 0 (x ? y) ? x + 0 + y ? 1 = 0 A + 0 = A (x ? y) ? x + y ? 1 = 0 A ? B = A + (?B) x + (?y) ? x + y ? 1 = 0 A + B = B + A (?y) + x ? x + y ? 1 = 0 A ? A = 0 (?y) + 0 + y ? 1 = 0 A + 0 = A (?y) + y ? 1 = 0 A + B = B + A y ? 1 + (?y) = 0 A + (?B) = A ? B y ? 1 ? y = 0 A ? 1 = A y ? y = 0 A ? A = 0 0 = 0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 True expressions and numerical evaluation</head><p>Some theorems are trivial, either because their statements match the pattern of an assertion rule that has no assumptions (e.g. x 2 ? 0 or e y?x = 0), or because they do not contain any variable and an exact numerical evaluation can attest that they are true (e.g (?1)/2 &lt; 6 or 1 ? 7/4 = ?6/8).</p><p>To prevent the model from wasting budget in "uninteresting" branches, we automatically discard generated subgoals that can be trivially verified. However, we only perform numerical verification of expressions without variables when they exclusively involve rational numbers. For instance, we will automatically close subgoals such as 5 &lt; (?3) 2 or 1 2 &gt; 1 4 , but not e 1 &lt; e 2 or cos(3) = 0. To prove that e 1 &lt; e 2 the model will need to use, for instance, an assertion rule such as A &lt; B =? e A &lt; e B (1 &lt; 2 will then be closed automatically).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 Environment vulnerabilities due to initial numerical approximations</head><p>In early implementations of the Equations environment, we found that the model was able to leverage vulnerabilities in the environment to reach a 100% accuracy and to prove any statement. These issues where coming from numerical approximations that were initially allowed during the numerical verification of constant expressions (c.f. Section B.4). To prevent these vulnerabilities, we restricted the numerical verification to rational expressions, in order to have an exact numerical evaluation and to avoid errors due to approximations. We give two examples of vulnerabilities found by the model when expressions were verified with an approximate numerical evaluation.</p><p>In <ref type="figure">Figure 9</ref>, the model manages to prove that 2 = 3 by using the injectivity of the exponential function, and the fact that for NumPy, exp(? exp(exp(2))) = exp(? exp(exp(3))). Evaluating the left and the right-hand side both numerically evaluate to 0.0, and the environment incorrectly considered the expression to be valid.</p><p>In <ref type="figure">Figure 10</ref>, the model manages to prove that 0 = 0 by first proving that cos(?/2) = 0, and combining this result with the fact that cos(?/2) = 0. The imprecision came from the NumPy approximation of cos(?/2) in 6.123 ? 10 ?17 , and in particular the fact that (((cos(?/2) 0.5 ) 0.5 ) 0.5 ) ? 9.4 ? 10 ?3 , which was considered large enough by our threshold to be considered non-zero. By using this approximation, and the assertion rule ? A = 0 =? A = 0, the model was able to conclude that (((cos(?/2) 0.5 ) 0.5 ) 0.5 ) = 0 =? cos(?/2) = 0 =? 0 = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">= 3</head><p>Statement to prove Since cos( ? 2 ) evaluates to 6.123 ? 10 ?17 in NumPy (and not exactly to 0), the model found that for any tolerance threshold applying the assertion rule ? A = 0 =? A = 0 enough times lead to an expression where the left-hand side evaluates numerically to a strictly positive value. In particular, (((cos( ? 2 ) 2 ?3 ) ? 9.4 ? 10 ?3 , which was considered large enough by our threshold to be considered non-zero. After that, any expressions A and B can be shown to be equal using the assertion rule (A ? C = B ? C ? C = 0) =? A = B where C is chosen to be 0 since 0 = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.6 Random theorem generator</head><p>While Metamath and Lean come with a collection of annotated theorems that can be used for training, Equations does not have an equivalent of manually proved statements. Instead, we generate a supervised training set of theorems to pretrain the model before we start the online training. We propose two simple generation procedures: a random walk, and a graph generation approach.</p><p>Random walk generation The random walk is the simplest way to generate a theorem. We start from an initial expression A 0 and a set of initial hypotheses, both randomly generated following the method of Lample and Charton <ref type="bibr" target="#b26">[27]</ref>. Then, we randomly apply an admissible transformation rule on A 0 to get an equivalent expression A 1 . The process is repeated, to get a sequence A 0 , A 1 , . . . , A N of equivalent expressions. The final theorem consists in proving that A 0 = A N , and the proof corresponds to the sequence of rules sequentially applied. To increase the diversity of generations, and to avoid sampling only rules without or with simple assumptions, we add a bias in the random sampling of rules to over-sample the underrepresented ones.</p><p>Graph generation Because of the simplicity of the random walk approach, the generated theorems usually tend to be very easy to prove, and the model quickly reaches a perfect accuracy on the generated theorems. Moreover, proofs generated by the random walk are only composed of transformation rules. To generate a more diverse set of theorems, we also use a graph generation procedure, that creates a large acyclic graph of theorems, where each node is connected to its children by a rule in the environment. To create such a graph, we proceed as follows. We first generate a set of initial hypotheses, and initialize the graph with a node for each hypothesis. We then randomly apply a transformation or assertion rule on nodes already in the graph.</p><p>For instance, if A ? B and B ? C are two nodes in the graph, then we can add the node A ? C using the assertion rule</p><formula xml:id="formula_15">A ? B ? B ? C =? A ? C. If x = y ? (z ? 1)</formula><p>is a node in the graph, we can use the transformation rule B = 0 =? A/B = C ?? A = B ? C to add the node x/y = z ? 1, provided that the node y = 0 is also in the graph. Required hypotheses that are trivially verifiable (e.g. 2 &gt; 0 or e ?x &gt; 0) are automatically added to the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.7 Translating Equations theorems to Lean</head><p>Exporting theorems to Lean. To enrich the existing Lean supervised dataset with synthetic data, we built a translator from Equations to Lean. Although Equations statements are easy to translate, proofs can only be translated if they involve rules that also exist in Lean. Since Equations is a modular environment where rules can be specified by the user, we created a collection of Equations rules from existing Mathlib statements. Synthetic theorems can then be generated using the random walk or random graph approaches described in Section B.6, and converted into Lean to augment the existing supervised dataset. Examples of randomly generated Lean proofs are provided in <ref type="figure" target="#fig_0">Figure 11</ref>.</p><p>Importing rules from Mathlib. To allow interfacing Equations and Lean, we automatically parsed Mathlib statements from the Lean library, and extracted theorems with a statement compatible with the Equations environment. Compatible theorems are converted into Equations transformation or assertion rules. Overall, we converted 1702 theorems from the Lean Library into our Equations environment. Details about the number of converted theorems are provided in <ref type="table" target="#tab_8">Table 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rule type</head><p>Natural numbers Integers Real numbers  (h0 : ((x4 * (real.exp x1)) &lt; 10)) : 24</p><p>((-((abs ((x4 * (real.exp x1)) -10)) / 2)) &lt; ((abs (10 -(x4 * (real.exp x1)))) / 2)) := 25 begin 26 have h1 : ((0:R) &lt; ((abs ((x4 * (real.exp x1)) -10)) / 2)), 27</p><p>apply half_pos, 28</p><p>apply abs_pos_of_neg, 29</p><p>apply sub_neg_of_lt h0, 30</p><p>apply norm_num.lt_neg_pos _ _ h1, 31</p><p>rw ? abs_sub_comm, 32</p><p>apply half_pos, 33</p><p>apply abs_pos_of_neg, 34</p><p>apply sub_neg_of_lt h0, 35 end <ref type="figure" target="#fig_0">Figure 11</ref>: Example of a randomly generated theorems in Lean. The theorems were initially generated in the Equations environment using rules from the Mathlib library, and converted to Lean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.8 Examples of identities solved by the model on Equations</head><p>In this section, we give some examples of identities solved by the model. For each statement, we indicate the proof size and the proof depth, for the first proof found by the model, and for the optimal proof. We observe that the first proofs are sometimes very large, with more than 100 nodes, and that the model later manages to find shorter proofs as it improves.  <ref type="table">Table 9</ref>: Examples of identities solved. Some of the 144 identities found by our model, in the order they were first solved. For each identity, we provide the size and the depth, both the for first proof, and for the minimal proof (i.e. the proof with the smaller number of steps) found during online training. The model found proofs with over 350 steps, some exceeding a depth of 100. After additional proof search, the model is often able to find shorter proofs. The proof of sin(2? + x) = sin(x) requires a large number of steps, as the model can only use simple rules (e.g. the trigonometric rules provided in <ref type="table">Table 7</ref>), and it does not have access to the value of sin(2?) or sin(?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Time vs Depth minimization</head><p>In Lean, powerful tactics like ring, linarith, or simp are helpful when it comes to proving theorems, but the model might become over-reliant on these automations and never learn what the underlying arguments of the proofs were. Since these tactics are usually slower than rewrite or apply, we experimented with minimizing the total Lean CPU time of the proof. After 3 days of training, the cumulative pass-rate is higher when minimizing this objective, with 50.4% problems solved on miniF2F-valid, compared to 47.5% with the depth objective. Besides, we found that a model trained to minimize the execution time will reduce the fraction of tactics that timeout by 40%. In <ref type="table" target="#tab_0">Table 10</ref> we provide a comparison of the tactic usage for two models trained with different minimization objectives, and we show the average Lean proof execution time in <ref type="figure" target="#fig_1">Figure 12</ref>.    <ref type="figure">Figure 13</ref>: A proof of the imo_1964_p1_2 problem found by our model. The model shows that for any value of n ? N, 2 n + 1 is not divisible by 7, by showing that 2 n mod 7 + 1 = 0, and 2 n mod 7 + 1 &lt; 7. The second part of the proof uses strong induction and the fact that 2 n ? 2 n+3 mod 7. We provide a version of the proof that was automatically cleaned by removing unnecessary tactics and tactic arguments.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>First 1 Figure 1 :</head><label>11</label><figDesc>subgoal : n + 0 ? + 0 Second subgoal : n + ? + ? + + 1 ? + + A simple proof of the statement n ? m ? n + k ? m + k in Lean. The induction tactic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>A visualization of the proof-tree for 2 + 2 = 4 in Metamath.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>A visualization of the proof-tree for cos(x) + e x &lt; 1 + 2e x in Equations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>An overview of our online training architecture. The controller sends statements to asynchronous HTPS provers and gathers training and proving statistics. The provers send training samples to the distributed trainers and periodically synchronize their copy of the models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>?</head><label></label><figDesc>identifying the matching variables and substituting them in R ? replacing T by R in the input equation ? return the resulting equation with the set of hypotheses required for the transformation For instance, if the input goal is: (e x ) 2 = e x Applying TRule( ? A 2 , A, [A ? 0]) on this expression will result in two subgoals: ? The same expression, where ? A 2 has been replaced by A: e x = e x ? The hypothesis required for the assumption to hold: e x ? 0 More generally, a transformation rule will result in N + 1 subgoals, where N is the number of hypotheses required by the rule. Assertion rules An assertion rule (ARule) expresses the fact that an expression is true, provided some hypotheses. It is represented by a main expression, and a set of assumptions sufficient for the main expression to hold. For instance, the rule ARule(A ? C, [A ? B, B ? C]) states the transitivity of the partial order ?, i.e. A ? C provided that there exists an expression B such that A ? B and B ? C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>sin(A) = sin(B) sin(?A) = ? sin(A) A = B =? cos(A) = cos(B) cos(?A) = cos(A) sin(A) = sin(B) =? A = B cos(A) = 0 =? tan(A) = sin(A) cos(A) cos(A) = cos(B) =? A = B sin(A + B) = sin(B) cos(A) + sin(A) cos(B) A = B, cos(A) = 0 =? tan(A) = tan(B) cos(A + B) = cos(A) cos(B) ? sin(A) sin(B) tan(A) = tan(B), cos(A) cos(B) = 0 =? A = B</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Proof of the identity (x ? y) ? (x + y) + 2y = 0 with elementary rules.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>?? e 2 = e 3 ?? e e 2 = e e 3 ?? ?e e 2 = ?e e 3 Figure 9 :Figure 10 :</head><label>32323910</label><figDesc>Rule: A = B ?? e A = e B , Rule: A = B ?? e A = e B , Rule: A = B ?? ?A = ?B, ?? e ?e e 2 = e ?e e 3 Rule: A = B ?? e A = e B , ?? 0 = 0 Numerical evaluation False "proof" of 2 = 3 found by the model when allowing numerical approximation to verify constant expressions.The model noticed that exp(?e e 2 ) = exp(?e e 3 ) is considered true by NumPy (as the left and the right hand side are both approximated to 0.0) to conclude that 2 = 3 using the injectivity of the exponential function. False "proof" that 0 = 0 found by the model when allowing numerical approximation to verify constant expressions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>exp(?x) exp(x ? y) = exp(?y) ) = cos(x/2) 2 ? sin(x/2) + y) ? sin(x ? y) = 2 sin(y) cos(x) =? 2x cosh(ln(x)) = x 2 + 1 20 14 18 12 tanh(x) = (exp(x) ? exp(?x))/(exp(x) + exp(?x)) 46 23 30 11 cos(x ? y) + cos(x + y) = 2 cos(x) cos(y) ? y) + cosh(x + y) = 2 cosh(x) cosh(y) 84 31 84 29 tanh(x) = (exp(2x) ? 1)/(exp(2x) + 1) 205 65 176 39 sin(x) = 2 sin(x/2) cos(x/2) 29 17 21 8 cos(2x) = 2 cos(x) 2 ? 1 72 26</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 12 :</head><label>12</label><figDesc>Average CPU time of proofs found by our model using different minimization objectives. When the model is trained to generate proofs that minimize the running time in Lean (red), the average proof time is significantly lower.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>1 theorem imo_2001_p6 2 (</head><label>12</label><figDesc>a b c d : N) 3 (h0 : 0 &lt; a ? 0 &lt; b ? 0 &lt; c ? 0 &lt; d) 4 (h1 : d &lt; c) 5 (h2 : c &lt; b) 6 (h3 : b &lt; a) 7 (h4 : a * c + b * d = (b + d + a -c) * (b + d -a + c)) : 8 ? nat.prime (a * b + c *</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 14 :</head><label>14</label><figDesc>A proof found by our model of another IMO problem in miniF2F. Although the proof is valid, the statement is erroneous. The hypothesis h4 : b + d ? a + c actually represents max(b + d ? a, 0) + c. This is due to Lean's nat type behaviour where (a : N) ? (b : N) = (0 : N) if b ? a. This makes the exercise easier than it should be, and the proof is no longer valid on the fixed statement.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc># train theorems # train proof steps Avg. goal length Dataset statistics for supervised training.</figDesc><table><row><cell>Equations</cell><cell>?</cell><cell>?</cell><cell>33.7</cell></row><row><cell>Metamath</cell><cell>35k</cell><cell>1M</cell><cell>120.1</cell></row><row><cell>Lean</cell><cell>24k</cell><cell>144k</cell><cell>169.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Pass rate on Lean environment using 64 trials (pass@64). Numbers with a ? exponent correspond to the cumulative pass-rate since the evaluated statements are part of the online training. Evariste refers to the method described in this paper.7.1.1 Lean In Lean, we run our experiments on A100 GPUs with 32 trainers and 200 provers. Each prover runs our Lean API on 48 CPU cores. Unlike Polu et al. [18], we sample statements equally from mathlib-train and miniF2F-curriculum, to avoid giving too much importance to statements from a different domain than the target. After 1 day of training (i.e. (200 + 32) A100 days of compute), each statement from miniF2F-curriculum has been sampled on average 250 times, and 110 out of the 327 statements have been solved. Our model outperforms GPT-f on miniF2F-test, with an approximately 10? training time speed-up. After 7 days, we solve 139 statements of miniF2F-curriculum (100 for GPT-f), and observe further improvements on miniF2F-valid or miniF2F-test.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>7.2.1 Online training data for tactic objective</figDesc><table><row><cell>Proof Of</cell><cell cols="2">All Solved</cell><cell cols="2">Root</cell><cell>All Nodes</cell></row><row><cell>Type of Proof</cell><cell>All</cell><cell>Min</cell><cell>All</cell><cell>Min</cell><cell>-</cell></row><row><cell>Metamath (valid)</cell><cell>61.2</cell><cell>65</cell><cell cols="2">57.4 68.6</cell><cell>51.6</cell></row><row><cell>Metamath (test)</cell><cell cols="4">57.2 58.8 54.8 57.4</cell><cell>54.4</cell></row><row><cell cols="5">Equations (Identities) 40.6 78.1 37.5 71.3</cell><cell>37.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Number of Equations rules converted from Lean. The converted Lean theorems can be used to generate synthetic theorems within the Equations environment. The generated theorems can then in turn be converted back to Lean, along with their proofs. Some theorems are generic and can be applied to different types of variables (e.g. add_comm), and will appear in different categories. Overall, we automatically converted 1702 different Lean rules in our Equations environment.</figDesc><table><row><cell cols="2">1 theorem SYNTHETIC_0</cell></row><row><cell>2</cell><cell>(x1 x3 x4 : R) :</cell></row><row><cell>3</cell><cell>((0:R) ? ((real.cos (real.cos ((-6:R) / ((x1 -x4) / x3)))) / (2:R))) :=</cell></row><row><cell cols="2">4 begin</cell></row><row><cell>5</cell><cell>apply norm_num.nonneg_pos,</cell></row><row><cell>6</cell><cell>apply half_pos,</cell></row><row><cell>7</cell><cell>apply real.cos_pos_of_le_one,</cell></row><row><cell>8</cell><cell>apply real.abs_cos_le_one,</cell></row><row><cell cols="2">9 end</cell></row><row><cell>10</cell><cell></cell></row><row><cell cols="2">11 theorem SYNTHETIC_1</cell></row><row><cell>12</cell><cell>(x2 : R)</cell></row><row><cell>13</cell><cell>(h0 : ((abs (5:R)) &lt; x2)) :</cell></row><row><cell>14</cell><cell>((1:R) &lt; (real.exp ((5:R) + x2))) :=</cell></row><row><cell cols="2">15 begin</cell></row><row><cell>16</cell><cell>rw real.one_lt_exp_iff,</cell></row><row><cell>17</cell><cell>rw ? neg_lt_iff_pos_add,</cell></row><row><cell>18</cell><cell>apply neg_lt_of_abs_lt h0,</cell></row><row><cell cols="2">19 end</cell></row><row><cell>20</cell><cell></cell></row><row><cell cols="2">21 theorem SYNTHETIC_2</cell></row><row><cell>22</cell><cell>(x1 x4 : R)</cell></row><row><cell>23</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>Qualitative comparison of the frequency of specific Lean tactics when using different minimization objective. Tactics in the upper half are slow automated tactics, while tactics in the bottom half are faster and simpler.F Example Lean proofsIn this section, we show examples of proofs found by our model. 1 theorem imo_1964_p1_2 (n : N) : ?7|2 n + 1 :=</figDesc><table><row><cell cols="2">2 begin</cell></row><row><cell>3</cell><cell>rw nat.dvd_iff_mod_eq_zero,</cell></row><row><cell>4</cell><cell>rewrite [nat.add_mod, nat.mod_eq_of_lt],</cell></row><row><cell>5</cell><cell>obviously,</cell></row><row><cell>6</cell><cell>apply nat.strong_induction_on n,</cell></row><row><cell>7</cell><cell>induction n,</cell></row><row><cell>8</cell><cell>{</cell></row><row><cell>9</cell><cell>intros n IH,</cell></row><row><cell>10</cell><cell>cases n,</cell></row><row><cell>11</cell><cell>norm_num,</cell></row><row><cell>12</cell><cell>cases n,</cell></row><row><cell>13</cell><cell>norm_num,</cell></row><row><cell>14</cell><cell>rw [nat.succ_eq_add_one, pow_succ],</cell></row><row><cell>15</cell><cell>rw [nat.succ_eq_add_one, pow_succ],</cell></row><row><cell>16</cell><cell>induction n,</cell></row><row><cell>17</cell><cell>norm_num,</cell></row><row><cell>18</cell><cell>rw [nat.succ_eq_add_one, pow_succ],</cell></row><row><cell>19</cell><cell>norm_num [nat.mul_mod, ?mul_assoc],</cell></row><row><cell>20</cell><cell>contrapose! IH,</cell></row><row><cell>21</cell><cell>refine n_n, nat.lt_succ_iff.mpr _, IH ,</cell></row><row><cell>22</cell><cell>exact nat.le_succ_of_le (nat.le_succ _),</cell></row><row><cell>23</cell><cell>},</cell></row><row><cell>24</cell><cell>exact n_ih,</cell></row><row><cell cols="2">25 end</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">A hypergraph is a graph where an edge leads to a set of nodes that is potentially empty in our set-up. A hypertree is a hypergraph without cycles. More formal definitions can be found in Appendix A.1</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the Meta AI and FLARE teams for useful comments and discussions throughout this work, notably, Faisal Azhar, Antoine Bordes, Quentin Carbonneaux, Maxime Darrin, Alexander Miller, Vincent Siles, Joe Spisak and Pierre-Yves Strub. We also thank the members of the Lean community for their help, notably Fabian Gl?ckle for valuable feedback on this project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the geographical problem of the four colours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alfred B Kempe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American journal of mathematics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="193" to="200" />
			<date type="published" when="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Univalent foundations of mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Voevodsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Logic, Language, Information, and Computation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="4" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A formal proof of the kepler conjecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gertrud</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Truong</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Magron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Mclaughlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Truong</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Nipkow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Obua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Pleso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Rute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Solovyev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">An</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tr?n</forename><surname>Trung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diep</forename><surname>Trieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Zumkeller</surname></persName>
		</author>
		<idno type="DOI">10.1017/fmp.2017.1</idno>
	</analytic>
	<monogr>
		<title level="j">Forum of Mathematics, Pi</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2017-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The lean theorem prover (system description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>De Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soonho</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Avigad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Floris</forename><surname>Van Doorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Von Raumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automated Deduction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="378" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An analysis of alpha-beta pruning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald W</forename><surname>Knuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="293" to="326" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A model of two-player evaluation functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Abramson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Korf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="90" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A general reinforcement learning algorithm that masters chess, shogi, and go through self-play</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dharshan</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">362</biblScope>
			<biblScope unit="issue">6419</biblScope>
			<biblScope unit="page" from="1140" to="1144" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunhao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">Michael</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Polu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.00110</idno>
		<title level="m">Minif2f: a cross-system benchmark for formal olympiad-level mathematics</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A proof method for quantification theory: Its justification and realization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Gilmore</surname></persName>
		</author>
		<idno type="DOI">10.1147/rd.41.0028</idno>
		<ptr target="https://doi.org/10.1147/rd.41.0028" />
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Dev</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="35" />
			<date type="published" when="1960-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A computing procedure for quantification theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hilary</forename><surname>Putnam</surname></persName>
		</author>
		<idno type="DOI">10.1145/321033.321034</idno>
		<ptr target="https://doi.org/10.1145/321033.321034" />
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="201" to="215" />
			<date type="published" when="1960-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">E-a brainiac theorem prover</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Commun</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="111" to="126" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Vampire 1.1 (system description)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Riazanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Voronkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAR</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Isabelle/HOL: A Proof Assistant for Higher-Order Logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Nipkow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">C</forename><surname>Paulson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Wenzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<imprint>
			<biblScope unit="volume">2283</biblScope>
			<date type="published" when="2002" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Interactive theorem proving and program development: Coq&apos;Art: the calculus of inductive constructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Bertot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Cast?ran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Generative language modeling for automated theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Polu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03393</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Proof artifact co-training for theorem proving with language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">Michael</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Rute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.06203</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Polu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">Michael</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunhao</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.01344</idno>
		<title level="m">Mantas Baksys, Igor Babuschkin, and Ilya Sutskever. Formal mathematics statement curriculum learning</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Holophrasm: a neural automated theorem prover for higher-order logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Whalen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.02644</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Holist: An environment for machine learning of higher order logic theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitij</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stewart</forename><surname>Wilcox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="454" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hol light: A tutorial introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Formal Methods in Computer-Aided Design</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="265" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Tactictoe: learning to prove with tactics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramana</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Norrish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="286" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning theorem proving components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Chvalovsk?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Jakub?v</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miroslav</forename><surname>Ol??k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automated Reasoning with Analytic Tableaux and Related Methods</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="266" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Unsupervised translation of programming languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baptiste</forename><surname>Roziere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lowik</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.03511</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Analysing mathematical reasoning abilities of neural models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Saxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1gR5iR5FX" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep learning for symbolic mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Charton</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=S1eZYeHFDS" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Deep symbolic regression for recurrent sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Alexandre</forename><surname>St?phane D&amp;apos;ascoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Kamienny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Charton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.04600</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><forename type="middle">Landajuela</forename><surname>Brenden K Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrell</forename><forename type="middle">N</forename><surname>Larma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><forename type="middle">Prata</forename><surname>Mundhenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soo</forename><forename type="middle">Kyung</forename><surname>Santiago</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanne Taery</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=m5Qsh0kBQG" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning advanced mathematical computations from examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Charton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amaury</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06462</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Metamath: A Computer Language for Mathematical Proofs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Megill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wheeler</surname></persName>
		</author>
		<ptr target="http://us.metamath.org/downloads/metamath.pdf" />
		<imprint>
			<date type="published" when="2019" />
			<publisher>Lulu Press</publisher>
			<pubPlace>Morrisville, North Carolina</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The mathlib Community. The lean mathematical library</title>
		<idno type="DOI">10.1145/3372885.3373824</idno>
		<ptr target="https://doi.org/10.1145%2F3372885.3373824" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs</title>
		<meeting>the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Mastering chess and shogi by self-play with a general reinforcement learning algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dharshan</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.01815</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Monte-carlo tree search as regularized policy optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Jean-Bastien Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhao</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Valko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Munos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3769" to="3778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Parallel monte-carlo tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mj-B</forename><surname>Guillaume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chaslot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hjvd</forename><surname>Winands</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Herik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computers and Games</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="60" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Blackwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cagdas</forename><surname>Alcicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rory</forename><surname>Fearon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><forename type="middle">De</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vedavyas</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stig</forename><surname>Petersen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.04296</idno>
		<title level="m">Massively parallel methods for deep reinforcement learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.07291</idno>
		<title level="m">Cross-lingual language model pretraining</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Mass: Masked sequence to sequence pre-training for language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaitao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02450</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Deep encoder, shallow decoder: Reevaluating non-autoregressive machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungo</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10369</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Reducing transformer depth on demand with structured dropout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SylO2yStDr" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Modifications of uct and sequence-like simulations for montecarlo go</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE Symposium on Computational Intelligence and Games</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="175" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Monte-carlo tree search solver</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yngvi</forename><surname>Winands</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jahn-Takeshi</forename><surname>Bj?rnsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computers and Games</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Selecting their optimal values would be difficult in practice, if not impractical, for several reasons. First, the model is constantly evolving over time, and the optimal parameters may evolve as well. For instance, if the model becomes too confident about its predictions, we may want to increase the decoding temperature to ensure a large diversity of tactics. Second, even for a fixed model, the ideal parameters may be goal-specific. If an input statement can only be proved with very deep proofs, we will favor depth over breadth, and a small number of tactics per node. If the proof is expected to be shallow and to use rare tactics, we will want to penalize the exploration in depth and increase the number of tactics sampled per node. Finally, there are simply too many parameters to tune and running each experiment is expensive. Thus, we do not set HTPS hyper-parameters to a fixed value</title>
	</analytic>
	<monogr>
		<title level="m">C Proof Search Hyper-Parameters HTPS depends on many hyper-parameters: the decoding hyper-parameters of the policy model and the search hyper-parameters</title>
		<imprint/>
	</monogr>
	<note>but sample them from pre-defined ranges at the beginning of each proof. The decoding parameters and the chosen distribution are the following: ? Number of samples: the number of tactics sampled from the policy model when a node is expanded. Distribution: uniform on discrete values [8, 16, 32, 48</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<title level="m">? Temperature: temperature used for decoding. Distribution: uniform on range</title>
		<imprint/>
	</monogr>
	<note>0.8, 2.0</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">? Length penalty: length penalty used for decoding</title>
		<imprint/>
	</monogr>
	<note>Distribution: uniform on range [0, 1.2</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<title level="m">Number of expansions: the search budget, i.e. the maximum number or nodes in the proof graph before we stop the search. Distribution: log-uniform</title>
		<imprint/>
	</monogr>
	<note>with range [1000, 10000</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">? Depth penalty: an exponential value decay during the backup-phase, decaying with depth to favor breadth or depth. Distribution: uniform on discrete values</title>
		<imprint/>
	</monogr>
	<note>0.8, 0.9, 0.95, 1</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Exploration: the exploration constant c in the policy (PUCT or RT)</title>
		<imprint/>
	</monogr>
	<note>Distribution: loguniform with range. 0.01, 100</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">When sampling proof search parameters during evaluation, we use the same distributions than at training time, with two differences: we fix the number of expansions to 5k in Lean and 10k in Metamath</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">D Metamath Lean versions To compare our models in the same setup while working on this project, we ran all our experiments with a fixed version of Metamath and Lean. In particular, all experiments were run with the following GitHub commits of set.mm, Lean, miniF2F</title>
		<ptr target="https://github.com/metamath/set.mm:861bd3552636dcdb9cbc8df59d01b14520c72f82?https://github.com/leanprover/lean/:tag/v3.3.0?https://github.com/openai/miniF2F:21723db70bbd030e034ed374db74cea4be1bf681?https://github.com/openai/miniF2F/tree/statement_curriculum_learning:c9d827c871aff2ab0f5ec64a0d72e61111a7f072?https://github.com/leanprover-community/mathlib" />
		<imprint>
			<biblScope unit="page" from="9" to="17" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
