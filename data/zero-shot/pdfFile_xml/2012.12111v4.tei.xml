<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MOCCA: Multi-layer One-Class ClassificAtion for Anomaly Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Valerio</forename><surname>Massoli</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Falchi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alperen</forename><surname>Kantarci</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Eymanur Akti</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hazim</forename><surname>Kemal Ekenel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Amato</surname></persName>
						</author>
						<title level="a" type="main">MOCCA: Multi-layer One-Class ClassificAtion for Anomaly Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Anomaly Detection</term>
					<term>One-Class Classification</term>
					<term>Deep Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Anomalies are ubiquitous in all scientific fields and can express an unexpected event due to incomplete knowledge about the data distribution or an unknown process that suddenly comes into play and distorts the observations. Usually, due to such events' rarity, to train deep learning models on the Anomaly Detection (AD) task, scientists only rely on "normal" data, i.e., nonanomalous samples. Thus, letting the neural network infer the distribution beneath the input data. In such a context, we propose a novel framework, named Multi-layer One-Class ClassificAtion (MOCCA), to train and test deep learning models on the AD task. Specifically, we applied our approach to autoencoders. A key novelty in our work stems from the explicit optimization of the intermediate representations for the task at hand. Indeed, differently from commonly used approaches that consider a neural network as a single computational block, i.e., using the output of the last layer only, MOCCA explicitly leverages the multi-layer structure of deep architectures. Each layer's feature space is optimized for AD during training, while in the test phase, the deep representations extracted from the trained layers are combined to detect anomalies. With MOCCA, we split the training process into two steps. First, the autoencoder is trained on the reconstruction task only. Then, we only retain the encoder tasked with minimizing the L2 distance between the output representation and a reference point, the anomaly-free training data centroid, at each considered layer. Subsequently, we combine the deep features extracted at the various trained layers of the encoder model to detect anomalies at inference time. To assess the performance of the models trained with MOCCA, we conduct extensive experiments on publicly available datasets, namely CIFAR10, MVTec AD, and ShanghaiTech. We show that our proposed method reaches comparable or superior performance to state-of-the-art approaches available in the literature. Finally, we provide a model analysis to give insights regarding the benefits of our training procedure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Concerning the Deep Learning (DL) field, an anomaly might be thought of as an out-of-distribution sample presented as input to a Deep Neural Network (DNN). More specifically, from a statistical point of view <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, we can discern among outliers and novelties that are described by the same probability distribution of the normal data and anomalies that are instead characterized by completely different statistics. Being able to detect such events is an attractive feature, especially concerning applications such as surveillance systems <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>, medical diagnosis <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>, fraud detection <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>, and defect detection <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. Indeed the task of Anomaly Detection (AD) <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref> is among the most active research fields in the machine learning community.</p><p>Since the cost to collect large amounts of anomalous samples is prohibitive, the AD is usually considered as an unsupervised problem with the training databases containing non-anomalous class instances only. Thus, to detect anomalies, deep models are typically trained on in-manifold samples only to learn an effective boundary that captures the concept of normality from the distribution of one kind of data only. In recent years, One-Class (OC) approaches to AD have drawn the scientific community's interest. Especially, autoencoders <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref> and GANs <ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref> based approaches reached the highest performance available in the literature.</p><p>In the Machine Learning (ML) field, commonly adopted approaches leverage the models' final output only, thus interpreting a neural network as a single computational block that performs an input-to-output mapping. Concerning such a point of view, throughout this manuscript, we refer to such an approach as "holistic" interpretation. Specifically, what we mean by "holistic" is that both the training and test phases rely on the output of the last layer only, i.e., there is no information extracted from the intermediate levels of the architecture.</p><p>In such a context, our contribution stems from a different interpretation of the mapping represented by a DNN. We show that by leveraging the deep representations extracted at various depths in both the training and inference phases of a learning model, a neural network reaches higher performance on the AD task than when only the last layer's output is considered. We propose a novel framework, named Multi-layer One-Class ClassificAtion (MOCCA), to train and test deep learning models on the AD task. The innovation in our work is the explicit optimization of the intermediate representations and their use in the test phase for the task at hand. MOCCA leverages the multi-layer structure of deep architectures, differently from commonly used approaches that consider a neural network as a single computational block, i.e., using the output of the last layer only. During training, each layer's feature space is optimized for AD, whereas in the test phase, the deep representations extracted from the trained layers are combined to detect anomalies. To prove the effectiveness of our strategy, we apply it to autoencoders. Specifically, with MOCCA, we split the training process into two steps. First, the autoencoder is trained on the reconstruction task only. Then, we only retain the encoder tasked with minimizing the L 2 distance between the output representation and a reference point, the anomaly-free training data centroid, at each considered layer. Subsequently, we combine the deep features extracted at the various trained layers of the encoder model to detect anomalies at inference time. We show a schematic view of our approach in <ref type="figure" target="#fig_0">Figure 1</ref>. Our contributions can be summarized as follows:</p><p>? we formulate a "multi-layer" based approach to AD, named MOCCA, that explicitly optimizes the representations extracted at different layers of a deep learning model during training, and then combines them in the test phase to detect anomalies; ? we perform extensive experiments on publicly available single-image AD datasets, namely, CIFAR10 and MVTec AD <ref type="bibr" target="#b24">[25]</ref>, and empirically show that models trained with the MOCCA approach reach higher performance compared to the state-of-the-art; ? we perform experiments on the ShanghaiTech <ref type="bibr" target="#b25">[26]</ref> dataset, and show that, even though our method is not tailored for video-based AD, it delivers models with performance comparable to state-of-the-art approaches specially designed for such a task. Thus, showing the high generalization capability of our technique; ? we perform a model analysis to give insights into how our approach works and empirically analyze the benefits of exploiting the representations generated at different layers of a learning model.</p><p>The remainder of the paper is organized as follows. In section II, we briefly review the related works, while in section III, we describe our approach to the anomaly detection task. In section IV and section V, we present the datasets we used and report the obtained results on them, respectively. In section VI we perform an analysis of the models, and, finally, in section VII, we conclude the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>The latest approaches to the AD task are mainly based on reconstruction and discrimination techniques. Autoencoders <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref> and GANs <ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref> belong to the former class while the latter approach gathers techniques such as the one-class classification <ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref>.</p><p>Concerning GAN-based approaches, in <ref type="bibr" target="#b31">[32]</ref>, the authors exploit a reconstruction technique that leverages an autoencoder and a CNN that are adversarially trained. In AnoGAN <ref type="bibr" target="#b9">[10]</ref> the generator learns to reconstruct the input sample through latent space optimization, and the discriminator generates deep representations for both the original and the reconstructed samples, while in <ref type="bibr" target="#b35">[36]</ref>, the authors propose to learn an encoder network that maps the input samples directly to the generator's latent space. A slightly different approach is proposed in <ref type="bibr" target="#b22">[23]</ref>, where an explicit latent space minimization is obtained by learning an encoder model. The OC-GAN approach is introduced in <ref type="bibr" target="#b36">[37]</ref>, where authors use a denoising autoencoder network and a classifier in order to learn the latent representations of the normal samples in an adversarial manner.</p><p>In <ref type="bibr" target="#b37">[38]</ref> variational autoencoders are used to detect anomalies by exploiting the reconstruction probability as the objective. In <ref type="bibr" target="#b38">[39]</ref> the authors combine a reconstruction approach based on autoencoders with an autoregressive model that learns a factorization of the latent space distribution. In <ref type="bibr" target="#b39">[40]</ref>, the authors use the structural similarity index metric (SSIM) to train autoencoders while <ref type="bibr" target="#b40">[41]</ref> propose the Inverse-Transform AutoEncoder (ITAE) based on the use of autoencoders that reconstruct images after the application of a set of specific transformations.</p><p>The One-Class (OC) approach has a long history starting from the study of shallow models. Indeed, first attempts in such a direction date back to the 2000s with the proposal of the One-Class SVM <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref>. In <ref type="bibr" target="#b43">[44]</ref>, a hybrid approach is proposed based on deep autoencoders and OC-SVM, while in <ref type="bibr" target="#b44">[45]</ref> the authors trained their models with an OC-SVM equivalent loss function. One of the first proposals concerning an end-to-end training approach to OC-AD is proposed in <ref type="bibr" target="#b45">[46]</ref>, where the code generated by an encoder is mapped to a point within a hypersphere so that the normal samples remained inside of it while anomalous ones lay outside. Lastly, in <ref type="bibr" target="#b46">[47]</ref>, the authors use an encoder for getting the latent representations of the normal samples, and a pseudo-negative class is created using zero-centered Gaussian noise in the same latent space.</p><p>Most recently, Venkataramanan et al. <ref type="bibr" target="#b47">[48]</ref> exploit a variational autoencoder combined with a specialized attention mechanism with the final goal of performing anomaly localization. In <ref type="bibr" target="#b48">[49]</ref>, the authors tackle the problem of the stability training of GANs when there are not lots of data available. A semi-supervised approach is proposed in <ref type="bibr" target="#b49">[50]</ref>, and in <ref type="bibr" target="#b50">[51]</ref>, the authors exploit a student-teacher framework to perform anomaly detection and pixel-precise anomaly segmentation at the same time. In <ref type="bibr" target="#b51">[52]</ref>, they leverage a multiple instance learning approach while in <ref type="bibr" target="#b19">[20]</ref>   differs from them on two key aspects. On the one side, it exploits the deep representation extracted at various layers of the learning model, both at training and inference time, which contrasts to classical methodology in which only the final output is considered to fulfill the task. On the other hand, it does not make any assumption on the deep features' statistical distributions. Combining these two properties allows the model to adjust each single feature space at its best to accomplish the AD task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED APPROACH</head><p>As a general conception, DNNs are a sequence of transformations that approximate a function f ? : X ? Y where X ? R d and Y ? R m are the input and output space, respectively, and ? are the parameters to be learned at training time. We refer to such an approach as "holistic" (see section I for more details) in the sense that the entire net is considered as a single computational block that given an input, returns an output. As opposed to such a point of view, with MOCCA we adopt a "multi-layer" interpretation of the learning models where we consider a DNN as a sequence of single transformations each mapping its input to a more representative space:</p><formula xml:id="formula_0">f ? (x) = ? m (? m ; o m?1 ) ? ? m?1 (? m?1 ; o m?2 ) ? .... ? ? 1 (? 1 ; x)<label>(1)</label></formula><p>where each ? i term represents the operation performed by a specific layer, and the matrices ? i represent their weights and biases. The output of each operation is reported as o i , while x is the network input.</p><p>Our intuition is that the outputs o i of the various layers, i.e., the representations generated at different depths of a DNN, can be exploited to enhance the performance of a learning model on the AD task compared to when the entire decision process leverages the last layer output only. Indeed, it has been already shown in literature <ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref> that deep features extracted at various layers of a model can help a DNN to fulfill its task. However, it is not enough to combine the representations at test time only. Instead, all the layers must be trained to a common aim.</p><p>As mentioned in section I, our base network is an autoencoder where both the encoder and the decoder are Deep Convolutional Neural Network (DCNN). With MOCCA we formulate the training process as a two-stage procedure in which we first train the full autoencoder on the reconstruction task only, and then we specialize only the encoder to detect anomalies by exploiting an OC-like objective <ref type="bibr" target="#b45">[46]</ref> applied to different layers of the network. However, we empirically observe that a single-step end-to-end training, in which we optimize the reconstruction and the OC objectives simultaneously, is more effective than the two-step one for videobased AD. A schematic representation of the MOCCA training procedures is presented in <ref type="figure" target="#fig_1">Figure 2</ref>. As one can see from the figure, we process the model inner layers' output using "selector" and "LSTM" modules concerning single-image and video-based data type, respectively. Concerning the "selector" blocks, they are made of an average pooling operation or a two-layer neural network concerning the CIFAR10 and MVTec AD <ref type="bibr" target="#b24">[25]</ref>, respectively. Specifically, concerning the CIFAR10 dataset, we use only the pooling operation to fully assess the real advantages brought by MOCCA.</p><p>As mentioned above, we exploit the OC objective and we evaluate it by using the deep features extracted at different depths of the encoder model. Specifically, we considered two variants for such an objective function termed softand hardboundary. The first one is expressed as follows:</p><formula xml:id="formula_1">L s j = R 2 j + 1 |B| ? ? |B| i max{0, ? j (x i ; ?) ? c j 2 ?R 2 j }<label>(2)</label></formula><p>The goal of such a loss is to minimize the volume of the hypersphere at each layer j, centered at c j and with radius R j , that is interpreted as the boundary region for normal data <ref type="bibr" target="#b42">[43]</ref>. Then, the goal of Equation 2 is to minimize the radius, R j , of such spheres (one for each trained layer). In other words, we expect the "normal" data to lie within a sphere, at each layer, while the anomalous samples are expected to remain outside of it. The second addend in the equation penalizes "normal" data points that lie outside the sphere after being passed through the network. The radius R j is a scalar quantity evaluated as the 1 ? ? quantile of the features' distance distribution, in a mini-batch, from the centroid c j . We re-evaluate the radius at each layer at regular intervals while training. A decreasing value of the radius at each layer is an indicator of converging training. The other terms in the equation have the following interpretation: |B| is the mini-batch size, ? is a hyperparameter that allows controlling the fraction of allowed outliers, ? j represents the function that the layer j carries out, and x i is the model input.</p><p>Concerning the hard-boundary loss, it is expressed as follows:</p><formula xml:id="formula_2">L h j = 1 |B| ? ? |B| i ? j (x i ; ?) ? c j 2 (3)</formula><p>Differently from Equation 2, Equation 3 simply tries to reduce as much as possible the distance of each sample from the layer's centroid by employing a quadratic loss.</p><p>After the first training step in which we tasked the full autoencoder with the reconstruction objective, we retain only the encoder and perform an initial forward step on the whole training dataset (that contains non-anomalous samples only) to extract deep features at different depths. Subsequently, we evaluate the centroids, at each layer, as the average of those features. We performed experiments in which we tested the hypothesis of using medoids instead of centroids, but we did not observe any improvement. Once we evaluate the centroids, they are kept fix while training the encoder. We also experimented with several strategies to re-evaluate them after a specific number of training iterations, but we did not observe tangible improvements. Regarding the video-based AD, we initialize the centroids at the beginning of the training, i.e., with the model not trained.</p><p>Considering a set of layers J = {j | j = 0, 1, ...J}, we formalize the MOCCA objective, during the second-step of the training, as:</p><formula xml:id="formula_3">L s/h = 1 |J | |J| j L s/h j + ? 2 |P | p ? p 2<label>(4)</label></formula><p>where |J| is the number of layers we consider, and the sum runs over the layer indexes j. The last term of the objective is the L 2 regularization for the model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DATASETS AND TRAINING</head><p>This section reports the used datasets and provides details about the training procedure that we adopt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. CIFAR10</head><p>The CIFAR10 dataset contains 50K training images and 10K test ones shared among ten different classes. We preprocess the images by applying a global contrast normalization procedure using the L 1 norm, and then we normalize them to be in the range [0, +1]. Given each class, which we refer to as the "normal class", we have 5000 images to train the model, and we evaluate each model's performance on the whole test set. With such a training approach, the model only sees instances from the "normal class" and never sees any anomaly while learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. MVTec</head><p>The MVTec AD <ref type="bibr" target="#b24">[25]</ref> dataset comprises ?3.6K and ?1.7K high-resolution images to train and test DNNs, respectively, shared among 15 classes which are divided into two categories: textures (5 classes) and objects (10 classes). The dataset is split into two sets: one for training purposes containing "normal" images only and one specifically designed to test the models' performance. Specifically, the latter one contains anomalous images, with defects of different types and non-anomalous ones. We apply two different preprocessing operations to objects-and texture-type classes. Concerning the formers, we first resize the image to 128x128 pixels and then apply a random rotation in the range [??/4, +?/4] when the anomaly of the object is not related to its orientation. Instead, we first resize images to 512x512 pixels in the latter type of classes, and then we crop 64x64 non-overlapping patches used as input to the network. Moreover, we augment the data by exploiting a random rotation in the range [0, +?/4]. Finally, we normalize all the objects-and texture-type images to be in the range [?1, +1]. In <ref type="figure" target="#fig_2">Figure 3</ref> we show an example of textures-and objects-type images from the dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. ShanghaiTech</head><p>The ShanghaiTech <ref type="bibr" target="#b25">[26]</ref> dataset is one of the largest video anomaly datasets. It comprises over 270,000 training frames from 13 scenes with complex light conditions and camera angles, accounting for 130 abnormal events. We follow the same preprocessing strategy as in <ref type="bibr" target="#b38">[39]</ref>, i.e., we use a MOGbased approach to estimate the background and remove it from the frames. By employing such a procedure, we eliminate the necessity of background estimation and let the model focus on foreground objects only. Given a video, we construct clips made by 16 frames to be used as input to the learning models. To exploit the temporal correlation among frames, we employ LSTM cells (we refer the reader to section III for more details about our models' architecture). Finally, we resize each frame to 256x512 pixels to feed models. In <ref type="figure">Figure 4</ref> we report an example of "normal" and anomalous frames from two different videos. <ref type="figure">Fig. 4</ref>. Samples of "normal" (left) and anomalous (right) frames from the ShanghaiTech <ref type="bibr" target="#b25">[26]</ref> dataset. We highlight in red the anomalies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Training details</head><p>Concerning the CIFAR10 dataset, we use a LeNet-like architecture as in <ref type="bibr" target="#b45">[46]</ref>, made of three convolutional layers and one fully connected layer after them. We use the Adam <ref type="bibr" target="#b55">[56]</ref> optimizer for both pre-train the full architecture and train the encoder with learning rates of 1.e ?3 and 1.e ?4 , respectively. We set the encoder code's size equals to 128 and the value of the parameter ? in the range [0, 0.1]. Finally, we use a batch size of 256. As we mentioned in section III, concerning the CIFAR10 dataset, we use an average pooling operation as the "selector" module. Thus, we emphasize that the higher performance reached by using MOCCA is not due to larger, deeper, or more models. Instead, the benefits of using MOCCA stand from its ability to exploit the representations generated at different depths of a learning model. To our aim, we train ten different seeded models on each class, considering the other nine as anomalies. Such a procedure allows us to estimate the mean response of our approach and its standard deviation.</p><p>Regarding the MVTec AD <ref type="bibr" target="#b24">[25]</ref> and the ShanghaiTech [26] datasets, we use a residual-like structure that comprises four and five residual blocks, respectively, followed by two fully connected layers. For this dataset, the "selector" blocks consist of a convolutional layer followed by a pooling operation, a batch norm layer, and a final fully connected layer. In videobased AD, we substitute the "selector" networks with LSTM cells to exploit the time correlation among the frames within a given input clip. To train models on those two datasets, we use again the Adam <ref type="bibr" target="#b55">[56]</ref> optimizer and a learning rate in the set {10 ?2 , 10 ?3 } that we drop by a factor of ten at specific epochs depending on the class under study. Being each class of each dataset an independent AD problem, we use different hyperparameters to train the models on each of them. Moreover, we do not always use the same set of layers to evaluate the objective in Equation 4. Indeed, we train the models by using different layer combinations and finally select the best performing one in each class.</p><p>To allow the researchers to reproduce our work, we made the code publicly available on GitHub 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>In this section, we report our experimental results. However, before that, we describe the various metrics we use to assess the models' performance. 1 https://github.com/fvmassoli/mocca-anomaly-detection.git</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Metrics</head><p>To assess the performance of the models trained with MOCCA and compare them to the other approaches in the literature, we exploit two metrics: the Area Under the Curve (AUC) and the maximum Balanced Accuracy (maxBA). The former metric is the area under the Receiver Operating Characteristics curve. Instead, concerning the latter, the Balanced Accuracy (BA) represents the arithmetic mean between the sensitivity, i.e., percentage of anomalous samples correctly detected, and the specificity, i.e., same as the sensitivity but for non-anomalous samples:</p><formula xml:id="formula_4">BA = T P 2 ? (T P + F N ) + T N 2 ? (T N + F P )<label>(5)</label></formula><p>where T P and F N are the true positives and the false negatives, respectively, and T N and F P are the true negatives and the false positives, respectively.</p><p>In the AD context, it is useful to quote both the AUC and the maxBA metrics. The former one provides an aggregate measure of the performance of a model across all possible classification thresholds. Instead, maxBA is a measure of performance at a specific threshold that could be used in production. It selects the threshold for which the balanced accuracy measure, i.e., the average among the correctly classified images for anomalous (true positives) and anomaly-free test images (true negatives), is maximum and reports the obtained BA. We evaluate both metrics only on the MVTec AD <ref type="bibr" target="#b24">[25]</ref> dataset since for the CIFAR10 and ShanghaiTech <ref type="bibr" target="#b25">[26]</ref> datasets we only found the AUC values reported in the literature. Concerning the anomaly score for a given input image, we evaluate its value as:</p><formula xml:id="formula_5">? j (x) = ? j (x, ?) ? c j 2 (6) ?(x) = 1 |J | |J | j ? ? ? ? ? ? j (x) hard boundary ? j (x) ? R 2 j soft boundary</formula><p>where x is the input image, J = {j | j = 0, 1, ...J} is the set of layers we consider, ? j (x, ?) is the feature vector extracted at layer j, and c j and R j are the center of the hypersphere and its radius at the layer j, respectively and ? is the anomaly score. We refer the reader to section III for further details on the meaning of the boundaries. Concerning the textures-type classes from the MVTec AD <ref type="bibr" target="#b24">[25]</ref>, we evaluate the anomaly score as the maximum among the scores relative to each of the 64x64 patches of the given image: ? h/s (x) = max ? h/s (patch i )) | i = 1, 2, ..., 64 <ref type="formula">(7)</ref> where the superscripts s and h correspond to when we apply a "soft" or "hard" boundary while training the model, respectively. More details on how we extract patches from a single image can be found in subsection IV-B. Lastly, considering video-based input we consider a single input clip as made of 16 frames. We then apply a sliding window technique to move through all the frames of a given video and construct the input clips. Since each frame can appear multiple times across different clips, we evaluate its score as the mean value among all of its scores. Moreover, a single frame can have different scores in different clips having a different time correlation, captured by the LSTMs (see <ref type="figure" target="#fig_1">Figure 2)</ref>, with all the other frames. For such a reason, we normalize the score of each frame to the maximum and minimum values of the scores within the clips in which the frame under analysis is present:</p><formula xml:id="formula_6">? h/s (x i ) = ? h/s (x i ) ? max clips ? h/s (x i ) max clips ? h/s (x i ) ? min clips ? h/s (x i )<label>(8)</label></formula><p>Finally, we add a reconstruction term to the score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental results -CIFAR10</head><p>Concerning the CIFAR10 dataset, we instantiate each class as a single AD problem, and we train ten different seeded models on each of them. Such a procedure allows us to quote a mean AUC value and the corresponding variance. We report the results in <ref type="table">Table I.</ref> As we can see from <ref type="table">Table I</ref>, our approach reaches the highest performance on six out of ten classes. Moreover, on class-1, class-5, class-7, class-8, and class-9, the MOCCA method performs better than the state-of-the-art (SotA) results concerning both the "soft" and the "hard" boundaries. As reported in subsection IV-D, on the CIFAR10 dataset we use a LeNet-like architecture as in <ref type="bibr" target="#b45">[46]</ref>. Moreover, to better emphasize that our approach's higher performance is not due to a mere addition of more models to the baseline, we use averaging pooling layers as "selectors" blocks. Thus, since we use the same architecture as in <ref type="bibr" target="#b45">[46]</ref>, we can conclude that the higher performance of our models are only due to the use of MOCCA and not because we use deeper models or because we add more branches to the base architecture. To summarize the previous results, we report in <ref type="table" target="#tab_2">Table II</ref> the AUC values, for each model in <ref type="table">Table I</ref>, averaged among all the ten classes of the dataset.</p><p>From <ref type="table" target="#tab_2">Table II</ref>, it is clear that our approach reaches the highest performance concerning both types of boundary settings. Moreover, we can appreciate that we obtain higher performance, also considering larger models such as LSA <ref type="bibr" target="#b38">[39]</ref>.</p><p>Average AUC VAE <ref type="bibr" target="#b56">[57]</ref> 0.586 ? .039 Pix CNN <ref type="bibr" target="#b57">[58]</ref> 0.551 ? .038 DCAE ? 0.595 ? .024 AnoGAN [10] ? 0.618 ? .021 LSA <ref type="bibr" target="#b38">[39]</ref> 0.640 ? .029 Deep SVDD (s) <ref type="bibr" target="#b45">[46]</ref> 0.634 ? .022 Deep SVDD (h) <ref type="bibr" target="#b45">[46]</ref> 0.648 ? .022</p><formula xml:id="formula_7">MOCCA (s) 0.676 ? .024 MOCCA (h) 0.669 ? .023</formula><p>Values reported in <ref type="bibr" target="#b38">[39]</ref>; ? Values reported in <ref type="bibr" target="#b45">[46]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experimental results -MVTec AD</head><p>Regarding the MVTec AD <ref type="bibr" target="#b24">[25]</ref> dataset, also, in this case, we consider each class as an independent AD problem. As reported in subsection IV-B, the dataset classes are divided into texture-and object-like sets. For each class, we report the maxBA and the AUC in <ref type="table" target="#tab_2">Table III and Table IV</ref>, respectively. Regarding the texture-type of classes, we see from the tables that the MOCCA approach allows our models to reach the highest performance on three out of five classes concerning both the hard and soft boundaries. Similar reasonings hold in the case of object-type classes, too. Concerning the results from <ref type="bibr" target="#b47">[48]</ref>, it is important to highlight that, even though we report their results, they should not directly compared with others. The reason for that is because in <ref type="bibr" target="#b47">[48]</ref>, the models are trained on more data rather than on MVTec AD only. Thus, those results are not directly comparable with the other methods. Due to the very low number of test images available in the dataset, typically large variations in the performance of the model are observed among the different classes. Thus, to better compare the performance of the various approaches, we report in <ref type="table">Table V</ref> the overall mean values for the maxBA and the AUC evaluated among all classes of the dataset.</p><p>From the table, we conclude that the MOCCA approach allows us to reach the highest performance on both types of metrics considering both the soft and hard type of boundary.  <ref type="bibr" target="#b40">[41]</ref>; Values reported in <ref type="bibr" target="#b60">[61]</ref>; Results obtained by using more data -should NOT be directly compared to all the other methods </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental results -ShanghaiTech</head><p>Differently from the CIFAR10 and MVTec AD <ref type="bibr" target="#b24">[25]</ref> datasets, the ShanghaiTech <ref type="bibr" target="#b25">[26]</ref> concerns the video-based AD task. Although we test models trained with MOCCA against such a protocol, it is essential to stress that our approach is not specially designed for the video-based scenario. We report our results in <ref type="table" target="#tab_6">Table VI</ref>   <ref type="bibr" target="#b38">[39]</ref> 0.725 ITAE <ref type="bibr" target="#b40">[41]</ref> 0.725 FFP+MC <ref type="bibr" target="#b65">[66]</ref> 0.728 Mem-Guided (w/o Mem.) <ref type="bibr" target="#b66">[67]</ref> 0.668 Mem-Guided (w/ Mem.) <ref type="bibr" target="#b66">[67]</ref> 0.705 MemAE-nonSpar <ref type="bibr" target="#b19">[20]</ref> 0.688 MemAE <ref type="bibr" target="#b19">[20]</ref> 0.712 Clustering-Driven <ref type="bibr" target="#b67">[68]</ref> 0.733</p><formula xml:id="formula_8">MOCCA (s) 0.730 MOCCA (h)</formula><p>0.725 ? Values reported in <ref type="bibr" target="#b40">[41]</ref>  From <ref type="table" target="#tab_6">Table VI</ref>, we can see that our approach's performance is utterly comparable to the current SotA models, specifically designed to handle video-based input. Thus, showing that our method is applicable to both the image-and video-based anomaly detection tasks. Indeed, the only modification we apply to MOCCA for video-based contexts is to move to a single-step training, based on the same objectives, and to substistute the "selector" modules with LSTMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. MODEL ANALYSIS</head><p>In this section, we look in more detail at the behavior of our models. First, we focus on an ablation study to show the impact of using a different number of layers to evaluate a specific image's anomaly score. Specifically, we prove that with MOCCA, we effectively succeed in exploiting the deep representations extracted at different depths of a DNN. To our aim, we perform the ablation study considering the "Leather" class of the MVTec AD <ref type="bibr" target="#b24">[25]</ref> dataset. We report the results in <ref type="table" target="#tab_2">Table VII</ref> As described in subsection IV-D, the encoder's architecture consists of four residual blocks followed by two fully connected layers. The indexes in the first column of <ref type="table" target="#tab_2">Table VII</ref> correspond to the layers' ordering where the 0-th layer is the closest to the input. The results in <ref type="table" target="#tab_2">Table VII</ref> should be interpreted as follows. Each row in the table represents a different model that we trained with MOCCA by considering the output from the layers listed in the first column. For example, the first row represents the results we obtained by considering the output (in the training and test phases) from the last layer only, while in the second row we consider the layer 5 and 6 together. We aim at showing that by exploiting the output at different layers while training a learning model, we can use the output from those same layers at inference time to enhance the network's discrimination power. On the contrary, we experimentally observed that training the model using the last layer's output only and then using more layers at inference time always gave worse results. Such an observation is one of the key points on which we base our approach.</p><p>As it is clear from the table, independently from the type of boundary we apply, we obtain higher results by utilizing more layers. This result supports our intuition that the features extracted at different depths help to detect anomalies in the input images. By carefully looking at Table VII we notice that the maxBA improves until we add layers 4 and 5 to the last one. Moreover, we can notice that, in the case of the hard boundary setting, we can obtain a slight improvement by adding layer 3. Finally, we notice that by adding more layers, we do not see any further improvement. We can interpret such behavior by considering that since the first layers are closer to the input data, they specialize on simple patterns. On the contrary, higher layers generate representations that amplify aspects of the input that are important for discrimination <ref type="bibr" target="#b68">[69]</ref>, thus more useful to fulfill the final task. Hence, adding layers that are too close to the input data does not improve the learning model's overall performance.</p><p>We then focus our attention on the distribution of the distances among the features and the centroids, of a given class, at different layers. Specifically, we compare our training approach against the "holistic" approach, i.e., when the learning model is considered a single computational block. As specified in section I, "holistic" refers to the approach similar to <ref type="bibr" target="#b45">[46]</ref> where the last layer's output only is used to train and test the encoder on the AD task. To our aim, we train two identical models once with the MOCCA approach and then by evaluating the OC loss on the last layer only ("holistic"). We report the resulting Cumulative Density Function (CDF) in <ref type="figure" target="#fig_3">Figure 5</ref>. Concerning the model trained with MOCCA, we see that the distributions for "normal" images always lies at the left of the corresponding for anomalous ones (as one would expect). Moreover, we see that the CDFs of "normal" images rise faster than the ones of anomalous samples. Thus, allowing one to set a more discriminative threshold on the anomaly score. On the contrary, we see that by considering the last layer only while training on the AD task, the distributions of distances for anomalous and "normal" images are highly overlapped even in the last layer. Thus, by training with MOCCA, we have a double gain: on the one side, we obtain discriminative deep features from more layers, and on the other hand, we are able to set more discriminative thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>The anomaly detection task is still an open challenge in many scientific fields. Several approaches have been proposed to tackle this problem in the context of deep learning, typically based on an unsupervised training paradigm. Indeed, being rare events, collecting anomalous samples to construct a supervised training dataset might be extremely expensive. Thus, approaches in which neural networks automatically learn the concept of "normality" from non-anomalous data only represent a promising solution.</p><p>We propose to adopt a multi-layer approach, named MOCCA, to exploit the output of a deep model at different depths to detect anomalous input in the one-class setting. Differently from the usual "holistic" interpretation of a learning model in which a neural network is considered a single computational block, MOCCA explicitly leverages the networks' multi-layer composition. Specifically, we show that such an approach enhances a neural network's discrimination capability. We conduct extensive experiments on three different datasets and perform an analysis of the models to support our intuitions. We test our method against the singleimage AD task showing that it improves the state-of-the-art both on the CIFAR10 and MVTec AD datasets. Specifically, concerning the performance averaged among all the classes, MOCCA improves upon the literature results with both the soft and hard type of boundary. We acknowledge the best improvement concerning the overall maxBA on the MVTec AD dataset that overcomes the state-of-the-art results by 6%. Moreover, even though our approach is not tailored for the video-based AD task, we test it also using such a protocol by employing the ShanghaiTech dataset. From the experimental results, we see that with MOCCA, the models' performance is utterly comparable to what was obtained by approaches specially designed for such a task. Thus, showing the high generalization capability of our method.</p><p>Finally, we report insights about the behavior of models trained with MOCCA by performing an ablation study and reporting the different CDFs of the distance of the deep representations from the centroids of a given class across different layers. Such an analysis, pointed out that the benefits from using MOCCA are two-fold: on the one side, we obtain discriminative deep features from more layers, and on the other hand, we are able to set more discriminative thresholds.  Dr. Giuseppe Amato was awarded a PhD in Computer Science at the University of Dortmund, Germany, in 2002. He is a senior researcher at CNR-ISTI in Pisa, where he leads the "Artificial Intelligence for Multimedia and Humanities" (AIMH) laboratory. His main research interests are artificial intelligence, content-based retrieval of multimedia documents, access methods for similarity search.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Schematic representation of the MOCCA approach. Each feature space is represented as an x ? y plane. The cyan dots represent the centroids of the anomaly-free images while the green (red) dots represent the normal (anomalous) samples, respectively. ? i is the distance between the deep representation of a given input image from the centroid at layer i.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Schematic representation of the MOCCA training. Left: two-stage training for single image input. Right: end-to-end training for video-based AD. To exploit the time correlation among frames, LSTMs are used instead of "selector" modules. The superscript s (h) refers to the soft (hard) boundary settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Samples from different classes of the MVTec AD<ref type="bibr" target="#b24">[25]</ref> dataset. Top: texture classes. Bottom: object classes. We highlight in red the anomalies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>a.u.) Centroid Distance (a.u.) Centroid Distance (a.u.) CDF of the test images distance from the "normal" class centroid for the MOCCA approach (top row) and for the "holistic" one (bottom row). The blue (red) line represents the CDF of "normal" (anomalous) images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Dr.</head><label></label><figDesc>Hazim Kemal Ekenel is a Professor at the Department of Computer Engineering in Istanbul Technical University. He received his PhD degree in Computer Science from the University of Karlsruhe (TH) in 2009. His research interest covers computer vision and machine learning with a focus on face analysis. He is a recipient of the Science Academy Turkey's Young Scientist Award 2018 and IEEE Turkey Section's Research Award 2019.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>AUC FOR THE CIFAR10 DATASET. THE SUBSCRIPTS (s) AND (h) REFER TO THE soft AND hard BOUNDARIES, RESPECTIVELY. WE EMPHASIZE IN BOLD THE PERFORMANCE OF THE BEST MODELS. WHENEVER OUR MODELS OVERCOME THE SOTA WITH BOTH THE TYPE OF BOUNDARIES, WE UNDERLINE THE BEST OF THE TWO. WE ONLY REPORT ERRORS FROM OTHERS WHEN AVAILABLE IN THE REFERENCE PAPER.</figDesc><table><row><cell cols="3">Class VAE [57] Pix</cell><cell>DCAE  ?</cell><cell>AnoGAN [10]  ?</cell><cell cols="2">LSA [39] Deep SVDD (s) [46]</cell><cell>MOCCA (s)</cell><cell>Deep SVDD (h) [46]</cell><cell>MOCCA (h)</cell></row><row><cell></cell><cell></cell><cell cols="2">CNN [58]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>0.688</cell><cell>0.788</cell><cell>0.601 ? .007</cell><cell>0.671 ? .025</cell><cell>0.735</cell><cell>0.617 ? .042</cell><cell>0.626 ? .021</cell><cell>0.617 ? .041</cell><cell>0.660 ? .015</cell></row><row><cell>1</cell><cell>0.403</cell><cell>0.428</cell><cell>0.574 ? .029</cell><cell>0.547 ? .034</cell><cell>0.580</cell><cell>0.648 ? .014</cell><cell>0.746 ? .008</cell><cell>0.659 ? .021</cell><cell>0.705 ? .013</cell></row><row><cell>2</cell><cell>0.679</cell><cell>0.617</cell><cell>0.489 ? .024</cell><cell>0.529 ? .030</cell><cell>0.690</cell><cell>0.495 ? .014</cell><cell>0.575 ? .018</cell><cell>0.508 ? .008</cell><cell>0.524 ? .010</cell></row><row><cell>3</cell><cell>0.528</cell><cell>0.574</cell><cell>0.584 ? .012</cell><cell>0.545 ? .019</cell><cell>0.542</cell><cell>0.560 ? .011</cell><cell>0.578 ? .011</cell><cell>0.591 ? .014</cell><cell>0.601 ? .006</cell></row><row><cell>4</cell><cell>0.748</cell><cell>0.511</cell><cell>0.540 ? .013</cell><cell>0.651 ? .032</cell><cell>0.761</cell><cell>0.599 ? .011</cell><cell>0.615 ? .012</cell><cell>0.609 ? .011</cell><cell>0.609 ? .012</cell></row><row><cell>5</cell><cell>0.519</cell><cell>0.571</cell><cell>0.622 ? .018</cell><cell>0.603 ? .018</cell><cell>0.546</cell><cell>0.621 ? .024</cell><cell>0.663 ? .010</cell><cell>0.657 ? .025</cell><cell>0.684 ? .016</cell></row><row><cell>6</cell><cell>0.695</cell><cell>0.422</cell><cell>0.512 ? .052</cell><cell>0.585 ? .014</cell><cell>0.751</cell><cell>0.678 ? .024</cell><cell>0.674 ? .012</cell><cell>0.677 ? .026</cell><cell>0.671 ? .005</cell></row><row><cell>7</cell><cell>0.500</cell><cell>0.454</cell><cell>0.586 ? .029</cell><cell>0.625 ? .008</cell><cell>0.535</cell><cell>0.652 ? .010</cell><cell>0.721 ? .004</cell><cell>0.673 ? .009</cell><cell>0.685 ? .010</cell></row><row><cell>8</cell><cell>0.700</cell><cell>0.715</cell><cell>0.768 ? .014</cell><cell>0.758 ? .041</cell><cell>0.717</cell><cell>0.756 ? .017</cell><cell>0.791 ? .012</cell><cell>0.759 ? .012</cell><cell>0.792 ? .008</cell></row><row><cell>9</cell><cell>0.398</cell><cell>0.426</cell><cell>0.673 ? .030</cell><cell>0.665 ? .028</cell><cell>0.548</cell><cell>0.710 ? .011</cell><cell>0.773 ? .010</cell><cell>0.731 ? .012</cell><cell>0.758 ? .007</cell></row><row><cell cols="5">Values reported in [39];  ? Values reported in [46]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>TABLE I</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II AUC</head><label>II</label><figDesc>AVERAGED AMONG ALL CLASSES OF THE CIFAR10 DATASET. THE SUBSCRIPTS (s) AND (h) REFER TO THE soft AND hard BOUNDARIES, RESPECTIVELY. WE EMPHASIZE IN BOLD THE PERFORMANCE OF THE BEST MODELS. WHENEVER OUR MODELS OVERCOME THE SOTA WITH BOTH THE TYPE OF BOUNDARIES, WE UNDERLINE THE BEST OF THE TWO.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Values reported in<ref type="bibr" target="#b61">[62]</ref>; ? Values reported in<ref type="bibr" target="#b60">[61]</ref> TABLE III MAXBA FOR ALL THE CLASSES OF THE MVTEC AD [25] DATASET. THE SUBSCRIPTS (s) AND (h) REFER TO THE soft AND hard BOUNDARIES, RESPECTIVELY. WE EMPHASIZE IN BOLD THE PERFORMANCE OF THE BEST MODELS. WHENEVER OUR MODELS OVERCOME THE SOTA WITH BOTH THE TYPE OF BOUNDARIES, WE UNDERLINE THE BEST OF THE TWO.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Textures</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Objects</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Carpet</cell><cell>Grid</cell><cell>Leather</cell><cell>Tile</cell><cell>Wood</cell><cell>Bottle</cell><cell cols="4">Cable Capsule Hazelnut MetalNut</cell><cell>Pill</cell><cell cols="4">Screw Toothbrush Transistor Zipper</cell></row><row><cell>AE SSIM [40]</cell><cell>0.67</cell><cell>0.69</cell><cell>0.46</cell><cell>0.52</cell><cell>0.83</cell><cell>0.88</cell><cell>0.61</cell><cell>0.61</cell><cell>0.54</cell><cell>0.54</cell><cell>0.60</cell><cell>0.51</cell><cell>0.74</cell><cell>0.52</cell><cell>0.80</cell></row><row><cell>AE L2 [40]</cell><cell>0.50</cell><cell>0.78</cell><cell>0.44</cell><cell>0.77</cell><cell>0.74</cell><cell>0.80</cell><cell>0.56</cell><cell>0.62</cell><cell>0.88</cell><cell>0.73</cell><cell>0.62</cell><cell>0.69</cell><cell>0.98</cell><cell>0.71</cell><cell>0.80</cell></row><row><cell>AnoGAN [10]  ?</cell><cell>0.49</cell><cell>0.51</cell><cell>0.52</cell><cell>0.51</cell><cell>0.68</cell><cell>0.69</cell><cell>0.53</cell><cell>0.58</cell><cell>0.50</cell><cell>0.50</cell><cell>0.62</cell><cell>0.35</cell><cell>0.57</cell><cell>0.67</cell><cell>0.59</cell></row><row><cell cols="2">VAE-grad [59]  ? 0.67</cell><cell>0.83</cell><cell>0.71</cell><cell>0.81</cell><cell>0.89</cell><cell>0.86</cell><cell>0.56</cell><cell>0.86</cell><cell>0.74</cell><cell>0.78</cell><cell>0.80</cell><cell>0.71</cell><cell>0.89</cell><cell>0.70</cell><cell>0.67</cell></row><row><cell>AVID [60]  ?</cell><cell>0.70</cell><cell>0.59</cell><cell>0.58</cell><cell>0.66</cell><cell>0.83</cell><cell>0.88</cell><cell>0.64</cell><cell>0.85</cell><cell>0.86</cell><cell>0.63</cell><cell>0.86</cell><cell>0.66</cell><cell>0.73</cell><cell>0.58</cell><cell>0.84</cell></row><row><cell>EGBAD [36]  ?</cell><cell>0.60</cell><cell>0.50</cell><cell>0.65</cell><cell>0.73</cell><cell>0.80</cell><cell>0.68</cell><cell>0.66</cell><cell>0.55</cell><cell>0.50</cell><cell>0.55</cell><cell>0.63</cell><cell>0.50</cell><cell>0.48</cell><cell>0.68</cell><cell>0.59</cell></row><row><cell>CBiGAN [61]</cell><cell>0.60</cell><cell>0.99</cell><cell>0.87</cell><cell>0.84</cell><cell>0.88</cell><cell>0.84</cell><cell>0.73</cell><cell>0.58</cell><cell>0.75</cell><cell>0.67</cell><cell>0.76</cell><cell>0.67</cell><cell>0.97</cell><cell>0.74</cell><cell>0.55</cell></row><row><cell>MOCCA (s)</cell><cell>0.81</cell><cell>0.85</cell><cell>0.96</cell><cell>0.80</cell><cell>0.97</cell><cell>0.90</cell><cell>0.72</cell><cell>0.77</cell><cell>0.77</cell><cell>0.85</cell><cell>0.81</cell><cell>0.82</cell><cell>0.93</cell><cell>0.77</cell><cell>0.78</cell></row><row><cell>MOCCA (h)</cell><cell>0.74</cell><cell>0.76</cell><cell>0.91</cell><cell>0.78</cell><cell>0.94</cell><cell>0.90</cell><cell>0.68</cell><cell>0.75</cell><cell>0.76</cell><cell>0.80</cell><cell>0.69</cell><cell>0.80</cell><cell>0.91</cell><cell>0.81</cell><cell>0.78</cell></row><row><cell cols="5">Values reported in [25];  ? Textures</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Objects</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Carpet</cell><cell>Grid</cell><cell>Leather</cell><cell>Tile</cell><cell>Wood</cell><cell>Bottle</cell><cell cols="5">Cable Capsule Hazelnut MetalNut Pill</cell><cell cols="4">Screw Toothbrush Transistor Zipper</cell></row><row><cell>AE L2 [40]  ?</cell><cell>0.64</cell><cell>0.83</cell><cell>0.80</cell><cell>0.74</cell><cell>0.97</cell><cell>0.65</cell><cell>0.64</cell><cell>0.62</cell><cell>0.73</cell><cell>0.64</cell><cell>0.77</cell><cell>1.00</cell><cell>0.77</cell><cell>0.65</cell><cell>0.87</cell></row><row><cell>GeoTrans [63]  ?</cell><cell>0.44</cell><cell>0.62</cell><cell>0.84</cell><cell>0.42</cell><cell>0.61</cell><cell>0.74</cell><cell>0.78</cell><cell>0.67</cell><cell>0.36</cell><cell>0.81</cell><cell>0.63</cell><cell>0.50</cell><cell>0.97</cell><cell>0.87</cell><cell>0.82</cell></row><row><cell>GANomaly [23]  ?</cell><cell>0.70</cell><cell>0.71</cell><cell>0.84</cell><cell>0.79</cell><cell>0.83</cell><cell>0.89</cell><cell>0.76</cell><cell>0.73</cell><cell>0.79</cell><cell>0.70</cell><cell>0.74</cell><cell>0.75</cell><cell>0.65</cell><cell>0.79</cell><cell>0.75</cell></row><row><cell>ITAE [41]</cell><cell>0.71</cell><cell>0.88</cell><cell>0.86</cell><cell>0.74</cell><cell>0.92</cell><cell>0.94</cell><cell>0.83</cell><cell>0.68</cell><cell>0.86</cell><cell>0.67</cell><cell>0.79</cell><cell>1.00</cell><cell>1.00</cell><cell>0.84</cell><cell>0.88</cell></row><row><cell>EGBAD [36]</cell><cell>0.52</cell><cell>0.54</cell><cell>0.55</cell><cell>0.79</cell><cell>0.91</cell><cell>0.63</cell><cell>0.68</cell><cell>0.52</cell><cell>0.43</cell><cell>0.47</cell><cell>0.57</cell><cell>0.46</cell><cell>0.64</cell><cell>0.73</cell><cell>0.58</cell></row><row><cell>CBiGAN [61]</cell><cell>0.55</cell><cell>0.99</cell><cell>0.83</cell><cell>0.91</cell><cell>0.95</cell><cell>0.87</cell><cell>0.81</cell><cell>0.56</cell><cell>0.77</cell><cell>0.63</cell><cell>0.81</cell><cell>0.58</cell><cell>0.94</cell><cell>0.77</cell><cell>0.53</cell></row><row><cell>CAVGA-Ru [48]</cell><cell>0.73</cell><cell>0.75</cell><cell>0.71</cell><cell>0.70</cell><cell>0.85</cell><cell>0.89</cell><cell>0.63</cell><cell>0.83</cell><cell>0.84</cell><cell>0.67</cell><cell>0.88</cell><cell>0.77</cell><cell>0.91</cell><cell>0.73</cell><cell>0.87</cell></row><row><cell>CAVGA-Du [48]</cell><cell>0.78</cell><cell>0.78</cell><cell>0.75</cell><cell>0.72</cell><cell>0.88</cell><cell>0.91</cell><cell>0.67</cell><cell>0.87</cell><cell>0.87</cell><cell>0.71</cell><cell>0.91</cell><cell>0.78</cell><cell>0.97</cell><cell>0.75</cell><cell>0.94</cell></row><row><cell>MOCCA (s)</cell><cell>0.86</cell><cell>0.87</cell><cell>0.98</cell><cell>0.89</cell><cell>1.00</cell><cell>0.95</cell><cell>0.76</cell><cell>0.82</cell><cell>0.80</cell><cell>0.85</cell><cell>0.82</cell><cell>0.84</cell><cell>0.97</cell><cell>0.88</cell><cell>0.84</cell></row><row><cell>MOCCA (h)</cell><cell>0.74</cell><cell>0.81</cell><cell>0.95</cell><cell>0.85</cell><cell>0.97</cell><cell>0.93</cell><cell>0.72</cell><cell>0.79</cell><cell>0.78</cell><cell>0.84</cell><cell>0.73</cell><cell>0.80</cell><cell>0.95</cell><cell>0.84</cell><cell>0.82</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>? Values reported in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV AUC</head><label>IV</label><figDesc>FOR ALL THE CLASSES OF THE MVTEC AD [25] DATASET. THE SUBSCRIPTS (s) AND (h) REFER TO THE soft AND hard BOUNDARIES, RESPECTIVELY. WE EMPHASIZE IN BOLD THE PERFORMANCE OF THE BEST MODELS. WHENEVER OUR MODELS OVERCOME THE SOTA WITH BOTH THE TYPE OF BOUNDARIES, WE UNDERLINE THE BEST OF THE TWO. AVERAGE MAXBA AND AUC FROM TABLE III AND TABLE IV. THE SUBSCRIPTS (s) AND (h) REFER TO THE soft AND hard BOUNDARIES, RESPECTIVELY. WE EMPHASIZE IN BOLD THE PERFORMANCE OF THE BEST MODELS. WHENEVER OUR MODELS OVERCOME THE SOTA WITH BOTH THE TYPE OF BOUNDARIES, WE UNDERLINE THE BEST OF THE TWO. THE "-" SYMBOL MEANS THAT THE AUTHORS DID NOT REPORT THE VALUE.</figDesc><table><row><cell></cell><cell>Overall Mean</cell><cell></cell></row><row><cell></cell><cell>maxBA</cell><cell>AUC</cell></row><row><cell>AE SSIM [40]</cell><cell>0.63</cell><cell>-</cell></row><row><cell>AE L2 [40]</cell><cell>0.71</cell><cell>0.75</cell></row><row><cell>AnoGAN [10]  ?</cell><cell>0.55</cell><cell>-</cell></row><row><cell>VAE-grad [59]  ?</cell><cell>0.77</cell><cell>-</cell></row><row><cell>AVID [60]  ?</cell><cell>0.73</cell><cell>-</cell></row><row><cell>EGBAD [36]  ?</cell><cell>0.61</cell><cell>0.60</cell></row><row><cell>GeoTrans [63]  ? ?</cell><cell>-</cell><cell>0.67</cell></row><row><cell>GANomaly [23]  ? ?</cell><cell>-</cell><cell>0.76</cell></row><row><cell>ITAE [41]  ? ?</cell><cell>-</cell><cell>0.84</cell></row><row><cell>CBiGAN [61]</cell><cell>0.76</cell><cell>0.77</cell></row><row><cell>MOCCA (s)</cell><cell>0.83</cell><cell>0.88</cell></row><row><cell>MOCCA (h)</cell><cell>0.80</cell><cell>0.83</cell></row><row><cell cols="2">Values reported in [25];  ? Values reported in [62]</cell><cell></cell></row><row><cell cols="2">? Values reported in [61];  ? ? Values reported in [41]</cell><cell></cell></row><row><cell></cell><cell>TABLE V</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>and others available in the literature.</figDesc><table><row><cell></cell><cell>AUC</cell></row><row><cell>AE-Conv2D [6]  ?</cell><cell>0.609</cell></row><row><cell>TSC [64]  ?</cell><cell>0.679</cell></row><row><cell>Stack RNN [64]  ?</cell><cell>0.680</cell></row><row><cell>AE-Conv3D [65]  ?</cell><cell>0.697</cell></row><row><cell>MemAE [20]  ?</cell><cell>0.712</cell></row><row><cell>LSA</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI AUC</head><label>VI</label><figDesc>VALUES FOR THE SHANGHAITECH [26] DATASET. THE SUBSCRIPTS (s) AND (h) REFER TO THE soft AND hard BOUNDARIES, RESPECTIVELY.</figDesc><table /><note>WE REPORT IN BOLD THE PERFORMANCE OF THE BEST MODEL.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>. DATASET. WE REPORT THE MAXBA FOR THE hard AND soft BOUNDARY SETTINGS. WE HIGHLIGHT IN BOLD THE BEST RESULTS.</figDesc><table><row><cell>Layer index</cell><cell>maxBA</cell><cell></cell></row><row><cell></cell><cell>hard boundary</cell><cell>soft boundary</cell></row><row><cell>6</cell><cell>0.819 ? .020</cell><cell>0.839 ? .010</cell></row><row><cell>5, 6</cell><cell>0.855 ? .021</cell><cell>0.840 ? .012</cell></row><row><cell>4, 5, 6</cell><cell>0.906 ? .001</cell><cell>0.955 ? .007</cell></row><row><cell>3, 4, 5, 6</cell><cell>0.912 ? .002</cell><cell>0.935 ? .005</cell></row><row><cell>2, 3, 4, 5, 6</cell><cell>0.903 ? .003</cell><cell>0.947 ? .005</cell></row><row><cell>1, 2, 3, 4, 5, 6</cell><cell>0.865 ? .004</cell><cell>0.948 ? .003</cell></row><row><cell>0, 1, 2, 3, 4, 5, 6</cell><cell>0.873 ? .002</cell><cell>0.924 ? .001</cell></row><row><cell></cell><cell>TABLE VII</cell><cell></cell></row><row><cell cols="3">ABLATION STUDY CONCERNING THE "LEATHER" CLASS OF THE MVTEC</cell></row><row><cell>AD [25]</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Alperen Kantarci received his B.S. degree in Computer Engineering at Istanbul Technical University in 2019. He is currently pursuing M.Sc. degree in Computer Engineering at Istanbul Technical University. His research interests include computer vision, deep learning, contrastive learning and unsupervised learning. ? eymanur Akti is a M.Sc. student and research assistant at department of computer engineering in Istanbul Technical University. She has received her B.S. degree in computer engineering from Istanbul Technical University in 2019. Her research interests include deep learning, computer vision, imbalanced data classification and anomaly detection.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan V GPU used for this research. This work was partially supported by WAC@Lucca funded by Fondazione Cassa di Risparmio di Lucca, AI4EU -an EC H2020 project (Contract n. 825619), and upon work from COST Action 16101 "Action MULTI-modal Imaging of FOREnsic SciEnce Evidence (MULTI-FORESEE)", supported by COST (European Cooperation in Science and Technology).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Identification of outliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Hawkins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Xli. on discordant observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">Y</forename><surname>Edgeworth</surname></persName>
		</author>
		<idno>1887. 1</idno>
	</analytic>
	<monogr>
		<title level="j">Dublin Philosophical Magazine and Journal of Science</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">143</biblScope>
			<biblScope unit="page" from="364" to="375" />
		</imprint>
	</monogr>
	<note>The London</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep learning approach for intelligent intrusion detection system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vinayakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alazab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Soman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Poornachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Al-Nemrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Anomaly-based intrusion detection from network flow features using variational autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zavrak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>?skefiyeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Network anomaly intrusion detection using a non-parametric bayesian approach and feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Alhakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alharbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bourouis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Alroobaea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bouguila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning temporal regularity in video sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Roy-Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Application of neural networks as an aid in medical diagnosis and general anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Stafford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beutel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">US Patent</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural memory plasticity for medical anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Denman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ahmedt-Aristizabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Laurens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Towards practical unsupervised anomaly detection on retinal images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ouardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Unnikrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Romain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Garcin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zenati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="225" to="234" />
		</imprint>
		<respStmt>
			<orgName>DART</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised anomaly detection with generative adversarial networks to guide marker discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schlegl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Seeb?ck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Waldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schmidt-Erfurth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIPMI</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep learning detecting fraud in credit card transactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mahoney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Alonzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Beling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIEDS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Credit card fraud detection using deep learning based on auto-encoder and restricted boltzmann machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pumsirirat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJACSA</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="25" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep-learning domain adaptation techniques for credit cards fraud detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lebichot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-A. Le</forename><surname>Borgne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He-Guelton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Obl?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bontempi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INNSBDDL</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="78" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Using generative adversarial networks for improving classification effectiveness in credit card fraud detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Fiore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zanetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Palmieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">479</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="448" to="455" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic vision system for wheel surface inspection and monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Retraint</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cogranne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASNT Annual Conference</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="207" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Computer-vision-based fabric defect detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIE</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="348" to="363" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Outlier analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="237" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Deep learning for anomaly detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chalapathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chawla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.03407</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Anomaly detection with robust deep autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Paffenroth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="665" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Memorizing normality to detect anomaly: Memoryaugmented deep autoencoder for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V D</forename><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">adVAE: A self-adversarial variational autoencoder with Gaussian anomaly prior knowledge for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KBS</title>
		<imprint>
			<biblScope unit="volume">190</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">105187</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schlegl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Seeb?ck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Waldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schmidt-Erfurth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIA</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="44" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">GANomaly: Semi-supervised anomaly detection via adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Akcay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Atapour-Abarghouei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Breckon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">MAD-GAN: Multivariate anomaly detection for time series data with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICANN</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="703" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">MVTec AD-a comprehensive real-world dataset for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A revisit of sparse coding based anomaly detection in stacked RNN framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A semisupervised autoencoder-based approach for anomaly detection in high performance computing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borghesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartolini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lombardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Milano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="634" to="644" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised lesion detection in brain CT using bayesian convolutional autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rajchl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mcdonagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cooke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khetani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIDL</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SpecAE: Spectral autoencoder for anomaly detection in attributed networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2233" to="2236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Sparse-GAN: Sparsity-constrained generative adversarial network for anomaly detection in retinal OCT image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1227" to="1231" />
		</imprint>
	</monogr>
	<note>in ISBI. IEEE, 2020</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fence GAN: towards better anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Winarto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K L</forename><surname>Kou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Akram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICTAI</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="141" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adversarially learned one-class classifier for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khalooei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">GODS: Generalized one-class discriminative subspaces for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Latent feature decentralization loss for one-class anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">One-class support tensor machines with bounded hinge loss function for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Razzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 Int. Joint Conf. on Neural Networks (IJCNN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Efficient GAN-based anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zenati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Foo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lecouat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Manek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.06222</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">OCGAN: One-class novelty detection using GANs with constrained latent representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Variational autoencoder based anomaly detection using reconstruction probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Special Lecture on IE</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Latent space autoregression for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Abati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Porrello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Calderara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Improving unsupervised defect segmentation by applying structural similarity to autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>L?we</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Steger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.02011</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Inverse-transform autoencoder for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10676</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Support vector method for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Support vector data description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M J</forename><surname>Tax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P W</forename><surname>Ruin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Highdimensional and large-scale anomaly detection using a linear one-class SVM with deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajasegarar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karunasekera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leckie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PR</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="134" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Anomaly detection using one-class neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chalapathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chawla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.06360</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep one-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goernitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="4393" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">One class convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Oza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="277" to="281" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Attention guided anomaly localization in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkataramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mahalanobis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Old is gold: Redefining the adversarially learned one-class classifier training paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Astrid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-I</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Deep semi-supervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>G?rnitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02694</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Uninformed students: Student-teacher anomaly detection with discriminative latent embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4183" to="4192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Real-world anomaly detection in surveillance videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sultani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6479" to="6488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Detection of face recognition adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">V</forename><surname>Massoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Carrara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Amato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Falchi</surname></persName>
		</author>
		<idno>2020. 3</idno>
	</analytic>
	<monogr>
		<title level="j">CVIU</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Deep k-nearest neighbors: Towards confident, interpretable and robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.04765</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Adversarial image detection in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Carrara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Falchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caldelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Amato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Becarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Tools and Applications</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2815" to="2835" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Conditional image generation with PixelCNN decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4790" to="4798" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Iterative energybased projection on a normal data manifold for anomaly localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Frigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Combrexelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eline</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.03734</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">AVID: Adversarial visual irregularity detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pourreza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Entezari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="488" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Combining GANs and autoencoders for efficient anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Carrara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Amato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Brombin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Falchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gennaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.08102,2020.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Attention guided anomaly detection and localization in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkataramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mahalanobis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.08616</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deep anomaly detection using geometric transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Golan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in NeurIPS</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="9758" to="9769" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">A revisit of sparse coding based anomaly detection in stacked RNN framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="341" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Spatiotemporal autoencoder for video anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1933" to="1941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Future frame prediction for anomaly detection -a new baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in CVPR</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="6536" to="6545" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Learning memory-guided normality for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="page" from="14" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Clustering driven deep autoencoder for video anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="329" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Massoli is a PostDoc at the Artificial Intelligence for Media and Humanities lab of ISTI-CNR. He has a Ph.D. in High Energy Physics from University of Bologna in collaboration with the Columbia University (NY)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Dr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Valerio</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>His research interests include deep learning, supervised and unsupervised learning, generative models, and quantum theory and technologies</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">He also received an M.B.A. from Scuola Superiore Sant&apos;Anna in Pisa. His research interests include deep learning, convolutional neural network, similarity search, distributed indexes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fabrizio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Falchi is researcher of the Artificial Intelligence for Media and Humanities lab of ISTI-CNR. He has a Ph.D. in Information Engineering from University of Pisa, and a Ph.D. in Informatics from Faculty of Informatics of Masaryk Univ. of Brno</title>
		<imprint/>
	</monogr>
	<note>multimedia information retrieval, computer vision</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
