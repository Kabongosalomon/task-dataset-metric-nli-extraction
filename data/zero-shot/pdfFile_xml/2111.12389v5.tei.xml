<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Track Boosting and Synthetic Data Aided Drone Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cagatay</forename><surname>Fatih</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">OBSS AI OBSS Technology</orgName>
								<address>
									<settlement>Ankara</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ogulcan</forename><surname>Akyon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">OBSS AI OBSS Technology</orgName>
								<address>
									<settlement>Ankara</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eryuksel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">OBSS AI OBSS Technology</orgName>
								<address>
									<settlement>Ankara</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil</forename><surname>Kamil</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">OBSS AI OBSS Technology</orgName>
								<address>
									<settlement>Ankara</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinan</forename><forename type="middle">Onur</forename><surname>Ozfuttu</surname></persName>
							<email>anil.ozfuttu@obss.com.tr</email>
							<affiliation key="aff0">
								<orgName type="institution">OBSS AI OBSS Technology</orgName>
								<address>
									<settlement>Ankara</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Altinuc</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">OBSS AI OBSS Technology</orgName>
								<address>
									<settlement>Ankara</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Track Boosting and Synthetic Data Aided Drone Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is the paper for the first place winning solution of the Drone vs. Bird Challenge, organized by AVSS 2021. As the usage of drones increases with lowered costs and improved drone technology, drone detection emerges as a vital object detection task. However, detecting distant drones under unfavorable conditions, namely weak contrast, longrange, low visibility, requires effective algorithms. Our method approaches the drone detection problem by finetuning a YOLOv5 model with real and synthetically generated data using a Kalman-based object tracker to boost detection confidence. Our results indicate that augmenting the real data with an optimal subset of synthetic data can increase the performance. Moreover, temporal information gathered by object tracking methods can increase performance further.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Initially being used for military applications, the use of drones has been extended to multiple application fields, including traffic and weather monitoring <ref type="bibr" target="#b4">[5]</ref>, smart agriculture monitoring <ref type="bibr" target="#b16">[17]</ref>, and many more <ref type="bibr" target="#b14">[15]</ref>. Furthermore, with the COVID-19 pandemic, there has been a radical increase in the use of drones not only for autonomous delivery of essential grocery and medical supplies but also to enforce social distancing. Nowadays, small quadcopters can be easily purchased on the Internet at low prices, which brings unprecedented opportunities but also poses several threats in terms of safety, privacy, and security <ref type="bibr" target="#b6">[7]</ref>.</p><p>The Drone vs. Bird Detection Challenge was launched in 2017, during the first edition of the International Workshop on Small-Drone Surveillance, Detection and Counteraction Techniques (WOSDETC) <ref type="bibr" target="#b3">[4]</ref> as part of the 14th edition of the IEEE International Conference on Advanced Video and Signal based Surveillance (AVSS). This challenge aims to address the technical issues of discriminating 978-1-6654-3396-9/21/$31.00 ?2021 IEEE between drones and birds <ref type="bibr" target="#b3">[4]</ref>. Given their characteristics, in fact, drones can be easily confused with birds, particularly at long distances, which makes the surveillance task even more challenging. The use of video analytics can solve the issue, but effective algorithms are needed that can operate under unfavorable conditions, namely weak contrast, longrange, low visibility, etc.</p><p>To overcome these issues, firstly, we use synthetic data selectively to enrich the dataset. Secondly, we make use of the Kalman filter <ref type="bibr" target="#b17">[18]</ref> based object tracking method to track objects across time to eliminate false positives and enhance detection performance. Lastly, we propose a track boosting method for boosting the confidence scores of detections based on track statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In recent years, the application of deep learning-based detection methods has led to excellent results for a wide range of applications, including drone detection. However, due to the absence of large amounts of drone detection datasets, a two-staged detection strategy has been proposed in <ref type="bibr" target="#b15">[16]</ref>. First, the authors examined the suitability of different flying object detection techniques, i.e., frame differencing and background subtraction techniques, locally adaptive change detection, and object proposal techniques <ref type="bibr" target="#b10">[11]</ref>, to extract region candidates in video data from static and moving cameras. In the second stage, a small CNN classification network is applied to distinguish each candidate region into drone and clutter categories.</p><p>In <ref type="bibr" target="#b2">[3]</ref>, Gagn and Mercier (referred to as Alexis team) proposed a drone detection approach based on YOLOv3 <ref type="bibr" target="#b12">[13]</ref> and taking a single RGB frame as input. By integrating an image tiling strategy, this approach is able to detect small drones in high-resolution images successfully. Alexis Team leveraged the public PyTorch implementation of YOLOv3 with Spatial Pyramid Pooling (YOLOv3-SPP) made available by Ultralytics <ref type="bibr" target="#b7">[8]</ref>. Spatial Pyramid Pooling <ref type="bibr" target="#b5">[6]</ref> is a simple technique for which the input features are processed by pooling layers of different sizes in parallel and then concatenated to generate fixed-length feature vectors. More-over, EagleDrone Team proposed a YOLOv5 based drone detection modality with a linear sampling-based data subsampling method. They propose to set the sampling probabilities using calculated loss per image. In addition to that, they utilize an ESRGAN based super-resolution technique to detect small and low-resolution drones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Technique</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Detection Model</head><p>The proposed technique focuses on a combination of two methods to improve the accuracy of drone detection performance using YOLOv5 <ref type="bibr" target="#b8">[9]</ref> object detection method. YOLOv5 is selected because of its speed and performance on object detection tasks. In addition, it supports anchor optimization, which is proven to improve performance <ref type="bibr" target="#b18">[19]</ref> and feature pyramids <ref type="bibr" target="#b9">[10]</ref> that handle objects at different scales. The use of synthetic data in deep learning appears helpful in scenarios where data is scarce or unavailable. Although synthetic data alone cannot show the same performance as real data, it has been seen that it increases performance when used alongside real data <ref type="bibr" target="#b18">[19]</ref>. Since there is no general method for creating synthetic data, each problem requires a unique approach. For the drone tracking problem, a method for creating labeled, randomized compositions by positioning 3D drone objects in front of 2D backgrounds were designed. This method was chosen because it is challenging to create a 3D randomized environment for the drone detection problem, and a location-independent object such as a drone can be used appropriately with 2D backgrounds. To generate the dataset, 3D drone models were rendered with various conditions such as position, rotation and lighting, and post-process effects on the randomized background images. Some samples from the synthetically generated dataset can be seen in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Synthetic Data</head><p>The most complex challenge encountered in the method is developing a solution to bridge the so-called "domain gap". To achieve this, experiments were conducted on the properties of the generated synthetic data, and the properties that make it similar to real data were investigated. In line with these studies, we created datasets with varying sample sizes that were optimized based on the features discovered. Finally, a series of experiments were conducted; first, a dataset was used with mixing synthetic and real data; second, a model trained on a synthetic dataset was used as a backbone for real data training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Object Tracking And Tracker Based Confidence Boosting</head><p>Object tracking algorithms are used to provide continuity of object detections over time. While tracking the objects is not directly required, it provides temporal information about the objects in the video that can further improve performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Tracker Method</head><p>A simple Kalman-based tracking method is applied <ref type="bibr" target="#b1">[2]</ref> over the predictions of the object detection network. Kalmanbased tracking uses a position and velocity-based process, object detection methods as measurements, and a hit counter mechanism. The tracking parameters are optimized for drone tracking with possibly moving cameras.</p><p>One benefit of using a tracker system is that for a track to be formed successfully, the object detection model needs to provide a consistent stream of predictions close to the object's predicted location. Therefore false positives occurring at random positions usually fail to build up the necessary hit count to form a track, as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. This has a positive impact on the mAP score. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Track Boosting Method</head><p>The tracks provide a spatiotemporal dimension and continuity over the predictions. This information is used in various ways to improve performance. However, tracking can provide object predictions where the object detection method provides no predictions; tracker-only predictions are not very useful compared to detection predictions due to their low IoU rate and test set not having annotations for occluded objects. Furthermore, in conducted experiments, including the tracker predictions had a negative impact on the mAP score. Therefore only detections from the object detection method are used in the Tracker Boosting Method.</p><p>Also, object detection model confidence may vary significantly with moving objects as the object moves or changes orientation over time. With the track information provided by the tracking algorithm, we increased the confidence of the predictions within a track by averaging the max confidence score in the track with the confidence provided by the object detection algorithm as shown in Eq. (1) where S i,j is the score for a prediction with i as track number and j as the position in the track and s i is the vector of scores for track i. </p><formula xml:id="formula_0">S i,j = S i,j + max(s i ) 2 (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Used Datasets</head><p>Before conducting the experiments, we randomly selected 15 of the videos from drone-vs-bird set <ref type="bibr" target="#b18">[19]</ref> as the validation set. Then extracted the frames from training and validation videos. We observed that using a subset of the training frames instead of the whole set prevents over-fitting resulting in improved accuracy. Therefore, uniformly sampled 10 4 frames from the drone vs. bird training is used as training data in experiments. This dataset will be referred as "Real Dataset".</p><p>Synthetic datasets with different features were generated using the method mentioned in sec. 3.2.These datasets with special features are:</p><p>? Original Original rendered image without spesific features</p><p>? Noise Image rendered with film grain noise post processing effect</p><p>? Optimal drone sizes Drones sized according to normal distribution</p><p>? Blur Rendered image with Gaussian Blur optimized for backgrounds</p><p>The dataset generated with 10 4 images by optimizing these features is called "Synthetic Dataset".</p><p>To perform experiments in which synthetic data will be used alongside real data, we created a combined dataset of 1.05 ? 10 4 images which will be referred as "Combined Dataset". This dataset includes all 10 4 samples from "Real Dataset" and an optimal sub-sample of 500 images from 'Synthetic Dataset'. The reason to include just a small subset of the synthetic images is to avoid the domain gap mentioned in sec. 3.2.</p><p>Moreover, we have also trained models with a combined dataset containing images from mav-vid <ref type="bibr" target="#b13">[14]</ref> and realworlduav <ref type="bibr" target="#b11">[12]</ref> drone detection datasets. However, since their distributions differ from the drone-vs-bird dataset, our dronevs-bird validation accuracy dropped, so we do not mention combined dataset training results in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>Firstly, a series of experiments were performed on various synthetic datasets to find the optimal synthetic features. All experiments were performed with COCO pretrained YOLOv5m6 model of 1333 input image size, 8 batch size, and 10 epochs setup and with datasets described in 4.1. For data sampling, inference and evaluation, our open source vision package SAHI <ref type="bibr" target="#b0">[1]</ref> is utilized. As seen in <ref type="figure" target="#fig_3">Fig. 4</ref>, experiments revealed that the most important property is the amount of blur applied to the image. In addition, it was understood that the distribution of drone sizes and noise effect similar to film grain significantly affect the performance. The results of the synthetic data experiments are used to create the optimized synthetic dataset known as 'Synthetic Dataset'. The training results obtained with the 'Synthetic Dataset' show that with the correct features, a training set consisting of only synthetic images gives us acceptable results considering no real images were required in the process. For the real data (drone-vs-bird) experiments, COCO pretrained YOLOv5m6 model is fine-tuned on drone-vsbird training split with 1333 input image size, 6 batch size for 10 epochs. During inference, vanilla YOLOv5 detection results are taken as a baseline. Then Kalman filter-based tracker is applied on top of model detections. Norfair package <ref type="bibr" target="#b1">[2]</ref> is utilized for the Kalman filter implementations with measurement (R) and process (Q) uncertainty parameters of 0.2 and 1, respectively. Lastly, the track boosting technique is applied to the tracker output for further performance improvement. <ref type="table">Table 1</ref>, real data gives better results than synthetic data; however, augmenting real data with synthetically generated data improves the validation results by up to 4.2 AP in all scenarios. Moreover, by applying a Kalman filter-based tracker, base results can be improved by up to 1 AP. More importantly, applying the track boosting method on top of a tracker provides us with an additional 1.5 and 0.6 AP improvement in real and combined dataset experiments, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>As seen in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Our results show that a YOLOv5 model fine-tuned only on synthetically generated images can achieve acceptable performance on drone detection tasks. Moreover, mixing an optimal subset of synthetic data yielded much better results than using real and synthetic images by themselves. Usage of the tracker improves upon the object detection performance in all cases. This improvement may be a result of filling out missing frames and eliminating the false positives by the tracker's internal mechanism. These results can be further improved by adjusting the frame predictions using the track information. Using the maximum confidence value in a track as a reference value, the overall mAP score increased. In cases where both the tracking algorithm and the object detection provide a prediction using the prediction from the object detection model results in improved accuracy as well.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Samples from synthetically generated drones images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Tracker results and false positive detections on a frame. Drone in the frame has a tracking id of 1 that shows tracker tracks the frame. The other red boxes on the clouds are false positives that can be filtered out by the tracker.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Plot of the confidence scores of a track. Red lines are the confidence scores of object detection and tracking. Blue lines are the results of the confidence increasing algorithm. In areas marked with orange, object detector failed to find the object.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Evaluation result for different synthetic features</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Slicing aided hyper inference and fine-tuning for small object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Akyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">O</forename><surname>Altinuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Temizel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.06934,2022.4</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Descoins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Castro</surname></persName>
		</author>
		<idno>try- olabs/norfair: v0.3.1</idno>
		<ptr target="https://github.com/tryolabs/norfair,2021" />
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Drone vs. bird detection: Deep learning algorithms and results from a grand challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coluccia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fascista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dimou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zarpalas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>M?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>De La Iglesia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gonz?lez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Mercier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">2824</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Drone-vs-bird detection challenge at ieee avss2019</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coluccia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fascista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghenescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Piatrik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">De</forename><surname>Cubber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nalamati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saqib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Monitoring road traffic with a uav-based system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elloumi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dhaou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Escrig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Idoudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Saidane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Wireless Communications and Networking Conference (WCNC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spatial pyramid pooling in deep convolutional networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1904" to="1916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Statement on the security threat posed by unmanned aerial systems and possible countermeasures. Oversight and Management Efficiency Subcommittee, Homeland Security Committee</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Humphreys</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Washington, DC, US House</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veitch-Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bianconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baltac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Suess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Xinyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Havlik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Skalski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reveriano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Falak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kendall</surname></persName>
		</author>
		<idno>ul- tralytics/yolov3: 43.1map@0.5:0.95 on coco2014</idno>
		<ptr target="https://github.com/ultralytics/yolov3,2020.1" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stoken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Borovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nanocode012</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Christo-Pherstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Changyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laughing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexwang1900</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Diaconu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Doug</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guilhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hatovix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Poznanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Petrdvoracek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rai</surname></persName>
		</author>
		<ptr target="https://github.com/ultralytics/yolov5" />
		<title level="m">ultralytics/yolov5: v3.1 -bug fixes and performance improvements</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Robust drone detection for day/night counter-uav with static vis and swir cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ground/Air Multisensor Interoperability, Integration, and Networking for Persistent ISR VIII</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">10190</biblScope>
			<biblScope unit="page">1019018</biblScope>
		</imprint>
	</monogr>
	<note>International Society for Optics and Photonics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Real world object detection dataset for quadcopter unmanned aerial vehicle detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paweczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wojtyra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>IEEE Access</publisher>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="174394" to="174409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.02767</idno>
		<title level="m">Yolov3: An incremental improvement</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptive inattentional framework for video object detection with reward-conditional training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rodriguez-Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rodriguez-Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sampedro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Campoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="124451" to="124466" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Unmanned aerial vehicles (uavs): A survey on civil applications and key research challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shakhatreh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Sawalmeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Almaita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Othman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khreishah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guizani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Ieee Access</publisher>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="48572" to="48634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Flying object detection for automatic uav recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schuchert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sensor planning for a symbiotic uav and ugv system for precision agriculture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tokekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Isler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1498" to="1511" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">An introduction to the kalman filter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distinguishing drones from birds in a uav searching laser scanner based on echo depolarization measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wojtanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zygmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Drozd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakubaszek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>?yczkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Muzal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
