<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">3D Medical Point Transformer: Introducing Convolution to Attention Networks for Medical Point Cloud Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhui</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingxin</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiange</forename><surname>Xiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongnan</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Cai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">3D Medical Point Transformer: Introducing Convolution to Attention Networks for Medical Point Cloud Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>General point clouds have been increasingly investigated for different tasks, and recently Transformerbased networks are proposed for point cloud analysis. However, there are barely related works for medical point clouds, which are important for disease detection and treatment. In this work, we propose an attention-based model specifically for medical point clouds, namely 3D medical point Transformer (3DMedPT), to examine the complex biological structures. By augmenting contextual information and summarizing local responses at query, our attention module can capture both local context and global content feature interactions. However, the insufficient training samples of medical data may lead to poor feature learning, so we apply position embeddings to learn accurate local geometry and Multi-Graph Reasoning (MGR) to examine global knowledge propagation over channel graphs to enrich feature representations. Experiments conducted on IntrA dataset proves the superiority of 3DMedPT, where we achieve the best classification and segmentation results. Furthermore, the promising generalization ability of our method is validated on general 3D point cloud benchmarks: ModelNet40 and ShapeNetPart. Code 1 is released.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Analysis of 3D point clouds has recently attracted much attention. Unlike 2D data structures that have a regular layout of pixels, 3D points are unordered and irregular, making it difficult to infer the underlying information. Efforts have been devoted to solving the problem by converting the 3D points to structured data, so that 1 https://3dmedpt.github.io/ Figure 1. Top part: 3D medical point clouds in IntrA <ref type="bibr" target="#b62">[63]</ref> with complex and diverse topology. Bottom part: 3D general point clouds in ModelNet40 <ref type="bibr" target="#b54">[55]</ref> with informative semantic structures and symmetry. conventional methods can be applied. Methods such as <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b35">36]</ref> regularize the structure of 3D points by voxelization or projection, which cause the loss of intrinsic geometric information. Direct point-based approaches have thus been investigated. Encouraged by PointNet <ref type="bibr" target="#b28">[29]</ref>, studies such as <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b66">67]</ref> directly learn spatial point features from 3D Euclidean space.</p><p>Although existing models can perform well on general 3D datasets, they could sometimes fail on medical data due to the domain gap. Accurate pathological segments of medical data are important for disease diagnosis and treatment. Nonetheless, 3D medical data may contain incomplete pathological structures, which are hard to be distinguished from healthy parts within one object <ref type="bibr" target="#b62">[63]</ref>. In addition, as shown in bottom part of <ref type="figure">Fig. 1</ref>, different types of the same object class usually have the same pattern for non-medical datasets. In contrast, medical point clouds of the same object class have more diverse and complex shapes in geometry and topology <ref type="bibr" target="#b33">[34]</ref>, which introduce difficulties for object classification or segmentation. The insufficient samples of medical data also make it difficult to learn distinctive shape descriptors. Hence, it is essential to design an effective deep learning method which can demonstrate good performances on medical and also generalize well on non-medical data.</p><p>The recent success of Transformer in natural language processing (NLP) <ref type="bibr">[10,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b41">42]</ref> and vision analysis <ref type="bibr">[11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr">4,</ref><ref type="bibr" target="#b46">47]</ref> inspires us to investigate its potentials for the medical point cloud processing. Self-attention is inherently orderinvariant because attentional weights between the query and key remain the same if the input order is changed, which introduces permutation invariance, making it suitable for handling 3D point clouds. Moreover, attention can model long-range dependencies and learn expressive features. Based on these perspectives, we decide to analyze the medical point clouds based on attention layers.</p><p>To address the issue of the irregular layout intrinsic to medical data, we augment the input feature with contexts from local neighborhood before each attention module, making our network context-aware. Meanwhile, the contextual information at query is further summarized via convolution to generate holistic geometric features. Moreover, due to the small-scale medical dataset compared to general ones, we learn diverse positional embeddings at query, key and value, and we propose Multi-Graph Reasoning to concurrently establish multiple channel graphs over the same feature nodes, with variant learnable adjacency matrices to enrich feature expressions.</p><p>Our contributions are summarized as follows: (1) We propose a Transformer-based network, namely 3DMedPT, to capture local context interactions via attention, and introduce convolution into Transformer to summarize global point features to obtain global content exchange within medical point clouds. <ref type="bibr">(2)</ref> We apply positional embeddings to address the irregular geometries of medical data. (3) We design Multi-Graph Reasoning which captures global relations among feature channels to enrich the representational power of medical features at deep layers.</p><p>(4) Our model ranks the 1st in both classification and segmentation tasks in IntrA benchmark and reveals good generalization ability on ModelNet40 and ShapeNetPart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>3D Point Cloud Processing. Medical data play an important role in the development of human health research. However, the number of datasets for 3D medical point clouds is quite small due to the expensive cost of data collection, thus existing methods are mostly proposed for general 3D objects. Methods such as <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b22">23]</ref> apply point-wise MLPs to analyze the irregular points.</p><p>PointNet <ref type="bibr" target="#b28">[29]</ref> as a pioneer processes point clouds with shared MLPs and further aggregates the information via pooling layers, but local relations of geometric shapes are ignored. Later works <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b53">54]</ref> investigate the underlying geometry by grouping information from local ranges. Some works <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b44">45]</ref> handle point clouds with continuous convolutional kernels, while others <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b43">44]</ref> utilize graphs and graph convolution for point-wise feature encoding to learn local 3D structures. However, these methods all adopt MLPs to process point features, which constrains the model ability in capturing more expressive shape information.</p><p>For medical point cloud processing, works such as <ref type="bibr">[3,</ref><ref type="bibr" target="#b12">13]</ref> directly borrow PointNet/PointNet++ for vessel labeling and aneurysm segmentation, and <ref type="bibr">[1]</ref> modifies PointNet with a hand-engineered geometry learning algorithm. Nonetheless, these works are still MLP-based, and the issue of complex and incomplete geometry of medical data cannot be well addressed. In contrast, we process medical point clouds based on Transformer network in an effective manner. Transformer and MLP-like Methods.</p><p>Transformer <ref type="bibr" target="#b41">[42]</ref> has shown great success in NLP and machine translation tasks <ref type="bibr">[10,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b41">42]</ref>, which also encourages popular applications for 2D image processing <ref type="bibr">[11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr">4,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b24">25]</ref>. However, due to the quadratic computational cost of attention maps, huge memory space will be taken to deal with even short input sequences. A number of methods have been devoted to designing efficient attention implementations. <ref type="bibr" target="#b32">[33,</ref><ref type="bibr">7,</ref><ref type="bibr" target="#b15">16]</ref> use sparse matrix with strict constraints for efficient attention computation. Others <ref type="bibr">[9,</ref><ref type="bibr">2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b42">43]</ref> employ kernel factorization or matrix factorization to reduce the computational overhead. Lambda attention <ref type="bibr">[2]</ref> reinterprets the attention as similarity kernels so that linear computations of attention are achieved, and axialattention <ref type="bibr" target="#b42">[43]</ref> decomposes 2D attention matrix into two 1D matrices along the width and height dimensions. Recently, the Swin Transformer <ref type="bibr" target="#b24">[25]</ref> uses shifted windows to save computational cost. In this work, we adopt the idea from Lambda attention by using linear functions for efficient computations. However, different from the initial purpose of Lambda attention in the 2D domain, we modify input features by augmenting local contexts and relative positional bias to address the complex topology and irregular geometries of 3D medical point clouds.</p><p>Most recently, several Transformer-based networks have been proposed for general 3D point cloud analysis. PCT <ref type="bibr">[12]</ref> utilizes input embedding and offset attention to improve the network behavior. Point Transformer <ref type="bibr" target="#b68">[69]</ref> modifies vector attention with relative positional embeddings to construct hierarchical attention layers for point cloud analysis. In this work, we propose an attentionbased model that specifically works for medical point clouds with good generalization ability on non-medical datasets as well.</p><p>There also exist works purely based on MLPs to truly explore the strength of MLPs. MLP-mixer <ref type="bibr" target="#b38">[39]</ref> and Synthesizer <ref type="bibr" target="#b36">[37]</ref> are two pioneers in this stream that are solely built based on MLPs. Variants such as <ref type="bibr">[5,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b39">40]</ref> all focus on 2D domain. PointMixer <ref type="bibr">[8]</ref> is the first work that uses MLP-like structures for point cloud analysis, where the query point feature is aggregated and updated from different dimensions. However they do not perform quite well on classification task. In contrast, our work reveals good behaviors on both medical and general datasets. Introducing Convolution to Transformers. Convolutions have been used to change the Transformer block in NLP and 2D image recognition, either by replacing multi-head attentions with convolution <ref type="bibr" target="#b47">[48]</ref> or adding more convolution layers to capture local correlations <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b48">49]</ref>. Different from all the previous works, we propose convolution operation (i.e., EdgeConv <ref type="bibr" target="#b45">[46]</ref>) solely on query features to summarize local responses from unordered 3D points to generate global geometric representations, of which the purpose is totally opposite to <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b48">49]</ref>. Graph-based Reasoning. Recently, graph convolutions <ref type="bibr" target="#b14">[15]</ref> have been adopted to capture relations between objects. Graph-based reasoning has been adopted to achieve global relation reasoning over 2D image graphs <ref type="bibr" target="#b67">[68]</ref>. However, general graph convolutions can only be safely applied when node connections are known, reasoning over point clouds is challenging since no link information between nodes is present. <ref type="bibr" target="#b17">[18]</ref> constructs graphs over 3D points with huge computational costs. Inspired by <ref type="bibr" target="#b26">[27]</ref>, we construct graphs on feature channels to avoid dealing with a large number of points. Moreover, to address the insufficient training samples in medical domain, we propose to construct multiple reasoning graphs over the same point features in parallel with learnable adjacency matrices for enriched global information learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>In this section, we firstly introduce the basic attention and Lambda attention (Sec. 3.1), then we explain how to embed local contexts for unordered 3D point clouds via contextual information augmentation (Sec. 3.2) and how to summarize local responses at query (Sec. 3.3). Relative positional embeddings are proposed to handle local geometry of medical data (Sec. <ref type="bibr">3.4)</ref>. Lastly, we propose MGR on feature channel domains to enrich the representations of learned features (Sec. 3.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminary</head><p>Original Attention. Suppose we are given an unordered set of N point features P ? R N ?C with C feature channels. Three matrices can be learned through linear mappings:</p><formula xml:id="formula_0">Q, K, V = PW q , PW k , PW v ,<label>(1)</label></formula><p>where Q, K ? R N ?C k and V ? R N ?Cv have output feature dimensions of C k and C v , respectively, and W q , W k ? R C?C k , and W v ? R C?Cv are learnable weights. Following the terms defined in <ref type="bibr" target="#b41">[42]</ref>, we denote Q, K, V as query, key, and value, respectively, and the self-attention operation is formulated as follows:</p><formula xml:id="formula_1">Attn(Q, K, V) = softmax QK ? C k V.<label>(2)</label></formula><p>As shown in Eq. 2, global attention weights calculated from Q and K have a time complexity O(N 2 C v ) and space complexity O(N 2 + N C k + N C v ), which increase quadratically when N increases and consumes much computational resources. Recently, existing works <ref type="bibr">[9,</ref><ref type="bibr">2,</ref><ref type="bibr" target="#b13">14]</ref> use linear operations to factorize the naive attention for computation acceleration. In our design, we directly borrow the attention operation from Lambda attention <ref type="bibr">[2]</ref> as improving the attention efficiency is not our main focus. Lambda Attention. With the assistance of linear attention <ref type="bibr" target="#b13">[14,</ref><ref type="bibr">9]</ref> and kernel factorization, an efficient algorithm named as Lambda attention is proposed to bypass the need of materializing the attention maps <ref type="bibr">[2]</ref>. This process can be briefly expressed as:</p><formula xml:id="formula_2">Attn(Q, K, V) = Q softmax(K) V ,<label>(3)</label></formula><p>where keys are normalized through the softmax function, and softmax(K) V ? R C k ?Cv is termed as content lambda <ref type="bibr">[2]</ref>, where each query can interact with the content lambda in a linear form. Therefore, the time and space</p><formula xml:id="formula_3">complexities are O(N C k C v ) and O(N C k +N C v +C k C v )</formula><p>, respectively, where the computational cost could be largely reduced when C k N . For efficient computation, we choose Lambda attention as our baseline model for medical point cloud processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Local Context Augmentation</head><p>Although self-attention is able to model long-range dependencies over the global domain, it cannot aggregate local information, which is essential in point cloud analysis <ref type="bibr">[12]</ref>. However, different from regular layouts such as 2D images where spatially neighboring pixels usually have high semantic correlations, 3D point clouds are unordered and nearby points can have no geometric or semantic relations due to permutation variance. Hence, instead of using local attention <ref type="bibr" target="#b31">[32]</ref> which may constrain the model's receptive field, we reform the input feature before each attention layer by defining a local context region, with the assumption that spatially closed points in Euclidean coordinates can have some relations for geometric study. We thus follow the idea of PointNet++ <ref type="bibr" target="#b30">[31]</ref> by firstly downsampling the points using farthest point sampling (FPS) and then group features from local contexts as DGCNN <ref type="bibr" target="#b45">[46]</ref>. Specifically, given xyz coordinates of N input points</p><formula xml:id="formula_4">P = {p i ? R 3 } N i=1 and the corresponding features F = {f i ? R Cin } N i=1</formula><p>with C in feature channels, the whole process can be formulated as follows:</p><formula xml:id="formula_5">N (p i ) = KNN(P, ||p i ? p j || 2 2 ), p j ? P S , f i = [f j ? f i , f i ] j?N (pi) ? R K?2Cin ,<label>(4)</label></formula><p>where P S is a point set downsampled from P using FPS, KNN(?) is K-nearest neighbor function, [?, ?] is concatenation, and f i is the augmented feature with local contexts. In this case, f i can now retain the locality property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Convolution at Query</head><p>This convolution operation proposed at query has two purposes: (1) it allows us to aggregate local responses and update geometric features at query; (2) Since global interaction should be considered between the query and content lambda softmax(K) V, so it is natural to capture global features from query. Therefore, we introduce convolution (i.e., EdgeConv) to Transformer to generate global query information.</p><p>Formally, the query tensor is obtained from the updated features F = {f i } N i=1 ? R N ?K?2Cin by using EdgeCov:</p><formula xml:id="formula_6">Q = EdgeConv(F )W q ? R N ?C k ,<label>(5)</label></formula><p>where W q ? R 2Cin?C k . In this case, the local information is integrated into Q, then we apply linear projections on flattened F to compute K and V as follows:</p><formula xml:id="formula_7">K = Flatten(F )W k ? R (N ?K)?C k , V = Flatten(F )W v ? R (N ?K)?Cv ,<label>(6)</label></formula><p>where W k ? R 2Cin?C k and W v ? R 2Cin?Cv . Based on the above modifications, we show an improved version of Eq. 3 in a per-point form as:</p><formula xml:id="formula_8">y i = q i softmax(k i ) v i ,<label>(7)</label></formula><p>where </p><formula xml:id="formula_9">y i ? R Cv is the layer output, k i ? R K?C k and v i ? R K?Cv .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Relative Positional Embedding</head><p>As mentioned in <ref type="bibr" target="#b68">[69]</ref>, positional information is critical for 3D point cloud processing. Especially for medical data where the structure is incomplete and complex, embedding positional bias encourages the model to focus on local geometry. In this work, we use relative positional information since computing absolute positions requires storing an ordered list before and after point permutations, which increases the computational overhead. In addition, we integrate the relative positions from local contexts with input feature as we empirically find that using addition cannot give the best result. Therefore, we define learnable relative positional embedding as follows:</p><formula xml:id="formula_10">h i = ? [p j ? p i ] j?N (pi) ? R K?C h , f i = [f j ? f i , f i , h i ] j?N (pi) ,<label>(8)</label></formula><p>where ?(?) is an MLP. However, learning accurate positional bias is quite hard when dataset is too small <ref type="bibr" target="#b40">[41]</ref>, which is our case when dealing with medical data. we therefore apply different MLPs ?(?) to learn positional information at query&amp;key&amp;value positions for accurate and complex medical geometry learning. As illustrated in <ref type="figure" target="#fig_0">Fig. 2</ref>, we improve Lambda attention by introducing positional bias terms at a modest cost to address the irregular geometric traits lurking inside medical data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Multi-Graph Reasoning</head><p>Feature representations are critical for model performance, especially when dealing with insufficient training samples, which is often the case in medical domain. In our method, we propose to enrich the feature representations by exploiting global relations of content in deep layers of our attention block with a Multi-Graph Reasoning (MGR) module based on graph reasoning <ref type="bibr">[6]</ref> and graph convolutions <ref type="bibr" target="#b14">[15]</ref>. As suggested in <ref type="bibr" target="#b26">[27]</ref>, graphs can be constructed on feature channels by learning graph nodes from channels, which could save the computational cost for the case of large input numbers. In contrast to <ref type="bibr" target="#b26">[27]</ref> that only a single graph is established over channels, we design an MGR module to initialize multiple graphs simultaneously with learnable adjacency matrices, enhancing the diversity of node features via various graph states. As shown inside the pink box of <ref type="figure" target="#fig_1">Fig. 3</ref>, MGR is adapted on values to replace the original positional encoding part in the last attention layer, where neighboring information augmentation is intentionally ignored for global information aggregation and relational interactions. Hence, the output F out of MGR module can be formulated as:</p><formula xml:id="formula_11">F out = [ReLU (V + I)a i ] i?C k , a i ? R Cv?Cv ,<label>(9)</label></formula><p>where I is the identity matrix, indicating that the self-loop of each node is introduced. C k graphs and the corresponding adjacency matrices a i are concurrently computed from C v channel nodes, such that contextual interactions between nodes can be modeled and structural relations are captured for feature learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Implementation Details</head><p>The overall model architecture for 3D object classification and part segmentation is shown in <ref type="figure" target="#fig_2">Fig. 4</ref>. In our overall network model, the input feature dimension C in is set to 3 representing 3D normal vectors, and if there is no normal vectors, C in will be the xyz positions. The output feature dimension C out is set to 2 for classifying and segmenting blood vessels or aneurysms, with binary cross entropy as the loss function. As shown in <ref type="figure" target="#fig_2">Fig. 4</ref>, we follow the architecture of PointNet++ for classification, where points are downsampled and features are embedded with locality, followed by the attention module to enhance interactions between local contexts and global contents. MGR is applied to further enrich the feature representations with graph reasoning, and maxpooling is employed to summarize the information while being insensitive to permutation as a symmetric function. For segmentation, we adopt a DGCNN-like network. Each MLP block contains a linear mapping layer, batch normalization layer and ReLU. To address bottleneck issues caused by a small C v , the multi-query algorithm <ref type="bibr">[2]</ref> is utilized so that h different query heads are constructed and concatenated, deriving a new output feature y i ? R hCv .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we present our experimental results on medical 3D points (IntrA <ref type="bibr" target="#b62">[63]</ref>) and show the model performance on other medical datasets in the supplementary material.</p><p>We also test the generalization ability on non-medical 3D point clouds (ModelNet40 <ref type="bibr" target="#b52">[53]</ref> and ShapeNetPart <ref type="bibr" target="#b64">[65]</ref>). Extensive experiments for ablation studies are conducted as well. The training details are reported in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">3D Object Classification</head><p>We first examine the model behavior on IntrA and then investigate our model on ModelNet40. IntrA. IntrA <ref type="bibr" target="#b62">[63]</ref> is a 3D medical point cloud dataset for binary classification and part segmentation to distinguish blood vessels and aneurysms, which contains mesh and point representations of the data structure. We use the point cloud with overall 2025 samples for classification. Fivefold cross-validation was adopted with F1-score and perclass testing accuracy as evaluation metrics.</p><p>As shown in <ref type="table" target="#tab_0">Table 1</ref>, our method reaches the highest accuracies of 94.06% with 512 points for aneurysm (A.) and 99.24% with 1024 points for blood vessel (V.) detection by using the PointNet++ backbone, which overpass the original work by 0.7% and 6.3% respectively. Our 3DMedPT achieves the best F1 score of 0.936 with 1024 points, which outperforms its Transformer counterpart PCT by 2.4%. It is also 3.3% and 9.1% higher than the latest attention-based works: PAConv <ref type="bibr" target="#b55">[56]</ref> and AdaptConv <ref type="bibr" target="#b69">[70]</ref>, showing the superiority of our method on 3D medical point cloud analysis. ModelNet40. ModelNet40 dataset <ref type="bibr" target="#b52">[53]</ref> consists of 13,211 3D synthetic models for general objects, with 9843 training samples and 2468 testing samples ranged within 40 classes. We uniformly sample 1024 points only with 3D coordinates as input features, and shuffle the points as in <ref type="bibr" target="#b30">[31]</ref>. Our performance compared to other state-of-the-art methods is listed in <ref type="table" target="#tab_1">Table 2</ref>.</p><p>We achieve an accuracy of 93.4%, which overpasses most typical point-based designs <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b45">46]</ref>. Additionally, our model performance is better than some networks based  <ref type="bibr" target="#b21">[22]</ref>), and our model is also better than the Transformer counterpart PCT <ref type="bibr">[12]</ref> with a much smaller model size (see <ref type="table">Table 6</ref>). Our classification accuracy is lower than recently proposed Point Transformer <ref type="bibr" target="#b68">[69]</ref> by only 0.3%, while this small gap validates the good generalization ability of 3DMedPT. Hence, our design can not only deal with medical dataset with complex topology such as blood vessels or aneurysms, but also distribute the excellence to regular 3D shapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">3D Part Segmentation</head><p>We then validate the segmentation ability of our model on both IntrA and ShapeNetPart, with the same data IntrA. There are a total of 116 annotated samples for part segmentation task in IntrA, where the boundary lines are grouped into aneurysm segments, making it a binary segmentation task. Five-fold cross-valuation is still applied with evaluation metrics based on Point Intersection over Union (IoU) and S?rensen-Dice cefficient (DSC). Results are reported in <ref type="table" target="#tab_2">Table 3</ref>. It can be seen that we achieve the highest IoU and DSC values of 94.82% and 97.29% for parent vessels segmentation with 512 input points. Meanwhile, our 3DMedPT also has the best performance on the aneurysm segmentation with 1024 points, resulting in IoU and DSC values of 82.39% and 89.71%. Our work outperforms PAConv and AdaptConv by a large margin by 4.7% and 9.5% on A. IoU and 2.8% and 4.2% on V. IoU, which exhibits our superiority on medical data.</p><p>To further examine the model behavior, we qualitatively evaluate our approach with respect to some recent works such as PAConv. Ground truth samples are shown in the 1st column for reference in <ref type="figure" target="#fig_3">Fig. 5</ref>. As can be seen, when the aneurysm takes a large size ratio of the blood vessel (row 1), our model performs the best and PCT cannot fully understand the shape of aneurysm, while PCT gives the similar segmentation results as ours in other cases (rows 2-3). However, we can see that the latest work PAConv totally fails when complicated structures are encountered (row 2). ShapeNetPart. ShapeNetPart [65] contains 16,880 3D samples with 14,006 training and 2874 testing data, grouped into 16 classes with totally 50 part annotation labels. We sample 2048 points from each object and use mean intersection over union averaged across 16 classes (cls. mIoU) as the evaluation metric. <ref type="table" target="#tab_3">Table 4</ref>  per-class results and the overall cls. mIoU of our DGCNN backbone. We achieve the overall value of 84.3%, which is 0.4% lower than PAConv but 1.1% higher than AdaptConv. Although we cannot achieve the best result, our model shows great performance in the class-wise segmentation results where we achieve the best in cap and mug. Considering the performance gaps among ours, PAConv and AdaptConv on the IntrA segmentation task, we claim that our model can generalize well to general datasets. Qualitative results are reported in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>presents detailed</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>In this section, we first examined the contribution of positional embeddings, and then investigated our model robustness on noise and compared the efficiency with some typical methods from <ref type="table" target="#tab_0">Table 1</ref>. Unless specified, all experiments are conducted on IntrA dataset for the 3D  object classification with the first fold as the testing set and the others as the training set, and 1024 points are sampled for fast computation. Positional Embeddings. To investigate the effectiveness of the relative positional embedding, different models are established and F1 scores are averaged across all folds and reported in <ref type="table" target="#tab_4">Table 5</ref>. Model A is the design where no positional bias is introduced in the attention block, and we examine the cases when positional embedding is shared at all three positions individually (models B ? D). More investigations are done when positional embedding is introduced at any two positions (model E ? G) or query&amp;key&amp;value (model H). We can see from <ref type="table" target="#tab_4">Table 5</ref> that without embedding position information, our model can still achieve a reasonable performance due to the design of our local context augmentation module.</p><p>Besides, introducing positional bias does improve the model performance when comparing model A with any others. We find that introducing positional bias terms to all positions (model H) gives us the best result with the F1 score of 0.936 across all 5 folds, which indicates that more accurate positional information is learned via learning mapping in all query, key and value positions. Model Efficiency. Computational costs of different models compared with 3DMedPT were explored in terms of the model size and processing speed. As shown in <ref type="table">Table 6</ref>, we achieved the highest performance with the smallest model size which only contains 1.54M model parameters, processing 843 examples per second.</p><p>Although the processing speed of PointNet <ref type="bibr" target="#b28">[29]</ref> is the fastest, it cannot perform as well as other models at a lower computational speed. Moreover, our Transformer counterpart PCT <ref type="bibr">[12]</ref> requires more trainable parameters to achieve a relatively good performance, with a slower processing speed than ours. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Robustness Analysis.</head><p>We demonstrated our model robustness to the point density by using sparser points as the network input from 2048 to 128 points. We compared our results with several works in <ref type="figure" target="#fig_4">Fig. 6 (left)</ref>, where all networks were trained with 1k points on IntrA. The absolute dropping difference from 2048 to 128 points of our method is 6.7%, which is the same as our Transformer counterpart PCT, while we reached the best F1 score on all experiments with different numbers of input points. For the noise resistance investigation, we introduced different numbers of noisy 3D points with random positions during model testing following <ref type="bibr" target="#b60">[61]</ref>. As can be seen from <ref type="figure" target="#fig_4">Fig. 6</ref> (right), 3DMedPT is more robust to noise compared with some latest works PAConv <ref type="bibr" target="#b55">[56]</ref> and AdaptConv <ref type="bibr" target="#b69">[70]</ref> under all testing environments. The absolute difference between no noise and 50 noisy points for our model is 11.3%, which is smaller than PCT with the value of 14.5%, presenting our excellent robustness ability to the noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we propose a Transformer network for 3D medical point cloud analysis, namely 3DMedPT, which can model long-range dependencies of global contents via the convolutional operation introduced at query to summarize local feature responses, and local context interactions based on lambda attention modified with local context augmentation. Variant relative positional information for query, key and value is encoded to capture the complex structure of medical data. Global interactions between features are obtained from channel space where multiple graphs are constructed to model diverse graph states, improving the expressiveness of feature information. Our model performs the best in 3D medical object classification and part segmentation tasks. Moreover, extensive analyses on general 3D point cloud datasets have validated the good generalization ability of our model. In future, we will extend our approach for large-scale point cloud processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Materials</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Training Details</head><p>We used PyTorch on one 11GB RTX2080Ti GPU to implement our model for IntrA <ref type="bibr">[11]</ref>, ModelNet40 <ref type="bibr">[9]</ref>, and ShapeNetPart <ref type="bibr">[12]</ref>. IntrA Classification. Data augmentation was applied during the training stage, where random point translation in [-0.2, 0.2] and rescaling in [0.67, 1.5] were adopted. We set the training batch size to 32 and testing batch size to <ref type="bibr" target="#b15">16</ref>. We trained the model for 250 epochs with Adam as the optimizer, where the learning rate was set to 1e-2 with momentum of 0.9 and weight decay of 1e-4. Cosine annealing was applied to reschedule the learning rate for each epoch. We used binary cross entropy as the loss function for the classification. IntrA Segmentation. Data augmentation utilized for segmentation task follows the same as classification, while both the training and testing batch size were set to 8. We trained the model with 400 epochs using Adam, where the learning rate was set to 1e-3 with weight decay value of 1e-4, and we applied cosine annealing to adjust the learning rate. The same loss function as the classification task was used. ModelNet40. We used the standard data split as <ref type="bibr">[5]</ref> where 9,843 samples were used for training and the remaining 2,468 were taken as the testing samples. We also applied FPS <ref type="bibr">[6]</ref> to downsample the number of points during network training. The same data augmentation technique is applied . The training batch size was set to 32 and the testing batch size was set to 16. The model was trained for 250 epochs with initial learning rate set to 1e-3. Adam was used as the optimizer with cosine annealing, and weight decay and momentum were set to 1e-4 and 0.9, respectively. The multi-class cross entropy was adopted as the loss function for the classifications of 40 objects. ShapeNetPart. The data augmentation techniques remain the same as the above experiments on ModelNet40. The total training epochs was set to 400 with 32 training batches and 16 testing batches. The learning rate was initialized to 1e-3, and Adam was selected as the model optimizer with a weight decay of 1e-4. We also applied the cosine annealing scheme to dynamically adjust the learning rate, with multiclass cross entropy adopted as the loss function. The loss function to guide the model training was the same as Mod-elNet40. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Effectiveness of MGR</head><p>To examine the effectiveness of MGR module, we used the first fold for testing and all the others for training with 1024 input points. As can be seen in <ref type="table" target="#tab_0">Table 1</ref>, experimental results of model with no MGR, with only one graph and with multiple graphs are reported. When MGR is ignored during the training stage, the final result is only 0.884, which is 4.3% smaller than the desired design where multiple graphs are used. Besides, with only one graph, our model can give a good performance with F1 score of 0.910.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Depth of Architecture</head><p>We investigated the impact of model depth on the performance when handling the classification task of the IntrA dataset. We used the first fold to testing and all others for training with 1024 input points. Specifically, we vary the number of attention layers and fix the MGR layer at the end. The F1 scores and model parameters of four different configurations are reported in <ref type="table" target="#tab_1">Table 2</ref>. It can be seen that more numbers of layers mean slower processing speed where the 1-layered form can process 1229 examples per second. The best model configuration is empirically found to be the 2layered one, which is the one that we applied for the blood vessel and aneurysm classification. For the trade-off between the model efficiency and the classification accuracy, we prefer the higher F1 score for more accurate disease diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Hyperparameter Search</head><p>To optimize the attention module design, we examined the influence of two hyperparameters, i.e., the number of multi-query heads h and query feature C k . F1 scores of models with different hyperparameter combinations with 1024 points are reported in <ref type="table" target="#tab_2">Table 3</ref>, where we used the first </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Normalization Functions</head><p>We further investigated the behavior difference when using different normalization functions. Common choices for normalization such as sigmoid and Tanh were applied to check their effectiveness. Extensive experiments are implemented on IntrA classification task, and the classification results are reported in <ref type="table" target="#tab_3">Table 4</ref>. It suggests that summarizing the contextual information by softmax is the best choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">More Results on Medical Datasets</head><p>While we focused on medical point clouds, we followed PointNet <ref type="bibr">[5]</ref> to implement a sanity check on our method with experiments on other medical data: RetinalOCT <ref type="bibr">[4]</ref> and AdrenalMNIST3D <ref type="bibr">[10]</ref>, where shape analysis is critical for disease classification in these two datasets.</p><p>RetinalOCT. RetinalOCT involves 2D gray-scale images of retinal diseases, which is comprised of 4 diagnosis categories with 108,318 training and 1,000 testing samples from 633 patients, leading to a multi-class classification task. To make it compatible for training with our model, we convert 2D image pixels to 2D points. Specifically, we firstly resize each image to 256x256 and use Sobel filters to detect the edges of each image, with (x, y) assigned by (row, col) of each pixel and z = 0. The number of points for each data sample is fixed and determined by the average value of all point sets obtained from all images. During training, we normalize each point set to a unit cube of [-1, 1] and use data augmentation following IntrA.</p><p>In <ref type="table" target="#tab_4">Table 5</ref>, we compared with ResNet-18/50 baselines <ref type="bibr">[2]</ref> with 3D convolutions and an open-source AutoML tool (AutoKeras <ref type="bibr">[3]</ref>). The highest testing accuracy is achieved by <ref type="bibr">[4]</ref> where InceptionV3 <ref type="bibr">[7]</ref> is applied and pre-trained on ImageNet. Although there are noticeable performance gaps between our approach and CNN-based methods, we argue that it is the information loss due to the data type conversion (i.e., image resizing and ignorance of pixel intensity) that causes the performance difference. AdrenalMNIST3D. AdrenalMNIST3D is a new 3D dataset collected from abdominal computed tomography for shape classification, consisting of shape masks with the size of 28x28x28 from 1,584 left and right adrenal glands from 792 patients. We first pre-process the volumetric images to transfer them to point clouds. To eliminate the advantages brought by pre-processing steps, we simply follow the steps from PointNet <ref type="bibr">[5]</ref>, where we only added voxels to our point set with intensity is greater than 128. The size of point set is 256 and normalized to a unit cube within the range of [-1, 1]. Point positions are represented by (x, y, z) coordinates of voxels.</p><p>As reported in <ref type="table">Table 6</ref>, we compared several point-based methods with well-engineered CNNs. It can be seen that the best model is sill the well-engineered CNN-based model, while our model can achieve a reasonable performance and also the accuracy of our work is quite near AutoKeras when converting 3D images to points in a simple fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Qualitative Results</head><p>ShapeNetPart. Object part segmentation results of our model are shown in <ref type="figure">Fig. 1</ref>, along with the groundtruth examples displayed for references. We tested our model performance on each class and reported the visual outputs <ref type="table">Table 6</ref>. Classification results on AdrenalMNIST3D with different methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Input Type Acc. (%) ResNet-18 <ref type="bibr">[2]</ref> voxels 82.7 ResNet-50 <ref type="bibr">[2]</ref> voxels 82.8 AutoKeras <ref type="bibr">[3]</ref> voxels 80.4 PointNet <ref type="bibr">[5]</ref> points 76.5 DGCNN <ref type="bibr">[8]</ref> points 77.1 PCT <ref type="bibr">[1]</ref> points 76.8 3DMedPT points 79.1 across all 16 classes. It can be seen that the segmented samples on mug, laptop, chair and laptop show almost no difference with the original labels, while there are still defects on segmentation results for motorbikes and rockets.</p><p>IntrA. More visual results on the segmentation task of In-trA dataset are shown in <ref type="figure" target="#fig_0">Fig. 2</ref> based on our best model, which are compared to the corresponding groundtruth annotations for comprehensiveness. As shown in <ref type="figure" target="#fig_0">Fig. 2</ref>, our method achieves fairly precise segmentation results on most cases, however, few undesired results might appear especially when the size ratio of aneurysms becomes smaller than the healthy blood vessels, or when the 3D structure topology becomes complicated. <ref type="figure">Figure 1</ref>. Segmentation comparisons between groundtruth (GT) annotations and the outputs generated from the 3DMedPT on ShapeNet-Part dataset. <ref type="figure" target="#fig_0">Figure 2</ref>. Segmentation comparisons between groundtruth (GT) annotations and the outputs generated from the 3DMedPT on IntrA dataset. Good segmentation results are shown above the red line and some failed cases are shown below the red line.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Detailed architecture of our attention module in 3DMedPT, where KNN and FPS denote k-nearest neighbor and farthest point sampling operations<ref type="bibr" target="#b30">[31]</ref>, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Modified attention module with MGR, where SL denotes the self-loop and residual connection is applied to compensate the low-level information loss. All dotted components imply different designs with the original Lambda attention[2].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>The overall architecture of 3DMedPT for medical point cloud analysis. Numbers in black, blue, and orange indicate the point number, the feature dimension for classification, and the feature dimension for segmentation. LCA and RPE denote local context augmentation and relative positional embedding, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Qualitative comparisons on IntrA segmentation. Ground-truth samples are shown in the first column for reference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Left: Comparison on different numbers of input points. Right: Comparison on different numbers of noisy points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Classification results of per-class accuracy and F1-score on healthy vessel segments (V.) and aneurysm segments (A.) with all input features. Results are averaged across all 5 folds.</figDesc><table><row><cell>Method</cell><cell cols="4">#Points V. (%) A. (%) F1</cell></row><row><cell></cell><cell>512</cell><cell>94.45</cell><cell>67.66</cell><cell>0.691</cell></row><row><cell>PointNet [29]</cell><cell>1024</cell><cell>94.98</cell><cell>64.96</cell><cell>0.684</cell></row><row><cell></cell><cell>2048</cell><cell>93.74</cell><cell>69.50</cell><cell>0.692</cell></row><row><cell></cell><cell>512</cell><cell>98.52</cell><cell>86.69</cell><cell>0.893</cell></row><row><cell>PointNet++ [31]</cell><cell>1024</cell><cell>98.52</cell><cell>88.51</cell><cell>0.903</cell></row><row><cell></cell><cell>2048</cell><cell>98.76</cell><cell>87.31</cell><cell>0.902</cell></row><row><cell></cell><cell>512</cell><cell>98.38</cell><cell>78.25</cell><cell>0.849</cell></row><row><cell>PointCNN [21]</cell><cell>1024</cell><cell>98.79</cell><cell>81.28</cell><cell>0.875</cell></row><row><cell></cell><cell>2048</cell><cell>98.95</cell><cell>85.81</cell><cell>0.904</cell></row><row><cell></cell><cell>512</cell><cell>99.21</cell><cell>91.96</cell><cell>0.915</cell></row><row><cell>PointConv [51]</cell><cell>1024</cell><cell>98.89</cell><cell>83.57</cell><cell>0.883</cell></row><row><cell></cell><cell>2048</cell><cell>98.61</cell><cell>90.47</cell><cell>0.883</cell></row><row><cell></cell><cell>512</cell><cell>98.76</cell><cell>84.24</cell><cell>0.884</cell></row><row><cell>SO-Net [20]</cell><cell>1024</cell><cell>98.88</cell><cell>81.21</cell><cell>0.868</cell></row><row><cell></cell><cell>2048</cell><cell>98.88</cell><cell>83.94</cell><cell>0.885</cell></row><row><cell></cell><cell>512</cell><cell>98.05</cell><cell>84.58</cell><cell>0.869</cell></row><row><cell>SpiderCNN [60]</cell><cell>1024</cell><cell>97.28</cell><cell>87.90</cell><cell>0.872</cell></row><row><cell></cell><cell>2048</cell><cell>97.28</cell><cell>84.89</cell><cell>0.866</cell></row><row><cell></cell><cell>512</cell><cell>95.22</cell><cell>60.73</cell><cell>0.658</cell></row><row><cell>DGCNN [46]</cell><cell>1024</cell><cell>95.34</cell><cell>72.21</cell><cell>0.738</cell></row><row><cell></cell><cell>2048</cell><cell>97.93</cell><cell>83.40</cell><cell>0.859</cell></row><row><cell></cell><cell>512</cell><cell>98.55</cell><cell>83.84</cell><cell>0.873</cell></row><row><cell>GS-Net [58]</cell><cell>1024</cell><cell>98.78</cell><cell>83.08</cell><cell>0.872</cell></row><row><cell></cell><cell>2048</cell><cell>98.39</cell><cell>85.74</cell><cell>0.882</cell></row><row><cell></cell><cell>512</cell><cell>99.03</cell><cell>89.07</cell><cell>0.911</cell></row><row><cell>PCT [12]</cell><cell>1024</cell><cell>98.87</cell><cell>89.71</cell><cell>0.914</cell></row><row><cell></cell><cell>2048</cell><cell>98.96</cell><cell>89.49</cell><cell>0.917</cell></row><row><cell></cell><cell>512</cell><cell>98.53</cell><cell>89.00</cell><cell>0.904</cell></row><row><cell>PAConv [56]</cell><cell>1024</cell><cell>98.98</cell><cell>89.71</cell><cell>0.906</cell></row><row><cell></cell><cell>2048</cell><cell>98.19</cell><cell>85.74</cell><cell>0.882</cell></row><row><cell></cell><cell>512</cell><cell>97.58</cell><cell>79.99</cell><cell>0.809</cell></row><row><cell>AdaptConv [70]</cell><cell>1024</cell><cell>99.05</cell><cell>82.90</cell><cell>0.858</cell></row><row><cell></cell><cell>2048</cell><cell>97.87</cell><cell>75.94</cell><cell>0.799</cell></row><row><cell>3DMedPT</cell><cell>512 1024 2048</cell><cell>99.02 99.24 99.07</cell><cell>94.06 93.26 93.49</cell><cell>0.920 0.936 0.931</cell></row><row><cell cols="5">on attention algorithms (e.g., Set Transformer [19], PAT [62] and Point2Sequence</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Classification results on ModelNet40 with different input types and point numbers.</figDesc><table><row><cell>Method</cell><cell>Input</cell><cell cols="2">#Points Acc. (%)</cell></row><row><cell>Set Transformer [19]</cell><cell>xyz</cell><cell>5k</cell><cell>90.4</cell></row><row><cell>PointCNN [21]</cell><cell>xyz</cell><cell>1k</cell><cell>91.7</cell></row><row><cell>DGCNN [46]</cell><cell>xyz</cell><cell>1k</cell><cell>92.2</cell></row><row><cell>Point2Sequence [22]</cell><cell>xyz</cell><cell>1k</cell><cell>92.6</cell></row><row><cell>GS-Net [58]</cell><cell>xyz</cell><cell>1k</cell><cell>92.9</cell></row><row><cell>RS-CNN [24]</cell><cell>xyz</cell><cell>1k</cell><cell>92.9</cell></row><row><cell>SO-Net [20]</cell><cell>xyz</cell><cell>2k</cell><cell>90.9</cell></row><row><cell>KPConv [38]</cell><cell>xyz</cell><cell>7k</cell><cell>92.9</cell></row><row><cell>PCT [12]</cell><cell>xyz</cell><cell>1k</cell><cell>93.2</cell></row><row><cell>AdaptConv [70]</cell><cell>xyz</cell><cell>1k</cell><cell>93.4</cell></row><row><cell cols="2">PAConv [56] Point Transformer [69] xyz xyz</cell><cell>1k 1k</cell><cell>93.6 93.7</cell></row><row><cell>PAT [62]</cell><cell cols="2">xyz + norm 1k</cell><cell>91.7</cell></row><row><cell>PointConv [51]</cell><cell cols="2">xyz + norm 1k</cell><cell>92.5</cell></row><row><cell>PointASNL [61]</cell><cell cols="2">xyz + norm 1k</cell><cell>93.2</cell></row><row><cell>PointNet++ [31]</cell><cell cols="2">xyz + norm 5k</cell><cell>91.9</cell></row><row><cell>SpiderCNN [60]</cell><cell cols="2">xyz + norm 5k</cell><cell>92.4</cell></row><row><cell>3DMedPT</cell><cell>xyz</cell><cell>1k</cell><cell>93.4</cell></row></table><note>augmentation method as Sec. 4.1.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Segmentation results of each point-based network. V. and A. represent parent vessel segments and aneurysm segments.</figDesc><table><row><cell>Method</cell><cell>#Points</cell><cell>V.</cell><cell>IoU (%) A.</cell><cell>V.</cell><cell>DSC (%) A.</cell></row><row><cell></cell><cell>512</cell><cell cols="4">73.99 37.30 84.05 48.96</cell></row><row><cell>PointNet [29]</cell><cell>1024</cell><cell cols="4">75.23 37.07 85.00 48.38</cell></row><row><cell></cell><cell>2048</cell><cell cols="4">74.22 37.75 84.17 49.59</cell></row><row><cell></cell><cell>512</cell><cell cols="4">93.42 76.22 96.48 83.92</cell></row><row><cell>PointNet++ [31]</cell><cell>1024</cell><cell cols="4">93.35 76.38 96.47 84.62</cell></row><row><cell></cell><cell>2048</cell><cell cols="4">93.24 76.21 96.40 84.64</cell></row><row><cell></cell><cell>512</cell><cell cols="4">92.49 70.65 95.97 78.55</cell></row><row><cell>PointCNN [21]</cell><cell>1024</cell><cell cols="4">93.47 74.11 96.53 81.74</cell></row><row><cell></cell><cell>2048</cell><cell cols="4">93.59 73.58 96.62 81.36</cell></row><row><cell></cell><cell>512</cell><cell cols="4">94.22 80.14 96.95 87.90</cell></row><row><cell>SO-Net [20]</cell><cell>1024</cell><cell cols="4">94.42 80.99 97.06 88.41</cell></row><row><cell></cell><cell>2048</cell><cell cols="4">94.46 81.40 97.09 88.76</cell></row><row><cell></cell><cell>512</cell><cell cols="4">90.16 67.25 94.53 75.82</cell></row><row><cell>SpiderCNN [60]</cell><cell>1024</cell><cell cols="4">87.95 61.60 93.24 71.08</cell></row><row><cell></cell><cell>2048</cell><cell cols="4">87.02 58.32 92.17 67.74</cell></row><row><cell></cell><cell>512</cell><cell cols="4">94.16 79.09 96.89 86.01</cell></row><row><cell>PointConv [51]</cell><cell>1024</cell><cell cols="4">94.59 79.42 97.15 86.29</cell></row><row><cell></cell><cell>2048</cell><cell cols="4">94.65 79.53 97.18 86.52</cell></row><row><cell></cell><cell>512</cell><cell cols="4">90.06 64.48 94.62 74.54</cell></row><row><cell>GS-Net [58]</cell><cell>1024</cell><cell cols="4">90.93 66.29 95.10 78.85</cell></row><row><cell></cell><cell>2048</cell><cell cols="4">91.06 65.76 95.15 75.06</cell></row><row><cell></cell><cell>512</cell><cell cols="4">92.49 78.09 96.08 85.84</cell></row><row><cell>PCT [12]</cell><cell>1024</cell><cell cols="4">92.05 78.12 95.85 86.77</cell></row><row><cell></cell><cell>2048</cell><cell cols="4">91.66 77.10 95.43 86.02</cell></row><row><cell></cell><cell>512</cell><cell cols="4">90.45 70.25 96.01 80.60</cell></row><row><cell>AdaptConv [70]</cell><cell>1024</cell><cell cols="4">90.69 75.26 94.92 84.40</cell></row><row><cell></cell><cell>2048</cell><cell cols="4">90.97 75.08 95.05 84.72</cell></row><row><cell></cell><cell>512</cell><cell cols="4">91.97 78.66 95.66 87.57</cell></row><row><cell>PAConv [56]</cell><cell>1024</cell><cell cols="4">90.34 74.31 94.54 83.16</cell></row><row><cell></cell><cell>2048</cell><cell cols="4">92.20 70.59 95.81 79.18</cell></row><row><cell>3DMedPT</cell><cell>512 1024 2048</cell><cell cols="4">94.82 81.80 97.29 89.25 94.76 82.39 97.25 89.71 93.52 80.13 96.59 88.69</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Segmentation results of different methods on ShapeNetPart. 83.4 78.7 82.5 74.9 89.6 73.0 91.5 85.9 80.8 95.3 65.2 93.0 81.2 57.9 72.8 80.6 PointNet++ [31] 81.9 82.4 79.0 87.7 77.3 90.8 71.8 91.0 85.9 83.7 95.3 71.6 94.1 81.3 58.7 76.4 82.6 PointCNN [21] 84.6 84.1 86.5 86.0 80.8 90.6 79.7 92.3 88.4 85.3 96.1 77.2 95.2 84.2 64.2 80.</figDesc><table><row><cell>Method</cell><cell>cls. mIoU plane air bag cap car chair</cell><cell>ear guitar knife lamp laptop phone</cell><cell>motor mug pistol rocket bike</cell><cell>skate table board</cell></row><row><cell>PointNet [29]</cell><cell cols="4">80.4 0 83.0</cell></row><row><cell cols="5">DGCNN [46] KPConv [38] PointASNL [61] 83.4 84.1 84.7 87.9 79.7 92.2 73.7 91.0 87.2 84.2 95.8 74.4 95.2 81.0 63.0 76.3 83.2 82.3 84.0 83.4 86.7 77.8 90.6 74.7 91.2 87.5 82.8 95.7 70.8 94.6 81.1 63.5 74.5 82.6 85.0 83.8 86.1 88.2 81.6 91.0 80.1 92.1 87.8 82.2 96.2 77.9 95.7 86.8 65.3 81.7 83.6</cell></row><row><cell cols="5">RS-CNN [24] PCT [12] PAConv [56] AdaptConv [70] 83.4 84.8 81.2 85.7 79.7 91.2 80.9 91.9 88.6 84.8 96.2 70.7 94.9 82.3 61.0 75.9 84.2 84.0 83.5 84.8 88.8 79.6 91.2 81.1 91.6 88.4 86.0 96.0 73.7 94.1 83.4 60.5 77.7 83.6 83.1 85.0 82.4 89.0 81.2 91.9 71.5 91.3 88.1 86.3 95.8 64.6 95.8 83.6 62.2 77.6 83.7 84.6 84.3 85.0 90.4 79.7 90.6 80.8 92.0 88.7 82.2 95.9 73.9 94.7 84.7 65.9 81.4 84.0 3DMedPT 84.3 81.2 86.0 91.7 79.6 90.1 81.2 91.9 88.5 84.8 96.0 72.3 95.8 83.2 64.6 78.2 83.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Positional embeddings in 3DMedPT evaluated on F1score. RPE k , RPEq and RPEv indicate relative positional embeddings at the key, query and value.</figDesc><table><row><cell></cell><cell cols="3">RPEq RPE k RPEv</cell><cell>F1</cell></row><row><cell cols="2">A</cell><cell></cell><cell></cell><cell>0.905</cell></row><row><cell cols="2">B</cell><cell></cell><cell></cell><cell>0.924</cell></row><row><cell cols="2">C</cell><cell></cell><cell></cell><cell>0.915</cell></row><row><cell cols="2">D</cell><cell></cell><cell></cell><cell>0.921</cell></row><row><cell cols="2">E</cell><cell></cell><cell></cell><cell>0.920</cell></row><row><cell cols="2">F</cell><cell></cell><cell></cell><cell>0.917</cell></row><row><cell cols="2">G</cell><cell></cell><cell></cell><cell>0.928</cell></row><row><cell cols="2">H</cell><cell></cell><cell></cell><cell>0.936</cell></row><row><cell>Table 6.</cell><cell cols="4">Model complexity of 3DMedPT for the IntrA</cell></row><row><cell cols="5">classification, where model parameters are in the unit of millions</cell></row><row><cell cols="5">and throughput is reported in examples per second.</cell></row><row><cell>Method</cell><cell></cell><cell cols="3">#Params Throughput</cell><cell>F1</cell></row><row><cell cols="2">PointNet++ [31]</cell><cell>1.75M</cell><cell cols="2">245 ex/s</cell><cell>0.769</cell></row><row><cell cols="2">DGCNN [46]</cell><cell>1.81M</cell><cell cols="2">365 ex/s</cell><cell>0.738</cell></row><row><cell cols="2">PCT [12]</cell><cell>2.73M</cell><cell cols="2">471 ex/s</cell><cell>0.872</cell></row><row><cell cols="2">AdaptConv [70]</cell><cell>1.76M</cell><cell cols="2">230 ex/s</cell><cell>0.806</cell></row><row><cell cols="2">PAConv [56] 3DMedPT</cell><cell>2.32M 1.54M</cell><cell cols="2">507 ex/s 843 ex/s</cell><cell>0.866 0.922</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1 .</head><label>1</label><figDesc>Model performance on IntrA classification with different configurations of MGR, where MGR-1 indicates only one graph is constructed.</figDesc><table><row><cell>Method</cell><cell>F1</cell></row><row><cell cols="2">w/o MGR 0.884 MGR-1 0.910 MGR 0.922</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 .</head><label>2</label><figDesc>Model performance comparisons among four different layer settings, where #Layers denotes the number of attention modules before the MGR module.</figDesc><table><row><cell>#Layers 1 2 3 4</cell><cell>F1 0.902 0.922 0.912 0.901</cell><cell>Throughout 1229 ex/s 843 ex/s 508 ex/s 326 ex/s</cell></row><row><cell cols="3">Table 3. Model performances of different hyperparameter choices</cell></row><row><cell cols="3">for the optimal attention block design.</cell></row><row><cell cols="3">F1 Score h 8 16 0.912 0.913 0.921 0.919 C k 8 16 32 48 0.913 0.912 0.922 0.916 32 0.919 0.918 0.921 0.916 64 0.915 0.910 0.916 0.904</cell></row><row><cell cols="3">Table 4. Model performance on IntrA classification with different</cell></row><row><cell>normalization functions.</cell><cell></cell><cell></cell></row><row><cell cols="2">Norm. function</cell><cell>F1</cell></row><row><cell cols="2">w/o norm sigmoid max(0, Tanh) softmax</cell><cell>0.887 0.915 0.913 0.922</cell></row><row><cell cols="3">fold as testing set and the others as training sets. It can be seen that the best F1 score of 0.922 is achieved when</cell></row><row><cell>C</cell><cell></cell><cell></cell></row></table><note>k = 32 and h = 8.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 .</head><label>5</label><figDesc>Classification results on RetinalOCT with different methods.</figDesc><table><row><cell>Method</cell><cell cols="2">Input Type Acc. (%)</cell></row><row><cell>Pre-trained InceptionV3 [4] ResNet-18 [2] ResNet-50 [2] AutoKeras [3]</cell><cell>pixels pixels pixels pixels</cell><cell>96.6 95.8 96.1 96.3</cell></row><row><cell>PointNet [5] DGCNN [8] PCT [1] 3DMedPT</cell><cell>points points points points</cell><cell>86.5 87.9 87.2 90.9</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tractogram filtering of anatomically non-plausible fibers with geometric deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Astolfi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruben</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Petit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Olivetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Avesani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Lambdanetworks: Modeling long-range interactions without attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwan</forename><surname>Bello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Franjo Pernu?, and?iga?piclin. Vascular surface segmentation for intracranial aneurysm isolation and quantification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?iga</forename><surname>Bizjak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo?tjan</forename><surname>Likar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">End-toend object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Cyclemlp: A mlp-like architecture for dense prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoufa</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongjian</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.10224</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graph-based global reasoning networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Shuicheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="433" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Generating long sequences with sparse transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.10509</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesung</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunghyun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Rameau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.11187</idno>
		<title level="m">Jaesik Park, and In So Kweon. Pointmixer: Mlp-mixer for point cloud understanding</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rethinking attention with performers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerii</forename><surname>Krzysztof Marcin Choromanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Likhosherstov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyou</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreea</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamas</forename><surname>Gane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Sarlos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><forename type="middle">Quincy</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afroz</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Mohiuddin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">Benjamin</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><forename type="middle">J</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Colwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 NAACL</title>
		<meeting>the 2019 NAACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Xiong</forename><surname>Meng-Hao Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Ning</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tai-Jiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><forename type="middle">R</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi-Min</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
		<title level="m">Pct: Point cloud transformer. Computational Visual Media</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="187" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning hybrid representations for automatic 3d vessel centerline extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafa</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengwei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Transformers are rnns: Fast autoregressive transformers with linear attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelos</forename><surname>Katharopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorv</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Fleuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML. PMLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Reformer: The efficient transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Kitaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Levskaya</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.04451</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Big transfer (bit): General visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.11370</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Large-scale point cloud semantic segmentation with superpoint graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Landrieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Simonovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Set transformer: A framework for attention-based permutation-invariant neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungtaek</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kosiorek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungjin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3744" to="3753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">So-net: Selforganizing network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9397" to="9406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Pointcnn: Convolution on x-transformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingchao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhan</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="820" to="830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Point2sequence: Learning the shape representation of 3d point clouds with an attention-based sequence to sequence network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Shen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zwicker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8778" to="8785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Densepoint: Learning densely contextual representation for efficient point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Shiming Xiang, and Chunhong Pan</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5239" to="5248" />
		</imprint>
	</monogr>
	<note>Proceedings of CVPR</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Relation-shape convolutional neural network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongcheng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bin Fan, Shiming Xiang, and Chunhong Pan</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Proceedings of CVPR</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Convtransformer: A convolutional transformer network for video frame synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouyong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wubin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingben</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luxi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.10185</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Global context reasoning for semantic segmentation of 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanni</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinjie</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gongjian</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Winter Conference on Applications of Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Voxnet: A 3d convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="922" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="652" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Volumetric and multi-view cnns for object classification on 3d data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Nie?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyuan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5648" to="5656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5099" to="5108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Stand-alone selfattention in vision models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwan</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NeuIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Efficient content-based sparse attention with routing transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Saffar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.05997</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Medmeshcnn-enabling meshcnn for medical surface models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annika</forename><surname>Niemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Beuing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Preim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvia</forename><surname>Saalfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Methods and Programs in Biomedicine</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Point-gnn: Graph neural network for 3d object detection in a point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><surname>Rajkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Evangelos Kalogerakis, and Erik Learned-Miller. Multi-view convolutional neural networks for 3d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="945" to="953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Synthesizer: Rethinking self-attention for transformer models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dara</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da-Cheng</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Che</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10183" to="10192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Kpconv: Flexible and deformable convolution for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Emmanuel</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatriz</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6411" to="6420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Mlp-mixer: An all-mlp architecture for vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Tolstikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">Peter</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NeuIPS</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alaaeldin</forename><surname>El-Nouby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.03404</idno>
		<title level="m">Feedforward networks for image classification with data-efficient training</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Medical transformer: Gated axialattention for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeya Maria Jose</forename><surname>Valanarasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Poojan</forename><surname>Oza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilker</forename><surname>Hacihaliloglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2021</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="36" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Axial-deeplab: Standalone axial-attention for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Graph attention convolution for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaolin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenman</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Shan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10296" to="10305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep parametric continuous convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chiu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Pokrovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Transactions On Graphics (tog)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Visual transformers: Token-based image representation and processing for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Auli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.10430</idno>
		<title level="m">Pay less attention with lightweight and dynamic convolutions</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiping</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.15808</idno>
		<title level="m">Cvt: Introducing convolutions to vision transformers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NeurIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Pointconv: Deep convolutional networks on 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fuxin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9621" to="9630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Lite transformer with long-short range attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.11886</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1912" to="1920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Walk in the cloud: Learning curves for point clouds shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiange</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2021-10" />
			<biblScope unit="page" from="915" to="924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deepshape: Deep-learned shape descriptor for 3d shape retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoxian</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1335" to="1345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Paconv: Position adaptive convolution with dynamic kernel assembling on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runyu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3173" to="3182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning geometry-disentangled representation for complementary understanding of 3d object point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021-05" />
			<biblScope unit="page" from="3056" to="3064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Geometry sharing network for 3d point cloud classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Grid-gcn for fast and scalable point cloud learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiangeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Ying</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panqu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5661" to="5670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Spidercnn: Deep learning on point sets with parameterized convolutional filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="87" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Pointasnl: Robust point clouds processing using nonlocal neural networks with adaptive sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoda</forename><surname>Xu Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5589" to="5598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Modeling point clouds with self-attention and gumbel subset sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiancheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengdie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3323" to="3332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Intra: 3d intracranial aneurysm dataset for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taichi</forename><surname>Kin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Igarashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2656" to="2666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Russ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A scalable active framework for region annotation in 3d shape collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I-Chao</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Sheffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">S2-mlpv2: Improved spatial-shift mlp architecture for vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfeng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.01072</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Exploiting edge-oriented reasoning for 3d point-based scene graph analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="page" from="9705" to="9715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Latentgnn: Learning efficient non-local relations for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shipeng</forename><surname>Yan</surname></persName>
		</author>
		<editor>ICLR. PMLR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Point transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="16259" to="16268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Adaptive graph convolution for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yidan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingqiang</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Xiong</forename><surname>Meng-Hao Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Ning</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tai-Jiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><forename type="middle">R</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi-Min</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
		<title level="m">Pct: Point cloud transformer. Computational Visual Media</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="187" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Auto-keras: An efficient neural architecture search system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingquan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1946" to="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Identifying medical diagnoses and treatable diseases by image-based deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kermany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjia</forename><surname>Goldbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Carolina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiying</forename><surname>Valentim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Baxter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangbing</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="652" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Point-net++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5099" to="5108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Transactions On Graphics (tog)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Deepshape: Deep-learned shape descriptor for 3d shape retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoxian</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1335" to="1345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiancheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donglai</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilian</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanspeter</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14795</idno>
		<title level="m">Medmnist v2: A large-scale lightweight benchmark for 2d and 3d biomedical image classification</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Intra: 3d intracranial aneurysm dataset for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taichi</forename><surname>Kin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Igarashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2656" to="2666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Alla Sheffer, and Leonidas Guibas. A scalable active framework for region annotation in 3d shape collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I-Chao</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
