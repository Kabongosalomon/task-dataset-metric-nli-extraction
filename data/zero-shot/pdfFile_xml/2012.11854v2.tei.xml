<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Second-Order Approach to Learning with Instance-Dependent Label Noise</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-03-30">30 Mar 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Zhu</surname></persName>
							<email>zwzhu@ucsc.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">Santa Cruz ? Trustworthy Machine Learning Lab</orgName>
								<orgName type="institution" key="instit1">University of California</orgName>
								<orgName type="institution" key="instit2">The University of Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
							<email>?tongliang.liu@sydney.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">Santa Cruz ? Trustworthy Machine Learning Lab</orgName>
								<orgName type="institution" key="instit1">University of California</orgName>
								<orgName type="institution" key="instit2">The University of Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<email>yangliu@ucsc.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">Santa Cruz ? Trustworthy Machine Learning Lab</orgName>
								<orgName type="institution" key="instit1">University of California</orgName>
								<orgName type="institution" key="instit2">The University of Sydney</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Second-Order Approach to Learning with Instance-Dependent Label Noise</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-03-30">30 Mar 2021</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The presence of label noise often misleads the training of deep neural networks. Departing from the recent literature which largely assumes the label noise rate is only determined by the true label class, the errors in humanannotated labels are more likely to be dependent on the difficulty levels of tasks, resulting in settings with instancedependent label noise. We first provide evidences that the heterogeneous instance-dependent label noise is effectively down-weighting the examples with higher noise rates in a non-uniform way and thus causes imbalances, rendering the strategy of directly applying methods for classdependent label noise questionable. Built on a recent work peer loss [24], we then propose and study the potentials of a second-order approach that leverages the estimation of several covariance terms defined between the instance-dependent noise rates and the Bayes optimal label. We show that this set of second-order statistics successfully captures the induced imbalances. We further proceed to show that with the help of the estimated secondorder statistics, we identify a new loss function whose expected risk of a classifier under instance-dependent label noise is equivalent to a new problem with only classdependent label noise. This fact allows us to apply existing solutions to handle this better-studied setting. We provide an efficient procedure to estimate these second-order statistics without accessing either ground truth labels or prior knowledge of the noise rates. Experiments on CI-FAR10 and CIFAR100 with synthetic instance-dependent label noise and Clothing1M with real-world human label noise verify our approach. Our implementation is available at https://github.com/UCSC-REAL/CAL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep neural networks (DNNs) are powerful in revealing and fitting the relationship between feature X and label Y when a sufficiently large dataset is given. However, the label Y usually requires costly human efforts for ac-curate annotations. With limited budgets/efforts, the resulting dataset would be noisy, and the existence of label noise may mislead DNNs to learn or memorize wrong correlations <ref type="bibr">[10,</ref><ref type="bibr">11,</ref><ref type="bibr" target="#b1">35,</ref><ref type="bibr" target="#b4">38,</ref><ref type="bibr">47]</ref>. To make it worse, the label noise embedded in human annotations is often instancedependent, e.g., some difficult examples are more prone to be mislabeled <ref type="bibr" target="#b0">[34]</ref>. This hidden and imbalanced distribution of noise often has a detrimental effect on the training outcome <ref type="bibr">[15,</ref><ref type="bibr">23]</ref>. It remains an important and challenging task to learn with instance-dependent label noise.</p><p>Theory-supported works addressing instance-dependent label noise mostly rely on loss correction, which requires estimating noise rates <ref type="bibr" target="#b6">[40]</ref>. Recent work has also considered the possibility of removing the dependency on estimating noise rates <ref type="bibr">[5]</ref>. The proposed solution uses a properly specified regularizer to eliminate the effect of instance-dependent label noise. The common theme of the above methods is the focus on learning the underlying clean distribution by using certain forms of first-order statistics of model predictions. In this paper, we propose a second-order approach with the assistance of additional second-order statistics and explore how this information can improve the robustness of learning with instance-dependent label noise. Our main contributions summarize as follows. 1. Departing from recent works <ref type="bibr">[5,</ref><ref type="bibr">24,</ref><ref type="bibr">27,</ref><ref type="bibr">29,</ref><ref type="bibr">32,</ref><ref type="bibr" target="#b6">40,</ref><ref type="bibr" target="#b8">42]</ref> which primarily rely on the first-order statistics (i.e. expectation of the models' predictions) to improve the robustness of loss functions, we propose a novel secondorder approach and emphasize the importance of using second-order statistics (i.e. several covariance terms) when dealing with instance-dependent label noise.</p><p>2. With the perfect knowledge of the covariance terms defined above, we identify a new loss function that transforms the expected risk of a classifier under instancedependent label noise to a risk with only class-dependent label noise, which is an easier case and can be handled well by existing solutions. Based on peer loss <ref type="bibr">[24]</ref>, we further show the expected risk of class-dependent noise is equivalent to an affine transformation of the expected risk under the Bayes optimal distribution. Therefore we establish that our new loss function for Covariance-Assisted Learning (CAL) will induce the same minimizer as if we can access the clean Bayes optimal labels. 3. We show how the second-order statistics can be estimated efficiently using existing sample selection techniques. For a more realistic case where the covariance terms cannot be perfectly estimated, we prove the worstcase performance guarantee of our solution. 4. In addition to the theoretical guarantees, the performance of the proposed second-order approach is tested on the CIFAR10 and CIFAR100 datasets with synthetic instance-dependent label noise and the Cloth-ing1M dataset with real-world human label noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related Works</head><p>Below we review the most relevant literature. Bounded loss functions Label noise encodes a different relation between features and labels. A line of literature treats the noisy labels as outliers. However, the convex loss functions are shown to be prone to mistakes when outliers exist <ref type="bibr">[25]</ref>. To handle this setting, the cross-entropy (CE) loss can be generalized by introducing temperatures to logarithm functions and exponential functions <ref type="bibr">[1,</ref><ref type="bibr">2,</ref><ref type="bibr">50]</ref>. Noting the CE loss grows explosively when the prediction f (x) approaches zero, some solutions focus on designing bounded loss functions <ref type="bibr">[8,</ref><ref type="bibr">9,</ref><ref type="bibr">31,</ref><ref type="bibr" target="#b2">36]</ref>. These methods focus on the numerical property of loss functions, and most of them do not discuss the type of label noise under treatment. Learning clean distributions To be noise-tolerant <ref type="bibr">[26]</ref>, it is necessary to understand the effect of label noise statistically. With the class-dependent assumption, the loss can be corrected/reweighted when the noise transition T is available, which can be estimated by discovering anchor points <ref type="bibr">[22,</ref><ref type="bibr">29,</ref><ref type="bibr" target="#b5">39]</ref>, exploiting clusterability [51], regularizing total variation <ref type="bibr">[49]</ref>, or minimizing volume of T [20]. The loss correction/reweighting methods rely closely on the quality of the estimated noise transition matrix. To make it more robust, an additive slack variable ?T <ref type="bibr" target="#b7">[41]</ref> or a multiplicative dual T [45] can be used for revision. Directly extending these loss correction methods to instance-dependent label noise is prohibitive since the transition matrix will become a function of feature X and the number of parameters to be estimated is proportional to the number of training instances. Recent follow-up works often introduce extra assumption <ref type="bibr" target="#b6">[40]</ref> or measure <ref type="bibr">[4]</ref>. Statistically, the loss correction approach is learning the underlying clean distribution if a perfect T is applied. When the class-dependent noise rate is known, surrogate loss <ref type="bibr">[27]</ref>, an unbiased loss function targeting on binary classifications, also learns the clean distribution. Additionally, the symmetric cross-entropy loss <ref type="bibr" target="#b2">[36]</ref>, an information-based loss L DMI <ref type="bibr" target="#b9">[43]</ref>, a correlated agreement (CA) based loss peer loss <ref type="bibr">[24]</ref>, and its adaptation for encouraging confident predictions [5] are proposed to learn the underlying clean distribution without knowing the noise transition matrix. Other popular methods Other methods exist with more sophisticated training framework or pipeline, including sample selection <ref type="bibr">[5,</ref><ref type="bibr">12,</ref><ref type="bibr">16,</ref><ref type="bibr">18,</ref><ref type="bibr" target="#b3">37,</ref><ref type="bibr">46,</ref><ref type="bibr">44]</ref>, label correction [13, 21, 33], and semi-supervised learning [19, 28], etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>This paper targets on a classification problem given a set of N training examples with Instance-Dependent label Noise (IDN) denoted by D := {(x n ,? n )} n?[N ] , where [N ] := {1, 2, ? ? ? , N } is the set of indices. The corresponding noisy data distribution is denoted by D. Examples (x n ,? n ) are drawn according to random variables (X, Y ) ? D. Our goal is to design a learning mechanism that is guaranteed to be robust when learning with only accessing D. Before proceeding, we summarize important definitions as follows. Clean distribution D Each noisy example (x n ,? n ) ? D corresponds to a clean example (x n , y n ) ? D, which contains one unobservable ground-truth label, a.k.a. clean label. Denote by D the clean distribution. Clean examples (x n , y n ) are drawn from random variables (X, Y ) ? D. Bayes optimal distribution D * Denote by Y * the Bayes optimal label given feature X, that is:</p><formula xml:id="formula_0">Y * |X := arg max Y P(Y |X), (X, Y ) ? D.</formula><p>The distribution of (X, Y * ) is denoted by D * . Note the Bayes optimal distribution D * is different from the clean distribution D when P(Y |X) / ? {0, 1}. Due to the fact that the information encoded between features and labels is corrupted by label noise, and both clean labels and Bayes optimal labels are unobservable, inferring the Bayes optimal distribution D * from the noisy dataset D is a non-trivial task. Notably there exist two approaches [5, 6] that provide guarantees on constructing the Bayes optimal dataset. We would like to remind the readers that the noisy label? n , clean label y n , and Bayes optimal label y * n for the same feature x n may disagree with each other.</p><p>Most of our developed approaches will focus on dealing with the Bayes optimal distribution D * . By referring to D * , as we shall see later, we are allowed to estimate the secondorder statistics defined w.r.t. Y * . Noise transition matrix T (X) Traditionally, the noise transition matrix is defined based on the relationship between clean distributions and noisy distributions <ref type="bibr">[5,</ref><ref type="bibr">24,</ref><ref type="bibr">30,</ref><ref type="bibr" target="#b6">40]</ref>. In recent literature [6], the Bayes optimal label (a.k.a. distilled label in [6]) also plays a significant role. In the image classification tasks where the performance is measured by the clean test accuracy, predicting the Bayes optimal label achieves the best performance. This fact motivates us to define a new noise transition matrix based on the Bayes optimal label as follows:</p><formula xml:id="formula_1">T i,j (X) = P( Y = j|Y * = i, X),</formula><p>where T i,j (X) denotes the (i, j)-th element of the matrix T (X). Its expectation is defined as</p><formula xml:id="formula_2">T := E[T (X)], with the (i, j)-th element being T i,j := E[T i,j (X)].</formula><p>Other notations Let X and Y 1 be the space of feature X and label Y , respectively. The classification task aims to identify a classifier f : X ? Y that maps X to Y accurately. One common approach is minimizing the empirical risk using DNNs with respect to the cross-entropy (CE) loss defined as:</p><formula xml:id="formula_3">?(f (X), Y ) := ? ln(f X [Y ]), Y ? [K], where f X [Y ] denotes the Y -th component of f (X)</formula><p>and K is the number of classes. Let 1{?} be the indicator function taking value 1 when the specified condition is satisfied and 0 otherwise. Define the 0-1 loss as</p><formula xml:id="formula_4">1(f (X), Y ) := 1{f (X) = Y }. Define the Bayes optimal classifier f * as f * = arg min f E D * [1(f (X), Y * )].</formula><p>Noting the CE loss is classification-calibrated [3], given enough clean data, the Bayes optimal classifier can be learned using the CE loss:</p><formula xml:id="formula_5">f * =arg min f E D [?(f (X), Y )].</formula><p>Goal Different from the goals in surrogate loss [27], L DMI <ref type="bibr" target="#b9">[43]</ref>, peer loss [24], and CORES 2 [5], which focus on recovering the performance of learning on clean distributions, we aim to learn a classifier f from the noisy distribution</p><formula xml:id="formula_6">D which also minimizes E[1(f (X), Y * )], (X, Y * ) ? D * . Note E[1(f * (X)</formula><p>, Y * )] = 0 holds for the Bayes optimal classifier f * . Thus, in the sense of searching for the Bayes optimal classifier, our goals are aligned with the ones focusing on the clean distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Insufficiency of First-Order Statistics</head><p>Peer loss [24] and its inspired confidence regularizer [5] are two recently introduced robust losses that operate without the knowledge of noise transition matrices, which presents them as preferred solutions for more complex noise settings. In this section, we will first review the usages of first-order statistics in peer loss and the confidence regularizer (Section 3.1), and then analyze the insufficiency of using only the first-order statistics when handling the challenging IDN (Section 3.2). Besides, we will anatomize the down-weighting effect of IDN and provide intuitions for how to make IDN easier to handle (Section 3.3).</p><p>We formalize our arguments using peer loss, primarily due to 1) its clean analytical form, and 2) that our later proposed solution will be built on peer loss too. Despite the focus on peer loss, we believe these observations are generally true when other existing training approaches meet IDN.</p><p>For ease of presentation, the following analyses focus on binary cases (with classes {?1, +1}). Note the class ?1 should be mapped to class 0 following the notations in Section 2. For a clear comparison with previous works, we follow the notation in [24] and use class {?1, +1} to represent classes {0, 1} when K = 2. The error rates in Y are then denoted as e + (X) := P( Y = ?1|Y * = +1, X), e ? (X) := P( Y = +1|Y * = ?1, X). Most of the discussions generalize to the multi-class setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Using First-Order Statistics in Peer Loss</head><p>It has been proposed and proved in peer loss [24] and CORES 2 [5] that the learning could be robust to label noise by considering some first-order statistics related to the model predictions. For each example (x n ,? n ), peer loss [24] has the following form:</p><formula xml:id="formula_7">? PL (f (x n ),? n ) := ?(f (x n ),? n ) ? ?(f (x n1 ),? n2 ),</formula><p>where (x n1 ,? n1 ) and (x n2 ,? n2 ) are two randomly sampled peer samples for n. The first-order statistics related to model predictions characterized by the peer term ?(f (x n1 ),? n2 ) are further extended to a confidence regularizer in CORES 2 [5]:</p><formula xml:id="formula_8">? CORES 2 (f (x n ),? n ) := ?(f (x n ),? n )??E D Y | D [?(f (x n ), Y )],</formula><p>where ? is a hyperparameter controlling the ability of regularizer, and D Y | D is the marginal distribution of Y given dataset D. Although it has been shown in [5] that learning with an appropriate ? would be robust to instancedependent label noise theoretically, in real experiments, converging to the guaranteed optimum by solving a highly non-convex problem is difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Peer Loss with IDN</head><p>Now we analyze the possible performance degradation of using the binary peer loss function proposed in [24] to handle IDN. Denote b?</p><formula xml:id="formula_9">f * peer := arg min f E D 1 PL (f (X), Y )</formula><p>the optimal classifier learned by minimizing 0-1 peer loss, where 1 PL represents ? PL with 0-1 loss (could also be generalized for ? CORES 2 with 0-1 loss). Let p * := P(Y * = +1). With a bounded variance in the error rates, supposing</p><formula xml:id="formula_10">E|e + (X)?E[e + (X)]| ? ? + , E|e ? (X)?E[e ? (X)]| ? ? ? ,</formula><p>the worst-case performance bound for using pure peer loss is provided in Theorem 1 and proved in Appendix B.1.</p><p>Theorem 1 (Performance of peer loss). With the peer loss function proposed in <ref type="bibr">[24]</ref>, we have</p><formula xml:id="formula_11">E[1(f * peer (X), Y * )] ? 2(? + + ? ? ) 1 ? e + ? e ? + 2|p * ? 0.5|.</formula><p>Theorem 1 shows the ratio of wrong predictions given b? f * peer includes two components. The former term 2(?++??) 1?e+?e? is directly caused by IDN, indicating the error is increasing when the instance-dependent noise rates have larger mean (larger e + + e ? ) and larger variation (larger ? + + ? ? ). The latter term 2|p * ? 0.5| shows possible errors induced by an unbalanced D * . Theorem 1 generalizes peer loss where ? + = ? ? = 0, i.e., the error rates are homogeneous across data instances, and there is no need to consider any secondorder statistics that involve the distribution of noise rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Down-weighting Effect of IDN</head><p>We further discuss motivations and intuitions by studying how IDN affects the training differently from the classdependent one. Intuitively, a high noise rate reduces the informativeness of a particular example (x, y), therefore "down-weighting" its contribution to training. We now analytically show this under peer loss.</p><p>As a building block, the invariant property (in terms of the clean distribution D) originally discovered by peer loss on class-dependent label noise is first adapted for the Bayes optimal distribution D * . Define e ? := P( Y = +1|Y * = ?1) and e + := P( Y = ?1|Y * = +1). Focusing on a particular class-dependent D, we provide Lemma 1 and its proof in Appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 1 (Invariant property of peer loss [24]). Peer loss is invariant to class-dependent label noise:</head><formula xml:id="formula_12">E D [1PL(f (X), Y )] = (1 ? e+ ? e?)ED * [1PL(f (X), Y * )]. (1)</formula><p>Then we discuss the effect of IDN. Without loss of generality, consider a case where noisy examples are drawn from two noisy distributions D I and D II , and the noise rate of D II is higher than D I , i.e. e +,II + e ?,II &gt; e +,I + e ?,I , where e +,I (II) := P DI (II) ( Y = ?1|Y * = +1). Assume a particular setting of IDN that the noise is class-dependent (but not instance-dependent) only within each distribution, and different between two distributions, i.e. part-dependent <ref type="bibr" target="#b6">[40]</ref>. Let D * I and D * II be the Bayes optimal distribution related to D I and D II . For simplicity, we write P((X,</p><formula xml:id="formula_13">Y * ) ? D * I(II) |(X, Y * ) ? D * ) as P(D * I(II)</formula><p>). Then P(D * I ) = P( D I ) and P(D * II ) = P( D II ). Note P( D I )e +,I + P( D II )e +,II = e + and P( D I )e ?,I + P( D II )e ?,II = e ? . Then we have the following equality:</p><formula xml:id="formula_14">E D [1 PL (f (X), Y )] =P( D I )(1 ? e +,I ? e ?,I )E D * I [1 PL (f (X), Y * )] + P( D II )(1 ? e +,II ? e ?,II )E D * II [1 PL (f (X), Y * )] =(1 ? e +,I ? e ?,I ) P(D * I )E D * I [1 PL (f (X), Y * )] + 1 ? e +,II ? e ?,II 1 ? e +,I ? e ?,I P(D * II )E D * II [1 PL (f (X), Y * )] , where 1 ? e +,II ? e ?,II 1 ? e +,I ? e ?,I &lt; 1</formula><p>indicates down-weighting examples drawn from D II (compared to the class-dependent label noise).</p><p>What can we learn from this observation? First, we show the peer loss is already down weighting the importance of the more noisy examples. However, simply dropping examples with potentially high-level noise might lead the classifier to learn a biased distribution. Moreover, subjectively confusing examples are more prone to be mislabeled and critical for accurate predictions <ref type="bibr" target="#b0">[34]</ref>, thus need to be carefully addressed. Our second observation is that if we find a way to compensate for the "imbalances" caused by the down-weighting effects shown above, the challenging instance-dependent label noise could be transformed into a class-dependent one, which existing techniques can then handle. More specifically, the above result shows the downweighting effect is characterized by T (X), implying only using the first-order statistics of model predictions without considering the distributions of the noise transition matrix T (X) is insufficient to capture the complexity of the learning task. However, accurately estimating T (X) is prohibitive since the number of parameters to be estimated is almost at the order of O(N K 2 ) -recall N is the number of training examples and K is the number of classes. Even though we can roughly estimate T (X), applying elementwise correction relying on the estimated T (X) may accumulate errors. Therefore, to achieve the transformation from the instance-dependent to the easier class-dependent, we need to resort to other statistical properties of T (X).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Covariance-Assisted Learning (CAL)</head><p>From the analyses in Section 3.3, we know the instancedependent label noise will "automatically" assign different weights to examples with different noise rates, thus cause imbalances. When the optimal solution does not change under such down-weighting effects, the first-order statistics based on peer loss [5, 24] work well. However, for a more robust and general solution, using additional information to "balance" the effective weights of different examples is necessary. Although the Bayes optimal distribution is not accessible in real experiments, we first assume its existence for theoretical analyses in the ideal case, then we will discuss the gap to this optimal solution when we can only use a proxyD that can be constructed efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Extracting Covariance from IDN</head><p>Again consider an instance-dependent noisy distribution D with binary classes where Y ? {?1, +1}. Define the following two random variables to facilitate analyses: Theorem 2 (Decoupling binary IDN). In binary classifications, the expected peer loss with IDN writes as:</p><formula xml:id="formula_15">Z 1 (X) := 1?e + (X)?e ? (X), Z 2 (X) = e + (X)?e ? (X).</formula><formula xml:id="formula_16">E D [1 PL (f (X), Y )] = (1 ? e + ? e ? )E D * [1 PL (f (X), Y * )] + Cov D * (Z 1 (X), 1(f (X), Y * )) + Cov D * (Z 2 (X), 1(f (X), ?1)). (2)</formula><p>Theorem 2 effectively divides the instance-dependent label noise into two parts. As shown in Eq. (2), the first line is the same as Eq. (1) in Lemma 1, indicating the average effect of instance-dependent label noise can be treated as a class-dependent one with parameters e + , e ? . The additional two covariance terms in the second and the third lines of Eq. (2) characterize the additional contribution of examples due to their differences in the label noise rates. The covariance terms will become larger for a setting with more diverse noise rates, capturing a more heterogeneous and uncertain learning environment. Interested readers are also referred to the high-level intuitions for using covariance terms at the end of Section 3.3.</p><p>We now briefly discuss one extension of Theorem 2 to a K-class classification task. Following the assumption adopted in [24], we consider a particular setting of IDN whose the expected transition matrix satisfies T i,j = T k,j , ?i = j = k. Denote by e j = T i,j , ?i = j. Corollary 1 decouples the effects of IDN in multi-class cases and is proved in Appendix C.1.</p><p>Corollary 1 (Decoupling multi-class IDN). In multi-class classifications, when the expected transition matrix satisfies e j = T i,j = T k,j , ?i = j = k, the expected peer loss with IDN writes as:</p><formula xml:id="formula_17">E D [? PL (f (X), Y )] = (1 ? i?[K] e i )E D * [? PL (f (X), Y * )] + j?[K] E D Y * Cov D * |Y * (T Y * ,j (X), ?(f (X), j)) , where D Y * is the marginal distribution of Y * and D * |Y * is the conditional distribution of D * given Y * .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Using Second-Order Statistics</head><p>Inspired by Theorem 2, if D * is available, we can subtract two covariance terms and make peer loss invariant to IDN. Specifically, defin?</p><formula xml:id="formula_18">f * CAL = arg min f E D [1PL(f (X), Y )] ? Cov(Z1(X), 1(f (X), Y * ))</formula><p>? Cov(Z2(X), 1(f (X), ?1)).</p><p>We have the following optimality guarantee and its proof is deferred to Appendix B.3.</p><formula xml:id="formula_19">Theorem 3.f * CAL ? arg min f E D * [1(f (X), Y * )]</formula><p>. For a K-class classification problem, a general loss function for our Covariance-Assisted Learning (CAL) approach is given by</p><formula xml:id="formula_20">? CAL (f (x n ),? n ) = ? PL (f (x n ),? n ) ? j?[K] E D Y * Cov D * |Y * (T Y * ,j (X), ?(f (X), j)) . (3)</formula><p>Eq. (3) shows the Bayes optimal distribution D * is critical in implementing the proposed covariance terms. However, D * cannot be obtained trivially, and only imperfect proxy constructions of the dataset (denoted byD) could be expected. Detailed constructions ofD are deferred to Section 4.2.1. Advantages of using covariance terms There are several advantages of using the proposed covariance terms. Unlike directly correcting labels according to D * , the proposed covariance term can be viewed as a "soft" correction that maintains the information encoded in both original noisy labels and the estimated Bayes optimal labels. Keeping both information is beneficial as suggested in <ref type="bibr">[13]</ref>. Moreover, compared to the direct loss correction approaches [30, <ref type="bibr" target="#b6">40,</ref><ref type="bibr" target="#b7">41]</ref>, we keep the original learning objective and apply "correction" using an additional term. Our method is more robust in practice compared to these direct endto-end loss correction approaches due to two reasons: 1) The covariance term summarizes the impact of the complex noise using an average term, indicating that our approach is less sensitive to the estimation precision of an individual example; 2) As will be shown in Section 4.3, the proposed method is tolerant with accessing an imperfect D * .</p><p>Estimating the covariance terms relies on samples drawn from distribution D * . Thus, we need to construct a dataset D, which is similar or unbiased w.r.t. D * . We will first show the algorithm for constructingD, then provide details for DNN implementations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">ConstructingD</head><p>To achieve unbiased estimates of the variance terms, the high-level intuition for constructingD is determining whether the label of each example in D is Bayes optimal or not by comparing the likelihood, confidence, or loss of classifying the (noisy) label to some thresholds. There are several methods for constructingD: distillation [6], searching to exploit <ref type="bibr">[44]</ref>, and sample sieve <ref type="bibr">[5]</ref>. If the model does not overfit the label noise and learns the noisy distribution, both methods in [6] and [44] work well. However, for the challenging instance-dependent label noise, overfitting occurs easily thus techniques to avoid overfitting are necessary. In this paper, we primarily adapt the sample sieve proposed in <ref type="bibr">[5]</ref>, which uses a confidence regularizer to avoid At Line 5, if the loss adjusted by ? n,t is small enough (smaller than the threshold L min ), we assume? n is the Bayes optimal label. Accordingly, at Line 7, if the adjusted loss is too large (larger than the threshold L max ), we treat y n as a corrupted one and assume the class with maximum predicted probability to be Bayes optimal one. For the examples with moderate adjusted loss, we drop it as indicated in Line 9. In ideal cases with infinite model capacity and sufficiently many examples (as assumed in [5]), we can set thresholds L min = L max = 0 to guarantee a separation of clean and corrupted examples, thusD will be an unbiased proxy to D * 2 . However, in real experiments, when both the model capacity and the number of examples are limited, we may need to tune L min and L max to obtain a high-quality construction ofD. In this paper, we set L min = L max to ensure |D| = |D * | and reduce the effort to tuning both thresholds simultaneously.</p><p>Note that usingD to estimate the covariance terms could be made theoretically more rigorous by applying appropriate re-weighting techniques <ref type="bibr">[6,</ref><ref type="bibr">7,</ref><ref type="bibr">14]</ref>. See Appendix D.1 for more discussions and corresponding guarantees. We omit the details here due to the space limit. Nonetheless, our approach is tolerant of an imperfectD, which will be shown theoretically in Section 4.3. <ref type="bibr">2</ref> In the ideal case as assumed in Corollary 1 of [5], we haveD = D * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Implementations</head><p>For implementations with deep neural network solutions, we need to estimate the transition matrix T (X) relying on D and estimate the covariance terms along with stochastic gradient descent (SGD) updates. Covariance Estimation in SGD As required in (3), with a particularD, each computation forT i,j (x n ) requires only one time check of the associated noisy label as follows:</p><formula xml:id="formula_21">T i,j (x n ) = 1{? n = i,? n = j}.<label>(4)</label></formula><p>WhenD is unbiased w.r.t. D * , the estimation in (4) is also unbiased because</p><formula xml:id="formula_22">E D|X,? =i [T i,j (X)] = E D|X,? =i [1{? = i, Y = j|X}] =P( Y = j|X,? = i) = P( Y = j|X, Y * = i). Noting Cov D (A, B) := E[(A ? E[A])(B ? E[B])] = E[(A ? E[A]) ? B]</formula><p>, the covariance can be estimated empirically as </p><formula xml:id="formula_23">1 N n?[N ] i,j?[K] 1{y * n = i} (T i,j (x n ) ?T i,j ) ? ?(f (x n ), j) .</formula><formula xml:id="formula_24">? CAL (f (x n ),? n ) = ? PL (f (x n ),? n ) ? i,j?[K] 1{y * n = i} (T i,j (x n ) ?T i,j ) ? ?(f (x n ), j) .</formula><p>With the above implementation, the estimation is done locally for each point in O(1) complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">CAL with Imperfect Covariance Estimates</head><p>As mentioned earlier, D * cannot be perfectly obtained in practice. Thus, there is a performance gap between the ideal case (with perfect knowledge of D * ) and the actually achieved one. We now analyze the effect of imperfect covariance terms (Theorem 4).</p><p>Denote the imperfect covariance estimates byD ? , where ? ? [0, 1] is the expected ratio (a.k.a. probability) of correct examples inD ? : ? = E[1{(X,? ) ?D ? |(X, Y * ) ? D * }] = P((X,? ) ?D ? |(X, Y * ) ? D * ). WithD ? , the minimizer of the 0-1 CAL loss is given by:</p><formula xml:id="formula_25">f * CAL-? =arg min f E D 1PL(f (X), Y )]?CovD? (Z1(X), 1(f (X),? ))</formula><p>? CovD? (Z2(X), 1(f (X), ?1)) .</p><p>Theorem 4 reports the error bound produced byf * CAL-? . See Appendix B.4 for the proof.</p><p>Theorem 4 (Imperfect Covariance). WithD ? , when p * = 0.5, we have</p><formula xml:id="formula_26">E[1(f * CAL-? (X), Y * )] ? 4(1 ? ? )(? + + ? ? ) 1 ? e + ? e ? .</formula><p>Theorem 4 shows the quality ofD ? controls the scale of the worst-case error upper-bound. Compared with Theorem 1 where no covariance term is used, we know the covariance terms will always be helpful when ? ? [0.5, 1]. That is, the training with the assistance of covariance terms will achieve better (worst-case) accuracy on the Bayes optimal distribution when the constructionD ? is better than a dataset that includes each instance in D * randomly with 50% chance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We now present our experiment setups and results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">General Experiment Settings</head><p>Datasets and models The advantage of introducing our second-order approach is evaluated on three benchmark datasets: CIFAR10, CIFAR100 [17] and Clothing1M <ref type="bibr" target="#b8">[42]</ref>. Following the convention from [5, 43], we use ResNet34 for CIFAR10 and CIFAR100 and ResNet50 for Clothing1M. Noting the expected peer term E D Y | D [?(f (x n ), Y )] (a.k.a. confidence regularizer (CR) as implemented in [5]) is more stable and converges faster than the one with peer samples, we train with ? CORES 2 . It also enables a fair ablation study sinceD is constructed relying on [5]. For numerical stability, we use a cut-off version of the crossentropy loss ?(f (x), y) = ? ln(f x [y] + ?). Specifically, we use ? = 10 ?8 for the traditional cross-entropy term, use ? = 10 ?5 for the CR term, and the covariance term. All the experiments use a momentum of 0.9. The weight decay is set as 0.0005 for CIFAR experiments and 0.001 for Clothing1M. Noise type For CIFAR datasets, the instance-dependent label noise is generated following the method from <ref type="bibr">[5,</ref><ref type="bibr" target="#b6">40]</ref>. The basic idea is randomly generating one vector for each class (K vectors in total) and project each incoming feature onto these K vectors. The label noise is added by jointly considering the clean label and the projection results. See Appendix D.2 for details. In expectation, the noise rate ? is the overall ratio of examples with a wrong label in the entire dataset. For the Clothing1M dataset, we train on 1 million noisy training examples that encode the real-world human noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Baselines</head><p>We compare our method with several related works, where the cross-entropy loss is tested as a common baseline. Additionally, the generalized cross-entropy [50] is compared as a generalization of mean absolute error and cross-entropy designed for label noise. Popular loss correction based methods [29, <ref type="bibr" target="#b6">40,</ref><ref type="bibr" target="#b7">41]</ref>, sample selection based methods [5, 12, 37, 46], and noise-robust loss functions <ref type="bibr">[24,</ref><ref type="bibr" target="#b9">43]</ref> are also chosen for comparisons. All the compared methods adopt similar data augmentations, including standard random crop, random flip, and normalization. Note the recent work on part-dependent label noise <ref type="bibr" target="#b6">[40]</ref> did not apply random crop and flip on the CIFAR dataset. For a fair comparison with <ref type="bibr" target="#b6">[40]</ref>, we remove the corresponding data augmentations from our approach and defer the comparison to Appendix D.3. The semi-supervised learning based methods with extra feature-extraction and data augmentations are not included. All the CIFAR experiments are repeated 5 times with independently synthesized IDN. The highest accuracies on the clean testing dataset are averaged over 5 trials to show the best generalization ability of each method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Performance Comparisons</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">CIFAR</head><p>In experiments on CIFAR datasets, we use a batch size of 128, an initial learning rate of 0.1, and reduce it by a factor of 10 at epoch 60.</p><p>ConstructD To constructD, we update the DNN for 65 epochs by minimizing ? CORES 2 (without dynamic sample sieve) and apply Algorithm 1 with L min = L max = ?8. 3 For a numerically stable solution, we use the square root of the noise prior for the CR term in ? CORES 2 as</p><formula xml:id="formula_27">?? i?[K] ? P( Y =i| D) K j=1 ? P( Y =j| D)</formula><p>?(f (x n ), i). The hyperparameter ? is set to 2 for CIFAR10 and 10 for CIFAR100. Train with CAL With an estimate of D * , we re-train the model 100 epochs. The hyper-parameter ? is set to 1 for CIFAR10 and 10 for CIFAR100. Note the hyperparameters (L min , L max , ?) can be better set if a clean validation set is available.</p><p>Performance <ref type="table" target="#tab_0">Table 1</ref> compares the means and standard deviations of test accuracies on the clean test dataset when the model is trained with synthesized instance-dependent label noise in different levels. All the compared methods use ResNet34 as the backbone. On CIFAR10, with a low-level label noise (? = 0.2), all the compared methods perform well and achieve higher average test accuracies than the standard CE loss. When the overall noise rates increase to high, most of the methods suffer from severe performance degradation while CAL still achieves the best performance. There are similar observations on CI-FAR100. By comparing CAL with CORES 2 , we conclude that the adopted second-order statistics do work well and bring non-trivial performance improvement. Besides, on the CIFAR100 dataset with ? = 0.4 and 0.6, we observe Reweight-R <ref type="bibr" target="#b7">[41]</ref> has a large standard deviation and a relatively high mean, indicating it may perform as well as or even better than CAL in some trials. It also shows the potential of using a revised transition matrix T <ref type="bibr" target="#b7">[41]</ref> in severe and challenging instance-dependent label noise settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Clothing1M</head><p>For Clothing1M, we first train the model following the settings in [5] and constructD with the best model. Noting the overall accuracy of noisy labels in Clothing1M is about 61.54% <ref type="bibr" target="#b8">[42]</ref>, we set an appropriate L min = L max such that 61.54% of training examples satisfying ? CORES 2 ? ? n,t ? L min . WithD, we sample a class-balanced dataset by randomly choosing 18, 976 noisy examples for each class and continue training the model with ? = 1 and an initial learning rate of 10 ?5 for 120 epochs. Other parameters are set following <ref type="bibr">[5]</ref>. See Appendix D.4 for more detailed experimental settings. <ref type="table" target="#tab_1">Table 2</ref> shows CAL performs well in the real-world human noise. <ref type="table" target="#tab_2">Table 3</ref> shows either the covariance term or the peer term can work well individually and significantly improve the performance when they work jointly. Comparing the first row with the second row, we find the second-order statistics can work well (except for ? = 0.4) even without the peer (CR) term. In row 4, we show the performance at epoch 65 since the second-order statistics are estimated relying on the model prediction at this epoch. By comparing row 4 with row 5, we know the second-order statistics indeed lead to non-trivial improvement in the performance. Even though the covariance term individually can only achieve an accu- 69.21 JoCoR <ref type="bibr" target="#b3">[37]</ref> 70.30 L DMI <ref type="bibr" target="#b9">[43]</ref> 72.46 PTD-R-V <ref type="bibr" target="#b6">[40]</ref> 71.67 CORES 2 <ref type="bibr">[5]</ref> 73.24 CAL 74.17 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Ablation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>This paper has proposed a second-order approach to transforming the challenging instance-dependent label noise into a class-dependent one such that existing methods targeting the class-dependent label noise could be implemented. Currently, the necessary information for the covariance term is estimated based on a sample selection method. Future directions of this work include extensions to other methods for estimating the covariance terms accurately. We are also interested in exploring the combination of secondorder information with other robust learning techniques. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><formula xml:id="formula_28">?E D * 1(f * peer (X), Y * ) ? p * ? E X [1(f * peer (X), +1)] ? (1 ? p * ) ? E X [1(f * peer (X), ?1)] + |p * ? 0.5| + 0.5 + Cov(Z 1 (X), 1(f * peer (X), Y * )) + Cov(Z 2 (X), 1(f * peer (X), ?1)) 1 ? e + ? e ? ?E D * [1(f * (X), Y * )] ? p * ? E X [1(f * (X), +1)] ? (1 ? p * ) ? E X [1(f * (X), ?1)] + |p * ? 0.5| + 0.5 + Cov(Z 1 (X), 1(f * (X), Y * )) + Cov(Z 2 (X), 1(f * (X), ?1)) 1 ? e + ? e ? ?E D * [1(f * (X), Y * )] + Cov(Z 1 (X), 1(f * (X), Y * )) + Cov(Z 2 (X), 1(f * (X), ?1)) 1 ? e + ? e ? + 2|p * ? 0.5|. Thus E D * 1(f * peer (X), Y * ) ? 1(f * (X), Y * ) ? Cov(Z 1 (X), 1(f * (X), Y * ) ? 1(f * peer (X), Y * )) + Cov(Z 2 (X), 1(f * (X), ?1) ? 1(f * peer (X), ?1)) 1 ? e + ? e ? + 2|p * ? 0.5| ?2 E|e + (X) ? E[e + (X)]| + E|e ? (X) ? E[e ? (X)]| 1 ? e + ? e ? + 2|p * ? 0.5| ? 2(? + + ? ? ) 1 ? e + ? e ? + 2|p * ? 0.5|.</formula><p>Noting 1(f * (X), Y * ) = 0, we finish the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Proof for Theorem 2</head><p>Proof. The covariance Cov(?, ?) in this proof is taken over the Bayes optimal distribution D * . Recall We first have the following equality:</p><formula xml:id="formula_29">E D [1 PL (f (X),? )] = E D * [(1 ? e + (X) ? e ? (X))1(f (X), Y * ))] (Term-A) + E X [e + (X)1(f (X), ?1) + e ? (X)1(f (X), +1)] (Term-B) ? (1 ? e + ? e ? ) ? E D * [1(f (X), Y * p ))] (Term-C)</formula><p>Similarly,</p><formula xml:id="formula_30">Cov D * (Z 1 (X), 1(f (X), Y )) = E D * [(Z 1 (X) ? E D * [Z 1 (X)]) 1(f (X), Y )] = P((X, Y ) ?D ? |(X, Y ) ? D * )E D * (Z 1 (X) ? E D * [Z 1 (X)]) 1(f (X), Y )|(X, Y ) ?D ? + P((X, Y ) / ?D ? |(X, Y ) ? D * )E D * (Z 1 (X) ? E D * [Z 1 (X)]) 1(f (X), Y )|(X, Y ) / ?D ? .</formula><p>When D * ,D ? andD have the same feature set, we have</p><formula xml:id="formula_31">P((X, Y ) ? D * |(X, Y ) ?D ? ) = P((X, Y ) ?D ? |(X, Y ) ? D * ) = ?, P((X, Y ) / ? D * |(X, Y ) ?D ? ) = P((X, Y ) / ?D ? |(X, Y ) ? D * ) = 1 ? ?.</formula><p>Therefore,</p><formula xml:id="formula_32">CovD ? (Z 1 (X), 1(f (X), Y )) ? Cov D * (Z 1 (X), 1(f (X), Y )) ? 2(1 ? ? )(? + + ? ? ).</formula><p>The rest of the proof can be accomplished by following the proof of Theorem 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Proof for Corollaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Proof for Corollary 1</head><p>Proof.</p><formula xml:id="formula_33">E D [? PL (f (X), Y )] = E D [?(f (X), Y )] ? E DY E DX [?(f (X p ), Y p )] .<label>(5)</label></formula><p>The first term in <ref type="formula" target="#formula_33">(5)</ref> is</p><formula xml:id="formula_34">E D [?(f (X), Y )] =E D * ? ? j?[K] P( Y = j|X, Y * )?(f (X), j) ? ? = j?[K] i?[K] P(Y * = i)E D * |Y * =i [T ij (X)?(f (X), j)] = j?[K] i?[K] P(Y * = i) T ij E D * |Y * =i [?(f (X), j)] + Cov D * |Y * =i [T ij (X), ?(f (X), j)] = j?[K] ? ? P(Y * = j) ? ? 1 ? i =j,i?[K] T ji ? ? E D * |Y * =j [?(f (X), j)] + i?[K],i =j P(Y * = i)T ij E D * |Y * =i [?(f (X), j)] ? ? + j?[K] i?[K] P (Y * = i)Cov D * |Y * =i [T ij (X), ?(f (X), j)] = j?[K] ? ? P(Y * = j) ? ? 1 ? i =j,i?[K] e i ? ? E D * |Y * =j [?(f (X), j)] + i?[K],i =j P(Y * = i)e j E D * |Y * =i [?(f (X), j)] ? ? + j?[K] i?[K] P (Y * = i)Cov D * |Y * =i [T ij (X), ?(f (X), j)] = ? ? 1 ? i?[K] e i ? ? E D * [?(f (X), Y * )] + j?[K] i?[K] P(Y * = i)e j E D * |Y * =i [?(f (X), j)] + j?[K] i?[K] P (Y * = i)Cov D * |Y * =i [T ij (X), ?(f (X), j)]</formula><p>The rest of proofs can be done following standard multi-class peer loss derivations [24].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. More Discussions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1. Setting Thresholds L min and L max</head><p>In a high level, there are two strategies for setting L min and L max : 1) L min &lt; L max and 2) L min = L max .</p><p>Strategy-1: L min &lt; L max : This strategy may provide a higher ratio of true Bayes optimal labels among feasible examples inD since some ambiguous examples are dropped. However, dropping examples changes the distribution of X (as well as the distribution of the unobservable Y * ), a.k.a. covariate shift <ref type="bibr">[14,</ref><ref type="bibr">6]</ref>. Importance re-weighting with weight ?(X) is necessary for correcting the covariate shift, i.e. the weight of each feasible example (x,?) ?D should be changed from 1 to ?(x). Let D X andD X be the marginal distributions of D andD on X. With a particular kernel ?(X), the optimization problem is:</p><formula xml:id="formula_35">min ?(X) E DX [?(X)] ? ED X [?(X)?(X)] s.t.</formula><p>?(X) &gt; 0 and ED X [?(X)] = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(6)</head><p>The optimal solution is supposed to be ? * (X) = PD X (X) PD X (X) . Note the selection of kernel ?(?) is non-trivial, especially for complicated features [7] in DNN solutions. Using this strategy, with appropriate L min and L max such that all the examples inD are Bayes optimal, the covariance could be guaranteed to be optimal when each example inD is re-weighted by ? * (X).</p><p>Strategy-2: L min = L max : Compared with Strategy-1, we effectively lose one degree of freedom for getting a betterD. However, this is not entirely harmful sinceD and D * have the same feature set, indicating estimating ?(X) is no longer necessary and ?(X) = 1 is an optimal solution for (6) with this strategy.</p><p>Strategy selection When we can get a high-qualityD by fine-tuning L min and L max orD is already provided from other sources, we may solve the optimization problem in (6) to find the optimal weight ?(X). However, considering the fact that estimating ?(X) introduces extra computation and potentially extra errors, we focus on Strategy-2 in this paper. Using Strategy-2 also reduces the effort on tuning hyperparameters. Besides, the proposed CAL loss is tolerant of an imperfectD (shown theoretically in Section 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. Generation of Instance-Dependent Label Noise</head><p>Pseudo codes for generate instance-based label noise are provided in Algorithm 2. This algorithm follows the state-ofthe-art method <ref type="bibr" target="#b6">[40]</ref>. Define the overall noise rate as ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2: Generating Instance-Dependent Label Noise</head><p>Input: Clean examples (x n , y n ) N n=1 ; Noise rate: ?; Number of classes: K; Shape of each feature x n : S ? 1. 1 Sample instance flip rates q n from the truncated normal distribution N (?, 0.1 2 , [0, 1]); // mean ?, variance 0.1 2 , range [0, 1] 2 Sample W ? R S?K from the standard normal distribution N (0, 1 2 ); 3 for n ? [N ] do 4 p = x ? n W // Generate instance dependent flip rates. The size of p is 1 ? K. Note Algorithm 2 cannot ensure T ii (X) &gt; T ij (X) when ? &gt; 0.5. To generate an informative dataset, we set 0.9 ? T ii (X) as the upper bound of T ij (X) and distribute the remaining probability to other classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3. Performance without Data Augmentations</head><p>For a fair comparison with the recent work on instance-dependent label noise <ref type="bibr" target="#b6">[40]</ref>, we adopt the same data augmentations as <ref type="bibr" target="#b6">[40]</ref> and re-produce their results using the same noise file as we employed in <ref type="table" target="#tab_0">Table 1</ref>. Each noise rate is tested 5 times with a different generation matrix W (defined in Algorithm 2). <ref type="table" target="#tab_4">Table 4</ref> shows the advantages of our second-order approach. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4. More Implementation Details on Clothing1M</head><p>ConstructD We first train the network for 120 epochs on 1 million noisy training images using the method in <ref type="bibr">[5]</ref>. The batch-size is set to 32. The initial learning rate is set as 0.01 and reduced by a factor of 10 at 30, 60, 90 epochs. We sample 1000 mini-batches from the training data for each epoch while ensuring the (noisy) labels are balanced. Mixup [48] is adopted for data augmentations. Hyperparameter ? is set to 0 at first 80 epochs, and linearly increased to 0.4 for next 20 epochs and kept as 0.4 for the rest of the epochs. We constructD with the best model.</p><p>Train with CAL We change the loss to the CAL loss after gettingD and continue training the model (without mixup) with an initial learning rate of 10 ?5 for 120 epochs (reduced by a factor of 10 at 30, 60, 90 epochs). We also tested re-train the model withD and get an accuracy of 73.56. A randomly-collected balanced dataset with 18, 976 noisy examples in each class is employed in training with CAL. Examples that are not in this balanced dataset are removed fromD for ease of implementation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Recall e + := E[e + (X)] and e ? := E[e ? (X)]. Let Cov D (A, B) := E[(A?E[A])(B?E[B])] be the covariance between random variables A and B w.r.t. the distribution D. The exact effects of IDN on peer loss functions are revealed in Theorem 2 and proved in Appendix B.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 :</head><label>1</label><figDesc>ConstructingD Input: Noisy dataset D. Thresholds L min ? L max . Number of epochs T .D = D. 1 Train the sample sieve in [5] for T epochs and get the model f ; 2 for n ? [N ] do 3 Calculate ? n,T following [5];4 if ? CORES 2 (f (x n ),? n ) ? ? n,T ? L min then 5? n =? n ; 6 else if ? CORES 2 (f (x n ),? n ) ? ? n,T &gt; L max then 7? n = arg max y?[K] f xn [y]; 8 else 9? n = ?1 (drop example n); 10 end Output:D := {(x n ,? n ) : n ? [N ],? n = ?1}overfitting, to constructD. Specifically, as shown in [5], in each epoch t, the regularized loss for each example is adjusted by the parameter ? n,t , which can be calculated based on model predictions in linear time. In the ideal cases assumed in [5], any example with a positive adjusted loss is corrupted (with a wrong label). We summarized the corresponding procedures in Algorithm 1, where the critical thresholds for comparing losses are denoted by L min and L max .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>For each batch of</head><label></label><figDesc>data, the above estimation has O(N ) complexities in computation and space. To reduce both complexities, with the cost of the estimation quality, we use |E b | examples to estimate the covariance in each batch, where E b is the set of sample indices of batch-b. Per sample wise, Eq. (3) can be transformed to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>e</head><label></label><figDesc>+ (X) := P( Y = ?1|Y * = +1, X), e ? (X) := P( Y = +1|Y * = ?1, X) and e + := E X [e + (X)], e ? := E X [e ? (X)]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>5p</head><label></label><figDesc>yn = ?? // Only consider entries that are different from the true label 6 p = q n ? softmax(p) // Let qn be the probability of getting a wrong label 7 p yn = 1 ? q n // Keep clean w.p. 1 ? qn 8 Randomly choose a label from the label space as noisy label? n according to p; 9 end Output: Noisy examples {(x i ,? n ), n ? [N ]}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of test accuracies (%) using different methods. 45?0.57 76.23?1.54 59.75?1.30 57.79?1.25 41.15?0.83 25.68?1.55 Forward T [29] 87.22?1.60 79.37?2.72 66.56?4.90 58.19?1.37 42.80?1.01 27.91?3.35 L DMI [43] 88.57?0.60 82.82?1.49 69.94?1.31 57.90?1.21 42.70?0.92 26.96?2.08 L q [50] 85.81?0.83 74.66?1.12 60.76?3.08 57.03?0.27 39.81?1.18 24.87?2.46 Co-teaching [12] 88.87?0.24 73.00?1.24 62.51?1.98 43.30?0.39 23.21?0.57 12.58?0.51 Co-teaching+ [46] 89.80?0.28 73.78?1.39 59.22?6.34 41.71?0.78 24.45?0.71 12.58?0.51 JoCoR [37] 88.78?0.15 71.64?3.09 63.46?1.58 43.66?1.32 23.95?0.44 13.16?0.91 Reweight-R [41] 90.04?0.46 84.11?2.47 72.18?2.47 58.00?0.36 43.83?8.42 36.07?9.73 Peer Loss [24] 89.12?0.76 83.26?0.42 74.53?1.22 61.16?0.64 47.23?1.23 31.71?2.06 CORES 2 [5] 91.14?0.46 83.67?1.29 77.68?2.24 66.47?0.45 58.99?1.49 38.55?3.25 CAL 92.01?0.75 84.96?1.25 79.82?2.56 69.11?0.46 63.17?1.40 43.58?3.30</figDesc><table><row><cell>Method</cell><cell>? = 0.2</cell><cell>Inst. CIFAR10 ? = 0.4</cell><cell>? = 0.6</cell><cell>? = 0.2</cell><cell>Inst. CIFAR100 ? = 0.4</cell><cell>? = 0.6</cell></row><row><cell>CE (Standard)</cell><cell>85.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>The best epoch (clean) test accuracies on Clothing1M.</figDesc><table><row><cell>Method</cell><cell>Accuracy</cell></row><row><cell>CE (standard)</cell><cell>68.94</cell></row><row><cell>Forward T [29]</cell><cell>70.83</cell></row><row><cell>Co-teaching [12]</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Analysis of each component of CAL on CIFAR10. The result of a particular trial is presented. Cov.: the covariance term. it can still contribute more than 1% of the performance improvement (from 84.41% to 85.55%) when it is implemented with the peer term. This observation shows the robustness of CAL.</figDesc><table><row><cell cols="3">row # Cov. Peer</cell><cell>Epoch</cell><cell cols="3">? = 0.2 ? = 0.4 ? = 0.6</cell></row><row><cell>1</cell><cell>?</cell><cell>?</cell><cell>Best</cell><cell>90.47</cell><cell>82.56</cell><cell>64.65</cell></row><row><cell>2</cell><cell>?</cell><cell>?</cell><cell>Best</cell><cell>92.10</cell><cell>78.49</cell><cell>73.55</cell></row><row><cell>3</cell><cell>?</cell><cell>?</cell><cell>Best</cell><cell>91.85</cell><cell>84.41</cell><cell>78.74</cell></row><row><cell>4</cell><cell>?</cell><cell>?</cell><cell>Fixed@65</cell><cell>90.73</cell><cell>82.76</cell><cell>77.70</cell></row><row><cell>5</cell><cell>?</cell><cell>?</cell><cell>Best</cell><cell>92.69</cell><cell>85.55</cell><cell>81.54</cell></row><row><cell cols="4">racy of 78.49 when ? = 0.4,</cell><cell></cell><cell></cell><cell></cell></row></table><note>Peer: the CR term [5] (a.k.a. expected peer term [24]).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>[ 1 ]</head><label>1</label><figDesc>Ehsan Amid, Manfred KK Warmuth, Rohan Anil, and Tomer Koren. Robust bi-tempered logistic loss based on bregman divergences. In Advances in Neural In-</figDesc><table><row><cell>[22] Tongliang Liu and Dacheng Tao. Classification with [44] Quanming Yao, Hansi Yang, Bo Han, Gang Niu, and</cell><cell>[11] Bo Han, Quanming Yao, Tongliang Liu, Gang Vision and Pattern Recognition, pages 839-847, 2017.</cell></row><row><cell>noisy labels by importance reweighting. IEEE Trans-James T Kwok. Searching to exploit memorization</cell><cell>Niu, Ivor W Tsang, James T Kwok, and Masashi 2</cell></row><row><cell>actions on pattern analysis and machine intelligence, effect in learning with noisy labels. In Proceedings of</cell><cell>Sugiyama. A survey of label-noise representation</cell></row><row><cell>38(3):447-461, 2015. 2 the 37th International Conference on Machine Learn-</cell><cell>learning: Past, present and future. arXiv preprint</cell></row><row><cell>[23] Yang Liu. The importance of understanding instance-ing, ICML '20, 2020. 2, 5 formation Processing Systems, pages 14987-14996, level noisy labels, 2021. 1 [45] Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, 2019. 2 [2] Ehsan Amid, Manfred K Warmuth, and Sriram Srini-vasan. Two-temperature logistic regression based on the tsallis divergence. In The 22nd International Con-ference on Artificial Intelligence and Statistics, pages Jiankang Deng, Gang Niu, and Masashi Sugiyama. [24] Yang Liu and Hongyi Guo. Peer loss functions: Learn-Dual T: Reducing estimation error for transition ma-ing from noisy labels without knowing noise rates. In trix in label-noise learning. In Advances in Neural Proceedings of the 37th International Conference on Information Processing Systems, volume 33, pages Machine Learning, ICML '20, 2020. 1, 2, 3, 4, 5, 7, 8, 12, 16 7260-7271, 2020. 2 2388-2396. PMLR, 2019. 2 [3] Peter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds. Journal of the American Statistical Association, [46] Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, [25] Philip M Long and Rocco A Servedio. Random clas-Ivor W Tsang, and Masashi Sugiyama. How does sification noise defeats all convex potential boosters. disagreement help generalization against label corrup-Machine learning, 78(3):287-304, 2010. 2 tion? arXiv preprint arXiv:1901.04215, 2019. 2, 7,</cell><cell>arXiv:2011.04406, 2020. 1 [12] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. In Advances in neu-ral information processing systems, pages 8527-8537, 2018. 2, 7, 8 [13] Jiangfan Han, Ping Luo, and Xiaogang Wang. Deep self-learning from noisy labels. In Proceedings of the IEEE International Conference on Computer Vision, pages 5138-5147, 2019. 2, 5</cell></row><row><cell>101(473):138-156, 2006. 3 [4] Antonin Berthon, Bo Han, Gang Niu, Tongliang Liu, and Masashi Sugiyama. Confidence scores [26] Naresh Manwani and PS Sastry. Noise tolerance under 8 risk minimization. IEEE transactions on cybernetics, [47] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Ben-43(3):1146-1151, 2013. 2 jamin Recht, and Oriol Vinyals. Understanding deep</cell><cell>[14] Jiayuan Huang, Arthur Gretton, Karsten Borgwardt, Bernhard Sch?lkopf, and Alex J Smola. Correcting sample selection bias by unlabeled data. In Advances</cell></row><row><cell>make instance-dependent label-noise learning possi-[27] Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K learning requires rethinking generalization. arXiv</cell><cell>in neural information processing systems, pages 601-</cell></row><row><cell>ble. arXiv preprint arXiv:2001.03772, 2020. 2 Ravikumar, and Ambuj Tewari. Learning with noisy preprint arXiv:1611.03530, 2016. 1</cell><cell>608, 2007. 6, 17</cell></row><row><cell>[5] Hao Cheng, Zhaowei Zhu, Xingyu Li, Yifei Gong, Xing Sun, and Yang Liu. Learning with instance-labels. In Advances in neural information processing [48] Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, systems, pages 1196-1204, 2013. 1, 2, 3 and David Lopez-Paz. mixup: Beyond empirical risk</cell><cell>[15] Lu Jiang, Di Huang, Mason Liu, and Weilong Yang. Beyond synthetic noise: Deep learning on controlled</cell></row><row><cell>dependent label noise: A sample sieve approach. [28] Duc Tam Nguyen, Chaithanya Kumar Mummadi, Thi minimization. In International Conference on Learn-</cell><cell>noisy labels. In Proceedings of the 37th International</cell></row><row><cell>In International Conference on Learning Representa-Phuong Nhung Ngo, Thi Hoai Phuong Nguyen, Laura ing Representations, 2018. 18</cell><cell>Conference on Machine Learning, volume 119, pages</cell></row><row><cell>tions, 2021. 1, 2, 3, 4, 5, 6, 7, 8, 18 [6] Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamo-hanarao, and Dacheng Tao. Learning with bounded Beggel, and Thomas Brox. Self: Learning to filter [49] Yivan Zhang, Gang Niu, and Masashi Sugiyama. noisy labels with self-ensembling. In International Learning noise transition matrix from only noisy la-Conference on Learning Representations, 2020. 2 bels via total variation regularization. arXiv preprint</cell><cell>4804-4815. PMLR, 13-18 Jul 2020. 1 [16] Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. Mentornet: Learning data-driven cur-</cell></row><row><cell>instance-and label-dependent label noise. In Proceed-[29] Giorgio Patrini, Alessandro Rozza, Aditya Kr-arXiv:2102.02414, 2021. 2</cell><cell>riculum for very deep neural networks on corrupted la-</cell></row><row><cell>ings of the 37th International Conference on Machine ishna Menon, Richard Nock, and Lizhen Qu. Mak-[50] Zhilu Zhang and Mert Sabuncu. Generalized cross en-</cell><cell>bels. In International Conference on Machine Learn-</cell></row><row><cell>Learning, ICML '20, 2020. 2, 5, 6, 17 ing deep neural networks robust to label noise: A loss tropy loss for training deep neural networks with noisy</cell><cell>ing, pages 2304-2313. PMLR, 2018. 2</cell></row><row><cell>[7] Tongtong Fang, Nan Lu, Gang Niu, and Masashi Sugiyama. Rethinking importance weighting for deep learning under distribution shift. In H. Larochelle, M. correction approach. In Proceedings of the IEEE Con-labels. In Advances in neural information processing ference on Computer Vision and Pattern Recognition, systems, pages 8778-8788, 2018. 2, 7, 8 pages 1944-1952, 2017. 1, 2, 7, 8 [51] Zhaowei Zhu, Yiwen Song, and Yang Liu. Cluster-</cell><cell>[17] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. Tech-nical report, Citeseer, 2009. 7</cell></row><row><cell>Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, [30] Giorgio Patrini, Alessandro Rozza, Aditya Kr-ability as an alternative to anchor points when learning</cell><cell>[18] Kuang-Huei Lee, Xiaodong He, Lei Zhang, and Lin-</cell></row><row><cell>Advances in Neural Information Processing Systems, ishna Menon, Richard Nock, and Lizhen Qu. Making with noisy labels. arXiv preprint arXiv:2102.05291,</cell><cell>jun Yang. Cleannet: Transfer learning for scalable im-</cell></row><row><cell>volume 33, pages 11996-12007. Curran Associates, deep neural networks robust to label noise: A loss cor-2021. 2</cell><cell>age classifier training with label noise. In Proceedings</cell></row><row><cell>Inc., 2020. 6, 17 rection approach. In The IEEE Conference on Com-</cell><cell>of the IEEE Conference on Computer Vision and Pat-</cell></row><row><cell>puter Vision and Pattern Recognition (CVPR), July [8] Aritra Ghosh, Himanshu Kumar, and PS Sastry. Ro-bust loss functions under label noise for deep neural 2017. 2, 5</cell><cell>tern Recognition, pages 5447-5456, 2018. 2 [19] Junnan Li, Richard Socher, and Steven C.H. Hoi.</cell></row><row><cell>networks. In Thirty-First AAAI Conference on Artifi-[31] Jun Shu, Qian Zhao, Keyu Chen, Zongben Xu, and</cell><cell>Dividemix: Learning with noisy labels as semi-</cell></row><row><cell>cial Intelligence, 2017. 2 Deyu Meng. Learning adaptive loss for robust learning</cell><cell>supervised learning. In International Conference on</cell></row><row><cell>with noisy labels. arXiv preprint arXiv:2002.06482, [9] Maoguo Gong, Hao Li, Deyu Meng, Qiguang Miao, and Jia Liu. Decomposition-based evolutionary 2020. 2</cell><cell>Learning Representations, 2020. 2 [20] Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu,</cell></row><row><cell>multiobjective optimization to self-paced learning. [32] Arash Vahdat. Toward robustness against label noise</cell><cell>and Masashi Sugiyama. Provably end-to-end label-</cell></row><row><cell>IEEE Transactions on Evolutionary Computation, in training deep discriminative neural networks. In</cell><cell>noise learning without anchor points. arXiv preprint</cell></row><row><cell>23(2):288-302, 2018. 2 Advances in Neural Information Processing Systems,</cell><cell>arXiv:2102.02400, 2021. 2</cell></row><row><cell>[10] Bo Han, Gang Niu, Xingrui Yu, Quanming Yao, Miao pages 5596-5605, 2017. 1</cell><cell>[21] Yuncheng Li, Jianchao Yang, Yale Song, Liangliang</cell></row><row><cell>Xu, Ivor Tsang, and Masashi Sugiyama. Sigua: For-[33] Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin,</cell><cell>Cao, Jiebo Luo, and Li-Jia Li. Learning from noisy</cell></row><row><cell>getting may make learning with noisy labels more ro-Abhinav Gupta, and Serge Belongie. Learning from</cell><cell>labels with distillation. In Proceedings of the IEEE</cell></row><row><cell>bust. In International Conference on Machine Learn-noisy large-scale datasets with minimal supervision.</cell><cell>International Conference on Computer Vision, pages</cell></row><row><cell>ing, pages 4006-4016. PMLR, 2020. 1 In Proceedings of the IEEE Conference on Computer</cell><cell>1910-1918, 2017. 2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Performance comparisons without data augmentations PTD-R-V[40] 69.62 ? 3.35 64.73 ? 3.64 CAL 75.52 ? 3.94 70.30 ? 2.96</figDesc><table><row><cell>Method</cell><cell>? = 0.2</cell><cell>? = 0.4</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We focus on the closed-set label noise, i.e. Y , Y , and Y * share the same space Y.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Theoretically, we have L min = Lmax = 0 if both the CE term and the CR term use a log loss without cut-off (? = 0). Current setting works well (not the best) for CIFAR experiments empirically.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Peer Loss on the Bayes Optimal Distribution Recall our goal is to learn a classifier f from the noisy distribution D which also minimizes the loss on the corresponding Bayes optimal distribution D * , i.e. E[1(f (X), Y * )], (X, Y * ) ? D * . Before considering the case with label noise, we need to prove peer loss functions induce the Bayes optimal classifier when minimizing the 0-1 loss on D * as in Lemma 2.Lemma 2. Given the Bayes optimal distribution D * , the optimal peer classifier defined below:f * peer = arg min f E D * [1 PL (f (X), Y * )] also minimizes E D * [1(f (X), Y * )].See the proof below. It has been shown in [24] that Lemma 2 holds for the clean distribution D when the clean dataset is class-balanced, i.e. P(Y = ?1) = P(Y = +1) = 0.5. For the Bayes optimal distribution D * , as shown in Lemma 2, there is no requirement for the prior p * := P(Y * = +1).Proof. Recall Y * is the Bayes optimal label defined asY * |X := arg max Y P(Y |X), (X, Y ) ? D.We need to prove that the "optimal peer classifier" defined below:f * peer = arg min f E D * [1 PL (f (X), Y * )]is the same as the Bayes optimal classifier f * . To see this, suppose the claim is wrong. Denote by (notations ? + and ? ? are defined only for this proof):? + := P(f * peer (X) = ?1|f * (X) = +1), ? ? := P(f * peer (X) = +1|f * (X) = ?1) and denote by p * := P(f * (X) = +1). ThenE D * [1 PL (f * peer (X), Y * )] = P(f * peer (X) = Y * ) ? p * ? P(f * peer (X) = +1) ? (1 ? p * ) ? P(f * peer (X) = ?1) = p * ? ? + + (1 ? p * ) ? ? ? ? p * ? P(f * peer (X) = +1) ? (1 ? p * )? P(f * peer (X) = ?1) = p * ? ? + + (1 ? p * ) ? ? ? ? p * ? P(f * peer (X) = +1|f * (X) = +1)P(f * (X) = +1) + P(f *</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">f (1 ? e + ? e ? ) (E D * [1(f (X), Y * ) ? p * ? E D * [1(f (X), +1)] ? (1 ? p * ) ? E D * [1(f (X), ?1)]) + Cov(Z 1 (X), 1(f (X), Y * )) + Cov(Z 2 (X), 1(f (X), ?1)) . Then E D * 1(f * peer (X), Y * ) + Cov(Z 1 (X), 1(f * peer (X), Y * )) + Cov(Z 2 (X), 1(f * peer (X), ?1)) 1 ? e + ? e ? =E D * 1(f * peer (X), Y * ) ? 0.5 ? E X [1(f * peer (X), +1)] ? 0.5 ? E X [1(f * peer (X), ?1)] + 0.5 + Cov(Z 1 (X), 1(f * peer (X), Y * )) + Cov(Z 2 (X), 1(f * peer (X), ?1))</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Proof for Lemmas</head><p>A.1. Proof for Lemma 1 Proof. We try to build the connection between noisy distribution D and the underlying Bayes optimal distribution D * by the noise rates e + and e ? . The primary difference from the proof of Lemma 2 in [24] is the usage of D * . Note:</p><p>Similarly, following the proof of Lemma 2 in [24], we can prove this lemma.</p><p>contradicting the optimality of f * peer . Thus our claim is proved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proof for Theorems</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Proof for Theorem 1</head><p>Proof. The covariance Cov(?, ?) in this proof is taken over the Bayes optimal distribution D * . The following proof is built on the result of Theorem 2, i.e. Eq. (2). First note</p><p>Similarly, one can show that</p><p>Now with bounded variance in the error rates, suppose: = arg min</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tackling instance-dependent label noise via a universal probabilistic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.05467</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangchao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.09468</idno>
		<title level="m">Learning with group noise</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Symmetric cross entropy for robust learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaiyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="322" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combating noisy labels by agreement: A joint training method with co-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="13726" to="13735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Robust earlylearning: Hindering the memorization of noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongyuan</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Extended T: Learning with mixed closed-set and open-set noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinian</forename><surname>Mao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.00932</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Part-dependent label noise: Towards instance-dependent label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Are anchor points really indispensable in label-noise learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="6838" to="6849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">L_dmi: A novel information-theoretic loss function for training deep nets robust to label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
