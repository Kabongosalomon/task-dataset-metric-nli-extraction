<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structured Landmark Detection via Topology-Adapting Deep Graph Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijian</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">PAII. Inc</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<settlement>Rochester</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">PAII. Inc</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of South Carolina</orgName>
								<address>
									<settlement>Columbia</settlement>
									<region>SC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">PAII. Inc</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haofu</forename><surname>Liao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<settlement>Rochester</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chihung</forename><surname>Lin</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Chang Gung Memorial Hospital</orgName>
								<address>
									<settlement>Linkou</settlement>
									<country key="TW">Taiwan, ROC</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<settlement>Rochester</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Tung</forename><surname>Cheng</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Chang Gung Memorial Hospital</orgName>
								<address>
									<settlement>Linkou</settlement>
									<country key="TW">Taiwan, ROC</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Xiao</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Ping An Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">PAII. Inc</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Fu</forename><surname>Kuo</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Chang Gung Memorial Hospital</orgName>
								<address>
									<settlement>Linkou</settlement>
									<country key="TW">Taiwan, ROC</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shun</forename><surname>Miao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">PAII. Inc</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Structured Landmark Detection via Topology-Adapting Deep Graph Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Landmark Detection</term>
					<term>GCN</term>
					<term>Adaptive Topology</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Image landmark detection aims to automatically identify the locations of predefined fiducial points. Despite recent success in this field, higher-ordered structural modeling to capture implicit or explicit relationships among anatomical landmarks has not been adequately exploited. In this work, we present a new topology-adapting deep graph learning approach for accurate anatomical facial and medical (e.g., hand, pelvis) landmark detection. The proposed method constructs graph signals leveraging both local image features and global shape features. The adaptive graph topology naturally explores and lands on task-specific structures which are learned end-to-end with two Graph Convolutional Networks (GCNs). Extensive experiments are conducted on three public facial image datasets (WFLW, 300W, and COFW-68 ) as well as three real-world X-ray medical datasets (Cephalometric (public), Hand and Pelvis). Quantitative results comparing with the previous state-of-theart approaches across all studied datasets indicating the superior performance in both robustness and accuracy. Qualitative visualizations of the learned graph topologies demonstrate a physically plausible connectivity laying behind the landmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Image landmark detection has been a fundamental step for many high-level computer vision tasks to extract and distill important visual contents, such as image registration <ref type="bibr" target="#b22">[23]</ref>, pose estimation <ref type="bibr" target="#b3">[4]</ref>, identity recognition <ref type="bibr" target="#b76">[77]</ref> and image super-resolution <ref type="bibr" target="#b4">[5]</ref>. Robust and accurate landmark localization becomes a vital component determining the success of the downstream tasks.</p><p>Recently, heatmap regression based methods <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b54">55]</ref> have achieved encouraging performance on landmark detection. They model landmark locations as heatmaps and train deep neural networks to regress the heatmaps. Despite popularity and success, they usually suffer from a major drawback of lacking a arXiv:2004.08190v6 [cs.CV] 23 Jul 2020 global representation for the structure/shape, which provides high-level and reliable cues in individual anatomical landmark localization. As a result, heatmapbased methods could make substantial errors when being exposed to large appearance variations such as occlusions.</p><p>In contrast, coordinate regression based methods <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b53">54]</ref> have an innate potential to incorporate structural knowledge since the landmark coordinates are directly expressed. Most existing methods initialize landmark coordinates using mean or canonical shapes, which indirectly inject weak structural knowledge <ref type="bibr" target="#b53">[54]</ref>. While the exploitation of the structural knowledge in existing methods has still been insufficient as well as further exploitation of the structural knowledge considering the underlying relationships between the landmarks. Effective means for information exchange among landmarks to facilitate landmark detection are also important but have yet to be explored. Due to these limitations, the performance of the latest coordinate-based methods <ref type="bibr" target="#b62">[63]</ref> falls behind the heatmap-based ones <ref type="bibr" target="#b57">[58]</ref>.</p><p>In this work, we introduce a new topology-adapting deep graph learning approach for landmark detection, termed Deep Adaptive Graph (DAG). We model the landmarks as a graph and employ global-to-local cascaded Graph Convolutional Networks (GCNs) to move the landmarks towards the targets in multiple steps. Graph signals of the landmarks are built by combining local image features and graph shape features. Two GCNs operate in a cascaded manner, with the first GCN estimating a global transformation of the landmarks and the second GCN estimating local offsets to further adjust the landmark coordinates. The graph topology, represented by the connectivity weights between landmarks, are learned during the training phase.</p><p>By modeling landmarks as a graph and processing it with GCNs, our method is able to effectively exploit the structural knowledge and allow rich information exchange among landmarks for accurate coordinate estimation. The graph topology learned for landmark detection task is capable of revealing reasonable landmark relationships for the given task. It also reduces the need for manually defining landmark relations (or grouping), making our method to be easily adopted for different tasks. By incorporating shape features into graph signal in addition to the local image feature, our model can learn and exploit the landmark shape prior to achieve high robustness against large appearance variations (e.g., occlusions). In summary, our main contributions are four-fold:</p><p>1. By representing the landmarks as a graph and detecting them using GCNs, our method effectively exploits the structural knowledge for landmark coordinate regression, closes the performance gap between coordinate-and heatmap-based landmark detection methods. 2. Our method automatically reveals physically meaningful relationships among landmarks, leading to a task-agnostic solution for exploiting structural knowledge via step-wise graph transformations. 3. Our model combines both visual contextual information and spatial positional information into the graph signal, allowing structural shape prior to be learned and exploited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>Comprehensive quantitative evaluations and qualitative visualizations on six datasets across both facial and medical image domains demonstrate the consistent state-of-the-art performance and general applicability of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A large number of studies have been reported in this domain including the classic Active Shape Models <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b11">12]</ref>, Active Appearance Models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b32">33]</ref>, Constraind Local Models <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b30">31]</ref>, and more recently the deep learning based models which can be further categorized into heatmap or regression based models.</p><p>Heatmap Based Landmark Detection: These methods <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b9">10]</ref> generate localized predictions of likelihood heatmaps for each landmark and achieve encouraging performances. A preliminary work by Wei et al. <ref type="bibr" target="#b59">[60]</ref> introduce a Convolutional Pose Machine (CPM) which models the long-range dependency with a multistage network. Newell et al. <ref type="bibr" target="#b37">[38]</ref> propose a Stacked Hourglass model leveraging the repeated bottom-up and top-down structure and intermediate supervision. Tang et al. <ref type="bibr" target="#b50">[51]</ref> investigate a stacked U-Net structure with dense connections. Lately, Sun et al. <ref type="bibr" target="#b48">[49]</ref> present a deep model named High-Resolution Network (HRNet18) which extracts feature maps in a joint deep and high resolution manner via conducting multi-scale fusions across multiple branches under different resolutions. Based on these models, other methods also integrate additional supervision cues such as the object structure constraints <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b77">78]</ref>, the variety of image, and object styles <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b41">42]</ref> to solve specific tasks.</p><p>Coordinate Based Landmark Detection: Another common approach directly locates landmark coordinates from input images <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b47">48]</ref>. Most of these methods consist of multiple steps to progressively update predictions based on visual signals, widely known as Cascaded-Regression. Toshev et al. <ref type="bibr" target="#b52">[53]</ref> and Sun et al. <ref type="bibr" target="#b49">[50]</ref> adopt cascaded Convolutional Neural Networks (CNNs) to predict landmark coordinates. Trigeorgis et al. <ref type="bibr" target="#b53">[54]</ref> model the cascaded regression process using a Recurrent Neural Network (RNN) based deep structure. Lv et al. <ref type="bibr" target="#b35">[36]</ref> propose a two-stage regression model with global and local reinitializations. From different perspectives, Zhu et al. <ref type="bibr" target="#b74">[75]</ref> investigate the methods of optimal initialization by searching the object shape space; Valle et al.</p><p>[55] present a combined model with a tree structured regressor to infer landmark locations based on heatmap prediction results; Wu et al. <ref type="bibr" target="#b62">[63]</ref> leverage uniqueness and discriminative characteristics across datasets to assist landmark detection.</p><p>Landmark Detection with Graphs: The structure of landmarks can be naturally modeled as a graph considering the landmark locations and landmark to landmark relationships <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b74">75]</ref>. Zhou et al. <ref type="bibr" target="#b72">[73]</ref> propose a Graph-Matching method which obtains landmark locations by selecting the set of landmark candidates that would best fit the shape constraints learned from the examplars. Yu et al. <ref type="bibr" target="#b67">[68]</ref> describe a two-stage deformable shape model to first extract a coarse optimum by maximizing a local alignment likelihood in the region of interest then refine the results by maximizing an energy function under</p><formula xml:id="formula_0">GCN-global CNN GCN-local GCN-local G=(V 0 ,E, F 0 ) G=(V 1 ,E, F 1 ) G=(V 2 ,E, F 2 ) G=(V K ,E, F K ) Feature Map: H V is ua l fe at ur e</formula><p>In te rp ol at io n   <ref type="bibr" target="#b31">[32]</ref> propose a fast object annotation framework, where contour vertices are regressed using GCN to perform segmentation, indicating the benefit of position prediction with iterative message exchanges. In their task, each point is considered with the same semantics towards coarse anonymous matching which is not appropriate for precise targeted localization tasks like landmark detection. Adaptively learning graph connectivities instead of employing a fixed graph structure based on prior knowledge should be explored to improve the model's generalizability to different tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Our method adopts the cascaded-regression framework, where given the input image and initial landmarks (from the mean shape), the predicted landmark coordinates are updated in multiple steps. Yet differently, we feature the cascadedregression framework with a graph representation of the landmarks, denoted by G = (V, E, F ), where V = {v i } denotes the landmarks, E = {e ij } denotes the learned connectivity between landmarks and F = {f i } denotes graph signals capturing appearance and shape information. The graph is processed by cascaded GCNs to progressively update landmark coordinates. An overview of our method is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Details of the cascaded GCNs, graph signal and learned connectivity are presented in Section 3.1, Section 3.2 and Section 3.3, respectively. The training scheme of our method can be found in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Cascaded GCNs</head><p>Given a graph representation of landmarks G = (V, E, F ), two-stage cascaded GCN modules are employed to progressively update the landmark coordinates. The first stage, GCN-global, estimates a global transformation to coarsely move the landmarks to the targets. The second stage, GCN-local, estimates local landmark coordinate offsets to iteratively move the landmarks toward the targets. Both modules employ the same GCN architecture (weights not shared) and the same learnable graph connectivity.</p><p>Graph Convolution: Given a graph connectivity E and a graph feature F , the k-th graph convolution operation updates the i-th node feature f j k by aggregating all node features weighted by the connectivity:</p><formula xml:id="formula_1">f i k+1 = W 1 f i k + j e ij W 2 f j k<label>(1)</label></formula><p>where W 1 and W 2 are learnable weight matrices. The graph convolutions can be seen as the mechanism of information collection among the neighborhoods.</p><p>The connectivity E serves as pathways for information flow from one landmark to another. Global Transformation GCN: Previous work <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b35">36]</ref> learn an affine transformation with a deep neural network by predicting a two by three affine transformation matrix which deforms the image to the satisfied posture. Inspired by this work, we employ a GCN on the initial landmarks to coarsely move them to the targets. Considering our graph is more flexible that does not have to maintain the parallelism and respective ratios among the edges, we model the global transformation using a perspective transformation <ref type="bibr" target="#b16">[17]</ref>. A perspective transformation can be parameterized by 9 scalars M = [a, b, c, d, e, f, g, h, i] T ? R 9?1 with the operation written as:</p><formula xml:id="formula_2">? ? x y 1 ? ? ? = ? ? rx ry r ? ? = ? ? a b c d e f g h i ? ? ? ? x y 1 ? ? (2)</formula><p>Given a target image, we initialize landmark locations V 0 using the mean shape of landmarks in the training set, and placed it at the center of the image. The graph is processed by the GCN-global to estimate a perspective transformation to bring the initial structure closer to the target.</p><p>Specifically, a graph isomorphism network (GIN) <ref type="bibr" target="#b65">[66]</ref> is employed to process the graph features {f i k } produced by the GCN to output a 9-dimensional vector representing the perspective transformation:</p><formula xml:id="formula_3">f G = MLP CONCAT READOUT f i k |i ? G |k = 0, 1, . . . , K ,<label>(3)</label></formula><p>where the READOUT operator sums the features from all the nodes in the graph G. The transformation matrix M is obtained by transforming and reshaping f G into a 3 by 3 matrix. We then apply this transformation matrix on the initial landmark node coordinates to obtain the aligned landmark coordinates:</p><formula xml:id="formula_4">V 1 = {v 1 i } = {Mv 0 i } (4)</formula><p>Local Refinement GCN: Given the transformed landmarks, we employ GCN-local to further shift the graph in a cascaded manner. GCN-local employs the same architecture as GCN-global, with a difference that the last layer produces a 2-dimensional vector for each landmark, representing the coordinate offset of the landmark. The updated landmark coordinates can be written as:</p><formula xml:id="formula_5">v t+1 i = v t i + ?v t i ,<label>(5)</label></formula><p>where ?v t i = (?x t i , ?y t i ) is the output of the GCN-local at the t-th step. In all our experiments, we perform T = 3 iterations of the GCN-local. Note that the graph signal is re-calculated after each GCN-local iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph signal with appearance and shape information</head><p>We formulate a graph signal F as a set of node features f i , each associated with a landmark v i . The graph signal contains a visual feature to encode local image appearance and a shape feature to encode the global landmark shape.</p><p>Visual Feature: Specifically, given a feature map H with D channels produced by a backbone CNN, visual features, denoted by p i ? R D , are extracted by interpolating H at the landmark coordinates v i . The interpolation is performed via a differentiable bi-linear interpolation <ref type="bibr" target="#b26">[27]</ref>. In this way, visual feature of each landmark is collected from the feature map, encoding the appearance of its neighborhood.</p><p>Shape Feature: While the visual feature encodes the appearance in a neighborhood of the landmark, it does not explicitly encode the global shape of the landmarks. To incorporate this structural information into the graph signal, for each landmark, we compute its displacement vectors to all other landmarks, denoted as</p><formula xml:id="formula_6">q i = {v j ? v i } j =i ? R 2?(N ?1)</formula><p>, where N is the number of landmarks. Such shape feature allows structural information of the landmarks to be exploited to facilitate landmark detection. For example, when the mouth of a face is occluded, the coordinates of the mouth landmarks can be inferred from the eyes and nose. Wrong landmark detection results that violate the shape prior can also be avoided when the shape is explicitly captured in the graph signal.</p><p>The graph signal F is then constructed for each landmark by concatenating the visual feature p i and the shape feature q i (flattened), resulting in a feature vector f i ? R D+2(N ?1) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Landmark graph with learnable connectivity</head><p>The graph connectivity determines the relationship between each pair of landmarks in the graph and serves as the information exchange channel in GCN. In most existing applications of GCN <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b60">61]</ref>, the graph connectivity is given based on the prior knowledge of the task. In our landmark detection application, it is non-trivial to manually define the optimal underlying graph connectivity for the learning task. Therefore, relying on hand-crafted graph connectivity would introduce a subjective element into the model, which could lead to sub-optimal performance. To address this limitation, we learn task-specific graph connectivities during the training phase in an end-to-end manner. The connectivity weight e ij behaves as information propagation gate in graph convolutions (Eqn. 1). We treat the connectivity {e ij }, represented as an adjacency matrix, as a learnable parameter that is trained with the network during the training phase. In this way, the task-specific optimal graph connectivity is obtained by optimizing the performance of the target landmark detection task, allowing our method to be applied to different landmark detection tasks without manual intervention.</p><p>Graph connectivity learning has been studied before by the research community. One notable example is Graph Attention Networks <ref type="bibr" target="#b55">[56]</ref>, which employs a self-attention mechanism to adaptively generate connectivity weights during the model inference. We conjugate that in structured landmark detection problems, the underlying relationship between the landmarks remains the same for a given task, instead of varying across individual images. Therefore, we share the same connectivity across images on the same task, and directly optimize the connectivity weights during the training phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GCN-global:</head><p>Since the perspective transformation estimated by GCN-global has limited degree of freedom, directly penalizing the distance between the predicted and the ground truth landmarks will lead to unstable optimization behavior. As the goal of GCN-global is to coarsely locate the landmarks, we propose to use a margin loss on the L 1 distance, written as:</p><formula xml:id="formula_7">L global = 1 N i?N x,y |v 1 i ? v i | ? m + (6) where [u] + := max(0, u). v 1 i = (x 1 i , y 1 i )</formula><p>and v i = (x i , y i ) denote the predicted and ground truth landmark coordinates for the i-th landmark. m is a hyperparameter representing a margin which controls how well we want the alignment to be. Following this procedure, we aim to obtain a high robustness of the coarse landmark detection, while forgive small errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GCN-local:</head><p>To learn a precise localization, we directly employ L1 loss on all predicted landmark coordinates after the GCN-local, written as:</p><formula xml:id="formula_8">L local = 1 N i?N x,y |v T i ? v i |<label>(7)</label></formula><p>where v T i is the T -th step (the last step) coordinate predictions, and v i is the ground truth coordinate for the i-th landmark.</p><p>The overall loss to train DAG is a combination of the above two losses:</p><formula xml:id="formula_9">L = ? 1 L global + ? 2 L local<label>(8)</label></formula><p>where ? k is the weight parameter for each loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We conduct evaluations on three public facial image and three medical image datasets:  <ref type="bibr" target="#b21">[22]</ref>. We follow previous studies <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b41">42]</ref> to conduct inferences on the re-annotated COFW-68 dataset to test our model's cross-dataset performance which is trained on 300W dataset. Cephalometric X-ray <ref type="bibr" target="#b56">[57]</ref> is a public dataset originally for a challenge in IEEE ISBI-2015. It contains 400 X-ray Cephalometric images with resolution of 1, 935 ? 2, 400, 150 images are used as training set, the rest 150 images and 100 images are used as validation and test sets. Each cephalometric image contains 19 landmarks. In this paper, we only focus on the landmark detection task.</p><p>Hand X-ray <ref type="bibr" target="#b34">[35]</ref> is a real-world medical dataset collected by a hospital. The X-ray images are taken with different hand poses with resolutions in 1, 500s ? 2, 000s. In total, 471 images are randomly split into a training set (80%, N =378) and a testing set (20%, N =93). 30 landmarks are manually labeled for each image.</p><p>Pelvic X-ray <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b8">9]</ref> another real-world medical dataset collected by the same hospital. Images are taken over patient's pelvic bone with resolutions in 2, 500s? 2, 000s. The challenges in this dataset is the high structural and appearance variation, caused by bone fractures and metal prosthesis. In total, 1,000 imagesare randomly splited into a training set (80%, N =800) and a testing set (20%, N =200). 16 landmarks are manually labeled for each image. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiment Settings</head><p>Evaluation Metrics: We evaluate the proposed method following two sets of metrics. For the facial image datasets, we employ the widely adopted Normalized Mean Error (NME), Area Under the Curve (AUC), Failure Rate for a maximum error of 0.1 (FR@0.1) and Cumulative Errors Distribution (CED) curve (supplementary material). To compare with previous methods, we conduct both "interocular" (outer-eye-corner-distance) and "inter-pupil" (eye-center-distance) normalizations on the detected landmark coordinates. For the Cephalometric X-ray images, we follow the original evaluation protocol to compare two sets of metrics: Mean Radial Error (MRE) which computes the average of Euclidean Distances of predicted coordinates and ground truth coordinates of all the landmarks; the corresponding Successful Detection Rate (SDR) under 2mm, 2.5mm, 3mm and 4mm. For the Hand and Pelvic X-rays, we compute MRE, Hausdorff Distance (HD) and Standard Deviations (STD). Recall that Hausdorff Distance measures the maximum value of the minimum distances between two sets of points. In our case, we aim to evaluate the error upper-bound for the detected landmarks. Implementation Details: Following previous studies, we crop and resize facial images into 256 ? 256 based on the provided bounding boxes. We follow <ref type="bibr" target="#b9">[10]</ref> to resize the Cephalometric X-rays to 640?800. For the Hand and Pelvic X-rays, we resize each image into 512?512 preserving the original height and width ratio by padding zero values to the empty regions. The proposed model is implemented in PyTorch and is experimented on a single NVIDIA Titan V GPU. We choose ? 1 = ? 2 = 1 for different parts in the overall loss function. HRNet18 <ref type="bibr" target="#b48">[49]</ref> pretrained on ImageNet is used as our backbone network to extract visual feature maps for its parallel multi-resolution fusion mechanism and deep network design which fits our need for both high resolution and semantic feature representation. The last output after fusion is extracted as feature map of dimension H ? R 256?64?64 . We employ 4 residual GCN blocks <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b29">30]</ref> in GCN-global and GCN-local and perform 3 iterations of GCN-local. Adjacency matrix values are initialized to 1/N so that the total weight for each node is 1 to avoid message explosion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison with the SOTA methods</head><p>WFLW: WFLW is a comprehensive public facial landmark detection dataset focusing on multi-discipline and difficult detection scenarios. Summary of results is shown in <ref type="table" target="#tab_2">Table 1</ref>. Following previous works, three evaluation metrics are computed: Mean Error, FR@0.1 and AUC@0.1. Our model achieves 4.21% mean error which outperforms all the strong state-of-the-art methods including AWING <ref type="bibr" target="#b57">[58]</ref> which adopts a new adaptive loss function, SAN <ref type="bibr" target="#b17">[18]</ref> and STYLE <ref type="bibr" target="#b41">[42]</ref> which leverage additional generated images for training. The most significant improvements lie in Make-up and Occlusion subsets, where only partial landmarks are visible. Our model is able to accurately infer those hard cases based on the visible landmarks due to the benefit of preserving and leveraging graph structural knowledge. This can be further illustrated by examining the visualization results for the occlusion scenarios in <ref type="figure" target="#fig_1">Figure 2</ref>.   300W: There are two evaluation protocols, namely inter-pupil and inter-ocular normalizations. In this paper, we conduct experiments under both settings on the detection results in order to comprehensively evaluate with the other stateof-the-arts. As can be seen from <ref type="table" target="#tab_3">Table 2</ref>, our model achieves competitive results in both evaluation settings comparing to the previous best models, STYLE <ref type="bibr" target="#b41">[42]</ref>, LAB <ref type="bibr" target="#b61">[62]</ref> and AWING <ref type="bibr" target="#b57">[58]</ref> which are all heatmap-based. Comparing to the latest coordinate-based model ODN <ref type="bibr" target="#b73">[74]</ref> and DVLN <ref type="bibr" target="#b62">[63]</ref>, our method achieves improvements in large margins (27% and 8% respectively) which sets a remarkable milestone for coordinate-based models, closing the gap between coordinateand heatmap-based methods. COFW-68 and 300W testset: To verify the robustness and generalizability of our model, we conduct inference on images from COFW-68 and 300W testset using the model trained on 300W training set and validated on 300W fullset. Results summarized in <ref type="table" target="#tab_4">Table 3</ref> indicating our model's superior performance over most of the other state-of-the-art methods in both datasets. In particular for the COFW-68 dataset, the Mean Error and FR@0.1 are significantly improved (5% and 86% ) comparing to the previous best model, STYLE <ref type="bibr" target="#b41">[42]</ref>, demonstrating a strong cross-dataset generalizability of our method. Cephalometric X-rays:</p><p>We further applied our model on a public Cephalometric X-ray dataset and compare with HRNet18 <ref type="bibr" target="#b48">[49]</ref> and three domain specific state-of-the-art models on this dataset, Arik et al. <ref type="bibr" target="#b1">[2]</ref>, Payer et al. <ref type="bibr" target="#b39">[40]</ref> and Chen et al. <ref type="bibr" target="#b9">[10]</ref>. As is shown in <ref type="table" target="#tab_6">Table 5</ref>, our model significantly outperforms Arik et al.,</p><p>HRNet18 <ref type="bibr" target="#b48">[49]</ref> and Payer et al. <ref type="bibr" target="#b39">[40]</ref> in all metrics. Comparing to Chen et al. <ref type="bibr" target="#b9">[10]</ref>, we also achieve improved overall accuracy evaluated under MRE. A closer look at the error distribution reveals that our model is able to achieve more precise localization under smaller error ranges, i.e., 2mm and 2.5mm.</p><p>Hand and Pelvic X-rays: As shown in <ref type="table" target="#tab_5">Table 4</ref>, our model achieves susbstantial performance improvements comparing to the HRNet18 <ref type="bibr" target="#b48">[49]</ref>, Payer et al. <ref type="bibr" target="#b39">[40]</ref> and Chen et al. <ref type="bibr" target="#b9">[10]</ref> on both the Hand and Pelvic X-ray datasets. On Hand X-ray, where the bone structure can vary in different shapes depending on the hand pose, our method still achieves largely reduced Hausdorff distance as well as its standard deviation, reveling DAG's ability in capturing landmark relationships under various situations toward robust landmark detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Graph Structure Visualization</head><p>To better understand learning outcomes, we look into the visualization on the learned graph structure. As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, the learned structures in different domains are meaningful indicating strong connections between 1) spatially close landmarks, and 2) remote but related landmarks that move coherently, e.g. symmetrical body parts. We believe the mechanism behind our algorithm is relying on these locations to provide reliable inductions when it makes movement predictions, such as similar movements by neighbors, or fixed spatial relationships by the symmetrical body parts (e.g., eyes, pelvis). With the learnable graph connectivity, we are able to capture the underlying landmarks relationships for different objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablation Studies</head><p>In this section, we examine the performance of the proposed methods by conducting ablation studies on the 300W fullset. We analyze: 1) the overall effect Overall effect of the proposed DAG: We analyze the effect of using DAG to regress landmark coordinates in comparison with two baselines, namely 1) Global feature: The last feature map of the backbone network is global average pooled to produce a feature vector, which connects to a fully connected layer to regress landmark coordinates. This approach is similar to previous coordinate regression based methods, e.g. <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b70">71]</ref>. 2) Local feature: The feature vectors are interpolated at each landmark's initial location on the last feature map of the backbone CNN. Then each landmark's feature vector is connected to a fully connected layer to regress the landmark's coordinate. To decouple the effect of the backbone strength, each experiment is conducted on four popular landmark detection backbone networks, namely VGG16 <ref type="bibr" target="#b46">[47]</ref>, ResNet50 <ref type="bibr" target="#b23">[24]</ref>, StackedHourGlass4 <ref type="bibr" target="#b37">[38]</ref>, HRNet18 <ref type="bibr" target="#b48">[49]</ref>. Results are listed in <ref type="table" target="#tab_7">Table 6</ref>. By comparing different regression methods with the same backbone (columnwise), DAG achieves the best results indicating the proposed framework's strong localization ability. By comparing DAG's results under different backbones (last row), we observe DAG's consistent performance boost demonstrating its effectiveness and promising generalizability.  Individual effect of learning graph connectivity: We study three kinds of graph connectivity schemes, namely 1) Self -connectivity: The landmarks only connect to themselves and no other landmarks. 2) Uniform connectivity: The landmarks connects to all other landmarks using the same edge weight. 3) Learned connectivity: learned edge weights as proposed. As summarized in Table 7, regardless of using shape feature or not, using uniform connectivity performs results in better performance than self-connectivity, demonstrating the importance of allowing information exchange on the graph. The learned connectivity performance the best, further demonstrating that learned edge weights further improve the effectiveness of information exchange on the graph. Individual effect of incorporating shape feature: We analyze the effect of incorporating the shape feature using self, uniformed and learned connectivities, respectively. As shown in <ref type="table" target="#tab_8">Table 7</ref>, on all three types of connectivities, incorporating the proposed shape feature into graph signal results in improved performance especially for self-connective graphs, where the shape feature adds the missing global structure information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we introduce a robust and accurate landmark detection model named Deep Adaptive Graph (DAG). The proposed model deploys an initial landmark graph, and then deforms and progressively updates the graph by learning the adjacency matrix. Graph convolution operations follow the strong structural prior to enable effective local information exchange as well as global structural constraints for each step's movements. The superior performances on three public facial image datasets and three X-ray datasets prove both the effectiveness and generalizability of the proposed method in multiple domains.</p><p>Acknowledgement. This work is supported in part by NSF through award IIS-1722847, NIH through the Morris K. Udall Center of Excellence in Parkinson's Disease Research. The main work was done when Weijian Li was a research intern at PAII Inc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Additional discussions with related works:</head><p>Though some recent works <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b39">40]</ref> propose to model landmark relationship, our problem/method has large differences from them. Tompson et al. <ref type="bibr" target="#b51">[52]</ref> propose to use spatial information in a post-processing step to filter outliers, while we leverage visual-spatial joint features for landmark regression. Also, the PAF proposed by Cao et al. <ref type="bibr" target="#b7">[8]</ref> focuses on a different task of assembling detected key points for multi-person parsing. Zhao et al. <ref type="bibr" target="#b71">[72]</ref> focus differently on predicting 3D poses from 2D joints. Their 2D joints are generated by a pre-trained 2D pose estimation network. Besides, their network structure is predefined by a fixed adjacency matrix while we actively learn the structures. Payer et al. <ref type="bibr" target="#b39">[40]</ref>, propose a spatial configuration branch to disambiguate candidates from the heatmap predictions. There is no explicit landmark structure modeling. In contrast, we explicitly model shape through a graph representation with learnable connectivity.</p><p>Among the SOTA, WING <ref type="bibr" target="#b20">[21]</ref> is pure coordinate-based, while LAB <ref type="bibr" target="#b61">[62]</ref> and AWING <ref type="bibr" target="#b57">[58]</ref> integrate face boundary information via heatmap, which is their key contributions. The gap between WING and AWING is significant on WFLW, which is a more challenging dataset than 300W in terms of dataset scale, pose variations, occlusions, etc. Our method performs significantly better than WING on WFLW by reducing the failure rate by 50%, and is competitive to AWING. In addition, WING focuses on loss design, which is orthogonal and complementary to our novelty. By employing WING loss in our method, our performance can be further improved (e.g., on 300W, inter-pupil NME from 4.27 to 4.21 and inter-ocular NME from 3.04 to 3.01). While LAB and AWING utilize global representation, human knowledge on face structure via a boundary heatmap is injected, leading to task-specific solutions. In contrast, our method is a general landmark detection method to model the structural information via a self-learned graph structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CED Curve:</head><p>Following previous works <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b41">42]</ref>, we report Cumulative Errors Distribution (CED) curve result on cross-evaluations of COFW-68 test set. Recall that the success rate measures the proportion of images that have a localization error below a certain threshold <ref type="bibr" target="#b21">[22]</ref>. Thus, given a range of thresholds, the corresponding success rates will form a distribution which is considered as Cumulative Error Distribution (CED). For clearer comparison, we include both Normalized Mean Error (Error) as well as the Failure Rate (i.e. 1 ? SuccessRate) (Failure) at threshold of 0.1. As we can see from <ref type="figure" target="#fig_3">Figure 4</ref>, our model outperforms previous methods by a large margin, especially in Failure Rate which is reduced to 0.39% for the first time. The comparison of numerical NME and Failure Rate values with the other state-of-the-arts can be found in <ref type="table" target="#tab_4">Table 3</ref> in our submitted ECCV-20 main paper. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Ablation Studies</head><p>Here we conduct three more types of ablation studies, namely: (1) The comparison of the transformation method used in GCN-global. <ref type="bibr">(</ref>2) The effectiveness of the proposed GCN modules. <ref type="formula" target="#formula_3">(3)</ref> The comparison of different number of regression steps used in GCN-local. Results are recorded in <ref type="table" target="#tab_9">Table 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choice of transformations:</head><p>We experiment two types of GCN-global choices: (1) Adopt Affine Transformation. In this case, the performance of our GCNglobal module drops to 3.13.(2) Adopt Perspective Transformation. We achieve the best result as 3.04 which is also reported in our main paper. This indicates that GCN-global can better locates ROIs with the more flexible perspective transformation.</p><p>Effectiveness of GCN modules: We examine the effectiveness of the proposed GCN modules by: (1) Replacing GCN-global with a CNN block: we replace the GCN-global module with a 2-layer CNN (Conv/BN/ReLU) with Global Average Pooling predicting 9 transformation parameters. The average error increased from 3.04 to 3.12. (2) Replacing GCN-local with a MLP block: we remove the connectivity used in GCN-local, making it a simple MLP (FC/ReLU). The average error increased from 3.04 to 3.18. These indicating the importance of the proposed GCN modules. Number of steps: We analyze different choices of steps for GCN-local. Results are shown in <ref type="table" target="#tab_9">Table 8</ref>. The overall performance improves as the number of steps increases indicating the benefit of cascading multiple regressions. The best performance is achieved when GCN-local is implemented with three iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">More Settings:</head><p>We describe more settings for training the model. Adam optimizer is adopted with initial learning rate lr = 0.0001. The learning rate decreases at every 100 epochs. L2 penalty is applied to the training parameters with rate 0.0001. Margin for training GCN-global is set to m = 0.1 for Face300W, m = 0.15 for WFLW, m = 0.15 for three Medical datasets. All data augmentations we used: <ref type="formula" target="#formula_1">(1)</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Overview of the proposed Deep Adaptive Graph (DAG</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Visualization of landmark detection results. Pairs of reseults are displayed side by side. For each pair, Left image: detection result from a SOTA method<ref type="bibr" target="#b48">[49]</ref>. Right image: result produced by our method. Green dot: predicted landmark location. Red dot: groundtruth landmark location.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Graph structure visualization. Red lines: edges. Green dots: landmarks. Deeper red means higher edge weights. [Leftmost column]: the constructed graphs (3 highest weighted edges for each landmark). [Right 5 columns]: for the 5 landmarks, the most related neighbors (10 highest weighted edges).of using the proposed DAG to regress landmark coordinates, 2) the individual effect of learning the graph connectivity, 3) the individual effect of incorporating shape feature into the graph signal. More ablation studies can be found in the supplementary material.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>,LFPW), Error: 8.76%, Failure: 20.12% TCDCN(HELEN,LFPW,AFW,MAFL), Error: 7.66%, Failure: 16.17% HPM(HELEN,LFPW), Error: 6.72%, Failure: 6.71% SAPM(HELEN), Error: 6.64%, Failure: 5.72% CFSS(HELEN,LFPW,AFW), Error: 6.28%, Failure: 9.07% Ours(HELEN,LFPW,AFW), Error: 4.22%, Failure: 0.39% Cumulative Errors Distribution (CED) curve results on the COFW-68 test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Rotate input image with a random angle in [-30, 30]. (2) Random flip the input image horizontally. (3) Scale input image with a random factor in [0.75, 1.25].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Evaluation on the WFLW dataset (98 Landmarks). *: focus on loss function. #: focus on data augmentation.</figDesc><table><row><cell>Metric</cell><cell>Method</cell><cell>Test</cell><cell cols="6">Pose Expression Illumination Make-up Occlusion Blur</cell></row><row><cell></cell><cell>CFSS [75]</cell><cell>9.07</cell><cell>21.36</cell><cell>10.09</cell><cell>8.30</cell><cell>8.74</cell><cell>11.76</cell><cell>9.96</cell></row><row><cell></cell><cell>DVLN [63]</cell><cell>6.08</cell><cell>11.54</cell><cell>6.78</cell><cell>5.73</cell><cell>5.98</cell><cell>7.33</cell><cell>6.88</cell></row><row><cell></cell><cell>LAB [62]</cell><cell>5.27</cell><cell>10.24</cell><cell>5.51</cell><cell>5.23</cell><cell>5.15</cell><cell>6.79</cell><cell>6.32</cell></row><row><cell>Mean Error %</cell><cell cols="2">SAN [18] # WING [21] * 5.11 5.22</cell><cell>10.39 8.75</cell><cell>5.71 5.36</cell><cell>5.19 4.93</cell><cell>5.49 5.41</cell><cell>6.83 6.37</cell><cell>5.80 5.81</cell></row><row><cell></cell><cell cols="2">HRNet18 [49] 4.60</cell><cell>7.94</cell><cell>4.85</cell><cell>4.55</cell><cell>4.29</cell><cell>5.44</cell><cell>5.42</cell></row><row><cell></cell><cell cols="2">STYLE [42] # 4.39</cell><cell>8.42</cell><cell>4.68</cell><cell>4.24</cell><cell>4.37</cell><cell>5.60</cell><cell>4.86</cell></row><row><cell></cell><cell cols="2">AWING [58] * 4.36</cell><cell>7.38</cell><cell>4.58</cell><cell>4.32</cell><cell>4.27</cell><cell>5.19</cell><cell>4.96</cell></row><row><cell></cell><cell>Ours</cell><cell cols="2">4.21 7.36</cell><cell>4.49</cell><cell>4.12</cell><cell>4.05</cell><cell>4.98</cell><cell>4.82</cell></row><row><cell></cell><cell>CFSS [75]</cell><cell cols="2">20.56 66.26</cell><cell>23.25</cell><cell>17.34</cell><cell>21.84</cell><cell>32.88</cell><cell>23.67</cell></row><row><cell></cell><cell>DVLN [63]</cell><cell cols="2">19.84 46.93</cell><cell>11.15</cell><cell>7.31</cell><cell>11.65</cell><cell>16.30</cell><cell>13.71</cell></row><row><cell></cell><cell>LAB [62]</cell><cell>7.56</cell><cell>28.83</cell><cell>6.37</cell><cell>6.73</cell><cell>7.77</cell><cell>13.72</cell><cell>10.74</cell></row><row><cell>Failure Rate @0.1</cell><cell cols="2">SAN [18] # WING [21] * 6.00 6.32</cell><cell>27.91 22.70</cell><cell>7.01 4.78</cell><cell>4.87 4.30</cell><cell>6.31 7.77</cell><cell>11.28 12.50</cell><cell>6.60 7.76</cell></row><row><cell></cell><cell cols="2">HRNet18 [49] 4.64</cell><cell>23.01</cell><cell>3.50</cell><cell>4.72</cell><cell>2.43</cell><cell>8.29</cell><cell>6.34</cell></row><row><cell></cell><cell cols="2">STYLE [42] # 4.08</cell><cell>18.10</cell><cell>4.46</cell><cell>2.72</cell><cell>4.37</cell><cell>7.74</cell><cell>4.40</cell></row><row><cell></cell><cell cols="3">AWING [58] * 2.84 13.50</cell><cell>2.23</cell><cell>2.58</cell><cell>2.91</cell><cell>5.98</cell><cell>3.75</cell></row><row><cell></cell><cell>Ours</cell><cell>3.04</cell><cell>15.95</cell><cell>2.86</cell><cell>2.72</cell><cell>1.45</cell><cell>5.29</cell><cell>4.01</cell></row><row><cell></cell><cell>CFSS [75]</cell><cell cols="2">0.3659 0.0632</cell><cell>0.3157</cell><cell>0.3854</cell><cell>0.3691</cell><cell cols="2">0.2688 0.3037</cell></row><row><cell></cell><cell cols="3">DVLN [63] 0.4551 0.1474</cell><cell>0.3889</cell><cell>0.4743</cell><cell>0.4494</cell><cell cols="2">0.3794 0.3973</cell></row><row><cell></cell><cell cols="3">HRNet18 [49] 0.5237 0.2506</cell><cell>0.5102</cell><cell>0.5326</cell><cell>0.5445</cell><cell cols="2">0.4585 0.4515</cell></row><row><cell>AUC @0.1</cell><cell cols="3">LAB [62] SAN [18] # 0.5355 0.2355 0.5323 0.2345</cell><cell>0.4951 0.4620</cell><cell>0.5433 0.5552</cell><cell>0.5394 0.5222</cell><cell cols="2">0.4490 0.4630 0.4560 0.4932</cell></row><row><cell></cell><cell cols="3">WING [21] * 0.5504 0.3100</cell><cell>0.4959</cell><cell>0.5408</cell><cell>0.5582</cell><cell cols="2">0.4885 0.4932</cell></row><row><cell></cell><cell cols="3">AWING [58] * 0.5719 0.3120</cell><cell>0.5149</cell><cell>0.5777</cell><cell>0.5715</cell><cell cols="2">0.5022 0.5120</cell></row><row><cell></cell><cell cols="3">STYLE [42] # 0.5913 0.3109</cell><cell>0.5490</cell><cell>0.6089</cell><cell>0.5812</cell><cell cols="2">0.5164 0.5513</cell></row><row><cell></cell><cell>Ours</cell><cell cols="3">0.5893 0.3150 0.5663</cell><cell>0.5953</cell><cell cols="3">0.6038 0.5235 0.5329</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Evaluation on 300W Common set, Challenge set and Fullset.</figDesc><table><row><cell cols="3">Inter-Pupil Normalization</cell><cell></cell></row><row><cell>Method</cell><cell cols="3">Year Comm. Challenge Full.</cell></row><row><cell>CFAN [70]</cell><cell>2014 5.50</cell><cell cols="2">16.78 7.69</cell></row><row><cell>ESR [7]</cell><cell>2014 5.28</cell><cell cols="2">17.00 7.58</cell></row><row><cell>SDM [65]</cell><cell>2013 5.57</cell><cell cols="2">15.40 7.52</cell></row><row><cell cols="2">3DDFA [76] 2016 6.15</cell><cell cols="2">10.59 7.01</cell></row><row><cell>LBF [43]</cell><cell>2014 4.95</cell><cell cols="2">11.98 6.32</cell></row><row><cell>CFSS [75]</cell><cell>2015 4.73</cell><cell>9.98</cell><cell>5.76</cell></row><row><cell cols="2">SeqMT [25] 2018 4.84</cell><cell>9.93</cell><cell>5.74</cell></row><row><cell cols="2">TCDCN [71] 2015 4.80</cell><cell>8.60</cell><cell>5.54</cell></row><row><cell>RCN [26]</cell><cell>2016 4.67</cell><cell>8.44</cell><cell>5.41</cell></row><row><cell>TSR [36]</cell><cell>2017 4.36</cell><cell>7.56</cell><cell>4.99</cell></row><row><cell cols="2">DVLN [63] 2017 3.94</cell><cell>7.62</cell><cell>4.66</cell></row><row><cell cols="2">HG-HSLE [78] 2019 3.94</cell><cell>7.24</cell><cell>4.59</cell></row><row><cell cols="2">DCFE [55] 2018 3.83</cell><cell>7.54</cell><cell>4.55</cell></row><row><cell cols="2">STYLE [42] # 2019 3.98</cell><cell>7.21</cell><cell>4.54</cell></row><row><cell cols="2">AWING [58] * 2019 3.77</cell><cell>6.52</cell><cell>4.31</cell></row><row><cell>LAB [62]</cell><cell>2018 3.42</cell><cell>6.98</cell><cell>4.12</cell></row><row><cell cols="2">WING [21] * 2018 3.27</cell><cell>7.18</cell><cell>4.04</cell></row><row><cell>Ours</cell><cell>2020 3.64</cell><cell>6.88</cell><cell>4.27</cell></row><row><cell cols="3">Inter-Ocular Normalization</cell><cell></cell></row><row><cell>Method</cell><cell cols="3">Year Comm. Challenge Full.</cell></row><row><cell cols="2">PCD-CNN [29] 2018 3.67</cell><cell>7.62</cell><cell>4.44</cell></row><row><cell>ODN [74]</cell><cell>2019 3.56</cell><cell>6.67</cell><cell>4.17</cell></row><row><cell cols="2">CPM+SBR [19] 2018 3.28</cell><cell>7.58</cell><cell>4.10</cell></row><row><cell cols="2">SAN [18] # 2018 3.34</cell><cell>6.60</cell><cell>3.98</cell></row><row><cell cols="2">STYLE [42] # 2019 3.21</cell><cell>6.49</cell><cell>3.86</cell></row><row><cell>LAB [62]</cell><cell>2018 2.98</cell><cell>5.19</cell><cell>3.49</cell></row><row><cell cols="2">HRNet18 [49] 2019 2.91</cell><cell>5.11</cell><cell>3.34</cell></row><row><cell cols="2">HG-HSLE [78] 2019 2.85</cell><cell>5.03</cell><cell>3.28</cell></row><row><cell cols="2">LUVLi [28] 2020 2.76</cell><cell>5.16</cell><cell>3.23</cell></row><row><cell cols="2">AWING [58] * 2019 2.72</cell><cell>4.52</cell><cell>3.07</cell></row><row><cell>Ours</cell><cell>2020 2.62</cell><cell>4.77</cell><cell>3.04</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Evaluation on 300W and COFW-68 testsets with the model trained on 300W training set.</figDesc><table><row><cell></cell><cell>300W</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="3">Year AUC@0.1 FR@0.1</cell></row><row><cell cols="2">Deng et al. [15] 2016</cell><cell>0.4752</cell><cell>5.50</cell></row><row><cell cols="2">Fan et al. [20] 2016</cell><cell>0.4802</cell><cell>14.83</cell></row><row><cell cols="2">DensReg+DSM [1] 2017</cell><cell>0.5219</cell><cell>3.67</cell></row><row><cell>JMFA [16]</cell><cell>2019</cell><cell>0.5485</cell><cell>1.00</cell></row><row><cell>LAB [62]</cell><cell>2018</cell><cell>0.5885</cell><cell>0.83</cell></row><row><cell cols="2">HRNet18 [49] 2019</cell><cell>0.6041</cell><cell>0.66</cell></row><row><cell cols="2">AWING [58] * 2019</cell><cell>0.6440</cell><cell>0.33</cell></row><row><cell>Ours</cell><cell>2020</cell><cell>0.6361</cell><cell>0.33</cell></row><row><cell></cell><cell cols="2">COFW-68</cell><cell></cell></row><row><cell>Method</cell><cell cols="3">Year Mean Error % FR@0.1</cell></row><row><cell>CFSS [75]</cell><cell>2015</cell><cell>6.28</cell><cell>9.07</cell></row><row><cell cols="2">HRNet18 [49] 2019</cell><cell>5.06</cell><cell>3.35</cell></row><row><cell>LAB [62]</cell><cell>2018</cell><cell>4.62</cell><cell>2.17</cell></row><row><cell cols="2">STYLE [42] # 2019</cell><cell>4.43</cell><cell>2.82</cell></row><row><cell>Ours</cell><cell>2020</cell><cell>4.22</cell><cell>0.39</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Evaluations on the hand Xray and pelvic X-ray images.</figDesc><table><row><cell></cell><cell cols="2">Hand X-ray Dataset</cell><cell></cell></row><row><cell>Method</cell><cell cols="4">Year MRE (pix) Hausdorff STD</cell></row><row><cell cols="2">HRNet18 [49] 2019</cell><cell>12.79</cell><cell>26.36</cell><cell>6.07</cell></row><row><cell cols="2">Chen et al. [10] 2019</cell><cell>7.14</cell><cell cols="2">18.71 14.43</cell></row><row><cell cols="2">Payer et al. [40] 2019</cell><cell>6.11</cell><cell>16.55</cell><cell>4.01</cell></row><row><cell>Ours</cell><cell>2020</cell><cell>5.57</cell><cell cols="2">14.83 3.63</cell></row><row><cell></cell><cell cols="3">Pelvic X-ray Dataset</cell></row><row><cell>Method</cell><cell cols="4">Year MRE (pix) Hausdorff STD</cell></row><row><cell cols="2">HRNet18 [49] 2019</cell><cell>24.77</cell><cell cols="2">71.31 19.98</cell></row><row><cell cols="2">Payer et al. [40] 2019</cell><cell>20.96</cell><cell cols="2">68.19 21.93</cell></row><row><cell cols="2">Chen et al. [10] 2019</cell><cell>20.10</cell><cell cols="2">59.92 20.14</cell></row><row><cell>Ours</cell><cell cols="2">2020 18.39</cell><cell cols="2">56.72 17.67</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Evaluation on the public Cephalometric dataset. .59 78.11 86.81 90.88 96.74 1.84 69.89 78.95 85.16 92.32 Payer et al. [40] 2019 1.34 81.47 89.36 93.15 97.01 1.65 69.94 78.84 85.74 93.89 Chen et al. [10] 2019 1.17 86.67 92.67 95.54 98.53 1.48 75.05 82.84 88.53 95.05 Ours -1.04 88.49 93.12 95.72 98.42 1.43 76.57 83.68 88.21 94.31</figDesc><table><row><cell>Model</cell><cell>Year</cell><cell>Validation set</cell><cell></cell><cell>Test set</cell></row><row><cell></cell><cell cols="4">MRE 2mm 2.5mm 3mm 4mm MRE 2mm 2.5mm 3mm 4mm</cell></row><row><cell cols="2">Arik et al. [2] 2017 -</cell><cell>75.37 80.91 84.32 88.25</cell><cell>-</cell><cell>67.68 74.16 79.11 84.63</cell></row><row><cell cols="2">HRNet18 [49] 2019 1</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Ablation studies on the effectiveness of the proposed method DAG.</figDesc><table><row><cell></cell><cell cols="4">VGG16 ResNet50 StackedHG4 HRNet18</cell></row><row><cell cols="2">Global feature 4.66</cell><cell>4.33</cell><cell>4.31</cell><cell>4.30</cell></row><row><cell>Local feature</cell><cell>4.42</cell><cell>4.10</cell><cell>3.96</cell><cell>3.72</cell></row><row><cell cols="2">Proposed DAG 3.66</cell><cell>3.65</cell><cell>3.07</cell><cell>3.04</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Ablation study on graph connectivity and shape feature.</figDesc><table><row><cell></cell><cell>w.o Shape Feature</cell><cell>w. Shape Feature</cell></row><row><cell>Self</cell><cell>3.31</cell><cell>3.16</cell></row><row><cell>Uniform</cell><cell>3.16</cell><cell>3.12</cell></row><row><cell>Learned</cell><cell>3.08</cell><cell>3.04</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Ablation studies on the proposed model with 300W fullset under Inter-Ocular normalization.</figDesc><table><row><cell>Different Transformations</cell><cell cols="2">Affine Transformation</cell><cell cols="2">Perspective Transformation (Ours)</cell></row><row><cell>NME</cell><cell></cell><cell>3.13</cell><cell></cell><cell>3.04</cell></row><row><cell cols="5">Effectivenes of GCN modules Replace GCN-global with CNN Replace GCN-local with MLP</cell></row><row><cell>NME</cell><cell></cell><cell>3.12</cell><cell></cell><cell>3.18</cell></row><row><cell>Different GCN Steps</cell><cell>Step=1</cell><cell>Step=3 (Ours)</cell><cell>Step=5</cell><cell>Step=7</cell></row><row><cell>NME</cell><cell>3.24</cell><cell>3.04</cell><cell>3.07</cell><cell>3.11</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Densereg: Fully convolutional dense shape regression in-the-wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alp</forename><surname>Guler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6799" to="6808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fully automated quantitative cephalometry using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">?</forename><surname>Arik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ibragimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14501</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust discriminative response map fitting with constrained local models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Asthana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3444" to="3451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Binarized convolutional landmark localizers for human pose estimation and face alignment with limited resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3706" to="3714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Super-fan: Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Robust face landmark estimation under occlusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">P</forename><surname>Burgos-Artizzu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1513" to="1520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Face alignment by explicit shape regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="177" to="190" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Realtime multi-person 2d pose estimation using part affinity fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7291" to="7299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Anatomy-aware siamese network: Exploiting semantic asymmetry for accurate pelvic fracture detection in x-ray images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Liao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.01464</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Cephalometric landmark detection by attentive feature pyramid fusion and regression-voting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="873" to="881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Active appearance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="681" to="685" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Active shape modelssmart snakes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="266" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Active shape models-their training and application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer vision and image understanding</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="38" to="59" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Feature detection and tracking with constrained local models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cristinacce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: BMVC. vol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2006" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">M3 csr: Multi-view, multi-scale and multicomponent cascade shape regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="19" to="26" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Joint multi-view face alignment in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3636" to="3648" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Detone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03798</idno>
		<title level="m">Deep image homography estimation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Style aggregated network for facial landmark detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="379" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Supervision-byregistration: An unsupervised approach to improve the precision of facial landmark detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sheikh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="360" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Approaching human level facial landmark localization by deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="27" to="35" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Wing loss for robust facial landmark localisation with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Awais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">J</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2235" to="2245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.08347</idno>
		<title level="m">Occlusion coherence: Detecting and localizing occluded faces</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust anatomical landmark detection with application to mr brain image registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Yap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="277" to="290" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improving landmark localization with semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Honari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tyree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1546" to="1555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Recombinator networks: Learning coarse-to-fine feature aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Honari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5743" to="5752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<title level="m">Spatial transformer networks</title>
		<imprint>
			<publisher>NeurIPS</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2017" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Luvli face alignment: Estimating landmarks&apos; location, uncertainty, and visibility likelihood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koike-Akino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="8236" to="8246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Disentangling 3d pose in a dendritic cnn for unconstrained 2d face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="430" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Can gcns go as deep as cnns?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Robust and accurate shape model matching using random forest regression-voting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lindner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Bromiley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Ionita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1862" to="1874" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fast interactive object annotation with curve-gcn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5257" to="5266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Generic face alignment using boosted appearance model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Fashion landmark detection in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="229" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Kuo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.03052</idno>
		<title level="m">Learning to segment anatomical structures accurately from one exemplar</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A deep regression architecture with two-stage re-initialization for high performance facial landmark detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3317" to="3326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Locating facial features with an extended active shape model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Milborrow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nicolls</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="504" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="483" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Regressing heatmaps for multiple landmark localization using cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Payer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>?tern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Urschler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="230" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Integrating spatial configuration into heatmap regression based CNNs for landmark localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Payer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>?tern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Urschler</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.media.2019.03.007</idno>
		<ptr target="https://doi.org/10.1016/j.media.2019.03.007" />
	</analytic>
	<monogr>
		<title level="j">MIA</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="207" to="219" />
			<date type="published" when="2019-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Attentive relational networks for mapping images to scene graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3957" to="3966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Aggregation via separation: Boosting facial landmark detector with semi-supervised style translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10153" to="10163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Face alignment at 3000 fps via regressing local binary features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1685" to="1692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">300 faces in-the-wild challenge: The first facial landmark localization challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CVPRW</publisher>
			<biblScope unit="page" from="397" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Face alignment through subspace constrained mean-shifts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Saragih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="1034" to="1041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Accurate regression procedures for active appearance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMVC. pp</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Efficient and accurate face alignment by global regression and cascaded local refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPRW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5693" to="5703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deep convolutional network cascade for facial point detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3476" to="3483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Quantized densely connected u-nets for efficient landmark localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="339" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Joint training of a convolutional network and a graphical model for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="1799" to="1807" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Deeppose: Human pose estimation via deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="1653" to="1660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Mnemonic descent method: A recurrent process applied for end-to-end face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4177" to="4187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">A deeply-initialized coarseto-fine ensemble of regression trees for face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Buenaposada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vald?s</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Baumela</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="585" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<title level="m">Graph attention networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A benchmark for comparison of dental radiography analysis algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Siao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ibragimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vrtovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIA</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="63" to="76" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Adaptive wing loss for robust face alignment via heatmap regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fuxin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6971" to="6981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Weakly supervised universal fracture detection in pelvic x-rays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="459" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramakrishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sheikh</surname></persName>
		</author>
		<title level="m">Convolutional pose machines</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4724" to="4732" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Session-based recommendation with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: AAAI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="346" to="353" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Look at boundary: A boundary-aware face alignment algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2129" to="2138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Leveraging intra and inter-dataset variations for robust face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPRW</publisher>
			<biblScope unit="page" from="150" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Facial landmark detection: A literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="142" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Supervised descent method and its applications to face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00826</idno>
		<title level="m">How powerful are graph neural networks? arXiv preprint</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Layout-graph reasoning for fashion landmark detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2937" to="2945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Face landmark fitting via optimized part mixtures and cascaded deformable model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2212" to="2226" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Deep deformation network for object landmark localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="52" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Coarse-to-fine auto-encoder networks (cfan) for real-time face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Learning deep representation for face alignment with auxiliary attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="918" to="930" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Semantic graph convolutional networks for 3d human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3425" to="3435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Exemplar-based graph matching for robust facial landmark localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1025" to="1032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Robust facial landmark detection via occlusion-adaptive deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sadiq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3486" to="3496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Face alignment by coarse-to-fine shape searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4998" to="5006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Face alignment across large poses: A 3d solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="146" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Deep learning identity-preserving face space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Learning robust facial landmark detection via hierarchical structured ensemble</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
