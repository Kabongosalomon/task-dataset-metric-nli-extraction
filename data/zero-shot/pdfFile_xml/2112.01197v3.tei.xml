<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sample Prior Guided Robust Model Learning to Suppress Noisy Labels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenkai</forename><surname>Chen</surname></persName>
							<email>wkchen@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Zhu</surname></persName>
							<email>czhu@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chen</surname></persName>
							<email>chenyi@emails.bjut.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Beijing University Of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengting</forename><surname>Li</surname></persName>
							<email>mtli@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Huang</surname></persName>
							<email>tjhuang@pku.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sample Prior Guided Robust Model Learning to Suppress Noisy Labels</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Imperfect labels are ubiquitous in real-world datasets and seriously harm the model performance. Several recent effective methods for handling noisy labels have two key steps: 1) dividing samples into cleanly labeled and wrongly labeled sets by training loss, 2) using semi-supervised methods to generate pseudo-labels for samples in the wrongly labeled set. However, current methods always hurt the informative hard samples due to the similar loss distribution between the hard samples and the noisy ones. In this paper, we proposed PGDF (Prior Guided Denoising Framework), a novel framework to learn a deep model to suppress noise by generating the samples' prior knowledge, which is integrated into both dividing samples step and semi-supervised step. Our framework can save more informative hard clean samples into the cleanly labeled set. Besides, our framework also promotes the quality of pseudo-labels during the semi-supervised step by suppressing the noise in the current pseudo-labels generating scheme. To further enhance the hard samples, we reweight the samples in the cleanly labeled set during training. We evaluated our method using synthetic datasets based on CIFAR-10 and CIFAR-100, as well as on the real-world datasets Web-Vision and Clothing1M. The results demonstrate substantial improvements over state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Deep learning techniques, such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs), have recently achieved great success in object recognition <ref type="bibr" target="#b20">(Montserrat et al. 2017)</ref>, image classification <ref type="bibr" target="#b14">(Krizhevsky, Sutskever, and Hinton 2012)</ref>, and natural language processing (NLP) <ref type="bibr" target="#b40">(Young et al. 2018</ref>). Most existing CNN or RNN deep models mainly rely on collecting large scale labeled datasets, such as ImageNet <ref type="bibr" target="#b24">(Russakovsky et al. 2015)</ref>. However, it is very expensive and difficult to collect a large scale dataset with clean labels <ref type="bibr" target="#b39">(Yi and Wu 2019)</ref>. Moreover, in the real world, noisy labels are often inevitable in manual annotation <ref type="bibr" target="#b27">(Sun et al. 2019)</ref>. Therefore, research on designing robust algorithms with noisy labels is of great significance <ref type="bibr" target="#b33">(Wei et al. 2019</ref>).</p><p>In the literature, a lot of approaches were proposed to improve the learning performance with label noise, such as es- timating the noise transition matrix <ref type="bibr" target="#b6">(Goldberger and Ben-Reuven 2017;</ref><ref type="bibr" target="#b22">Patrini et al. 2017)</ref>, designing noise-robust loss functions <ref type="bibr" target="#b5">(Ghosh, Kumar, and Sastry 2017;</ref><ref type="bibr" target="#b19">Lyu and Tsang 2019;</ref><ref type="bibr" target="#b38">Xu et al. 2019)</ref>, designing noise-robust regularization <ref type="bibr">(Liu et al. 2020;</ref><ref type="bibr" target="#b29">Tanno et al. 2020)</ref>, sample selection <ref type="bibr" target="#b7">(Han et al. 2018;</ref><ref type="bibr" target="#b2">Chen et al. 2019)</ref>, and semisupervised learning <ref type="bibr" target="#b15">(Li, Socher, and Hoi 2020;</ref><ref type="bibr" target="#b4">Cordeiro et al. 2021)</ref>. Recently, methods of semi-supervised learning achieve state-of-the-art performance. They always first divide samples into cleanly labeled and wrongly labeled sets by training loss, and then use semi-supervised methods to generate pseudo-labels for samples in the wrongly labeled set. The sample dividing step is generally based on the small-loss strategy <ref type="bibr" target="#b41">(Yu et al. 2019)</ref>, where at every epoch, samples with small loss are classified as clean data, and large loss as noise. However, the above methods fail in distinguishing informative hard samples from noisy ones due to their similar loss distributions (as depicted in <ref type="figure">Figure 1(a)</ref>, samples in the yellow dotted box are indistinguishable), and thus may neglect the important information of the hard samples <ref type="bibr" target="#b37">(Xiao et al. 2015)</ref>. To the best of our knowledge, there are very few works studying hard samples under noisy label scenarios. Work ) mentioned the hard samples in learning with noisy labels, but that work did not explicitly identify hard samples.</p><p>Although the hard samples and noisy samples cannot be directly distinguished by training loss, we observed that they have different behaviors in training history. Through this intuition, we propose PGDF (Prior Guided Denoising Framework), a novel framework to learn a deep model to suppress noise. We first use the training history to distinguish the hard samples from the noisy ones (as depicted in <ref type="figure">Figure 1(b)</ref>, samples between two thresholds are distinguished by training history). Thus, we classify the samples into three sets by using the prior knowledge. The divided dataset is then guiding the subsequent training process. Our key findings and contributions are summarized as follows:</p><p>? Hard samples and noisy samples can be recognized using training history. We first propose a Prior Generation Module, which generates the prior knowledge to preclassify the samples into an easy set, a hard set, and a noisy set. We further optimize the pre-classification result at each epoch with adaptive sample attribution obtained by Gaussian Mixture Model. ? We realize robust noisy labels suppression based on the divided sets. On one hand, we generate high-quality pseudo-labels by the estimated distribution transition matrix with the divided easy set. On the other hand, we further safely enhance the informative samples in the hard set, while previous existing noisy labels processing methods cannot achieve this because they fail to distinguish the hard samples and noisy ones. ? We experimentally show that our PGDF significantly advances state-of-the-art results on multiple benchmarks with different types and levels of label noise. We also provide the ablation study to examine the effect of different components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>In this section we describe existing works on learning with noisy labels. Typically, the noisy-label processing algorithms can be classified into five categories by exploring different strategies: estimating the noise transition matrix <ref type="bibr" target="#b6">(Goldberger and Ben-Reuven 2017;</ref><ref type="bibr" target="#b22">Patrini et al. 2017)</ref>, designing noise-robust loss functions <ref type="bibr" target="#b5">(Ghosh, Kumar, and Sastry 2017;</ref><ref type="bibr" target="#b19">Lyu and Tsang 2019;</ref><ref type="bibr" target="#b38">Xu et al. 2019;</ref><ref type="bibr">Zhou et al. 2021a,b)</ref>, adding noise-robust regularization <ref type="bibr">(Liu et al. 2020;</ref><ref type="bibr" target="#b29">Tanno et al. 2020)</ref>, selecting sample subset <ref type="bibr" target="#b7">(Han et al. 2018;</ref><ref type="bibr" target="#b2">Chen et al. 2019;</ref><ref type="bibr" target="#b11">Huang et al. 2019)</ref>, and semisupervised learning <ref type="bibr" target="#b15">(Li, Socher, and Hoi 2020;</ref><ref type="bibr" target="#b4">Cordeiro et al. 2021</ref>). In the first category, different transition matrix estimation methods were proposed in <ref type="bibr" target="#b6">(Goldberger and Ben-Reuven 2017;</ref><ref type="bibr" target="#b22">Patrini et al. 2017)</ref>, such as using additional softmax layer <ref type="bibr" target="#b6">(Goldberger and Ben-Reuven 2017)</ref>, and two-step estimating scheme <ref type="bibr" target="#b22">(Patrini et al. 2017</ref>). However, these transition matrix estimations fail in real-world datasets where the utilized prior assumption is no longer valid <ref type="bibr" target="#b8">(Han, Luo, and Wang 2019)</ref>. Being free of transition matrix estimation, the second category targets at designing loss functions that have more noise-tolerant power. Work in <ref type="bibr" target="#b5">(Ghosh, Kumar, and Sastry 2017)</ref> adopted mean absolute error (MAE) which demonstrates more noise-robust ability than crossentropy loss. The authors in work  proposed determinant-based mutual information loss which can be applied to any existing classification neural networks regardless of the noise pattern. Recently, work <ref type="bibr" target="#b46">(Zhou et al. 2021b)</ref> proposed a novel strategy to restrict the model output and thus made any loss robust to noisy labels. Nevertheless, it has been reported that performances with such losses are significantly affected by noisy labels <ref type="bibr" target="#b23">(Ren et al. 2018)</ref>. Such implementations perform well only in simple cases where learning is easy or the number of classes is small. For designing noise-robust regularization, work in <ref type="bibr" target="#b29">(Tanno et al. 2020)</ref> assumed the existence of multiple annotators and introduced a regularized EM-based approach to model the label transition probability. In work <ref type="bibr">(Liu et al. 2020</ref>), a regularization term was proposed to implicitly prevent memorization of the false labels.</p><p>Most recent successful sample selection strategies in the fourth category conducted noisy label processing by selecting clean samples through "small-loss" strategy. Work <ref type="bibr" target="#b12">(Jiang et al. 2018)</ref> pre-trained an extra network, and then used the extra network for selecting clean instances to guide the training. The authors in work <ref type="bibr" target="#b7">(Han et al. 2018</ref>) proposed a Co-teaching scheme with two models, where each model selected a certain number of small-loss samples and fed them to its peer model for further training. Based on this scheme, work  tried to improve the performance by proposing an Iterative Noisy Cross-Validation (INCV) method. Work <ref type="bibr" target="#b11">(Huang et al. 2019</ref>) adjusted the hyper-parameters of model to make its status transfer from overfitting to underfitting cyclically, and recorded the history of sample training loss to select clean samples. This family of methods effectively avoids the risk of false correction by simply excluding unreliable samples. However, they may eliminate numerous useful samples. To solve this shortcoming, the methods of the fifth category based on semi-supervised learning treated the noisy samples as unlabeled samples, and used the outputs of classification models as pseudo-labels for subsequent loss calculations. The authors in <ref type="bibr" target="#b15">(Li, Socher, and Hoi 2020)</ref> proposed DivideMix, which relied on MixMatch <ref type="bibr" target="#b1">(Berthelot et al. 2019</ref>) to linearly combine training samples classified as clean or noisy. Work <ref type="bibr" target="#b4">(Cordeiro et al. 2021</ref>) designed a two-stage method called LongReMix, which first found the high confidence samples and then used the high confidence samples to update the predicted clean set and trained the model. Recently, work <ref type="bibr" target="#b21">(Nishi et al. 2021)</ref> used different data augmentation strategies in different steps to improve the performance of DivideMix, and work <ref type="bibr" target="#b44">(Zheltonozhskii et al. 2022</ref>) used a self-supervised pre-training method to improve the performance of DivideMix.</p><p>The above sample selection strategy and semi-supervised learning strategy both select the samples with clean labels for the subsequent training process. All of their selecting strategies are based on the training loss because the clean samples tend to have small loss during training. However, they will hurt the informative hard samples due to the similar loss distribution between the hard samples and the noisy ones. Our work strives to reconcile this gap by distinguishing the hard samples from the noisy ones by introducing a sample prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>The overview of our proposed PGDF is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. The first stage (Prior Guided Sample Dividing) of PGDF is  dividing the samples into an easy set, a hard set, and a noisy set. The Prior Generation Module first pre-classifies the samples into three sets as prior knowledge; then, at each epoch, the pre-classification result is optimized by the training loss (Sample Dividing Optimization). With the divided sets, the second stage (Denoising with the Divided Sets) conducts label correction for samples with the help of the estimated distribution transition matrix (Pseudo-labels Refining), and then the hard samples are further enhanced (Hard Samples Enhancing). The details of each component are described in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prior Guided Sample Dividing</head><p>Prior Generation Module. Previous work <ref type="bibr" target="#b41">(Zhang et al. 2016)</ref> shows that CNNs tend to memorize simple samples first, and then the networks can gradually learn all the remaining samples, even including the noisy samples, due to the high representation capacity. According to this finding, many methods use the "small-loss" strategy, where at each epoch, samples with small loss are classified as clean data and large loss as noise. Sample with small loss means the prediction probability of the model output is closer to the supervising label. We directly used the normalized probability for analysis since the loss value is just calculated by the Algorithm 1: Prior Generation Module.</p><formula xml:id="formula_0">Input: D = [d 1 , d 2 , ..., d n ], d i is input image, label Y =</formula><p>[y 1 , y 2 , ..., y n ], y i is label for d i , easy samples ratio ? e , part of noisy samples ratio ? n1 Output: easy set D e , hard set D h , noise set D n 1: Train classification model M c by using D and Y , record</p><formula xml:id="formula_1">training history H = [h 1 , h 2 , ..., h n ], where h i is a vec- tor with shape of 1 * k(epoch) 2: Calculate the mean value of H as H m , H m = [mean(h 1 ), mean(h 2 ), ..., mean(h n )], sort D descending by H m , select easy samples D e = D[0 : len(D) * ? e ], select part of noisy samples D n1 = D[len(D) * (1 ? ? n1 ) : len(D)]</formula><p>3: Add noise to D e as D a , get noisy label Y n and record whether it is noise or not R = [r 1 , r 2 , ..., r n ] 4: Retrain M c by D a and Y n , record training history H n 5: Sort H n descending by mean, select training history H n = H n [len(H n ) * ? e : len(H n ) * (1 ? ? n1 )] 6: Train classifier M m by using H n and R 7: Put the samples in D \ (D e ? D n1 ) into M m and get D h and D n2 8: D n = D n1 ? D n2 9: return D e , D h , D n normalized probability and the ground truth label. We first train a CNN classification model with the data, and record the probability history of the model output for each sample on the class of its corresponding label. Then, we calculate the mean prediction probability value of the sample training history which is shown in <ref type="figure">Figure 1</ref>(b). The figure shows the clean sample tends to have a higher mean prediction probability than the noisy one. Therefore, we can set two thresholds (such as the black dotted lines in <ref type="figure">Figure 1(b)</ref>). Samples with mean prediction probability lower than T 1 are almost noisy, while higher than T 2 are almost clean. However, we still cannot distinguish the samples with mean prediction probability between two thresholds. We define this part of clean data as hard samples in our work.</p><p>In order to distinguish the hard samples from the noisy ones, we construct the Prior Generation Module based on the prediction history of the training samples, as depicted by <ref type="figure" target="#fig_2">Figure 3</ref>. For the training set D with N samples, we gradually obtain the corresponding N prediction probability maps through the training of a CNN classification model for k epochs. This module first selects easy samples D e and part of noisy samples D n1 by using the mean prediction probability values. Then we manually add noise to the D e as D a and record whether the sample is noise or not. The noise ratio of the adding noise is the same as the original dataset, which can be known or estimated by the noise cross-validation algorithm of work . After that, we train the same classification model by using D a and record training history again. Then we discard the "easy samples" and part of "noisy samples" of D a according to mean prediction probability, and utilize the rest samples as training data to train the classifier. We use a simple one dimension CNN which contains 3 one dimension convolution layers and a fully connected layer as the classifier here. So far, we will obtain a classifier that takes the prediction probability map of training history as input, and output whether it is a hard sample or a noisy one. Finally, we put the samples in D \ (D e ? D n1 ) into the classifier to get the hard sample set D h and a part of the noisy set D n2 , and we combine D n1 and D n2 as the noisy set D n . Algorithm 1 shows the details of this module.</p><p>Sample Dividing Optimization. Considering the online training loss at each epoch is also important information to help sample dividing, we apply this information to optimize the pre-classification result. Specifically, as shown in <ref type="figure">Figure</ref> 2, at each epoch, we get the clean probability w it of each sample from training loss by using Gaussian Mixture Model (GMM) following previous work <ref type="bibr" target="#b15">(Li, Socher, and Hoi 2020)</ref>. And we have already got the prior knowledge of each sample, we set the clean probability of prior knowledge as w ip from Equation <ref type="formula" target="#formula_2">(1)</ref>,</p><formula xml:id="formula_2">w ip = ? ? ? ? ? 1, d i ? D e p h , d i ? D h 1 ? p n , d i ? D n2 0, d i ? D n1 ,<label>(1)</label></formula><p>where p h is the classifier (M m ) prediction probability for d i to be hard sample and p n is the classifier prediction probability for d i to be noisy sample. Then, we combine w it and w ip to get the clean probability w i by Equation <ref type="formula" target="#formula_3">(2)</ref>,</p><formula xml:id="formula_3">w i = 1, d i ? D e mw it + (1 ? m)w ip , d i ? D h ? D n ,<label>(2)</label></formula><p>where m is a hyper-parameter. Finally, we divide samples with w i equal to 1 into the easy setD e , the samples with 0.5 &lt; w i &lt; 1 are divided into the hard setD h , and the rest samples are divided into the noisy setD n . Each network divides the original dataset for the other network to use to avoid confirmation bias of self-training similar to previous works <ref type="bibr" target="#b7">(Han et al. 2018;</ref><ref type="bibr" target="#b2">Chen et al. 2019;</ref><ref type="bibr" target="#b15">Li, Socher, and Hoi 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Denoising with the Divided Sets</head><p>Pseudo-labels Refining. After the sample dividing phase, we combine the outputs of the two models to generate the pseudo-labels P to conduct label correction, similar to "coguessing" in DivideMix <ref type="bibr" target="#b15">(Li, Socher, and Hoi 2020)</ref>. Considering the samples in the easy set are highly reliable, we can use this part of data to estimate the distribution difference between pseudo-label and the ground truth, which can then be used to refine the pseudo-labels. Given the ground truth label Y , we use a square matrix T to denote the differences between ground truth label distribution? and pseudo-label distributionP , thusP =? T and? =P T ?1 . Specifically, we use the easy setD e and its label YD e to estimate the T to refine P . We first pass the easy setD e to the model and get PD e , where PD e denotes the model outputs ofD e . Then we obtain T , of which the element T i,j can be calculated by Equation <ref type="formula" target="#formula_4">(3)</ref>,</p><formula xml:id="formula_4">T i,j = 1 |N i | n?Ni p n j ,<label>(3)</label></formula><p>where N i consists of samples with the same label of class i in D e , |N i | is the sample number of N i , p n j is the model output softmax probability for class j of the sample n. After that, we refine the pseudo-labels P by Equation <ref type="formula" target="#formula_5">(4)</ref>,</p><formula xml:id="formula_5">P = P T ?1 ,<label>(4)</label></formula><p>whereP is the refined pseudo-labels. BecauseP may contain negative values, we first utilize Equation <ref type="formula" target="#formula_6">(5)</ref> to enable the non-negative matrix, and then perform normalization along the row direction by Equation <ref type="formula" target="#formula_7">(6)</ref> to ensure the summation of elements in each pseudo-label probability vector equal to 1.P = max P , 0 .</p><formula xml:id="formula_6">P ij =P ij / jP ij .<label>(5)</label></formula><p>Finally, the labels of samples in noisy setD n are replaced by the refined pseudo-labelsP . And the label of sample i in hard setD h is replaced by the combination of the refined pseudo-label p i inP and original label y i in Y as Equation <ref type="formula">(7)</ref>, where w i is the clean probability of sample i.</p><formula xml:id="formula_8">y i = w i y i + (1 ? w i )p i . (7)</formula><p>Hard Sample Enhancing. After generating the pseudolabels, the samples in easy set and hard set are grouped in labeled setX , and the noisy set is considered as unlabeled set?. We followed MixMatch <ref type="bibr" target="#b1">(Berthelot et al. 2019)</ref> to "mix" the data, where each sample is randomly interpolated with another sample to generate mixed input x and label p. MixMatch transformsX and? to X and U . To further enhance the informative hard samples, the loss on X is reweighted by w i as shown in Equation <ref type="formula">(8)</ref>, where r is a hyper-parameter. Similar to DivideMix <ref type="bibr" target="#b15">(Li, Socher, and Hoi 2020)</ref>, the loss on U is the mean squared error as shown in Equation <ref type="formula">(9)</ref>, and the regularization term is shown in Equation <ref type="formula" target="#formula_2">(10)</ref>.</p><formula xml:id="formula_9">L X = ? 1 |X | xi?X 1 w r i c p c log (p c model (x i ; ?)) . (8) L U = 1 |U | xi?U p ? p model (x i ; ?) 2 2 . (9) L reg = c ? c log ? c / 1 |X | + |U | xi?X +U p c model (x i ; ?) .</formula><p>(10) Finally the total loss is defined in Equation <ref type="formula" target="#formula_2">(11)</ref>. ? u and ? r follow the same settings in DivideMix.</p><formula xml:id="formula_10">L = L X + ? u L U + ? r L reg .<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment Datasets and Implementation Details</head><p>We compare our PGDF with related approaches on four benchmark datasets, namely CIFAR-10 (Krizhevsky and Hinton 2009), CIFAR-100 (Krizhevsky and Hinton 2009), WebVision <ref type="bibr" target="#b34">(Wen et al. 2017)</ref>, and Clothing1M <ref type="bibr" target="#b31">(Tong et al. 2015)</ref>. Both CIFAR-10 and CIFAR-100 have 50000 training and 10000 testing images of size 32?32 pixels. And CIFAR-10 contains 10 classes and CIFAR-100 contains 100 classes for classification. As CIFAR-10 and CIFAR-100 datasets originally do not contain label noise, following previous works <ref type="bibr" target="#b15">(Li, Socher, and Hoi 2020;</ref><ref type="bibr" target="#b21">Nishi et al. 2021)</ref>, we experiment with two types of label noise: symmetric and asymmetric. Symmetric noise is generated by randomly replacing the labels for a percentage of the training data with all possible labels, and asymmetric noise is designed to mimic the structure of real-world label noise, where labels are only replaced by similar classes (e.g. deer?horse, dog?cat) <ref type="bibr" target="#b15">(Li, Socher, and Hoi 2020)</ref>. WebVision contains 2.4 million images in 1000 classes. Since the dataset is quite large, for quick experiments, we follow the previous works <ref type="bibr" target="#b15">Li, Socher, and Hoi 2020;</ref><ref type="bibr" target="#b36">Wu et al. 2021</ref>) and only use the first 50 classes of the Google image subset. Its noise level is estimated at 20% <ref type="bibr" target="#b27">(Song et al. 2019</ref>). Cloth-ing1M is a real-world dataset that consists of 1 million training images acquired from online shopping websites and it is composed of 14 classes. Its noise level is estimated at 38.5% <ref type="bibr" target="#b27">(Song et al. 2019</ref>).</p><p>In our experiment, we use the same backbones as previous methods to make our results comparable. For CIFAR-10 and CIFAR-100, we use an 18-layer PreAct ResNet <ref type="bibr" target="#b10">(He et al. 2016b</ref>) as the backbone and train it using SGD with a batch size of 128, a momentum of 0.9, a weight decay of 0.0005, and the models are trained for roughly 300 epochs depending on the speed of convergence. The image augmentation strategy is the same as in work <ref type="bibr" target="#b21">(Nishi et al. 2021)</ref>. We set the initial learning rate as 0.02, and reduce it by a factor of 10 after 150 epochs. The warm up period is 10 epochs for CIFAR-10 and 30 epochs for CIFAR-100.</p><p>For WebVision, we use the Inception-ResNet v2 <ref type="bibr" target="#b28">(Szegedy et al. 2017</ref>) as the backbone, and train it using SGD with a momentum of 0.9, a learning rate of 0.01, and a batch size of 32. The networks are trained for 80 epochs and the warm up period is 1 epoch.</p><p>For Clothing1M, we use a ResNet-50 with pre-trained Im-ageNet weights. We train the network using SGD for 80 epochs with a momentum of 0.9, a weight decay of 0.001, and a batch size of 32. The initial learning rate is set as 0.002 and reduced by a factor of 10 after 40 epochs.</p><p>The hyper-parameters proposed in this paper are set in the same manner for all datasets. We set m = 0.5, r = 2, ? e = 0.5 * (1 ? ? ), and ? n1 = 0.5 * ? (? is the estimated noise ratio).  <ref type="bibr" target="#b4">(Cordeiro et al. 2021)</ref>, and DM-AugDesc-WS-SAW 1 <ref type="bibr" target="#b21">(Nishi et al. 2021)</ref>. <ref type="table" target="#tab_0">Table 1</ref> shows the results on CIFAR-10 with different levels of symmetric label noise ranging from 20% to 90% and with 40% asymmetric noise. <ref type="table" target="#tab_1">Table 2</ref> shows the results on CIFAR-100 with different levels of symmetric label noise ranging from 20% to 90%. Following the same metrics in previous works <ref type="bibr" target="#b21">(Nishi et al. 2021;</ref><ref type="bibr" target="#b4">Cordeiro et al. 2021;</ref><ref type="bibr" target="#b15">Li, Socher, and Hoi 2020;</ref><ref type="bibr">Liu et al. 2020)</ref>, we report both the best test accuracy across all epochs and the averaged test accuracy over the last 10 epochs of training. Our PGDF outperforms the state-of-the-art methods across all noise ratios. <ref type="table" target="#tab_2">Table 3</ref> compares PGDF with state-of-the-art methods on (mini) WebVision dataset. Our method outperforms all other methods by a large margin. <ref type="table" target="#tab_3">Table 4</ref> shows the result on Clothing1M dataset. Our method also achieves state-of-theart performance. The result shows our method also works in real-world situations.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Test Accuracy</head><p>Cross-Entropy 69.21 M-correction <ref type="bibr" target="#b0">(Arazo et al. 2019)</ref> 71.00 Meta-Learning  73.47 NCT <ref type="bibr" target="#b25">(Sarfraz, Arani, and Zonooz 2020)</ref> 74.02 ELR+ <ref type="bibr">(Liu et al. 2020)</ref> 74.81 DivideMix <ref type="bibr" target="#b15">(Li, Socher, and Hoi 2020)</ref> 74.76 LongReMix <ref type="bibr" target="#b4">(Cordeiro et al. 2021)</ref> 74.38 DM-AugDesc-WS-SAW <ref type="bibr" target="#b21">(Nishi et al. 2021)</ref> 75.11 PGDF (ours) 75.19</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study</head><p>We study the effect of removing different components to provide insights into what makes our method successful. The result is shown in <ref type="table" target="#tab_4">Table 5</ref>.</p><p>To study the effect of the prior knowledge, we divide the dataset only by w it and change the easy set threshold to 0.95 because there is no value equal to 1 in w it . The result shows the prior knowledge is very effective to save more hard samples and filter more noisy ones. By removing the prior knowledge, the test accuracy decreases by an average of about 0.93%.</p><p>To study the effect of the two networks scheme, we train a single network. All steps are done by itself. By removing the two networks scheme, the test accuracy decreases by an average of about 0.91%.</p><p>To study the effect of the sample dividing optimization, we divide the dataset only by the prior knowledge w ip . The result shows that whether a sample is noisy or not depends not only on the training history, but also on the information of the image itself and the corresponding label. Integrating this information can make judgments more accurate. By removing the sample dividing optimization phase, the test accuracy decreases by an average of about 0.68%.</p><p>To study the effect of the pseudo-labels refining phase, we use the pseudo-labels without being refined by the esti-  mated transition matrix. By removing the pseudo-labels refining phase, the test accuracy decreases by an average of about 0.69%. We also evaluate the pseudo-labels refinement method in DivideMix <ref type="bibr" target="#b15">(Li, Socher, and Hoi 2020)</ref> by replacing our scheme with "co-refinement" and "co-guessing". By replacing our pseudo-labels refining phase with "corefinement" and "co-guessing", the test accuracy decreases by an average of about 0.49%.</p><p>To study the effect of the hard samples enhancing, we remove the hard enhancing component. The decrease in accuracy suggests that by enhancing the informative hard samples, the method yields better performance by an average of 0.30%.</p><p>Among the prior knowledge, two networks, sample dividing optimization, pseudo-labels refining phase, and hard enhancing, the prior knowledge introduces the maximum performance gain. All components have a certain gain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalization to Instance-dependent Label Noise</head><p>Note that the instance-dependent label noise is a new challenging synthetic noise type and would introduce many hard confident samples. We conducted additional experiments on this noise type to better illustrate the superiority of our method. In order to make the comparison fair, we followed the same metrics and used the same noisy label files in work <ref type="bibr" target="#b3">(Chen et al. 2021)</ref>. We compared the recent state-ofthe-art methods in learning with instance-dependent label noise: CAL <ref type="bibr" target="#b47">(Zhu, Liu, and Liu 2021)</ref>, SEAL <ref type="bibr" target="#b3">(Chen et al. 2021)</ref>; and some other baselines <ref type="bibr" target="#b22">(Patrini et al. 2017;</ref><ref type="bibr" target="#b7">Han et al. 2018;</ref><ref type="bibr" target="#b43">Zhang and Sabuncu 2018;</ref><ref type="bibr" target="#b30">Thulasidasan et al. 2019;</ref><ref type="bibr" target="#b38">Xu et al. 2019)</ref>. <ref type="table" target="#tab_5">Table 6</ref> shows the experimental result. Result for "CAL" was re-implemented based on the public code of work <ref type="bibr" target="#b47">(Zhu, Liu, and Liu 2021)</ref>. Other results for previous methods were directly copied from work <ref type="bibr" target="#b3">(Chen et al. 2021</ref>). According to the experimental results, our method outperforms all other methods by a large margin. This shows the generalization ability of our method is well since it also works in complex synthetic label noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-parameters Analysis</head><p>In order to analyze how sensitive PGDF is to the hyperparameters ? e and ? n1 , we trained on different ? e and ? n1 in CIFAR-10 dataset with 50% symmetric noise ratio. Specifically, we first adjusted the value of ? e with fixed ? n1 = 0.25, and thus obtained the sensitivity of PGDF to ? e . Then we adjusted the value of ? n1 with fixed ? e = 0.25, and thus obtained the sensitivity of PGDF to ? n1 . We report both the best test accuracy across all epochs and the averaged test accuracy over the last 10 epochs of training, as shown in Table 9. The result shows that the performance is stable when changing ? e and ? n1 in a reasonable range. Thus, the performance does not highly rely on the pre-defined settings of ? e and ? n1 . Although their settings depend on the noise ratio, they are still easy to set due to the insensitivity. In fact, we set hyper-parameter ? e to select a part of samples which are highly reliable to train the M m (the classifier to distinguish the hard and noisy samples). The settings of ? e and ? n1 are not critical, they just support the algorithm. Analysis of other hyper-parameters is shown in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Why D a Works?</head><p>To study why M m trained on the artificial created D a can recognize hard and noisy samples in original dataset D, we plotted both the mean prediction probability histogram of the clean and noisy samples in CIFAR-10 (50% symmetric noise ratio) D and the corresponding D a . The results are shown in <ref type="figure" target="#fig_3">Figure 4</ref>. According to <ref type="figure" target="#fig_3">Figure 4(b)</ref>, there are also some clean samples which can not be distinguished from the noisy ones by mean prediction probability. Although the samples in D e are all easy ones to dataset D, part of the samples became hard ones to dataset D a . In <ref type="figure" target="#fig_3">Figure 4</ref>, it should be noted that the mean prediction probabilities of samples trained on D a have similar distribution with the original dataset D, and this is why our Prior Generation Module works by using the artificial created D a .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Work with Other SSL Methods</head><p>To utilize the samples which were divided into noisy set, we used MixMatch <ref type="bibr" target="#b1">(Berthelot et al. 2019)</ref> in Section while other SSL methods are also applicable. We found that Fix-Match <ref type="bibr" target="#b26">(Sohn et al. 2020)</ref> as an alternative works even better, and achieves 75.3% accuracy in Clothing1M dataset. Our method is flexible to other SSL methods. However, these augmentation strategies are not the focus of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>The quantifiable behavioral differences between hard and noisy samples are not clear. There could exist other better metrics that can be used to directly distinguish them. Our subsequent work will continue to investigate specific quantifiable metrics to simplify the process of the Prior Generation Module, and how to strengthen hard samples more reasonably is a direction worth studying in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>The existing methods for learning with noisy labels fail to distinguish the hard samples from the noisy ones and thus ruin the model performance. In this paper, we propose PGDF to learn a deep model to suppress noise. We found that the training history can be used to distinguish the hard samples and noisy samples. By integrating our Prior Generation, more hard clean samples can be saved. Besides, our pseudo-labels refining and hard enhancing phase further boost the performance. Through extensive experiments show that PGDF outperforms state-of-the-art performance. <ref type="table">Table 8</ref>: Average test accuracy (%) and stardard deviation on CIFAR-10 with symmetric noise (ranging from 20% to 80%). Results for previous techniques were directly copied from <ref type="bibr" target="#b35">(Wu et al. 2020</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-parameters Analysis</head><p>In order to analyze the sensitivity of the hyper-parameters proposed in this paper, we conduct experiments on CIFAR-10 dataset with 50% symmetric noise ratio. Specifically, we first fixed the hyper-parameters settings as m = 0.5, r = 2, k = 300, ? e = 0.25, and ? n1 = 0.25, then change the value of each hyper-parameter respectively to obtain the sensitivity. The results are shown in <ref type="table">Table 9</ref>. According to <ref type="table">Table 9</ref>, for m and r, the performances of the model increase first, then achieve the peak, and finally decrease with the increase of each parameter. For k, the performance first increases, and then becomes relatively stable when k exceeds a certain threshold. It should be noted that m = 0 is equivalent to the ablation study "PGDF w/o prior knowledge", and m = 1 is equivalent to the ablation study "PGDF w/o sample dividing optimization". <ref type="table">Table 9</ref>: Results in terms of average test accuracy (%, 3 runs) with standard deviation on different "m", "r" and "k" on CIFAR-10 with 50% symmetric noise ratio. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hard and Noisy Sample Behavior Analysis</head><p>To analyze the training process behavior of the hard sample and the noise sample, inspired by (Toneva et al. 2018), we randomly selected 1000 hard samples, 1000 noisy samples on CIFAR-10 with 20% symmetric noise, and calculated the number of "Learning" event and "Forgetting" event of them through the training epochs. The "Learning" event in the t epoch is defined as the prediction probability of the labeled class is less than 0.5 in t ? 1 epoch, while greater than 0.5 in t epoch. The "Forgetting" event in the t epoch is defined as the prediction probability of the labeled class is greater than 0.5 in t ? 1 epoch, while less than 0.5 in t epoch. The statistical result is shown in <ref type="figure" target="#fig_4">Figure 5</ref>. This result shows that the hard sample and the noisy sample have great behavioral differences with the increase of the epoch in training. Before the model converges, the number of learning events and forgetting events of noisy samples is relatively small in the early training stage, and gradually increases as the number of training epochs increases. The learning forgetting events of hard samples are relatively consistent throughout the training process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Time Report</head><p>We recorded the training time of different steps of PGDF on CIFAR-10 with 50% symmetric noise by using a single Nvidia V100 GPU. The results are shown in <ref type="table" target="#tab_0">Table 10</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Wenkai</head><label></label><figDesc>Chen and Chuang Zhu contributed equally to this work. (Corresponding author: Chuang Zhu.) Figure 1: (a) Loss distribution of the clean and noise samples in CIFAR-100 with 50% symmetric noise ratio. (b) Mean prediction probability distribution of the clean and noisy samples in CIFAR-100 with 50% symmetric noise ratio.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>PGDF first generates the prior knowledge by the Prior Generation Module. Then, it trains two models (A and B) simultaneously. At each epoch, a model divides the original dataset into an easy set, a hard set, and a noisy set by combining the prior knowledge and the loss value of each sample. The divided dataset is used by the other network. After the first stage, the models conduct label correction for samples with the help of the estimated distribution transition matrix. Finally, the training loss is reweighted by the dividing result to further enhance the hard samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The overview of the Prior Generation Module. It pre-classifies the samples into an easy set, a hard set, and a noisy set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>(a) Mean prediction probability histogram of the clean and noisy samples in CIFAR-10 (D) with 50% symmetric noise. (b) Mean prediction probability histogram of the clean and noisy samples in corresponding D a .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>The forgetting and learning event histogram on CIFAR-10 with 20% symmetric noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison with state-of-the-art methods in test accuracy (%) on CIFAR-10 with symmetric noise (ranging from 20% to 90%) and 40% asymmetric noise. Results for previous techniques were directly copied from their respective papers.</figDesc><table><row><cell>Noise type</cell><cell></cell><cell></cell><cell cols="2">sym.</cell><cell></cell><cell>asym.</cell></row><row><cell>Method/Noise ratio</cell><cell></cell><cell>20%</cell><cell>50%</cell><cell>80%</cell><cell>90%</cell><cell>40%</cell></row><row><cell>Cross-Entropy</cell><cell>best last</cell><cell>86.8 82.7</cell><cell>79.4 57.9</cell><cell>62.9 26.1</cell><cell>42.7 16.8</cell><cell>85.0 72.3</cell></row><row><cell>Mixup</cell><cell>best</cell><cell>95.6</cell><cell>87.1</cell><cell>71.6</cell><cell>52.2</cell><cell>-</cell></row><row><cell>(Zhang et al. 2018)</cell><cell>last</cell><cell>92.3</cell><cell>77.3</cell><cell>46.7</cell><cell>43.9</cell><cell>-</cell></row><row><cell>M-correction</cell><cell>best</cell><cell>94.0</cell><cell>92.0</cell><cell>86.8</cell><cell>69.1</cell><cell>87.4</cell></row><row><cell>(Arazo et al. 2019)</cell><cell>last</cell><cell>93.8</cell><cell>91.9</cell><cell>86.6</cell><cell>68.7</cell><cell>86.3</cell></row><row><cell>Meta-Learning</cell><cell>best</cell><cell>92.9</cell><cell>89.3</cell><cell>77.4</cell><cell>58.7</cell><cell>89.2</cell></row><row><cell>(Li et al. 2019)</cell><cell>last</cell><cell>92.0</cell><cell>88.8</cell><cell>76.1</cell><cell>58.3</cell><cell>88.6</cell></row><row><cell>ELR+</cell><cell>best</cell><cell>95.8</cell><cell>94.8</cell><cell>93.3</cell><cell>78.7</cell><cell>93.0</cell></row><row><cell>(Liu et al. 2020)</cell><cell>last</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DivideMix</cell><cell>best</cell><cell>96.1</cell><cell>94.6</cell><cell>93.2</cell><cell>76.0</cell><cell>93.4</cell></row><row><cell>(Li, Socher, and Hoi 2020)</cell><cell>last</cell><cell>95.7</cell><cell>94.4</cell><cell>92.9</cell><cell>75.4</cell><cell>92.1</cell></row><row><cell>LongReMix</cell><cell>best</cell><cell>96.2</cell><cell>95.0</cell><cell>93.9</cell><cell>82.0</cell><cell>94.7</cell></row><row><cell>(Cordeiro et al. 2021)</cell><cell>last</cell><cell>96.0</cell><cell>94.7</cell><cell>93.4</cell><cell>81.3</cell><cell>94.3</cell></row><row><cell>DM-AugDesc-WS-SAW</cell><cell>best</cell><cell>96.3</cell><cell>95.6</cell><cell>93.7</cell><cell>35.3</cell><cell>94.4</cell></row><row><cell>(Nishi et al. 2021)</cell><cell>last</cell><cell>96.2</cell><cell>95.4</cell><cell>93.6</cell><cell>10.0</cell><cell>94.1</cell></row><row><cell>PGDF (ours)</cell><cell>best last</cell><cell>96.7 96.6</cell><cell>96.3 96.2</cell><cell>94.7 94.6</cell><cell>84.0 83.1</cell><cell>94.8 94.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison with state-of-the-art methods in test accuracy (%) on CIFAR-100 with symmetric noise (ranging from 20% to 90%). Results for previous techniques were directly copied from their respective papers.</figDesc><table><row><cell>Method/Noise ratio</cell><cell></cell><cell>20%</cell><cell>50%</cell><cell>80%</cell><cell>90%</cell></row><row><cell>Cross-Entropy</cell><cell>best last</cell><cell>62.0 61.8</cell><cell>46.7 37.3</cell><cell>19.9 8.8</cell><cell>10.1 3.5</cell></row><row><cell>Mixup</cell><cell>best</cell><cell>67.8</cell><cell>57.3</cell><cell>30.8</cell><cell>14.6</cell></row><row><cell>(Zhang et al. 2018)</cell><cell>last</cell><cell>66.0</cell><cell>46.6</cell><cell>17.6</cell><cell>8.1</cell></row><row><cell>M-correction</cell><cell>best</cell><cell>73.9</cell><cell>66.1</cell><cell>48.2</cell><cell>24.3</cell></row><row><cell>(Arazo et al. 2019)</cell><cell>last</cell><cell>73.4</cell><cell>65.4</cell><cell>47.6</cell><cell>20.5</cell></row><row><cell>Meta-Learning</cell><cell>best</cell><cell>68.5</cell><cell>59.2</cell><cell>42.4</cell><cell>19.5</cell></row><row><cell>(Li et al. 2019)</cell><cell>last</cell><cell>67.7</cell><cell>58.0</cell><cell>40.1</cell><cell>14.3</cell></row><row><cell>ELR+</cell><cell>best</cell><cell>77.6</cell><cell>73.6</cell><cell>60.8</cell><cell>33.4</cell></row><row><cell>(Liu et al. 2020)</cell><cell>last</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DivideMix</cell><cell>best</cell><cell>77.3</cell><cell>74.6</cell><cell>60.2</cell><cell>31.5</cell></row><row><cell>(Li, Socher, and Hoi 2020)</cell><cell>last</cell><cell>76.9</cell><cell>74.2</cell><cell>59.6</cell><cell>31.0</cell></row><row><cell>LongReMix</cell><cell>best</cell><cell>77.8</cell><cell>75.6</cell><cell>62.9</cell><cell>33.8</cell></row><row><cell>(Cordeiro et al. 2021)</cell><cell>last</cell><cell>77.5</cell><cell>75.1</cell><cell>62.3</cell><cell>33.2</cell></row><row><cell>DM-AugDesc-WS-SAW</cell><cell>best</cell><cell>79.6</cell><cell>77.6</cell><cell>61.8</cell><cell>17.3</cell></row><row><cell>(Nishi et al. 2021)</cell><cell>last</cell><cell>79.5</cell><cell>77.5</cell><cell>61.6</cell><cell>15.1</cell></row><row><cell>PGDF (ours)</cell><cell>best last</cell><cell>81.3 81.2</cell><cell>78.0 77.6</cell><cell>66.7 65.9</cell><cell>42.3 41.7</cell></row><row><cell cols="5">Comparison with State-of-the-Art Methods</cell><cell></cell></row><row><cell cols="6">We compare the performance of PGDF with recent state-of-</cell></row><row><cell cols="6">the-art methods: Mixup (Zhang et al. 2018), M-correction</cell></row><row><cell cols="6">(Arazo et al. 2019), Meta-Learning (Li et al. 2019), NCT</cell></row><row><cell cols="6">(Sarfraz, Arani, and Zonooz 2020), ELR+ (Liu et al.</cell></row><row><cell cols="6">2020), DivideMix (Li, Socher, and Hoi 2020), NGC (Wu</cell></row><row><cell>et al. 2021), LongReMix</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparison with state-of-the-art methods trained on (mini) WebVision dataset in top-1/top-5 accuracy (%) on the WebVision validation set and the ImageNet ILSVRC12 validation set. Results for previous techniques were directly copied from their respective papers.</figDesc><table><row><cell>Method</cell><cell cols="2">WebVision</cell><cell cols="2">ILSVRC12</cell></row><row><cell></cell><cell>top1</cell><cell>top5</cell><cell>top1</cell><cell>top5</cell></row><row><cell>NCT (Sarfraz, Arani, and Zonooz 2020)</cell><cell>75.16</cell><cell>90.77</cell><cell>71.73</cell><cell>91.61</cell></row><row><cell>ELR+ (Liu et al. 2020)</cell><cell>77.78</cell><cell>91.68</cell><cell>70.29</cell><cell>89.76</cell></row><row><cell>DivideMix (Li, Socher, and Hoi 2020)</cell><cell>77.32</cell><cell>91.64</cell><cell>75.20</cell><cell>90.84</cell></row><row><cell>LongReMix (Cordeiro et al. 2021)</cell><cell>78.92</cell><cell>92.32</cell><cell>-</cell><cell>-</cell></row><row><cell>NGC (Wu et al. 2021)</cell><cell>79.16</cell><cell>91.84</cell><cell>74.44</cell><cell>91.04</cell></row><row><cell>PGDF (ours)</cell><cell>81.47</cell><cell>94.03</cell><cell>75.45</cell><cell>93.11</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: Comparison with state-of-the-art methods in test ac-</cell></row><row><cell>curacy (%) on the Clothing1M dataset. Results for previous</cell></row><row><cell>techniques were directly copied from their respective papers.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Ablation study results in terms of average test accuracy (%, 3 runs) with standard deviation on CIFAR-10 with 50% and 80% symmetric noise.</figDesc><table><row><cell>Method/Noise ratio</cell><cell></cell><cell>50%</cell><cell>80%</cell></row><row><cell>PGDF</cell><cell>best last</cell><cell>96.26 ? 0.09 96.15 ? 0.13</cell><cell>94.69 ? 0.46 94.55 ? 0.25</cell></row><row><cell>PGDF w/o prior knowledge</cell><cell>best last</cell><cell>95.55 ? 0.11 95.12 ? 0.19</cell><cell>93.77 ? 0.19 93.51 ? 0.23</cell></row><row><cell>PGDF w/o two networks</cell><cell>best last</cell><cell>95.65 ? 0.35 95.22 ? 0.39</cell><cell>93.84 ? 0.73 93.11 ? 0.80</cell></row><row><cell>PGDF w/o sample dividing optimization</cell><cell>best last</cell><cell>95.73 ? 0.09 95.50 ? 0.12</cell><cell>93.51 ? 0.28 93.20 ? 0.32</cell></row><row><cell>PGDF w/o pseudo-labels refining</cell><cell>best last</cell><cell>95.78 ? 0.26 95.35 ? 0.27</cell><cell>94.06 ? 0.68 93.71 ? 0.52</cell></row><row><cell>PGDF with "co-refinement &amp; co-guessing"</cell><cell>best last</cell><cell>95.91 ? 0.22 95.66 ? 0.29</cell><cell>94.30 ? 0.51 93.81 ? 0.62</cell></row><row><cell>PGDF w/o hard samples enhancing</cell><cell>best last</cell><cell>96.01 ? 0.19 95.78 ? 0.07</cell><cell>94.39 ? 0.28 94.21 ? 0.23</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell cols="5">: Comparison with state-of-the-art methods in terms</cell></row><row><cell cols="5">of average test accuracy (%, 3 runs) on CIFAR-10 with</cell></row><row><cell cols="5">instance-dependent label noise (ranging from 10% to 40%).</cell></row><row><cell>Method</cell><cell>10%</cell><cell>20%</cell><cell>30%</cell><cell>40%</cell></row><row><cell>CE</cell><cell>91.25 ? 0.27</cell><cell>86.34 ? 0.11</cell><cell>80.87 ? 0.05</cell><cell>75.68 ? 0.29</cell></row><row><cell>Forward</cell><cell>91.06 ? 0.02</cell><cell>86.35 ? 0.11</cell><cell>78.87 ? 2.66</cell><cell>71.12 ? 0.47</cell></row><row><cell>Co-teaching</cell><cell>91.22 ? 0.25</cell><cell>87.28 ? 0.20</cell><cell>84.33 ? 0.17</cell><cell>78.72 ? 0.47</cell></row><row><cell>GCE</cell><cell>90.97 ? 0.21</cell><cell>86.44 ? 0.23</cell><cell>81.54 ? 0.15</cell><cell>76.71 ? 0.39</cell></row><row><cell>DAC</cell><cell>90.94 ? 0.09</cell><cell>86.16 ? 0.13</cell><cell>80.88 ? 0.46</cell><cell>74.80 ? 0.32</cell></row><row><cell>DMI</cell><cell>91.26 ? 0.06</cell><cell>86.57 ? 0.16</cell><cell>81.98 ? 0.57</cell><cell>77.81 ? 0.85</cell></row><row><cell>CAL</cell><cell>90.55 ? 0.02</cell><cell>87.42 ? 0.13</cell><cell>84.85 ? 0.07</cell><cell>82.18 ? 0.18</cell></row><row><cell>SEAL</cell><cell>91.32 ? 0.14</cell><cell>87.79 ? 0.09</cell><cell>85.30 ? 0.01</cell><cell>82.98 ? 0.05</cell></row><row><cell>PGDF</cell><cell>94.09 ? 0.27</cell><cell>91.85 ? 0.09</cell><cell>90.64 ? 0.50</cell><cell>87.67 ? 0.32</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Results in terms of average test accuracy (%, 3 runs) with standard deviation on different "? e " and "? n1 " on CIFAR-10 with 50% symmetric noise ratio.</figDesc><table><row><cell>?e</cell><cell>0.2</cell><cell>0.25</cell><cell>0.3</cell><cell>0.35</cell></row><row><cell>best</cell><cell>96.09 ? 0.04</cell><cell>96.26 ? 0.09</cell><cell>96.14 ? 0.08</cell><cell>96.11 ? 0.06</cell></row><row><cell>last</cell><cell>95.98 ? 0.06</cell><cell>96.15 ? 0.13</cell><cell>95.99 ? 0.10</cell><cell>95.93 ? 0.09</cell></row><row><cell>?n1</cell><cell>0.2</cell><cell>0.25</cell><cell>0.3</cell><cell>0.35</cell></row><row><cell>best</cell><cell>96.26 ? 0.12</cell><cell>96.26 ? 0.09</cell><cell>96.25 ? 0.13</cell><cell>96.02 ? 0.07</cell></row><row><cell>last</cell><cell>96.08 ? 0.11</cell><cell>96.15 ? 0.13</cell><cell>96.11 ? 0.16</cell><cell>95.82 ? 0.10</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10 :</head><label>10</label><figDesc>Different steps of training time (hours) on CIFAR-10 with 50% symmetric noise.</figDesc><table><row><cell>Prior Generation Module</cell><cell>Subsequent training process</cell><cell>All</cell></row><row><cell>2.1 h</cell><cell>8.2 h</cell><cell>10.3 h</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The DM-AugDesc-WS-WAW strategy in work<ref type="bibr" target="#b21">(Nishi et al. 2021</ref>) is not considered here because of the unstable reproducibility mentioned in authors' github page. (https://github.com/KentoNishi/Augmentation-for-LNL/)</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix Additional Experiment Results</head><p>Note that there is another criterion for symmetric label noise injection where the true labels cannot be maintained. Work <ref type="bibr" target="#b35">(Wu et al. 2020)</ref> reported the results with the average test accuracy and standard deviation in this criterion. We use the same backbone (ResNet-18 <ref type="bibr" target="#b9">(He et al. 2016a)</ref>) and follow the same metrics as work <ref type="bibr" target="#b35">(Wu et al. 2020)</ref>. The results are reported in <ref type="table">Table 8</ref>. Our method outperforms all other baselines by a large margin. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="312" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05040</idno>
		<title level="m">Understanding and Utilizing Deep Neural Networks Trained with Noisy Labels</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Beyond Class-Conditional Assumption: A Primary Attempt to Combat Instance-Dependent Label Noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Cordeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sachdeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.04173</idno>
		<title level="m">LongReMix: Robust Learning with High Confidence Samples in a Noisy Label Environment</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Robust loss functions under label noise for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Training deep neural-networks using a noise adaptation layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ben-Reuven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8527" to="8537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep self-learning from noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5138" to="5147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Identity Mappings in Deep Residual Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">O2u-net: A simple noisy label detection approach for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3326" to="3334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images. Handbook of Systemic Autoimmune Diseases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">DivideMix: Learning with Noisy Labels as Semi-supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hoi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning to Learn From Noisy Labeled Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kankanhalli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Niles-Weed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fernandez-Granda</surname></persName>
		</author>
		<title level="m">C. 2020. Early-Learning Regularization Prevents Memorization of Noisy Labels</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Curriculum Loss: Robust Learning and Generalization against Label Corruption</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Training object detection and recognition CNN models using data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Montserrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Allebach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Delp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Imaging</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="27" to="36" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Augmentation Strategies for Learning with Noisy Labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hllerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishna Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1944" to="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<title level="m">Learning to Reweight Examples for Robust Deep Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Noisy Concurrent Training for Efficient Learning under Label Noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sarfraz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zonooz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<title level="m">FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Prestopping: How Does Early Stopping Help Generalization against Label Noise?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="168296" to="168306" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Limited Gradient Descent: Learning With Noisy Labels</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Inception-v4, inception-ResNet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning From Noisy Labels by Regularized Estimation of Annotator Confusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tanno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saeedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">An empirical study of example forgetting during deep neural network learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thulasidasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chennupati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mohd-Yusof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Toneva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Combes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10964</idno>
		<idno>arXiv:1812.05159</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Combating label noise in deep learning using abstention</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Symmetric cross entropy for robust learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="322" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Harnessing Side Information for Classification Under Label Noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
		<title level="m">WebVision Database: Visual Learning and Understanding from Web Data</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Topological Filter for Learning with Label Noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="pre" to="proceedings" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-F</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.11035</idno>
		<title level="m">NGC: A Unified Framework for Learning with Open-World Noisy Data</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.03388</idno>
		<title level="m">L dmi: An information-theoretic noise-robust loss function</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Probabilistic End-to-end Noise Correction for Learning with Noisy Labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.07788</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Recent trends in deep learning based natural language processing. ieee Computational intelligenCe magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="55" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">How does Disagreement Help Generalization against Label Corruption?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Understanding deep learning requires rethinking generalization</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<title level="m">mixup: Beyond Empirical Risk Minimization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8778" to="8788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Contrast to divide: Selfsupervised pre-training for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zheltonozhskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Litany</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="1657" to="1667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03110</idno>
		<title level="m">Asymmetric Loss Functions for Learning with Noisy Labels</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning with Noisy Labels via Sparse Regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="72" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A second-order approach to learning with instance-dependent label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10113" to="10123" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
