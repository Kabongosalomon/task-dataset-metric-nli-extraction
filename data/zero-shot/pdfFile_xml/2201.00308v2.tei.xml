<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DiffuseVAE: Efficient, Controllable and High-Fidelity Gener- ation from Low-Dimensional Latents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kushagra</forename><surname>Pandey</surname></persName>
							<email>kushagrap20@iitk.ac.in</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avideep</forename><surname>Mukherjee</surname></persName>
							<email>avideep@cse.iitk.ac.in</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Rai</surname></persName>
							<email>piyush@cse.iitk.ac.in</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Research</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kanpur</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kanpur</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kanpur</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DiffuseVAE: Efficient, Controllable and High-Fidelity Gener- ation from Low-Dimensional Latents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Diffusion probabilistic models have been shown to generate state-of-the-art results on several competitive image synthesis benchmarks but lack a low-dimensional, interpretable latent space, and are slow at generation. On the other hand, standard Variational Autoencoders (VAEs) typically have access to a low-dimensional latent space but exhibit poor sample quality. We present DiffuseVAE, a novel generative framework that integrates VAE within a diffusion model framework, and leverage this to design novel conditional parameterizations for diffusion models. We show that the resulting model equips diffusion models with a low-dimensional VAE inferred latent code which can be used for downstream tasks like controllable synthesis. The proposed method also improves upon the speed vs quality tradeoff exhibited in standard unconditional DDPM/DDIM models (for instance, FID of 16.47 vs 34.36 using a standard DDIM on the CelebA-HQ-128 benchmark using T=10 reverse process steps) without having explicitly trained for such an objective. Furthermore, the proposed model exhibits synthesis quality comparable to state-of-the-art models on standard image synthesis benchmarks like CIFAR-10 and CelebA-64 while outperforming most existing VAE-based methods. Lastly, we show that the proposed method exhibits inherent generalization to different types of noise in the conditioning signal. Our code and model checkpoints are publicly available at https://github.com/kpandey008/DiffuseVAE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Figure 1</ref><p>: DiffuseVAE generated samples on the CelebA-HQ-256 (Left), CelebA-HQ-128 (Middle), <ref type="bibr">Top)</ref> and CelebA-64 (Right, Bottom) datasets using just 25, 10, 25 and 25 time-steps in the reverse process for the respective datasets. The generation is entirely driven by low dimensional latentsthe diffusion process latents are fixed and shared between samples after the model is trained (See Section 4.2 for more details). most VAE-based methods require large latent code hierarchies. Even then, there is still a significant gap in sample quality between VAEs and their implicit-likelihood counterparts like GANs <ref type="bibr" target="#b16">(Goodfellow et al., 2014;</ref><ref type="bibr" target="#b22">Karras et al., 2018;</ref><ref type="bibr" target="#b46">2019;</ref>.</p><p>In contrast, Diffusion Probabilistic Models (DDPM) <ref type="bibr" target="#b54">(Sohl-Dickstein et al., 2015;</ref><ref type="bibr" target="#b20">Ho et al., 2020)</ref> have been shown to achieve impressive performance on several image synthesis benchmarks, even surpassing GANs on several such benchmarks <ref type="bibr" target="#b39">(Dhariwal &amp; Nichol, 2021;</ref>. However, conventional diffusion models require an expensive iterative sampling procedure and lack a low-dimensional latent representation, limiting these models' practical applicability for downstream applications.</p><p>We present DiffuseVAE, a novel framework which combines the best of both VAEs and DDPMs in an attempt to alleviate the aforementioned issues with both types of model families. We present a novel twostage conditioning framework where, in the first stage, any arbitrary conditioning signal (y) can be first modeled using a standard VAE. In the second stage, we can then model the training data (x) using a DDPM conditioned on y and the low-dimensional VAE latent code representation of y. With some simplifying design choices, our framework reduces to a generator-refiner framework which involves fitting a VAE on the training data (x) itself in the first stage followed by modeling x in the second stage using a DDPM conditioned on the VAE reconstructions (x) of the training data,. The main contributions of our work can be summarized as follows:</p><p>1. A novel conditioning framework: We propose a generic DiffuseVAE conditioning framework and show that our framework can be reduced to a simple generator-refiner framework in which blurry samples generated from a VAE are refined using a conditional DDPM formulation (See <ref type="figure" target="#fig_0">Fig.2</ref>). This effectively equips the diffusion process with a low dimensional latent space. As a part of our conditioning framework, we explore two types of conditioning formulations in the second stage DDPM model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Controllable synthesis from a low-dimensional latent:</head><p>We show that, as part of our model design, major structure in the DiffuseVAE generated samples can be controlled directly using the low-dimensional VAE latent space while the diffusion process noise controls minor stochastic details in the final generated samples.</p><p>3. Better speed vs quality tradeoff : We show that DiffuseVAE inherently provides a better speed vs quality tradeoff as compared to a standard DDPM model on several image benchmarks. Moreover, combined with DDIM sampling <ref type="bibr" target="#b55">(Song et al., 2021a)</ref>, the proposed model can generate plausible samples in as less as 10 reverse process sampling steps (For example, the proposed method achieves an FID <ref type="bibr" target="#b18">(Heusel et al., 2018)</ref> of 16.47 as compared to 34.36 by the corresponding DDIM model at T=10 steps on the CelebA-HQ-128 benchmark <ref type="bibr" target="#b22">(Karras et al., 2018)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">State of the art comparisons:</head><p>We show that DiffuseVAE exhibits synthesis quality comparable to recent state-of-the-art on standard image synthesis benchmarks like CIFAR-10 <ref type="bibr" target="#b30">(Krizhevsky, 2009</ref>), CelebA-64 <ref type="bibr" target="#b34">(Liu et al., 2015)</ref>) and CelebA-HQ <ref type="bibr" target="#b22">(Karras et al., 2018)</ref> while maintaining access to a low-dimensional latent code representation.</p><p>5. Generalization to different noises in the conditioning signal: We show that a pre-trained DiffuseVAE model exhibits generalization to different noise types in the DDPM conditioning signal exhibiting the effectiveness of our conditioning framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Variational Autoencoders</head><p>VAEs <ref type="bibr" target="#b47">Rezende &amp; Mohamed, 2016</ref>) are based on a simple but principled encoderdecoder based formulation. Given data x with a latent representation z, learning the VAE is done by maximizing the evidence lower bound (ELBO) on the data log-likelihood, log p(x) (which is intractable to compute in general). The VAE optimization objective can be stated as follows</p><formula xml:id="formula_0">L(?, ?) = E q ? (z|x) [log p ? (x|z)] ? D KL [q ? (z|x) p(z)]<label>(1)</label></formula><p>Under amortized variational inference, the approximate posterior on the latents, i.e., (q ? (z|x)), and the likelihood (p ? (x|z)) distribution can be modeled using deep neural networks with parameters ? and ?, respectively, using the reparameterization trick <ref type="bibr" target="#b47">Rezende &amp; Mohamed, 2016)</ref>. The choice of the prior distribution p(z) is flexible and can vary from a standard Gaussian  to more expressive priors (van den <ref type="bibr">Berg et al., 2019;</ref><ref type="bibr" target="#b17">Grathwohl et al., 2018;</ref><ref type="bibr" target="#b28">Kingma et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Denoising Diffusion Probabilistic Models</head><p>DDPMs <ref type="bibr" target="#b54">(Sohl-Dickstein et al., 2015;</ref><ref type="bibr" target="#b20">Ho et al., 2020)</ref> are latent-variable models consisting of a forward noising process (q(x 1:T |x 0 )) which gradually destroys the structure of the data x 0 and a reverse denoising process ((p(x 0:T ))) which learns to recover the original data x 0 from the noisy input. The forward noising process is modeled using a first-order Markov chain with Gaussian transitions and is fixed throughout training, and the noise schedules ? 1 to ? T can be fixed or learned. The form of the forward process can be summarized as follows:</p><formula xml:id="formula_1">q(x 1:T |x 0 ) = T t=1 q(x t |x t?1 ) (2) q(x t |x t?1 ) = N ( 1 ? ? t x t?1 , ? t I) (3) q(x t |x 0 ) = N ( ?? t x 0 , (1 ?? t )I) where ? t = (1 ? ? t ) and? t = t ? t<label>(4)</label></formula><p>The reverse process can also be parameterized using a first-order Markov chain with a learned Gaussian transition distribution as follows</p><formula xml:id="formula_2">p(x 0:T ) = p(x T ) T t=1 p ? (x t?1 |x t ) (5) p ? (x t?1 |x t ) = N (? ? (x t , t), ? ? (x t , t))<label>(6)</label></formula><p>Given a large enough T and a well-behaved variance schedule of ? t , the distribution q(x T |x 0 ) will approximate an isotropic Gaussian. The entire probabilistic system can be trained end-to-end using variational inference. During sampling, a new sample can be generated from the underlying data distribution by sampling a latent (of the same size as the training data point x 0 ) from p(x T ) (chosen to be an isotropic Gaussian distribution) and running the reverse process. We highly encourage the readers to refer to Appendix A for a more detailed background on diffusion models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DiffuseVAE: VAEs meet Diffusion Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">DiffuseVAE Training Objective</head><p>Given a high-resolution image x 0 , an auxiliary conditioning signal y to be modelled using a VAE, a latent representation z associated with y, and a sequence of T representations x 1:T learned by a diffusion model, the DiffuseVAE joint distribution can be factorized as:</p><formula xml:id="formula_3">p(x 0:T , y, z) = p(z)p ? (y|z)p ? (x 0:T |y, z)<label>(7)</label></formula><p>where ? and ? are the parameters of the VAE decoder and the reverse process of the conditional diffusion model, respectively. Furthermore, since the joint posterior p(x 1:T , z|y, x 0 ) is intractable to compute, we approximate it using a surrogate posterior q(x 1:T , z|y, x 0 ) which can also be factorized into the following conditional distributions: q(x 1:T , z|y, x 0 ) = q ? (z|y, x 0 )q(x 1:T |y, z, x 0 )</p><p>where ? are the parameters of the VAE recognition network (q ? (z|y, x 0 )). As considered in previous works <ref type="bibr" target="#b54">(Sohl-Dickstein et al., 2015;</ref><ref type="bibr" target="#b20">Ho et al., 2020)</ref> we keep the DDPM forward process (q(x 1:T |y, z, x 0 )) nontrainable throughout training. The log-likelihood of the training data can then be obtained as:</p><p>log p(x 0 , y) = log p(x 0:T , y, z)dx 1:T dz</p><p>Since this estimate is intractable to estimate analytically, we optimize the ELBO corresponding to the loglikelihood. It can be shown that the log-likelihood estimate of the data can be approximated using the following lower bound (See Appendix D.1 for the proof)</p><formula xml:id="formula_6">log p(x 0 , y) ? E q ? (z|y,x0) [p ? (y|z)] ? D KL (q ? (z|y, x 0 )||p(z)) L VAE + E z?q(z|y,x0) E q(x 1:T |y,z,x0) p ? (x 0:T |y, z) q(x 1:T |y, z, x 0 ) L DDPM<label>(10)</label></formula><p>We next discuss the choice of the conditioning signal y, some simplifying design choices and several parameterization choices for the VAE and the DDPM models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Simplifying design choices</head><p>In this work we are interested in unconditional modeling of data. To this end, we make the following simplifying design choices:</p><p>1. Choice of the conditioning signal y: We assume the conditioning signal y to be x 0 itself which ensures a deterministic mapping between y and x 0 . Given this choice, we do not condition the reverse diffusion process on y and take it as p ? (x 0:T |z) in Eq. 10.</p><p>2. Choice of the conditioning signal z: Secondly, instead of conditioning the reverse diffusion directly on the VAE inferred latent code z, we condition the second stage DDPM model on the VAE reconstructionx 0 which is a deterministic function of z.</p><p>3. Two-stage training: We train Eq. 10 in a sequential two-stage manner, i.e., first optimizing L VAE and then optimizing for L DDPM in the second stage while fixing ? and ? (i.e. freezing the VAE encoder and the decoder).</p><p>With these design choices, as shown in <ref type="figure" target="#fig_0">Fig. 2</ref>, the DiffuseVAE training objective reduces to simply training a VAE model on the training data x 0 in the first stage and conditioning the DDPM model on the VAE reconstructions in the second stage. We next discuss the specific parameterization choices for the VAE and DDPM models. We also justify these design choices in Appendix E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">VAE parameterization</head><p>In this work, we only consider the standard VAE (with a single stochastic layer) as discussed in Section 2.1. However, in principle, due to the flexibility of the DiffuseVAE two-stage training, more sophisticated, multi-stage VAE approaches as proposed in <ref type="bibr" target="#b46">(Razavi et al., 2019;</ref><ref type="bibr" target="#b9">Child, 2021;</ref> can also be utilized to model the input data x 0 . One caveat of using multi-stage VAE approaches is that we might no longer have access to the useful low-dimensional representation of the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">DDPM parameterization</head><p>In this section, we discuss the two types of conditional DDPM formulations considered in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Formulation 1</head><p>In this formulation, we make the following simplifying assumptions 1. The forward process transitions are conditionally independent of the VAE reconstructionsx and the latent code information z i.e. q(x 1:T |z, x 0 ) ? q(x 1:T |x 0 ).</p><p>2. The reverse process transitions are conditionally dependent on only the VAE reconstruction, i.e., p(x 0:T |z) ? p(x 0:T |x 0 )</p><p>A similar parameterization has been considered in recent work on conditional DDPM models . We concatenate the VAE reconstruction to the reverse process representation x t at each time step t to obtain x t?1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Formulation 2</head><p>In this formulation, we make the following simplifying assumptions 1. The forward process transitions are conditionally dependent on the VAE reconstruction, i.e., q(x 1:T |z, x 0 ) ? q(x 1:T |x 0 , x 0 ) 2. The reverse process transitions are conditionally dependent on only the VAE reconstruction, i.e., p(x 0:T |z) ? p(x 0:T |x 0 ) Specifically, we design the forward process transitions to incorporate the VAE reconstructionx 0 as follows: </p><formula xml:id="formula_7">q(x 1 |x 0 ,x 0 ) = N ( 1 ? ? 1 x 0 +x 0 , ? 1 I)<label>(11)</label></formula><formula xml:id="formula_8">q(x t |x t?1 ,x 0 ) = N ( 1 ? ? t x t?1 + (1 ? 1 ? ? t )x 0 , ? t I) for t &gt; 1</formula><p>It can be shown that the forward conditional marginal in this case becomes (See Appendix D.2 for proof)</p><formula xml:id="formula_9">q(x t |x 0 ,x 0 ) = N ( ?? t x 0 +x 0 , (1 ?? t )I)<label>(12)</label></formula><p>For t = T and a well-behaved noise schedule ? t ,? T ? 0 which implies q(x T |x 0 ,x 0 ) ? N (x 0 , I). Intuitively, this means that the Gaussian N (x 0 , I) becomes our base measure (p(x T )) during inference on which we need to run our reverse process. Since the simplified denoising training formulation proposed in <ref type="bibr" target="#b20">(Ho et al., 2020)</ref> depends on the functional form of the forward process posterior q(x t?1 |x t , x 0 ), this formulation results in several modifications in the standard DDPM training and inference which are discussed in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We now investigate several properties of the DiffuseVAE model. We use a mix of qualitative and quantitative evaluations for demonstrating these properties on several image synthesis benchmarks including CIFAR-10 (Krizhevsky, 2009), CelebA-64 <ref type="bibr" target="#b34">(Liu et al., 2015)</ref> and CelebA-HQ <ref type="bibr" target="#b22">(Karras et al., 2018)</ref> datasets. For quantitative evaluations involving sample quality, we use the FID <ref type="bibr" target="#b18">(Heusel et al., 2018)</ref> metric. We also report the Inception Score (IS) metric <ref type="bibr" target="#b51">(Salimans et al., 2016)</ref> for state-of-the-art comparisons on CIFAR-10. For all the experiments, we set the number of diffusion time-steps (T ) to 1000 during training. The noise schedule in the DDPM forward process was set to a linear schedule between ? 1 = 10 ?4 and ? 2 = 0.02 during training. More details regarding the model and training hyperparameters can be found in Appendix F. Some additional experimental results are presented in Appendix G.     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Generator-refiner framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Controllable synthesis via low-dimensional DiffuseVAE latents</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">DiffuseVAE Interpolation</head><formula xml:id="formula_10">(1) vae + (1 ? ?)z (2)</formula><p>vae for (0 &lt; ? &lt; 1), which are then used to generate the corresponding DiffuseVAE samples. <ref type="figure">Fig. 4</ref> (Middle Row) shows the VAE samples generated by interpolating between two sampled VAE codes as described previously. The corresponding DiffuseVAE generated samples obtained by interpolating in the z vae space are shown in <ref type="figure">Fig. 4</ref> (Top Row). It can be observed that the refined samples corresponding to the blurry VAE samples preserve the overall structure of the image (facial expressions, hair style, gender etc). However, due to the stochasticity in the reverse process sampling in the second stage DDPM model, minor image details (like lip color and minor changes in skin tone) do not vary smoothly between the interpolation samples due to which the overall interpolation is not smooth. This becomes more clear when interpolating the DDPM latent x T while keeping the VAE code z vae fixed as discussed next.</p><p>Interpolation in the DDPM latent space with fixed z vae : Next, we sample the VAE latent code z vae using the standard Gaussian distribution. With a fixed z vae , we then sample two initial DDPM representations x</p><p>(1)</p><p>T and x</p><p>(2) T from the reverse process base measure p(x T ). We then perform linear interpolation between x</p><p>(1) T and x</p><p>(2) T with a fixed z vae to generate the final DiffuseVAE samples (Note that interpolation is not performed on other DDPM latents, x 1:T , which are obtained using ancestral sampling from the corresponding x T 's as usual). <ref type="figure" target="#fig_4">Fig 5 shows</ref> the DiffuseVAE generated samples with a fixed z vae and the interpolated x T . As can be observed, interpolating in the DDPM latent space leads to changes in minor features (skin tone, lip color, collar color etc.) of the generated samples while major image structure (face orientation, gender, facial expressions) is preserved across samples. This observation implies that the low-dimensional VAE latent code mostly controls the structure and diversity of the generated samples and has more entropy than the DDPM representations x T , which carry minor stochastic information. Moreover, this results in non-smooth DiffuseVAE interpolations. We discuss a potential remedy next.</p><p>Handling the DDPM stochasticity: The stochasticity in the second stage DDPM sampling process can occasionally result in artifacts in DiffuseVAE samples which might be undesirable in downstream applications. To make the samples generated from DiffuseVAE deterministic (i.e. controllable only from z vae ), we simply share all stochasticity in the DDPM reverse process (i.e. due to x T and z t ) across all generated samples. This simple technique adds more consistency in our latent interpolations as can be observed in <ref type="figure">Fig. 4</ref>   implies using the same stylization for all refined samples leading to smoothness between interpolations.</p><p>Having achieved more consistency in our interpolations, we can now utilize the low-dimensional VAE latent code for controllable synthesis which we discuss next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">From Interpolation to Controllable Generation</head><p>Since DiffuseVAE gives us access to the entire low dimensional VAE latent space, we can perform image manipulation by performing vector arithmetic in the VAE latent space (See Appendix G.2 for details). The resulting latent code can then be used to sample from DiffuseVAE to obtain a refined manipulated image. As discussed in the previous section, we share the DDPM latents across samples to prevent the generated samples from using different styles. <ref type="figure" target="#fig_5">Fig. 6</ref> demonstrates single-attribute image manipulation using DiffuseVAE on several attributes like Gender, Age and Hair texture. Moreover, the vector arithmetic in the latent space can be composed to generate composite edits (See <ref type="figure" target="#fig_5">Fig. 6</ref>), thus signifying the usefulness of a low-dimensional latent code representation. Some additional results on image manipulation are illustrated in <ref type="figure" target="#fig_0">Fig. 12</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Better Sampling Speed vs Quality tradeoffs with DiffuseVAE</head><p>There exists a trade-off between the number of reverse process sampling steps vs the quality of the generated samples in DDPMs. Usually the best sample quality is achieved when the number of reverse process steps used during inference matches the number of time-steps used during training. However, this can be very time-consuming <ref type="bibr" target="#b55">(Song et al., 2021a)</ref>. On the other hand, as the number of reverse process steps is reduced, the sample quality gets worse. We next examine this trade-off in detail. <ref type="table" target="#tab_3">Table 2</ref> compares the sample quality (in terms of FID) vs the number of sampling steps between DiffuseVAE and our unconditional DDPM baseline on the CelebA-HQ-128 dataset. For all time-steps T = 10 to T = 100, DiffuseVAE outperforms the standard DDPM by large margins in terms of FID. Between DiffuseVAE formulations, the sample quality is similar with Formulation-1 performing slightly better. More notably, the FID score of DiffuseVAE at T = 25 and 50 is better than that of unconditional DDPM at T = 50 and 100 respectively. Thus, in low time-step regimes, the speed vs quality tradeoff in DiffuseVAE is significantly better than an unconditional DDPM baseline. It is worth noting that this property is intrinsic to DiffuseVAE as the model was not specifically trained to reduce the number of reverse process sampling steps during inference <ref type="bibr" target="#b50">(Salimans &amp; Ho, 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with a baseline unconditional DDPM:</head><p>However, at T = 1000 the unconditional DDPM baseline performs better than both DiffuseVAE formulations-1 and 2. We hypothesize that this gap in performance can be primarily attributed to the prior-hole problem, i.e., the mismatch between the VAE prior p(z) and the aggregated posterior q(z) <ref type="bibr" target="#b1">(Bauer &amp; Mnih, 2019;</ref><ref type="bibr" target="#b11">Dai &amp; Wipf, 2019;</ref><ref type="bibr" target="#b15">Ghosh et al., 2020)</ref> due to which VAEs can generate poor samples from regions of the latent space unseen during training. DDPM refinement of such samples can affect the FID scores negatively. We confirm this hypothesis next.</p><p>Improving DiffuseVAE sample quality using post-fitting: One way to alleviate the prior-hole problem is to fit a density estimator (denoted by Ex-PDE) on the training latent codes and sample from this estimator during inference as in <ref type="bibr" target="#b62">(van den Oord et al., 2017;</ref><ref type="bibr" target="#b46">Razavi et al., 2019;</ref><ref type="bibr" target="#b15">Ghosh et al., 2020)</ref>. Along similar lines, we fit a GMM on the VAE latent code representations of the training data. We then use this estimator to sample VAE latent codes during DiffuseVAE sampling.   <ref type="bibr" target="#b43">(Parmar et al., 2021)</ref> 17.90 8.2 NVAE  51.67 5.51 NCP-VAE <ref type="bibr" target="#b0">(Aneja et al., 2020)</ref> 24.08 -LSGM (FID)  2.10 -D2C  10.15 -</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GAN-based methods</head><p>AutoGAN <ref type="bibr" target="#b5">(Cao et al., 2020)</ref> 12.4 8.55 ? 0.1 BigGAN <ref type="bibr" target="#b2">(Brock et al., 2018)</ref> 14.73 9.22 StyleGAN2 (w/o ADA) <ref type="bibr" target="#b23">(Karras et al., 2019)</ref> 8.32 9.21 ? 0.09 Progressive GAN <ref type="bibr" target="#b22">(Karras et al., 2018)</ref> -8.8 SNGAN <ref type="bibr" target="#b38">(Miyato et al., 2018)</ref> 21.7 8.22 ? 0.05 SNGAN + DDLS <ref type="bibr" target="#b6">(Che et al., 2021)</ref> 15.42 9.09 ? 0.10</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Score-based methods</head><p>NCSN <ref type="bibr" target="#b56">(Song &amp; Ermon, 2020a)</ref> 25.32 8.87 ? 0.12 NCSNv2 (w/denoising) <ref type="bibr" target="#b57">(Song &amp; Ermon, 2020b)</ref> 10.87 8.40 ? 0.07 DDPM <ref type="bibr" target="#b20">(Ho et al., 2020)</ref> 3.17 9.46 ? 0.11 SDE (NCSN++) <ref type="bibr" target="#b58">(Song et al., 2021b)</ref> 2.45 9.73 SDE (DDPM++) <ref type="bibr" target="#b58">(Song et al., 2021b)</ref> 2.78 9.64 <ref type="table">Table 4</ref>: Generative performance on unconditional CIFAR-10. FID and IS computed on 50k samples Ex-PDE during sampling leads to a reduced gap in sample quality at T = 1000, thereby confirming our hypothesis. We believe that the remaining gap can be closed by using stronger density estimators which we do not explore in this work. Moreover, a side benefit of using a Ex-PDE during sampling is further improvement in the speed-quality tradeoff.</p><p>Further improvements with DDIM: DDIM (Song et al., 2021a) employs a non-Markovian forward process and achieves a better speed-quality tradeoff than DDPM along with deterministic sampling. Since DiffuseVAE employs a DDPM model in the refiner stage, we found DDIM sampling to be complementary with the DiffuseVAE framework. Notably, since the forward process for DiffuseVAE (Form-2) is different, we derive the DDIM updates for this formulation in Appendix B.  <ref type="bibr" target="#b0">(Aneja et al., 2020)</ref> 5.25 VAEBM <ref type="bibr" target="#b66">(Xiao et al., 2021)</ref> 5.31 NVAE  14.74 NCSN <ref type="bibr" target="#b56">(Song &amp; Ermon, 2020a)</ref> 25.30 NCSNv2 <ref type="bibr" target="#b57">(Song &amp; Ermon, 2020b)</ref> 10.23 QA-GAN <ref type="bibr" target="#b42">(PARIMALA &amp; Channappayya, 2019)</ref> 6.42 COCO- <ref type="bibr">GAN (Lin et al., 2020)</ref> 4.0  <ref type="bibr" target="#b14">(Esser et al., 2020)</ref> 10.2 D2C  18.74 DCVAE <ref type="bibr" target="#b43">(Parmar et al., 2021)</ref> 15.81 VAEBM <ref type="bibr" target="#b66">(Xiao et al., 2021)</ref> 20.38 NCP-VAE <ref type="bibr" target="#b0">(Aneja et al., 2020)</ref> 24.8 NVAE  40.26 <ref type="table">Table 6</ref>: Generative performance on CelebA-HQ-256</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">State-of-the-art comparisons</head><p>For reporting comparisons with the state-of-the-art we primarily use the FID <ref type="bibr" target="#b18">(Heusel et al., 2018)</ref> metric to assess sample quality. We compute FID on 50k samples for CIFAR-10 and CelebA-64. For comparisons on the CelebA-HQ-256 dataset, we report the FID only for 10k samples (as opposed to 30k samples which is the norm on this benchmark) due to compute limitations. Due to this, we anticipate the true FID score on this benchmark using our method to be lower. However, as we show, the FID score obtained by DiffuseVAE on this benchmark on 10k samples is still comparable to state-of-the-art. <ref type="table">Table 4</ref> shows quantitative comparison between DiffuseVAE (Form-1) and other state-of-the-art generative models in terms of sample quality (FID@50k) and sample diversity (IS) on the CIFAR-10 dataset. DiffuseVAE with Ex-PDE outperforms the DDPM baseline while performing similarly even without Ex-PDE estimation in terms of FID. DiffuseVAE also maintains a good sample diversity (in terms of IS) competitive with recent continuous score-based methods <ref type="bibr" target="#b58">(Song et al., 2021b)</ref>. Notably, with the exception of LSGM , DiffuseVAE outperforms all prior state-of-the-art VAE-based methods <ref type="bibr" target="#b66">Xiao et al., 2021;</ref>, even when most of these methods utilize powerful hierarchical VAE-based backbones. In contrast, DiffuseVAE utilizes a simple VAE backbone with a very poor baseline FID score and it would be interesting to benchmark LSGM using a simple VAE backbone as ours (some initial evaluations on CIFAR-10 already suggest that LSGM might perform much worse than DiffuseVAE with a simple VAE baseline 1 ). In this work our CIFAR-10 model is the same size as in <ref type="bibr" target="#b20">(Ho et al., 2020)</ref> which is an order of magnitude smaller than LSGM (See <ref type="table" target="#tab_0">Table 14</ref>). Moreover, we believe that, like LSGM, DiffuseVAE can also take advantage of larger model sizes (See Appendix G.4).</p><p>We also benchmarked DiffuseVAE (with Ex-PDE) on two popular face image benchmarks: CelebA-64 and CelebA-HQ-256. On the CelebA-64 benchmark, DiffuseVAE performs comparably with the DDPM baseline. Similar to CIFAR10, DiffuseVAE outperforms other VAE-based methods <ref type="bibr" target="#b0">Aneja et al., 2020;</ref><ref type="bibr" target="#b66">Xiao et al., 2021</ref>) by a significant margin. We observed similar trends on the CelebA-HQ-256 dataset where DiffuseVAE outperforms competing VAE based methods except LSGM and is comparable to VQGAN <ref type="bibr" target="#b14">(Esser et al., 2020)</ref>. However, when comparing with LSGM on this benchmark, similar arguments as pointed out for CIFAR-10 hold. Interestingly, we found that for CelebA-HQ-256 dataset, samples generated during intermediate training stages (and even after convergence) suffer from color bleeding. We found that this problem can be alleviated by using temperature sampling in the second stage DDPM latents (Appendix G.4). Therefore, only for T = 1000, we report the FID scores on this benchmark with a scaling factor of 0.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Generalization to different noise types</head><p>To test if DiffuseVAE can generalize over different types of noisy conditioning signals during sample generation, we condition the second stage DDPM model in DiffuseVAE (pre-trained on the CIFAR-10 dataset) on different types of noisy conditioning signals (instead of the VAE reconstruction). More specifically, we experiment with two such types of conditioning signals obtained by adding noise to CIFAR-10 test samples: downsampling CIFAR samples to 16x16 resolution (effectively blurring them when scaled back) and adding Gaussian noise (with standard deviation = 0.3). Final DiffuseVAE samples obtained after conditioning on these noisy inputs are visualized in <ref type="figure" target="#fig_6">Fig. 7</ref>. We observed that DiffuseVAE is able to recover the original samples from the noisy inputs which demonstrates generalization to different noisy conditioning inputs.</p><p>Intuitively, these results can be expected since, during training, the proposed DiffuseVAE method learns to refine VAE reconstructions which lack a lot of detail. Hence the task of refining these reconstructions might be more challenging, thus allowing the network to generalize to simpler tasks inherently as illustrated above. However, it is worth noting that certain artifacts in the generated reconstructions are evident, leaving scope for design of more stronger conditioning mechanisms in diffusion models that allow to adapt conditional diffusion models on downstream tasks like image super-resolution in an out-of-the-box fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Following the seminal work of (Sohl-Dickstein et al., 2015; Ho et al., 2020) on diffusion models, there has been a lot of recent progress in both unconditional <ref type="bibr" target="#b39">(Nichol &amp; Dhariwal, 2021;</ref><ref type="bibr" target="#b39">Dhariwal &amp; Nichol, 2021;</ref><ref type="bibr">Kingma et al., 2021)</ref> and conditional diffusion models <ref type="bibr" target="#b10">Choi et al., 2021;</ref> (including score-based models <ref type="bibr" target="#b58">(Song et al., 2021b;</ref><ref type="bibr" target="#b56">Song &amp; Ermon, 2020a)</ref>) for a variety of downstream tasks including image synthesis, audio synthesis and likelihood estimation among others. Here we only compare DiffuseVAE to recent methods which attempt to combine VAEs with diffusion models. We refer the readers to Appendix C for a detailed comparison of DiffuseVAE to other types of model families.</p><p>Among recent advances, D2C ) utilizes a learned diffusion-based prior over the VAE latent representations for few-shot conditional generation while also refining the VAE latent space using a contrastive loss. We hypothesize this kind of a framework to be complementary to DiffuseVAE. LSGM  performs score-based generative modeling in the latent space of an expressive hierarchical VAE like NVAE . In contrast, DiffuseVAE uses a simple VAE backbone which equips diffusion models with a low-dimensional latent code. <ref type="bibr" target="#b36">(Luo &amp; Hu, 2021</ref>) present a probabilistic autoencoding framework for point cloud generation via a VAE-like encoder and a diffusion model based decoder. Notably, the most closest to our approach is the concurrent work on DiffAE <ref type="bibr">(Preechakul et al., 2022)</ref> which uses an end-to-end autoencoding framework for conditioning the diffusion process decoder on the latent code output of an encoder. This equips the diffusion model with a low-dimensional latent space. However, since the model is non-probabilistic, DiffAE relies on fitting a powerful DDIM density estimator on the latent space of the encoder to enable sampling. Moreover, it's unclear if DiffAE exhibits good sample quality when fitting simple density estimators on the encoder latent space. In contrast, sampling in DiffuseVAE is straightforward due to a probabilistic formulation. Additionally, DiffuseVAE can also take advantage of fitting external density estimators on the latent space as demonstrated in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Limitations and Discussion</head><p>In this work, we presented a novel unifying framework for training VAEs and diffusion models and demonstrated its effectiveness in generating high-quality samples, providing a better sample quality vs number of steps trade-off while equipping DDPM with a low dimensional latent code which can be used for controllable synthesis using DDPM, and generalizing to different types of noise in the conditioning signal. However, the DiffuseVAE model is not without its limitations. Due to a generator-refiner framework, the semantics of the final generated samples depends largely on the coarse sample generated by the generator model (a simple VAE in our case). Therefore, if the coarse sample is not semantically meaningful, this will propagate to the final generated sample after refinement. This can be expected from VAEs due to a mismatch between the aggregated posterior q(z) and the prior p(z) during VAE training which we alleviate using Ex-PDE estimation but the problem still persists (which is evident from the gap in sample quality between an unconditional DDPM baseline and DiffuseVAE even after Ex-PDE). We also observed that when the conditioning signal provided by the first stage VAE is uninformative (too blurry), the second stage DDPM model can generate unpredictable refinements. On this note, it would be interesting to explore the impact of the VAE sample quality on the overall sample quality of the model. Lastly, it would be interesting to explore stronger conditioning mechanisms in the context of diffusion models which reduce the reliance of the final sample on the stochastic DDPM sub-code. In the context of DiffuseVAE, this can also be useful in improving model generalization to downstream tasks like image super-resolution and denoising as presented in Section 4.5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact Statement</head><p>In addition to modelling images, our proposed approach can also be used to model data of other modalities like speech, text, etc. It has the potential to mitigate bias and privacy issues for related ML models that require data collection and annotation. However, such techniques could also be misused to produce fake or misleading information, and researchers should be aware of these risks and explore the proposed approaches responsibly.  <ref type="figure">Fig. 8</ref>) and a reverse denoising process (p(x 0:T )) (corresponding to a generator or decoder in VAEs. See <ref type="figure">Fig. 9</ref>). The forward process is modeled using a Markov chain which gradually destroys the structure of the data x 0 over a number of time-steps T. Similarly, the reverse process is also modeled as a Markov chain which learns to recover the original data x 0 from the noisy input x T . The form of the forward process and some notable properties of the forward process conditional distributions are summarized in the following equations ).</p><p>q(x 1:</p><formula xml:id="formula_11">T |x 0 ) = T t=1 q(x t |x t?1 ) (13) q(x t |x t?1 ) = N ( 1 ? ? t x t?1 , ? t I)<label>(14)</label></formula><p>The forward process of DDPMs admits a closed form for x t for any t, as follows:</p><formula xml:id="formula_12">q(x t |x 0 ) = N ( ?? t x 0 , (1 ?? t )I) (15) where ? t = (1 ? ? t ) and? t = t ? t<label>(16)</label></formula><p>The forward process posteriors are also tractable and are given by</p><formula xml:id="formula_13">q(x t?1 |x t , x 0 ) = N (? t (x t , x 0 ),? t ) (17) where? t (x t , x 0 ) = ?? t?1 ? t 1 ?? t x 0 + ? ? t (1 ?? t?1 ) 1 ?? t x t<label>(18)</label></formula><formula xml:id="formula_14">and? t = 1 ?? t?1 1 ?? t ? t<label>(19)</label></formula><p>The reverse process can also be parameterized using a first-order Markov chain with a learned Gaussian transition distribution as follows</p><formula xml:id="formula_15">p(x 0:T ) = p(x T ) T t=1 p ? (x t?1 |x t ) (20) p ? (x t?1 |x t ) = N (? ? (x t , t), ? ? (x t , t)) (21) p ? (x t?1 |x t ) = N (? ? (x t , t), ? ? (x t , t))<label>(22)</label></formula><p>Given a large enough T and a well-behaved variance schedule of ? t , the distribution q(x T |x 0 ) will approximate an isotropic Gaussian. We can generate a new sample from the underlying data distribution q(x 0 ) by sampling a latent from p(x T ) (chosen to be an isotropic Gaussian distribution) and running the reverse process. As proposed in <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>, the reverse process in DDPM is trained to minimize the following upper bound over the negative log-likelihood (See <ref type="bibr" target="#b54">(Sohl-Dickstein et al., 2015)</ref> for detailed proofs):</p><formula xml:id="formula_16">E q D KL (q(x T |x 0 ) p(x T )) + t&gt;1 D KL (q(x t?1 |x t , x 0 ) p ? (x t?1 |x t )) ? log p ? (x 0 |x 1 )<label>(23)</label></formula><p>A notable aspect of the above objective is that all the KL divergences involve Gaussians and, consequently, are available in closed form. Notably, <ref type="bibr" target="#b20">(Ho et al., 2020)</ref> parameterize the reverse process conditional p ? (x t?1 |x t ) using the forward process posterior q(x t?1 |x t , x 0 ). <ref type="bibr" target="#b20">(Ho et al., 2020)</ref> show that such a parameterization simplifies the second term in Eq. 23 at any given time-step t to the following objective in Eq. 24. <ref type="figure">and ? N (0, I)</ref>. Intuitively, this means that the reverse process in DDPM is trained to predict the noise added to the input x 0 at any time-step t. We use this simplified training formulation throughout our work to train all proposed parameterizations of diffusion models as <ref type="bibr" target="#b20">(Ho et al., 2020)</ref> show that this formulation yields superior sample quality than other forms of reverse process parameterizations. For further details on the exact training and inference processes, we encourage the readers to refer to <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>.</p><formula xml:id="formula_17">? ? ( ?? t x 0 + ? 1 ?? t , t)) 2 2 (24) where x t = ?? t x 0 + ? 1 ?? t</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Discussion of DiffuseVAE (Formulation-2)</head><formula xml:id="formula_18">Algorithm 1 DDPM Training (Form. 2) repeat x 0 ? q(x 0 ) x 0 = V AE(x 0 ) t ? Uniform({1 . . . T}) ? N (0, I) Take gradient descent step on: ? ? ? ( ?? t x 0 +x 0 + ? 1 ?? t , t,x 0 ) 2 until convergence Algorithm 2 DDPM Inference (Form. 2) z vae ? N (0, I) y = VAEDEC(z vae ) x T ? N (y, I) for t = T to 1 do z = N (0, I), if t &gt; 1 else 0 x 0 = 1 ?? t (x t ? y ? ? (x t , y, t) ? 1 ?? t ) x t?1 = ? 0x0 + ? 1 x t + ? 2 y x t?1 =x t?1 + z? t end for return x 0 ? y</formula><p>The DDPM training objective proposed in <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>, has the following form:</p><formula xml:id="formula_19">E q D KL (q(x T |x 0 ) p(x T )) L T + t&gt;1 D KL (q(x t?1 |x t , x 0 ) p ? (x t?1 |x t )) Lt?1 ? log p ? (x 0 |x 1 ) L0 (25)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Reverse Process parameterization</head><p>Following <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>, we parameterize the reverse process transition p ? (x t?1 |x t ) using the functional form of the forward process posterior q(x t?1 |x t , x 0 ). For the DiffuseVAE formulation proposed in Section 3.4.2 in our paper, the forward process conditional distributions can be specified as:</p><formula xml:id="formula_20">q(x t |x t?1 ,x 0 ) = N 1 ? ? t x t?1 + (1 ? 1 ? ? t )x 0 , ? t I where t &gt; 1 (26) q(x t |x 0 ,x 0 ) = N ?? t x 0 +x 0 , (1 ?? t )I<label>(27)</label></formula><p>The posterior distribution q(x t?1 |x t , x 0 ,x 0 ) will also be a Gaussian distribution with the following form:</p><formula xml:id="formula_21">q(x t?1 |x t , x 0 ,x 0 ) = N (? t (x t , x 0 ,x 0 ),? t I) (28) where,? t (x t , x 0 ,x 0 ) = ? t ?? t?1 1 ?? t x 0 + (1 ?? t?1 ) ? ? t 1 ?? t x t ?t(xt,x0) + (1 ? (1 ?? t?1 ) ? ? t 1 ?? t ) ?x 0 (29) ? t = (1 ?? t?1 ) 1 ?? t ? t and x 0 = 1 ?? t (x t ?x 0 ? ? 1 ?? t ) where ? N (0, I)<label>(30)</label></formula><p>Hence the forward process posterior in this DiffuseVAE formulation is a shifted version of the forward process posterior proposed in <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>. Since the VAE reconstructionx 0 for an image x 0 is constant during DDPM training, we can parameterize the reverse process posterior as? ? (x t , x 0 ,x 0 , t) =? ? (x t , x 0 , t) + ?x 0 . Additionally, we keep the variance of the reverse process conditional fixed and equal to? t as proposed in <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>. Since L t?1 ? ? t (x t , x 0 , y) ?? ? (x t , x 0 , y, t) 2 , the DDPM training objective in our formulation remains unchanged from the simplified denoising score matching objective proposed in <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Choice of the decoder, L 0</head><p>One possible choice for the decoder is to set p ? (x 0 |x 1 ) to be a discrete independent decoder derived from the Gaussian N (? ? (x 1 ,x 0 , 1),? 1 I) <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>. However, at t = 1, we have? ? (x 1 ,x 0 , 1) = x 0 (x 1 ,x 0 , ? )+x 0 . Therefore, to account for the VAE reconstruction bias in the final DDPM output, we set our decoder p ? (x 0 |x 1 ) = N (? ? (x 1 ,x 0 , 1) ?x 0 ,? 1 I). Without using this adjustment, we found the final DDPM samples to be a bit blurry in our initial experiments.The final training and inference algorithms are summarized in Algorithms 1 and 2 respectively. In Algorithm 2, the coefficients ? 0 , ? 1 and ? 2 denote the coefficients of the forward process posterior in Eqn. 29.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Integration with DDIM</head><p>We now derive the updates for the DiffuseVAE formulation-2 when combined with DDIM sampling. Given the form of the forward process marginal as in Eqn. 27, we assume the following form of the forward process posterior:</p><formula xml:id="formula_22">q(x t?1 |x t ,x 0 , x 0 ) = N (? t , ? 2 t ) (31) ? t = ? t?1 x 0 + 1 ?? t?1 ? ? 2 t x t ? ?? t x 0 ? 1 ?? t + ?x 0 (32) ? 2 t = ? 1 ?? t?1 1 ?? t 1 ?? t ? t?1<label>(33)</label></formula><p>We now have,</p><formula xml:id="formula_23">q(x t?1 |x 0 ,x 0 ) = q(x t?1 |x t , x 0 ,x 0 )q(x t |x 0 ,x 0 )dx t<label>(34)</label></formula><p>Since both the distributions within the integral are gaussians, the resulting marginal will also be a gaussian with the following form:</p><formula xml:id="formula_24">q(x t?1 |x 0 ,x 0 ) = N (? t ,? 2 t ) (35) ? t = ? t?1 x 0 + ? + 1 ?? t?1 ? ? 2 t ? 1 ?? t x 0 (36) ? 2 t = 1 ?? t?1<label>(37)</label></formula><p>However, we already know the form of the marginal q(x t?1 |x 0 ,x 0 ) from Eqn. 27 as follows:</p><formula xml:id="formula_25">q(x t?1 |x 0 ,x 0 ) = N ( ? t?1 x 0 +x 0 , 1 ?? t?1 I)<label>(38)</label></formula><p>Therefore it implies that,</p><formula xml:id="formula_26">? = 1 ? 1 ?? t?1 ? ? 2 t ? 1 ?? t<label>(39)</label></formula><p>This completes the analysis of the modified DDIM forward process posterior which is compatible with DiffuseVAE formualation-2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Primary Intuition</head><p>The primary intuition behind constructing such a formulation is that by initializing the base distribution from a VAE reconstruction, we can hope to speed up the reverse diffusion process. In the low time-step regime, DiffuseVAE (Form-2) usually performs better than (Form-1) (See <ref type="table" target="#tab_0">Tables 3, 11</ref> and 12). These results indicate our hypothesis might hold valid in the low-time-step regime in diffusion models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Related Work</head><p>Recent work in DDPMs also includes improving the speed vs sample quality tradeoff in the DDPM sampling process <ref type="bibr" target="#b55">(Song et al., 2021a;</ref><ref type="bibr" target="#b64">Watson et al., 2021;</ref><ref type="bibr" target="#b35">Luhman &amp; Luhman, 2021;</ref><ref type="bibr" target="#b50">Salimans &amp; Ho, 2022;</ref><ref type="bibr" target="#b67">Xiao et al., 2022)</ref>. We consider these advances in speeding up diffusion models are complementary to our work and can also be used to improve the sampling efficiency of DiffuseVAE. However, on the contrary, a majority of such methods were designed for improving sampling speeds in DDPMs while DiffuseVAE improves this tradeoff inherently. Similarly for VAEs <ref type="bibr" target="#b47">Rezende &amp; Mohamed, 2016)</ref>, there has also been progress in improving the ELBO estimates <ref type="bibr" target="#b53">(Sinha &amp; Dieng, 2021;</ref><ref type="bibr" target="#b3">Burda et al., 2016;</ref><ref type="bibr" target="#b37">Masrani et al., 2021)</ref> and image synthesis <ref type="bibr" target="#b9">(Child, 2021;</ref><ref type="bibr" target="#b32">Lee et al., 2020b;</ref><ref type="bibr" target="#b66">Xiao et al., 2021)</ref>. Next, we compare our proposed approach in detail with several of these related existing model families.</p><p>Unconditional DDPM: DDPM/DDIM as introduced in <ref type="bibr" target="#b20">(Ho et al., 2020;</ref><ref type="bibr" target="#b55">Song et al., 2021a)</ref> lacks a lowdimensional latent code which limits model application scope in several downstream tasks. In contrast, DiffuseVAE equips diffusion models with a low dimensional latent code that can be utilized for downstream tasks including but not limited to controllable synthesis. Moreover, we demonstrate a better speed vs quality tradeoff in DiffuseVAE as compared to standard unconditional DDPM/DDIM models and that the conditioning signal in DiffuseVAE helps in generalization to noisy conditioning signals.</p><p>Conditional DDPM: Conditional DDPM as introduced in  and  uses a cascade of multiple diffusion models (CDMs) for generating high-resolution images. However, for even a two-stage pipeline, the sampling time of such models would be effectively much higher than DiffuseVAE. Given the flexibility of our approach, we hypothesize that a single-stage VAE can also be replaced by a complex multi-stage VAE architecture as proposed in <ref type="bibr" target="#b9">(Child, 2021;</ref> for comparable sample quality to cascaded diffusion models without affecting the sampling time significantly. Moreover, such cascades lack a low-dimensional latent code which might be a limiting factor for certain downstream applications. It is worth noting that,  use a conditioning augmentation scheme where the high-resolution image is generated by conditioning on a blurred/noisy low resolution image. In contrast, our model is already conditioned on a reconstruction generated by a VAE (which is inherently blurry) and in some sense resembles the heuristic employed in CDMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VAE based methods</head><p>Hierarchical VAEs <ref type="bibr" target="#b59">(S?nderby et al., 2016;</ref><ref type="bibr" target="#b9">Child, 2021;</ref><ref type="bibr" target="#b46">Razavi et al., 2019)</ref> can suffer from posterior collapse and heuristics like gradient skipping and spectral normalization <ref type="bibr" target="#b38">(Miyato et al., 2018)</ref> might be required to stabilize training. Moreover, these models require a large dimensionality of the latent codes to generate high-fidelity samples <ref type="bibr" target="#b46">Razavi et al., 2019)</ref>. In contrast, DiffuseVAE training does not suffer from such instabilities and provides access to a single latent code layer (with dimensionality comparable to GANs) to generate high-fidelity samples. Among other recent works, VAEBM <ref type="bibr" target="#b66">(Xiao et al., 2021)</ref> uses EBMs <ref type="bibr" target="#b13">(Du &amp; Mordatch, 2020;</ref><ref type="bibr" target="#b40">Nijkamp et al., 2019)</ref> to refine VAE samples while LSGM  perform score-based modeling in the latent space of a VAE backbone. However, both VAEBM and LSGM use NVAE  as the base VAE architecture which also lacks a low-dimensional latent code. <ref type="bibr" target="#b32">(Lee et al., 2020b)</ref> distill the disentanglement properties in the VAE latent code to the latent space of a GAN-based generator. However, this approach would also suffer from existing problems of training stability and mode-collapse in GAN-based models. On the other hand, DiffuseVAE does not suffer from such problems D Detailed Proofs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Derivation of the DiffuseVAE objective</head><p>Given a high-resolution image x 0 , an auxiliary conditioning signal y to be modelled using a VAE, a latent representation z associated with y, and a sequence of T representations x 1:T learned by a diffusion model, the DiffuseVAE generative process, p(x 0:T , y, z) can be factorized as follows:</p><formula xml:id="formula_27">p(x 0:T , y, z) = p(z)p ? (y|z)p ? (x 0:T |y, z)<label>(40)</label></formula><p>where ? and ? are the parameters of the VAE decoder and the reverse process of the conditional diffusion model, respectively.The log-likelihood of the training data can then be obtained as:</p><formula xml:id="formula_28">log p(x 0 , y) = log p(x 0:T , y, z)dx 1:T dz<label>(41)</label></formula><p>Furthermore, since the joint posterior p(x 1:T , z|y, x 0 ) is intractable to compute, we approximate it using a surrogate posterior q(x 1:T , z|y, x 0 ) which can also be factorized into the following conditional distributions:</p><formula xml:id="formula_29">q(x 1:T , z|y, x 0 ) = q ? (z|y, x 0 )q(x 1:T |y, z, x 0 )<label>(42)</label></formula><p>where ? are the parameters of the VAE recognition network (q ? (z|y, x 0 )). Since computation of the likelihood in Eq. <ref type="formula" target="#formula_0">(41)</ref> is intractable, we can approximate it by computing a lower bound (ELBO) with respect to the joint posterior over the unknowns (x 1:T , z) as:</p><formula xml:id="formula_30">log p(x 0 , y) ? E q(x 1:T ,z|x0,y) log p(x 0:T , y, z) q(x 1:T , z|x 0 , y)<label>(43)</label></formula><p>Plugging the factorial forms of the DiffuseVAE generative process and the joint posterior defined above in eqn. (43), we can simplify the ELBO as follows:</p><p>log p(x 0 , y) ? E q(x 1:T ,z|y,x0) log p(x 0:T , y, z) q(x 1:T , z|y, x 0 ) (44)</p><formula xml:id="formula_31">? E q(x 1:T ,z|x0,y) log p(z)p ? (y|z)p ? (x 0:T |y, z) q ? (z|y, x 0 )q(x 1:T |y, z, x 0 ) (45) ? E q(x 1:T ,z|x0,y) log p(z) q ? (z|y, x 0 ) + log p ? (y|z) + log p ? (x 0:T |y, z) q(x 1:T |y, z, x 0 ) (46) ? E q(z|y,x0) log p(z) q ? (z|y, x 0 ) + log p ? (y|z) + E q(x 1:T ,z|x0,y) log p ? (x 0:T |y, z) q(x 1:T |y, z, x 0 ) (47) ? E q ? (z|y,x0) [p ? (y|z)] ? D KL (q ? (z|y, x 0 )||p(z)) L VAE +E z?q(z|y,x0) E q(x 1:T |y,z,x0) p ? (x 0:T |y, z) q(x 1:T |y, z, x 0 ) L DDPM<label>(48)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Derivation of the DiffuseVAE (Formulation-2) marginals</head><p>Given:</p><formula xml:id="formula_32">q(x 1 |x 0 ,x 0 ) = N ( 1 ? ? 1 x 0 +x 0 , ? 1 I) (49) q(x t |x t?1 ,x 0 ) = N ( 1 ? ? t x t?1 + (1 ? 1 ? ? t )x 0 , ? t I)<label>(50)</label></formula><p>From Eqn.(50), we can write,</p><formula xml:id="formula_33">x t = 1 ? ? t x t?1 + (1 ? 1 ? ? t )x 0 + ? t , where ? N (0, I)<label>(51)</label></formula><p>Taking expectations both sides,</p><formula xml:id="formula_34">E(x t ) = 1 ? ? t E(x t?1 ) + (1 ? 1 ? ? t )x 0 (52) E(x t ) = 1 ? ? t 1 ? ? t?1 E(x t?2 ) + (1 ? 1 ? ? t?1 )x 0 + (1 ? 1 ? ? t )x 0 E(x t ) = (1 ? ? t )(1 ? ? t?1 )E(x t?2 ) + 1 ? (1 ? ? t )(1 ? ? t?1 ) x 0 . . . (53) E(x t ) = t t=2 (1 ? ? t )E(x 1 ) +x 0 ? ? 1 ? t t=2 (1 ? ? t ) ? ?<label>(54)</label></formula><p>Substituting E(x 1 ) = ? 1 ? ? 1 x 0 +x 0 from Eqn.(49) into the above formulation we get,</p><formula xml:id="formula_35">E(x t ) = t t=1 (1 ? ? t )x 0 +x 0 = ?? t x 0 +x 0<label>(55)</label></formula><p>Similarly it can be shown that V ar(x t ) = (1 ?? t )I. Therefore,</p><formula xml:id="formula_36">q(x t |x 0 ,x 0 ) = N ( ?? t x 0 +x 0 , (1 ?? t )I)<label>(56)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>FID@10k ?</p><p>DiffuseVAE (x 0 ) 5.94 DiffuseVAE (x 0 + Latent code) 6.07  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Justification of the design choices in DiffuseVAE</head><p>Here we justify the design choices made in the DiffuseVAE model specification.</p><p>1. Choice of the conditioning signal y: The choice of assuming the conditioning signal y in Eq. 10 to be the training data x 0 is motivated by the task of refining the blurry samples generated by a simple VAE model using a DDPM model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Choice of the conditioning signal z:</head><p>The choice of conditioning the DDPM model onx 0 (the VAE reconstruction of the training data x 0 ) instead of the VAE inferred latent code z (usually lowerdimensional) allows us to condition the second stage DDPM directly on samples drawn from another model (not necessarily VAE) or on real images, which can be quite useful as illustrated in Section 4.5. Additionally, there can be a variant of our method in which the DDPM model is conditioned on both z andx. We conditioned the DDPM decoder on z using Adaptive group normalization layers <ref type="bibr" target="#b39">(Dhariwal &amp; Nichol, 2021;</ref><ref type="bibr" target="#b65">Wu &amp; He, 2018)</ref> as follows:</p><formula xml:id="formula_37">y = MLP(z) + e t<label>(57)</label></formula><formula xml:id="formula_38">AdaGN(h, y) = y s GroupNorm(h) + y b<label>(58)</label></formula><p>where h is the output of the first convolution in the residual block and y = [y s , y b ] is obtained from the latent code z and the time-step embedding e t . On benchmarking this DiffuseVAE (Formulation-1) variant on CIFAR-10 trained for around 1.1M steps, we found that the resulting model exhibited slightly worse performance compared to the DiffuseVAE variant conditioned only on the VAE reconstructions (x 0 ) (See <ref type="table" target="#tab_8">Table 7</ref>). Therefore, we only condition the DDPM model in DiffuseVAE only on the VAE generated reconstructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Two-stage training:</head><p>The choice of a two-stage training approach in DiffuseVAE is motivated by two reasons. Firstly, in our early experiments on CIFAR-10, we observed that the end-to-end model exhibited much worse performance than its two-stage counterpart during inference (See <ref type="table" target="#tab_9">Table 8</ref>) where both models were trained for 400k steps. Secondly, from a computational standpoint, using a two-stage training formulation would be more amenable to training on limited compute resources as end-to-end training would require both models to fit in memory.</p><p>Training and Inference: Unless specified otherwise, we use the same hyperparameters during training as proposed in <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>. All DDPM models were trained using the simplified objective proposed in <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>. We used a mix of 4 Nvidia 1080Ti GPUs (44GB memory), a cloud TPUv2-8 (64GB memory) and a cloud TPUv3-8 (128GB memory) for training the models. Specifically, we used the GPU setup for training our CIFAR-10 and CelebA-64 models while we utilized the TPUv2-8 for training CelebA-HQ models at the 128 x 128 resolutions. Finally, we utilized the TPUv3-8 model for training on CelebA-HQ model at 256 x 256 resolution.</p><p>Evaluation: For FID <ref type="bibr" target="#b18">(Heusel et al., 2018)</ref> score computation, we utilized 10k samples for the CelebA-HQ-128 dataset and 50k samples for state-of-the-art comparisons on the CIFAR-10 and the CelebA-64 datasets. For CelebA-HQ 256 comparisons we computed FID scores on 30k samples since the CelebA-HQ dataset contains 30k images. We used the torch-fidelity <ref type="bibr" target="#b41">(Obukhov et al., 2020)</ref> package for FID and IS score computations. In this work, when saving samples to disk, we used standard denormalization (i.e. 0.5 * img + 0.5) for all datasets. We used our GPU setup primarily for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-10 (FID@50k)</head><p>CelebA-64 (FID@50k)   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1 Generator-Refiner Framework</head><p>Some additional qualitative results demonstrating the generator-refiner framework in VAEs are shown in <ref type="figure">Fig. 11</ref>. <ref type="table" target="#tab_0">Table 10</ref> provides further supports our qualitative results for several other benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.2 Controllable synthesis</head><p>The directions for meaningful concepts (or image attributes like gender, age, hair style) are obtained by considering pairs of attribute negative and positive training samples. For each such pair, we compute the latent code representation for the positive and the negative sample and compute the difference between the attribute positive and the negative latent. We repeat this procedure for all such pairs and compute the average of the difference between the latent codes to obtain the direction vector for the attribute. Formally, given an attribute of interest a and the a set of tuples (x</p><formula xml:id="formula_39">(i) pos , x (i) neg ) N i=1</formula><p>of attribute positive and negative images, the latent direction z a is given by:</p><formula xml:id="formula_40">z a = 1 N N i=1 f (x (i) pos ) ? f (x (i) neg )<label>(59)</label></formula><p>where f denotes a mapping from the image to the latent space (the VAE encoder in this case). Given this latent direction, we can manipulate an attribute negative image by simply adding this vector to the latent code representation of the attribute negative image and decoding the resulting latent code representation as follows:</p><formula xml:id="formula_41">z p = z n + ?z a<label>(60)</label></formula><p>where z n is the latent code representation of the atribute negative image, z p is the new latent code containing the missing attribute and ? is a scalar which controls the coarseness of the controllable generation (higher values usually result in more coarse generations). In this work, we use the attribute annotations provided by the CelebAMask-HQ dataset <ref type="bibr" target="#b31">(Lee et al., 2020a)</ref>    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.3 Speed vs quality tradeoffs</head><p>Reverse Process subsequence selection: We use the linear and quadratic time-step selection as discussed in DDIM <ref type="bibr" target="#b55">(Song et al., 2021a)</ref>, when running the reverse process for only a subsample of the time-steps for efficient sampling. We call this spaced sampling. For benchmarking both DiffuseVAE and the baseline DDPM/DDIM models for the speed vs quality tradeoff, we selected the scheme which yielded lower FID values. Hence, we use the quadratic time-step schedule for all datasets when benchmarking DiffuseVAE while we used the quadratic schedule for the CIFAR-10 and the CelebA-64 datasets and linear schedule for the CelebA-HQ dataset when benchmarking the baseline DDPM/DDIM. There is also a possibility of using truncated sampling in which only the last t time-steps are used for sampling. However, we found that the latter yielded inferior results than spaced sampling, so we do not report the FID scores for truncated sampling here.</p><p>Additional results on speed vs quality tradeoff : <ref type="table" target="#tab_0">Table 11</ref> shows a speed vs quality tradeoff comparison between DiffuseVAE (with Ex-PDE) and the DDPM baseline for the CIFAR-10 and the CelebA-64 benchmarks. Both methods use the fixedsmall variance type as discussed in <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>. On the CelebA-64 dataset, DiffuseVAE again provides a much better speed vs quality tradeoff than a standard DDPM. However, on the CIFAR10 dataset, DiffuseVAE lags behind the standard DDPM (except at T=10) in terms of FID scores. We observed a similar trend on CIFAR-10 when comparing with DDIM (See <ref type="table" target="#tab_0">Table 12</ref>). This is surprising, since for T=1000, our DiffuseVAE model outperforms our baseline DDPM. A possible explanation for this result might be uninformative conditioning signal (for instance, samples with extremely poor VAE reconstructions) which does not help the Stage-II DDPM decoder in producing good quality refinements thus hurting sample quality in the low step regime. For completeness, we also report the FID scores on 10k samples for our CelebA-HQ-256 DiffuseVAE (Form-1) model using DDIM sampling in <ref type="table" target="#tab_0">Table 13</ref> G.4 State-of-the-art Comparisons Model size comparison: LSGM and DiffuseVAE: Here we compare model sizes between DiffuseVAE and LSGM . <ref type="table" target="#tab_0">Table 14</ref> compares the model sizes between the LSGM and DiffuseVAE models on the CIFAR-10 and the CelebA-HQ-256 benchmarks. LSGM utilizes an order of magnitude larger VAE backbones and denoising decoders in comparison to DiffuseVAE. When computing the LSGM model size, we compute the size of the best FID model (See https://github.com/NVlabs/LSGM). To examine the performance gains when using larger models, we trained a DiffuseVAE (Form-1) model with an unchanged VAE baseline but with a larger DDPM decoder with around 70M parameters on CIFAR-10. Indeed, when using a larger model, DiffuseVAE with Ex-PDE achieves a FID of 3.13 and a mean IS of 9.78 on CIFAR-10 which shows that our model can take advantage of larger model sizes as well. Lastly, its worth noting that our baseline DDPM implementation achieved a FID score of 3.90 on CIFAR-10 in contrast to 3.17 reported by <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>. Due to this, rather minor, perfor-  <ref type="table" target="#tab_0">Table 14</ref>: Model size comparison (in terms of the number of parameters) between DiffuseVAE and LSGM on the CIFAR-10 and CelebA-HQ-256 benchmark mance gap, we expect the actual FID scores for DiffuseVAE to be slightly lower than the reported FID scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Temperature Sampling in DiffuseVAE:</head><p>We experiment with a temperature scaling technique where during the DDPM sampling stage in DiffuseVAE, we sample the initial DDPM latent x T from a base Gaussian distribution with standard deviation scaled by ?. This is a common technique utilized in prior works <ref type="bibr" target="#b25">Kingma &amp; Dhariwal, 2018)</ref> to tradeoff between sample quality and diversity. Interestingly, we found that for CelebA-HQ-256 dataset, samples generated during intermediate training stages (and even after convergence) suffer from color bleeding as shown in <ref type="figure" target="#fig_8">Fig. 10</ref> (Top Row). We found that by applying temperature annealing in the second stage DDPM latents alleviates this problem (See <ref type="figure" target="#fig_8">Fig. 10(Bottom Row)</ref>). Therefore, we compute FID for state-of-the-art comparisons on this benchmark with a scaling factor of 0.8. We did not observe such color channel bleeding in samples of other benchmarks. In such cases, we observed that temperature scaling did not help and thus was not used to report FID scores. Additional Samples: Some additional samples from our CelebA-HQ model using DDIM sampling with 50 steps in the reverse process are shown in <ref type="figure" target="#fig_1">Figure 13</ref>. <ref type="figure">Figure 14</ref> shows some additional samples from the same model with T=1000 and a temperature scaling factor of 0.8. Lastly, <ref type="figure" target="#fig_4">Figure 15</ref> shows samples from the CelebAHQ-256 model but with shared latents in the DDPM stage (so effectively the generation is driven completely by low-dimensional latents from the VAE model).   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Composite</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Proposed DiffuseVAE generative process under the simplifying design choices discussed in Section 3.2. DiffuseVAE is trained in a two-stage manner: The VAE encoder takes the original image x 0 as input and generates a reconstructionx 0 which is used to condition the second stage DDPM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Illustration of the generator-refiner framework in DiffuseVAE. The VAE generated samples (Bottom row) are refined by the Stage-2 DDPM model with T=1000 during inference (Top Row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3</head><label>3</label><figDesc>shows samples generated from the proposed DiffuseVAE model trained on the CelebA-HQ dataset at the 128 x 128 resolution and their corresponding Stage-1 VAE samples. For both DiffuseVAE formulations-1 and 2, DiffuseVAE generated samples(Fig. 3 (Top row)are a refinement of the blurry samples generated by our single-stage VAE model (Bottom row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>DiffuseVAE samples generated by linearly interpolating in the x T latent space (Formulation-1, T=1000). ? denotes the interpolation factor. justify this argument where on the CelebA-HQ-128 benchmark, DiffuseVAE improves the FID score of a baseline VAE by about eight times. Additional qualitative results demonstrating this observation can be found inFig. 11.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Controllable generation on DiffuseVAE generated samples on the CelebA-HQ 256 dataset. Red and green arrows indicate vector subtract and addition operations respectively. Top and Bottom panels show single edits and composite edits respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Illustration of DiffuseVAE generalization to different noise types in the conditioning signal on the CIFAR-10 test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure</head><label></label><figDesc><ref type="bibr" target="#b54">-Dickstein et al., 2015;</ref><ref type="bibr" target="#b20">Ho et al., 2020)</ref> are latent-variable models consisting of a forward noising process (q(x 1:T |x 0 )) (corresponding to an inference model in other generative model families like VAEs<ref type="bibr" target="#b47">Rezende &amp; Mohamed, 2016)</ref>. See</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Effect of temperature sampling in DDPM latents in DiffuseVAE. (Top Row) Samples generated with ? = 1.0. (Bottom Row) Samples generated with ? = 0.8</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 12 :Figure 14 :</head><label>1214</label><figDesc>Additional results demonstrating controllable synthesis in the CelebA-HQ-128 dataset. Green boxes denote the vector addition operation while Red boxes denote the vector subtract operation Figure 13: Additional samples from generated from DiffuseVAE trained on the CelebAHQ-256 dataset. T=50 using DDIM sampling.32 Additional samples from generated from DiffuseVAE trained on the CelebAHQ-256 dataset (T=1000, Temp. Scaling factor was set to 0.8 during sampling).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 15 :</head><label>15</label><figDesc>Additional samples from generated from DiffuseVAE trained on the CelebAHQ-256 dataset with the DDPM latents shared between samples. The generation is effectively driven by low-dimensional VAE latent space (T=1000, Temp. Scaling factor was set to 0.8 during sampling). 34</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>: Quantitative Illustration of the generator-refiner framework in DiffuseVAE for the CelebA-HQ (128</cell></row><row><cell>x 128) dataset. FID reported on 10k samples (Lower is better)</cell></row><row><cell>This observation qualitatively validates our generator-refiner framework in which the Stage-1 VAE model</cell></row><row><cell>acts as a generator and the Stage-2 DDPM model acts as a refiner. The results in Table 1 quantitatively</cell></row><row><cell>6</cell></row></table><note>VAE Samples</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The proposed DiffuseVAE model consists of two types of latent representations: the low-dimensional VAE latent code z vae and the DDPM intermediate representations x 1:T associated with the DDPM reverse process (which are of the same size of the input image x 0 and thus might not be beneficial for downstream tasks). We next discuss the effects of manipulating both z vae and x T . Although, it is possible to inspect interpolations on the intermediate DDPM representations x 1:T ?1 , we do not investigate this case in this work.</figDesc><table><row><cell cols="2">We consider</cell></row><row><cell>the following interpolation settings:</cell><cell></cell></row><row><cell>Interpolation in the VAE latent space z vae : We first sample two VAE latent codes z vae and z (1)</cell><cell>(2) vae using</cell></row><row><cell cols="2">the standard Gaussian distribution. We then perform linear interpolation between z vae and z (1) vae to obtain (2)</cell></row><row><cell>intermediate VAE latent codesz vae = ?z</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>(Bottom  Row)  while also enabling deterministic sampling. This observation is intuitive as initializing the second stage DDPM in DiffuseVAE with different stochastic noise codes during sampling might be understood as imparting different styles to the refined sample. Thus, sharing this stochasticity in DDPM sampling across samples</figDesc><table><row><cell></cell><cell>10</cell><cell>25</cell><cell>50</cell><cell>100</cell><cell>1000</cell></row><row><cell>DDPM (Uncond)</cell><cell>41.25</cell><cell>27.83</cell><cell>21.40</cell><cell>16.29</cell><cell>8.93</cell></row><row><cell>DiffuseVAE (Form-1)</cell><cell>31.11</cell><cell>19.44</cell><cell>15.31</cell><cell>13.68</cell><cell>12.63</cell></row><row><cell>DiffuseVAE (Form-2)</cell><cell>31.08</cell><cell>19.67</cell><cell>15.96</cell><cell>13.96</cell><cell>13.20</cell></row><row><cell>DiffuseVAE (Form-1, GMM=100)</cell><cell>30.74</cell><cell>18.55</cell><cell>14.10</cell><cell>12.12</cell><cell>10.87</cell></row><row><cell>DiffuseVAE (Form-2, GMM=100)</cell><cell>30.66</cell><cell>18.98</cell><cell>14.45</cell><cell>12.50</cell><cell>11.44</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparison of sample quality (FID@10k) vs speed on the CelebA-HQ-128 dataset (DiffuseVAE vs unconditional DDPM). Top Row represents the number of reverse process sampling steps.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="2">CelebAHQ-128</cell><cell></cell><cell></cell><cell cols="2">CelebA-64</cell><cell></cell></row><row><cell></cell><cell>10</cell><cell>25</cell><cell>50</cell><cell>100</cell><cell>10</cell><cell>25</cell><cell>50</cell><cell>100</cell></row><row><cell>DDIM (uncond)</cell><cell>34.36</cell><cell>25.04</cell><cell>19.83</cell><cell>16.69</cell><cell>14.14</cell><cell>7.88</cell><cell>6.77</cell><cell>6.38</cell></row><row><cell>DiffuseVAE (Form-1)</cell><cell>19.42</cell><cell>15.12</cell><cell>14.53</cell><cell>14.53</cell><cell>10.79</cell><cell>6.87</cell><cell>6.08</cell><cell>5.82</cell></row><row><cell>DiffuseVAE (Form-1, Ex-PDE)</cell><cell>18.01</cell><cell>13.21</cell><cell>12.40</cell><cell>12.28</cell><cell>10.44</cell><cell>6.59</cell><cell>5.81</cell><cell>5.55</cell></row><row><cell>DiffuseVAE (Form-2)</cell><cell>17.51</cell><cell>13.45</cell><cell>12.56</cell><cell>12.51</cell><cell>9.81</cell><cell>6.34</cell><cell>5.83</cell><cell>5.59</cell></row><row><cell>DiffuseVAE (Form-2, Ex-PDE)</cell><cell>16.47</cell><cell>11.62</cell><cell>10.83</cell><cell>10.28</cell><cell>9.56</cell><cell>5.90</cell><cell>5.43</cell><cell>5.21</cell></row></table><note>shows the FID scores on the CelebA-HQ-128 dataset for both DiffuseVAE formulations using a GMM with 100 components. Across all time-steps, using</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Comparison of sample quality (FID@10k) vs speed between DiffuseVAE and the unconditional DDIM on the CelebA-HQ-128 and CelebA-64 datasets.</figDesc><table><row><cell></cell><cell>Method</cell><cell>FID@50k ?</cell><cell>IS ?</cell></row><row><cell></cell><cell>DiffuseVAE (Form-1, T=1000)</cell><cell>3.93</cell><cell>9.62 ? 0.11</cell></row><row><cell></cell><cell>DiffuseVAE (Form-1, T=1000, GMM=50)</cell><cell>3.77</cell><cell>9.52 ? 0.18</cell></row><row><cell>Ours</cell><cell>DiffuseVAE (Form-2, T=1000, GMM=50) DDPM (T=1000, Our impl.)</cell><cell>3.84 3.91</cell><cell>9.42 ? 0.07 9.34 ? 0.07</cell></row><row><cell></cell><cell>VAE Baseline</cell><cell>139.50</cell><cell>3.23 ? 0.02</cell></row><row><cell></cell><cell>VAE Baseline (GMM=50)</cell><cell>137.68</cell><cell>3.30 ? 0.02</cell></row><row><cell></cell><cell>VAEBM (Xiao et al., 2021) (w/ PC)</cell><cell>12.19</cell><cell>8.43</cell></row><row><cell>VAE-based</cell><cell>DC-VAE</cell><cell></cell><cell></cell></row><row><cell>methods</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc>compares the speed-quality tradeoff between DDIM and DiffuseVAE (with DDIM sampling) on the CelebA-HQ-128 and CelebA-64 datasets. DiffuseVAE (both formulations) largely outperforms the standard unconditional DDIM at all time-steps. For the CelebA-HQ-128 benchmark, similar to our previous observation, DiffuseVAE (with DDIM sampling and Ex-PDE using GMMs) at T = 25 and 50 steps performs better than the standard DDIM at T = 50 and 100 steps respectively.</figDesc><table><row><cell>Method</cell><cell>FID@50k ?</cell></row><row><cell>DiffuseVAE (Form-1, T=1000, GMM=75)</cell><cell>4.05</cell></row><row><cell>DiffuseVAE (Form-2, T=1000, GMM=75)</cell><cell>3.97</cell></row><row><cell>DDPM (T=1000, Our impl.)</cell><cell>3.93</cell></row><row><cell>VAE Baseline (GMM=75)</cell><cell>72.11</cell></row><row><cell>D2C (Sinha et al., 2021)</cell><cell>5.7</cell></row><row><cell>NCP-VAE</cell><cell></cell></row></table><note>In fact, at T = 10, DiffuseVAE (with Formulation-2) achieves a FID of 16.47 which is better than DDIM with T = 100 steps, thus providing a speedup of almost 10x. Similarly for the CelebA- 64 benchmark, at T = 25, DiffuseVAE (Formulation-2) performs similarly to the unconditional DDIM at T = 100, thus providing a 4x speedup. Lastly, it can be observed from Tables 3, 11 and 12 that in the low time-step regime, DiffuseVAE (Form-2) usually performs better than Form-1 and that the speed-quality trade-off in DiffuseVAE becomes better with increasing image resolutions.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Generative performance on CelebA-64</figDesc><table><row><cell>Method</cell><cell>FID ?</cell></row><row><cell>DiffuseVAE (T=1000, GMM=100, FID@10k)</cell><cell>11.28</cell></row><row><cell>VAE Baseline (GMM=100, FID@10k)</cell><cell>97.07</cell></row><row><cell>LSGM (Vahdat et al., 2021)</cell><cell>7.22</cell></row><row><cell>VQGAN + Transformer</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell>Method</cell><cell>FID@10k ?</cell></row><row><cell>DiffuseVAE (Two-stage)</cell><cell>6.81</cell></row><row><cell>DiffuseVAE (End-to-end)</cell><cell>8.12</cell></row><row><cell>: FID (10k samples) comparison between dif-</cell><cell></cell></row><row><cell>ferent DiffuseVAE conditioning schemes on CIFAR10.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell>: FID (10k samples) comparison between two-</cell></row><row><cell>stage and end-to-end training on CIFAR10.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 :</head><label>10</label><figDesc>Quantitative comparison between sample quality of first stage VAEs in DiffuseVAE and the final</figDesc><table><row><cell>DiffuseVAE samples</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">CelebA-64</cell><cell></cell><cell></cell><cell cols="2">CIFAR-10</cell></row><row><cell></cell><cell>10</cell><cell>25</cell><cell>50</cell><cell>100</cell><cell>10</cell><cell>25</cell><cell>50</cell><cell>100</cell></row><row><cell>DDPM (uncond)</cell><cell>37.31</cell><cell cols="3">17.06 10.99 8.26</cell><cell cols="4">42.46 15.37 9.44 7.35</cell></row><row><cell cols="2">DiffuseVAE (Form-1, Ex-PDE) 26.09</cell><cell>14.16</cell><cell>9.58</cell><cell>7.54</cell><cell>37.58</cell><cell cols="3">18.65 12.27 9.37</cell></row><row><cell cols="9">DiffuseVAE (Form-2, Ex-PDE) 25.79 13.89 9.09 7.15 36.64 17.97 11.94 9.19</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 :</head><label>11</label><figDesc>Speed vs quality tradeoff comparison between DDPM and DiffuseVAE for the CIFAR-10 and CelebA-64 datasets. FID reported using 10k samples</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>and a value of N=100 to construct the set of positive and negative samples for any attribute of interest. Additional controllable synthesis (including single attribute manipulation and composite manipulations) results for the CelebA-HQ dataset at the 128 x 128 resolution are shown inFig. 12DiffuseVAE (DDIM, Form1, Ex-PDE) 17.84 10.34 8.63 7.92 DiffuseVAE (DDIM, Form2, Ex-PDE) 17.35 10.41 8.86 8.05</figDesc><table><row><cell></cell><cell>10</cell><cell>25</cell><cell>50</cell><cell>100</cell></row><row><cell>DDIM (uncond)</cell><cell cols="4">16.43 8.78 7.38 6.83</cell></row><row><cell>27</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 12 :24.09 17.47 16.65 16.63</head><label>12</label><figDesc>Speed vs quality tradeoff comparison between DDIM and DiffuseVAE for the CIFAR-10 dataset.</figDesc><table><row><cell>FID reported using 10k samples</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>10</cell><cell>25</cell><cell>50</cell><cell>100</cell></row><row><cell>DiffuseVAE (DDIM, Form-1)</cell><cell>26.07</cell><cell>19.75</cell><cell>18.90</cell><cell>18.85</cell></row><row><cell>DiffuseVAE (DDIM, Form-1, GMM=100)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 13 :</head><label>13</label><figDesc>FID scores (on 10k samples) for DiffuseVAE (Form-1) using DDIM sampling for the CelebA-HQ-256 dataset</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">See https://openreview.net/forum?id=P9TYG0j-wtG&amp;noteId=Z7AYukcBJ_q</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Architecture  Model architecture: We use the same network architectures as explored in prior work in diffusion models <ref type="bibr" target="#b20">(Ho et al., 2020;</ref><ref type="bibr" target="#b39">Dhariwal &amp; Nichol, 2021;</ref><ref type="bibr" target="#b39">Nichol &amp; Dhariwal, 2021)</ref>. The VAE architecture used for Stage-1 training consists of residual block architectures inspired from <ref type="bibr" target="#b9">(Child, 2021</ref>) (Refer to our code for exact architectural details). The VAE latent code size was set to 1024 for CelebA-HQ (both 128 and 256 resolution variants) and 512 for the CIFAR-10 and CelebA (64 x 64) datasets. We did not experiment with the size of the latent code in this work. Similar to prior work <ref type="bibr" target="#b20">(Ho et al., 2020)</ref>, we use the U-Net <ref type="bibr" target="#b48">(Ronneberger et al., 2015)</ref> decoder implementation from <ref type="bibr" target="#b39">(Nichol &amp; Dhariwal, 2021)</ref> in the reverse process in Stage-II DDPM training. The UNet decoder model hyperparameters are listed in <ref type="table">Table 9</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ncp-vae: Variational autoencoders with noise contrastive priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jyoti</forename><surname>Aneja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<idno>abs/2010.02917</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Resampled priors for variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="http://proceedings.mlr.press/v89/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<meeting>the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS)</meeting>
		<imprint>
			<date type="published" when="2019-04" />
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="66" to="75" />
		</imprint>
	</monogr>
	<note>of Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.11096</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Importance weighted autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Understanding disentangling in ?-vae</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">P</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arka</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Watters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Lerchner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Auto-gan: self-supervised collaborative learning for medical image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinbo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinggang</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="10486" to="10493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Your gan is secretly an energy-based model and you should use discriminator driven latent sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruixiang</forename><surname>Tong Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Paull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Wavegrad: Estimating gradients for waveform generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanxin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Isolating sources of disentanglement in variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuechen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duvenaud</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Very deep vaes generalize autoregressive models and can outperform them on images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Ilvr: Conditioning method for denoising diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jooyoung</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghyun</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjune</forename><surname>Gwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Prafulla Dhariwal and Alex Nichol. Diffusion models beat gans on image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wipf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.05789</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Diagnosing and enhancing vae models</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Generating images with perceptual similarity metrics based on deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Implicit generation and generalization in energy-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Taming transformers for high-resolution image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bj?rn</forename><surname>Ommer</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2012.09841" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">From variational to deterministic autoencoders. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mehdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Vergari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sch?lkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Ffjord: Freeform continuous dynamics for scalable reversible generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">beta-vae: Learning basic visual concepts with a constrained variational framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">P</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Lerchner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Cascaded diffusion models for high fidelity image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitwan</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salimans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.15282</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Analyzing and improving the image quality of stylegan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miika</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janne</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Glow: Generative flow with invertible 1x1 convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><forename type="middle">J</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Improving variational inference with inverse autoregressive flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Variational diffusion models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ho</surname></persName>
		</author>
		<idno>2021. 14</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<ptr target="https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf" />
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="32" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Maskgan: Towards diverse and interactive facial image manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Cheng-Han Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingyun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">High-fidelity synthesis with disentangled representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonkwang</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donggyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Coco-gan: Generation by parts via conditional coordinating</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chieh</forename><surname>Hubert Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Che</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Sheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da-Cheng</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwann-Tzong</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Knowledge distillation in iterative generative models for improved sampling speed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Luhman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Troy</forename><surname>Luhman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Diffusion probabilistic models for 3d point cloud generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shitong</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">The thermodynamic variational objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaden</forename><surname>Masrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan</forename><forename type="middle">Anh</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wood</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Spectral normalization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiki</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuichi</forename><surname>Yoshida</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Improved denoising diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Learning non-convergent non-persistent short-run mcmc toward energy-based model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitch</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Song-Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying Nian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">High-fidelity performance metrics for generative models in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Obukhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Seitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Semen</forename><surname>Zhydenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Kyl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elvis Yu-Jing</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4957738</idno>
		<ptr target="https://github.com/toshas/torch-fidelity" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Version: 0.3.0</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Quality aware generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kancharla</forename><surname>Parimala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumohana</forename><surname>Channappayya</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/b59a51a3c0bf9c5228fde841714f523a-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d Alche-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Dual contradistinctive generative autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="823" to="832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Anomaly detection with conditional variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><forename type="middle">Alan</forename><surname>Pol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianluca</forename><surname>Cerminara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cecile</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurizio</forename><surname>Pierini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Diffusion autoencoders: Toward a meaningful and decodable representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konpat</forename><surname>Preechakul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nattanat</forename><surname>Chatthee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suttisak</forename><surname>Wizadwongsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Supasorn</forename><surname>Suwajanakorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Generating diverse high-fidelity images with vq-vae-2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Razavi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Aaron van den Oord, and Oriol Vinyals</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Image super-resolution via iterative refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitwan</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Norouzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.07636</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Progressive distillation for fast sampling of diffusion models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=TIdIXIpzhoI" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">D2c: Diffusion-denoising models for few-shot conditional generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenlin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.06819</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Consistency regularization for variational auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samarth</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adji</forename><forename type="middle">B</forename><surname>Dieng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">A</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niru</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Denoising diffusion implicit models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenlin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Improved techniques for training score-based generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Score-based generative modeling through stochastic differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Poole</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=PxTIG12RRHS" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Ladder variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapani</forename><surname>Casper Kaae S?nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maal?e</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>S?ren Kaae S?nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Winther</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Nvae: A deep hierarchical variational autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Score-based generative modeling in latent space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Kreis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rianne van den Berg, Leonard Hasenclever, Jakub M. Tomczak, and Max Welling. Sylvester normalizing flows for variational inference</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Neural discrete representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS&apos;17</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems, NIPS&apos;17<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6309" to="6318" />
		</imprint>
	</monogr>
	<note>ISBN 9781510860964</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Neural discrete representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Learning to efficiently sample from diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Group normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1803.08494" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Vaebm: A symbiosis between variational autoencoders and energy-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Kreis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Tackling the generative learning trilemma with denoising diffusion GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Kreis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<idno>id=JprM0p-q0Co. CIFAR-10</idno>
		<ptr target="https://openreview.net/forum" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">CelebA-64</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">CelebaA-64 (VAE) CelebA-64 (DiffuseVAE)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Additional results demonstrating the generator-refiner framework in DiffuseVAE</title>
	</analytic>
	<monogr>
		<title level="j">Figure</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
