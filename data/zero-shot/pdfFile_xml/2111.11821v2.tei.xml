<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Representation for Clustering via Prototype Scattering and Positive Sampling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junping</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongming</forename><surname>Shan</surname></persName>
						</author>
						<title level="a" type="main">Learning Representation for Clustering via Prototype Scattering and Positive Sampling</title>
					</analytic>
					<monogr>
						<title level="j" type="main">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE</title>
						<imprint>
							<biblScope unit="volume">XX</biblScope>
							<biblScope unit="page">1</biblScope>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Contrastive learning</term>
					<term>deep clustering</term>
					<term>representation learning</term>
					<term>self-supervised learning</term>
					<term>unsupervised learning !</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing deep clustering methods rely on either contrastive or non-contrastive representation learning for downstream clustering task. Contrastive-based methods thanks to negative pairs learn uniform representations for clustering, in which negative pairs, however, may inevitably lead to the class collision issue and consequently compromise the clustering performance. Non-contrastive-based methods, on the other hand, avoid class collision issue, but the resulting non-uniform representations may cause the collapse of clustering. To enjoy the strengths of both worlds, this paper presents a novel end-to-end deep clustering method with prototype scattering and positive sampling, termed ProPos. Specifically, we first maximize the distance between prototypical representations, named prototype scattering loss, which improves the uniformity of representations. Second, we align one augmented view of instance with the sampled neighbors of another view-assumed to be truly positive pair in the embedding space-to improve the within-cluster compactness, termed positive sampling alignment. The strengths of ProPos are avoidable class collision issue, uniform representations, well-separated clusters, and within-cluster compactness. By optimizing ProPos in an end-to-end expectation-maximization framework, extensive experimental results demonstrate that ProPos achieves competing performance on moderate-scale clustering benchmark datasets and establishes new state-of-the-art performance on large-scale datasets. Source code is available at https://github.com/Hzzone/ProPos.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Deep clustering is gaining considerable attention as it aims to learn the representation of images and perform clustering in an end-to-end fashion. The main thrust to advance deep clustering is the self-supervised representation learning, including contrastive learning <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> and non-contrastive learning <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>.</p><p>Remarkably, existing deep clustering methods heavily rely on contrastive representation learning, referred to as contrastive-based methods <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>. Specifically, they are usually built upon MoCo <ref type="bibr" target="#b0">[1]</ref> or Sim-CLR <ref type="bibr" target="#b1">[2]</ref>, requiring specially designed losses <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> or an extra pre-training stage for more discriminative representations <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b10">[11]</ref>. Although achieving promising clustering results, contrastive-based methods usually require a large number of negative examples to learn uniform representations in an embedding space where all instances are well-separated. The involved negative pairs may inevitably lead to the class collision issue that different instances from the same semantic class are regarded as negative pairs and are wrongly pushed away, which hampers the downstream clustering. An alternative perspective on ? Z. Huang, J. Chen, and J. <ref type="bibr">Zhang</ref>  this issue is to separate the typical contrastive loss into two terms <ref type="bibr" target="#b11">[12]</ref>: 1) alignment term to improve the closeness of positive pairs, and 2) uniformity term to encourage instances to be uniformly distributed on a unit hypersphere by pushing away the negative pairs. Apparently, the uniformity term could introduce class collision issue <ref type="bibr" target="#b12">[13]</ref> as the constructed negative pairs may not be truly negative. Different from contrastive learning, non-contrastive learning only involves the alignment term using the representations of one augmented view to predict another. The non-contrastive learning can avoid the class collision issue as there are no negative pairs. Lacking the uniformity term in contrastive loss, it is not guaranteed to learn uniform representations <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>, which may cause the collapse of downstream clustering-most samples are assigned to few clusters. This phenomenon would even worsen when learning in conjunction with extra clustering losses introduced by current state-of-the-art deep clustering methods <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>; see Sec. 5.4 and supplemental <ref type="figure">Fig. 9</ref>.</p><p>To enjoy the strengths of both worlds, we propose a novel end-to-end deep clustering method, ProPos, with two novel techniques: prototype scattering loss and positive sampling alignment. First, considering that different prototypes/clusters are truly negative pairs, we propose to perform contrastive learning over prototypical representations, in which two augmented views of the same prototypes are positive pairs and different prototypes are negative pairs. This yields the proposed prototype scattering loss or PSL, which maximizes the between-cluster distance so as to learn uniform representations towards well-separated clusters. Second, to improve the within-cluster compactness, we further propose to align one augmented view of the instance with the randomly sampled neighbors of another view that are assumed to be truly positive pairs in the embedding space, which we refer to as positive sampling alignment or PSA. Compared to conventional alignment between two augmented views, the proposed PSA takes into account the neighboring samples in the embedding space, improving the within-cluster compactness. Moreover, we optimize ProPos in an expectation-maximization (EM) framework, in which we iteratively perform E-step as estimating the instance pseudo-labels via spherical k-means and M-step as minimizing the proposed losses.</p><p>The contributions are summarized as follows: <ref type="bibr">?</ref> We propose a novel end-to-end deep clustering method, termed ProPos, which enjoys the advantages of contrastive and non-contrastive representation learning: avoidable class collision issue, uniform representations for improved clustering stability, well-separated clusters, and improved withincluster compactness. <ref type="bibr">?</ref> We propose a novel prototype scattering loss or PSL, which can align one augmented view of prototypes with another view and maximize the between-cluster scattering on the unit hypersphere, hence maximizing the inter-cluster distance for uniform representations. <ref type="bibr">?</ref> We propose a positive sampling alignment or PSA to extend instance alignment by taking into account neighboring positive examples in the embedding space, which can improve the within-cluster compactness.</p><p>? By optimizing ProPos in an EM framework, extensive experimental results on several benchmark datasets demonstrate that ProPos outperforms the existing state-of-the-art methods by a significant margin, especially for large-scale datasets.</p><p>The remainder of this paper is organized as follows. A brief review on the related work of self-supervised learning and deep clustering is given in Sec. 2, followed by the contrastive and non-contrastive representation learning in Sec. 3. We present the proposed PSL and PSA as well as our ProPos in Sec. <ref type="bibr" target="#b3">4</ref>. Experimental results are reported and analyzed in Sec. 5, where Sec. 5.2 further justifies the motivation. Finally, Sec. 6 discusses the relations to previous works, followed by a concluding summary in Sec. 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>This section briefly surveys the development of selfsupervised learning and deep clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Self-Supervised Learning</head><p>Previous self-supervised learning (SSL) methods for representation learning attempt to capture the data distribution using generative models <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref> or learn the representations through some special designed pretext tasks <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. In recent years, contrastive learning methods <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b20">[21]</ref> have shown promising results for both representation learning and downstream tasks. Contrastive representation learning requires a large number of negative examples to achieve instance-wise discrimination in an embedding space where all instances are well-separated. The constructed negative pairs usually require a large batch size <ref type="bibr" target="#b1">[2]</ref>, memory queue <ref type="bibr" target="#b0">[1]</ref>, or memory bank <ref type="bibr" target="#b20">[21]</ref>, which not only bring extra computational cost but also give rise to class collision issue <ref type="bibr" target="#b21">[22]</ref> that the semantic similar instances are pushed away since they could be regarded as negative pairs. For example, MoCo <ref type="bibr" target="#b0">[1]</ref> uses a memory queue to store the consistent representations output by a movingaveraged encoder. However, the class collision issue remains unavoidable. Some attempts have been made to address this issue <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>.</p><p>On the contrary, the recent studies of SSL demonstrate that the negative examples are not necessary, termed noncontrastive methods <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b25">[26]</ref>. Recently, mask image modeling (MIM) such as MAE <ref type="bibr" target="#b26">[27]</ref> arises a new trend for self-supervised learning that leverages ViT <ref type="bibr" target="#b27">[28]</ref> to directly reconstruct mask images. However, MIM may not be ready for deep clustering yet as ViT needs to be trained on large datasets such as ImageNet-1k <ref type="bibr" target="#b28">[29]</ref> and it does not learn discriminative representations for deep clustering.</p><p>In summary, SSL methods mainly focus on inducing transferable representations for the (supervised) downstream tasks instead of grouping the data into different semantic classes for deep clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deep Clustering</head><p>Deep clustering <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref> has been significantly advanced by self-supervised representation learning. Most of deep clustering methods are based on contrastive learning by exploiting the discriminative representations, learned from contrastive learning, to assist the downstream clustering tasks <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b37">[38]</ref> or simultaneously optimize representation learning and clustering <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>. For example, SCAN <ref type="bibr" target="#b5">[6]</ref> yields the confident pseudo-labels by the pre-trained SimCLR model, and IDFD <ref type="bibr" target="#b8">[9]</ref> proposes to perform both instance discrimination and feature decorrelation. Although GCC <ref type="bibr" target="#b40">[41]</ref> and WCL <ref type="bibr" target="#b41">[42]</ref> select the neighbor samples from a graph as pseudo-positive examples for contrastive loss, however, they still suffer from the class collision issue as these selected examples may not be truly positive. In a nutshell, all of them are built upon the contrastive learning framework, in which they require a large number of negative examples to maintain uniform representations, inevitably leading to class collision issue.</p><p>Although some attempts have been made to use noncontrastive learning, such as BYOL <ref type="bibr" target="#b2">[3]</ref>, to avoid class collision issue <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>, they produce inferior results as they suffer from the collapse of downstream clustering due to the non-uniform representations.</p><p>Our work advances deep clustering via the two novel techniques to address current drawbacks. First, the proposed PSL maximizes the between-cluster distance, which leads to uniform representations, hence alleviating the collapse of downstream clustering. Second, the proposed positive sampling alignment improves within-cluster compactness. As a result, the proposed ProPos can enjoy the strengths of both worlds: avoidable class collision issue, uniform representation for improved clustering stability, well-separated clusters, and improved within-cluster compactness. In Sec. 6, we discuss the differences from existing methods including CC <ref type="bibr" target="#b7">[8]</ref>, GCC <ref type="bibr" target="#b40">[41]</ref>, WCL <ref type="bibr" target="#b41">[42]</ref>, PCL <ref type="bibr" target="#b6">[7]</ref>, and instance-reweighted contrastive loss <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARY</head><p>Here, we briefly introduce representative contrastive learning and non-contrastive learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Contrastive Learning</head><p>Contrastive learning methods perform instance-wise discrimination <ref type="bibr" target="#b20">[21]</ref> using the InfoNCE loss <ref type="bibr" target="#b45">[46]</ref>. Formally, assume that we have one instance x, its augmented version x + by using random data augmentation, and a set of M negative examples drawn from the dataset,</p><formula xml:id="formula_0">{x ? 1 , x ? 2 , . . . , x ? M }.</formula><p>The contrastive learning aims to learn an embedding function f (?) that maps x onto a unit hypersphere. The corresponding InfoNCE loss for one instance is defined as follows:</p><p>? log</p><formula xml:id="formula_1">exp f (x) T f (x + ) ? exp f (x) T f (x + ) ? + M i=1 exp f (x) T f (x ? i ) ? (1) ? ? f (x) T f (x + ) ? instance alignment + log M i=1 exp f (x) T f (x ? i ) ? instance uniformity ,<label>(2)</label></formula><p>where the representation f (x) is 2 normalized on a unit hypersphere, and the temperature ? controls the concentration level of representations. Intuitively, the InfoNCE loss aims to pull together the positive pair (x, x + ) from two different data augmentations of the same instance, and push x away from M negative examples of other instances. As discussed in <ref type="bibr" target="#b11">[12]</ref>, the In-foNCE loss in Eq. (1) can be approximately decoupled into two terms in Eq. (2): the first term refers to as instance alignment, and the second term instance uniformity. Despite the alignment term pulls together the positive pair, the key to avoiding representation collapse is the uniformity term, which makes the negative examples uniformly distributed on the unit hypersphere. Although alleviating the collapse of downstream clustering, the negative examples may inevitably lead to the class collision issue <ref type="bibr" target="#b12">[13]</ref>, hurting the representations for clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Non-Contrastive Learning</head><p>Non-contrastive methods only optimize the alignment term in Eq. (2) to match the representations between two augmented views <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. Specifically, they often leverage an online, a target, and a predictor network to bridge the gap between these two views with stop gradient operation to avoid representation collapse. In particular, if ? = 0.5, the loss used in <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref> can be written as:</p><formula xml:id="formula_2">?2g (f (x)) T f (x + ) = g (f (x))?f (x + ) 2 2 ? 2, (3) where g(?)</formula><p>, f (?), and f (?) are the predictor, online, and target networks, respectively; g(f (x)) and f (x + ) are 2normalized. Without using negative pairs, non-contrastive learning avoids the class collision issue. However, due to the lack of uniformity, they tend to produce non-uniform representations that usually result in the collapse of downstream clustering, making them unstable for deep clustering; see Sec. 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHOD</head><p>The goal of deep clustering is to learn the representation of images and perform the clustering task simultaneously. Our ProPos advances deep clustering via two novel techniques: prototype scattering loss (PSL) and positive sampling alignment (PSA) detailed in Secs. 4.1 and 4.2, respectively. We then present the overview of ProPos and its EM optimization process in Sec. 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Prototype Scattering Loss</head><p>A good clustering is supposed to have well-separated prototypes/clusters. Assuming that the dataset has K clusters, where K is a predefined number and assumed to be known, it naturally constructs a contrastive loss for these K prototypes as for one prototype, the remaining K ? 1 prototypes are definitely negative examples. Therefore, we propose a prototype scattering loss or PSL, which encourages the prototypical alignment between two augmented views and the prototypical uniformity, hence maximizing the intercluster distance. Specifically, assume we obtain K prototypes from one view in the embedding space, {? 1 , ? 2 , . . . , ? K }, and another K prototypes from another view, {? 1 , ? 2 , . . . , ? K }, our proposed PSL, illustrated in <ref type="figure" target="#fig_0">Fig. 1(a)</ref>, is defined as follows:</p><formula xml:id="formula_3">L psl = 1 K K k=1 ? log exp ? T k ? k ? exp ? T k ? k ? + K j=1 j =k exp ? T k ? j ? (4) ? 1 K K k=1 ? ? T k ? k ? prototypical alignment + 1 K K k=1 log K j=1 j =k exp ? T k ? j ? prototypical uniformity .<label>(5)</label></formula><p>Here, the cluster centers ? k and ? k are computed within a mini-batch B as follows:</p><formula xml:id="formula_4">? k = x?B p(k|x)f (x) x?B p(k|x)f (x) 2 ,<label>(6)</label></formula><formula xml:id="formula_5">? k = x?B p(k|x)f (x) x?B p(k|x)f (x) 2 ,<label>(7)</label></formula><p>where p(k|x) is the cluster assignment posterior probability. When K &gt; |B|, it is obvious that the mini-batch cannot cover all clusters. To this end, we zero out the losses and logits of empty clusters for each iteration. During training, it is critical to estimate accurate p(k|x) to optimize the proposed PSL, so we adopt an EM framework that alternately uses a k-means clustering for every epoch at the E-step, and then minimize Eq. (4) at the M-step, which will be detailed later.</p><p>Intuitively, our PSL for prototypes is similar to conventional contrastive loss in Eq. (1) for instances. The key difference is that PSL will not cause the class collision issue as the prototypes are definitely negative examples for each other, which is more suitable for deep clustering. However, the cluster centers may not be as accurate as expected during the early epochs of training. For an accurate initialization, following <ref type="bibr" target="#b6">[7]</ref>, PSL will be involved in training after the finish of the learning rate warmup.</p><p>Similarly, PSL in Eq. (4) can be approximately divided into Eq. (5): prototypical alignment and prototypical uniformity. On one hand, the prototypical alignment is to align the prototypes between two views, which can stabilize the update of the prototypes. On the other hand, the prototypical uniformity is to encourage the prototypes to be uniformly distributed on a unit hypersphere, which can maximize the inter-cluster distance. We note that there are two clusterlevel losses related to ours: ProtoNCE <ref type="bibr" target="#b6">[7]</ref> to improve cluster compactness and CC <ref type="bibr" target="#b7">[8]</ref> to contrast cluster assignments; we discuss the major differences in Sec. 6. Uniform representation and well-separated clusters. In the context of non-contrastive learning for deep clustering, the lack of uniformity term in Eq. (3) fails to produce uniform representations, which may cause severe collapse of downstream clustering. PSL overcomes this drawback by maximizing the inter-clusters distance between prototypical representations, which yields uniform representations and well-separated clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Positive Sampling Alignment</head><p>Following previous discussion, the negative examples are essential for contrastive-based deep clustering to learn uniform representations, at the cost of inevitable class collision issue <ref type="bibr" target="#b21">[22]</ref> that harms the within-cluster compactness. On the other hand, non-contrastive learning can avoid the class collision issue by only optimizing the instance alignment. However, the conventional instance alignment in Eq. (3) only encourages the representation of one augmented view to be close to another view. In the context of clustering, such compactness is instance-wise and neutral for deep clustering, since the semantic class information cannot be captured at only instance level.</p><p>To improve within-cluster compactness for conventional instance alignment while avoiding class collision issue, we propose to optimize the opposite of the uniformity instead, i.e. the compactness within clusters. We aim to encourage the neighboring examples around one augmented viewsampled from the embedding space and assumed to be truly positive pairs-to be aligned with another view, as shown in <ref type="figure" target="#fig_0">Fig. 1(b)</ref>. Our motivation is that although we cannot guarantee the negative pairs constructed from the dataset are truly negative, we can certainly assume that the neighboring samples around one view in the embedding space are truly positive with respect to another view and belong to the same class. Therefore, we propose a positive sampling alignment to extend the instance alignment in Eq. (3) by taking into account the neighboring samples towards improved withincluster compactness.</p><p>The key step of PSA is to sample the neighboring examples v. A natural way is modeling the representation of one augmented view of an instance as a continuous distribution in the embedding space. We thus introduce a Gaussian distribution thanks to its simplicity, which can be formulated as follows:</p><formula xml:id="formula_6">v ? N f (x), ? 2 I ,<label>(8)</label></formula><p>where I represents the identity matrix and ? is a positive hyperparameter controlling how many samples around one view can be treated as positive pairs with another view. However, the sampled examples from Eq. (8) cannot allow the error to be backpropagated through the network to update the network parameters. By leveraging the reparametrization trick <ref type="bibr" target="#b46">[47]</ref>, the positive sampling can be implemented as follows:</p><formula xml:id="formula_7">v = f (x) + ? , where ? N (0, I) .<label>(9)</label></formula><p>We then extend the instance alignment in Eq. (3) by taking into account the neighboring samples. With only sampling one example from the Gaussian distribution, the positive sampling alignment (PSA) can be formally defined as:</p><formula xml:id="formula_8">L psa = g(v) ? f (x + ) 2 2 = g (f (x) + ? ) ? f (x + ) 2 2 .<label>(10)</label></formula><p>Here, when ? = 0, PSA reduces to Eq. (3). Avoidable class collision issue. In the context of noncontrastive learning without negative examples, our PSA can guarantee that the positive examples around one instance, sampled in the embedding space, are from the same cluster and form truly positive pairs. Therefore, optimizing PSA loss would not cause class collision issue that exists in contrastive-based deep clustering methods. We discuss the difference from <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref> that sample positive examples from the dataset in Sec. 6. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Overview of ProPos and its optimization</head><p>We present the overview of our ProPos in <ref type="figure" target="#fig_1">Fig. 2</ref> and optimize it in an EM framework to facilitate the understanding of the training procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Overview</head><p>We build ProPos upon non-contrastive learning framework similar to BYOL, which is comprised of three networks: an online, a target, and a predictor. During training, the parameters of target network are momentum updated (a.k.a moving averaged) from the ones of online network, following</p><formula xml:id="formula_9">? target = m? target + (1 ? m)? online ,<label>(11)</label></formula><p>where m ? [0, 1) is the coefficient, and ? * denotes the parameters. Two different random data augmentations from the same inputs are fed into the network to optimize the proposed losses in an EM framework. Specifically, k-means clustering is performed in the E-step at the beginning of each epoch to obtain the p(k|x), which is fixed in the latter training to optimize the proposed PSL. The ? k and ? k are computed from online and target networks using Eqs. <ref type="formula" target="#formula_4">(6)</ref> and <ref type="formula" target="#formula_5">(7)</ref>, respectively. Furthermore, PSA is applied to the representations from online network, which are then passed through predictor network for alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">EM framework</head><p>The optimization of ProPos is done in an EM framework, where E-step and M-step are detailed as follows; supplemental Sec. 8 presents detailed derivations. E-step: This step aims to estimate p(k|x) for the proposed PSL. We perform spherical k-means algorithm on the features extracted from the target network since the target network performs more stable and yields more consistent clusters, similar to BYOL and MoCo. Although we need an additional k-means clustering to obtain the cluster pseudolabels p(k|x) for every r epochs, we found that even with a larger r &gt; 1, our method can still produce consistent performance improvement over the baseline methods. Therefore, our method will not introduce much computation cost and is robust to the cluster pseudo-labels; see detailed results in Secs. 5.5 and 5.6. Finally, with p(k|x), we build the prototypical representations within a mini-batch without additional memory. M-step: Combining PSL in Eq. (4) and the PSA in Eq. (10) yields our objective function for M-step as follows:</p><formula xml:id="formula_10">L = L psa + ? psl L psl ,<label>(12)</label></formula><p>where ? psl controls the balance between two loss components. Therefore, there are only two hyper-parameters in the loss function, including: ? in L psa and the loss weight ? psl ; see the effects of hyper-parameters in Sec. 5.5.</p><p>The training procedure of the proposed ProPos is presented in Algorithm 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Datasets</head><p>We conducted experiments on seven benchmark datasets, including CIFAR-10 <ref type="bibr" target="#b47">[48]</ref>, CIFAR-20 <ref type="bibr" target="#b47">[48]</ref>, STL-10 <ref type="bibr" target="#b48">[49]</ref>, ImageNet-10 <ref type="bibr" target="#b30">[31]</ref>, ImageNet-Dogs <ref type="bibr" target="#b30">[31]</ref>, Tiny-ImageNet <ref type="bibr" target="#b49">[50]</ref>, and ImageNet-1k <ref type="bibr" target="#b28">[29]</ref>, which are summarized in <ref type="table" target="#tab_1">Table 1</ref>. We note that CIFAR-20 contains 20 superclasses of CIFAR-100. STL-10 includes extra unlabeled images. ImageNet-10, ImageNet-Dogs, and Tiny-ImageNet are the widely-used subsets of ImageNet-1k <ref type="bibr" target="#b28">[29]</ref>, containing 10, 15, 200 classes, respectively. This paper follows the experimental settings widely used in deep clustering work <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>, including the image size, backbone, and train-test split. For image size, we use 32 ? 32 for CIFAR-10 and CIFAR-20, 96 ? 96 for STL-10, ImageNet-10, and ImageNet-Dogs, and 224 ? 224 for Tiny-ImageNet and ImageNet-1k. For train-test split, we use the whole datasets including training and testing set for CIFAR-10 and CIFAR-20 while both labeled and unlabeled data are employed for STL-10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Backbones</head><p>We use ResNet-34 <ref type="bibr" target="#b50">[51]</ref> as the backbone for fair comparisons to report the main results on moderate-scale benchmark datasets. We use ResNet-18 <ref type="bibr" target="#b50">[51]</ref> on Tiny-ImageNet and ResNet-50 <ref type="bibr" target="#b50">[51]</ref> on ImageNet-1k, following the literature. Unless noted otherwise, we use ResNet-18 for the rest of the experiments. Since the image sizes of CIFAR-10 and CIFAR-100 are relatively small, following <ref type="bibr" target="#b1">[2]</ref>, we replace the first convolution layer of kernel size 7 ? 7 and stride 2 with a convolution layer of kernel size 3 ? 3 and stride 1, and remove the first max-pooling layer for all experiments on CIFAR-10 and CIFAR-100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Implementation details</head><p>We train all methods with 1,000 epochs, strictly following the literature <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, and adopt the stochastic gradient descent (SGD) optimizer and the cosine decay learning rate schedule with 50 epochs for learning rate warmup. The base learning rate for MoCo v2 <ref type="bibr" target="#b51">[52]</ref>, BYOL <ref type="bibr" target="#b2">[3]</ref>, and ProPos were 0.05, scaled linearly with the batch size (LearningRate = 0.05?BatchSize/256). Note that the learning rates for predictor networks of BYOL and ProPos are 10? as the learning rate of feature extractor. It is relatively important to achieve satisfactory performance, as discussed in <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. For other hyperparameters of ProPos, the temperature ? , ? psl for prototypical scattering loss, and ? for positive sampling were set as 0.5, 0.1, and 0.001, respectively. The mini-batch size was 512 for MoCo and 256 for the remaining methods. ProPos was trained on 4 NVIDIA V100 GPUs.</p><p>Regarding CC <ref type="bibr" target="#b7">[8]</ref> and PCL <ref type="bibr" target="#b6">[7]</ref>, we tried our best to reproduce their results for fair comparisons. For CC, we used their official code. For PCL, under the fair conditions of MoCo, we set the loss weight of ProtoNCE to 0.01 and the number of clusters to {250, 500, 1000} following the suggestions of authors, which we found can achieve the best results. We integrated CC and PCL into BYOL by adding their losses without changing other settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">Configurations of SSL frameworks</head><p>We adopt the same data augmentations as SimCLR <ref type="bibr" target="#b1">[2]</ref>, including ResizedCrop, ColorJitter, Grayscale, and Hori-zontalFlip. We have removed GaussianBlur since we only used a small image size for all datasets. We also strictly follow the settings of BYOL <ref type="bibr" target="#b2">[3]</ref>. Specifically, despite the standard ResNet backbones, the projection and predictor networks have the architectures of FC-BN-ReLU-FC, where the projection dimension and hidden size were 256 and 4096 for both two networks, respectively. For fair comparisons, we have also set the projection dimension of MoCo v2 as 256. We have used symmetric loss for all methods, i.e., swapping two data augmentations to compute twice loss. For the momentum hyperparameter m ? [0, 1), we set it to 0.996 for both BYOL and ProPos same as <ref type="bibr" target="#b2">[3]</ref> and 0.99 for MoCo v2. For MoCo v2, the queue size, temperature for InfoNCE loss, weight decay were 4,096, 1.0, and 1.0 ? 10 ?4 , respectively. We have not employed SyncBN in ProPos. We note that SyncBN would introduce much additional computation cost. Instead, we adopt the shufflingBN in MoCo to avoid the trivial solution of non-contrastive learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Empirical Justification</head><p>We provide an empirical justification on how the proposed ProPos improves representation learning for deep clustering from the aspects of PSL and PSA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">The role of PSL</head><p>The non-uniform representations produced by noncontrastive representation learning would lead to the collapse of downstream clustering where most samples are assigned to few clusters. We emphasize that it is desirable to avoid the trivial solution for deep clustering. For example, CC <ref type="bibr" target="#b7">[8]</ref> and etc <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b52">[53]</ref> have usually employed an entropy term in loss function to regularize the model equally assigning the images into different clusters. This paper mainly investigates this phenomenon of non-contrastive representation learning for deep clustering, and the theoretical analysis can be found in <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b53">[54]</ref>.</p><p>Our ProPos can encourage cluster uniformity for representations via PSL. Here, we use the representative noncontrastive learning method, Bootstrap Your Own Latent (BYOL), as the representation learning for deep clustering. We performed spherical k-means on the learned representations for the clustering task with 10 different initializations. Following <ref type="bibr" target="#b3">[4]</ref>, we use the standard deviation (STD) of 2normalized representations to measure the uniformity. Ideally, if the 2 -normalized representations are uniformly distributed on a unit hypersphere, we have STD [z ] ? 1/ ? d, where z and d are the 2 -normalized version and the dimension of the feature representation z. To justify the effectiveness of ProPos, we conducted the following experiments in terms of the uniformity of the representations, the collapse of clustering, and the clustering performance.</p><p>First, we visualize the uniformity of representations in <ref type="figure" target="#fig_3">Fig. 3(a)</ref>. Taking a look at STDs during the training stage, ProPos produces higher STDs, while BYOL performs unstable with the STDs gradually decreasing. Note that a higher standard deviation close to 1/ ? d indicates more uniform representations. Our ProPos yields more uniform representations than BYOL. Most importantly, the uniformity of ProPos is rather stable during training.</p><p>Second, we further visualize the cluster imbalance to measure the potential collapse during clustering. More specifically, we compute the cluster imbalance ratio between the cluster with least samples and the cluster with most samples, min(</p><formula xml:id="formula_11">{N k } K k=1 )/ max({N k } K k=1 ),</formula><p>where N k is the number of samples in k-th cluster. A higher value indicates more balanced clusters. In addition, we also show the cluster statistics or the sorted number of samples in each cluster for the model at 1000-th epoch. The results of cluster imbalance during training and the cluster statistics at the final epoch are shown in <ref type="figure" target="#fig_3">Fig. 3(b)</ref> and (c). <ref type="figure" target="#fig_3">Fig. 3(b)</ref> shows that the kmeans clustering process of ProPos produces more balanced clusters with a higher cluster imbalance ratio. On the contrary, the clusters of BYOL are highly imbalanced, which is consistent with decreasing STDs. Moreover, <ref type="figure" target="#fig_3">Fig. 3(c)</ref> shows that the cluster statistics for ProPos are approximately and equally assigned to different clusters, compared to almost long-tailed assignments of BYOL. The more balanced clusters validate that ProPos can alleviate the collapse of kmeans clustering over BYOL. Finally, <ref type="figure" target="#fig_3">Fig. 3(d)</ref> shows the clustering performance comparison between the proposed ProPos and BYOL, which is measured by the normalized mutual information (NMI) between clustering results and ground-truth labels. We can see that ProPos produces higher and more stable NMIs than BYOL. In line with the analysis above, we conclude that directly applying BYOL to deep clustering, although avoiding class collision issue, suffers from the collapse of k-means clustering due to the non-uniform representations. In contrast, ProPos with PSL yields more uniform representations and well-clustered samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2.2</head><p>The role of PSA PSA assumes that the sampled neighbors are truly positive examples with respect to another view, i.e., they belong to the same semantic classes. To validate this assumption, we investigate the behavior of PSA during training by checking whether the semantic classes of input examples have been changed.</p><p>First, we perform k-NN classification to predict the classes of both inputs and their sampled neighbors from <ref type="bibr">TABLE 2</ref> Clustering results (%) of various methods on five benchmark datasets. The best and second best results are shown in bold and underline, respectively. We split different methods according to different training paradigms. The works most related to our method are IDFD and PCL that improve the representations for clustering. <ref type="table" target="#tab_1">CIFAR-20  STL-10  ImageNet-10  ImageNet-Dogs   NMI  ACC  ARI  NMI  ACC  ARI  NMI  ACC  ARI  NMI  ACC  ARI  NMI  ACC  ARI   IIC [36</ref> testing set, and then use the proportion of sampled neighbors that have preserved original classes as the preservation rate. We run the experiments 10 times with different ? for PSA. As shown in <ref type="figure" target="#fig_4">Fig. 4(a)</ref>, even at the early training stage, the sampled neighbors well preserve original classes for ? &lt; 0.005. The preservation rate drops as expected for ? = 0.01 since PSA may sample the instances from another cluster for large ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-10</head><p>Second, we showcase some randomly-selected input images whose nearest neighbors have been changed during the sampling procedure, Specifically, <ref type="figure" target="#fig_4">Fig. 4(b)</ref> visualizes the input images, their nearest neighbors, and the sampled neighbors. We note that we replaced the images of sampled neighbors with their nearest neighbors since it is too hard to reconstruct the image from embedding space. Obviously, the sampled neighbors belong to the same class as the input images even at the early stage of training (i.e. 100th epoch).</p><p>In summary, the results suggest that the sampled neighbors could be truly positive examples both quantitatively and qualitatively so that PSA can improve the within-cluster compactness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Main Results</head><p>In this section, we evaluate ProPos with previous state-ofthe-art clustering methods on various benchmark datasets. We divide these methods into 5 types: i) methods without using contrastive learning; ii) multi-stage methods requiring step-by-step pretraining or finetuning; iii) methods directly outputting the cluster assignments; iv) methods learning general representations, e.g., MoCo; and v) methods improving representation learning for clustering. We strictly follow the experimental settings of previous works <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> for fair comparisons. We reproduced PCL <ref type="bibr" target="#b6">[7]</ref>, SimSiam <ref type="bibr" target="#b1">[2]</ref>, and BYOL <ref type="bibr" target="#b2">[3]</ref> under the same conditions, and directly use the their learned representations for k-means clustering.</p><p>In terms of qualitative results of clustering, we visualize the learned representations by t-SNE <ref type="bibr" target="#b56">[57]</ref> for four different training epochs throughout the training process in supplemental <ref type="figure" target="#fig_0">Fig. 10</ref> and the outlier points produced by the model at 1000-th epoch on CIFAR-10 in supplemental <ref type="figure" target="#fig_0">Fig. 11</ref>. For fair comparisons, supplemental <ref type="table" target="#tab_1">Table 10</ref> presents the results excluding the testing set for CIFAR-10/20 and using a larger image size for ImageNet-10/Dogs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Results on moderate-scale datasets</head><p>The comparisons on five moderate-scale datasets are reported in <ref type="table" target="#tab_9">Table 2</ref>. The results of MoCo are referred from <ref type="bibr" target="#b9">[10]</ref>.</p><p>For fair comparison, we excluded SPICE <ref type="bibr" target="#b10">[11]</ref> in <ref type="table" target="#tab_9">Table 2</ref> since it requires multiple pre-training stages. ProPos achieves significant performance improvement on all benchmark datasets, demonstrating the superiority of ProPos for deep clustering to capture the semantic class information.</p><p>On the ImageNet-10, our ProPos achieves competitive performance as compared to IDFD <ref type="bibr" target="#b8">[9]</ref> since this dataset is relatively small with only 13K images, which cannot arise discriminative differences for current state-of-the-art methods. On the ImageNet-Dogs, a fine-grained dataset containing different species of dogs from the ImageNet dataset, there are almost 20% improvements over previous <ref type="bibr">TABLE 4</ref> Clustering results (%) on ImageNet-1k using ResNet-50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method AMI</head><p>DeepCluster <ref type="bibr" target="#b19">[20]</ref> 28.1 MoCo <ref type="bibr" target="#b0">[1]</ref> 28.5 PCL <ref type="bibr" target="#b6">[7]</ref> 41.0 ProPos (ours) 52.5 state-of-the-art work. The contrastive-based methods cannot handle this kind of dataset due to severe class collision issue that pushes away the instances from the same class. Meanwhile, IDFD can deal with this problem to some degree thanks to the feature decorrelation along with the instance discrimination. Furthermore, BYOL and SimSiam can achieve significant improvements, which suggests a great potential for non-contrastive representation learning for deep clustering without suffering class collision issue. However, our ProPos has introduced further substantial improvements for deep clustering by addressing existing issues. Although CC <ref type="bibr" target="#b7">[8]</ref> and TCL <ref type="bibr" target="#b37">[38]</ref> achieve the better NMIs on STL-10, we highlight that they use a large image size of 224 ? 224 for all datasets, which is not fair to ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Results on large-scale datasets</head><p>To validate the effectiveness of our method on large-scale datasets with large number of classes, we evaluate it on Tiny-ImageNet and ImageNet-1k, which contains 200 and 1000 classes, respectively. The results are reported in Tables 3 and 4. We note that we exclude the methods that their authors did not report results on the corresponding datasets from <ref type="table" target="#tab_3">Tables 3 and 4</ref>. For ImageNet-1k, we strictly follow the settings in <ref type="bibr" target="#b6">[7]</ref> and employed Adjusted Mutual Information (AMI) to evaluate the performance, the results in <ref type="table">Table 4</ref> are referred from <ref type="bibr" target="#b6">[7]</ref>, and we trained a ResNet-50 for 200 epochs same as <ref type="bibr" target="#b6">[7]</ref>. The results show the strong generalization ability of ProPos on complex datasets with a large number of clusters. To further show the effectiveness of ProPos for downstream classification task, we conducted the linear evaluation on ImageNet-1k dataset, and provide the comparisons with the recent state-of-the-art methods in <ref type="table" target="#tab_4">Table 5</ref>. Following the same settings in <ref type="bibr" target="#b3">[4]</ref>, we have trained the linear classifier for 90 epochs with a batch size of 4,096, an initial learning rate of 1.6, cosine learning rate decay, and the SGD optimizer of momentum 0.9 and weight decay 0. Under fair conditions, ProPos outperforms other competitors by a clear margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation Study</head><p>Here, we perform detailed ablation studies with both quantitative and qualitative comparisons to provide more insights into why ProPos performs well for deep clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Quantitative ablation study</head><p>The quantitative results are shown in <ref type="table">Table 6</ref>. Ablation study of PSL and PSA. ProPos w/o PSA improves the baseline results by a large margin while ProPos w/o PSL achieves marginal improvements, which indicates that PSL is the key to boosting the clustering performance. However, PSA plays an important role in two parts. First, simply using the PSA can stable and further improve the performance than the baseline BYOL (only instance alignment loss), especially when the number of semantic classes increases for CIFAR-20. Second, PSA can make ProPos better for clustering when PSL is used in conjunction with the PSA to pull together the neighbor examples. This is because the well-seperated clusters by PSL can further ensure that PSA samples the positive neighbors that are in the same semantic classes than the one without PSL. On the other hand, PSL only considers inter-cluster distance, and cannot benefit within-cluster compactness. Therefore, the combination of the positive sampling and PSL achieves the best clustering results, where PSL aligns the cluster centers between two augmented views and maximizes the inter-cluster distance, and PSA improves the within-cluster compactness.</p><p>To further explore the effect of PSL, following Eq. (5) we split PSL into alignment and uniformity terms denoted as PSL-alignment and PSL-uniformity in <ref type="table">Table 6</ref>. It is clear that the performance gain from the alignment term is marginal while the gain from the uniformity term is significant. For only alignment term, we compute the loss after predictor network instead of feature extractor, otherwise, representation collapse will turn out. This indicates that uniformity is more important than alignment which can scatter the prototypes to encourage the uniform representations to address the issues in Sec. 5.2. However, the alignment term is essential to stabilize the training process, as demonstrated in the results for CIFAR-20 with more clusters. Ablation study of self-supervised learning framework. To alleviate the bias of self-supervised learning framework, we conduct experiments in two folds. First, we integrate CC <ref type="bibr" target="#b7">[8]</ref> and PCL <ref type="bibr" target="#b6">[7]</ref> into BYOL; the results in <ref type="table">Table 6</ref> show that both of them compromise clustering performance and become unstable. This is because CC contrasts the cluster probability not helpful for representation learning, and PCL <ref type="bibr">TABLE 6</ref> Ablation studies (NMI/ACC/ARI) for different self-supervised learning frameworks, positive sampling alignment (PSA), and prototype scattering loss (PSL) for ProPos. The best and second best results are shown in bold and underline, respectively.  would collapse without negative examples; see supplemental <ref type="figure">Fig. 9</ref> for detailed analysis. We emphasize that BYOL has addressed the class collision issue. Instead, this paper proposes the ProPos with PSL to scatter the prototypes by maximizing inter-cluster distance and positive sampling to improve within-cluster compactness. Second, we replace the cluster head of CC with our PSL on the representations while keeping other hyper-parameters unchanged. Although class collision issue remains, the significant improvements over CC on both datasets suggest that 1) PSL over representation prototypes is better than the one over cluster probabilities, and 2) PSL can be generalized to other self-supervised learning frameworks.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Qualitative ablation study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.3">Effect of predefined number of clusters</head><p>In the above experiments, the number of clusters is predefined as the number of ground-truth classes, which cannot be identified in the practical scenarios. To this end, we conduct experiments on CIFAR-10 and CIFAR-20 with different number of clusters, i.e., K ? {5, 10, 20, 30, 40, 50}.</p><p>We reported NMIs following <ref type="bibr" target="#b19">[20]</ref> in <ref type="figure" target="#fig_7">Fig. 6</ref>. We note that the predefined K of ProPos during the training of ProPos is the same as the K in k-means clustering process for evaluation. To further investigate the influences of K, we also reported the results of vanilla BYOL during k-means clustering.</p><p>The results in <ref type="figure" target="#fig_7">Fig. 6</ref> demonstrate that BYOL and ProPos have the same behavior on these two datasets. For overclustering cases (K is larger than the true number of classes), the trends on these two datasets are opposite. Specifically, over-clustering leads to a performance drop for CIFAR-10, but it leads to an increase for CIFAR-20. However, our ProPos can still produce large improvements over BYOL with the same predefined number of clusters. The opposite results are due to the significant difference between these two datasets. Although having the same number of samples, CIFAR-10 has 10 distinct classes while CIFAR-20 has, in fact, 100 classes but uses 20 super-classes instead. Same trends are also consistently reported in <ref type="bibr" target="#b19">[20]</ref>. In other cases, if the representations are well aligned within the same semantic clusters, the over-clustering would try to destroy the structures of the clusters and push the semantically similar examples away, which certainly compromises the clustering performance. For under-clustering cases, the clustering performance has been significantly harmed for both two datasets and two methods. In supplemental <ref type="figure" target="#fig_0">Fig. 12</ref>, we have visualized the learned representations for underclustering, which shows that the examples from the same semantic classes can be still clustered together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Hyperparameter Analysis</head><p>To investigate the effect of different hyperparameters, we conduct extensive experiments on the CIFAR-10/20 datasets. For the projection dimension, backbone, and data augmentation of SSL, we adopted the BYOL as the baseline method. The results are reported in <ref type="figure" target="#fig_8">Fig. 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Frequency of performing k-means clustering</head><p>ProPos performs k-means clustering for every r epoch. Here, we study how different r influences the clustering performance. The results in <ref type="figure" target="#fig_8">Fig. 7(a)</ref> demonstrate ProPos is robust to large r and the cluster pseudo-labels, which means it is not necessary to perform clustering for every epoch so that the computation cost can be significantly reduced. In summary, we suggest that r can be set to <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8]</ref> by considering the datasets and computation resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">The hyperparameter ? in PSA</head><p>The hyperparameter ? in PSA controls the degree of positive sampling. Taking a look at ? ? [0, 10 ?3 ] in <ref type="figure" target="#fig_8">Fig. 7(b)</ref>, although introducing the positive sampling into BYOL causes a slight drop on CIFAR-10, the clustering performance becomes more stable as evidenced by the standard deviation. This is because the neighbors of one sample are regarded as positive examples. Besides, the performance for CIFAR-20 has increased over baseline with the standard deviation reduced. These results indicate that positive sampling can improve the stability of performance. However, when ? is too large, the performance becomes unstable and drops a lot. It is not surprising since during positive sampling with large ?, the instances from other clusters could be sampled and regarded as positive examples. Therefore, we suggest setting ? to a small value, saying (0, 10 ?3 ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.5.3</head><p>The hyperparameter ? psl for PSL The hyperparameter ? psl controls the importantance of PSL. The results in <ref type="figure" target="#fig_8">Fig. 7(c)</ref> suggest that ProPos is robust to different choices on CIFAR-20. However, the higher ? psl leads to instability on CIFAR-10. The possible reason is that CIFAR-20 is more diverse and has more semantic classes than CIFAR-10 (100 versus 10). Therefore, we suggest that ? psl can be set to [0.01, 0.1], which has demonstrated superior performance on both two datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.4">Projection dimension</head><p>The projection dimension describes the embedding space of SSL. The results in <ref type="figure" target="#fig_8">Fig. 7(d)</ref> shows that ProPos achieves consistent and significant performance improvement over baseline regardless of different projection dimension. <ref type="figure" target="#fig_8">Fig. 7(e)</ref> shows that with the deeper ResNet networks, ProPos achieves significant improvements with small standard deviations for clustering, demonstrating its superior stability and performance against the baseline method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.5">ResNet backbone</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.6">Data augmentation</head><p>Data augmentation is important for self-supervised learning. <ref type="figure" target="#fig_8">Fig. 7(f)</ref> shows that the performance drops for both BYOL and ProPos when removing some data augmentations. However, the results suggest that ProPos still performs more stable and is robust to data augmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Computational Cost</head><p>The main additional computational cost of ProPos is the kmeans clustering procedure. We have implemented the kmeans algorithm with k-means++ <ref type="bibr" target="#b64">[65]</ref> initialization using PyTorch to utilize the GPU and accelerate the clustering process. We performed k-means clustering with 10 different initialization in cosine distance. <ref type="table" target="#tab_6">Table 7</ref> summarizes the training time of ProPos and BYOL on different datasets. ProPos does not introduce much additional computational cost. Besides, as suggested in the results of <ref type="figure" target="#fig_8">Fig. 7(a)</ref>, ProPos is robust to the different r, so there is no need to perform k-means for every epoch. Therefore, the training time can be further reduced for ProPos. The computational cost of the PSL is also small since we build the cluster centers within mini-batch, saying that ProPos does not need additional memory to store the cluster centers. Consequently, considering the promising performance improvements, the additional computational cost is relatively affordable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Subsets of ImageNet</head><p>In addition, we also reported the clustering results on Im-ageNet subsets like SCAN <ref type="bibr" target="#b5">[6]</ref> in <ref type="table" target="#tab_7">Table 8</ref>. We strictly follow the settings in <ref type="bibr" target="#b5">[6]</ref>: we have adopted the same 50, 100, and 200 classes from ImageNet, clustered on the training set, and tested on the validation set. We have used the same experimental settings as the other benchmarked datasets and trained ProPos with ResNet-50 for 300 epochs. We note that SCAN has used the pre-trained model of MoCo trained on the full ImageNet for 800 epochs. The results are   directly referred from their published paper including kmeans with pre-trained MoCo, SCAN after the clustering step, and SCAN after the self-labeling step. With much fewer training epochs and training data, ProPos still produces better performance by a clear margin, demonstrating the superiority of ProPos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Long-tail Dataset</head><p>We also conducted additional experiments in <ref type="table">Table 9</ref> to demonstrate the ability of ProPos handling the long-tailed datasets. We built the long-tailed version of CIFAR-10 and CIFAR-20, termed CIFAR-10-LT and CIFAR-20-LT using the codes of <ref type="bibr" target="#b65">[66]</ref>, which follows <ref type="bibr" target="#b66">[67]</ref>, <ref type="bibr" target="#b67">[68]</ref>. Specifically, they were built upon the training datasets under the control of data imbalance ratio min({N k } K k=1 )/ max({N k } K k=1 ) = 0.1. Consequently, the samples in the long-tailed datasets are almost all in the minority classes (head), versus few samples in other classes (tail). MoCo v2 cannot handle this problem well due to the class collision issue, as a result, the samples in the head will be pushed away and the ones in the tail will be mixed together. BYOL and ProPos do not need negative examples so that they outperform MoCo v2 by a large margin. By introducing PSA and PSL, we can further boost the clustering performance of BYOL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9">Boosting Performance with Memory Queue</head><p>To better represent the prototype of one class, the mini-batch should contain a sufficient number of samples. However, this would significantly increase the requirement of GPU memory when one dataset has a large number of clusters. Here, we highlight that although we use a mini-batch size of 256, we find that ProPos generalizes well on the datasets such as Tiny-ImageNet with 200 classes (about 1 sample per class in a mini-batch) and ImageNet-1k with 1,000 classes (about 0.25 sample per class in a mini-batch).</p><p>To compute class prototypes accurately with a small mini-batch size, we propose to employ a memory queue for updating prototypes. In the vanilla PSL, we use the representations within mini-batch B to estimate the prototypes in Eqs. (6) and <ref type="bibr" target="#b6">(7)</ref>. With a memory queue Q used in <ref type="bibr" target="#b0">[1]</ref> to store the representations from the momentum-updated encoder, we can update the prototypes with samples in both minibatch and memory queue, B ? Q.</p><p>To show the effectiveness of the memory queue, we conduct the experiments on Tiny-ImageNet as it is challenging <ref type="bibr">TABLE 9</ref> Clustering results (%) on long-tailed datasets of different self-supervised learning frameworks and our proposed ProPos.  enough with 200 classes, and the corresponding results are shown in <ref type="figure" target="#fig_9">Fig. 8</ref>; we trained the model with the same settings as detailed in Section 5.1.3 except for 200 epochs. As shown in <ref type="figure" target="#fig_9">Fig. 8</ref>, the performance can be further improved with more samples used to compute the prototypes. However, the performance could drop when the size of memory queue becomes too large, saying 4,096 in <ref type="figure" target="#fig_9">Fig. 8</ref>. The reason is that when the memory queue is too large, the representations enqueued at early iterations may be far away from the true ones due to the longer update of the encoder <ref type="bibr" target="#b0">[1]</ref>. Moreover, using the memory queue brings more computational costs and introduces an additional hyperparameter-the size of memory queue. Therefore, ProPos works well when the mini-batch size is small compared to the number of classes, and its performance can be further improved with a memory queue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-10-LT CIFAR-20-LT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>In this section, we discuss the differences between our method and previous works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Relation to CC</head><p>Although both PSL and CC <ref type="bibr" target="#b7">[8]</ref> are class-level contrastive loss, which perform contrastive learning at the cluster level, they have the following difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>The class-level contrastive loss in CC implements the contrastive loss on the cluster probabilities while ours on the representation of cluster centers. Implementing contrastive loss on the cluster probability in <ref type="bibr" target="#b7">[8]</ref> would lose the semantic information of the learned representations, which is not helpful for representation learning. Specifically, given the x ? B, CC obtains the cluster assignments P k = [p(k|x <ref type="bibr" target="#b0">(1)</ref> ), . . . , p(k|x (N ) )] from one view and P k from another view, and then contrasts P k and P k at the cluster level using the InfoNCE loss. In contrast, PSL implements the contrastive loss on the representation of the cluster centers within a mini-batch using the pseudo-labels from k-means clustering. As a result, PSL is able to sense the semantic information of the latent space and make the representations of clusters more discriminative and suitable for the clustering task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>The class-level contrastive loss in CC does not encourage cluster uniformity while our PSL does. CC still needs the instance-wise contrastive loss to encourage instance uniformity, which inevitably introduces the class collision issue.</p><p>In addition to these differences, experimentally, we also compare the PSL and CC <ref type="bibr" target="#b7">[8]</ref> in the same BYOL framework and report the results in <ref type="table">Table 6</ref>. The experimental results show that compared to BYOL, BYOL+CC drops the performance and makes the training unstable as CC fails to encourage uniform representations. Under the same conditions, ProPos achieves significant improvements over BYOL+CC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Relation to GCC and WCL</head><p>To alliterate the class collision issue, GCC <ref type="bibr" target="#b40">[41]</ref> and WCL <ref type="bibr" target="#b41">[42]</ref> built a graph to label the neighbor samples as pseudopositive examples. Then, they enforce the two data augmentations of one example to be close to its multiple pseudopositive examples using a supervised contrastive loss. GCC adopted a moving-averaged memory bank for the graphbased pseudo-labeling while WCL built the graph within a mini-batch. GCC and WCL mainly focus on how to effectively select positive examples from mini-batch/memory bank to alleviate the class collision issue. Here, we divide the class collision issue into the following two cases:</p><p>? Negative class collision issue: negative examples may not be truly negative, which is the case contrastive learning faces. Consequently, they still suffer from the positive class collision issue as the selected pseudo-positive examples may not be truly positive. In addition to this, they also suffer from the negative class collision issue since they still need negative examples for instance-wise contrastive learning.</p><p>We summarize the difference between our PSA and theirs in the following four aspects. ? GCC and WCL still rely on instance-wise contrastive loss that could lead to class collision issue while ours can avoid class collision issue by using noncontrastive BYOL.</p><p>? GCC and WCL require additional computational cost for graph construction while ours is rather cheap in sampling one example in the embedding space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Relation to PCL</head><p>Here, we summarize the difference between our ProPos and PCL <ref type="bibr" target="#b6">[7]</ref> in terms of the losses and EM frameworks. First, we summarize the difference between our PSL and ProtoNCE loss used in PCL as follows.</p><p>? Our ProPos can avoid class collision issue while PCL cannot. ProPos is based on BYOL that does not require negative examples for representation learning while PCL is based on instance-wise contrastive loss that requires a number of negative examples for representation learning, inevitably leading to class collision issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>The proposed PSL in ProPos is conceptually different from the ProtoNCE in PCL. PSL is to maximize the inter-cluster distance to form a uniformly distributed space while ProtoNCE is to minimize the instance-to-cluster distance to improve the withincluster compactness. The within-cluster compactness of ProPos is improved by the proposed positive sampling alignment.</p><p>? Pure PSL can work well for deep clustering while ProtoNCE requires another InfoNCE to form uniformly distributed space. This is a direct result of the different designs of the losses. PSL can maximize the inter-cluster distance to form a uniformly distributed space while ProtoNCE suffers from collapse without the help of another InfoNCE to form such a space.</p><p>Second, we summarize the difference between our ProPos and PCL in the EM framework. Formulating ProPos into an EM framework can offer more insights about ProPos and make it easy to understand. Although both in an EM framework, the M-step in PCL is significantly different from the one in our ProPos. More specifically, the M-step in PCL is to optimize the ProtoNCE, which is an instance-to-prototypes contrastive loss to improve the within-cluster compactness while the M-step in our ProPos is to optimize the proposed PSL, which is a prototypes-to-prototypes contrastive loss to maximize the inter-cluster distance for better clustering performance. In addition, ProPos also proposes a positive sampling alignment by sampling positive examples around each sample to improve within-cluster compactness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Relation to Instance-reweighted Contrastive Loss</head><p>We provide a new perspective to understand the proposed cluster-wise PSL from instance-reweighted contrastive loss <ref type="bibr" target="#b44">[45]</ref>. Here, we first focus on analyzing the alignment term of PSL. By substituting ? k and ? k into the prototypical alignment term of PSL, we can rewrite the alignment term as:</p><formula xml:id="formula_12">1 K K k=1 ? ? T k ? k ? (13) = 1 K K k=1 ? 1 ? x?B p(k|x)f (x) T c k x?B p(k|x)f (x) c k (14) = 1 K K k=1 ? 1 ? N i=1 N j=1 p(k|x i )p(k|x j )f (x i ) T f (x j ) c k c k (15) = N i=1 N j=1 ? 1 K K k=1 p(k|x i )p(k|x j ) c k c k wij f (x i ) T f (x j ) ? ,<label>(16)</label></formula><p>where</p><formula xml:id="formula_13">p(k|x) ? {0, 1}, c k = x?B p(k|x)f (x) T 2 , c k = x?B p(k|x)f (x) 2 , and w = {w ij } N i,j=1</formula><p>? R N ?N denotes the weights of each instance pair. Eq. <ref type="bibr" target="#b15">(16)</ref> shows that the alignment term in PSL can be formulated as an instancereweighted contrastive loss.</p><p>From Eq. (16), we have the following observation:</p><p>? When x i and x j belong to the same cluster, i.e. p(k|x i ) = p(k|x j ) = 1, we have w ij &gt; 0.</p><p>? When x i and x j belong to the different clusters, we have w ij = 0.</p><p>As a result, the alignment term in PSL only contains the sample pairs belonging to the same clusters, which is similar to supervised contrastive loss <ref type="bibr" target="#b22">[23]</ref>. Therefore, the alignment term of PSL is a generalized case of instance-reweighted contrastive loss that takes into account the pseudo-labels. Similarly, one can observe that the uniformity term in PSL is to maximize the distance between instances in different clusters (j = k). Therefore, we can understand the proposed PSL from a perspective of instance-reweighted contrastive loss with cluster labels taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We introduced a novel deep clustering method ProPos, which enjoys the strengths of both contrastive-and noncontrastive-based methods. The proposed positive sampling alignment and prototype scattering loss can lead to withincluster compactness and well-separated clusters. The results empirically showed that the proposed ProPos outperforms the state-of-the-art methods by a significant margin. Current state-of-the-art methods are mostly beneficial from the progress of self-supervised representation learning while the new trends such as MAE <ref type="bibr" target="#b26">[27]</ref> have presented more superior performance on downstream tasks, which deserves studying as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>-Supplementary Material-</head><p>This supplementary material provides the following extra contents: (1) Sec. 8 presents detailed derivations of EM framework; (2) Sec. 9 contains additional experimental results, including <ref type="figure">Fig. 9</ref> for the analysis of applying PCL <ref type="bibr" target="#b6">[7]</ref> to MoCo <ref type="bibr" target="#b0">[1]</ref> and BYOL <ref type="bibr" target="#b2">[3]</ref>, <ref type="figure" target="#fig_0">Fig. 10</ref> for visualization of feature representations throughout the training process, <ref type="figure" target="#fig_0">Fig. 11</ref> for visualizations for the outlier points, <ref type="table" target="#tab_1">Table 10</ref> for the results under different data split and image size, and <ref type="figure" target="#fig_0">Fig. 12</ref> for visualizations of representations for underclustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">EM FRAMEWORK</head><p>In this section, we first describe the von Mises-Fisher (vMF) distribution on the hypersphere, and then derive the evidence lower bound (ELBO) for our expectation-maximization (EM) framework, followed by detailed E-step and M-step. Finally, we describe our proposed prototypical contrastive loss and provide proof for convergence analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">von Mises-Fisher Distribution</head><p>Since the features in current SSL methods are usually 2 -normalized, it is more proper to employ the spherical distribution to describe the features. The von Mises-Fisher (vMF) distribution, often seen as the Gaussian distribution on a hypersphere, is parameterized by ? ? R d the mean direction and ? ? R + the concentration around ?. For the special case of ? = 0, the vMF distribution represents a uniform distribution on the hypersphere. The probability density function of vMF distribution for the random unit vector v ? R d is defined as:</p><formula xml:id="formula_14">p(v | ?, ?) = C d (?) exp(?? T v), where C d (?) = ? d/2?1 (2?) d/2 I d/2?1 (?) ,<label>(17)</label></formula><p>where d is the feature dimension, ? 2 = 1, C d (?) is the normalizing constant, and I v denotes the modified Bessel function of the first kind at order v. The standard Gaussian distribution z ? N (0, I) can be approximately seen as the uniform vMF distribution if the z is 2 -normalized and d is large for the high dimension data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Derivation of Evidence Lower Bound (ELBO)</head><p>Given the dataset D = {x (n) } N n=1 with N observed data points that are related to a set of K cluster latent variables, k ? K = {1, 2, . . . , K}, the marginal likelihood can be written as:</p><formula xml:id="formula_15">L(D; ?) = 1 N N n=1 log p(x (n) ; ?) = 1 N N n=1 log k?K p(x (n) , k; ?),<label>(18)</label></formula><p>where ? denotes the model parameters. Eq. <ref type="formula" target="#formula_6">(18)</ref> is usually maximized to train the neural network. However, it is hard to directly optimize the log-likelihood function. Using an inference model q(k) like VAE <ref type="bibr" target="#b46">[47]</ref> to approximate the distribution of K, especially k?K q(k) = 1, we can re-write the log-likelihood function for one example as:</p><formula xml:id="formula_16">log p(x; ?) = k?K q(k) log p(x; ?)<label>(19)</label></formula><formula xml:id="formula_17">= k?K q(k)(log p(x, k; ?) ? log p(k|x; ?)) (20) = k?K q(k) log p(x, k; ?) q(k) ? k?K q(k) log p(k|x; ?) q(k)<label>(21)</label></formula><p>= ELBO(q, x; ?) + KL(q(k) p(k|x; ?)),</p><p>where p(x, k; ?) = p(k|x; ?)p(x; ?) so we have log p(x; ?) = log p(x, k; ?) ? log p(k|x; ?) and the evidence lower bound (ELBO) is the lower bound of log-likelihood function since KL(q(k) p(k|x; ?)) ? 0. When KL(q(k) p(k|x; ?)) = 0, the ELBO reaches its maximum value log p(x; ?), making q(k) = p(k|x; ?). By replacing q(k) with p(k|x; ?) and ignoring the constant value k?K ?q(k) log q(k), we are ready to maximize:</p><formula xml:id="formula_19">k?K p(k|x; ?) log p(x, k; ?).<label>(23)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">EM Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E-step.</head><p>With the fixed ? t at the iteration t, this step aims to estimate q t+1 (k) that makes q t+1 (k) = p(k|x; ? t ) so that ELBO(q t+1 , x; ? t ) = log p(x; ? t ). Here, we perform the spherical k-means algorithm to estimate p(k|x; ? t ). We extract features from the target network since the target network performs more stable and yields more consistent clusters, similar to BYOL and MoCo. M-step. With the fixed suboptimal q t+1 (k) = p(k|x; ? t ) after E-step, we turn to optimize the ? to maximize the ELBO:</p><formula xml:id="formula_20">? t+1 = arg max ? N n=1</formula><p>ELBO(q t+1 , x (n) ; ?).</p><p>Using a uniform prior for k as p(k) = 1/K, we can obtain p(x, k; ?) = p(k)p(x|k; ?) = p(x|k; ?)/K. By replacing p(x, k; ?) in Eq. (23) and ignoring constant value, in this step, we should maximize:</p><formula xml:id="formula_22">k?K 1(x ? k) log p(x|k; ?),<label>(25)</label></formula><p>where p(k|x; ?) = 1(x ? k). 1(?) is an indicator function using the hard labels estimated from E-step so that 1(x ? k) = 1 if x belongs to k-th cluster; otherwise 1(x ? k) = 0. Following <ref type="bibr" target="#b6">[7]</ref>, if we assume that the distribution for each cluster is the vMF distribution with a constant ? as the temperature of softmax function, we can further obtain the follow:</p><formula xml:id="formula_23">p(x|k; ?) = exp(? T k v/? ) K k=1 exp(? T k v/? ) ,<label>(26)</label></formula><p>where v = f (x; ?), ? = 1/?, and ? k is the cluster center of k-th cluster. Combining Eqs. <ref type="bibr" target="#b24">(25)</ref> and <ref type="formula" target="#formula_1">(26)</ref>, we can achieve the maximum log-likelihood estimation to find the optimal ? * by minimizing the following negative log-likelihood:</p><formula xml:id="formula_24">? * = arg min ? N n=1 ? log exp(? T y (n) v (n) /? ) K k=1 exp(? T k v (n) /? ) ,<label>(27)</label></formula><p>where y (n) is the pseudo-label for x (n) estimated by the k-means algorithm in E-step. Directly optimizing Eq. (27) usually leads to improve the cluster compactness, which, however, will compromise the stability of BYOL since it does not consider the uniformity term. To this end, we propose a prototypical scattering loss (PSL) to maximize the log-likelihood at the cluster level by employing the clusters centers as the special instances, or prototypes from a set of instances. The PSL is defined as:</p><formula xml:id="formula_25">L psl = 1 K K k=1 ? log exp(? T k ? k /? ) exp(? T k ? k /? ) + K j=1,j =k exp(? T k ? j /? ) ,<label>(28)</label></formula><p>where {? 1 , ? 2 , . . . , ? K } and {? 1 , ? 2 , . . . , ? K } are K prototypes from target and online networks, respectively. Here, instead of using the centroids computed from k-means, our cluster center ? k and ? k is empirically estimated within mini-batch B as follows:</p><formula xml:id="formula_26">? k = x?B p(k|x)f (x) x?B p(k|x)f (x) 2 , and ? k = x?B p(k|x)f (x) x?B p(k|x)f (x) 2 ,<label>(29)</label></formula><p>where p(k|x) is estimated from E-step. When K &gt; |B|, it is obvious that the mini-batch cannot cover all clusters. To this end, we zero out the losses and logits of empty clusters for each iteration. Intuitively, PSL can encourage the prototypical alignment between two augmented views and the prototypical uniformity, hence maximizing the inter-cluster distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Convergence Analysis</head><p>At E-step of the iteration t, we estimate q t+1 (k) to make ELBO(q t+1 , x; ? t ) = log p(x; ? t ). At M-step after E-step, we obtain the optimized ? t+1 with the fixed q t+1 (k) so that ELBO(q t+1 , x; ? t+1 ) ? ELBO(q t+1 , x; ? t ). Consequently, we obtain the following sequence: log p(x; ? t+1 ) ? ELBO(q t+1 , x; ? t+1 ) ? ELBO(q t+1 , x; ? t ) = log p(x; ? t ).</p><p>Given log p(x; ? t+1 ) ? log p(x; ? t ), we can guarantee the convergence of our ProPos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">ADDITIONAL EXPERIMENTAL RESULTS</head><p>(a) Normalized Mutual Information (b) Standard Deviation <ref type="figure">Fig. 9</ref>. Visualizations of NMIs and STDs by applying PCL <ref type="bibr" target="#b6">[7]</ref> to MoCo and BYOL on CIFAR-10. Compared to PCL+BYOL, PCL+MoCo performs more stable during clustering with a more uniform distribution of representations. The decreasing STDs (standard deviation of 2 -normalized features) also indicate that PCL+BYOL suffers from the representation collapse. This is because PCL can only improve the within-cluster compactness. During training, the fixed prototypes of PCL will also be gradually collapsed without negative examples, making the representations for BYOL collapse at the same time. These results validate our assumptions that BYOL is not robust to additional clustering losses for clustering tasks, since there is no negative example for BYOL to maintain uniform representations to avoid collapse. Our ProPos can avoid the class collision issue and representation collapse by the proposed positive sampling alignment to improve the within-cluster compactness and prototypical scattering loss to maximize the inter-class distance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 10</head><p>Clustering results (%) for fair comparisons. We train ProPos to demonstrate its effectiveness for fair comparisons with the following settings: (1) we exclude test set from the whole dataset; and (2) we use an original image size (224) for ImageNet-10 and ImageNet-Dogs. All results were trained with ResNet-34. There is no clear margin for CIFAR-10 and CIFAR-20 datasets with different splits, while significant improvements can be observed for ImageNet-10 and ImageNet-Dogs datasets. Considering that ProPos has already achieved state-of-the-art performance against previous work in  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Illustration of the proposed two key techniques in ProPos. (a) The proposed prototype scattering loss to encourage alignment and maximize the between-cluster distance. (b) The proposed positive sampling alignment to encourage the alignment between sampled neighbors of one view with another for better within-cluster compactness.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Improved within-cluster compactness. Unlike conventional instance alignment for non-contrastive learning, our PSA in Eq. (10) encourages neighboring examples around one augmented view-either different augmented examples of the same instance or same/different augmented examples of different instances within the same cluster-to be positive pairs with another view. This helps to improve withincluster compactness. The overall framework of the proposed ProPos in an EM framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 :</head><label>1</label><figDesc>Training Algorithm Input: Dataset D = {x}; Functions f (?) and f (?) Output: Clustering results {p(k|x)}. repeat E-step: update {p(k|x)} for each sample in D using k-means clustering M-step: repeat Randomly sample a mini-batch B from D for each x i in B do Randomly augment x and x + Compute cluster centers using Eqs. (6) and (7) L psl ?Eq. (4) L psa ?Eq. (10) end L ?Eq. (12) Update f with momentum moving average Update f with SGD optimizer until an epoch finished; until reaching max epochs;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Detailed comparison between BYOL<ref type="bibr" target="#b2">[3]</ref> and ProPos on CIFAR-10 in terms of (a) standard deviation (STD) of 2 -normalized features to evaluate the uniformity, (b) cluster imbalance ratio computed by min({N k } K k=1 )/ max({N k } K k=1 ) to show how balanced the clusters are, (c) cluster statistics, or the sorted number of samples in each cluster for the model at 1000-th epoch, and (d) normalized mutual information (NMI) between the clustering results and ground-truth labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Visualization of sampled neighbors for ProPos on CIFAR-10: (a) The odds of sampled neighbors that have preserved their original semantic classes under different ? during training; and (b) The input images, the 1-nearest-neighbors (1-NN) of input images, and three sample neighbors at 100th epoch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Visualization of feature representations learned by different representation learning frameworks and our proposed ProPos on CIFAR-10 with t-SNE. Zoom in for better view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5</head><label>5</label><figDesc>visualizes the distribution of representations learned from BYOL, ProPos w/o PSL, ProPos w/o PSA, and our ProPos. ProPos w/o PSA leverages PSL to discriminate different clusters by maximizing the inter-cluster distance, and produces more uniform representations. Although ProPos w/o PSL with only PSA achieves marginal improvements and does not produce a significant difference than BYOL, the positive sampling can further improve the within-cluster compactness with only PSL via the sampling-based instance alignment loss to pull together the neighbor samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>The effect of the predefined number of clusters K on CIFAR-10/20 datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Effects of different hyperparameters in ProPos.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>The performance of ProPos using a memory queue with different sizes on Tiny-ImageNet. We repeated each run for 3 times and reported the mean and std values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>?</head><label></label><figDesc>Positive class collision issue: positive examples may not be truly positive, which is a new case raised in GCC and WCL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>?</head><label></label><figDesc>GCC and WCL select the examples that exist in the dataset (mini-batch/memory bank) while ours samples examples from the latent space that may not exist in the dataset.? GCC and WCL select neighbor examples in a graph as pseudo-positive examples that may not be truly positive while ours samples examples around the instance in the embedding space that can be assumed to be truly positive.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 .</head><label>10</label><figDesc>Visualization of feature representations learned by ProPos on CIFAR-10 with t-SNE, for four different training epochs throughout the training process. Different colors denote the different semantic classes. Zoom in for better view. At the beginning, the random-initialized model cannot distinguish the instances from different semantic classes, where all instances are mixed together. As the training process goes, ProPos gradually attracts the instances from the same cluster while pushing the clusters away from each other. Obviously, at the end of the training, ProPos produces clear boundary between clusters and within-cluster compactness.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 11 .</head><label>11</label><figDesc>Visualizations for the outlier points produced by the model at 1000-th epoch on CIFAR-10 with t-SNE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 12 .</head><label>12</label><figDesc>Visualization of feature representations learned by ProPos with underestimated K = 5 on CIFAR-10 with t-SNE: (a) the points are colored according to the pseudo-labels of k-means clustering, where the text box denotes the true sematic classes; (b) The points are colored according to the true labels. Zoom in for better view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>are with the Shanghai Key Lab of Intelligent Information Processing and the School of Computer Science, Fudan University, Shanghai 200433, China. Email: {zzhuang19, chenj19, jpzhang}@fudan.edu.cn.</figDesc><table /><note>? H. Shan is with Institute of Science and Technology for Brain-inspired Intelligence, MOE Frontiers Center for Brain Science, and Key Laboratory of Computational Neuroscience and Brain-Inspired Intelligence, Fudan University, Shanghai, 200433, China, and also with Shanghai Center for Brain Science and Brain-inspired Technology, Shanghai 201210, China.E-mail: hmshan@fudan.edu.cn. Manuscript received xx xx, 2022; revised xx xx, 2022.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1</head><label>1</label><figDesc>Summary of the datasets.</figDesc><table><row><cell>Dataset</cell><cell>Split</cell><cell cols="3"># Samples # Classes Image Size</cell></row><row><cell>CIFAR-10</cell><cell>Train+Test</cell><cell>60,000</cell><cell>10</cell><cell>32?32</cell></row><row><cell>CIFAR-20</cell><cell>Train+Test</cell><cell>60,000</cell><cell>20</cell><cell>32?32</cell></row><row><cell>STL-10</cell><cell>Train+Test</cell><cell>13,000</cell><cell>10</cell><cell>96?96</cell></row><row><cell>ImageNet-10</cell><cell>Train</cell><cell>13,000</cell><cell>10</cell><cell>96?96</cell></row><row><cell cols="2">ImageNet-Dogs Train</cell><cell>19,500</cell><cell>15</cell><cell>96?96</cell></row><row><cell>Tiny-ImageNet</cell><cell>Train</cell><cell>100,000</cell><cell>200</cell><cell>224?224</cell></row><row><cell>ImageNet-1k</cell><cell>Train</cell><cell>1,281,167</cell><cell>1,000</cell><cell></cell></row></table><note>224?224 Relations between PSL and PSA. A good clustering model should have well-separated clusters and within- cluster compactness. On the one hand, PSL encourages well- separated clusters by maximizing inter-cluster distance, which, however, cannot improve within-cluster compact- ness. On the other hand, PSA can pull together the sampled neighboring examples around one augmented view and another view, which can further improve within-cluster compactness. By combing these two losses in Eq. (12), we expect ProPos can improve deep clustering towards well- separated clusters and within-cluster compactness.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 3 Clustering</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Tiny-ImageNet</cell><cell></cell></row><row><cell>Method</cell><cell>NMI</cell><cell>ACC</cell><cell>ARI</cell></row><row><cell>DCCM [35]</cell><cell>22.4</cell><cell>10.8</cell><cell>3.8</cell></row><row><cell>PICA [55]</cell><cell>27.7</cell><cell>9.8</cell><cell>4.0</cell></row><row><cell>CC [8]</cell><cell>34.0</cell><cell>14.0</cell><cell>7.1</cell></row><row><cell>GCC [41]</cell><cell>34.7</cell><cell>13.8</cell><cell>7.5</cell></row><row><cell>MoCo [1]</cell><cell>34.2</cell><cell>16.0</cell><cell>8.0</cell></row><row><cell>PCL [7]</cell><cell>35.0</cell><cell>15.9</cell><cell>8.7</cell></row><row><cell>SimSiam [2]</cell><cell>35.1</cell><cell>20.3</cell><cell>9.4</cell></row><row><cell>BYOL [3]</cell><cell>36.5</cell><cell>19.9</cell><cell>10.0</cell></row><row><cell>ProPos (ours)</cell><cell>40.5</cell><cell>25.6</cell><cell>14.3</cell></row></table><note>results (%) on Tiny-ImageNet. We trained ProPos using ResNet-18.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 5</head><label>5</label><figDesc>Linear evaluation on ImageNet-1k dataset. We report the Top-1 classification accuracy (%) by training a linear classifier; the results are adopted from corresponding papers. The upper group uses more fair conditions, e.g., backbone and training epoch.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Pre-training</cell><cell></cell></row><row><cell>Method</cell><cell>Backbone</cell><cell>Batch size</cell><cell>Epochs</cell><cell>ACC</cell></row><row><cell>Jigsaw [18]</cell><cell>AlexNet</cell><cell>256</cell><cell>-</cell><cell>34.6</cell></row><row><cell>Rotation [58]</cell><cell>AlexNet</cell><cell>128</cell><cell>100</cell><cell>38.7</cell></row><row><cell>DeepCluster [20]</cell><cell>AlexNet</cell><cell>256</cell><cell>500</cell><cell>41.0</cell></row><row><cell>InstDisc [21]</cell><cell>ResNet-50</cell><cell>256</cell><cell>200</cell><cell>54.0</cell></row><row><cell>LocalAgg [59]</cell><cell>ResNet-50</cell><cell>128</cell><cell>200</cell><cell>60.2</cell></row><row><cell>CMC [60]</cell><cell>ResNet-50</cell><cell>-</cell><cell>200</cell><cell>66.2</cell></row><row><cell>SimCLR [2]</cell><cell>ResNet-50</cell><cell>256</cell><cell>200</cell><cell>64.3</cell></row><row><cell>MoCo [1]</cell><cell>ResNet-50</cell><cell>256</cell><cell>200</cell><cell>60.6</cell></row><row><cell>MoCo v2 [52]</cell><cell>ResNet-50</cell><cell>256</cell><cell>200</cell><cell>67.5</cell></row><row><cell>PCL [7]</cell><cell>ResNet-50</cell><cell>256</cell><cell>200</cell><cell>67.6</cell></row><row><cell>IFND [61]</cell><cell>ResNet-50</cell><cell>256</cell><cell>200</cell><cell>69.7</cell></row><row><cell>BYOL [62]</cell><cell>ResNet-50</cell><cell>4096</cell><cell>200</cell><cell>70.6</cell></row><row><cell>SimSiam [4]</cell><cell>ResNet-50</cell><cell>256</cell><cell>200</cell><cell>70.0</cell></row><row><cell>ProPos (ours)</cell><cell>ResNet-50</cell><cell>256</cell><cell>200</cell><cell>72.2</cell></row><row><cell>CPC [46]</cell><cell>ResNet-101</cell><cell>512</cell><cell>-</cell><cell>48.7</cell></row><row><cell>SeLa [63]</cell><cell>ResNet-50</cell><cell>1024</cell><cell>400</cell><cell>61.5</cell></row><row><cell>PIRL [64]</cell><cell>ResNet-50</cell><cell>1024</cell><cell>800</cell><cell>63.6</cell></row><row><cell>SimCLR [2]</cell><cell>ResNet-50</cell><cell>4096</cell><cell>1000</cell><cell>69.3</cell></row><row><cell>BYOL [62]</cell><cell>ResNet-50</cell><cell>4096</cell><cell>1000</cell><cell>74.3</cell></row><row><cell>SwAV [26]</cell><cell>ResNet-50</cell><cell>4096</cell><cell>800</cell><cell>75.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 7</head><label>7</label><figDesc>The training time (hours) in the settings of 1,000 epochs, 4 V100 GPUs, and ResNet-50.</figDesc><table><row><cell>Method</cell><cell>CIFAR-10</cell><cell>CIFAR-20</cell><cell>STL-10</cell><cell>ImageNet-10</cell><cell>ImageNet-dogs</cell><cell>Tiny-ImageNet</cell></row><row><cell>BYOL [3]</cell><cell>9.0</cell><cell>9.0</cell><cell>14.7</cell><cell>1.7</cell><cell>2.6</cell><cell>13.0</cell></row><row><cell>ProPos (r = 1)</cell><cell>10.9(+1.9)</cell><cell>11.0(+2.0)</cell><cell>15.8(+1.1)</cell><cell>2.7(+1.0)</cell><cell>3.7(+1.1)</cell><cell>15.7(+2.7)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 8</head><label>8</label><figDesc>Clustering results (%) on the subsets of ImageNet.</figDesc><table><row><cell>ImageNet</cell><cell cols="2">50 Classes</cell><cell cols="2">100 Classes</cell><cell cols="2">200 Classes</cell></row><row><cell>Method</cell><cell>NMI</cell><cell>ARI</cell><cell>NMI</cell><cell>ARI</cell><cell>NMI</cell><cell>ARI</cell></row><row><cell>k-means w/ pre-trained MoCo</cell><cell>77.5</cell><cell>57.9</cell><cell>76.1</cell><cell>50.8</cell><cell>75.5</cell><cell>43.2</cell></row><row><cell>SCAN [6] after clustering step</cell><cell>80.5</cell><cell>63.5</cell><cell>78.7</cell><cell>54.4</cell><cell>75.7</cell><cell>44.1</cell></row><row><cell>SCAN [6] after self-labeling step</cell><cell>82.2</cell><cell>66.1</cell><cell>80.8</cell><cell>57.6</cell><cell>77.2</cell><cell>47.0</cell></row><row><cell>ProPos (ours)</cell><cell>82.8</cell><cell>69.1</cell><cell>83.5</cell><cell>63.5</cell><cell>80.6</cell><cell>53.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 2 90.8?0.4 96.2?0.1 91.8?0.3 73.7?0.2 77.5?0.1 67.5?0.1</head><label>2</label><figDesc>, these results further demonstrate the superiority of ProPos. 60.6?0.3 61.4?1.1 45.1?0.1 Exclude test set 88.3?0.2 94.2?0.2 88.1?0.6?0.2 95.6?0.0 90.6?0.1 69.2?0.3 74.5?0.1 62.7?0.1 Large image size (224)</figDesc><table><row><cell></cell><cell>NMI</cell><cell>ACC</cell><cell>ARI</cell><cell>NMI</cell><cell>ACC</cell><cell>ARI</cell></row><row><cell></cell><cell></cell><cell>CIFAR-10</cell><cell></cell><cell></cell><cell>CIFAR-20</cell></row><row><cell>Baseline (train+test)</cell><cell cols="3">88.6?1.0 94.3?0.6 88.4?1.1 ImageNet-10</cell><cell></cell><cell>ImageNet-Dogs</cell></row><row><cell>Baseline (96)</cell><cell>89.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>3 61.2?0.9 61.5?0.9 45.9?0.5</note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank the associate editor and two anonymous reviewers for their valuable comments, which greatly improved the quality of this article.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn. PMLR, 2020</title>
		<meeting>Int. Conf. Mach. Learn. PMLR, 2020</meeting>
		<imprint>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent: A new approach to selfsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Azar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Adv. Neural Inf. Process. Syst</title>
		<meeting>Adv. Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploring simple Siamese representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning by cross-level instance-group discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="12" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SCAN: Learning to classify images without labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Comput. Vis</title>
		<meeting>European Conf. Comput. Vis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="268" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Prototypical contrastive learning of unsupervised representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Contrastive clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf</title>
		<meeting>AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Clustering-friendly representation learning via instance discrimination and feature decorrelation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Takagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">MiCE: Mixture of contrastive experts for unsupervised image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">SPICE: Semantic pseudo-labeling for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.09382</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn. PMLR, 2020</title>
		<meeting>Int. Conf. Mach. Learn. PMLR, 2020</meeting>
		<imprint>
			<biblScope unit="page" from="9929" to="9939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A theoretical analysis of contrastive unsupervised representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Khandeparkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saunshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">How does SimSiam avoid collapse without negative samples? A unified understanding with self-supervised contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">X</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Large scale adversarial representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Adv. Neural Inf. Process. Syst</title>
		<meeting>Adv. Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Comput. Vis</title>
		<meeting>European Conf. Comput. Vis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Comput. Vis</title>
		<meeting>European Conf. Comput. Vis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Comput. Vis</title>
		<meeting>European Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="132" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis</title>
		<meeting>IEEE Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A theoretical analysis of contrastive unsupervised representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Khandeparkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn. PMLR</title>
		<meeting>Int. Conf. Mach. Learn. PMLR</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5628" to="5637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Adv. Neural Inf. Process. Syst</title>
		<meeting>Adv. Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">AdCo: Adversarial contrast for efficient learning of unsupervised representations from selftrained negative adversaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1074" to="1083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Debiased contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yen-Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Adv. Neural Inf. Process. Syst</title>
		<meeting>Adv. Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Adv. Neural Inf. Process. Syst</title>
		<meeting>Adv. Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Masked autoencoders are scalable vision learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.06377</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Im-ageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn. PMLR</title>
		<meeting>Int. Conf. Mach. Learn. PMLR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep adaptive image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5879" to="5887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep self-evolution clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="809" to="823" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Associative deep clustering: Training a classification network with no labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haeusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Plapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Aljalbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="18" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Local-aggregation graph networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2874" to="2886" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep comprehensive correlation mining for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8150" to="8159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9865" to="9874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">AutoNovel: Automatically discovering and learning novel visual categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ehrhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Twin contrastive learning for online clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">You never cluster alone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">HCSC: Hierarchical contrastive selective coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Graph contrastive clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Weakly supervised contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Learning representations by contrasting clusters while bootstrapping instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=MRQJmsNPp8E" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Consensus clustering with unsupervised representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Regatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Deshmukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Manavoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Dogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Jt. Conf. Neural Netw</title>
		<meeting>Int. Jt. Conf. Neural Netw</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Representation learning via invariant causal mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mitrovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics. JMLR Workshop and Conference Proceedings</title>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Statistics. JMLR Workshop and Conference Proceedings</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Tiny ImageNet visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CS 231N</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Improved baselines with momentum contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">GATCluster: Selfsupervised Gaussian-attention network for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Comput. Vis</title>
		<meeting>European Conf. Comput. Vis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="735" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Understanding self-supervised learning dynamics without contrastive pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn. PMLR, 2021</title>
		<meeting>Int. Conf. Mach. Learn. PMLR, 2021</meeting>
		<imprint>
			<biblScope unit="page" from="10" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep semantic clustering by partition confidence maximisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8849" to="8858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Nearest neighbor matching for deep clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Local aggregation for unsupervised learning of visual embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yamins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6002" to="6012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Contrastive multiview coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Comput. Vis</title>
		<meeting>European Conf. Comput. Vis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="776" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Incremental false negative detection for contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-Y</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Understanding self-supervised and contrastive learning with bootstrap your own latent (BYOL)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fetterman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Albrecht</surname></persName>
		</author>
		<ptr target="https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Self-labelling via simultaneous clustering and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rupprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Self-supervised learning of pretextinvariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6707" to="6717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">k-means++: The advantages of careful seeding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stanford, Tech. Rep</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Long-tailed classification by keeping the good and removing the bad momentum causal effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Adv. Neural Inf. Process. Syst</title>
		<meeting>Adv. Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">BBN: Bilateralbranch network with cumulative learning for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9719" to="9728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Learning imbalanced datasets with label-distribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Adv. Neural Inf. Process. Syst</title>
		<meeting>Adv. Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
