<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HyperShot: Few-Shot Learning by Kernel HyperNetworks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Sendera</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Przewi??likowski</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Karanowski</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Zi?ba</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacek</forename><surname>Tabor</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Przemys?aw</forename><surname>Spurek</surname></persName>
						</author>
						<title level="a" type="main">HyperShot: Few-Shot Learning by Kernel HyperNetworks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Few-shot models aim at making predictions using a minimal number of labeled examples from a given task. The main challenge in this area is the one-shot setting where only one element represents each class. We propose HyperShotthe fusion of kernels and hypernetwork paradigm. Compared to reference approaches that apply a gradient-based adjustment of the parameters, our model aims to switch the classification module parameters depending on the task's embedding. In practice, we utilize a hypernetwork, which takes the aggregated information from support data and returns the classifier's parameters handcrafted for the considered problem. Moreover, we introduce the kernel-based representation of the support examples delivered to hypernetwork to create the parameters of the classification module. Consequently, we rely on relations between embeddings of the support examples instead of direct feature values provided by the backbone models. Thanks to this approach, our model can adapt to highly different tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Current Artificial Intelligence techniques cannot rapidly generalize from a few examples. This common inability is because most deep neural networks must be trained on large-scale data. In contrast, humans can learn new tasks quickly by utilizing what they learned in the past. Few-shot learning models try to fill this gap by learning how to learn from a limited number of examples. Few-shot learning is the problem of making predictions based on a small number of samples. The goal of few-shot learning is not to recognize a fixed set of labels but to learn how to quickly adapt to new tasks with a small amount of training data. After training, the model can classify new data using only a few training samples.</p><p>The most popular approaches for few-shot learning use the meta-learning framework. We sample few-shot classification tasks from training samples belonging to the base classes and optimize the model to perform well on these tasks. We work with N -way and K-shot tasks, where we have N classes with K support samples and Q query samples in each category. The goal is to classify these N ? Q query samples into the N classes based on the N ? K support samples.</p><p>One of the most common approaches to Few-shot learning is Model-Agnostic Meta-Learning (MAML) <ref type="bibr" target="#b5">(Finn et al., 2017)</ref>, where the model is trained to adapt to new Few-shot learning tasks quickly. The main idea is to produce universal weights which can be rapidly updated to solve new small tasks. The model's main limitation is the complicated optimization procedure that uses an inner and outer loop, which can be seen as second-order optimization. Moreover, such an optimization procedure only partially implements the learn how to learn paradigm, which assumes the model learns some rules to adapt to the new tasks. The induction of such rules by MAML is limited by gradient-based optimization applied to adjust the parameters of the classification module to the new task. In practice, we can realize learning rules which are based on gradient optimization. New classification module parameters are obtained by gradient descent.</p><p>This paper introduces a new strategy, which solves the above problem with restriction only to gradient-based decision rules. Our goal is to mimic the human learning process. First, we look at the entire support set and extract the information to distinguish objects in classes. Then, based on the relation between features, we create the decision rules.</p><p>We combine the Hypernetworks paradigm with kernel methods to realize such a scenario, see <ref type="figure">Fig. 1</ref>. Hypernetworks, introduced in <ref type="bibr" target="#b10">(Ha et al., 2016)</ref>, are defined as neural models that generate weights for a separate target network solving a specific task. In our approach, the Hypernetwork aggregates the information from the support set and produces weights of the target model, classifying the query set. <ref type="figure">Figure 1</ref>. The overview of HyperShot architecture. We create the kernel matrix for features extracted from support examples, which is further processed by a hypernetwork. The role of the hypernetwork is to create the set of parameters for the considered task. The target network further uses the parameters to classify the query examples.</p><p>Kernel methods realize the first part of the process. For each of the few-shot tasks, we extract the features from the support set through the backbone architecture and calculate kernel values between them. Then we use a Hypernetwork architecture -a neural network that takes kernel representation and produces decision rules in the form of a classifier (target network) dedicated to the query set.</p><p>Such a solution realizes the learn how to learn paradigm. Hypernetwork, which produces the decision rules from kernel representation of the support set, is trained by gradientbased method and can be seen as a classical learning process. However, the weights of the target network (decision rules) can realize different strategies and lay in varying weight space parts. Our approach allows training a universal architecture model, which can be quickly updated to new tasks without any second-order procedure (inner and outer loop).</p><p>We perform an extensive experimental study of our approach by benchmarking it on various one-shot and few-shot image classification tasks. We find that HyperShot demonstrates high accuracy in all tasks, performing comparably or better than the other recently proposed methods. Moreover, Hy-perShot shows a strong ability to generalize, as evidenced by its performance on cross-domain classification tasks.</p><p>The contributions of our work can be summarized as follows:</p><p>? In this paper, we propose a model which realizes the learn how to learn paradigm by modeling learning rules which are not based on gradient optimization and can produce completely different strategies.</p><p>? We propose a new approach to solve the few-shot learning problem by aggregating information from the support set and directly producing weights from the neural network dedicated to the query set.</p><p>? We propose HyperShot, which uses the Hypernetwork paradigm to produce the weights dedicated for each task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">HyperShot: Hypernetwork for few-shot learning</head><p>In this section, we present our HyperShot model for fewshot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Background</head><p>Few-shot learning The terminology describing the fewshot learning setup is dispersive due to the colliding definitions used in the literature. For a unified taxonomy, we refer the reader to <ref type="bibr" target="#b3">(Chen et al., 2019;</ref><ref type="bibr" target="#b43">Wang et al., 2020)</ref>. Here, we use the nomenclature derived from the meta-learning literature, which is the most prevalent at the time of writing. Let:</p><formula xml:id="formula_0">S = {(x l , y l )} L l=1</formula><p>(1) be a support-set containing input-output pairs, with L examples with the equal class distribution. In the one-shot scenario, each class is represented by a single example, and L = K, where K is the number of the considered classes in the given task. Whereas, for few-shot scenarios, each class usually has from 2 to 5 representatives in the support set S. Let:</p><formula xml:id="formula_1">Q = {(x m , y m )} M m=1</formula><p>(2) be a query-set (sometimes referred to in the literature as a target-set), with M examples, where M is typically one order of magnitude greater than K. For ease of notation, the support and query sets are grouped in a task T = {S, Q}.</p><p>During the training stage, the models for few-shot applications are fed by randomly selected examples from training set D = {T n } N n=1 , defined as a collection of such tasks. During the inference stage, we consider task T * = {S * , X * }, where S * is a support set with the known class values for a given task, and X * is a set of query (unlabeled) inputs. The goal is to predict the class labels for query inputs x ? X * , assuming support set S * and using the model trained on D.</p><p>Hypernetwork In the canonical work <ref type="bibr" target="#b10">(Ha et al., 2016)</ref>, hyper-networks are defined as neural models that generate weights for a separate target network solving a specific task. The authors aim to reduce the number of trainable parameters by designing a hyper-network with a smaller number of parameters than the target network. Making an analogy between hyper-networks and generative models, the authors of <ref type="bibr" target="#b35">(Sheikh et al., 2017)</ref> use this mechanism to generate a diverse set of target networks approximating the same function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">HyperShot -overview</head><p>We introduce our HyperShot -model that utilizes hypernetwork for few-shot problems. The main idea of the proposed approach is to predict the values of the parameters for a classification network that makes predictions on query images given the information extracted from support examples for a given task. Thanks to this approach, we can switch the classifier's parameters between completely different tasks based on the support set. The information about the current task is extracted from the support set using parametrized kernel function that operates on embedding space. Thanks to this approach, we use relations among the support examples instead of taking the direct values of the embedding values as an input to the hypernetwork. Consequently, this approach is robust to the embedding values for new tasks far from the feature regions observed during training. The classification of the query image is also performed using the kernel values calculated with respect to the support set.</p><p>The architecture of the HyperShot is provided in <ref type="figure" target="#fig_0">Fig. 2</ref>. We aim to predict the class distribution p(y|S, x), given a query image x and set of support examples S = {(x l , y l )} K l=1 . First, all images from the support set are grouped by their corresponding class values. Next, each of the images x l from the support set is transformed using encoding network E(?), which creates low-dimensional representations of the images, E(x l ) = z l . The constructed embeddings are sorted according to class labels and stored in the matrix Z S = [z ?(1) , . . . , z ?(K) ] T , where ?(?) is the bijective function, that satisfies y ?(l) ? y ?(k) for l ? k.</p><p>In the next step we calculate the kernel matrix K S,S , for vector pairs stored in rows of Z S . To achieve this, we use the parametrized kernel function k(?, ?), and calculate k i,j element of matrix K S,S in the following way:</p><formula xml:id="formula_2">k i,j = k(z ?(i) , z ?(j) ).</formula><p>(3)</p><p>The kernel matrix K S,S represents the extracted information about the relations between support examples for a given task. The matrix K S,S is further reshaped to the vector format and delivered to the input of the hypernetwork H(?).</p><p>The role of the hypernetwork is to provide the parameters ? T of target model T (?) responsible for the classification of the query object. Thanks to that approach, we can switch between the parameters for entirely different tasks without moving via the gradient-controlled trajectory, like in some reference approaches like MAML.</p><p>The query image x is classified in the following manner. First, the input image is transformed to low-dimensional feature representation z x by encoder E(x). Further, the kernel vector k x,S between the query embedding and sorted support vectors Z S is calculated in the following way:</p><formula xml:id="formula_3">k x,S = [k(z x , z ?(1) ), . . . , k(z x , z ?(K) )] T .<label>(4)</label></formula><p>The vector k x,S is further provided on the input of target model T (?) that is using the parameters ? T returned by hypernetwork H(?). The target model returns the probability distribution p(y|S, x) for each class considered in the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Kernel function</head><p>One of the key components of our approach is a kernel function k(?, ?). In this work we consider the dot product of the transformed vectors given by:</p><formula xml:id="formula_4">k(z 1 , z 2 ) = f (z 1 ) T f (z 2 ),<label>(5)</label></formula><p>where f (?) can be a parametrized transformation function, represented by MLP model, or simply an identity operation, f (z) = z. In Euclidean space this criterion can be expressed as k(z 1 , z 2 ) = ||f (z 1 )||?||f (z 2 )|| cos ?, where ? is an angle between vectors f (z 1 ) and f (z 2 ). The main feature of this function is that it considers the vectors' norms, which can be problematic for some tasks that are outliers regarding the representations created by f (?). Therefore, we consider in our experiments also the cosine kernel function given by:</p><formula xml:id="formula_5">k c (z 1 , z 2 ) = f (z 1 ) T f (z 2 ) ||f (z 1 )|| ? ||f (z 2 )|| ,<label>(6)</label></formula><p>that represents the normalized version dot product. Considering the geometrical representation, k c (z 1 , z 2 ) can be expressed as cos ? (see the example given by <ref type="figure">Fig. 3</ref>). The support set is represented by two examples from different classes, f 1 and f 2 . The target model parameters ? T are created based only on the cosine value of the angle between vectors f 1 and f 2 . During the classification stage, the query example is represented by f x , and the classification is applied on the cosine values of angles between f x and f 1 , and f x and f 2 , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Training and prediction</head><p>The training procedure assumes the following parametrization of the model components. The encoder E := E ? E is parametrized by ? E , the hypernetwork H = H ? H by ? H , and the kernel function k by ? k . We assume that training set D is represented by tasks T i composed of support S i and query Q i examples. The training is performed by optimizing the cross-entropy criterion:</p><formula xml:id="formula_6">L = ? Ti?D M m=1 K k=1 y k i,m log p(y k i,m |S i , x i,m ),<label>(7)</label></formula><p>where</p><formula xml:id="formula_7">(x i,n , y i,n ) are examples from query set Q i , where Q i = {(x i,m , y i,m )} M m=1 .</formula><p>The distribution for currently considered classes p(y|S, x) is returned by target network T of HyperShot. During the training, we jointly optimize the parameters ? H , ? k , and ? E , minimizing the L loss.</p><p>During the inference stage, we consider the task T * , composed of a set of labeled support examples S * and a set of unlabelled query examples represented by input values X * that the model should classify. We can simply take the probability values p(y|S * , x) assuming the given support set S * and single query observation x from X * , using the model with trained parameters ? H , ? k , and ? E . However, we observe that slightly better results are obtained while tuning the model's parameters on the considered task. We do not have access to labels for query examples. Therefore we imitate the query set for this task simply by taking support examples and creating the tuning task T i = {S * , S * } and updating the parameters of the model using several gradient iterations. The detailed presentation o training and prediction procedures are provided by Algorithm 1. <ref type="figure">Figure 3</ref>. Simple 2D example illustrating the application of cosine kernel for HyperShot. We consider the two support examples from different classes represented by vectors f1 and f2. For this simple scenario, the input of hypernetwork is represented simply by the cosine of ?, which is an angle between vectors f1 and f2. We aim at classifying the query example x represented by a vector fx. Considering our approach, we deliver to the target network T (?) the cosine values of angles between first (?x,1) and second (?x,2) support vectors and classify the query example using the weights ?T created by hypernetwork H(?) from cos ? (remaining components on the diagonal of KS,S are constant for cosine kernel).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Adaptation to few-shot scenarios</head><p>The proposed approach uses the ordering function ?(?) that keeps the consistency between support kernel matrix K S,S and the vector of kernel values k x,S for query example x. For few-shot scenarios, each class has more than one representative in the support set. As a consequence, there are various possibilities to order the feature vectors in the support set inside the considered class. To eliminate this issue, we propose to apply the aggregation function to the embeddings z considering the support examples from the same class. Thanks to this approach, the kernel matrix is calculated based on the aggregated values of the latent space of encoding network E, making our approach independent of the ordering among the embeddings from the same class. In experimental studies, we examine the quality of mean aggregation operation (averaged) against simple class-wise concatenation of the embeddings (fine-grained) in ablation studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related Work</head><p>Feature transfer <ref type="bibr" target="#b48">(Zhuang et al., 2020</ref>) is a baseline procedure for few-shot learning and consists of pre-training the neural network and a classifier. During meta-validation, the classifier is fine-tuned to the novel tasks. <ref type="bibr" target="#b3">(Chen et al., 2019)</ref> extend this idea by using cosine distance between the examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 HyperShot -training and prediction functions</head><p>Require: Training set D = {Tn} N n=1 , and T * = {S * , X * } test task. Parameters: ?H -parameters , ? k -kernel parameters, and ?Eencoder parameters Hyperparameters: Ntrain -number of training iterations, Ntune number of tuning iterations, ?step size.</p><p>1: function TRAIN(D, ?, Ntrain, ?H , ? k , ?E) 2:</p><p>while n ? Ntrain do 3:</p><formula xml:id="formula_8">Sample task T = {S, Q} ? D 4: Assign support S = {(xm, ym)} M m=1 5: L = ? M m=1 K k=1 y k m log p(y k m |Si, xm, ?H , ? k , ?E) 6: Update: ?E ? ?E ? ?? ? E L, 7: ?H ? ?H ? ?? ? H L, 8: ? k ? ? k ? ?? ? k L 9:</formula><p>n = n + 1 10:</p><p>end while 11:</p><p>return ?H , ? k , ?E 12: end function 13: function PREDICT(T * , ?, Ntune, ?H , ? k , ?E) 14:</p><p>Create tuning task: Tt = {S * , S * } 15:</p><p>Tune?H ,? k ,?E = TRAIN(Tt, ?, Ntune, ?H , ? k , ?E) 16:</p><p>for each x ? X * do 17:</p><p>return arg maxy p(y|S * , x,?H ,? k ,?E) 18: end for 19: end function In recent years, a variety of meta-learning methods <ref type="bibr" target="#b12">(Hospedales et al., 2020;</ref><ref type="bibr" target="#b34">Schmidhuber, 1992;</ref><ref type="bibr" target="#b1">Bengio et al., 1992)</ref> have been proposed to tackle the problem of fewshot learning. The various meta-learning architectures for few-shot learning can be roughly categorized into several groups:</p><p>Memory-based methods <ref type="bibr" target="#b31">(Ravi &amp; Larochelle, 2017;</ref><ref type="bibr" target="#b21">Munkhdalai et al., 2018;</ref><ref type="bibr" target="#b33">Santoro et al., 2016;</ref><ref type="bibr" target="#b19">Mishra et al., 2018;</ref><ref type="bibr" target="#b20">Munkhdalai &amp; Yu, 2017;</ref><ref type="bibr" target="#b46">Zhen et al., 2020)</ref> are based on the idea to train a meta-learner with memory to learn novel concepts.</p><p>Metric-based methods meta-learn a deep representation with a metric in feature space, such that distance between examples from the support and query set with the same class have a small distance in such space. Some of the earliest works exploring this notion are Matching Networks <ref type="bibr" target="#b40">(Vinyals et al., 2016)</ref> and Prototypical Networks <ref type="bibr" target="#b37">(Snell et al., 2017)</ref>, which form prototypes based on embeddings of the examples from the support set in the learned feature space and classify the query set based on the distance to those prototypes. Numerous subsequent works aim to improve the expressiveness of the prototypes through various techniques. <ref type="bibr" target="#b24">(Oreshkin et al., 2018)</ref> achieve this by conditioning the network on specific tasks, thus making the learned space task-dependent. <ref type="bibr" target="#b13">(Hu et al., 2021)</ref> transform embeddings of support and query examples in the feature space to make their distributions closer to Gaussian. <ref type="bibr" target="#b39">(Sung et al., 2018)</ref> propose Relation Nets, which learn the metric function instead of using a fixed one, such as Euclidean or cosine distance.</p><p>Similar to the above methods, HyperShot uses a kernel function that predicts the relations between the examples in a given task. The key difference is that instead of performing a nearest-neighbor classification based on the kernel values, in HyperShot, the kernel matrix is classified by a task-specific classifier generated by the hypernetwork.</p><p>Optimization-based methods follow the idea of an optimization process over support set within the meta-learning framework like MetaOptNet <ref type="bibr" target="#b18">(Lee et al., 2019)</ref>, Model-Agnostic Meta-Learning (MAML), and its extensions <ref type="bibr" target="#b5">(Finn et al., 2017;</ref><ref type="bibr" target="#b23">Nichol et al., 2018;</ref><ref type="bibr" target="#b27">Raghu et al., 2019;</ref><ref type="bibr" target="#b28">Rajeswaran et al., 2019;</ref><ref type="bibr" target="#b6">Finn et al., 2018;</ref><ref type="bibr" target="#b23">Nichol et al., 2018)</ref>. Those techniques aim to train general models, which can adapt their parameters to the support set at hand in a small number of gradient steps. Similar to such techniques, HyperShot also aims to produce task-specific models but utilizes a hypernetwork instead of optimization to achieve that goal.</p><p>Gaussian processes <ref type="bibr" target="#b29">(Rasmussen, 2003</ref>) possess many properties useful in few-shot learning, such as natural robustness to the limited amounts of data and the ability to estimate uncertainty. When combined with meta-learned deep kernels, <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref>, Gaussian processes were demonstrated to be a suitable tool for few-shot regression and classification, dubbed Deep Kernel Transfer (DKT). The assumption that such a universal deep kernel has enough data to generalize well to unseen tasks has been challenged in subsequent works. <ref type="bibr">(Wang et al., 2021)</ref> introduced a technique of learning dense Gaussian processes by inducing variables. This approach achieves substantial performance improvement over the alternative methods. Similarly, Hy-perShot also depends on learning a model that estimates task-specific functions' parameters. However, HyperShot employs a hypernetwork instead of a Gaussian process to achieve that goal.</p><p>Hypernetworks <ref type="bibr" target="#b10">(Ha et al., 2016)</ref> have been proposed as a solution to few-shot learning problems in a number of works but have not been researched as widely as the approaches mentioned above. Multiple works proposed various variations of hyper-networks that predict a shallow classifier's parameters given the support examples <ref type="bibr" target="#b0">(Bauer et al., 2017;</ref><ref type="bibr" target="#b26">Qiao et al., 2017)</ref>. Subsequent works have extended those models by calculating cosine similarity between the query examples and the generated classifier weights <ref type="bibr" target="#b7">(Gidaris &amp; Komodakis, 2018)</ref> and utilizing a probabilistic model that predicts a distribution over the parameters suitable for the given task <ref type="bibr" target="#b8">(Gordon et al., 2018)</ref>. More recently, <ref type="bibr" target="#b47">(Zhmoginov et al., 2022)</ref> explored generating all of the parameters of the target network with a transformer-based hypernetwork, but found that for larger target networks, it is sufficient to generate only the parameters of the final classification layer. A key characteristic of the above approaches is that during inference, the hypernetwork predicts weights responsible for classifying each class independently, based solely on the examples of that class from the support set. This property makes such solutions agnostic to the number of classes in a task, useful in practical applications. However, it also means that the hypernetwork does not take advantage of the inter-class differences in the task at hand.</p><p>In contrast, HyperShot exploits those differences by utilizing kernels, which helps improve its performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In the typical few-shot learning setting, making a valuable and fair comparison between proposed models is often complicated because of the existence of the significant differences in architectures and implementations of known methods. In order to limit the influence of the deeper backbone (feature extractor) architectures, we follow the unified procedure proposed by <ref type="bibr" target="#b3">(Chen et al., 2019)</ref>.</p><p>In this section, we describe the experimental analysis and performance of the HyperShot in the large variety of fewshot benchmarks. Specifically, we consider both classification (see Section 4.1) and cross-domain adaptation (see Section 4.2) tasks. Whereas the classification problems are focused on the most typical few-shot applications, the latter cross-domain benchmarks check the ability of the models to adapt to out-of-distribution tasks. Additionally, we perform an ablation study of the possible adaptation procedures of HyperShot to few-shot scenarios -presented in Section 4.3.</p><p>In all of the reported experiments, the tasks consist of 5 classes (5-way) and 1 or 5 support examples (1 or 5-shot). Unless indicated otherwise, all compared models use a known and widely utilized backbone consisting of four convolutional layers (each consisting of a 2D convolution, a batch-norm layer, and a ReLU non-linearity; each layer consists of 64 channels) and have been trained from scratch.</p><p>We report the performance of two variants of HyperShot:</p><p>? HyperShot -models generated by the hypernetworks for each task.</p><p>? HyperShot + finetuning -models generated by hypernetworks finetuned to the support examples of each task for 10 training steps 1 .</p><p>In all cases, we observe a modest performance boost thanks to finetuning the hypernetwork.</p><p>Comprehensive details for each training procedure are re-  <ref type="bibr" target="#b48">(Zhuang et al., 2020)</ref> 46.19 ? 0.64 39.51 ? 0.23 Baseline++ <ref type="bibr" target="#b3">(Chen et al., 2019)</ref> 61.75 ? 0.95 47.15 ? 0.49 MatchingNet <ref type="bibr" target="#b40">(Vinyals et al., 2016)</ref> 60.19 ? 1.02 48.25 ? 0.65 ProtoNet <ref type="bibr" target="#b37">(Snell et al., 2017)</ref> 52.52 ? 1.90 44.19 ? 1.30 MAML <ref type="bibr" target="#b5">(Finn et al., 2017)</ref> 56.11 ? 0.69 45.39 ? 0.49 RelationNet <ref type="bibr" target="#b39">(Sung et al., 2018)</ref> 62.52 ? 0.34 48.76 ? 0.17 DKT + CosSim <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref> 63.37 ? 0.19 48.64 ? 0.45 DKT + BNCosSim <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref> 62.96 ? 0.62 49.73 ? 0.07 GPLDLA <ref type="bibr" target="#b15">(Kim &amp; Hospedales, 2021)</ref> 63.40 ? 0.14 52.58 ? 0.19 amortized Bayesian prototype meta-learning <ref type="bibr" target="#b38">(Sun et al., 2021)</ref> 63.46 ? 0.98 53.28 ? 0.91 VAMPIRE (Nguyen et al., 2020) -51.54 ? 0.74 PLATIPUS  -50.13 ? 1.86 ABML <ref type="bibr" target="#b30">(Ravi &amp; Beatson, 2018)</ref> 49.57 ? 0.42 45.00 ? 0.60 Bayesian MAML <ref type="bibr" target="#b45">(Yoon et al., 2018)</ref> 55.93 ? 0.71 53.80 ? 1.46 OVE PG GP + Cosine (ML) <ref type="bibr" target="#b36">(Snell &amp; Zemel, 2020)</ref> 63.98 ? 0.43 50.02 ? 0.35 OVE PG GP + Cosine (PL) <ref type="bibr" target="#b36">(Snell &amp; Zemel, 2020)</ref> 60. ported in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Classification</head><p>Firstly, we consider a classical few-shot learning scenario, where all the classification tasks (both training and inference) come from the same dataset. The main aim of the proposed classification experiments is to find the ability of the few-shot models to adapt to never-seen tasks from the same data distribution.</p><p>We benchmark the performance of the HyperShot and other methods on two challenging and widely considered datasets: Caltech-USCD Birds (CUB) <ref type="bibr" target="#b41">(Wah et al., 2011)</ref> and mini-ImageNet <ref type="bibr" target="#b31">(Ravi &amp; Larochelle, 2017)</ref>. The following experiments are in the most popular setting, 5-way, consisting of 5 random classes. In all experiments, the query set of each task consists of 16 samples for each class (80 in total). We provide the additional training details in the Appendix. We compare HyperShot to a vast pool of the state-of-the-art algorithms, including the canonical methods (like Matching Networks <ref type="bibr" target="#b40">(Vinyals et al., 2016)</ref>, Prototypical Networks <ref type="bibr" target="#b37">(Snell et al., 2017)</ref>, MAML <ref type="bibr" target="#b5">(Finn et al., 2017)</ref>, and its extensions) as well as the recently popular Bayesian methods mostly build upon the Gaussian Processes framework (like DKT <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref>).  <ref type="bibr" target="#b3">(Chen et al., 2019)</ref> 78.51 ? 0.59 66.18 ? 0.18 MatchingNet <ref type="bibr" target="#b40">(Vinyals et al., 2016)</ref> 75.11 ? 0.35 62.71 ? 0.44 ProtoNet <ref type="bibr" target="#b37">(Snell et al., 2017)</ref> 75.93 ? 0.46 64.07 ? 0.65 MAML <ref type="bibr" target="#b5">(Finn et al., 2017)</ref> 74.84 ? 0.62 61.58 ? 0.53 RelationNet <ref type="bibr" target="#b39">(Sung et al., 2018)</ref> 78.22 ? 0.07 64.20 ? 0.28 DKT + CosSim <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref> 77.73 ? 0.26 62.85 ? 0.37 DKT + BNCosSim <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref> 77.76 ? 0.62 64.00 ? 0.09 GPLDLA <ref type="bibr" target="#b15">(Kim &amp; Hospedales, 2021)</ref> 78.86 ? 0.35 amortized Bayesian prototype meta-learning <ref type="bibr" target="#b38">(Sun et al., 2021)</ref> 80.94 ? 0.62 70.44 ? 0.72 VAMPIRE (Nguyen et al., 2020) -64.31 ? 0.74 ABML <ref type="bibr" target="#b30">(Ravi &amp; Beatson, 2018)</ref> 68.94 ? 0.16 -Bayesian MAML <ref type="bibr" target="#b45">(Yoon et al., 2018)</ref> -64.23 ? 0.69 OVE PG GP + Cosine (ML) <ref type="bibr" target="#b36">(Snell &amp; Zemel, 2020)</ref> 77.44 ? 0.18 64.58 ? 0.31 OVE PG GP + Cosine (PL) <ref type="bibr" target="#b36">(Snell &amp; Zemel, 2020)</ref> 79. We first consider the more challenging 1-shot task and report the results in <ref type="table" target="#tab_0">Table 1</ref>. We further consider the 5-shot setting and report the results in <ref type="table" target="#tab_2">Table 2</ref>. The additional results comparing methods on larger backbones are included in Appendix.</p><p>In the 1-shot scenario, HyperShot achieves the highest accuracies in the CUB dataset with and without utilizing a finetuning procedure (66.13% with a finetuning, 65.27% without) and performs better than any other model. However, in the mini-ImageNet dataset, our approach is among the best models (53.18%), slightly losing with DFSVLwF (Gidaris &amp; Komodakis, 2018) (56.20%).</p><p>Considering the 5-shot scenario, HyperShot is the secondbest model achieving 80.07% in the CUB dataset and 69.62% in the mini-ImageNet, whereas the best model, amortized Bayesian prototype meta-learning, is insignificantly better and achieves 80.94% and 70.44% on the mentioned datasets, respectively.</p><p>The obtained results clearly show that HyperShot achieves state-of-the-art or comparable results to the best models on the intensive set of a standard classification few-shot learning setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Cross-domain adaptation</head><p>In the cross-domain adaptation setting, the model is evaluated on tasks coming from a different distribution than the one it had been trained on. Therefore, such a task is  <ref type="bibr" target="#b3">(Chen et al., 2019)</ref> 56.84 ? 0.91 80.01 ? 0.92 39.19 ? 0.12 57.31 ? 0.11 MatchingNet <ref type="bibr" target="#b40">(Vinyals et al., 2016)</ref> 75.01 ? 2.09 87.41 ? 1.79 36.98 ? 0.06 50.72 ? 0.36 ProtoNet <ref type="bibr" target="#b37">(Snell et al., 2017)</ref> 72.04 ? 0.82 87.22 ? 1.01 33.27 ? 1.09 52.16 ? 0.17 MAML <ref type="bibr" target="#b5">(Finn et al., 2017)</ref> 72.68 ? 1.85 83.54 ? 1.79 34.01 ? 1.25 48.83 ? 0.62 RelationNet <ref type="bibr" target="#b39">(Sung et al., 2018)</ref> 75.62 ? 1.00 87.84 ? 0.27 37.13 ? 0.20 51.76 ? 1.48 DKT <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref> 75.40 ? 1.10 90 .30 ? 0 .49 40.14 ? 0.18 56.40 ? 1.34 Bayesian MAML <ref type="bibr" target="#b45">(Yoon et al., 2018)</ref> 63.94 ? 0.47 65.26 ? 0.30 33.52 ? 0.36 51.35 ? 0.16 OVE PG GP + Cosine (ML) <ref type="bibr" target="#b36">(Snell &amp; Zemel, 2020)</ref> 68.43 ? 0.67 86.22 ? 0.20 39.66 ? 0.18 55.71 ? 0.31 OVE PG GP + Cosine (PL) <ref type="bibr" target="#b36">(Snell &amp; Zemel, 2020)</ref> 77.00 ? 0.50 87. more challenging than standard classification and is a plausible indicator of a model's ability to generalize. In order to benchmark the performance of HyperShot in cross-domain adaptation, we merge data from two datasets so that the training fold is drawn from the first dataset and validation and testing fold -from another one. Specifically, we test HyperShot on two cross-domain classification tasks: mini-ImageNet ? CUB (model trained on mini-ImageNet and evaluated on CUB) and Omniglot ? EM-NIST in the 1-shot and 5-shot settings. We report the results in <ref type="table" target="#tab_4">Table 3</ref>. In most settings, HyperShot achieves the highest accuracy, except for 1-shot mini-ImageNet ? CUB classification, where its accuracy is on par with the accuracy achieved by DKT <ref type="bibr">(Patacchiola et al., 2020) (40.14% and 40.03% achieved by DKT and HyperShot, respectively)</ref>. We note that just in the case of regular classification, finetuning the hypernetwork on the individual tasks consistently improves its performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Aggregating support examples in the 5-shot setting</head><p>In HyperShot, the hypernetwork generates the weights of the information about the support examples, expressed through the support-support kernel matrix. In the case of 5-way 1-shot classification, each task consists of 5 support examples, and therefore, the size of the kernel matrix is (5 ? 5), and the input size of the hypernetwork is 25. However, when the number of support examples grows, increasing the size of the kernel matrix may be impractical and lead to overparametrization of the hypernetwork.</p><p>Since hypernetworks are known to be sensitive to large input sizes <ref type="bibr" target="#b10">(Ha et al., 2016)</ref>, we consider a way to maintain a constant input size of HyperShot, independent of the number of support examples of each class by using means of support embeddings of each class for kernel calculation, instead of individual embeddings. Prior works suggest that when there are multiple examples of a class, an averaged embedding of such class represents it sufficiently in the embedding space <ref type="bibr" target="#b37">(Snell et al., 2017)</ref>.</p><p>To verify this approach, in the 5-shot setting, we train Hy-perShot with two variants of calculating the inputs to the kernel matrix:</p><p>? fine-grained -utilizing a hypernetwork that takes as an input a kernel matrix between each of the embeddings of the individual support examples. This kernel matrix has a shape of (25 ? 25).</p><p>? averaged -utilizing a hypernetwork where the kernel matrix is calculated between the means of embeddings of each class. The kernel matrix in this approach has a shape of (5 ? 5).</p><p>We benchmark both variants of HyperShot on the 5-shot classification task on CUB and mini-ImageNet datasets. Moreover, we compare these approaches also on crossdomain classification between the Omniglot and EMNIST datasets. We report the accuracies in <ref type="table" target="#tab_6">Table 4</ref>. It is evident that averaging the embeddings before calculating the kernel matrix yields superior results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we introduced HyperShot -a new framework that uses kernel methods combined with hypernetworks.</p><p>Our method uses the kernel-based representation of the support examples and a hypernetwork paradigm to create the query set's classification module. We concentrate on relations between embeddings of the support examples instead of direct feature values. Thanks to this approach, our model can adapt to highly different tasks.</p><p>We evaluate the HyperShot model on various one-shot and few-shot image classification tasks. HyperShot demonstrates high accuracy in all tasks, performing comparably or better to state-of-the-art solutions. Furthermore, the model has a strong ability to generalize, as evidenced by its performance on cross-domain classification tasks. <ref type="table">Table 6</ref>. The classification accuracy results for the inference tasks in the mini-ImageNet dataset in the 5-way (1-shot and 5-shot) scenarios. We consider models using the ResNet-10 backbone. The highest results are bold and second-highest in italic (the larger, the better).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method 1-shot 5-shot</head><p>Baseline++ <ref type="bibr" target="#b3">(Chen et al., 2019)</ref> 54.35 ? 0.34 75.26 ? 0.16 MatchingNet <ref type="bibr" target="#b40">(Vinyals et al., 2016)</ref> 54.18 ? 0.09 67.71 ? 0.20 ProtoNet <ref type="bibr" target="#b37">(Snell et al., 2017)</ref> 53.28 ? 0.17 73.04 ? 0.15 RelationNet <ref type="bibr" target="#b39">(Sung et al., 2018)</ref> 51.88 ? 0.45 67.21 ? 0.16 DKT + BNCosSim <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref>  of that parameter. All heads of HyperShot have identical lengths, hidden sizes, and input sizes that depend on the generated parameter's size.</p><p>The target network generated by HyperShot re-uses its backbone. We outline this architecture in <ref type="figure">Figure 4</ref>.</p><p>Backbone For each experiment described in the main body of this work, we follow <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref> in using a shallow backbone (feature extractor) for HyperShot as well as referential models. This backbone consists of four convolutional layers, each consisting of a convolution, batch normalization, and ReLU nonlinearity. Apart from the first convolution, which has the number of input size equal to the number of image channels, each convolution has an input and output size of 64. We apply max-pooling between each convolution, which decreases by half the resolution of the processed feature maps. The output of the backbone is flattened so that the further layers can process it.</p><p>We perform additional experiments described in Appendix A where instead of the above backbone, we utilize ResNet-10 <ref type="bibr" target="#b11">(He et al., 2015)</ref>.</p><p>Datasets For the purpose of making a fair comparison, we follow the procedure presented in, e.g., <ref type="bibr" target="#b25">(Patacchiola et al., 2020;</ref><ref type="bibr" target="#b3">Chen et al., 2019)</ref>. In the case of the CUB dataset <ref type="bibr" target="#b41">(Wah et al., 2011)</ref>, we split the whole amount of 200 classes (11788 images) across train, validation, and test consisting of 100, 50, and 50 classes, respectively <ref type="bibr" target="#b3">(Chen et al., 2019)</ref>. The mini-ImageNet dataset <ref type="bibr" target="#b31">(Ravi &amp; Larochelle, 2017)</ref> is created as the subset of ImageNet <ref type="bibr" target="#b32">(Russakovsky et al., 2015)</ref>, which consists of 100 different classes represented by 600 images for each one. We followed the standard procedure and divided the mini-ImageNet into 64 classes for the train, 16 for the validation set, and the remaining 20 classes for the test. The well-known Omniglot dataset <ref type="bibr" target="#b17">(Lake et al., 2011</ref>) is a collection of characters from 50 different languages. The Omniglot contains 1623 white and black characters in total. We utilize the standard procedure to include the examples rotated by 90 ? and increase the size of the dataset to 6492, from which 4114 were further used in training. Finally, the EMNIST dataset <ref type="bibr" target="#b4">(Cohen et al., 2017)</ref> collects the characters and digits coming from the English alphabet, which we split into 31 classes for the test and 31 for validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data augmentation</head><p>We apply data augmentation during model training in all experiments, except Omniglot ? EMNIST cross-domain classification. The augmentation pipeline is identical to the one used by <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref> and consists of the random crop, horizontal flip, and color jitter steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Hyperparameters</head><p>Below, we outline the hyperparameters of architecture and training procedures used in each experiment.</p><p>We use cosine similarity as a kernel function and averaged support embeddings aggregation in all experiments. HyperShot is trained with the learning rate of 0.001 with the Adam optimizer <ref type="bibr" target="#b16">(Kingma &amp; Ba, 2014)</ref> and no learning rate scheduler. Task-specific finetuning is also performed with the Adam optimizer and the learning rate of 0.0001.</p><p>For the natural image tasks (CUB, mini-ImageNet, mini-ImageNet ? CUB classification), we use a hypernetwork with the neck length o 2, head lengths of 3, and a hidden size of 4096, which produce a target network with a single fully-connected layer. We perform training for 10000 epochs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>The general architecture of HyperShot. First, the examples from a support set are sorted according to the corresponding class labels and transformed by encoding network E(?) to obtain the matrix of ordered embeddings of the support examples, ZS. The low-dimensional representations stored in ZS are further used to compute kernel matrix KS,S. The values of the kernel matrix are passed to the hypernetwork H(?) that creates the parameters ?T for the target classification module T (?). The query image x is processed by encoder E(?), and the vector of kernel values kx,S is calculated between query embedding zx and the corresponding representations of support examples, ZS. The kernel vector kx,S is further passed to target model T (?) to obtain the probability distribution for the considered classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>The classification accuracy results for the inference tasks on CUB and mini-ImageNet datasets in the 1-shot setting. The highest results are bold and second-highest in italic (the larger, the better).</figDesc><table><row><cell>Method</cell><cell>CUB</cell><cell>mini-ImageNet</cell></row><row><cell>ML-LSTM (Ravi &amp; Larochelle, 2017)</cell><cell>-</cell><cell>43.44 ? 0.77</cell></row><row><cell>SNAIL (Mishra et al., 2018)</cell><cell>-</cell><cell>45.10</cell></row><row><cell>iMAML-HF (Rajeswaran et al., 2019)</cell><cell>-</cell><cell>49.30 ? 1.88</cell></row><row><cell>LLAMA (Grant et al., 2018)</cell><cell>-</cell><cell>49.40 ? 1.83</cell></row><row><cell>VERSA (Gordon et al., 2018)</cell><cell>-</cell><cell>48.53 ? 1.84</cell></row><row><cell>Amortized VI (Gordon et al., 2018)</cell><cell>-</cell><cell>44.13 ? 1.78</cell></row><row><cell>Meta-Mixture (Jerfel et al., 2019)</cell><cell>-</cell><cell>49.60 ? 1.50</cell></row><row><cell>SimpleShot (Wang et al., 2019)</cell><cell>-</cell><cell>49.69 ? 0.19</cell></row><row><cell>Feature Transfer</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>The classification accuracy results for the inference tasks on CUB and mini-ImageNet datasets in the 5-shot setting. The highest results are bold and second-highest in italic (the larger, the better).</figDesc><table><row><cell>Method</cell><cell>CUB</cell><cell>mini-ImageNet</cell></row><row><cell>ML-LSTM (Ravi &amp; Larochelle, 2017)</cell><cell>-</cell><cell>60.60 ? 0.71</cell></row><row><cell>SNAIL (Mishra et al., 2018)</cell><cell>-</cell><cell>55.20</cell></row><row><cell>VERSA (Gordon et al., 2018)</cell><cell>-</cell><cell>67.37 ? 0.86</cell></row><row><cell>Amortized VI (Gordon et al., 2018)</cell><cell>-</cell><cell>55.68 ? 0.91</cell></row><row><cell>Meta-Mixture (Jerfel et al., 2019)</cell><cell>-</cell><cell>64.60 ? 0.92</cell></row><row><cell>SimpleShot (Wang et al., 2019)</cell><cell>-</cell><cell>66.92 ? 0.17</cell></row><row><cell>Feature Transfer</cell><cell>68.40 ? 0.79</cell><cell>60.51 ? 0.55</cell></row><row><cell>Baseline++</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>The classification accuracy results for the inference tasks on cross-domain tasks (Omniglot?EMNIST and mini-ImageNet?CUB) datasets in the 1-shot setting. The highest results are bold and second-highest in italic (the larger, the better).</figDesc><table><row><cell>Omni?EMNIST</cell><cell>mini-ImageNet?CUB</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc>The classification accuracy results for HyperShot in the 5-shot setting with two variants of the support embeddings aggregation. The performance measured on Omniglot?EMNIST, CUB, and mini-ImageNet?CUB tasks. The larger, the better.</figDesc><table><row><cell></cell><cell>Omni?EMNIST</cell><cell>CUB</cell><cell>mini-ImageNet</cell></row><row><cell>HyperShot (fine-grained)</cell><cell>87.55 ? 0.19</cell><cell>78.05 ? 0.20</cell><cell>67.07 ? 0.47</cell></row><row><cell>HyperShot (averaged)</cell><cell>89.04 ? 0.18</cell><cell>79.80 ? 0.16</cell><cell>69.62 ? 0.28</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In the case of the finetuned hypernetworks, we tune a copy of the hypernetwork separately for each validation task. This way, we ensure that our model does not take unfair advantage of the validation tasks.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In the case of the mini-ImageNet classification with ResNet10, we benchmarked all of the listed models ourselves. To our best knowledge, previously, there were no reported benchmarks on this dataset with the ResNet-10 backbone.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This section provides additional results in the 5-way (1-shot and 5-shot) classification tasks for models using a larger backbone, namely ResNet-10 <ref type="bibr" target="#b11">(He et al., 2015)</ref>. We provide the results for CUB and mini-ImageNet datasets in Tables 5 and 6.</p><p>In the CUB dataset classification tasks (see <ref type="table">Table 5</ref>), HyperShot is amongst the state-of-the-art models achieving classification accuracy often equal within the variance to the best models. Considering the 5-shot scenario, the highest classification result across the evaluated methods (86.38% ? 0.15) obtained the GPLDLA model based on the Gaussian Processes framework. However, the HyperShot performance, 86.28% ? 0.29, is the second-best but even lies within the variance of the best model. In the 1-shot setting, ProtoNet obtains the highest result (73.22% ? 0.92), whereas HyperShot is the third one (71.99% ? 0.70) but still equal according to the variances.</p><p>In the mini-ImageNet classification task, HyperShot achieves the second-best accuracy in both 1-shot and 5-shot settings 2 . In the 1-shot setting, the DKT model <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref> achieved the best result, with HyperShot being a close second, with only 0.04 pp difference. In the 5-shot setting, the baseline++ approach outperforms all others by a large margin <ref type="bibr" target="#b3">(Chen et al., 2019)</ref>, whereas HyperShot and ProtoNet <ref type="bibr" target="#b37">(Snell et al., 2017)</ref> achieve similar, second-best results. We observe that apart from HyperShot, which achieves second-best results in both settings, models which perform well in one setting are outperformed by others in the second and vice versa.</p><p>It is worth noticing that HyperShot without finetuning steps performances sometimes slightly better than the same with finetuning. We even observe that a few first steps of finetuning procedure result in an unnoticeable increase of accuracy of the basic model. However, the usual 10 steps result in this setting in slightly worse performance, so one should use it cautiously. We decided to report the results after the standard finetuning procedure only. <ref type="table">Table 5</ref>. The classification accuracy results for the inference tasks in the CUB dataset in the 5-way (1-shot and 5-shot) scenarios. We consider models using the ResNet-10 backbone. The highest results are bold and second-highest in italic (the larger, the better).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>1-shot 5-shot Feature Transfer 63.64 ? 0.91 81.27 ? 0.57 Baseline++ <ref type="bibr" target="#b3">(Chen et al., 2019)</ref> 69.55 ? 0.89 85.17 ? 0.50 MatchingNet <ref type="bibr" target="#b40">(Vinyals et al., 2016)</ref> 71.29 ? 0.87 83.47 ? 0.58 ProtoNet <ref type="bibr" target="#b37">(Snell et al., 2017)</ref> 73.22 ? 0.92 85.01 ? 0.52 MAML <ref type="bibr" target="#b5">(Finn et al., 2017)</ref> 70.32 ? 0.99 80.93 ? 0.71 RelationNet <ref type="bibr" target="#b39">(Sung et al., 2018)</ref> 70.47 ? 0.99 83.70 ? 0.55 DKT + CosSim <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref> 70.81 ? 0.52 83.26 ? 0.50 DKT + BNCosSim <ref type="bibr" target="#b25">(Patacchiola et al., 2020)</ref> 72 .27 ? 0 .30 85.64 ? 0.29 SimpleShot  53.78 ? 0.21 71.41 ? 0.17 GPLDLA <ref type="bibr" target="#b15">(Kim &amp; Hospedales, 2021)</ref> 71 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Training details</head><p>In this section, we present in detail the architecture and hyperparameters of HyperShot.</p><p>Architecture overview From a high-level perspective, the architecture of HyperShot consists of three parts:</p><p>? backbone -a convolutional feature extractor.</p><p>? neck -a sequence of zero or more fully-connected layers with ReLU nonlinearities in between.</p><p>? heads -for each parameter of the target network, a sequence of one or more linear layers, which predicts the values  For the simpler Omniglot ? EMNIST character classification task, we train a smaller hypernetwork with the neck length of 1, head lengths of 2, and the hidden size of 512, which produces a target network with two fully-connected layers and a hidden size of 128. We train this hypernetwork for a shorter number of epochs, namely 2000.</p><p>We summarize all the above hyperparameters in <ref type="table">Table 7</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Discriminative k-shot learning using probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rojas-Carulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>?wiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">On the optimization of a synaptic learning rule</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cloutier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gecsei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable closed-form solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.04232</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Emnist: an extension of mnist to handwritten letters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Afshar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tapson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Schaik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.05373</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Model-agnostic metalearning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Probabilistic modelagnostic meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9537" to="9548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4367" to="4375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Meta-learning probabilistic inference for prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bronskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Recasting gradient-based meta-learning as hierarchical bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hypernetworks</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.09106</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Meta-learning in neural networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Micaelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Leveraging the feature distribution in transfer-based few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gripon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pateux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reconciling meta-learning and continual learning with online mixtures of tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jerfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Heller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Neural Information Processing Systems</title>
		<meeting>the 33rd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9122" to="9133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Gaussian process meta fewshot classifier learning via linear discriminant laplace approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.05392</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<title level="m">A method for stochastic optimization. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">One shot learning of simple visual concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the annual meeting of the cognitive science society</title>
		<meeting>the annual meeting of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Metalearning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10657" to="10665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Meta</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Networks</surname></persName>
		</author>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2554" to="2563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rapid adaptation with conditionally shifted neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3664" to="3673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Uncertainty in model-agnostic meta-learning using variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-T</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3090" to="3100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tadam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10123</idno>
		<title level="m">Task dependent adaptive metric for improved few-shot learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bayesian meta-learning for the few-shot setting via deep kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Patacchiola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Crowley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>O&amp;apos;boyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Few-shot image recognition by predicting parameters from activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuille</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Rapid learning or feature reuse? towards understanding the effectiveness of maml</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.09157</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Meta-learning with implicit gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="113" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Gaussian processes in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Summer school on machine learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="63" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Amortized bayesian meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beatson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Meta-learning with memory-augmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1992.4.1.131</idno>
		<ptr target="https://doi.org/10.1162/neco.1992.4.1.131" />
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="139" />
			<date type="published" when="1992-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Stochastic maximum likelihood optimization via hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-S</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Merentitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bergmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.01141</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bayesian few-shot classification with one-vs-each p?lya-gamma augmented gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.05175</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Amortized bayesian prototype meta-learning: A new probabilistic meta-learning approach to few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1414" to="1422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<title level="m">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-L</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simpleshot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.04623</idno>
		<title level="m">Revisiting nearest-neighbor classification for few-shot learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Generalizing from a few examples: A survey on few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Ni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning to learn dense gaussian processes for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Bayesian model-agnostic meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Dia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahn</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7343" to="7353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Learning to learn variational semantic memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Hypertransformer: Model generation for supervised and semi-supervised few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vladymyrov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>A comprehensive survey on transfer learning</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
