<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxin</forename><surname>Wang</surname></persName>
							<email>boxinw2@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chejian</forename><surname>Xu</surname></persName>
							<email>xuchejian@zju.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
							<email>shuohang.wang@microsoft.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
							<email>zhe.gan@microsoft.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
							<email>yu.cheng@microsoft.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
							<email>jfgao@microsoft.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">Hassan</forename><surname>Awadallah</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T22:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large-scale pre-trained language models have achieved tremendous success across a wide range of natural language understanding (NLU) tasks, even surpassing human performance. However, recent studies reveal that the robustness of these models can be challenged by carefully crafted textual adversarial examples. While several individual datasets have been proposed to evaluate model robustness, a principled and comprehensive benchmark is still missing. In this paper, we present Adversarial GLUE (AdvGLUE), a new multi-task benchmark to quantitatively and thoroughly explore and evaluate the vulnerabilities of modern large-scale language models under various types of adversarial attacks. In particular, we systematically apply 14 textual adversarial attack methods to GLUE tasks to construct AdvGLUE, which is further validated by humans for reliable annotations. Our findings are summarized as follows. (i) Most existing adversarial attack algorithms are prone to generating invalid or ambiguous adversarial examples, with around 90% of them either changing the original semantic meanings or misleading human annotators as well. Therefore, we perform careful filtering process to curate a high-quality benchmark. (ii) All the language models and robust training methods we tested perform poorly on AdvGLUE, with scores lagging far behind the benign accuracy. We hope our work will motivate the development of new adversarial attacks that are more stealthy and semantic-preserving, as well as new robust language models against sophisticated adversarial attacks. AdvGLUE is available at https://adversarialglue.github.io.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Pre-trained language models <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b5">6]</ref> have achieved state-of-the-art performance over a wide range of Natural Language Understanding (NLU) tasks <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b37">38]</ref>. However, recent studies <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b12">13]</ref> reveal that even these large-scale language models are vulnerable to carefully crafted adversarial examples, which can fool the models to output arbitrarily wrong answers by perturbing input sentences in a human-imperceptible way. Real-world systems built upon these vulnerable models can be misled in ways that would have profound security concerns <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>.</p><p>To address this challenge, various methods <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b29">30]</ref> have been proposed to improve the adversarial robustness of language models. However, the adversary setup considered in these methods lacks a unified standard. For example, Jiang et al. <ref type="bibr" target="#b22">[23]</ref>, Liu et al. <ref type="bibr" target="#b29">[30]</ref> mainly evaluate their robustness against human-crafted adversarial datasets <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b20">21]</ref>, while Wang et al. <ref type="bibr" target="#b50">[51]</ref> evaluate the model robustness against automatic adversarial attack algorithms <ref type="bibr" target="#b23">[24]</ref>. The absence of a principled adversarial benchmark makes it difficult to compare the robustness across different models and identify the adversarial attacks that most models are vulnerable to. This motivates us to build a unified and principled robustness evaluation benchmark for natural language models and hope to help answer the following questions: what types of language models are more robust when evaluated on the unified adversarial benchmark? Which adversarial attack algorithms against language models are more effective, transferable, or stealthy to human? How likely can human be fooled by different adversarial attacks?</p><p>We list out the fundamental principles to create a high-quality robustness evaluation benchmark as follows. First, as also pointed out by <ref type="bibr" target="#b1">[2]</ref>, a reliable benchmark should be accurately and unambiguously annotated by humans. This is especially crucial for the robustness evaluation, as some adversarial examples generated by automatic attack algorithms can fool humans as well <ref type="bibr" target="#b33">[34]</ref>. Given our analysis in ?3.4, among the generated adversarial data, there are only around 10% adversarial examples that receive at least 4-vote consensus among 5 annotators and align with the original label. Thus, additional rounds of human filtering are critical to validate the quality of the generated adversarial attack data. Second, a comprehensive robustness evaluation benchmark should cover enough language phenomena and generate a systematic diagnostic report to understand and analyze the vulnerabilities of language models. Finally, a robustness evaluation benchmark needs to be challenging and unveil the biases shared across different models.</p><p>In this paper, we introduce Adversarial GLUE (AdvGLUE), a multi-task benchmark for robustness evaluation of language models. Compared to existing adversarial datasets, there are several contributions that render AdvGLUE a unique and valuable asset to the community.</p><p>? Comprehensive Coverage. We consider textual adversarial attacks from different perspectives and hierarchies, including word-level transformations, sentence-level manipulations, and human-written adversarial examples, so that AdvGLUE is able to cover as many adversarial linguistic phenomena as possible. ? Systematic Annotations. To the best of our knowledge, this is the first work that performs systematic and comprehensive evaluation and annotation over 14 different textual adversarial examples. Concretely, AdvGLUE adopts crowd-sourcing to identify high-quality adversarial data for reliable evaluation. ? General Compatibility. To obtain comprehensive understanding of the robustness of language models across different NLU tasks, AdvGLUE covers the widely-used GLUE tasks and creates an adversarial version of the GLUE benchmark to evaluate the robustness of language models. ? High Transferability and Effectiveness. AdvGLUE has high adversarial transferability and can effectively attack a wide range of state-of-the-art models. We observe a significant performance drop for models evaluated on AdvGLUE compared with their standard accuracy on GLUE leaderboard. For instance, the average GLUE score of ELECTRA(Large) <ref type="bibr" target="#b5">[6]</ref> drops from 93.16 to 41.69.</p><p>Our contributions are summarized as follows. (i) We propose AdvGLUE, a principled and comprehensive benchmark that focuses on robustness evaluation of language models. (ii) During the data construction, we provide a thorough analysis and a fair comparison of existing strong adversarial attack algorithms. (iii) We present thorough robustness evaluation for existing state-of-the-art language models and defense methods. We hope that AdvGLUE will inspire active research and discussion in the community. More details are available at https://adversarialglue.github.io.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Existing robustness evaluation work can be roughly divided into two categories: Evaluation Toolkits and Benchmark Datasets. (i) Evaluation toolkits, including OpenAttack <ref type="bibr" target="#b57">[58]</ref>, TextAttack <ref type="bibr" target="#b34">[35]</ref>, TextFlint <ref type="bibr" target="#b16">[17]</ref> and Robustness Gym <ref type="bibr" target="#b14">[15]</ref>, integrate various ad hoc input transformations for different tasks and provide programmable APIs to dynamically test model performance. However, it is challenging to guarantee the quality of these input transformations. For example, as reported in <ref type="bibr" target="#b56">[57]</ref>, the validity of adversarial transformation can be as low as 65.5%, which means that more than one third of the adversarial sentences have wrong labels. Such a high percentage of annotation errors could lead to an underestimate of model robustness, making it less qualified to serve as an accurate and reliable benchmark <ref type="bibr" target="#b1">[2]</ref>. (ii) Benchmark datasets for robustness evaluation create challenging testing cases by using human-crafted templates or rules <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b35">36]</ref>, or adopting a human-and-modelin-the-loop manner to write adversarial examples <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b0">1]</ref>. While the quality and validity of these adversarial datasets can be well controlled, the scalability and comprehensiveness are limited by the human annotators. For example, template-based methods require linguistic experts to carefully construct reasonable rules for specific tasks, and such templates can be barely transferable to other tasks. Moreover, human annotators tend to complete the writing tasks through minimal efforts and shortcuts <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b46">47]</ref>, which can limit the coverage of various linguistic phenomena.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset Construction</head><p>In this section, we provide an overview of our evaluation tasks, as well as the pipeline of how we construct the benchmark data. During this data construction process, we also compare the effectiveness of different adversarial attack methods, and present several interesting findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>Tasks. We consider the following five most representative and challenging tasks used in GLUE <ref type="bibr" target="#b48">[49]</ref>: Sentiment Analysis (SST-2), Duplicate Question Detection (QQP), and Natural Language Inference (NLI, including MNLI, RTE, QNLI). The detailed explanation for each task can be found in Appendix A.3. Some tasks in GLUE are not included in AdvGLUE, since there are either no well-defined automatic adversarial attacks (e.g., CoLA), or insufficient data (e.g., WNLI) for the attacks.  <ref type="table">Table 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Adversarial Perturbations</head><p>In this section, we detail how we optimize different levels of adversarial perturbations to the benign source samples and collect the raw adversarial data with noisy labels, which will then be carefully filtered by human annotators described in the next section. Specifically, we consider the dev sets of GLUE benchmark as our source samples, upon which we perform different adversarial attacks. For relatively large-scale tasks (QQP, QNLI, MNLI-m/mm), we sample 1,000 cases from the dev sets for efficiency purpose. For the remaining tasks, we consider the whole dev sets as source samples.</p><p>... </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GLUE Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Word-level Perturbation</head><p>Existing word-level adversarial attacks perturb the words through different strategies, such as perturbing words with their synonyms <ref type="bibr" target="#b23">[24]</ref> or carefully crafted typo words <ref type="bibr" target="#b26">[27]</ref> (e.g., "foolish" to "fo01ish"), such that the perturbation does not change the semantic meaning of the sentences but dramatically change the models' output. To examine the model robustness against different perturbation strategies, we select one representative adversarial attack method for each strategy as follows.</p><p>Typo-based Perturbation. We select TextBugger <ref type="bibr" target="#b26">[27]</ref> as the representative algorithm for generating typo-based adversarial examples. When performing the attack, TextBugger first identifies the important words and then replaces them with typos.</p><p>Embedding-similarity-based Perturbation. We choose TextFooler <ref type="bibr" target="#b23">[24]</ref> as the representative adversarial attack that considers embedding similarity as a constraint to generate semantically consistent adversarial examples. Essentially, TextFooler first performs word importance ranking, and then substitutes those important ones to their synonyms extracted according to the cosine similarity of word embeddings.</p><p>Context-aware Perturbation. We use BERT-ATTACK <ref type="bibr" target="#b28">[29]</ref> to generate context-aware perturbations. The fundamental difference between BERT-ATTACK and TextFooler lies on the word replacement procedure. Specifically, BERT-ATTACK uses the pre-trained BERT to perform masked language prediction to generate contextualized potential word replacements for those crucial words.</p><p>Knowledge-guided Perturbation. We consider SememePSO <ref type="bibr" target="#b56">[57]</ref> as an example to generate adversarial examples guided by the HowNet <ref type="bibr" target="#b40">[41]</ref> knowledge base. SememePSO first finds out substitutions for each word in HowNet based on sememes, and then searches for the optimal combination based on particle swarm optimization.</p><p>Compositions of different Perturbations. We also implement a whitebox-based adversarial attack algorithm called CompAttack that integrates the aforementioned perturbations in one algorithm to evaluate model robustness to various adversarial transformations. Moreover, we efficiently search for perturbations via optimization so that CompAttack can achieve the attack goal while perturbing the minimal number of words. The implementation details can be found in Appendix A.4.</p><p>We note that the above adversarial attacks require a surrogate model to search for the optimal perturbations. In our experiments, we follow the setup of ANLI <ref type="bibr" target="#b37">[38]</ref> and generate adversarial examples against three different types of models (BERT, RoBERTa, and RoBERTa ensemble) trained on the GLUE benchmark. We then perform one round of filtering to retain those examples with high adversarial transferability between these surrogate models. We discuss more implementation details and hyper-parameters of each attack method in Appendix A.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Sentence-level Perturbation</head><p>Different from word-level attacks that perturb specific words, sentence-level attacks mainly focus on the syntactic and logical structures of sentences. Most of them achieve the attack goal by either paraphrasing the sentence, manipulating the syntactic structures, or inserting some unrelated sentences to distract the model attention. AdvGLUE considers the following representative perturbations. Question: What was the population of the Dutch Republic before this emigration? https://t.co/DlI9kw</p><p>False ? True Sentence: This was a huge influx as the entire population of the Dutch Republic amounted to ca.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CheckList (Human-crafted)</head><p>Question: What is Tony's profession?</p><p>True ? False Sentence: Both Tony and Marilyn were executives, but there was a change in Marilyn, who is now an assistant.</p><p>Syntactic-based Perturbation. We incorporate three adversarial attack strategies that manipulate the sentence based on the syntactic structures. (i) Syntax Tree Transformations. SCPN <ref type="bibr" target="#b19">[20]</ref> is trained to produce a paraphrase of a given sentence with specified syntactic structures. Following the default setting, we select the most frequent 10 templates from ParaNMT-50M corpus <ref type="bibr" target="#b51">[52]</ref> to guide the generation process. An LSTM-based encoder-decoder model (SCPN) is used to generate parses of target sentences according to the templates. These parses are further fed into another SCPN to generate full sentences. We use the pre-trained SCPNs released by the official codebase. (ii) Context Vector Transformations. T3 <ref type="bibr" target="#b49">[50]</ref> is a whitebox attack algorithm that can add perturbations on different levels of the syntax tree and generate the adversarial sentence. In our setting, we add perturbations to the context vector of the root node given syntax tree, which is iteratively optimized to construct the adversarial sentence. (iii) Entailment Preserving Transformations. We follow the entailment preserving rules proposed by AdvFever <ref type="bibr" target="#b44">[45]</ref>, and transform all the sentences satisfying the templates into semantically equivalent ones. More details can be found in Appendix A.4.</p><p>Distraction-based Perturbation. We integrate two attack strategies: (i) StressTest <ref type="bibr" target="#b35">[36]</ref> appends three true statements ("and true is true", "and false is not true", "and true is true" for five times) to the end of the hypothesis sentence for NLI tasks. (ii) CheckList <ref type="bibr" target="#b42">[43]</ref> adds randomly generated URLs and handles to distract model attention. Since the aforementioned distraction-based perturbations may impact the linguistic acceptability and the understanding of semantic equivalence, we mainly apply these rules to part of the GLUE tasks, including SST-2 and NLI tasks (MNLI, RTE, QNLI), to evaluate whether model can be easily misled by the strong negation words or such lexical similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Human-crafted Examples</head><p>To ensure our benchmark covers more linguistic phenomena in addition to those provided by automatic attack algorithms, we integrate the following high-quality human-crafted adversarial data from crowdsourcing or expert-annotated templates and transform them to the formats of GLUE tasks.</p><p>CheckList 2 <ref type="bibr" target="#b42">[43]</ref> is a testing method designed for analysing different capabilities of NLP models using different test types. For each task, CheckList first identifies necessary natural language capabilities a model should have, then designs several test templates to generate test cases at scale. We follow the instructions and collect testing cases for three tasks: SST-2, QQP and QNLI. For each task, we adopt two capability tests: Temporal and Negation, which test if the model understands the order of events and if the model is sensitive to negations.</p><p>StressTest 2 <ref type="bibr" target="#b35">[36]</ref> proposes carefully crafted rules to construct "stress tests" and evaluate robustness of NLI models to specific linguistic phenomena. We adopt the test cases focusing on Numerical Reasoning into our adversarial MNLI dataset. These premise-hypothesis pairs are able to test whether the model can perform reasoning involving numbers and quantifiers and predict the correct relation between premise and hypothesis.</p><p>ANLI <ref type="bibr" target="#b37">[38]</ref> is a large-scale NLI dataset collected iteratively in a human-in-the-loop manner. In each iteration, human annotators are asked to design sentences to fool current model. Then the model is further finetuned on a larger dataset incorporating these sentences, which leads to a stronger model. Finally, annotators are asked to write harder examples to detect the weakness of this stronger model. In the end, the sentence pairs generated in each round form a comprehensive dataset that aims at examining the vulnerability of NLI models. We adopt ANLI into our adversarial MNLI dataset. We obtain the permission from the ANLI authors to include the ANLI dataset as part of our leaderboard.</p><p>AdvSQuAD <ref type="bibr" target="#b20">[21]</ref> is an adversarial dataset targeting at reading comprehension systems. Adversarial examples are generated by appending a distracting sentence to the end of the input paragraph. The distracting sentences are carefully designed to have common words with questions and look like a correct answer to the question. We mainly consider the examples generated by ADDSENT and ADDONESENT strategies, and adopt the distracting sentences and questions in the QNLI format with labels "not answered". The use of AdvSQuAD in AdvGLUE is authorized by the authors.</p><p>We present sampled AdvGLUE examples with the word-level, sentence-level perturbations and human-crafted samples in <ref type="table" target="#tab_2">Table 2</ref>. More examples are provided in Appendix A.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data Curation</head><p>After collecting the raw adversarial dataset, additional rounds of filtering are required to guarantee its quality and validity. We consider two types of filtering: automatic filtering and human evaluation.</p><p>Automatic Filtering mainly evaluates the generated adversarial examples along two fronts: transferability and fidelity. Human Evaluation validates whether the adversarial examples preserve the original labels and whether the labels are highly agreed among annotators. Concretely, we recruit annotators from Amazon Mechanical Turk. To make sure the annotators fully understand the GLUE tasks, each worker is required to pass a training step to be qualified to work on the main filtering tasks for the generated adversarial examples. We tune the pay rate for different tasks, as shown in <ref type="table" target="#tab_0">Appendix Table  11</ref>. The pay rate of the main filtering phase is twice as much as that of the training phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1.</head><p>Human Training Phase is designed to ensure that the annotators understand the tasks. The annotation instructions for each task follows <ref type="bibr" target="#b36">[37]</ref>, and we provide at least two examples for each class to help annotators understand the tasks. <ref type="bibr" target="#b2">3</ref> Each annotator is required to work on a batch of 20 examples randomly sampled from the GLUE dev set. After annotators answer each example, a ground-truth answer will be provided to help them understand whether the answer is correct. Workers who get at least 85% of the examples correct during training are qualified to work on the main filtering task. A total of 100 crowd workers participated in each task, and the number of qualified workers are shown in Appendix <ref type="table" target="#tab_0">Table 11</ref>. We also test the human accuracy of qualified annotators for each task on 100 randomly sampled examples from the dev set excluding the training samples. The details and results can be found in Appendix <ref type="table" target="#tab_0">Table 11</ref>. <ref type="table">Table 3</ref>: Statistics of data curation. We report Attack Success Rate (ASR) and ASR after data curation (Curated ASR) to evaluate the effectiveness of different adversarial attacks. We present the Filter Rate of data curation and inter-annotator agreement rate (Fleiss Kappa) before and after curation to evaluate the validity of adversarial examples. Human Accuracy on our curated dataset is evaluated by taking one random annotator's annotation as prediction and the majority voted label as ground truth. SPSO: SememePSO, TF: TextFooler, TB:TextBugger, CA: CompAttack, BA:BERT-ATTACK. ?/?: higher/lower the better. 2. Human Filtering Phase verifies the quality of the generated adversarial examples and only maintains high-quality ones to construct the benchmark dataset. Specifically, annotators are required to work on a batch of 10 adversarial examples generated from the same attack method. Every adversarial example will be validated by 5 different annotators. Examples are selected following two criteria: (i) high consensus: each example must have at least 4-vote consensus; (ii) utility preserving: the majority-voted label must be the same as the original one to make sure the attacks are valid (i.e., cannot fool human) and preserve the semantic content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tasks Metrics</head><p>The data curation results including inter-annotator agreement rate (Fleiss Kappa) and human accuracy on the curated dataset are shown in <ref type="table">Table 3</ref>. We will provide more analysis in the next section. Note that even after the data curation step, some grammatical errors and typos can still remain, as some adversarial attacks intentionally inject typos (e.g., TextBugger) or manipulate syntactic trees (e.g., SCPN) which are very stealthy. We will retain these samples as their labels receive high consensus from annotators, which means the typos do not substantially impact humans' understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Benchmark of Adversarial Attack Algorithms</head><p>Our data curation phase also serves as a comprehensive benchmark over existing adversarial attack methods, as it provides a fair standard for all adversarial attacks and systematic human annotations to evaluate the quality of the generated samples. Evaluation Metrics. Specifically, we evaluate these attacks along two fronts: effectiveness and validity. For effectiveness, we consider two evaluation metrics: Attack Success Rate (ASR) and Curated Attack Success Rate (Curated ASR). Formally, given a benign dataset</p><formula xml:id="formula_0">D = {(x (i) , y (i) )} N i=1</formula><p>consisting of N pairs of sample x (i) and ground truth y (i) , for an adversarial attack method A that generates an adversarial example A(x) given an input x to attack a surrogate model f , ASR is calculated as</p><formula xml:id="formula_1">ASR = (x,y)?D 1[f (A(x)) = y] 1[f (x) = y] ,<label>(1)</label></formula><p>where 1 is the indicator function. After the data curation phase, we collect a curated adversarial dataset D c . Thus, Curated ASR is calculated as</p><formula xml:id="formula_2">Curated ASR = (x,y)?D 1[f (A(x)) = y] ? 1[A(x) ? Dc] 1[f (x) = y] .<label>(2)</label></formula><p>For validity, we consider three evaluation metrics: Filter Rate, Fleiss Kappa, and Human Accuracy. Specifically, Filter Rate is calculated by 1? Curated ASR ASR to measure how many examples are rejected in the data curation procedures and can reflect the noisiness of the generated adversarial examples. We report the average ASR, Curated ASR, and Filter Rate over the three surrogate models we consider in <ref type="table">Table 3</ref>. Fleiss Kappa is a widely used metric in existing datasets (e.g., SNLI, ANLI, and FEVER <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b45">46]</ref>) to measure the inter-annotator agreement rate on the collected dataset. Fleiss Kappa between 0.4 and 0.6 is considered as moderate agreement and between 0.6 and 0.8 as substantial agreement. The inter-annotator agreement rates of most high-quality datasets fall into these two intervals. In this paper, we follow the standard protocol and report Fleiss Kappa and Curated Fleiss Kappa to analyze the inter-annotator agreement rate on the collected adversarial dataset before and after curation to reflect the ambiguity of generated examples. We also estimate the human performance on our curated datasets. Specifically, given a sample with 5 annotations, we take one random annotator's annotation as the prediction and the majority voted label as the ground truth and calculate the human accuracy as shown in <ref type="table">Table 3</ref>. <ref type="table">Table 3</ref>, in terms of attack effectiveness, while most attacks show high ASR, the Curated ASR is always less than 11%, which indicates that most existing adversarial attack algorithms are not effective enough to generate high-quality adversarial examples. In terms of validity, the filter rates for most adversarial attack methods are more than 85%, which suggests that existing strong adversarial attacks are prone to generating invalid adversarial examples that either change the original semantic meanings or generate ambiguous perturbations that hinder the annotators' unanimity. We provide detailed filter rates for automatic filtering and human evaluation in Appendix <ref type="table" target="#tab_0">Table 12</ref>, and the conclusion is that around 60 ? 80% of examples are filtered due to the low transferability <ref type="table">Table 5</ref>: Diagnostic report of state-of-the-art language models and robust training methods. For each attack method, we evaluate models against generated adversarial data for different tasks to obtain per-task accuracy scores, and report the macro-average of those scores. (C1=Embedding-similarity, C2=Typos, C3=Contextaware, C4=Knowledge-guided, C5=Compositions, C6=Syntactic-based Perturbations, C7=Distraction-based Perturbations, C8=CheckList, C9=StressTest, C10=ANLI and C11=AdvSQuAD).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis. As shown in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>Word We also note that the data curation procedures are indispensable for the adversarial evaluation, as the Fleiss Kappa before curation is very low, suggesting that a lot of adversarial sentences have unreliable labels and thus tend to underestimate the model robustness against the textual adversarial attacks. After the data curation, our AdvGLUE shows a Curated Fleiss Kappa of near 0.6, comparable with existing high-quality dataset such as SNLI and ANLI. Among all the existing attack methods, we observe that TextBugger is the most effective and valid attack method, as it demonstrates the highest Curated ASR and Curated Fleiss Kappa across different tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Finalizing the Dataset</head><p>The full pipeline of constructing AdvGLUE is summarized in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>Merging. We note that distraction-based adversarial examples and human-crafted adversarial examples are guaranteed to be valid by definition or crowd-sourcing annotations, and thus data curation is not needed on these attacks. When merging them with our curated set, we calculate the average number of samples per attack from our curated set, and sample the same amount of adversarial examples from these attacks following the same label distribution. This way, each attack contributes to similar amount of adversarial data, so that AdvGLUE can evaluate models against different types of attacks with similar weights and provide a comprehensive and unbiased diagnostic report.</p><p>Dev-Test Split. After collecting the adversarial examples from the considered attacks, we split the final dataset into a dev set and a test set. In particular, we first randomly split the benign data into 9 : 1, and the adversarial examples generated based on 90% of the benign data serve as the hidden test set, while the others are published as the dev set. For human-crafted adversarial examples, since they are not generated based on the benign GLUE data, we randomly select 90% of the data as the test set, and the remaining 10% as the dev set. The dev set is publicly released to help participants to understand the tasks and the data format. To protect the integrity of our test data, the test set will not be released to the public. Instead, participants are required to upload the model to CodaLab, which automates the evaluation process on the hidden test set and provides a diagnostic report.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Diagnostic Report for Language Models</head><p>Benchmark Results. We follow the official implementations and training scripts of pre-trained language models to reproduce results on GLUE and test these models on AdvGLUE. The training details can be found in Appendix A.6. Results are summarized in <ref type="table" target="#tab_4">Table 4</ref>. We observe that although state-of-the-art language models have achieved high performance on GLUE, they are vulnerable to various adversarial attacks. For instance, the performance gap can be as large as 55% on the SMART (BERT) model in terms of the average score. DeBERTa (Large) and ALBERT (XXLarge) achieve the highest average AdvGLUE scores among all the tested language models. This result is also aligned with the ANLI leaderboard <ref type="bibr" target="#b3">4</ref> , which shows that ALBERT (XXLarge) is the most robust to human-crafted adversarial NLI dataset <ref type="bibr" target="#b37">[38]</ref>.</p><p>We note that although our adversarial examples are generated from surrogate models based on BERT and RoBERTa, these examples have high transferability between models after our data curation. Specifically, the average score of ELECTRA (Large) on AdvGLUE is even lower than RoBERTa (Large), which demonstrates that AdvGLUE can effectively transfer across models of different architectures and unveil the vulnerabilities shared across multiple models. Moreover, we find some models even perform worse than random guess. For example, the performance of BERT on AdvGLUE for all tasks is lower than random-guess accuracy.</p><p>We also benchmark advanced robust training methods to evaluate whether these methods can indeed provide robustness improvement on AdvGLUE and to what extent. We observe that SMART and FreeLB are particularly helpful to improve robustness for RoBERTa. Specifically, SMART (RoBERTa) improves RoBERTa (Large) over 3.71% on average, and it even improves the benign accuracy as well. Since InfoBERT is not evaluated on GLUE, we run InfoBERT with different hyper-parameters and report the best accuracy on benign GLUE dev set and AdvGLUE test set. However, we find that the benign accuracy of InfoBERT (RoBERTa) is still lower than RoBERTa (Large), and similarly for the robust accuracy. These results suggest that existing robust training methods only have incremental robustness improvement, and there is still a long way to go to develop robust models to achieve satisfactory performance on AdvGLUE.</p><p>Diagnostic Report of Model Vulnerabilities. To have a systematic understanding of which adversarial attacks language models are vulnerable to, we provide a detailed diagnostic report in <ref type="table">Table 5</ref>. We observe that models are most vulnerable to human-crafted examples, where complex linguistic phenomena (e.g., numerical reasoning, negation and coreference resolution) can be found. For sentence-level perturbations, models are more vulnerable to distraction-based perturbations than directly manipulating syntactic structures. In terms of word-level perturbations, models are similarly vulnerable to different word replacement strategies, among which typo-based perturbations and knowledge-guided perturbations are the most effective attacks.</p><p>We hope the above findings can help researchers systematically examine their models against different adversarial attacks, thus also devising new methods to defend against them. Comprehensive analysis of the model robustness report is provided in our website and Appendix A.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We introduce AdvGLUE, a multi-task benchmark to evaluate and analyze the robustness of stateof-the-art language models and robust training methods. We systematically conduct 14 adversarial attacks on GLUE tasks and adopt crowd-sourcing to guarantee the quality and validity of generated adversarial examples. Modern language models perform poorly on AdvGLUE, suggesting that model vulnerabilities to adversarial attacks still remain unsolved. We hope AdvGLUE can serve as a comprehensive and reliable diagnostic benchmark for researchers to further develop robust models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Glossary of Adversarial Attacks</head><p>We present a glossary of adversarial attacks considered in AdvGLUE in <ref type="table" target="#tab_6">Table 6</ref> and 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Additional Related Work</head><p>We discuss more related work about textual adversarial attacks and defenses in this subsection.</p><p>Textual Adversarial Attacks Recent research has shown deep neural networks (DNNs) are vulnerable to adversarial examples that are carefully crafted to fool machine learning models without disturbing human perception <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b32">33]</ref>. However, compared with a large amount of adversarial attacks in continuous data domain <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b10">11]</ref>, there are a few studies focusing on the discrete text domain. Most existing gradient-based attacks on image or audio models are no longer applicable to NLP models, as words are intrinsically discrete tokens. Another challenge for generating adversarial text is to ensure the semantic and syntactic coherence and consistency.</p><p>Existing textual adversarial attacks can be roughly divided into three categories: word-level transformations, sentence-level attacks, and human-crafted samples. (i) Word-level transformations adopt different word replacement strategies during attack. For example, existing work <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b9">10]</ref> applies character-level perturbation to carefully crafted typo words (e.g., from "foolish" to "fo0lish"), thus making the model ignore or misunderstand the original statistical cues. Others adopt knowledgebased perturbation and utialize knowledge base to constrain the search space. For example, Zang et al. <ref type="bibr" target="#b56">[57]</ref> uses sememe-based knowledge base from HowNet <ref type="bibr" target="#b40">[41]</ref> to construct a search space for word substitution. Some <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b26">27]</ref> use non-contextualized word embedding from GLoVe <ref type="bibr" target="#b39">[40]</ref> or Word2Vec <ref type="bibr" target="#b31">[32]</ref> to build synonym candidates, by querying the cosine similarity or euclidean distance between the original and candidate word and selecting the closet ones as the replacements. Recent work <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b28">29]</ref> also leverages BERT to generate contextualized perturbations by masked language modeling. (ii) Different from the dominant word-level adversarial attacks, sentence-level adversarial attacks perform sentence-level transformation or paraphrasing by perturbing the syntactic structures based on human crafted rules <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b42">43]</ref> or carefully designed auto-encoders <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b49">50]</ref>. Sentence-level manipulations are generally more challenging than word-level attacks, because the perturbation space for syntactic structures are limited compared to word-level perturbation spaces that grow exponentially with the sentence length. However, sentence-level attacks tend to have higher linguistic quality than word-level, as both semantic and syntactic coherence are taken into considerations when generating adversarial sentences. (iii) Human-crafted adversarial examples are generally crafted in the human-in-the-loop manner <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b0">1]</ref> or use manually crafted templates to generate test cases <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b42">43]</ref>. Our AdvGLUE incorporates all of the above textual adversarial to provide a comprehensive and systematic diagnostic report over existing state-of-the-art large-scale language models.</p><p>Defenses against Textual Adversarial Attacks To defend against textual adversarial attacks, existing work can be classified into three categories: (i) Adversarial Training is a practical method to defend against adversarial examples. Existing work either uses PGD-based attacks to generate adversarial examples in the embedding space of NLP as data augmentation <ref type="bibr" target="#b60">[61]</ref>, or regularizes the standard objective using virtual adversarial training <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b11">12]</ref>. However, one drawback is that the threat model is often unknown, which renders adversarial training less effective when facing unseen attacks. (ii) Interval Bound Propagation (IBP) <ref type="bibr" target="#b8">[9]</ref> is proposed as a new technique to consider the worst-case perturbation theoretically. Recent work <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b21">22]</ref> has applied IBP in the NLP domain to certify the robustness of models. However, IBP-based methods rely on strong assumptions of model architecture and are difficult to adapt to recent transformer-based language models. (iii) Randomized Smoothing <ref type="bibr" target="#b6">[7]</ref> provides a tight robustness guarantee in 2 norm by smoothing the classifier with Gaussian noise. Ye et al. <ref type="bibr" target="#b55">[56]</ref> adapts the idea to the NLP domain, and replace the Gaussian noise with synonym words to certify the robustness as long as adversarial word substitution falls into predefined synonym sets. However, to guarantee the completeness of the synonym set is challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Task Descriptions, Statistics and Evaluation Metrics</head><p>We present the detailed label distribution statistics and evaluation metrics of GLUE and AdvGLUE benchmark in 8. StressTest appends three true statements ("and true is true", "and false is not true", "and true is true" for five times) to the end of the hypothesis sentence for NLI tasks.  StressTest proposes carefully crafted rules to construct "stress tests" and evaluate robustness of NLI models to specific linguistic phenomena.</p><p>Here we adopt the test cases focusing on Numerical Reasoning.</p><p>Task: MNLI Premise: If Anne' s speed were doubled, they could clean their house in 3 hours working at their respective rates.</p><p>Hypothesis: If Anne' s speed were doubled, they could clean their house in less than 6 hours working at their respective rates. Prediction: Entailment ? Contradiction</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ANLI (Humancrafted)</head><p>ANLI is a large-scale NLI dataset collected iteratively in a human-in-the-loop manner. The sentence pairs generated in each round form a comprehensive dataset that aims at examining the vulnerability of NLI models. AdvSQuAD is an adversarial dataset targeting at reading comprehension systems. Examples are generated by appending a distracting sentence to the end of the input paragraph. We adopt the distracting sentences and questions in the QNLI format with labels "not answered". </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SST-2</head><p>The Stanford Sentiment Treebank <ref type="bibr" target="#b43">[44]</ref> consists of sentences from movie reviews and human annotations of their sentiment. Given a review sentence, the task is to predict the sentiment of it. Sentiments can be divided into two classes: positive and negative.</p><p>QQP The Quora Question Pairs (QQP) dataset is a collection of question pairs from the community question-answering website Quora. The task is to determine whether a pair of questions are semantically equivalent.</p><p>MNLI The Multi-Genre Natural Language Inference Corpus <ref type="bibr" target="#b52">[53]</ref> consists of sentence pairs with textual entailment annotations. Given a premise sentence and a hypothesis sentence, the task is to predict whether the premise entails the hypothesis (entailment), contradicts the hypothesis (contradiction), or neither (neutral)</p><p>QNLI Question-answering NLI (QNLI) dataset consists of question-sentence pairs modified from The Stanford Question Answering Dataset <ref type="bibr" target="#b41">[42]</ref>. The task is to determine whether the context sentence contains the answer to the question.</p><p>RTE The Recognizing Textual Entailment (RTE) dataset is a combination of a series of data from annual textual entailment challenges. Examples are constructed based on news and Wikipedia text. The task is to predict the relationship between a pair of sentences. For consistency, the relationship can be classified into two classes: entailment and not entailment, where neutral and contradiction are seen as not entailment.</p><p>We also show the detailed per-task model performance on AdvGLUE and GLUE in <ref type="table" target="#tab_12">Table 9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Implementation Details of Adversarial Attacks</head><p>TextBugger To ensure the small magnitude of the perturbation, we consider the following five strategies: (i) randomly inserting a space into a word; (ii) randomly deleting a character of a word; (iii) randomly replacing a character of a word with its adjacent character in the keyboard; (iv) randomly replacing a character of a word with its visually similar counterpart (e.g., "0" v.s. "o", "1" <ref type="table">Table 8</ref>: The label distribution of AdvGLUE dataset. For SST-2, we report the label distribution as "negative":"positive". For QQP, we report the label distribution as "not equivalent":"equivalent". For QNLI, we report the label distribution as "true":"false". For RTE, we report the label distribution as "entailment":"not entailment". For MNLI, we report the label distribution as "entailment":"neutral":"contradiction".  v.s. "l"); and (v) randomly swapping two characters in a word. The first four strategies guarantee the word edit distance between the typo word and its original word to be 1, and that of the last strategy is limited to 2. Following the default setting, in Strategy (i), we only insert a space into a word when the word contains less than 6 characters. In Strategy (v), we swap characters in a word only when the word has more than 4 characters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus</head><p>TextFooler Concretely, for the sentiment analysis tasks, we set the cosine similarity threshold to be 0.8, which encourages the synonyms to be semantically close to original ones and enhances the quality of adversarial data. For the rest of the tasks, we follow the default hyper-parameter to set the cosine similarity threshold to be 0.7. Besides, the number of synonyms for each word is set to 50 following the default setting.</p><p>BERT-ATTACK We follow the hyper-parameters from the official codebase, and set the number of candidate words to 48 and cosine similarity threshold to 0.4 in order to filter out antonyms using synonym dictionaries, as BERT masked language model does not distinguish synonyms and antonyms.</p><p>SememePSO We adopt the official hyper-parameters in which maximum and minimum inertia weights are set to 0.8 and 0.2, respectively. We also set the maximum and minimum movement probabilities of the particles to 0.8 and 0.2, respectively, following the default setting. Population size is set to 60 in every task.</p><p>CompAttack We follow the T3 <ref type="bibr" target="#b49">[50]</ref> and C&amp;W attack <ref type="bibr" target="#b4">[5]</ref> and design the same optimization objective for adversarial perturbation generation in the embedding space as:</p><formula xml:id="formula_3">L(e * ) = ||e * ||p + c ? g(x ),<label>(3)</label></formula><p>where the first term controls the magnitude of perturbation, while g(?) is the attack objective function depending on the attack scenario. c weighs the attack goal against attack cost. CompAttack constrains the perturbation to be close to pre-defined perturbation space, including typo space (e.g., TextBugger), knowledge space (e.g., WordNet) and contextualized embedding space (e.g., BERT embedding clusters) to make sure the perturbation is valid. We can also see from <ref type="table">Table 3</ref> that CompAttack overall has lower filter rate than other state-of-the-art attack methods.</p><p>SCPN We use the pre-trained SCPN models released by the official codebase. Following the default setting, we select the most frequent 10 templates from ParaNMT-50M corpus <ref type="bibr" target="#b51">[52]</ref> to guide the generation process. We first parse sentences from GLUE dev set using Stanford CoreNLP. We used CoreNLP version 3.7.0 in our experiment, along with the Shift-Reduce Parser models. T3 We follow the hyper-parameters in the official setting where the scaling const is set to 1e4 and the optimizing confidence is set to 0. In each iteration, we optimize the perturbation vector for at most 100 steps with learning rate 0.1.</p><p>AdvFever We follow the entailment preserving rules proposed by the official implementation. We adopt all 23 templates to transform original sentences into semantically equivalent ones. Many common sentence patterns in everyday life are included in these templates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Examples of AdvGLUE benchmark</head><p>We show more comprehensive examples in <ref type="table" target="#tab_0">Table 10</ref>. Examples are generated with different levels of perturbations and they all can successfully change the predictions of all surrogate models (BERT, RoBERTa and RoBERTa ensemble).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 Fine-tuning Details of Large-Scale Language Models</head><p>For all the experiments, we are using a GPU cluster with 8 V100 GPUs and 256GB memory. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ELECTRA (Large)</head><p>We follow the official hyper-parameter setting to set the learning rate to 5e ? 5 and set batch size to 32. We train ELECTRA on RTE for 10 epochs and train for 2 epochs on other tasks. We set the weight decay rate to 0.01 for every task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RoBERTa (Large)</head><p>We train our RoBERTa for 10 epochs with learning rate 2e ? 5 on each task. The batch size for QNLI is 32 and 64 for other tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T5 (Large)</head><p>We train our T5 for 10 epochs with learning rate 2e ? 5 on each task. The batch size for QNLI is 32 and 64 for other tasks. We follow the templates in original paper to convert GLUE tasks into generation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ALBERT (XXLarge)</head><p>We use the default hyper-parameters to train our ALBERT. For example, max training steps for SST-2, MNLI, QNLI, QQP, RTE, is 20935, 10000, 33112, 14000, 800 respectively. For MNLI and QQP, batch size is set to 32 and for other tasks batch size is set to 128.</p><p>DeBERTa (Large) We use the official hyper-parameters to train our DeBERTa. For example, learning rate is set to 1e ? 5 across all tasks. For MNLI and QQP, batch size is set to 64 and for other tasks batch size is set to 32.</p><p>SMART For SMART(BERT) and SMART(RoBERTa), we use grid search to search for the best parameters and report the best performance among all trained models.</p><p>FreeLB (RoBERTa) For FreeLB, we test every parameter combination provided by the official codebase and select the best parameters for our training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>InfoBERT (RoBERTa)</head><p>We set the batch size to 32 and learning rate to 2e ? 5 for all tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.7 Human Evaluation Details</head><p>Human Training We present the pay rate and the number of qualified workers in <ref type="table" target="#tab_0">Table 11</ref>. We also test our qualified workers on another non-overlapping 100 samples of the GLUE dev sets for each task. We can see that the human accuracy is comparable to <ref type="bibr" target="#b36">[37]</ref>, which means that most our selected annotators understand the GLUE tasks well.</p><p>Human Filtering The detailed filtering statistics of each stage is shown in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human Annotation Instructions</head><p>We show examples of annotation instructions in the training phase and filtering phase on MNLI in <ref type="figure" target="#fig_2">Figure 2</ref> and 3. More instructions can be found in https://adversarialglue.github.io/instructions. We also provide a </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.8 Discussion of Limitations</head><p>Due to the constraints of computational resources, we are unable to conduct a comprehensive evaluation of all existing language models. However, with the release of our leaderboard website, we are expecting researchers to actively submit their models and evaluate against our AdvGLUE benchmark to have a systematic understanding of model robustness. We are also interested in the adversarial robustness of large-scale auto-regressive language models under the few-shot settings, and leave it as a compelling future work.</p><p>In this paper, we follow ANLI <ref type="bibr" target="#b37">[38]</ref> and generate adversarial examples against surrogate models based on BERT and RoBERTa. However, there are concerns <ref type="bibr" target="#b1">[2]</ref> that such adversarial filtering may not be able to fairly benchmark the model robustness, as participants may top the leaderboard by producing different errors from our surrogate models. We note that such concerns can be solved given systematic data curation. As shown in our main benchmark results, we observe we successfully select the adversarial examples with high adversarial transferability that can unveil the vulnerabilities shared across models of different architectures. Specifically, we observe a huge performance gap in ELECTRA (Large) that is pre-trained with different data and shown less robust than one of surrogate model RoBERTa (Large).</p><p>Finally, we emphasize that our AdvGLUE benchmark mainly focuses on robustness evaluation. Thus AdvGLUE can also be considered as a supplementary diagnostic test set besides the standard GLUE benchmark. We suggest that participants should evaluate their models against both GLUE benchmark and our AdvGLUE to understand both model generalization and robustness. We hope our work can help researchers to develop models with high generalization and adversarial robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.9 Website</head><p>We present the diagnostic report on our website in <ref type="figure" target="#fig_3">Figure 4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Data Sheet</head><p>We follow the documentation frameworks provided by Gebru et al. <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Motivation</head><p>For what purpose was the dataset created? While recently a lot of methods (SMART, FreeLB, InfoBERT, ALUM) claim that they can improve the model robustness against adversarial attacks, the adversary setup in these methods (i) lacks a unified standard and is usually different across different methods; (ii) fails to cover comprehensive linguistic transformation (typos, synonymous substitution, paraphrasing, etc) to recognize to which levels of adversarial attacks models are still vulnerable. This motivates us to build a unified and principled robustness benchmark dataset and evaluate to which extent the state-of-the-art models have progressed so far in terms of adversarial robustness.</p><p>Who created the dataset (e.g., which team, research group) and on behalf of which entity (e.g., company, institution, organization)? University of Illinois at Urbana-Champaign (UIUC) and Microsoft Corporation.</p><p>B.2 Composition/collection process/preprocessing/cleaning/labeling and uses:</p><p>The answers are described in our paper as well as website https://adversarialglue.github. io. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Overview of the AdvGLUE dataset construction pipeline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 . 2 .</head><label>12</label><figDesc>Transferability evaluates whether the adversarial examples generated against one source model (e.g., BERT) can successfully transfer and attack the other two (e.g., RoBERTa and RoBERTa ensemble), given the surrogate models used to generate adversarial examples (BERT, RoBERTa and RoBERTa ensemble). Only adversarial examples that can successfully transfer to the other two models will be kept for the next round of fidelity filtering, so that the selected examples can exploit the biases shared across different models and unveil their fundamental weakness. Fidelity evaluates how the generated adversarial examples maintain the original semantics. For word-level adversarial examples, we use word modification rate to measure what percentage of words are perturbed. Concretely, word-level adversarial examples with word modification rate larger than 15% are filtered out. For sentence-level adversarial examples, we use BERTScore [59] to evaluate the semantic similarity between the adversarial sentences and their corresponding original ones. For each sentence-level attack, adversarial examples with the highest similarity scores are kept to guarantee their semantic closeness to the benign samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Human annotation instructions (training phase) for MNLI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>An example of model diagnostic report for BERT (Large).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of AdvGLUE benchmark. We apply all word-level perturbations (C1=Embeddingsimilarity, C2=Typos, C3=Context-aware, C4=Knowledge-guided, and C5=Compositions) to the five GLUE tasks. For sentence-level perturbations, we apply Syntactic-based perturbations (C6) to the five GLUE tasks. Distraction-based perturbations (C7) are applied to four GLUE tasks without QQP, as they may affect the semantic similarity. For human-crafted examples, we apply CheckList (C8) to SST-2, QQP, and QNLI; StressTest (C9) and ANLI (C10) to MNLI; and AdvSQuAD (C11) to QNLI tasks.</figDesc><table><row><cell>Corpus</cell><cell>Task</cell><cell cols="4">|Train| (GLUE) (AdvGLUE) C1 C2 C3 C4 C5 C6 |Test| Word-Level Sent.-Level C7</cell><cell cols="4">Human-Crafted C8 C9 C10 C11</cell></row><row><cell>SST-2</cell><cell cols="2">sentiment 67,349</cell><cell>1,420</cell><cell cols="4">204 197 91 175 64 211 320 158 0</cell><cell>0</cell><cell>0</cell></row><row><cell>QQP</cell><cell cols="2">paraphrase 363,846</cell><cell>422</cell><cell>42 151 17 35 75 37</cell><cell>0</cell><cell>65</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>QNLI</cell><cell cols="2">NLI/QA 104,743</cell><cell>968</cell><cell cols="2">73 139 71 98 72 159 219</cell><cell>80</cell><cell>0</cell><cell>0</cell><cell>57</cell></row><row><cell>RTE</cell><cell>NLI</cell><cell>2,490</cell><cell>304</cell><cell>43 44 31 27 23 48</cell><cell>88</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>MNLI</cell><cell>NLI</cell><cell>392,702</cell><cell>1,864</cell><cell cols="2">69 402 114 161 128 217 386</cell><cell cols="4">0 194 193 0</cell></row><row><cell cols="3">Sum of AdvGLUE test set</cell><cell>4,978</cell><cell cols="6">431 933 324 496 362 672 1013 303 194 193 57</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Examples of AdvGLUE benchmark. We show 3 examples from QNLI task. These examples are generated with three levels of perturbations and they all can successfully change the predictions of all surrogate models (BERT, RoBERTa and RoBERTa ensemble).</figDesc><table><row><cell>Linguistic</cell><cell>Samples (Strikethrough = Original Text, red = Adversarial Perturbation)</cell><cell>Label ?</cell></row><row><cell>Phenomenon</cell><cell></cell><cell>Prediction</cell></row><row><cell></cell><cell>Question: What was the population of the Dutch Republic before this</cell><cell></cell></row><row><cell>Typo (Word-level)</cell><cell>emigration? Sentence: This was a huge hu ge influx as the entire population of the</cell><cell>False ? True</cell></row><row><cell></cell><cell>Dutch Republic amounted to ca.</cell><cell></cell></row><row><cell>Distraction</cell><cell></cell><cell></cell></row><row><cell>(Sent.-level)</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Model performance on AdvGLUE test set. BERT (Large) and RoBERTa (Large) are fine-tuned using different random seeds and thus different from the surrogate models used for adversarial text generation. For MNLI, we report the test accuracy on the matched and mismatched test sets; for QQP, we report accuracy and F1; and for other tasks, we report the accuracy. All values are reported by percentage (%). We also report the macro-average (Avg) of per-task scores for different models. (Complete results are listed in our leaderboard.)State-of-the-art Pre-trained Language Models BERT (Large) 33.03 28.72/27.05 40.46 39.77 37.91/16.56 33.68 85.76 52.08 ELECTRA (Large) 58.59 14.62/20.22 23.03 57.54 61.37/42.40 41.69 93.16 51.47 RoBERTa (Large) 58.52 50.78/39.62 45.39 52.48 57.11/41.80 50.21 91.44 41.23 T5 (Large) 60.56 48.43/38.98 62.83 57.64 63.03/55.68 56.82 90.39 33.57 ALBERT (XXLarge) 66.83 51.83/44.17 73.03 63.84 56.40/32.35 59.22 91.87 32.65 DeBERTa (Large) 57.89 58.36/52.46 78.95 57.85 60.43/47.98 60.86 92.67 31.81 Robust Training Methods for Pre-trained Language Models SMART (BERT) 25.21 26.89/23.32 38.16 34.61 36.49/20.24 30.29 85.70 55.41 SMART (RoBERTa) 50.92 45.56/36.07 70.39 52.17 64.22/44.28 53.71 92.62 38.91 FreeLB (RoBERTa) 61.69 31.59/27.60 62.17 62.29 42.18/31.07 50.47 92.28 41.81 InfoBERT (RoBERTa) 47.61 50.39/41.26 39.47 54.86 49.29/35.54 46.04 89.06 43.02</figDesc><table><row><cell>Model</cell><cell>SST-2 AdvGLUE</cell><cell>MNLI AdvGLUE</cell><cell>RTE AdvGLUE AdvGLUE QNLI</cell><cell>QQP AdvGLUE</cell><cell>Avg AdvGLUE GLUE Avg Avg ? ?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>31.96 45.18 45.86 33.85 44.86 24.16 16.33 23.20 13.47 10.53 ELECTRA (Large) 43.07 45.12 47.95 46.33 47.33 43.47 33.30 32.20 26.29 26.94 52.63 RoBERTa (Large) 56.54 57.19 60.47 49.81 55.92 50.49 41.89 37.78 28.35 16.58 35.09 T5 (Large) 60.04 67.94 64.60 59.84 58.50 50.54 42.20 69.02 23.20 17.10 52.63 ALBERT (XXLarge) 66.71 67.61 73.49 70.36 59.52 63.76 49.14 45.55 39.69 26.94 43.86 DeBERTa (Large) 65.07 74.87 68.02 65.30 62.54 57.41 47.22 45.08 52.06 22.80 54.39 SMART (BERT) 45.17 31.04 42.89 45.23 30.76 40.74 16.62 8.20 18.56 10.36 1.75 SMART (RoBERTa) 62.93 58.03 65.09 62.65 61.37 55.31 40.13 39.27 28.35 15.54 31.58 FreeLB (RoBERTa) 51.95 53.23 52.92 51.15 52.18 50.75 37.72 66.87 23.71 29.02 64.91 InfoBERT (RoBERTa) 55.47 55.78 59.02 51.33 55.48 44.56 31.49 34.31 42.27 14.51 43.86 and high word modification rate. Among the remaining samples, around 30 ? 40% examples are filtered due to the low human agreement rates (Human Consensus Filtering), and around 20 ? 30% are filtered due to the semantic changes which lead to the label changes (Utility Preserving Filtering).</figDesc><table><row><cell></cell><cell></cell><cell cols="4">-Level Perturbations</cell><cell cols="6">Sent.-Level Human-Crafted Examples</cell></row><row><cell></cell><cell>C1</cell><cell>C2</cell><cell>C3</cell><cell>C4</cell><cell>C5</cell><cell>C6</cell><cell>C7</cell><cell>C8</cell><cell>C9</cell><cell>C10</cell><cell>C11</cell></row><row><cell>BERT (Large)</cell><cell>42.02</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Glossary of adversarial attacks (word-level and sentence-level) in AdvGLUE. For each adversarial attack, we provide a brief explanation and a corresponding example in AdvGLUE.</figDesc><table><row><cell>Perturbations</cell><cell>Explanation</cell><cell>Examples (Strikethrough = Original Text, red = Adver-sarial Perturbation)</cell></row><row><cell></cell><cell></cell><cell>Task: QNLI</cell></row><row><cell>TextBugger (Word-level / Typo-based)</cell><cell>TextBugger first identifies the important words in each sentence and then replaces them with carefully crafted typos.</cell><cell>Question: What was the population of the Dutch Repub-lic before this emigration? Sentence: This was a huge hu ge influx as the entire population of the Dutch Republic amounted to ca.</cell></row><row><cell></cell><cell></cell><cell>Prediction: False ? True</cell></row><row><cell>TextFooler (Word-level / Embedding-similarity-based)</cell><cell>Embedding-similarity-based adversarial attacks such as TextFooler select synonyms according to the cosine similarity of word embeddings. Words that have high similarity scores will be used as candidates to replace original words in the sentences.</cell><cell>Task: QQP Question 1: I am getting fat on my lower body and on the chest torso, is there any way I can get fit without looking skinny fat? Question 2: Why I am getting skinny instead of losing body fat? Prediction: Not Equivalent ? Equivalent</cell></row><row><cell></cell><cell></cell><cell>Task: MNLI</cell></row><row><cell>BERT-ATTACK (Word-level / Context-aware)</cell><cell>BERT-ATTACK uses pre-trained BERT to perform masked language prediction to generate contextualized potential word replacements for those crucial words.</cell><cell>Premise: Do you know what this is? With a dramatic gesture she flung back the left side of her coat sleeve and exposed a small enamelled badge. Hypothesis: The coat that she wore was long enough to cover her knees .</cell></row><row><cell></cell><cell></cell><cell>Prediction: Neutral ? Contradiction</cell></row><row><cell></cell><cell></cell><cell>Task: QQP</cell></row><row><cell>SememePSO</cell><cell>Knowledge-guided adversarial attacks such as</cell><cell>Question 1: What people who you've never met have</cell></row><row><cell>(Word-level /</cell><cell>SememePSO use external knowledge base such</cell><cell>influenced infected your life the most?</cell></row><row><cell>Knowledge-</cell><cell>as HowNet or WordNet to search for</cell><cell>Question 2: Who are people you have never met who</cell></row><row><cell>guided)</cell><cell>substitutions.</cell><cell>have had the greatest influence on your life?</cell></row><row><cell></cell><cell></cell><cell>Prediction: Equivalent ? Not Equivalent</cell></row><row><cell></cell><cell>CompAttack is a whitebox-based adversarial</cell><cell>Task: SST-2</cell></row><row><cell>CompAttack</cell><cell>attack that integrates all other word-level</cell><cell>Sentence: The primitive force of this film seems to bub-</cell></row><row><cell>(Word-level /</cell><cell>perturbation methods in one algorithm to</cell><cell>ble bybble up from the vast collective memory of the</cell></row><row><cell>Compositions)</cell><cell>evaluate model robustness to various adversarial</cell><cell>combatants.</cell></row><row><cell></cell><cell>transformations.</cell><cell>Prediction: Positive ? Negative</cell></row><row><cell></cell><cell></cell><cell>Task: RTE</cell></row><row><cell>SCPN (Sent.-level / Syntactic-based)</cell><cell>SCPN is an attack method based on syntax tree transformations. It is trained to produce a paraphrase of a given sentence with specified syntactic structures.</cell><cell>Sentence 1: He became a boxing referee in 1964 and became most well-known for his decision against Mike Tyson, during the Holyfield fight, when Tyson bit Holy-field's ear. Sentence 2: Mike Tyson bit Holyfield's ear in 1964.</cell></row><row><cell></cell><cell></cell><cell>Prediction: Not Entailment ? Entailment</cell></row><row><cell></cell><cell></cell><cell>Task: MNLI</cell></row><row><cell>T3 (Sent.-level /</cell><cell>T3 is a whitebox attack algorithm that can add</cell><cell>Premise: What's truly striking, though, is that Jobs has</cell></row><row><cell>Syntactic-</cell><cell>perturbations on different levels of the syntax</cell><cell>had never really let this idea go.</cell></row><row><cell>based)</cell><cell>tree and generate the adversarial sentence.</cell><cell>Hypothesis: Jobs never held onto an idea for long.</cell></row><row><cell></cell><cell></cell><cell>Prediction: Contradiction ? Entailment</cell></row><row><cell>AdvFever (Sent.-level / Syntactic-based)</cell><cell>Entailment preserving rules proposed by AdvFever transform all the sentences satisfying the templates into semantically equivalent ones.</cell><cell>Task: SST-2 Sentence: I'll bet the video game is There exists a lot more fun than the film that goes by the name of i 'll bet the video game. Prediction: Negative ? Positive</cell></row><row><cell>StressTest</cell><cell></cell><cell></cell></row><row><cell>(Sent.-level /</cell><cell></cell><cell></cell></row><row><cell>Distraction-</cell><cell></cell><cell></cell></row><row><cell>based)</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Glossary of adversarial attacks (human-crafted) in AdvGLUE. For each adversarial attack, we provide a brief explanation and a corresponding example in AdvGLUE.Temporal and Negation,   which test if the model understands the order of events and if the model is sensitive to negations.</figDesc><table><row><cell>Perturbations</cell><cell>Explanation</cell><cell>Examples (Strikethrough = Original Text, red = Adver-sarial Perturbation)</cell></row><row><cell>CheckList (Human-</cell><cell cols="2">CheckList analyses different capabilities of NLP models using different test types. We adopt two capability tests: Task: SST-2 Sentence: I think this movie is perfect, but I used to think it was annoying.</cell></row><row><cell>crafted)</cell><cell></cell><cell>Prediction: Positive ? Negative</cell></row><row><cell>StressTest</cell><cell></cell><cell></cell></row><row><cell>(Human-</cell><cell></cell><cell></cell></row><row><cell>crafted)</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>Model performance on AdvGLUE test set and GLUE dev set.</figDesc><table><row><cell>Models</cell><cell>GLUE</cell><cell>Avg AdvGLUE</cell><cell>GLUE</cell><cell cols="2">SST-2 AdvGLUE</cell><cell>GLUE</cell><cell>MNLI AdvGLUE</cell><cell>GLUE</cell><cell>RTE AdvGLUE</cell><cell>GLUE</cell><cell cols="2">QNLI AdvGLUE</cell><cell>GLUE</cell><cell>QQP</cell><cell>AdvGLUE</cell></row><row><cell>BERT(Large)</cell><cell>85.76</cell><cell>33.68</cell><cell cols="2">93.23</cell><cell>33.03</cell><cell cols="3">85.78/85.57 28.72/27.05 68.95</cell><cell>40.46</cell><cell cols="2">91.91</cell><cell>39.77</cell><cell cols="2">90.72/87.38 37.91/16.56</cell></row><row><cell>RoBERTa(Large)</cell><cell>91.44</cell><cell>50.21</cell><cell cols="2">95.99</cell><cell>58.52</cell><cell cols="3">89.74/89.86 50.78/39.62 86.60</cell><cell>45.39</cell><cell cols="2">94.14</cell><cell>52.48</cell><cell cols="2">91.99/89.37 57.11/41.80</cell></row><row><cell>T5(Large)</cell><cell>90.39</cell><cell>56.82</cell><cell cols="2">95.53</cell><cell>60.56</cell><cell cols="3">88.98/89.20 48.43/38.98 84.12</cell><cell>62.83</cell><cell cols="2">93.78</cell><cell>57.64</cell><cell cols="2">90.82/88.07 63.03/55.68</cell></row><row><cell>ALBERT(XXLarge)</cell><cell>91.87</cell><cell>59.22</cell><cell cols="2">95.18</cell><cell>66.83</cell><cell cols="3">89.29/89.88 51.83/44.17 88.45</cell><cell>73.03</cell><cell cols="2">95.26</cell><cell>63.84</cell><cell cols="2">92.26/89.49 56.40/32.35</cell></row><row><cell>ELECTRA(Large)</cell><cell>93.16</cell><cell>41.69</cell><cell cols="2">97.13</cell><cell>58.59</cell><cell>90.71</cell><cell cols="2">14.62/20.22 90.25</cell><cell>23.03</cell><cell cols="2">95.17</cell><cell>57.54</cell><cell>92.56</cell><cell>61.37/42.40</cell></row><row><cell>DeBERTa(Large)</cell><cell>92.67</cell><cell>60.86</cell><cell cols="2">96.33</cell><cell>57.89</cell><cell cols="3">90.95/90.85 58.36/52.46 90.25</cell><cell>78.94</cell><cell cols="2">94.86</cell><cell>57.85</cell><cell cols="2">92.29/89.69 60.43/47.98</cell></row><row><cell>SMART(BERT)</cell><cell>85.70</cell><cell>30.29</cell><cell cols="2">93.35</cell><cell>25.21</cell><cell cols="3">84.72/85.34 26.89/23.32 69.68</cell><cell>38.16</cell><cell cols="2">91.71</cell><cell>34.61</cell><cell cols="2">90.25/87.22 36.49/20.24</cell></row><row><cell>SMART(RoBERTa)</cell><cell>92.62</cell><cell>53.71</cell><cell cols="2">96.56</cell><cell>50.92</cell><cell cols="3">90.75/90.66 45.56/36.07 90.98</cell><cell>70.39</cell><cell cols="2">95.04</cell><cell>52.17</cell><cell cols="2">91.20/88.44 64.22/44.28</cell></row><row><cell>FreeLB(RoBERTa)</cell><cell>92.28</cell><cell>50.47</cell><cell cols="2">96.44</cell><cell>61.69</cell><cell>90.64</cell><cell cols="2">31.59/27.60 86.69</cell><cell>62.17</cell><cell cols="2">95.04</cell><cell>62.29</cell><cell>92.58</cell><cell>42.18/31.07</cell></row><row><cell cols="2">InfoBERT(RoBERTa) 89.06</cell><cell>46.04</cell><cell cols="2">96.22</cell><cell>47.61</cell><cell cols="3">89.67/89.27 50.39/41.26 74.01</cell><cell>39.47</cell><cell cols="2">94.62</cell><cell>54.86</cell><cell cols="2">92.25/89.70 49.29/35.54</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>Examples of AdvGLUE benchmark. The primitive force of this film seems to bubble bybble up from the vast collective memory of the combatants. She has modeled in fashion shows for designers such as Marc Jacobs, Chanel, Givenchy, Dolce &amp; Gabbana, and Sonia Rykiel. And appeared on the cover of Vogue Italia two times in a row. This was a huge influx as the entire population of the Dutch Republic amounted to ca. Mike Tyson bit Holyfield's ear in 1964.</figDesc><table><row><cell>Task</cell><cell>Linguistic Phe-</cell><cell>Samples (Strikethrough = Original Text, red = Adversarial Perturbation)</cell><cell>Label ? Pre-</cell></row><row><cell></cell><cell>nomenon</cell><cell></cell><cell>diction</cell></row><row><cell>SST-2</cell><cell>Typo (Word-level)</cell><cell cols="2">Sentence: Positive ? Negative</cell></row><row><cell>SST-2</cell><cell>Context-aware (Word-level)</cell><cell>Sentence: In execution , this clever idea is far less smaller funny than the original , killers from space.</cell><cell>Negative ? Positive</cell></row><row><cell>SST-2</cell><cell>CheckList (Human-crafted)</cell><cell>Sentence: I think this movie is perfect, but I used to think it was annoy-ing.</cell><cell>Positive ? Negative</cell></row><row><cell>QQP</cell><cell>Embedding (Word-level)</cell><cell>Question 1: I am getting fat on my lower body and on the chest torso, is there any way I can get fit without looking skinny fat? Question 2: Why I am getting skinny instead of losing body fat?</cell><cell>Not Equivalent ? Equivalent</cell></row><row><cell>QQP</cell><cell>Syntactic (Sent.-level)</cell><cell>Question 1: Can I learn MMA at the age of 26? You can learn MMA at 24? Question 2: Can I learn MMA at the age of 24?</cell><cell>Not Equivalent ? Equivalent</cell></row><row><cell>QQP</cell><cell>CheckList (Human-crafted)</cell><cell>Question 1: Is Alfred Kennedy an analyst? Question 2: Is Alfred Kennedy becoming an analyst?</cell><cell>Not Equivalent ? Equivalent</cell></row><row><cell>MNLI</cell><cell>Typo (Word-level)</cell><cell>Premise: uh-huh how about any matching mathcing programs Hypothesis: What about matching programs?</cell><cell>Entailment ? Contradiction</cell></row><row><cell>MNLI</cell><cell>Distraction (Sent.-level)</cell><cell>Premise: You and your friends are not welcome here, said Severn. Hypothesis: Severn said the people were not welcome there and true is true.</cell><cell>Entailment ? Contradiction</cell></row><row><cell></cell><cell></cell><cell>Premise: Kamila Filipcikova (born 1991) is a female Slovakian fashion</cell><cell></cell></row><row><cell>MNLI</cell><cell>ANLI (Human-crafted)</cell><cell cols="2">model. Neutral ? Contradiction</cell></row><row><cell></cell><cell></cell><cell>Hypothesis: Filipcikova lives in Italy.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Question: What was the population of the Dutch Republic before this</cell><cell></cell></row><row><cell cols="3">QNLI Sentence: QNLI Distraction (Sent.-level) emigration? https://t.co/DlI9kw AdvSQuAD (Human-crafted) Question: What day was the Super Bowl played on? Sentence: The Champ Bowl was played on August 18th,1991.</cell><cell>False ? True False ? True</cell></row><row><cell>RTE</cell><cell>Knowledge (Word-level)</cell><cell>Sentence 1: In Nigeria, by far the most populous country in sub-Saharan Africa, over 2.7 million people are exist infected with HIV. Sentence 2: 2.7 percent of the people infected with HIV live in Africa.</cell><cell>Not Entailment ? Entailment</cell></row><row><cell></cell><cell></cell><cell>Sentence 1: He became a boxing referee in 1964 and became most</cell><cell></cell></row><row><cell>RTE</cell><cell>Syntactic (Sent.-level)</cell><cell>well-known for his decision against Mike Tyson, during the Holyfield fight, when Tyson bit Holyfield's ear.</cell><cell>Not Entailment ? Entailment</cell></row><row><cell></cell><cell></cell><cell>Sentence 2:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 :</head><label>11</label><figDesc>The statistics of AdvGLUE in the human training phase. For RTE, we train our model for 10 epochs and for other tasks we train our model for 4 epochs. Batch size for QNLI is set to 512, and for other tasks it is set to 256. Learning rates are all set to 2e ? 5.</figDesc><table><row><cell>Corpus</cell><cell cols="2">Pay Rate #/ Qualified (per batch) Workers</cell><cell cols="3">Human Acc. (Avg.) Acc. (vote) Kappa Human Fleiss</cell></row><row><cell>SST-2</cell><cell>$0.4</cell><cell>70</cell><cell>89.2</cell><cell>95.0</cell><cell>0.738</cell></row><row><cell>MNLI</cell><cell>$1.0</cell><cell>33</cell><cell>80.4</cell><cell>85.0</cell><cell>0.615</cell></row><row><cell>RTE</cell><cell>$1.0</cell><cell>66</cell><cell>85.8</cell><cell>92.0</cell><cell>0.602</cell></row><row><cell>QNLI</cell><cell>$1.0</cell><cell>41</cell><cell>85.6</cell><cell>91.0</cell><cell>0.684</cell></row><row><cell>QQP</cell><cell>$0.5</cell><cell>58</cell><cell>86.4</cell><cell>90.0</cell><cell>0.691</cell></row><row><cell>BERT (Large)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 12 .</head><label>12</label><figDesc>We can see that around 60 ? 80% of examples are filtered due to the low transferability and high word modification rate. Among the remaining samples, around 30 ? 40% examples are filtered due to the low human agreement rates (Human Consensus Filtering), and around 20 ? 30% are filtered due to the semantic changes which lead to the label changes (Utility Preserving Filtering).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 12 :</head><label>12</label><figDesc>Filter rates during data curation.</figDesc><table><row><cell>Tasks</cell><cell>Metrics</cell><cell></cell><cell></cell><cell>Word-level Attacks</cell><cell></cell><cell></cell><cell>Average</cell></row><row><cell></cell><cell></cell><cell cols="5">SememePSO TextFooler TextBugger CombAttack BERT-ATTACK</cell><cell></cell></row><row><cell></cell><cell>Transferability</cell><cell>58.85</cell><cell>63.56</cell><cell>64.87</cell><cell>53.58</cell><cell>66.87</cell><cell>61.54</cell></row><row><cell></cell><cell>Fidelity</cell><cell>14.65</cell><cell>11.06</cell><cell>22.40</cell><cell>19.93</cell><cell>12.03</cell><cell>16.01</cell></row><row><cell>SST-2</cell><cell>Human Consensus Utility Preserving</cell><cell>10.53 6.68</cell><cell>10.56 5.43</cell><cell>2.27 0.51</cell><cell>9.92 3.20</cell><cell>7.09 3.82</cell><cell>8.07 3.93</cell></row><row><cell></cell><cell>Filter Rate</cell><cell>90.71</cell><cell>90.62</cell><cell>90.04</cell><cell>86.63</cell><cell>89.81</cell><cell>89.56</cell></row><row><cell></cell><cell>Transferability</cell><cell>44.16</cell><cell>43.15</cell><cell>42.58</cell><cell>35.08</cell><cell>41.80</cell><cell>41.36</cell></row><row><cell></cell><cell>Fidelity</cell><cell>36.57</cell><cell>45.94</cell><cell>37.71</cell><cell>38.14</cell><cell>38.60</cell><cell>39.39</cell></row><row><cell>MNLI</cell><cell>Human Consensus Utility Preserving</cell><cell>10.37 4.49</cell><cell>6.38 2.08</cell><cell>5.51 1.32</cell><cell>11.15 11.07</cell><cell>9.78 5.91</cell><cell>8.64 4.97</cell></row><row><cell></cell><cell>Filter Rate</cell><cell>95.59</cell><cell>97.55</cell><cell>87.12</cell><cell>95.45</cell><cell>96.10</cell><cell>94.36</cell></row><row><cell></cell><cell>Transferability</cell><cell>55.32</cell><cell>67.38</cell><cell>41.96</cell><cell>54.20</cell><cell>60.94</cell><cell>55.96</cell></row><row><cell></cell><cell>Fidelity</cell><cell>19.83</cell><cell>7.79</cell><cell>42.18</cell><cell>23.17</cell><cell>14.25</cell><cell>21.44</cell></row><row><cell>RTE</cell><cell>Human Consensus Utility Preserving</cell><cell>8.08 8.69</cell><cell>7.91 6.13</cell><cell>3.55 0.60</cell><cell>7.64 5.70</cell><cell>8.44 8.54</cell><cell>7.12 5.93</cell></row><row><cell></cell><cell>Filter Rate</cell><cell>91.93</cell><cell>89.21</cell><cell>88.29</cell><cell>90.72</cell><cell>92.16</cell><cell>90.46</cell></row><row><cell></cell><cell>Transferability</cell><cell>63.36</cell><cell>70.67</cell><cell>59.24</cell><cell>55.47</cell><cell>69.15</cell><cell>63.58</cell></row><row><cell></cell><cell>Fidelity</cell><cell>17.73</cell><cell>13.01</cell><cell>25.31</cell><cell>23.53</cell><cell>13.17</cell><cell>18.55</cell></row><row><cell>QNLI</cell><cell>Human Consensus Utility Preserving</cell><cell>10.06 3.48</cell><cell>9.80 2.41</cell><cell>6.84 1.50</cell><cell>9.98 4.94</cell><cell>9.36 4.10</cell><cell>9.21 3.29</cell></row><row><cell></cell><cell>Filter Rate</cell><cell>94.63</cell><cell>95.89</cell><cell>92.89</cell><cell>93.92</cell><cell>95.78</cell><cell>94.62</cell></row><row><cell></cell><cell>Transferability</cell><cell>42.96</cell><cell>58.60</cell><cell>55.09</cell><cell>44.83</cell><cell>51.97</cell><cell>50.69</cell></row><row><cell></cell><cell>Fidelity</cell><cell>45.61</cell><cell>29.35</cell><cell>26.46</cell><cell>30.99</cell><cell>37.77</cell><cell>34.04</cell></row><row><cell>QQP</cell><cell>Human Consensus Utility Preserving</cell><cell>4.38 3.79</cell><cell>4.69 3.86</cell><cell>5.19 3.16</cell><cell>10.08 7.93</cell><cell>3.94 4.60</cell><cell>5.66 4.67</cell></row><row><cell></cell><cell>Filter Rate</cell><cell>96.73</cell><cell>96.50</cell><cell>89.90</cell><cell>93.83</cell><cell>98.28</cell><cell>95.05</cell></row></table><note>FAQ document in each task description page https://docs.google.com/document/d/ 1MikHUdyvcsrPqE8x-N-gHaLUNAbA6-Uvy-iA5gkStoc/edit?usp=sharing.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We note that both CheckList and StressTest propose both rule-based distraction sentences and manually crafted templates to generate test samples. The former is considered as sentence-level distraction-based perturbations, while the latter is considered as human-crafted examples.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Instructions can be found at https://adversarialglue.github.io/instructions.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/facebookresearch/anli</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments and Disclosure of Funding</head><p>We thank the anonymous reviewers for their constructive feedback. We also thank Prof. Sam Bowman, Dr. Adina Williams, Nikita Nangia, Jinfeng Li, and many others for the helpful discussion. We thank Prof. Robin Jia and Yixin Nie for allowing us to incorporate their datasets as part of the evaluation. We thank the SQuAD team for allowing us to use their website template and submission tutorials. This work is partially supported by the NSF grant No.1910100, NSF CNS 20-46726 CAR, the Amazon Research Award.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Beat the ai: Investigating adversarial human annotation for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="662" to="678" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">What will it take to fix benchmarking in natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<editor>L. M?rquez, C. Callison-Burch, J. Su, D. Pighin, and Y. Marton</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Origins of algorithmic instabilities in crowdsourced ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Burghardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hogg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Posfai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">CSCW2</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Audio adversarial examples: Targeted attacks on speech-to-text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Security and Privacy Workshops (SPW)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Electra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10555</idno>
		<title level="m">Pre-training text encoders as discriminators rather than generators</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Certified adversarial robustness via randomized smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<editor>J. Burstein, C. Doran, and T. Solorio</editor>
		<imprint>
			<date type="published" when="2019" />
			<publisher>HLT</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Training verified learners with learned verifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dvijotham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gowal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stanforth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>O&amp;apos;donoghue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<idno>abs/1805.10265</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hotflip: White-box adversarial examples for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lowd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Robust physical-world attacks on deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eykholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Evtimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rahmati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kohno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">X</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Large-scale adversarial training for vision-and-language representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06195</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bae: Bert-based adversarial examples for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6174" to="6181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vecchione</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daum?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crawford</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.09010</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Datasheets for datasets. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>R?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.04840</idno>
		<title level="m">Robustness gym: Unifying the nlp evaluation landscape</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>abs/1412.6572</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.11441</idno>
		<title level="m">Unified multilingual robustness evaluation toolkit for natural language processing</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.03654</idno>
		<title level="m">Deberta: Decoding-enhanced bert with disentangled attention</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Achieving verified robustness to symbol substitutions via interval bound propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stanforth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gowal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dvijotham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adversarial example generation with syntactically controlled paraphrase networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Adversarial examples for evaluating reading comprehension systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<editor>M. Palmer, R. Hwa, and S. Riedel</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Certified robustness to adversarial word substitutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>G?ksel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">SMART: robust and efficient finetuning for pre-trained natural language models through principled regularized optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<editor>D. Jurafsky, J. Chai, N. Schluter, and J. R. Tetreault</editor>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Is BERT really robust? A strong baseline for natural language attack on text classification and entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dynabench: Rethinking benchmarking in nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ringshia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Thrush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Albert: A lite bert for self-supervised learning of language representations. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-Z</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Soricut</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Textbugger: Generating adversarial text against real-world applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NDSS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Textshield: Robust text classification based on multimodal embedding and neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">29th USENIX Security Symposium (USENIX Security 20). USENIX Association</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Bert-attack: Adversarial attack against bert using bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6193" to="6202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Adversarial training for large neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno>abs/2004.08994</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roberta</surname></persName>
		</author>
		<title level="m">A robustly optimized BERT pretraining approach. CoRR, abs</title>
		<imprint>
			<date type="published" when="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held</title>
		<editor>C. J. C. Burges, L. Bottou, Z. Ghahramani, and K. Q. Weinberger</editor>
		<meeting><address><addrLine>Lake Tahoe, Nevada, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deepfool: A simple and accurate method to fool deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-M</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page" from="2574" to="2582" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Reevaluating adversarial examples in natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lifland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lanchantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<meeting><address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Textattack: A framework for adversarial attacks, data augmentation, and adversarial training in nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lifland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Grigsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.05909</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.00692</idno>
		<title level="m">Stress test evaluation for natural language inference</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Human vs. muppet: A conservative estimate of human performance on the glue benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Adversarial NLI: A new benchmark for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<editor>D. Jurafsky, J. Chai, N. Schluter, and J. R. Tetreault</editor>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Distillation as a defense to adversarial perturbations against deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="582" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>A. Moschitti, B. Pang, and W. Daelemans</editor>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2014-10-25" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Openhownet: An open sememe-based lexical knowledge base. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Beyond accuracy: Behavioral testing of NLP models with CheckList</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="4902" to="4912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
		<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Adversarial attacks against fact extraction and verification. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Fever: a large-scale dataset for fact extraction and verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Left, right, and gender: Exploring interaction traces to mitigate human biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Narechania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coscia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Paden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.03536</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Superglue: A stickier benchmark for general-purpose language understanding systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">T3: Tree-autoencoder constrained adversarial text generation for targeted attack</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Infobert: Improving robustness of language models from an information theoretic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Paranmt-50m: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05732</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05426</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Characterizing audio adversarial examples using temporal dependency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y.</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">X</forename><surname>Song</surname></persName>
		</author>
		<idno>abs/1809.10875</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">SAFER: A structure-free approach for certified robustness to adversarial word substitutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Word-level textual adversarial attacking as combinatorial optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.09191</idno>
		<title level="m">Openattack: An open-source textual adversarial attack toolkit</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Bertscore: Evaluating text generation with bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Ernie: Enhanced language representation with informative entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Freelb: Enhanced adversarial training for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2020. Figure 3: Human annotation instructions (filtering phase) for MNLI</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">company, institution, organization) on behalf of which the dataset was created? The dev set is released to the public. The test set is hidden and can only be evaluated by an automatic submission API hosted on CodaLab</title>
		<ptr target="https://adversarialglue.github.io" />
	</analytic>
	<monogr>
		<title level="m">The test set is hidden and hosted on CodaLab. When will the dataset be distributed? It has been released now</title>
		<meeting><address><addrLine>API, GitHub</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>Distribution Will the dataset be distributed to third parties outside of the entity</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Will the dataset be distributed under a copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)?</title>
	</analytic>
	<monogr>
		<title level="m">Our dataset will be distributed under the CC BYthe dataset be contacted</title>
		<imprint/>
	</monogr>
	<note>email address. Boxin Wang (boxinw2@illinois.edu) and Chejian Xu (xuchejian@zju.edu.cn) will be responsible for maintenance</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">to correct labeling errors, add new instances, delete instances)? Yes. If we include more tasks or find any errors, we will correct the dataset and update the leaderboard accordingly</title>
	</analytic>
	<monogr>
		<title level="m">Will the dataset be updated</title>
		<imprint/>
	</monogr>
	<note>It will be updated on our website</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so? They can contact us via email for the contribution</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
