<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Emotion-Aware Transformer Encoder for Empathetic Dialogue Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>ACIIW</publisher>
				<availability status="unknown"><p>Copyright ACIIW</p>
				</availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Goel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Delhi Technological University</orgName>
								<address>
									<postCode>110042</postCode>
									<settlement>New Delhi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seba</forename><surname>Susan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Delhi Technological University</orgName>
								<address>
									<postCode>110042</postCode>
									<settlement>New Delhi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Vashisht</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Delhi Technological University</orgName>
								<address>
									<postCode>110042</postCode>
									<settlement>New Delhi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armaan</forename><surname>Dhanda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Delhi Technological University</orgName>
								<address>
									<postCode>110042</postCode>
									<settlement>New Delhi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Emotion-Aware Transformer Encoder for Empathetic Dialogue Generation</title>
					</analytic>
					<monogr>
						<title level="m">2021 9th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos</title>
						<imprint>
							<publisher>ACIIW</publisher>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/ACIIW52867.2021.9666315</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Transformer-XL</term>
					<term>Empathetic dialogue generation</term>
					<term>Affective state</term>
					<term>Encoder-decoder model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modern day conversational agents are trained to emulate the manner in which humans communicate. To emotionally bond with the user, these virtual agents need to be aware of the affective state of the user. Transformers are the recent state of the art in sequence-to-sequence learning that involves training an encoder-decoder model with word embeddings from utterance-response pairs. We propose an emotion-aware transformer encoder for capturing the emotional quotient in the user utterance in order to generate human-like empathetic responses. The contributions of our paper are as follows: 1) An emotion detector module trained on the input utterances determines the affective state of the user in the initial phase 2) A novel transformer encoder is proposed that adds and normalizes the word embedding with emotion embedding thereby integrating the semantic and affective aspects of the input utterance 3) The encoder and decoder stacks belong to the Transformer-XL architecture which is the recent state of the art in language modeling. Experimentation on the benchmark Facebook AI empathetic dialogue dataset confirms the efficacy of our model from the higher BLEU-4 scores achieved for the generated responses as compared to existing methods. Emotionally intelligent virtual agents are now a reality and inclusion of affect as a modality in all human-machine interfaces is foreseen in the immediate future.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Virtual assistants such as Cortana, Alexa and Siri, are now an integral part of modern life. Their services range from facilitating simple financial transactions to conducting a friendly conversation with the user. The latter is a more challenging task since the virtual agent needs to emulate the manner in which a human listener empathizes with the emotions of the speaker and generates an appropriate response that syncs with the emotional state of the speaker. To empathize with a human, the machine needs to be emotionally intelligent and needs to be trained on the emotion metadata available in modern dialogue corpora.</p><p>Virtual conversational agents generally have at their core a sequence-to-sequence (Seq2Seq) model trained on inputoutput sentence pairs <ref type="bibr" target="#b0">[1]</ref>. In order to generate an appropriate response to a user utterance, the contextual information in the input sentence needs to be captured <ref type="bibr" target="#b1">[2]</ref>. Language and sequence modelling tasks require long-term dependencies to be captured effectively from sequential data in order to make sense of the context and identify the meaning conveyed by the sentence. Practically, it is not possible to learn long-term dependencies from an infinitely long time window. Instead, the effort is to learn a long dependency from a time-step that is as large as possible. Recurrent Neural Networks (RNN) such as Long Short-Term Memory (LSTM) <ref type="bibr" target="#b2">[3]</ref> and Gated Recurrent Unit (GRU) <ref type="bibr" target="#b3">[4]</ref> capture long-term dependencies in sequential data. The standard vanilla RNN suffers from problems like vanishing gradient and exploding gradient. Despite contributing to improvements in machine translation tasks, their performance dropped when the length of the input sentence is increased <ref type="bibr" target="#b3">[4]</ref>. Attention mechanism <ref type="bibr" target="#b4">[5]</ref> was incorporated into the encoder-decoder architecture for capturing context in the encoder output. Alternatives to purely recurrent encoder-decoder architectures <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> are purely convolutional <ref type="bibr" target="#b5">[6]</ref> and convolutional-recurrent architectures <ref type="bibr" target="#b6">[7]</ref>. A convolutional encoder was preferred in <ref type="bibr" target="#b6">[7]</ref> to better capture the context information in the input sentence in order to generate semantically meaningful responses.</p><p>The advent of transformers brought about a revolution in the field of sequence modeling that was mainly dominated by RNNs. The transformer architecture was proposed by <ref type="bibr">Vaswani et al. in 2017 [8]</ref> for machine translation tasks, that allowed for significant parallel computations and is based entirely on self-attention which was further improved with the "multi-head" attention mechanism. Self-attention allows for better word encoding as each word is processed by the model by looking at the other words in the input sentence which helps in getting better clues/hints about the context in which the current word is being used. The transformer architecture also uses positional encoding by making changes to the original input embedding such that the model learns the position of each word and meaningful distances between different words in the sentence. However, the transformer works with a fixedlength context. This restricts its ability to model dependencies beyond a segment. There is also the problem of context fragmentation which arises due to fixed-length segments not respecting the sentence boundaries leading to a loss of context of the original sentence due to semantic boundaries of the sentence being ignored.</p><p>The Transformer-XL model <ref type="bibr" target="#b9">[9]</ref> was introduced by Dai et al. in 2019 as an improvement over the vanilla transformer with much faster evaluation speeds and much longer dependency learning capability. Transformer-XL (XL for extra-long) overcomes the shortcomings of the vanilla transformer of Al-Rfou et al. (2019) <ref type="bibr" target="#b11">[10]</ref> by incorporating recurrence mechanism and relative positional encoding. In this paper, we propose a Transformer-XL architecture for empathetic response generation by adding and normalizing the word embedding from the input utterance with the emotion embedding. An emotion detection module forms the first stage in our learning framework. The result is an emotionally intelligent conversational agent that can understand the emotions of the user and generates empathetic responses accordingly. The rest of the paper is organized as follows: section II presents related work, the proposed model is described in section III, the experimental setup and the results are discussed in sections IV and V respectively, and the paper is concluded in section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Most of the contemporary work on conversational agents focus on improving language understanding. Recent works advocate the incorporation of contextual knowledge through attention mechanisms <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5]</ref>. However, such models are unaware of the emotions of the user, and the generated responses may sometimes reveal the lack of personality or character of the virtual agent. Incorporation of affect as a modality in human-machine interactions is now regarded as a means for gaining human trust. Understanding the affective state of the user is useful for generating emotive responses that improves the overall quality of the human machine interaction and increases customer satisfaction <ref type="bibr" target="#b31">[30]</ref>. In two separate works, Lee et al. <ref type="bibr">(2005)</ref> and <ref type="bibr" target="#b13">Devillers and Vidrascu (2006)</ref> presented some initial work on emotion recognition from conversations using audio and lexicon-based methods <ref type="bibr" target="#b12">[11,</ref><ref type="bibr" target="#b13">12]</ref>. Emotion classification using raw audio features is already well explored in literature <ref type="bibr" target="#b14">[13]</ref>. Inclusion of text cues improved the classification scores in <ref type="bibr" target="#b15">[14]</ref>.</p><p>Some of the earliest attempts to create emotionally intelligent conversational agents was based on selecting an emotional response using manually crafted rules <ref type="bibr" target="#b32">[31]</ref> that required expertise and was not scalable to larger datasets. The introduction of the encoder-decoder model for sequence-tosequence learning <ref type="bibr" target="#b3">[4]</ref> changed the drift of research with most of the researchers adopting this methodology for mapping the input utterance to a suitable output response which is predicted on a word-by-word basis using neural networks. LSTM which is a recurrent neural network captures the temporal information in the words in a sentence effectively <ref type="bibr" target="#b16">[15]</ref>, hence most of the sequence-to-sequence models have LSTM as the encoder and the decoder. <ref type="bibr" target="#b17">Hu et al., (2018)</ref> proposed an encoder-decoder architecture with LSTM to develop a toneaware chatbot meant for social media customer care <ref type="bibr" target="#b17">[16]</ref>. Most of the corpora for dialogue systems, till recently, did not include meta-data such as topic of discussion, speaker-name, personality or emotions. Now, there are available datasets, that are emotionally annotated, like the Facebook AI Empathetic Dialogue (ED) dataset introduced by Rashkin et al. in 2019 <ref type="bibr" target="#b18">[17]</ref>. There are also datasets based on textual and acoustic features <ref type="bibr" target="#b19">[18,</ref><ref type="bibr" target="#b20">19]</ref> from which models have been developed for sentiment classification and emotion recognition. Zhou et al.</p><p>(2020) used a Seq2Seq GRU-RNN model to develop an empathetic social chatbot which takes into consideration the Emotional Quotient (EQ) and Intelligence Quotient (IQ) for generating responses with proper emotions <ref type="bibr" target="#b21">[20]</ref>. Li et al.</p><p>(2019) developed a conversational agent that generated meaningful emotional replies using Reinforcement Learning and emotional editing constraints <ref type="bibr" target="#b22">[21]</ref>.</p><p>An empathetic response-based chatbot called CARO was introduced in <ref type="bibr" target="#b23">[22]</ref> that was capable of engaging in empathetic conversations and providing medical advice for people suffering with major depression; it generated responses by appending emotions as a prefix for each utterance. A classification stage forms the first stage of this chatbot that decided whether the user utterance belonged to the category of medical question answering or an empathetic dialogue. The model was trained using both the datasets in this case. <ref type="bibr" target="#b24">Ma et al. (2020)</ref>, has presented a systematic review of chatbots that generate empathetic responses to user utterances; these were termed as Emotionally Aware Chatbots (EAC) <ref type="bibr" target="#b24">[23]</ref>. LSTM with attention mechanism has proved to generate more empathetic responses than the LSTM sans attention, as proved by researchers in <ref type="bibr" target="#b25">[24]</ref> who experimented on the Facebook AI ED dataset. Likewise, transformer models have proved to outperform LSTM with attention for empathetic dialogue generation, as proved in <ref type="bibr" target="#b18">[17]</ref>. The details of our model, which is based on one of the latest advancements in transformer architectures, are described in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED MODEL</head><p>Motivated by the work on transformer based empathetic dialogue generation in <ref type="bibr" target="#b18">[17]</ref>, we propose a novel technique for rendering the virtual agent emotionally intelligent. Assuming that the dialogue dataset has emotion annotations, a separate classifier is trained on the emotion meta-data, apart from the usual training on utterance-response pairs. <ref type="figure" target="#fig_0">Fig. 1</ref> shows the basic blocks of our model. To make the dialogue generator emotionally intelligent, we incorporate an emotional bias in the input embedding. The transformer encoder that encodes the input utterance is made emotion aware by incorporating the emotion information in the form of an embedding vector. Unlike <ref type="bibr" target="#b18">[17]</ref> that prepends the emotion information along with the utterance embedding as a separate piece of information, we add and normalize each word embedding in the input utterance with the embedding vector of the predicted emotion; the result is provided as input to the transformer encoder. The Keras word embedding is used, that yields better results than the conventional bag-of-words representation used for text classification <ref type="bibr" target="#b26">[25]</ref>.</p><p>Our learning model, therefore, comprises of two independent models that are trained separately on the same dataset; one is the Emotion Classifier and the other is the Generative Chatbot, as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. The Emotion Classifier uses the utterance to detect the emotion in the utterance, while the Generative Chatbot provides the utterance and detected emotion as the inputs to the transformer encoder in order to generate the empathetic response. The result is an emotionally intelligent conversational agent that can detect and respond to the emotional state of the user. The details of Emotion Classifier and the Generative Chatbot are given next. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Emotion Classifier</head><p>The first stage of our learning framework comprises of an emotion detection module. <ref type="figure" target="#fig_1">Fig. 2(a)</ref> shows the distribution of 32 emotions in the ED dataset. We have divided the total number of emotions into eight groups by grouping similar emotions together, as shown in <ref type="figure" target="#fig_1">Fig. 2 (b)</ref>. We used the same coarse grouping of emotions as in <ref type="bibr" target="#b23">[22]</ref>.  <ref type="bibr" target="#b23">[22]</ref> The Emotion Classifier that we have used for predicting the context of the given utterance consists of an LSTM unit of 300 cells and a 100-unit dense layer. The softmax layer consists of eight units corresponding to the eight emotion groups. The highest probability in the output layer determines the emotion. The pipeline for our emotion prediction module is shown in <ref type="figure" target="#fig_2">Fig. 3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Generative Chatbot</head><p>For the Generative Chatbot, we make use of the Transformer-XL (XL for extra-long) architecture proposed by Dai et al.</p><p>(2019) <ref type="bibr" target="#b9">[9]</ref> to model long-term dependencies, which is a recently introduced transformer architecture for language modelling. Transformer-XL has a similar base as that of the vanilla Transformer in <ref type="bibr" target="#b11">[10]</ref>. The ability of the Transformer-XL model to handle long-term dependencies in a much better way than the vanilla transformer makes the Transformer-XL much more preferable. In the Transformer-XL architecture, the output of the hidden layer of the last segment is also passed with the present segment's hidden layer output which helps to capture the long term dependencies in a better manner. Also, to capture the long-term dependencies more effectively, positional encoding is introduced in each part of the attention module. The Generative Chatbot model consists of two parts i.e. encoder and decoder. The encoder receives as its input the word embedding of the utterance augmented by the emotion embedding, as shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. The embedding vector we get after adding and normalizing the two components has the information about both the words and the emotional context in the input utterance, which will be further processed to generate suitable empathetic responses. The normalization procedure comprises of subtracting the mean and dividing by the standard deviation. An emotional bias is, therefore, introduced in the embedding stage, that makes the transformer encoder emotion aware. Adding and normalizing embedded feature vectors was found to improve accuracy in several Seq2Seq models due to the induced bias that makes the model sensitive to context <ref type="bibr" target="#b6">[7]</ref>. The transformer encoder consists of several layers, each consisting of multi-head attention layer and feed-forward network. The decoder receives the hidden representation from the encoder and decodes it to probabilistically generate the target response, one word at a time. The output sequence obtained from the transformer decoder is the generated response. The responses generated by our model are evaluated for their correctness, as per procedure explained in sections IV and V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL SETUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset</head><p>The Facebook AI Empathetic Dialogue (ED) dataset <ref type="bibr" target="#b18">[17]</ref> is used for the experimentation. The training dataset comprises of a total of 79189 entries with 8 columns consisting of nonnull values of prompt and utterance, associating a prescribed emotion in the context value. A total of 32 unique emotions have been classified in the dialogues that are grouped into 8 emotion categories, as previously shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. Also, it is quite evident that the 32 different emotions need not specifically highlight unique emotions in real life. For example, 'afraid' and 'terrified' can relate to the same emotion type in all practical scenarios. We use the grouping followed by <ref type="bibr" target="#b23">[22]</ref> for the ED dataset. A total of 5242 entries are present in the test dataset. It was observed that the relative count of emotions in the train and test dataset is almost the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Training setup</head><p>The standard text pre-processing steps were performed such as tokenization, converting to lower case. This was followed by lemmatization to standardize the vocabulary. The software implementation was done in Python. We have made our code available online 1 . We use an 8-head Transformer-XL encoder with inner-size dimensionality of 256 and the hiddenlayer size is 100. The training process consisted of 50 epochs with a batch size of 64 and a learning rate of 0.001, and the dropout regularization parameter was set to 0.1. Sparse Categorical Cross Entropy loss function was used along with Adam optimizer with the hyperparameters ?1= 0.9, ?2=0.98 and ? = 10 ?9 . The loss value was reduced to 0.6054 at the end of 50 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULTS AND DISCUSSIONS</head><p>The Emotion Classifier in the first stage of our learning framework achieved a test accuracy of 95%. The predicted emotion was mapped into a 256-dimensional embedded vector, that was added and normalized with the word embedding of the same size. Keras word embedding was used. We used the BLEU-4 score <ref type="bibr" target="#b28">[27]</ref> metric to evaluate the quality of the generated responses. This is a value between 0 to 1 that matches the machine generated response with the human response (ground-truth). A value of 1 means a perfect match with the human annotated response. The higher the score, the closer is the machine generated response to the ground-truth. The BLEU-4 scores of all the ground truths available for an input utterance were averaged.</p><p>We have considered seven models for comparison, the first is the one proposed by Facebook AI <ref type="bibr" target="#b18">[17]</ref> based on the transformer architecture. This model prepends the emotion with the user utterance. The second is the baseline Seq2Seq encoder-decoder model based on LSTM with Attention Mechanism <ref type="bibr" target="#b25">[24]</ref>. The third is another LSTM-based conversational agent called CARO <ref type="bibr" target="#b23">[22]</ref>. The fourth is the vanilla transformer model proposed by <ref type="bibr" target="#b8">Vaswani et al. (2017)</ref>  <ref type="bibr" target="#b8">[8]</ref>. The fifth method EmoDS is that of <ref type="bibr" target="#b29">Song et al. (2019)</ref>  <ref type="bibr" target="#b29">[28]</ref>, that plugs emotional words at certain time-steps in between words to make the system emotion aware. The sixth method is EmpTransfo <ref type="bibr" target="#b30">[29]</ref>, a multi-head transformer model that predicts the next emotion and utterance given the current emotion and utterance. The BLEU scores for the responses generated by all models are summarized in <ref type="table" target="#tab_0">Table I</ref>.  <ref type="table" target="#tab_0">Table II</ref>. From the empathetic responses generated by our model, it is evident that it is more emotionally intelligent than the vanilla transformer model. For example, the model is aware of the happy occasion being that of a job, in the first instance, and that the user is going to be a parent, in the second case. The vanilla transformer, on the other hand, generates a generic complimentary response, that has no bearing on the particular situation of the user. The limitation of our model is highlighted in the third case in <ref type="table" target="#tab_0">Table II</ref>, where the symbolic notation of math test is not comprehended by both the transformer models and a generic response is generated in both cases that conveys the hope that the problem will be sorted out and that it can happen with anybody.</p><p>There are also cases where multiple emotions can be associated with a user utterance. A notable instance is the fourth case in <ref type="table" target="#tab_0">Table II</ref>, where the emotion associated with the user statement on skydiving is decoded by our model as "terrified" and a suitable response is generated accordingly. Though the predicted emotion did not match with the dataset annotation ("excited"), the generated response yet was found to sync with some of the ground truth responses that expressed fear and apprehension in regard of skydiving. This leads to the observation that more than one affective state may be involved in human-machine dialogue systems. Identification of compatible human emotions can lead to the development of more emotionally-sensitive human-machine interfaces. Exploration of dynamically evolving emotions in humanmachine conversations forms the future scope of our work. Have you ever done anything else so frightening?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSIONS</head><p>In this paper, we have presented an emotionally intelligent conversational agent that is capable of conducting empathetic conversations with users. The proposed model integrates both the semantic and affective aspects of the input utterance. The two embeddings (semantic, affective) are added and normalized and fed as input to the transformer encoder. For the same set of utterances, the BLEU score improved from 0.173 to 0.225 as we moved from the standard transformer to the advanced Transformer-XL architecture, which is also reflected in the difference in the quality of the responses generated by the two models. The proposed conversational agent successfully emulates a human agent that can perceive user emotion and respond empathetically to the user input. Emotionally intelligent virtual agents are now a reality and the inclusion of affect as a modality in all human-machine interfaces is foreseen in the immediate future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Basic outline of the proposed model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>(a) Frequency Distribution of emotions in the Facebook AI ED dataset (b) Grouping of emotions in the ED dataset into eight categories (Harilal et al. 2020)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Emotion classifierThe model uses the dropout regularization technique, in order to prevent model overfitting. The classifier uses the Categorical Cross-Entropy Loss function along with Adam Optimizer<ref type="bibr" target="#b27">[26]</ref> for model training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Augmentation of word embedding with emotion embedding for the transformer encoder</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I .</head><label>I</label><figDesc>BLEU SCORES FOR DIFFERENT MODELS</figDesc><table><row><cell>Models</cell><cell>BLEU Score</cell></row><row><cell>Facebook AI Model</cell><cell>0.08</cell></row><row><cell>Seq2Seq with Attention Model</cell><cell>0.137</cell></row><row><cell>CARO Model</cell><cell>0.179</cell></row><row><cell>Transformer Model</cell><cell>0.173</cell></row><row><cell>EmoDS Seq2Seq model</cell><cell>0.173</cell></row><row><cell>EmpTransfo</cell><cell>0.1592</cell></row><row><cell>Proposed Model</cell><cell>0.225</cell></row><row><cell cols="2">As observed, the BLEU score for the proposed model is the</cell></row><row><cell cols="2">highest (0.225), thus, this model generates the most</cell></row><row><cell cols="2">empathetic responses among all methods. However, it was</cell></row><row><cell cols="2">observed that substitution of Keras word embedding with</cell></row><row><cell cols="2">GloVe word embedding reduced the BLEU score of our</cell></row><row><cell cols="2">model from 0.225 to 0.213. A comparison of the responses</cell></row><row><cell cols="2">generated by our model vs. the standard transformer model is</cell></row><row><cell cols="2">shown for a set of utterance-response pairs of the ED dataset</cell></row><row><cell>in</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II .</head><label>II</label><figDesc>RESPONSES GENERATED BY THE VANILLA TRANSFORMER MODEL VS. THE PROPOSED MODEL FOR SAMPLES FROM THE ED DATASET</figDesc><table><row><cell>Utterance</cell><cell>Ground Truth (Human</cell><cell>Original</cell><cell>Detected</cell><cell>Vanilla</cell><cell>Proposed</cell></row><row><cell>(user input)</cell><cell>annotations)</cell><cell>emotion</cell><cell>Emotion</cell><cell>Transformer</cell><cell>Model</cell></row><row><cell></cell><cell>(Gray highlighted regions</cell><cell></cell><cell>(Coarse</cell><cell>response</cell><cell>response</cell></row><row><cell></cell><cell>introduced to distinguish</cell><cell></cell><cell>classification)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>between ground truths)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>I was very happy to get</cell><cell>oh wow. we're practically neighbors.</cell><cell></cell><cell></cell><cell>That is huge.</cell><cell>Congratulations. What do you do?</cell></row><row><cell>my new job</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>I started a new job about a month ago and it's going really well.</cell><cell>excited</cell><cell>joyful (excited)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>I work in I.T. for the</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>provincial government in</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Canada</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>My first baby is on the way. make sure they have a great life. I'm going to</cell><cell>Oh wow! Congratulations! I think you will be a great parent! I do not yet but hope to one day.</cell><cell>grateful</cell><cell>(grateful) hopeful</cell><cell>Congratulations! That is wonderful.</cell><cell>Oh wow! I think you will be a great parent</cell></row><row><cell></cell><cell>Thank you. We have been</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>trying for a year.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>I was hoping that I would</cell><cell>My math teacher told the class I needed to do better on my next</cell><cell></cell><cell></cell><cell>It surely can be sorted.</cell><cell>It can happen to anyone.</cell></row><row><cell>do better on a</cell><cell>test.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>math test.</cell><cell>Well you should try to study more and see what happens Well maybe you should talk about</cell><cell>grateful</cell><cell>hopeful (grateful)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>getting a tutor or something</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>I'm skydiving this going</cell><cell>Oh my! That sounds exciting for sure! I couldn't do it, I don't think.</cell><cell></cell><cell></cell><cell>Have a great weekend. It's</cell><cell></cell></row><row><cell>weekend.</cell><cell>I would say that you're an</cell><cell></cell><cell></cell><cell>fun.</cell><cell></cell></row><row><cell></cell><cell>adventurous person. Me, I'm more</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>laid back and mellow. Kudos to you</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>and have fun!</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>That's i'm so scared but it will be worth it. You only have one life so</cell><cell>excited</cell><cell>terrified (afraid)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>don't hold back.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>I'm going skydiving this weekend.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>I'm afraid of heights and freaking</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>out a little.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/r9729104234/Emotion-Aware-Transformer-Encoder-for-Empathetic-Dialogue-Generation</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey on conversational agents/chatbots classification and design techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafquat</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omid</forename><forename type="middle">Ameri</forename><surname>Sianaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nedal</forename><surname>Ababneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshops of the International Conference on Advanced Information Networking and Applications</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="946" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Effective Approaches to Attention-based Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</title>
		<meeting>SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyung</forename><forename type="middle">Hyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolutional sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1243" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Context-and sequence-aware convolutional recurrent encoder for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritam</forename><surname>Mallick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seba</forename><surname>Susan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaibhaw</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rizul</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Rawal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th</title>
		<meeting>the 36th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Annual ACM Symposium on Applied Computing</title>
		<imprint>
			<biblScope unit="page" from="853" to="856" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Transformer-XL: Attentive Language Models beyond a Fixed-Length Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th</title>
		<meeting>the 57th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2978" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Character-level language modeling with deeper self-attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dokook</forename><surname>Rami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandy</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3159" to="3166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Toward detecting emotions in spoken dialogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chul Min Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shrikanth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on speech and audio processing</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="293" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Real-life emotions detection with lexical and paralinguistic cues on human-human call center dialogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurence</forename><surname>Devillers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurence</forename><surname>Vidrascu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth International Conference on Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Measuring the randomness of speech cues for emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seba</forename><surname>Susan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amandeep</forename><surname>Kaur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 Tenth International Conference on Contemporary Computing (IC3)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised Fuzzy Inference System for Speech Emotion Recognition using audio and text cues (Workshop Paper)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srishti</forename><surname>Vashishtha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seba</forename><surname>Susan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE Sixth International Conference on Multimedia Big Data (BigMM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="394" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sentiment cognition from words shortlisted by fuzzy entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srishti</forename><surname>Vashishtha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seba</forename><surname>Susan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cognitive and Developmental Systems</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="541" to="550" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Touch your heart: A toneaware chatbot for customer care on social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianran</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anbang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanzeng</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibha</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Akkiraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI conference on human factors in computing systems</title>
		<meeting>the 2018 CHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">Michael</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-Lan</forename><surname>Boureau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5370" to="5381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">IEMOCAP: Interactive emotional dyadic motion capture database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Busso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murtaza</forename><surname>Bulut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Chun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abe</forename><surname>Kazemzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Mower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeannette</forename><forename type="middle">N</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungbok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrikanth</forename><forename type="middle">S</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language resources and evaluation</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="335" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautam</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The design and implementation of xiaoice, an empathetic social chatbot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heung-Yeung</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="93" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Reinforcement learning based emotional editing constraint conversation generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhua</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08061</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">CARO: an empathetic health conversational chatbot for people with major depression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nidhin</forename><surname>Harilal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rushil</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saumitra</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vedanta</forename><surname>Bhutani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM IKDD CoDS and 25th COMAD</title>
		<meeting>the 7th ACM IKDD CoDS and 25th COMAD</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="349" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A survey on empathetic dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khanh</forename><forename type="middle">Linh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><forename type="middle">Z</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="50" to="70" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An Empathetic Conversational Agent with Attentional Mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Vashisht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armaan</forename><surname>Dhanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seba</forename><surname>Susan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 International Conference on Computer Communication and Informatics (ICCCI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Finding significant keywords for document databases by two-phase Maximum Entropy Partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seba</forename><surname>Susan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juli</forename><surname>Keshari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="195" to="205" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR (Poster)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Generating responses with a specific emotion in dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenqiao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan-Jing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3685" to="3695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Emptransfo: A multihead transformer architecture for creating empathetic dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohola</forename><surname>Zandie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">H</forename><surname>Mahoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third International Flairs Conference</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Delivering cognitive behavioral therapy using a conversational social robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Dino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohola</forename><surname>Zandie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hojjat</forename><surname>Abdollahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Schoeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">H</forename><surname>Mahoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2089" to="2095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Emotion-sensitive humancomputer interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Polzin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA tutorial and research workshop (ITRW) on speech and emotion</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
