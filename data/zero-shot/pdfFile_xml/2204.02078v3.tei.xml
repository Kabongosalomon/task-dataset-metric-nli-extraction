<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semi-supervised Semantic Segmentation with Error Localization Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyeon</forename><surname>Kwon</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of AI</orgName>
								<address>
									<country>POSTECH</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of AI</orgName>
								<address>
									<country>POSTECH</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Dept. of CSE</orgName>
								<address>
									<postBox>POSTECH</postBox>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Semi-supervised Semantic Segmentation with Error Localization Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T19:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper studies semi-supervised learning of semantic segmentation, which assumes that only a small portion of training images are labeled and the others remain unlabeled. The unlabeled images are usually assigned pseudo labels to be used in training, which however often causes the risk of performance degradation due to the confirmation bias towards errors on the pseudo labels. We present a novel method that resolves this chronic issue of pseudo labeling. At the heart of our method lies error localization network (ELN), an auxiliary module that takes an image and its segmentation prediction as input and identifies pixels whose pseudo labels are likely to be wrong. ELN enables semi-supervised learning to be robust against inaccurate pseudo labels by disregarding label noises during training and can be naturally integrated with self-training and contrastive learning. Moreover, we introduce a new learning strategy for ELN that simulates plausible and diverse segmentation errors during training of ELN to enhance its generalization. Our method is evaluated on PAS-CAL VOC 2012 and Cityscapes, where it outperforms all existing methods in every evaluation setting.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recent advances in semantic segmentation have been attributed to supervised learning of deep neural networks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b49">50]</ref> on large-scale datasets <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b31">32]</ref>. However, collecting training data for semantic segmentation is labour-intensive and time-consuming due to the prohibitive cost of pixel-wise class labeling, which often leads to a dataset limited in terms of the number of annotated data and class diversity. To address this issue, label efficient learning, such as semi-supervised learning <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>, unsupervised learning <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b45">46]</ref>, weakly supervised learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b47">48]</ref>, and synthetic-toreal domain adaptation <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b52">53]</ref>, has been proposed for semantic segmentation.</p><p>This paper studies semi-supervised learning of semantic segmentation, which assumes that only a subset of train-ing images are assigned segmentation labels while the others remain unlabeled. Undoubtedly, the key to the success of this task is to utilize the unlabeled images effectively. Self-training <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b48">49]</ref> and contrastive learning <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b51">52]</ref> are techniques commonly used for the purpose in literature. Self-training generates pseudo labels of unlabeled images using a model trained on labeled ones, and uses them for supervised learning. Meanwhile, contrastive learning forces feature vectors corresponding to the same pseudo label to be close to each other. Although these techniques have improved the performance of semisupervised semantic segmentation substantially, they share a common drawback: Since predictions for unlabeled images are usually corrupted by errors, learning using such predictions as supervision causes confirmation bias towards the errors and returns corrupted models consequently. Most existing methods alleviate this issue simply by not using uncertain predictions as supervision <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b35">36]</ref>, but their performance depends heavily on hand-tuned thresholds.</p><p>A recent approach deals with errors on pseudo labels by learning and exploiting an auxiliary network that corrects the errors <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b34">35]</ref>; this model, called error correction network (ECN), learns from the difference between predictions of the main segmentation network and their ground truth labels on the labeled subset of training images. Ideally, ECN can significantly improve the quality of pseudo labels, but in practice, its advantage is often limited due to the challenges in its training. Since the segmentation network is quickly overfitted to a small number of labeled images, its outputs used as input to ECN do not cover a wide variety of prediction errors that ECN faces in testing, which results in limited generalization capability of ECN.</p><p>We present a novel method that is also dedicated to handling errors on pseudo labels yet better generalizes to those of arbitrary unlabeled images. The core of our method is the error localization network (ELN), which identifies pixels with erroneous pseudo labels in the form of binary segmentation. As will be demonstrated empirically, simply disregarding invalid pseudo labels, instead of correcting them, is sufficient to alleviate the confirmation bias and to learn accurate segmentation models. More importantly, since er-  <ref type="figure">Figure 1</ref>. Our semi-supervised learning framework incorporating ELN. It employs two segmentation networks, the student (s), which will be our final model, and the teacher (t) used for generating pseudo labels. The student is trained using the pseudo labels of the teacher in two different ways, self-training and contrastive learning. To be specific, the decoder has two heads, one for segmentation (Seg) and the other for feature embedding (Proj); self-training and contrastive learning are applied to outputs of the Seg and Proj heads, respectively. Then the teacher is updated by an exponential moving average (EMA) of the student. ELN allows both self-training and contrastive learning to be robust against noises on pseudo labels by identifying and disregarding pixels whose pseudo labels are likely to be noisy. ror localization is a class-agnostic subproblem of error correction and accordingly easier to solve, it is more straightforward to train an accurate and well-generalizable network for the target task.</p><p>Moreover, we design a novel training strategy for ELN to further improve its generalization. Specifically, we attach multiple auxiliary decoders to the main segmentation network and train them to achieve different accuracy levels so that they simulate the segmentation network at different training stages. ELN is then trained to localize errors on the predictions given by the auxiliary decoders as well as the main segmentation network. This strategy improves generalization of ELN since such predictions used as input to ELN potentially exhibit error patterns that the segmentation network causes during self-training with unlabeled images.</p><p>The trained ELN is then used for semi-supervised learning of semantic segmentation; the overall pipeline incorporating ELN is illustrated in <ref type="figure">Fig. 1</ref>. Our framework exploits unlabeled images in two ways: self-training and contrastive learning, both relying on pseudo labels. To this end, we adopt two segmentation networks: A student network, which will be our final model, and a teacher network generating pseudo labels and updated by an exponential moving average of the student. Self-training is done by learning the student using pseudo labels produced by the teacher. Meanwhile, contrastive learning encourages embedding vectors of the student and teacher to be similar if their pseudo labels are identical. ELN helps improve the effect of both self-training and contrastive learning by filtering out potentially erroneous pseudo labels.</p><p>Following the convention, the proposed method is evaluated on the PASCAL VOC 2012 <ref type="bibr" target="#b11">[12]</ref> and Cityscapes <ref type="bibr" target="#b9">[10]</ref> datasets while varying the number of labeled training images, and it demonstrates superior performance to previous work on both of the datasets.</p><p>In brief, our main contribution is three-fold. ? We propose error localization, a new approach to dealing with errors on pseudo labels. It is simple yet effective and can be naturally incorporated with self-training and contrastive learning. Moreover, we empirically demonstrate the superiority of error localization to error correction. ? We develop a new strategy for generating diverse and plausible prediction errors intentionally during the training of ELN. This improves the generalization of ELN even using a small number of labeled data for training. ? Segmentation networks trained by our method achieves the state of the art on two benchmark datasets, PASCAL VOC 2012 and Cityscapes, in every setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Forward/Backward</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Forward Only Concatenate</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Semantic segmentation. The goal of semantic segmentation is to generate dense pixel-wise classification. Starting with FCN <ref type="bibr" target="#b20">[21]</ref>, which replaced the classifier's last fullyconnected layer with a fully convolutional layer for the first time, various approaches have been studied early. An encoder-decoder structure has been proposed to obtain an accurate high-resolution output <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b39">40]</ref>, and structures such as ASPP <ref type="bibr" target="#b5">[6]</ref> and PSPNet <ref type="bibr" target="#b49">[50]</ref> have been exploited to obtain more diverse spatial contexts. An attention mechanism has been studied to obtain a global relation <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b21">22</ref>]. However, the success of these models requires a large amount of data, which costs expensive labour. Semi-supervised semantic segmentation. Attempts to reduce the cost by applying a semi-supervised learning scheme have been studied intensely. Several methods <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b35">36]</ref> based on GAN and adversarial learning have been studied to reduce the gap between prediction on unlabeled and labeled data. One of the techniques frequently used in semi-supervised learning <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41]</ref> is consistency regularization. It allows the decision boundary to be located in a low-density region by using constraints to make the outputs of various perturbed inputs consistent with each other. Another approach <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b48">49]</ref>, self-training, is a method of generating pseudo labels with unlabeled data by pre-trained model and training the model with both labeled and pseudo labeled data. Recently, various methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b51">52]</ref> have applied contrastive learning <ref type="bibr" target="#b15">[16]</ref> to semantic segmentation in a semi-supervised manner, showing significant performance improvement. Self-correction networks for semi-supervised semantic segmentation. The idea of correcting pseudo labels by an auxiliary network has been studied in <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b34">35]</ref>. They presented networks that correct errors of pseudo labels by learning the difference between predicted and ground truth segmentation labels. However, it is challenging to train such networks effectively in the semi-supervised learning setting since the segmentation network is quickly overfitted to the labeled data, leading to a poor generalization of correction networks. To address this generalization issue of the previous work, we introduce a new auxiliary task called error localization, and present ELN and its training strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>Our framework consists of two-stage, learning ELN using labeled data and semi-supervised learning with ELN. The major issue in the first stage is the lack of diversity in predictions of the main network, which leads to a poor generalization of ELN. To address this issue, in addition to the main segmentation network (encoder E, decoder D), we employ auxiliary decoders (D 1 aux , ..., D K aux ) that are learned to be inferior to the main segmentation network intentionally; predictions of the auxiliary decoders will depict plausible and diverse errors. ELN is learned along with the seg-mentation network and auxiliary decoders to identify errors on their predictions. The overall procedure of ELN training is illustrated in <ref type="figure" target="#fig_0">Fig. 2</ref>.</p><p>In the second stage, the trained ELN is then used for semi-supervised learning of semantic segmentation, where unlabeled images are exploited in two ways, self-training, and contrastive learning. The role of ELN is to identify pixels whose pseudo labels are likely to be erroneous so that we disregard such pixels in the process of self-training and contrastive learning for stable and effective training.</p><p>The remainder of this section presents details of the two stages of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Learning ELN Using Labeled Data</head><p>At first, the main segmentation network is pre-trained with the standard pixel-wise cross-entropy loss L sup on the set of labeled images D L . Let L ce (P, Y ) denote the standard pixel-wise cross-entropy between segmentation prediction P and its ground truth label Y :</p><formula xml:id="formula_0">L ce (P, Y ) = ? i Y ? i log(P i ),<label>(1)</label></formula><p>where i is the index indicating each pixel of the input and Y i is the one-hot vector of the ground truth for pixel i. Let P = D(E(X)) denote segmentation prediction of the main network for an image X. L sup is then given by</p><formula xml:id="formula_1">L sup = 1 |D L | X?D L L ce (P, Y ),<label>(2)</label></formula><p>where Y is the ground truth of the input image X.</p><p>When the pre-training is completed, each auxiliary decoder is trained similarly to the main network but with a constrained cross-entropy loss, which is minimized only up to a certain multiple of L ce (P, Y ) and its gradient is not propagated beyond the auxiliary decoder. Let K be the number of all auxiliary decoders and k be their index. Then the total loss for the K auxiliary decoders, denoted by L aux , is given by</p><formula xml:id="formula_2">L aux = 1 |D L | X?D L K k=1 1{L ce (P k , Y ) &gt; ? k ? L ce (P, Y )} ? L ce (P k , Y ),<label>(3)</label></formula><p>where P k = D k (E(X)) denotes segmentation prediction of the kth decoder, and ? k indicates a scale hyper-parameter for constraining the loss applied to the kth auxiliary decoder. Training the auxiliary decoders in this way enables them to produce plausibly erroneous predictions, which are used as training input to ELN. Given an image and its segmentation prediction as input, ELN is trained to localize errors on the prediction through supervised learning, where true locations of the errors are revealed by comparing the prediction with its ground truth counterpart. Let E k be the pixel-wise entropy map of P k and B k = ELN(X?P k ?E k ) denote the prediction of ELN in the form of binary segmentation map, where ? represents channel-wise matrix concatenation. Then the binary crossentropy loss for ELN, L ELN , is given by</p><formula xml:id="formula_3">L ELN = 1 |D L | ? (K + 1) X?D L K k=0 L ce (B k , M k ),<label>(4)</label></formula><p>where M k denotes the ground truth mask of B k ; M k i is 1 if the prediction of pixel i is correct and 0 otherwise. Note that k = 0 denotes the main decoder.</p><p>Despite using the auxiliary decoders, the population of pixel-level binary labels in M k is typically biased to 1 (correct), which impairs the error identification ability of ELN. To alleviate this, a re-weighting factor is applied to pixels with incorrect predictions in L ELN for balanced training. Let L wce denote a weight re-adjusted pixel-wise cross-entropy between segmentation prediction P and its binary ground truth label Y :</p><formula xml:id="formula_4">L wce (P, Y ) = ? i 1{Y i = 0} j 1{Y j = 1} j 1{Y j = 0} Y ? i log(P i ) + 1{Y i = 1}Y ? i log(P i ) .<label>(5)</label></formula><p>Then the loss in Eq. (4) is revised as</p><formula xml:id="formula_5">L ELN = 1 |D L | ? (K + 1) X?D L K k=0 L wce (B k , M k ). (6)</formula><p>The total loss minimized in the first stage for labeled data is as follows:</p><formula xml:id="formula_6">L labeled = L sup + L aux + L ELN .<label>(7)</label></formula><p>Note that losses in L labeled are jointly optimized in the first stage, although in pre-training L sup is solely minimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Semi-supervised Learning with ELN</head><p>After learning ELN, the main segmentation network is trained on the set of unlabeled images D U with two losses, a self-training loss and a pixel-wise contrastive loss. We adopt the mean teacher framework <ref type="bibr" target="#b42">[43]</ref>, which allows the teacher network to provide more stable pseudo supervision to the student network. Weights? of the teacher (?,D) are updated by the exponential moving average of weights ? of the student (E, D) with an update ratio ?:</p><formula xml:id="formula_7">? t = ?? t?1 + (1 ? ?)? t .<label>(8)</label></formula><p>The proposed self-training loss L pseudo is the pixelwise cross-entropy loss like L sup , but is applied only to valid pixels identified by ELN. LetP =D(?(X)) denote segmentation prediction of the teacher network and P a = D(E(A ? X)) denote that of the student network, where A is the perturbation operator applied to the input image X. Also, letB = ELN(X ?P ??) be the binary segmentation output of ELN. Then L pseudo is given by</p><formula xml:id="formula_8">L pseudo = ? 1 |D U | X?D U i ?B? i ?? ? i log(P a i ),<label>(9)</label></formula><p>where ?? is a function rounding to the nearest integer and Y i denotes the one-hot vector of the pseudo label for pixel i. Through the rounded binary mask, the main segmentation network can be trained on valid pixels only. In order to further improve the quality of learned features, we adopt a pixel-wise contrastive loss L contra . Specifically, in this loss, features whose pseudo labels are the same attract each other while those from different categories are pushed away in the feature space. Instead of applying the loss on a single image, we expand its range to the whole input batch for considering various feature relations, leading to a significant performance improvement. For a given input, let ? i p denote a set of pixels belonging to the class of pixel i and ? i n denote a set of pixels that do not belong to the class of pixel i. Also, let d represent a distance function, d(f 1 , f 2 ) = exp(cos(f 1 , f 2 )/? ), where cos means the cosine similarity and ? is a temperature hyperparameter. The pixel-wise contrastive loss L contra is then given by</p><formula xml:id="formula_9">L contra = ? 1 |V | i?V j?? i p log d(f i ,f j ) d(f i ,f j ) + k?? i n d(f i ,f k ) ,<label>(10)</label></formula><p>where V denotes the set of valid pixels on D U , f i andf i are feature embeddings of pixel i from the student and teacher networks, respectively. The total loss for unlabeled data is as follows:</p><formula xml:id="formula_10">L unlabeled = L pseudo + L contra .<label>(11)</label></formula><p>Note that labeled data are also involved in training through L labeled . When training is completed, only the student network is used at inference since the others, including ELN, are all auxiliary modules that support semi-supervised learning of the student.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Network Architecture</head><p>We use DeepLab v3+ <ref type="bibr" target="#b7">[8]</ref> with ResNet <ref type="bibr" target="#b17">[18]</ref> backbone as our segmentation network since it has been adopted in  <ref type="table">Table 2</ref>. mIoU value in the Cityscapes val set with different labeled-unlabeled ratios. All results of our experiments are averaged from three different subsets of the same ratio. recent papers <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35]</ref> and shares a similar structure with Deeplab v2 <ref type="bibr" target="#b5">[6]</ref>, that has been widely used in literature <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b37">38]</ref>. The proposed model mainly consists of two types of networks, the main segmentation network and the ELN. Each network is formed with an encoder and decoder. The encoder includes a ResNet <ref type="bibr" target="#b17">[18]</ref> backbone, and the decoder (including the auxiliary decoders) contains sub-modules such as an atrous spatial pyramid pooling layer <ref type="bibr" target="#b5">[6]</ref>, a pixel-wise classifier for segmentation (Seg in <ref type="figure">Fig. 1)</ref>, and a projector for feature embedding (Proj in <ref type="figure">Fig. 1</ref>). The last two modules are implemented by two 1 ? 1 convolutional layers and one intermediate ReLU activation layer.</p><p>We adopt ResNet-50 or ResNet-101 as the backbone of the main network, and ResNet-34 for ELN. The backbones are pre-trained on ImageNet, but since the input to ELN is the concatenation of an image and tensors, its first convolutional layer is accordingly re-designed and fine-tuned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>Datasets. We conduct experiments on two different datasets, PASCAL VOC 2012 <ref type="bibr" target="#b11">[12]</ref> and Cityscapes <ref type="bibr" target="#b9">[10]</ref>. PASCAL VOC 2012 is a standard semantic segmentation dataset consisting of 21 classes including the background class. The dataset has three separate subsets for training, validation, and testing; the subsets consist of 1464, 1449, 1456 images, respectively. Following the common practice, we use additional 9118 training images from the Segmentation Boundary (SBD) Dataset <ref type="bibr" target="#b16">[17]</ref>. During training on PASCAL VOC 2012, we resize images to 512 ? 512 pixels. Cityscapes <ref type="bibr" target="#b9">[10]</ref> is a dataset of urban driving scenes with 19 classes for objects and background stuffs. It consists of training, validation, and testing splits with 2975, 500, and 1525 images, respectively. Images of the dataset is randomly cropped to 512 ? 1024. Data augmentation. Random horizontal flip is applied to both training datasets with the probability of 0.5. As the perturbation operator for the semi-supervised learning, we adopt color jittering and random grayscale with the probability of 0.2. Optimizer. AdamW <ref type="bibr" target="#b33">[34]</ref> is adopted with learning rate 1e-4 and weight decay 1e-5. Hyper-parameters. For both labeled and unlabeled data, the size of a mini-batch is 6 on PASCAL VOC 2012 and 4 on Cityscapes. We assign 20 and 50 to the first and second auxiliary decoders, respectively. The temperature value ? of L contra is set to 0.5. The update ratio ? is set to 0.995. Evaluation Metrics. We adopt the mean Intersection-over-Union (mIoU) as an evaluation metric. During evaluation, image of PASCAL VOC 2012 are resized to 512 ? 512 and those of Cityscapes are used as-is. We conduct experiments on several proportions of labeled data to unlabeled data for validating our method under different conditions. For PAS-CAL VOC 2012, we use three ratios, 1/20, 1/8, and 1/4, while 1/8, 1/4, and 1/2 are used for Cityscapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>Performance analysis on semantic segmentation. To demonstrate the superior performance of our method, we compare the method with recent state-of-the-art models and training on labeled data only (Baseline). The results of our method on PASCAL VOC 2012 are listed in <ref type="table" target="#tab_1">Table 1</ref>. We abbreviate Deeplab v2 to DL2, Deeplab v3+ to DL3+ and ResNet-50 to R50, ResNet-101 to R101. To test the performance of our method under various conditions, we conduct experiments on three ratios (1/20, 1/8, 1/4) with ResNet-50 and ResNet-101 as a backbone network, respectively. As we can see from the table, our method achieves superior performance over all other works for both backbone networks. It is considered that our error localization concept is much more effective than error correction in the semisupervised scheme from the comparison of results between ECS <ref type="bibr" target="#b34">[35]</ref> and Ours. We achieve higher performance than ECS with less labeled data; note that the performance of ECS is 70. <ref type="bibr" target="#b21">22</ref>   <ref type="table">Table 2</ref>, showing that our method still outperforms other methods. <ref type="figure">Fig. 3 and 4</ref> show qualitative results of our method under various ratio conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance analysis on error localization network.</head><p>We further conduct additional experiments to compare our method with two similar approaches to demonstrate the effectiveness of ELN. We conduct experiments on the ratio of 1/20 to PASCAL VOC 2012 with ResNet-50 as a backbone network. As the first thing to compare, we consider a simple error correction network (s-ECN) which has a similar learning strategy as ELN; s-ECN is trained with pixelwise cross-entropy loss and yields a corrected segmentation prediction as an output, not a binary mask. We choose another method, performing confidence score threshold on the output of segmentation prediction after softmax layer, without an additional network. As we can see from <ref type="table">Table 3</ref>, ELN achieves the highest mIoU value over the other two approaches. We also conduct another experiment to understand how well each method performs error localization to unseen data. In <ref type="table">Table 4</ref>, ELN shows the highest F1 score among methods. Note that results of s-ECN are worse than Threshold; it emphasizes the limitations of the error correction scheme, implying that it does not work as intended due to its harsh training condition. In <ref type="figure">Fig. 5 and 6</ref>, we display our qualitative results of segmentation prediction and its binary mask. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Studies</head><p>We conduct ablation studies to investigate the impacts of each component of the proposed method. The experiment is based on PASCAL VOC 2012 with the ratio of 1/20, and results are averaged over three times. We use ResNet-50 as the backbone of the main segmentation network. Different number of auxiliary decoders. The auxiliary decoder plays a critical role in ELN learning. We experiment with how the auxiliary decoders affect the overall performance by changing the number of auxiliary decoders and constraints parameters. The result is listed in <ref type="table">Table 5</ref>. As reported from the experiments, the performance improves as the number of decoders increases and a high loss constrain value is applied. It shows that various quality of segmen-  <ref type="table">Table 5</ref>. An ablation study for the model performance according to the number of decoders and loss constrain parameter ?.</p><formula xml:id="formula_11">Input Image GT (a) (b) (c) (d)</formula><p>tation predictions helps the effective learning of the ELN. Note that we could achieve sufficient performance improvement with only two auxiliary decoders. Different loss combination in Eq. (11). In the semisupervised learning stage, L pseudo and L contra are jointly optimized. The proposed pixel-wise contrastive loss, L contra , enables the training of feature embeddings in more diverse contexts by learning the relation between images in a batch with a standard pixel-wise cross-entropy loss L pseudo . We make a comparison to investigate effect of Threshold L pseudo L contra L pseudo + L contra 67.77 69.14 69.30 70.52 <ref type="table">Table 6</ref>. An ablation study on different loss combinations in mIoU. "Threshold" in the table is the method using none of the two losses associated with ELN but applying a confidence score threshold. each loss term in Eq. <ref type="bibr" target="#b10">(11)</ref>. As shown in <ref type="table">Table 6</ref>, each term contributes to the performance, and using both of them improves the most.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have presented a novel training framework suitable for semi-supervised semantic segmentation tasks. To mitigate the performance degradation caused by confirmation bias due to invalid pseudo labels, we have proposed error localization network (ELN) and its training scheme. Our experiments validated that ELN effectively removes error of pseudo labels for unseen data, which demonstrate that our learning strategy using erroneous predictions simulated by auxiliary decoders is helpful. Our method achieved the state of the art on both of the PASCAL VOC 2012 and Cityscapes datasets with high generalization capability.</p><p>limitations. Due to the additional auxiliary networks, our method needs a relatively larger amount of GPU memory during training, and as the number of auxiliary decoders increases, larger memory footprint is required. ELN sometimes failed to indicate erroneous predictions that the main segmentation network has strong confidence (i.e., lowentropy).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Training ELN along with the main segmentation network and the auxiliary decoders. (left) The main segmentation network is trained with the ordinary cross-entropy loss Lsup, but the auxiliary decoders are trained with constrained cross-entropy losses Laux so that they are inferior to the main segmentation network, and their predictions contain plausible and diverse errors intentionally. (right) All predictions from the decoders are used as training input to ELN, which learns to localize errors on the predictions. Note that ELN and other components are trained simultaneously, although their training processes are drawn separately in this figure for brevity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .Figure 4 .</head><label>34</label><figDesc>Qualitative results on a val set of PASCAL VOC 2012 in various proportions of labeled data to unlabeled data. Qualitative results on a val set of Cityscapes in various proportions of labeled data to unlabeled data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>Qualitative results on unlabeled data of training set on PASCAL VOC 2012 in the labeled ratio of 1/20. (a) Segmentation prediction from the main segmentation network. (b) Ground truth binary mask. (c) Binary mask predicted by ELN. (d) Filtered segmentation prediction by the predicted binary mask. Erroneous predictions colored in white in (d) are not used as pseudo labels. Qualitative results on unlabeled data of training set on Cityscapes in the labeled ratio of 1/8. (a) Segmentation prediction from the main segmentation network. (b) Ground truth binary mask. (c) Binary mask predicted by ELN. (d) Filtered segmentation prediction by the predicted binary mask. Erroneous predictions colored in white in (d) are not used as pseudo labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Student network Teacher network EMA Embedding Space ELN</head><label></label><figDesc></figDesc><table><row><cell>Concatenate</cell></row><row><cell>Forward/Backward</cell></row><row><cell>Forward Only</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>mIoU value in the PASCAL VOC 2012 val set with different labeled-unlabeled ratios. All results of our experiments are averaged from three different subsets of the same ratio.</figDesc><table><row><cell>Method</cell><cell></cell><cell cols="3">SegNet Backbone 1/20</cell><cell>1/8</cell><cell>1/4</cell><cell>Full</cell></row><row><cell>CutMix [14]</cell><cell></cell><cell>DL2</cell><cell>R101</cell><cell cols="2">66.48 67.60</cell><cell>-</cell><cell>72.54</cell></row><row><cell cols="2">S4GAN+MLMT [36]</cell><cell>DL2</cell><cell>R101</cell><cell>62.9</cell><cell>67.3</cell><cell>-</cell><cell>73.2</cell></row><row><cell>GCT [27]</cell><cell></cell><cell>DL2</cell><cell>R101</cell><cell>-</cell><cell cols="3">72.14 73.62 75.73</cell></row><row><cell>Alonso et al. [3]</cell><cell></cell><cell>DL2</cell><cell>R101</cell><cell>67.8</cell><cell>69.9</cell><cell>-</cell><cell>72.6</cell></row><row><cell>Baseline</cell><cell></cell><cell>DL3+</cell><cell>R50</cell><cell cols="4">59.88 67.63 70.56 76.6</cell></row><row><cell>ECS [35]</cell><cell></cell><cell>DL3+</cell><cell>R50</cell><cell>-</cell><cell cols="3">70.22 72.60 76.29</cell></row><row><cell>Xin et al. [29]</cell><cell></cell><cell>DL3+</cell><cell>R50</cell><cell>-</cell><cell>72.4</cell><cell>74.0</cell><cell>76.5</cell></row><row><cell>Alonso et al. [3]</cell><cell></cell><cell>DL3+</cell><cell>R50</cell><cell>69.1</cell><cell>71.8</cell><cell>-</cell><cell>75.9</cell></row><row><cell>Ours</cell><cell></cell><cell>DL3+</cell><cell>R50</cell><cell cols="3">70.52 73.20 74.63</cell><cell>-</cell></row><row><cell>Baseline</cell><cell></cell><cell>DL3+</cell><cell>R101</cell><cell cols="4">64.47 69.52 72.95 78.24</cell></row><row><cell>CutMix [14]</cell><cell></cell><cell>DL3+</cell><cell>R101</cell><cell cols="2">69.57 72.45</cell><cell>-</cell><cell>76.73</cell></row><row><cell>Xin et al. [29]</cell><cell></cell><cell>DL3+</cell><cell>R101</cell><cell>-</cell><cell>74.6</cell><cell>76.3</cell><cell>78.2</cell></row><row><cell>Ours</cell><cell></cell><cell>DL3+</cell><cell>R101</cell><cell cols="3">72.52 75.10 76.58</cell><cell>-</cell></row><row><cell>Method</cell><cell cols="3">SegNet Backbone</cell><cell>1/8</cell><cell>1/4</cell><cell>1/2</cell><cell>Full</cell></row><row><cell>CutMix [14]</cell><cell cols="2">DL2</cell><cell>R101</cell><cell cols="2">60.34 63.87</cell><cell>-</cell><cell>67.68</cell></row><row><cell>S4GAN [36]</cell><cell cols="2">DL2</cell><cell>R101</cell><cell>59.3</cell><cell>61.9</cell><cell>-</cell><cell>65.8</cell></row><row><cell>Alonso et al. [3]</cell><cell cols="2">DL2</cell><cell>R101</cell><cell>63.0</cell><cell>64.8</cell><cell>-</cell><cell>66.4</cell></row><row><cell>Baseline</cell><cell cols="2">DL3+</cell><cell>R50</cell><cell cols="4">59.88 61.86 67.63 77.70</cell></row><row><cell>ECS [35]</cell><cell cols="2">DL3+</cell><cell>R50</cell><cell cols="4">67.38 70.70 72.89 74.76</cell></row><row><cell>Xin et al. [29]</cell><cell cols="2">DL3+</cell><cell>R50</cell><cell>69.7</cell><cell>72.7</cell><cell>-</cell><cell>77.5</cell></row><row><cell cols="3">Alonso et al. [3] DL3+</cell><cell>R50</cell><cell>70.0</cell><cell>71.6</cell><cell>-</cell><cell>74.2</cell></row><row><cell>Ours</cell><cell cols="2">DL3+</cell><cell>R50</cell><cell cols="3">70.33 73.52 75.33</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>in the 1/8 ratio, while Ours is 70.52 in the Method ELN s-ECN Threshold mIoU 70.52 67.14 67.77Table 3. mIoU value of ELN, s-ECN and confidence score threshold method. The experiment is conducted in a val set of PASCAL VOC 2012.</figDesc><table><row><cell>Method</cell><cell>ELN</cell><cell cols="2">s-ECN Threshold</cell></row><row><cell cols="3">Precision 0.6961 0.7060</cell><cell>0.7054</cell></row><row><cell>Recall</cell><cell cols="2">0.9673 0.8294</cell><cell>0.8783</cell></row><row><cell>F1 score</cell><cell cols="2">0.7881 0.7424</cell><cell>0.7627</cell></row><row><cell cols="4">Table 4. Precision, Recall, and F1 score of the ELN, s-ECN, and</cell></row><row><cell cols="4">confidence score threshold method. Reported scores are averages</cell></row><row><cell cols="4">of all the results of each image. To compare s-ECN, we only con-</cell></row><row><cell cols="4">sider its error localization ability, not a correction. The experiment</cell></row><row><cell cols="4">is conducted on the unlabeled data of the given ratio of 1/20 to</cell></row><row><cell>PASCAL VOC 2012.</cell><cell></cell><cell></cell></row><row><cell cols="4">1/20. Moreover, we conduct experiments on Cityscapes on</cell></row><row><cell cols="4">three ratios (1/8, 1/4, 1/2) to show the generalization capa-</cell></row><row><cell cols="4">bility of our method. The results are displayed in</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgement. This work was supported by Samsung Electronics Co., Ltd (IO201210-07948-01).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of instance segmentation with inter-pixel relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning pixel-level semantic affinity with image-level supervision for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with pixel-level contrastive learning from a class-wise memory bank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I?igo</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Sabater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ferstl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Montesano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><forename type="middle">C</forename><surname>Murillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Weakly supervised semantic segmentation with boundary exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Naivestudent: Leveraging semi-supervised learning in video sequences for urban scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><forename type="middle">Gontijo</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><forename type="middle">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2017" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Picie: Unsupervised semantic segmentation using invariance and equivariance in clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Utkarsh</forename><surname>Jang Hyun Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavita</forename><surname>Mall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="page" from="2021" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Causal intervention for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Hanwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tang</forename><surname>Jinhui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Xiansheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sun</forename><surname>Qianru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Neural Information Processing Systems (NeurIPS)</title>
		<meeting>Neural Information essing Systems (NeurIPS)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The Pascal Visual Object Classes (VOC) Challenge. International Journal of Computer Vision (IJCV)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dual attention network for scene segmentation</title>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<editor>Haijie Tian Yong Li Yongjun Bao Zhiwei Fang and Jing Liu Hanqing Lu Jun Fu</editor>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation needs strong, varied perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Finlayson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conference (BMVC)</title>
		<meeting>British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Are we ready for autonomous driving? the kitti vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semantic contours from inverse detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Arbel?ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Redistributing biased pseudo labels for semi-supervised semantic segmentation: A baseline investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<biblScope unit="page" from="2021" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning (ICML)</title>
		<meeting>International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Fcns in the wild: Pixel-level adversarial and constraint-based adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.02649</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ccnet: Criss-cross attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Weakly-supervised semantic segmentation network with deep seeded region growing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Universal semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarun</forename><surname>Kalluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C V</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Pixel-level cycle association: A new perspective for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueting</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Neural Information Processing Systems (NeurIPS)</title>
		<meeting>Neural Information essing Systems (NeurIPS)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A three-stage self-training framework for semisupervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rihuan</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelica</forename><surname>Aviles-Rivero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saikumar</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carola-Bibiane</forename><surname>Sch?nlieb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Guided collaborative training for pixel-wise semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanghan</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaican</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rynson</forename><forename type="middle">W H</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Weakly supervised semantic segmentation using superpixel pooling network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with directional context-aware consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Semantic segmentation with generative models: Semi-supervised learning and strong out-of-domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiqing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junlin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Kreis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Microsoft COCO: common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Semisupervised segmentation based on error-correcting supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Mendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Antonio De Souza</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rauber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Jo?o Paulo Papa, and Christoph Palm</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with high-and low level consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudhanshu</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Tatarchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonwoo</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Classmix: Segmentation-based data augmentation for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilhelm</forename><surname>Tranheden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliano</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lennart</forename><surname>Svensson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Winter Conf. on Applications of Computer Vision (WACV)</title>
		<meeting>IEEE Winter Conf. on Applications of Computer Vision (WACV)</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with crossconsistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yassine</forename><surname>Ouali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Celine</forename><surname>Hudelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myriam</forename><surname>Tami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Medical Image Computing and Computer-Assisted Intervention (MICCAI)</title>
		<meeting>Medical Image Computing and Computer-Assisted Intervention (MICCAI)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin</forename><surname>Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Neural Information Processing Systems (NeurIPS)</title>
		<meeting>Neural Information essing Systems (NeurIPS)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mining cross-image semantics for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
		<idno>2017. 4</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Neural Information Processing Systems</title>
		<meeting>Neural Information essing Systems</meeting>
		<imprint>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Domain adaptation for structured output via discriminative patch representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised semantic segmentation by contrasting object mask proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Wouter Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<biblScope unit="page" from="2021" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himalaya</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Weakly-supervised semantic segmentation by iteratively mining common object features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaodi</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huimin</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Self-training with noisy student improves imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Pixel contrastive-consistent semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanyi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Yuan2</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">c 3 -semiseg: Contrastive semi-supervised segmentation via crossset learning and dynamic class-balancing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanning</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
