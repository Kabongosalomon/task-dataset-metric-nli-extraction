<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ROBUST TEMPORAL ENSEMBLING FOR LEARNING WITH NOISY LABELS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-09-30">September 30, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abel</forename><surname>Brown</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benedikt</forename><surname>Schifferer</surname></persName>
							<email>bschifferer@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dipietro</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ROBUST TEMPORAL ENSEMBLING FOR LEARNING WITH NOISY LABELS</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-09-30">September 30, 2021</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Successful training of deep neural networks with noisy labels is an essential capability as most real-world datasets contain some amount of mislabeled data. Left unmitigated, label noise can sharply degrade typical supervised learning approaches. In this paper, we present robust temporal ensembling (RTE), which combines robust loss with semi-supervised regularization methods to achieve noiserobust learning. We demonstrate that RTE achieves state-of-the-art performance across the CIFAR-10, CIFAR-100, ImageNet, WebVision, and Food-101N datasets, while forgoing the recent trend of label filtering and/or fixing. Finally, we show that RTE also retains competitive corruption robustness to unforeseen input noise using CIFAR-10-C, obtaining a mean corruption error (mCE) of 13.50% even in the presence of an 80% noise ratio, versus 26.9% mCE with standard methods on clean data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep neural networks have enjoyed considerable success across a variety of domains, and in particular computer vision, where the common theme is that more labeled training data yields improved model performance <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b29">30]</ref>. However, performance depends on the quality of the training data, which is expensive to collect and inevitably imperfect. For example, ImageNet <ref type="bibr" target="#b9">[10]</ref> is one of the most widely-used datasets in the field of deep learning and despite over 2 years of labor from more than 49,000 human annotators across 167 countries, it still contains erroneous and ambiguous labels <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b28">29]</ref>. It is therefore essential that learning algorithms in production workflows leverage noise robust methods.</p><p>Noise robust learning has a long history and takes many forms <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b53">54]</ref>. Common strategies include loss correction and reweighting <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b44">45]</ref>, label refurbishment <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b52">53]</ref>, abstention <ref type="bibr" target="#b57">[58]</ref>, and relying on carefully constructed trusted subsets of human-verified labeled data <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b65">66]</ref>. Additionally, recent methods such as SELF <ref type="bibr" target="#b46">[47]</ref> and DivideMix <ref type="bibr" target="#b37">[38]</ref> convert the problem of learning with noise into a semi-supervised learning approach by splitting the corrupted training set into clean labeled data and noisy unlabeled data at which point semi-supervised learning methods such as Mean Teacher <ref type="bibr" target="#b56">[57]</ref> and MixMatch <ref type="bibr" target="#b3">[4]</ref> can be applied directly. In essence, these methods effectively discard a majority of the label information so as to side-step having to learning with noise at all. The problem here is that noisy label filtering tactics are imperfect resulting in corrupted data in the small labeled partition and valuable clean samples lost to the large pool of unlabeled data. Moreover, caution is needed when applying semi-supervised methods where the labeled data is not sampled i.i.d. from the pool of unlabeled data <ref type="bibr" target="#b47">[48]</ref>. Indeed, filtering tactics can be biased and irregular, driven by specification error and the underlying noise process of the label corruption. Recognizing the success of semi-supervised approaches, we ask: can we leverage the underlying mechanisms of semi-supervised learning such as entropy regularization for learning with noise without discarding our most valuable asset, the labels? that maps input features to distributions over labels f : X ? R c . The dataset of training examples containing in-sample noise is defined as</p><formula xml:id="formula_0">D = {(x i ,? i )} n i=1</formula><p>where (x i ,? i ) ? (X ? Y) and? i is the noisy version of the true label y i such that p(? i = k|y i = j, x i ) ? ? ijk . We do not consider open-set noise <ref type="bibr" target="#b58">[59]</ref>, in which there is a particular type of noise that occurs on inputs,x, rather than labels. Following most prior work, we make the simplifying assumption that the noise is conditionally independent of the input, x i , given the true labels. In this setting, we can write ? ijk = p(? i = k|y i = j) ? ? jk which is, in general, considered to be class dependent noise <ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2</ref> .</p><p>To aid in a simple and precise corruption procedure, we now depart from traditional notation and further decompose ? jk as p j ? c jk , where p j ? [0, 1] is the probability of corruption of the j-th class and c jk ? [0, 1] is the relative probability that corrupted samples of class j are labeled as class k, with c i =j ? 0, c jj = 0 and k c jk = 1. A noisy dataset with m classes can then be described as transition probabilities specified by F = diag(P ) ? C + diag(1 ? P ) ? I <ref type="bibr" target="#b0">(1)</ref> where C ? R m?m defines the system confusion or noise structure, P ? R m defines the noise intensity or ratio for each class, and I is the identity matrix. When c jk = c kj the noise is said to be symmetric and is considered asymmetric otherwise. If ratio of noise is the same for all classes then p j = p and the dataset is said to exhibit uniform noise. For the case of uniform noise, equation <ref type="formula">(1)</ref> interestingly takes the familiar form of the Google matrix equation <ref type="bibr" target="#b10">[11]</ref> as</p><formula xml:id="formula_1">F p = p ? C + (1 ? p) ? I<label>(2)</label></formula><p>Note that, by this definition, ? jj = p ? c jj = 0 which prohibits? i = y i . This ensures a true effective noise ratio of p. For example, suppose there are m = 10 classes and we wish to corrupt labels with 80% probability. Then if corrupted labels are sampled from Y rather than Y \ {y}, 1 10 ? 0.8 = 8% of the corrupted samples will not actually be corrupted, leading to a true corruption rate of 72%. Therefore, despite prescribing p = 0.8, the true effective noise ratio would be 0.72, which in turn yields a 0.08 1?0.8 = 40% increase in clean labels, and this is indeed the case in many studies <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b65">66]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Methods</head><p>Cross entropy based loss can achieve noise-robust properties by using a Box-Cox power transform to stabilize loss variance which can be shown to be a form of maximum likelihood estimation (MLE) <ref type="bibr" target="#b12">[13]</ref>. Additionally, pseudo-labeling <ref type="bibr" target="#b43">[44]</ref> can be shown to be a form of entropy regularization <ref type="bibr" target="#b15">[16]</ref> which in the framework of maximum a posterior (MAP) estimation encourages low-density separation between classes by minimizing the conditional entropy of the class probabilities of the noisy data <ref type="bibr" target="#b33">[34]</ref>. That is, by minimizing entropy, the overlap of class probability distribution can be reduced. The implicit assumption here is that classes are, in fact, well separated <ref type="bibr" target="#b6">[7]</ref>. Moreover, MAP estimation itself acts as a regularization of MLE by incorporating a priori knowledge of related training examples in order to solve the ill-posed noisy learning objective and further prevent overfitting. Indeed, entropy regularization is favorable in situations for which the joint distribution, p(x, y), is mis-specified <ref type="bibr" target="#b15">[16]</ref> which further underpins the motivation of pseudo-labeling as an apt basis for regularization. A noise-robust task loss is leveraged which can be seen as a generalization of mean absolute error (MAE) and categorical cross entropy (CCE) <ref type="bibr" target="#b64">[65]</ref>. The idea is that CCE learns quickly, but more emphasis is put on difficult samples which is prone to overfit noisy labels, while MAE treats all samples equally, providing noise-robustness but learning slowly. To exploit the benefits of both MAE and CCE, a negative Box-Cox transformation <ref type="bibr" target="#b4">[5]</ref> is used to stabilize the loss variance as</p><formula xml:id="formula_2">L q (f (x i ), y i = j) = (1 ? f j (x i ) q ) q<label>(3)</label></formula><p>where q ? (0, 1], and f j denotes the j-th element of f . Note that this loss becomes CCE for lim q?0 L q and becomes MAE/unhinged loss when q = 1.</p><p>Consistency regularization works under the assumption that a model should output similar predictions given augmented versions of the same input. This regularization strategy is a common component of semi-supervised learning algorithms with the general form of p ? (y|x aug1 ) ? p ? (y|x aug2 ) where p ? (y|x) is the predicted class distribution produced by the model having parameters ? for input x <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b51">52]</ref>. We build upon numerous variations from semi-supervised learning <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b2">3]</ref> and leverage an ensemble consistency regularization (ECR) strategy as</p><formula xml:id="formula_3">ECR = 1 |Y|N * N * i=1 p ? (y|x) ? p ? (y|A(x))<label>(4)</label></formula><p>where x is the training example, A is stochastic augmentation function reevaluated for each term in the summation, ? t = ?? t?1 + (1 ? ?)? t is a temporal moving average of model weights used to generate pseudo-label targets, and inputs are pre-processed with standard random horizontal flip and crop. In practice, this consists of initializing a copy of the initial model and maintaining an exponential moving average as training progresses. Some methods directly average multiple label predictions together at each optimization step to form a single pseudo-label target <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b37">38]</ref> but we find pseudo-label target distributions generated by ? to be better suited for the learning with noise problem due to the intrinsic ensemble nature of the weight averaging process over many optimization steps <ref type="bibr" target="#b56">[57]</ref>. In semi-supervised learning techniques, it is common to leverage a large batch-size of unlabeled data for consistency regularization. However, we found that modulating N * , rather than the batch size of the consistency term, yields a monotonic increase in model performance consistent with related works <ref type="bibr" target="#b2">[3]</ref>. Moreover, in semi-supervised learning, different batches are used for supervised and unsupervised loss terms but we find (see Section 4.4) that for the case of learning with noise, batches synchronized with task loss term yields superior performance.</p><p>The Jensen-Shannon consistency loss is used to enforce a flat response of the classifier by incentivizing the model to be stable, consistent, and insensitive across a diverse range of inputs <ref type="bibr" target="#b66">[67]</ref>. The Jensen-Shannon divergence (JSD) is minimized across distributions p orig , p aug1 , and p aug2 of the original sample x orig and its augmented variants x aug1 and x aug2 which can be understood to measure the average information that the sample reveals about the identity of its originating distribution <ref type="bibr" target="#b22">[23]</ref>. This JSD term is computed with M = (p orig + p aug1 + p aug2 )/3 and is then</p><formula xml:id="formula_4">JSD = 1 3 KL(p orig M ) + KL(p aug1 M ) + KL(p aug2 M )<label>(5)</label></formula><p>where KL(p q) is Kullback-Leibler divergence from q to p. In this way, the JSD term improves the stability of training in the presence of noisy labels and heavy data augmentation with a modest contribution to final classifier test accuracy as shown in <ref type="table" target="#tab_8">Table 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Putting It All Together</head><p>We unify the various components defined in sections 2.2 together under a single parsimonious loss function at training defined as</p><formula xml:id="formula_5">L RTE = L q + ? JSD ? JSD +? ECR ? ECR<label>(6)</label></formula><p>where the JSD term is synchronized with ECR by computing the clean distribution using p ? . Final performance is reported using ? . In practice we find AugMix <ref type="bibr" target="#b22">[23]</ref> to be most performant at high levels of label noise as AugMix layers together several stochastically sampled augmentation chains in a convex combination which mitigates input degradation but also generates highly diverse transformations. Because the ECR loss term is based on the Mean Squared Error between the probability predictions, its depends on the number of classes of the dataset since the average is calculated by the squared error per class. As we sum GCE, JSD and ECR terms, the weights ? JSD and ? ECR are adjusted so that associated loss terms have similar magnitudes.</p><p>Here, data augmentation serves dual purpose as a generic regularizer to mitigate over-fitting of noisy labels <ref type="bibr" target="#b63">[64]</ref> as well as provides additional information about the vicinity or neighborhood of the training examples which is formalized by Vicinal Risk Minimization <ref type="bibr" target="#b5">[6]</ref>. These augmented examples can be seen as drawn from a vicinity distribution of the training examples to enlarge support of the training distribution such that samples in the vicinity share the same class but does not model the relation across examples of different classes <ref type="bibr" target="#b63">[64]</ref>. Therefore, data augmentations approximate samples of nearby elements of the data manifold where the difference, ?(x) = A(x) ? x, approximates elements of its tangent space <ref type="bibr" target="#b1">[2]</ref>. In this way, the ECR term can loosely be seen as generating a set of stochastic differential constraints at each optimization step of the classification task loss. While stronger augmentation can enrich the vicinity distribution, augmentation methods such as MixUp <ref type="bibr" target="#b63">[64]</ref> and RandAugment <ref type="bibr" target="#b8">[9]</ref> can overly degrade training examples and drift off the data manifold <ref type="bibr" target="#b22">[23]</ref>. When learning with noise, it is therefore essential to leverage an augmentation process rich in variety but which also preserve the image semantics and local statistics so as to minimize the additional strain on an already ill-posed noisy learning objective. Consistent with this understanding, although RandAugment has been successfully leveraged in semi-supervised learning <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b59">60]</ref>, our experiments with RandAugment proved unsuccessful for extreme levels of label noise <ref type="table" target="#tab_8">(Table 8</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Some methods for learning with noise attempt to improve noisy learning performance head-on by leveraging augmentation as a strong regularizer to mitigate memorization of corrupted labels <ref type="bibr" target="#b63">[64]</ref> while others attempt to refurbish corrupted labels to control the accumulation of noise from mislabeled data <ref type="bibr" target="#b52">[53]</ref>. A recent theme in learning with noisy labels has been to transform the learning with noise problem into a semi-supervised one by removing the labels of training data determined to be corrupted to form the requisite dichotomy of clean labeled data and a pool of unlabeled data <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b37">38]</ref>; then directly applying semi-supervised approaches such as MixMatch <ref type="bibr" target="#b3">[4]</ref> and MeanTeacher <ref type="bibr" target="#b56">[57]</ref>. Other methods go so far as to require trusted human verified data and combine re-weighting with re-labeling into a meta optimization approach <ref type="bibr" target="#b65">[66]</ref>.</p><p>Semi-supervised learning algorithms have advanced considerably in recent years, making heavy use of both data augmentation and consistency regularization. MixMatch <ref type="bibr" target="#b3">[4]</ref> proposed a low-entropy label-guessing approach for augmented unlabeled data and mixes labeled and unlabeled data using MixUp. In MixMatch, pseudo-label targets are formed by averaging label distributions produce by the model on samples drawn from the vicinity distribution ( 1 K K p ? (y|A(x))). However, this averaging requires artificial sharpening to generate low-entropy pseudo-labels. From the MAP estimation perspective, sharpening does not add auxiliary a priori knowledge for the optimization step but rather prescribes a desirable property of the model generated label distribution. Indeed, our experiments with the use of artificial label sharpening in RTE resulted in failed training at high levels of label noise and subsequent related work recognized that stronger augmentations can result in disparate predictions so their average may not generate meaningful targets <ref type="bibr" target="#b2">[3]</ref>. ReMixMatch <ref type="bibr" target="#b2">[3]</ref> introduced augmentation anchoring which aims to minimize the entropy between label distributions produced by multiple weak and strong data augmentations of unlabeled data using a control theory augmentation approach. While pseudo-label guessing and augmentation anchoring motivate the utility of multiple augmentations of the same data, our proposed ECR for learning with noise differs in the following important ways: ECR does not use distribution alignment for "fairness", distribution averaging, or label-sharpening; ECR forms pseudo-label targets using an exponential average of model weights and is batch-synchronized with the task loss term. Finally, the recent work, FixMatch <ref type="bibr" target="#b31">[32]</ref>, proposes a simplified semi-supervised approach where the consistency regularization term uses hard pseudo-labeling for low-entropy targets together with a filtering step to remove low-confidence unlabeled examples but does not leverage multiple strong augmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section we analyze the performance of RTE against various uniform noise configurations for both symmetric and asymmetric settings, and against real-world label noise. For asymmetric noise, we test both the traditional configuration <ref type="bibr" target="#b48">[49]</ref>, typically reported by related works, and an additional configuration defined by <ref type="bibr" target="#b6">(7)</ref> which is in the spirit of <ref type="bibr" target="#b34">[35]</ref>, where we define the asymmetric noise structure using the confusion matrix of a trained shallow network. In all of these experiments, RTE outperforms existing methods. Finally, we perform additional ablation studies to better understand the contribution and synergy of the terms in equation <ref type="formula" target="#formula_5">(6)</ref> as well as to probe the efficacy of ECR.</p><p>In our first set of experiments we consider the standard CIFAR-10, CIFAR-100, and ImageNet datasets <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b9">10]</ref>. CIFAR-10 and CIFAR-100 each contain 50,000 training and 10,000 test images of 10 and 100 classes, respectively; and ImageNet contains approximately 1,000,000 training images and 50,000 validation images of 1000 classes. Additionally, we test networks trained with noisy labels against unforeseen input corruptions using CIFAR-10-C <ref type="bibr" target="#b20">[21]</ref> which was constructed by corrupting the original CIFAR-10 test set with a total of 15 noise, blur, weather, and digital corruptions under different severity levels and intensities. Classifier performance is averaged across these corruption types and severity levels to yield mean corruption error (mCE). Since CIFAR-10-C is used to measure network behavior under data shift, these 15 corruptions are not included during the training procedure. Here, CIFAR-10-C helps to establish a rigorous benchmark for image classifier robustness to better understand how models trained with noisy data might perform in safety-critical applications.</p><p>To mitigate the sensitivity of experimental results to empirical, and perhaps arbitrary, choices of hyperparameters, we present additional results that leverage Population Based Training (PBT) <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b36">37]</ref> which is a simple asynchronous optimisation algorithm that jointly optimize a population of models and their hyperparameters. In particular, PBT discovers a per-epoch schedule of hyperparameter settings rather than a static fixed configuration used over the entirety of training. These PBT schedules, for example, allow task loss L q to vary between CE and MAE loss dynamically during training and similarly the number of ECR terms N * can be modulated to realize a form of curriculum learning. Moreover, for our purposes, PBT schedules also provide a form of quasi-ablation study, as optimization of the task-loss parameter q, the number of ECR terms N * , and the ECR weight ? ECR allows for the realization of a simplified loss which forgos these components if determined maximally beneficial. We find, as in other studies, that this joint optimization of hyperparameter schedules typically results in faster wall-clock convergence and higher final performance. <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b36">37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Uniform Symmetric Noise</head><p>Training Setup. Training details can be found in Section C of the Supplementary Material. Baselines. To best interpret the effectiveness of RTE, we compare our results to many techniques for learning with noise ( <ref type="table">Table 1)</ref>. A description of each baseline method can be found in Section B in the Supplementary Material. Only two of these references provide ImageNet results trained with label noise <ref type="table" target="#tab_2">(Table 3)</ref>.</p><p>Results. Experimental results with uniform symmetric noise for both CIFAR-10 and CIFAR-100 are presented in <ref type="table">Table  1</ref> with comparisons to related work, including current state-of-the-art methods. RTE establishes new state-of-the-art performance at all noise levels and exhibits especially large performance gaps at high noise levels. At 80% noise, previous state-of-the-art was achieved by <ref type="bibr" target="#b0">[1]</ref> in the case of CIFAR-10 and by <ref type="bibr" target="#b37">[38]</ref> in the case of CIFAR-100. RTE improves performance over these methods by 7.0 absolute percentage points and 6.2 absolute percentage points, respectively. Of all of these works, only two report results on ImageNet training with noisy labels. These are included alongside RTE results in <ref type="table" target="#tab_2">Table 3</ref>, where once again we see that RTE performs favorably, improving state-of-the-art performance in terms of both top-1 accuracy and top-5 accuracy. As in <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b37">[38]</ref>, we also include loss distributions over clean and corrupt labels in <ref type="figure" target="#fig_0">Figure 1</ref>. Here we can see that RTE prevents rote memorization of noisy labels. Moreover, <ref type="table" target="#tab_1">Table 2</ref> shows that RTE retains strong corruption robustness with an mCE of 12.05% and 13.50% at noise ratios of 40% and 80% respectively, as measured using CIFAR-10-C. Put in context, experiments summarized in <ref type="table" target="#tab_1">Table  2</ref> indicate that even with extreme levels of mislabeled training data, RTE trained models have lower corruption error than models trained using standard methods using clean data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Uniform Asymmetric Noise</head><p>Training Setup. For consistency, uniform asymmetric noise experiments use the same hyperparameter configurations outlined for uniform symmetric noise. Here we test RTE performance using both the traditional asymmetric noise configuration <ref type="bibr" target="#b48">[49]</ref> typically reported by related works defined by <ref type="bibr">Equation 8</ref> in Section F of the Supplementary Material as well as an additional configuration in the spirit of <ref type="bibr" target="#b34">[35]</ref> where we define the asymmetric noise structure using the confusion matrix of a trained shallow network defined by <ref type="bibr">Equation 7</ref> in Section D of the Supplementary Material.</p><p>The asymmetric noise defined by <ref type="bibr" target="#b48">[49]</ref> in equation <ref type="formula">(8)</ref> does not corrupt all classes but rather attempts to capture a noise process whereby labelers confuse specific pairs of classes which by some is argued to be more realistic in practice <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b50">51]</ref>. We additionally consider a rich noise structure by training a shallow classifier (ResNet-10) on clean CIFAR-10 and use the resulting confusion matrix of this model to define the noise structure in equation <ref type="bibr" target="#b6">(7)</ref>. For example, this asymmetric noise process readily captures the phenomenon that objects on blue backgrounds are often confused (e.g. birds, ships, and airplanes) and its natural asymmetry where p(? i = SHIP|y i = AIRPLANE) = 0.2772 while p(? i = AIRPLANE|y i = SHIP) = 0.4603 (locations <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9]</ref> and <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b0">1]</ref> in Eq. 7). Dataset statistics are provided for an instance of CIFAR-10 with asymmetric label noise prescribed according to equation <ref type="bibr" target="#b6">(7)</ref> with a uniform noise ratio of 60% in <ref type="table">Table 11</ref> of Section F in the Supplementary Material.</p><p>Baselines. In the case of asymmetric noise as defined in <ref type="bibr" target="#b48">[49]</ref>, by equation <ref type="formula">(8)</ref>, we compare the performance of RTE against existing work. A brief description of each baseline method can be found in Section B of the Supplementary Material. In the case of asymmetric noise structure as defined in equation <ref type="formula" target="#formula_6">(7)</ref>, to our knowledge, prior work does not exist, and we report RTE performance at varied noise levels.</p><p>Results. The results for asymmetric noise as presented in related works defined in <ref type="bibr" target="#b48">[49]</ref> by equation <ref type="formula">(8)</ref> with a uniform noise ratio of 40% are shown in <ref type="table" target="#tab_3">Table 4</ref> along side the performance of related methods. Again, RTE improves the state-of-the-art performance in this category, with a 1.1 absolute percentage point increase over <ref type="bibr" target="#b37">[38]</ref>. <ref type="table">Table 1</ref>: Test accuracy on CIFAR-10 and CIFAR-100 under uniform symmetric label noise. Results in parentheses are upper bounds since they were computed using lower noise levels (see sect. 2.1 for discussion). Note, our GCE-only results use true noise of 80%, rather than the 72% from the original GCE paper <ref type="bibr" target="#b64">[65]</ref>. The results for Reed-Hard, S-Model <ref type="bibr" target="#b14">[15]</ref>, Forward T and Co-Teaching are from <ref type="bibr" target="#b46">[47]</ref> and the results for MixUp and Meta-Learning are from <ref type="bibr" target="#b37">[38]</ref>. Finally, Polulation Based Training (PBT, see sect. 4 for discussion) was used only for RTE (PBT) experiments. That is, all non-CIFAR experiments, as well as the 'manual' CIFAR experiments, including baseline configurations, were performed without PBT. The configurations for RTE (manual) and alternative configurations based on <ref type="bibr" target="#b2">[3]</ref> and <ref type="bibr" target="#b22">[23]</ref>. RTE provides better robustness to label noise than all other methods. Higher is better.    Test accuracy for different level of asymmetric noise using C defined by <ref type="formula" target="#formula_6">(7)</ref> are shown in <ref type="table">Table 5</ref>. Even with 60% noise ratio, RTE achieves 93.99% test accuracy. The first significant decline in accuracy occurs around a 65% asymmetric noise ratio, when the majority labels in a class are corrupted labels from another class. That is, for F p=0. <ref type="bibr" target="#b64">65</ref> with C defined by <ref type="formula" target="#formula_6">(7)</ref>, there are more AUTOMOBILE images labeled as TRUCKs, than actual TRUCK images labeled as TRUCK.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Real-World Data with Noisy Labels</head><p>Most prior work on learning with noisy labels focuses on synthetically added noise, as considered in the previous section. Here, we also consider two datasets with real-world label noise: WebVision <ref type="bibr" target="#b39">[40]</ref> and Food-101N <ref type="bibr" target="#b35">[36]</ref>. All experiments use ResNet-50. For WebVision, we follow the experimental setup in <ref type="bibr" target="#b37">[38]</ref>, which uses the first 50 classes that overlap with ImageNet. Hyperparameters for both datasets can be found in <ref type="table" target="#tab_9">Table 9</ref> of the Supplementary Material. Results are shown alongside prior work in <ref type="table" target="#tab_5">Tables 6 and 7</ref>. RTE leads to state-of-the-art results in both cases, increasing top-1 accuracy from 77.32% <ref type="bibr" target="#b37">[38]</ref> to 80.84% when training on WebVision and evaluating on the ImageNet validation set (which is clean), and from 85.11% to 86.46% in the case of Food-101N.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Studies</head><p>We perform various ablation studies to better understand the contribution of each term in equation <ref type="formula" target="#formula_5">(6)</ref>, probe the efficacy of ECR, and compare with alternative regularization approaches. Our ablation results are presented in <ref type="table" target="#tab_8">Table 8</ref>. These ablation studies use the training configurations defined in section 4.1 unless otherwise stated. First, because some prior work was carried out using a PreAct ResNet-18, e.g. DivideMix and M-DYR-H in <ref type="table">Table 1</ref>, we provide results with the 28-layer Wide ResNet swapped out and a PreAct ResNet-18 swapped in. We can see that RTE's performance is minimally affected by this small difference in capacity: RTE achieves 93.09% with a WRN and 92.00% with a PreAct ResNet-18, vs. 79.8% for DivideMix <ref type="bibr" target="#b37">[38]</ref> and 86.6% for M-DYR-H <ref type="bibr" target="#b0">[1]</ref>, both using PreAct ResNet-18. Next, we perform a component analysis where we remove one component at a time from equation 6 to better understand the performance contributions of each term. Removal of any term degrades performance. We also test alternative consistency regularization approaches using label guessing as proposed in MixMatch <ref type="bibr" target="#b3">[4]</ref> and augmentation anchoring from ReMixMatch <ref type="bibr" target="#b2">[3]</ref> which both underperform by significant margins compared to ECR. Moreover, our results show significant benefits in the use of EMA whereas performance degrades with the augmentation anchoring approach consistent with prior work <ref type="bibr" target="#b3">[4]</ref>. Additionally, we test if label sharpening could benefit ECR, but we find that the artificial <ref type="table">Table 5</ref>: RTE test performance on CIFAR-10 for different ratios of uniform asymmetric noise defined according to equation <ref type="bibr" target="#b6">(7)</ref>. Sharp declines in accuracy begin to occur at 65% noise due to more AUTOMOBILE images labeled as TRUCK, than actual TRUCK images labeled as TRUCK, and so on.   <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b37">[38]</ref>. Higher is better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noise</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Top-  sharpening process amplifies noisy pseudo-labels early in training and learning collapses for high noise ratios. Similarly, we find the strong linear chains of augmentations performed by RandAugment lead to training instabilities. <ref type="figure">Figure  2</ref> summarizes the comparison of ECR to a traditional semi-supervised approach where a larger batch size is used for unsupervised regularization terms. This comparison indicates improved noisy learning performance with batch synchronization and repeated augmentation over larger batch sizes with single augmentations, validating the use of ECR for learning with noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We introduced robust temporal ensembling (RTE), which unifies semi-supervised regularization approaches and noise robust task loss as an effective method for learning with noisy labels. Rather than discarding noisy labels and applying semi-supervised methods, we successfully demonstrated a new approach for learning with noise which leverages all the data together without the need to filter, refurbish, or abstain from noisy training examples. Through various experiments, we showed that RTE performs quite well in practice, advancing state-of-the-art performance across the : RTE ablation study using CIFAR-10 with uniform symmetric noise ratio of 80%. Left: the ECR batch entries are shared with the task loss and the batch size is fixed at 128, while the number of ECR terms (N * ) is varied. Right: 1 ECR term is used with varying ECR batch size, using batch entries that are distinct from the task loss (analogous to a more traditional semi-supervised approach). The dashed red line on the right is the ECR baseline established using N * = 8.</p><p>CIFAR-10, CIFAR-100, and ImageNet datasets by 7.0, 6.2, and 3.5 absolute percentage points, respectively. Moreover, we demonstrated that RTE also performs well when training with data that exhibits real label noise, achieving state-ofthe-art results on the WebVision and Food-101N datasets. In addition, experiments summarized in <ref type="table" target="#tab_1">Tables 5 and 2</ref> show that despite significant label noise, RTE trained models retain lower corruption error on unforeseen data shifts than models trained using standard methods on clean data. Finally, the results of numerous ablations summarized in section 4.4 validate the composition of loss terms and their combined efficacy over alternative methods. In future work, we are interested in the application of RTE for different modalities such as natural language processing and speech where label noise can be more pervasive and subjective. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Hyperparameters</head><p>We include manual hyperparameter configurations in <ref type="table" target="#tab_9">Table 9</ref>. The configurations for CIFAR-10 and CIFAR-100 are based on <ref type="bibr" target="#b2">[3]</ref> and <ref type="bibr" target="#b22">[23]</ref>. Experiment configurations were based on <ref type="bibr" target="#b22">[23]</ref> for ImageNet, <ref type="bibr" target="#b37">[38]</ref> for Webvision, and <ref type="bibr" target="#b17">[18]</ref> for Food101N to facilitate comparison of results. <ref type="table">Table 1</ref> In this section we provide a brief summary of the baseline methods in the main text:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Baselines for</head><p>[50] introduce two methods for achieving prediction consistency, one based on reconstruction and one based on bootstrapping, and demonstrated empirically that bootstrapping leads to better robustness to label noise. <ref type="bibr" target="#b14">[15]</ref> model the correct label as latent and having gone through a parameterized corruption process. Expectation maximization is used to estimate both the parameters of the corruption process and the underlying latent label. <ref type="bibr" target="#b27">[28]</ref> introduce the idea of learning a curriculum-learning strategy with a mentor model to train a student model to be robust to label noise. <ref type="bibr" target="#b48">[49]</ref> estimate the noise transition matrix (under the assumption of feature independent noise) and show that, given the true noise transition matrix, optimizing for the true underlying labels is possible. <ref type="bibr" target="#b58">[59]</ref> introduce an iterative scheme that combines 1. outlier detection in feature space (acting as a proxy to noisy-label detection), 2. a Siamese network (taking either a clean, clean pair or a clean, noisy pair) to encourage separation, and 3. sample reweighting based on clean vs. noisy confidence levels in order to effectively filter out noisy labels during training. They focus primarily on open-set noise, but they also report performance of their system when used in the closed-set setting. <ref type="bibr" target="#b50">[51]</ref> use a meta-learning approach to dynamically weight examples to minimize loss using a set of validation examples with clean labels, however they also report a competitive baseline using a randomized weighting scheme which requires no clean validation set. <ref type="bibr" target="#b26">[27]</ref> formulate example weighting as a bilevel-optimization problem, in which performance on a validation set is maximized with respect to example weights, subject to the constraint that the model maximizes performance on the training set; and they argue that this approach should lead to better generalization when label noise is present. <ref type="bibr" target="#b64">[65]</ref> introduce a loss function that is a generalization of cross-entropy loss and mean absolute error, which is beneficial since each exhibits distinct desirable properties: cross-entropy exhibits better gradient properties for learning, while mean absolute error exhibits better theoretically-grounded robustness to noisy labels. <ref type="bibr" target="#b16">[17]</ref> leverage co-teaching such that two networks are trained together, in which each network 1. identifies high-confidence examples, 2. passes this information in a message to its peer, and 3. leverages the incoming message to optimize using the examples selected by its peer. <ref type="bibr" target="#b63">[64]</ref> train using convex combinations of both input images and their labels, arguing that this approach makes it more difficult for the network to memorize corrupt labels. </p><formula xml:id="formula_6">? ? ? ? ? ? ? ? ? ? ? ? ? ?<label>(7)</label></formula><p>that the estimated label distribution stays close to the noisy labels provided with the training set.</p><p>[39] subject a student model to artificial label noise during training and take alternating gradient steps and maintain a teacher model that is not subjected to such noise. Here, alternating gradient steps are taken to 1. minimize classification loss and 2. minimize the KL divergence from the student's predicted distributions to the teacher's predicted distributions. <ref type="bibr" target="#b46">[47]</ref> use discrepancy between an ensemble-based teacher model and labels to identify and filter out incorrect labels, and continue to leverage these samples without the labels. This is done in a semi-supervised fashion by maintaining consistency between the teacher's predictions and the student's predictions. <ref type="bibr" target="#b37">[38]</ref> maintain two networks and for each network models loss using a mixture of Gaussians with two components (clean and noisy). Each network estimates which samples belong to each component, and the other network then uses the clean samples in a supervised manner along with the noisy labels in a semi-supervised manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Uniform Symmetric Noise Experimental Setup</head><p>For CIFAR-10, we leverage equation <ref type="formula" target="#formula_1">(2)</ref> with C 10 i =j = 1 9 and we employ a 28-layer residual network <ref type="bibr" target="#b18">[19]</ref> with a widening factor of 6 (WNR 28x6) <ref type="bibr" target="#b62">[63]</ref>, a dropout rate of 0.01 <ref type="bibr" target="#b54">[55]</ref>, ? = 0.99, AugMix with a mixture width and severity of 3, a batch size of 128, and 300 epochs of training. We optimize using SGD with Nesterov momentum of 0.9 <ref type="bibr" target="#b55">[56]</ref>, a weight decay of 0.001, and a cosine learning rate <ref type="bibr" target="#b41">[42]</ref> of 0.03 ? cos(7?k/16K), where k is the current training step and K is the total number of training steps. The RTE loss function <ref type="formula" target="#formula_5">(6)</ref> is configured with static ? JSD , ? ECR and N * of 12, 1, and 10, respectively, whereas q is scheduled according to 0.6 ? sin(13?k/16K) (which assigns small q-values in early training epochs, reaches a maximum of q = 0.6 after 180 epochs, and decreases to q = 0.33 over the remaining 120 epochs). For CIFAR-100, the setup is similar, but different hyperparameters are used; details are included in the Appendix in <ref type="table" target="#tab_9">Table 9</ref>. In addition to manual configurations, we consider PBT with a population size of 35 to optimize learning rate, weight decay, q, ? JSD , ? ECR and N * . Fastidious readers will find the complete PBT configuration defined in Appendix E. For ImageNet, ResNet50 is used and trained with SGD for 300 epochs with a stepped learning rate of 0.1, 0.01 and 0.001 which begin at epochs 0, 100 and 200 respectively. ImageNet hyperparameters are also included in the Appendix in <ref type="table" target="#tab_9">Table 9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Confusion Matrix for Uniform Asymmetric Noise</head><p>The confusion matrix for uniform asymmetric noise is given in Equation 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E PBT Experiments</head><p>PBT sampling configurations are shown in <ref type="table">Table 10</ref>, and parameter schedules are shown in <ref type="figure">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Appendix: Uniform Asymmetric Noise on CIFAR-10</head><p>The matrix C in Equation 8 defines the noise structure for uniform asymmetric noise on CIFAR-10 with following labels: AIRPLANE, AUTOMOBILE, BIRD, CAT, DEER, DOG, FROG, HORSE, SHIP, TRUCK.</p><p>Class distributions are shown in <ref type="table">Table 11</ref>. <ref type="table">Table 10</ref>: PBT sampling configuration for CIFAR-10 and CIFAR-100. We used a population size of 35, and permutation interval of 2 epochs. In the case a member inherits another checkpoint, each hyperparameter is resampled from its distribution with p = 0.25 or is multiplied with w ? Uniform(0.8, 1.2) within its parameter range with p = 0.75. In the case of N * , the previous/next hyperparameter from the ordered list is selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter</head><p>Sample </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Appendix: Extended Data and Analysis</head><p>In <ref type="table" target="#tab_1">Tables 12 and 13</ref> we include test accuracy and mean corruption error on CIFAR-10 and CIFAR-10-C. In <ref type="figure" target="#fig_2">Figure 4</ref>, we include reliability diagrams using CIFAR-10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Appendix: Compute Resources</head><p>We used an internal cluster of NVIDIA V100s for all experiments. We estimate that all experiments across all datasets (CIFAR-10, CIFAR-100, ImageNet, WebVision, and Food-101N) required approximately 2,000 GPU hours. <ref type="table">Table 11</ref>: Overview of class distribution of total and correct labels after sampling noisy CIFAR-10 training labels with asymmetric noise defined by equation <ref type="formula" target="#formula_6">(7)</ref> with a uniform 60% noise ratio.  <ref type="table" target="#tab_1">Table 12</ref>: RTE test accuracy and mean corruption error (mCE) on CIFAR-10 and CIFAR-10-C, respectively. In this experiment, fixed batch size of bs = 128 is used and the number of ECR terms, N * is varied. Training configuration of these data is described in section 4.1. Test accuracy is presented in <ref type="figure">Figure 2</ref> (left).  <ref type="table" target="#tab_2">Table 13</ref>: RTE test accuracy and mean corruption error (mCE) on CIFAR-10 and CIFAR-10-C, respectively. In this experiment a single consistency loss term is used and vary the batch size of that term. This experiment with varying batch size is analogous to a more traditional semi-supervised approach where large batch size is used for unsupervised loss terms. Training configuration for these data is described in section 4.1. Test accuracy is presented in <ref type="figure">Figure 2</ref> (right).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-10</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-10</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Loss distributions for clean labels versus corrupt labels on CIFAR-10 with 40% label noise (left) and 80% label noise (right). All losses are computed with respect to the labels used during training, which mimics a realistic setting (no access to clean labels).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Reliability diagrams for RTE training models on CIFAR-10 with 40% uniform label noise (left) and 80% label noise (right). Perfectly calibrated models follow the black line, whereas over-confident models lie below and under-confident models lie above. This figure indicates our RTE trained model is well calibrated when trained with 40% label noise, while (perhaps justifiably) conservative when trained with a more extreme level of 80% label noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>RTE mean corruption error on CIFAR-10-C for models trained at various uniform symmetric noise ratios.</figDesc><table><row><cell cols="5">Baseline reference values for 'Standard' and 'AugMix' mCE are reported from [23] using WRN 40x2 on clean data.</cell></row><row><cell>Lower is better.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">RTE with Noise Ratio:</cell></row><row><cell></cell><cell cols="3">Standard AugMix 0%</cell><cell>40%</cell><cell>80%</cell></row><row><cell>? mCE</cell><cell>26.9</cell><cell>11.2</cell><cell cols="2">11.5 12.05 13.50</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Validation accuracy on ImageNet with 40% uniform symmetric label noise. RTE hyperparameter configuration based on<ref type="bibr" target="#b22">[23]</ref>.</figDesc><table><row><cell></cell><cell cols="2">MentorNet [28] SELF [47]</cell><cell>RTE</cell></row><row><cell># Params</cell><cell>59M</cell><cell>25.0M</cell><cell>25.6M</cell></row><row><cell>Top-1 Acc</cell><cell>65.1</cell><cell>71.31</cell><cell>74.79</cell></row><row><cell>Top-5 Acc</cell><cell>85.9</cell><cell>89.92</cell><cell>91.26</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Test accuracy on CIFAR-10 with asymmetric noise as defined in<ref type="bibr" target="#b48">[49]</ref> by equation<ref type="bibr" target="#b7">(8)</ref>. Higher is better.</figDesc><table><row><cell></cell><cell cols="2">Noise Ratio: 40%</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">GCE [65] SELF [47] PENCIL [62] DivideMix [38] RTE</cell></row><row><cell>Acc</cell><cell>64.79</cell><cell>89.07</cell><cell>91.16</cell><cell>93.40</cell><cell>94.49</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>94.82 93.99 80.55 72.12 59.70 ? mCE 11.22 11.89 13.73 25.44 33.61 44.87</figDesc><table><row><cell></cell><cell></cell><cell>Ratio</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>20%</cell><cell>40%</cell><cell>60%</cell><cell>65%</cell><cell>70%</cell><cell>72%</cell></row><row><cell>? Acc</cell><cell>95.34</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>ImageNet validation accuracy when trained on WebVision. Prior results are from</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Test accuracy on Food-101N. All methods are based on the ResNet-50 architecture. The Baseline and CleanNet results are from<ref type="bibr" target="#b35">[36]</ref>, and the Deep Self Learning result is from<ref type="bibr" target="#b17">[18]</ref>. Higher is better.</figDesc><table><row><cell>Method</cell><cell>Top-1 Acc</cell></row><row><cell>Baseline</cell><cell>81.44</cell></row><row><cell>CleanNet (hard)</cell><cell>83.47</cell></row><row><cell>CleanNet (soft)</cell><cell>83.95</cell></row><row><cell cols="2">Deep Self Learning 85.11</cell></row><row><cell>RTE</cell><cell>86.46</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Ablation study. Test accuracy reported from CIFAR-10 with 80% noisy labels. Label guessing<ref type="bibr" target="#b3">[4]</ref> and augmentation anchoring<ref type="bibr" target="#b2">[3]</ref> use a sharpening temperature of T = 0.5 as recommended in the associated related works.</figDesc><table><row><cell>Ablation</cell><cell cols="2">Test Acc Ablation</cell><cell>Test Acc</cell></row><row><cell>RTE</cell><cell>93.09</cell><cell>Label Guessing, K = 2</cell><cell>79.09</cell></row><row><cell>RTE (PreAct ResNet-18)</cell><cell>92.00</cell><cell>Aug. Anchoring, K = 2</cell><cell>83.59</cell></row><row><cell>No ECR (? ECR = 0)</cell><cell>61.91</cell><cell>Aug. Anchoring, K = 4</cell><cell>83.24</cell></row><row><cell>with CCE (q = 0)</cell><cell>76.08</cell><cell>Aug. Anchoring, K = 6</cell><cell>83.20</cell></row><row><cell>No JSD (? JSD = 0)</cell><cell>90.37</cell><cell>Aug. Anchoring, K = 2, EMA</cell><cell>77.38</cell></row><row><cell>with ECR, N  *  = 2, no EMA</cell><cell>67.23</cell><cell>ECR with Label Sharpening</cell><cell>fail</cell></row><row><cell>with ECR, N  *  = 2, no batch-sync</cell><cell>88.46</cell><cell>ECR with RandAugment</cell><cell>fail</cell></row><row><cell>with ECR, N  *  = 2, batch-sync</cell><cell>91.90</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>Manual hyperparameter configurations. The two ? values are ? JSD and ? ECR . For WebVision and Food-101N, the base b of the LR decay is computed such that the learning rate has decayed by 3 orders of magnitude at the end of training.</figDesc><table><row><cell></cell><cell cols="4">Wt. Decay ? Dropout BS</cell><cell>LR</cell><cell>?</cell><cell>q</cell><cell>N  *</cell><cell>?</cell></row><row><cell>CIFAR-10</cell><cell>.001</cell><cell>.9</cell><cell>.01</cell><cell>128</cell><cell>cos( 7?k 16K )</cell><cell cols="4">12, 1 sin( 13?k 16K ) 10 .99</cell></row><row><cell>CIFAR-100</cell><cell>.0005</cell><cell>.9</cell><cell>.01</cell><cell>128</cell><cell>0.04</cell><cell>5, 3</cell><cell>0.3</cell><cell>8</cell><cell>.99</cell></row><row><cell>ImageNet</cell><cell>.001</cell><cell>.9</cell><cell>.00</cell><cell cols="3">256 10 ?1,?2,?3 12, 10</cell><cell>0.3</cell><cell>3</cell><cell>.99</cell></row><row><cell>WebVision</cell><cell>.0001</cell><cell>.9</cell><cell>.00</cell><cell>256</cell><cell>10 ?3 ? b k</cell><cell>12, 5</cell><cell>0.3</cell><cell>3</cell><cell>.99</cell></row><row><cell>Food-101N</cell><cell>0.01</cell><cell>.9</cell><cell>.00</cell><cell cols="3">128 10 ?1,?2,?3 12, 1</cell><cell>0.1</cell><cell>2</cell><cell>.99</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc><ref type="bibr" target="#b52">[53]</ref> measure label consistency throughout training in order to determine which samples are 'refurbishable', and these samples are then 'corrected' by replacing their ground-truth label with the most frequently-predicted label.<ref type="bibr" target="#b34">[35]</ref> do not modify the training process of the underlying neural network but instead form a generative model over the final (pre-softmax) features of the neural network, and this generative distribution along with Bayes rule is then used to estimate a more robust conditional distribution over the label.<ref type="bibr" target="#b0">[1]</ref> fit a beta mixture model over the loss using two mixture components, representing clean and noisy labels, and each sample's underlying component probabilities are used to weight each sample's contribution during training. They combine this approach with MixUp<ref type="bibr" target="#b63">[64]</ref>.<ref type="bibr" target="#b61">[62]</ref> maintain a direct estimate of a distribution over true underlying labels during training, and train the parameters of a neural network by minimizing reverse KL divergence (from the model's predicted distribution to these true-label estimates). Meanwhile a 'compatibility loss' is introduced to ensure.0000 .0396 .2475 .0594 .0594 .0396 .0495 .0693 .2772 .1584 .1765 .0000 .0294 .0000 .0000 .0000 .0294 .0000 .1765 .5882 .1745 .0000 .0000 .1544 .1879 .1074 .2617 .0872 .0268 .0000 .0388 .0116 .1473 .0000 .1240 .3682 .1899 .0853 .0155 .0194 .0303 .0000 .2197 .1667 .0000 .0606 .2879 .2121 .0227 .0000 .0324 .0000 .1435 .4676 .1019 .0000 .1204 .1157 .0093 .0093 .0536 .0179 .3571 .3036 .1071 .0714 .0000 .0536 .0179 .0179 .0704 .0000 .0986 .1268 .3803 .1831 .0986 .0000 .0000 .0423 .4603 .0952 .0794 .0476 .0317 .0000 .0476 .0317 .0000 .2063 .1711 .5132 .0263 .0526 .0263 .0132 .0658 .0395 .0921 .0000</figDesc><table><row><cell></cell><cell>?</cell></row><row><cell>C =</cell><cell>? ? ? ? ? ? ? ? ? ? ? ? ?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc># samples % samples # correct labels % correct labels</figDesc><table><row><cell>AIRPLANE</cell><cell>5578</cell><cell>11%</cell><cell>1958</cell><cell>35%</cell></row><row><cell>AUTOMOBILE</cell><cell>4069</cell><cell>8%</cell><cell>2003</cell><cell>49%</cell></row><row><cell>BIRD</cell><cell>6023</cell><cell>12%</cell><cell>2017</cell><cell>33%</cell></row><row><cell>CAT</cell><cell>6205</cell><cell>12%</cell><cell>2038</cell><cell>33%</cell></row><row><cell>DEER</cell><cell>5056</cell><cell>10%</cell><cell>1986</cell><cell>39%</cell></row><row><cell>DOG</cell><cell>4480</cell><cell>9%</cell><cell>1977</cell><cell>44%</cell></row><row><cell>FROG</cell><cell>5476</cell><cell>11%</cell><cell>2019</cell><cell>37%</cell></row><row><cell>HORSE</cell><cell>4130</cell><cell>8%</cell><cell>2028</cell><cell>49%</cell></row><row><cell>SHIP</cell><cell>3896</cell><cell>8%</cell><cell>2024</cell><cell>52%</cell></row><row><cell>TRUCK</cell><cell>5087</cell><cell>10%</cell><cell>1950</cell><cell>38%</cell></row><row><cell>TOTAL</cell><cell>50000</cell><cell>100%</cell><cell>20000</cell><cell>40%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Test Acc 91.51 91.90 92.57 92.65 92.77 93.14 93.09 93.21 ? mCE 15.32 14.87 13.74 13.90 13.84 13.48 13.67 13.66</figDesc><table><row><cell cols="3">Fixed batch-size: 128</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Uniform Symmetric Noise: 80%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Vary the number of ECR terms: N  *</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell></row><row><cell>?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>Test Acc 86.54 88.95 90.32 88.46 85.87 78.13 ? mCE 19.77 17.78 16.41 18.20 20.42 28.57</figDesc><table><row><cell cols="3">Fixed ECR terms: N  *  = 1</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Uniform Symmetric Noise: 80%</cell><cell></cell><cell></cell></row><row><cell cols="3">Vary the batch size:</cell><cell></cell><cell></cell><cell></cell></row><row><cell>32</cell><cell>64</cell><cell>128</cell><cell>256</cell><cell>512</cell><cell>1024</cell></row><row><cell>?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">See<ref type="bibr" target="#b34">[35]</ref> for treatment of conditionally dependent semantic noise such that ? ijk = ? jk . 2 Note that<ref type="bibr" target="#b48">[49]</ref> define the noise transition matrix T such that T jk ? ? jk .</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E O&amp;apos;</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcguinness</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.11238</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">There are many consistent explanations of unlabeled data: Why you should average</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Athiwaratkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Finzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Remixmatch: Semi-supervised learning with distribution matching and augmentation anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An analysis of transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E P</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Vicinal risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>T. Leen, T. Dietterich, and V. Tresp</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="416" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semi-supervised classification by low density separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="volume">01</biblScope>
			<biblScope unit="page" from="57" to="64" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Understanding and utilizing deep neural networks trained with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><forename type="middle">Ben</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyu</forename><surname>Zhang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">of Proceedings of Machine Learning Research</title>
		<meeting><address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR Workshops 2020</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3008" to="3017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Google matrix analysis of directed networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Ermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><forename type="middle">M</forename><surname>Frahm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dima</forename><forename type="middle">L</forename><surname>Shepelyansky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Mod. Phys</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="1261" to="1310" />
			<date type="published" when="2015-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Imagenet: Where have we been? where are we going?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Fei</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<ptr target="http://image-net.org/challenges/talks_2017/imagenet_ilsvrc2017_v1.0.pdf" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Maximum l q -likelihood estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="753" to="783" />
			<date type="published" when="2010-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Frenay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="845" to="869" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Training deep neural-networks using a noise adaptation layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Ben-Reuven</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-01" />
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingrui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8527" to="8537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep self-learning from noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangfan</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5138" to="5147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.05027</idno>
		<title level="m">Identity Mappings in Deep Residual Networks. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2016-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using trusted data to train deep networks on labels corrupted by severe noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duncan</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10456" to="10465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Augmix: A simple method to improve robustness and uncertainty under data shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Ekin Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lakshminarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Hestness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Newsha</forename><surname>Ardalani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Kianinejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md. Mostofa Ali</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.00409</idno>
		<title level="m">Deep Learning Scaling is Predictable, Empirically. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2017-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Population Based Augmentation: Efficient Learning of Augmentation Policy Schedules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05393</idno>
		<imprint>
			<date type="published" when="2019-05" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Dalibard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Dunning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisantha</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.09846</idno>
		<title level="m">Population Based Training of Neural Networks. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2017-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep bilevel learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Jenni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="618" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<ptr target="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/" />
		<title level="m">What i learned from competing against a convnet on imagenet</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.11370</idno>
	</analytic>
	<monogr>
		<title level="m">General Visual Representation Learning. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2019-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin</forename><forename type="middle">Dogus</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Alia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Pseudo-label : The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2013 Workshop : Challenges in Representation Learning (WREPL)</title>
		<imprint>
			<biblScope unit="volume">07</biblScope>
			<biblScope unit="page">2013</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Robust inference via generative classifiers for handling noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sukmin</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Cleannet: Transfer learning for scalable image classifier training with label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuang-Huei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjun</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5447" to="5456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">A Generalized Framework for Population Based Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ola</forename><surname>Spyra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sagi</forename><surname>Perel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Dalibard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenjie</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Budden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pramod</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01894</idno>
		<imprint>
			<date type="published" when="2019-02" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dividemix: Learning with noisy labels as semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning to learn from noisy labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongkang</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><forename type="middle">S</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5051" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Webvision database: Visual learning and understanding from web data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirikur</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Preprint. arXiv, 1708</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Learning from noisy labels with distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuncheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yale</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangliang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1928" to="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Exploring the Limits of Weakly Supervised Pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.00932</idno>
		<imprint>
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
	<note>Ashwin Bharambe, and Laurens van der Maaten</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Iterative reclassification procedure for constructing an asymptotically optimal rule of allocation in discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Mclachlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">350</biblScope>
			<biblScope unit="page" from="365" to="369" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Can gradient clipping mitigate label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Singh Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sashank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagarajan</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Inderjit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambuj</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1196" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Self: Learning to filter noisy labels with self-ensembling</title>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<editor>Duc Tam Nguyen, Chaithanya Kumar Mummadi, Thi Phuong Nhung Ngo, Thi Hoai Phuong Nguyen, Laura Beggel, and Thomas Brox</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Realistic evaluation of deep semi-supervised learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin</forename><surname>Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="3235" to="3246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Qu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03683</idno>
		<title level="m">Making Deep Neural Networks Robust to Label Noise: a Loss Correction Approach. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2016-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training Deep Neural Networks on Noisy Labels with Bootstrapping. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.09050</idno>
		<title level="m">Bin Yang, and Raquel Urtasun. Learning to reweight examples for robust deep learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehran</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1163" to="1171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">SELFIE: Refurbishing unclean samples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwanjun</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minseok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae-Gil</forename><surname>Lee</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>Kamalika Chaudhuri and Ruslan Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwanjun</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minseok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae-Gil</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.08199</idno>
		<title level="m">Learning from Noisy Labels with Deep Neural Networks: A Survey. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2020-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">56</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30th International Conference on Machine Learning, ICML 2013</title>
		<imprint>
			<date type="published" when="2013-01" />
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanmoy</forename><surname>Sunil Thulasidasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gopinath</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamal</forename><surname>Chennupati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohd-Yusof</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10964</idno>
		<title level="m">Combating label noise in deep learning using abstention</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Iterative learning with open-set noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu-Tao</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12848</idno>
		<title level="m">Unsupervised Data Augmentation for Consistency Training. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2019-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.04252</idno>
		<title level="m">Self-training with Noisy Student improves ImageNet classification. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2019-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Probabilistic end-to-end noise correction for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7017" to="7025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<title level="m">Wide Residual Networks. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mert</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8778" to="8788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Distilling effective supervision from severe label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sercan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Arik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Improving the robustness of deep neural networks via stability training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4480" to="4488" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
