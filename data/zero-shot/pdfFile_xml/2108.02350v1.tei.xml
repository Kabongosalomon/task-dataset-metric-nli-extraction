<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical Aggregation for 3D Instance Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoyu</forename><surname>Chen</surname></persName>
							<email>shaoyuchen@hust.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of EIC</orgName>
								<orgName type="institution">Huazhong University of Science &amp; Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiemin</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EIC</orgName>
								<orgName type="institution">Huazhong University of Science &amp; Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of AI</orgName>
								<orgName type="institution">Huazhong University of Science &amp; Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
							<email>qian01.zhang@horizon.ai</email>
							<affiliation key="aff2">
								<orgName type="department">Horizon Robotics</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EIC</orgName>
								<orgName type="institution">Huazhong University of Science &amp; Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
							<email>xgwang@hust.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of EIC</orgName>
								<orgName type="institution">Huazhong University of Science &amp; Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Hierarchical Aggregation for 3D Instance Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Instance segmentation on point clouds is a fundamental task in 3D scene perception. In this work, we propose a concise clustering-based framework named HAIS, which makes full use of spatial relation of points and point sets.</p><p>Considering clustering-based methods may result in oversegmentation or under-segmentation, we introduce the hierarchical aggregation to progressively generate instance proposals, i.e., point aggregation for preliminarily clustering points to sets and set aggregation for generating complete instances from sets. Once the complete 3D instances are obtained, a sub-network of intra-instance prediction is adopted for noisy points filtering and mask quality scoring. HAIS is fast (only 410ms per frame) and does not require non-maximum suppression. It ranks 1st on the ScanNet v2 benchmark 1 , achieving the highest 69.9% AP 50 and surpassing previous state-of-the-art (SOTA) methods by a large margin. Besides, the SOTA results on the S3DIS dataset validate the good generalization ability. Code will be available at https://github.com/hustvl/HAIS.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the rapid development and popularization of commodity 3D sensors (Kinect, RealSense, Velodyne laser scanner, etc.), 3D scene understanding has become a hot research topic in the field of computer vision. Instance segmentation on point cloud, as the basic perception task of 3D scene understanding, is the technical foundation of a wide range of real-life applications, e.g., robotics, augmented/virtual reality, and autonomous driving.</p><p>Instance segmentation on 2D images has been exhaustively studied in the past few years <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b10">11]</ref>. Top-down methods dominate 2D instance segmentation. They first generate instance-level proposals and then predict the mask for each proposal. <ref type="bibr">Though</ref>   instance segmentation methods can be directly extended to 3D scenes, most existing 3D methods adopt a totally different bottom-up pipeline <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20]</ref>, which generates instances through clustering. However, directly clustering a point cloud into multiple instances is very difficult for the following reasons: (1) A point cloud usually contains a large number of points; <ref type="bibr" target="#b1">(2)</ref> The number of instances in a point cloud has large variations for different 3D scenes; (3) The sizes of instances vary significantly; (4) Each point has a very weak feature, i.e., 3D coordinate and color. The semantic gap between point and instance identity is huge. Thus, over-segmentation or under-segmentation are common problems and are prone to exist.</p><p>We propose a hierarchical aggregation scheme in bottom-up 3D instance segmentation networks to cope with these problems. We first aggregate points to sets with low bandwidth to avoid over-segmentation and then set aggregation with dynamic bandwidth is adopted to form complete instances. Set aggregation may absorb noisy point sets into predictions, making the aggregated instances overcomplete. Thus, we design a sub-network for outlier filtering and mask quality scoring. Based on the hierarchical aggregation and the sub-network for intra-instance prediction, we propose a novel bottom-up framework, named HAIS. HAIS achieves the state-of-the-art (SOTA) performance on both the ScanNet v2 benchmark <ref type="bibr" target="#b5">[6]</ref> and the S3DIS <ref type="bibr" target="#b0">[1]</ref> dataset. Beyond this, HAIS is efficient, only requiring a concise single-forward inference without any post-processing steps. Compared with all the existing methods, HAIS takes the lowest inference latency.</p><p>Our contributions can be summarized as follows.</p><p>? We propose a novel bottom-up framework with the hierarchical aggregation for instance segmentation on 3D point cloud. The hierarchical aggregation strategy makes up the defects of bottom-up clustering. Besides, an intra-instance prediction network is designed for generating more fine-grained instance predictions.</p><p>? Our method ranks 1st on the leaderboard of ScanNet v2 <ref type="bibr" target="#b5">[6]</ref>. HAIS also achieves the state-of-the-art result on S3DIS <ref type="bibr" target="#b0">[1]</ref>. We significantly promote the performances on various challenging datasets and demonstrate the generalization of the proposed methods.</p><p>? Our method achieves the highest efficiency among all existing methods. HAIS keeps a concise single-forward inference pipeline without any postprocessing steps. The average per-frame inference time on ScanNet v2 is only 410 ms, much faster than other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Deep Learning on Point Clouds Extracting features from point clouds is the foundation of 3D scene understanding. Deep learning equipped methods mainly include point-based ones and voxel-based ones. Point-based methods, e.g., PointNet <ref type="bibr" target="#b34">[35]</ref> and PointNet++ <ref type="bibr" target="#b35">[36]</ref>, directly operate on unstructured sets of points. Voxel-based methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b29">30]</ref> transform the unordered and unstructured point sets to ordered and structured volumetric grids, and then perform 3D sparse convolutions on the grids. We adopt voxel-based methods for more efficient feature extraction.</p><p>Proposal-based Instance Segmentation Proposal-based approaches directly generate object proposals and predict masks inside each proposal. In the 2D domain, proposalbased methods employ 2D object detectors <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">25]</ref> to generate region proposals and then predict masks inside each proposal. Mask R-CNN <ref type="bibr" target="#b15">[16]</ref> extends Faster R-CNN <ref type="bibr" target="#b36">[37]</ref> by adding a mask prediction. EmbedMask <ref type="bibr" target="#b44">[45]</ref> introduces proposal embedding and pixel embedding so that pixels are assigned to instance proposals according to their embedding similarity. In the 3D domain, GSPN <ref type="bibr" target="#b43">[44]</ref> proposes a generative shape proposal network for 3D object proposals following an analysis-by-synthesis strategy. 3D-SIS <ref type="bibr" target="#b16">[17]</ref> takes both 3D geometry and 2D color images as input and combines 2D and 3D features through the back projection for a better prediction. 3D-BoNet <ref type="bibr" target="#b42">[43]</ref> regresses a fixed set of bounding boxes and designs a novel association layer to match predicted boxes and ground truth boxes. 3D-MPA <ref type="bibr" target="#b8">[9]</ref> predicts centers of instances and employs a graph convolutional network to refine proposal features. GICN <ref type="bibr" target="#b27">[28]</ref> approximates the distributions of instance centers as Gaussian center heatmaps and uses a center selection mechanism for choosing candidates.</p><p>Clustering-based Instance Segmentation Clusteringbased approaches first predict point-wise labels and then use clustering methods to generate instance predictions. In the 2D domain, metric learning is widely used to group pixels. Fathi et al. <ref type="bibr" target="#b11">[12]</ref> compute likelihoods of pixels and group similar pixels together within an embedding space. Bai and Urtasun <ref type="bibr" target="#b1">[2]</ref> adopt energy maps to distinguish among individual instances. Kong and Fowlkes <ref type="bibr" target="#b20">[21]</ref> assign all pixels to a spherical embedding for clustering. Neven et al. <ref type="bibr" target="#b32">[33]</ref> introduce a learnable clustering bandwidth instead of learning the embedding using hand-crafted cost functions. Bert et al. <ref type="bibr" target="#b2">[3]</ref> propose a discriminative loss function which encourages the network to map each pixel to a point in feature space so that pixels belonging to the same instance lie close together while different instances are separated by a wide margin. In the 3D domain, SGPN <ref type="bibr" target="#b40">[41]</ref> proposes to learn a similarity matrix for all point pairs and merges similar points to generate instances. JSIS3D <ref type="bibr" target="#b33">[34]</ref> adopts multi-value conditional random fields to form instance predictions. MTML <ref type="bibr" target="#b21">[22]</ref> introduces a multi-task learning strategy for grouping points. OccuSeg <ref type="bibr" target="#b14">[15]</ref> adopts learnt occupancy signals to guide clustering. PointGroup <ref type="bibr" target="#b19">[20]</ref> proposes to cluster points based on dual coordinate sets and designs ScoreNet to predict scores for instances.</p><p>Our HAIS follows the clustering-based paradigm but differs from existing clustering-based methods in two terms. First, most clustering-based methods require complicated and time-consuming clustering procedures, but our HAIS adopts a much more concise pipeline and keeps high efficiency. Second, previous methods usually group points according to point-level embeddings, without the instancelevel correction. Our HAIS introduces the set aggregation and intra-instance prediction to refine the instance at the object level.  For the input point cloud, our method first employs 3D UNet-like structure with submanifold sparse convolution <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b13">14]</ref> for point-wise feature learning. Then, we use the spatial constraint of points to perform point aggregation with fixed bandwidth. Based on point aggregation results, set aggregation with dynamic bandwidth is performed to form instance proposals. The intra-instance prediction is designed for outlier filtering and mask quality scoring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>The overall architecture of HAIS is depicted in <ref type="figure" target="#fig_2">Fig. 2</ref>, which consists of four main parts. The point-wise prediction network (Sec. 3.1) extracts features from point clouds and predicts point-wise semantic labels and center shift vectors. The point aggregation module (Sec. 3.2) forms preliminary instance predictions based on point-wise prediction results. The set aggregation module (Sec. 3.3) expands incomplete instances to cover missing parts, while the intrainstance prediction network (Sec. 3.4) smooths instances to filter out outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Point-wise Prediction Network</head><p>The point-wise prediction network takes the point cloud P ? R N ?K as input, where N is the number of points and K is the number of channels. K is normally set as 6 for colors r, g, b and locations x, y, z. The submanifold sparse convolution <ref type="bibr" target="#b13">[14]</ref> is widely used in 3D perception methods <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b8">9]</ref> to extract features from point clouds. Following the common practice, we first convert the point cloud data into regular volumetric grids. Then a UNet-like structure <ref type="bibr" target="#b38">[39]</ref> composed of stacked 3D sparse convolution layers <ref type="bibr" target="#b13">[14]</ref> is used to extract voxel features F voxel . Third, we map the voxel features F voxel back to point features F point . Based on point features F point , two branches are built, one for predicting point labels and the other for predicting the per-point center shift vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic Label Prediction Branch</head><p>We apply a 2-layer Multi-Layer Perception (MLP) with a softmax layer upon F point to produce semantic scores for every class. The class with the highest score will be regraded as the predicted point label. The cross-entropy loss of semantic scores L seg is used to train this branch.</p><p>Center Shift Vector Prediction Branch Paralleled with the semantic label prediction branch, we apply a 2-layer MLP upon F point to predict the point-wise center shift vector x i ( x i ? R 3 ), which represents the offset from each point to its instance center, similar to <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20]</ref>. The instance center is defined as the coordinate mean of all points in this instance. During training, L shift is used to optimize the center shift vector prediction, which is formulated as</p><formula xml:id="formula_0">L shift = 1 pi?P 1(p i ? P fg ) ? pi?P L(p i ), L(p i ) = w(p i ) ? x gt i ? x pred i 1 ? 1(p i ? P fg ), w(p i ) = min( x gt i 2 , 1).<label>(1)</label></formula><p>1(?) is the indicator function. P and P fg denote the whole point set and the foreground point set respectively. Background points are ignored in L shift . w(p i ) serves as a point-wise weighted term. Points closer to the instance center less rely on the center shift vectors and should contribute less to the loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Point Aggregation</head><p>In the 3D space, points of the same instance are inherently adjacent to each other. It's intuitive to utilize this spatial constraint for clustering. Thus, based on the semantic label and the center shift vector, we use a basic and compact clustering method to get preliminary instances. First, as shown in <ref type="figure" target="#fig_3">Fig. 3(b)</ref>, according to the point-wise center shift vector x i , we shift every point x origin i toward its instance center, making the points of the same instance spatially closer to each other. The shifted coordinate is computed as,</p><formula xml:id="formula_1">x shift i = x origin i + x i .<label>(2)</label></formula><p>Second, we ignore background points and regard each foreground point as a node. For every pair of nodes, if they have the same semantic label and their spatial distance is smaller than a fixed spatial clustering bandwidth r point , an edge between these two nodes is created. After traversing all the pairs of node and establishing edges, the whole point cloud is separated into multiple independent sets, as shown in <ref type="figure" target="#fig_3">Fig. 3</ref>(c). Each set can be viewed as a preliminary instance prediction. <ref type="figure" target="#fig_5">Fig. 4</ref> shows the distribution of instance size (the number of points in an instance) of the ground truth and the point aggregation results. Compared with the sizes of ground truth instances, point aggregation generates a much larger number of instance predictions with small sizes. It is because center shift vectors are not totally accurate. Point aggregation cannot guarantee that all the points in an instance are grouped together. As illustrated in <ref type="figure" target="#fig_3">Fig. 3(d)</ref>, most points with accurate center shift vectors can be clustered together to form incomplete instance predictions. We call these instances "primary instances". But a minority of points with poor center shift vector predictions split from the majority and form fragmentary instances with small sizes, which we call "fragments". Fragments are too small in size to be regarded as complete instances, but are possible to be the missing part of primary instances. Considering the large number of fragments, it's not appropriate to directly filter out fragments with a hard threshold. Intuitively, we can aggregate primary instances and fragments at set level to generate complete instance predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Set Aggregation</head><p>Based on the above clues, we propose the set aggregation to smooth the instance predictions generated by point aggregation, which is shown in <ref type="figure" target="#fig_3">Fig. 3(d)</ref>. The detailed procedure is provided in Alg. 1. Briefly, if the following two conditions are satisfied, we consider the fragment m to be a part of the primary instance n. First, among all the primary instances that have the same semantic label with the fragment m, the primary instance n is the one whose geometric center is closest to the fragment m. Secondly, for the frag-  ment m and the primary instance n, the distance between their geometric center should be smaller than r set , which is the dynamic clustering bandwidth defined as, r set = max(r size , r cls ),</p><formula xml:id="formula_2">r size = ? S n prim .<label>(3)</label></formula><p>The clustering bandwidth of set aggregation is determined by r size and r cls . r size denotes the size-specific bandwidth. It is reasonable that the larger primary instances should absorb fragments in a wider range, and we consider r size relative to the square root of the primary instance n's size S n prim . r cls denotes the class-specific bandwidth, which is the statistical average instance radii of the specific class. The distribution of instance size after the set aggregation is shown in <ref type="figure" target="#fig_5">Fig. 4</ref>. A large amount of fragments are combined together with primary instances to form instances with higher quality. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Intra-instance Prediction Network</head><p>The hierarchical aggregation may mistakenly absorb fragments belonging to other instances, generating inaccurate instance predictions. Thus, we propose the intrainstance prediction network for further refining the instances, as shown in <ref type="figure">Fig. 5</ref>. First, we crop instance point cloud patches as input and use the 3D submanifold sparse convolution network to extract features inside instances. After intra-instance feature extraction, the mask branch predicts binary masks to distinguish the instance foreground and background. For every predicted instance, we choose the best matched GT (ground truth) as the mask supervision. The overlapped parts between the predicted instance and the GT are assigned with positive labels, and others are assigned with negative labels. Low quality instances (low IoU with GT) contain little instance-level information and are valueless to optimizing the mask branch. Thus, only the instances with IoU higher than 0.5 are used as training samples, while others are ignored. For mask prediction, the loss is formulated as,</p><formula xml:id="formula_3">L mask = ? 1 Nins i=1 1(iou i &gt; 0.5) ? N i ? Nins i=1 1(iou i &gt; 0.5) ? Ni j=1 y j ? log(? j ) + (1 ? y j ) ? log(1 ?? j ) ,<label>(4)</label></formula><p>where N ins denotes the number of instances and N i denotes the point number of instance i.</p><p>Besides mask prediction, the instance certainty score is needed for ranking among instances. We utilize masks for better scoring instances, as illustrated in <ref type="figure">Fig. 5</ref>. Firstly, masks are used to filter out features of background point, which would be noise for scoring. The remained foreground features are sent into a MLP with a sigmoid layer to predict the instance certainty scores. Secondly, inspired by <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23]</ref>, we regard the IoUs between predicted masks and GT masks as the mask quality and use them to supervise instance certainty. For the score prediction, the loss is formulated as,</p><formula xml:id="formula_4">L score = ? 1 N ins ? Nins i=1 iou i ? log(? i ) + (1 ? iou i ) ? log(1 ?? i ) .<label>(5)</label></formula><p>Ablation studies in Sec. 4.4 further demonstrate that using masks to assist score prediction boosts performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Multi-task Training</head><p>The whole network is trained from scratch in an endto-end manner and optimized by a joint loss consisting of several loss terms,</p><formula xml:id="formula_5">L = L seg + L shift + L mask + L score ,<label>(6)</label></formula><p>where L seg is the cross-entropy loss of semantic scores, and L shift , L mask and L score are defined in Eq. 1, 4 and 5 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">NMS-free and Single-forward Inference</head><p>Proposal-based methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b27">28]</ref>   <ref type="table">Table 2</ref>. Quantitative comparison on S3DIS <ref type="bibr" target="#b0">[1]</ref>. Methods marked with ? are evaluated on Area 5 and those marked with ? are on the 6-fold cross validation. Our method significantly outperforms previous methods in terms of mCov (coverage), mWCov (weighted coverage), mean precision (mPrec) and mean recall (mRec).</p><p>clustering-based methods <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b19">20]</ref> adopt multiple clustering strategies to generate redundant instance predictions. Thus, non-maximum suppression (NMS) or other post-processing steps which function as NMS, are widely required for removing duplicated instance predictions. But in our HAIS, one point is only clustered into a single instance in point aggregation, resulting in no overlap among instance predictions. We can directly use instance certainty scores to rank the instances and take the ones with the highest scores as final predictions, not requiring any post-processing steps. Besides, iterative clustering procedure is widely used in clustering based methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b33">34]</ref>, which refines predictions step by step but is time-consuming. In contrast, HAIS only requires a compact single-forward inference procedure to generate accurate predictions. With the NMS-free and single-forward design, HAIS keeps a much more concise pipeline with higher efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we first present our experimental settings (Sec. 4.1). Then, we provide both quantitative (Sec. 4.2) and qualitative evaluations (Sec. 4.3) to demonstrate the effectiveness of HAIS. To better validate each component of our method, we provide detailed ablation studies (Sec. 4.4). And evaluation on inference speed (Sec. 4.5) is offered to prove the efficiency of HAIS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Settings</head><p>ScanNet v2 The ScanNet v2 <ref type="bibr" target="#b5">[6]</ref> dataset is the most accepted and robust dataset in 3D instance segmentation. It contains 1, 613 scans with 3D object instance annotations. The dataset is split into the training, validation and testing set, each with 1, 201, 312, and 100 scans, respectively. 18 object categories are used for instance segmentation evaluation. To fairly compare with other works, we report results on the testing set which come from the official evaluation server. For ablation studies, we report results on the validation set. Keeping the same with the ScanNet v2 benchmark, we use the mean average precision with an IoU threshold of 0.5 (AP 50 ) as the main evaluation metric. We also report the mean average precision at the overlap 0.25 (AP 25 ) and overlaps from 0.5 to 0.95 (AP ) in the ablation study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3DIS</head><p>To validate the generalization of HAIS, we also conduct experiments on the S3DIS <ref type="bibr" target="#b0">[1]</ref> dataset. S3DIS has 3D scans across six areas with 271 scenes in total. Each point is assigned with one label out of 13 semantic classes. All the 13 classes are used in instance evaluation. We report results evaluated on both Area 5 and the 6-fold cross validation. We use coverage (mCov), weighted coverage (mW-Cov), mean precision (mPrec) and mean recall (mRec) with the IoU threshold of 0.5 as evaluation metrics. Experimental details Our model is trained on one single Titan X GPU with a batch size of 4 for 120k iterations. The initial learning rate is 0.001 and decays with a cosine anneal schedule <ref type="bibr" target="#b28">[29]</ref>. For stability and efficiency, we do not adopt set aggregation during the training phase. And this does not affect the effectiveness of set aggregation during inference. We set the voxel size as 0.02m following the common practice <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b19">20]</ref>. The bandwidth r point for point aggregation is set as 0.03. ? in Eq. 3 is set as 0.01. The final predictions containing less than 100 points are filtered out before evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Quantitative Evaluation</head><p>ScanNet v2 In Tab. 1, we compare our HAIS with other methods on the unreleased testing set of ScanNet v2 <ref type="bibr" target="#b5">[6]</ref> benchmark. HAIS achieves the highest AP 50 of 69.9%, ranking the first place on the leaderboard of ScanNet v2 and surpassing the previous state-of-the-art (SOTA) work <ref type="bibr" target="#b27">[28]</ref> by 6.1%. For results on each class, our method achieves the best performance in 12 out of 18 classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3DIS</head><p>In Tab. 2, we present the results on S3DIS. HAIS achieves much higher results than other methods in terms of all the widely-used metrics (mCov, mWCov, mPre and mRec). ScanNet v2 and S3DIS are quite different in terms of category, scene style and point cloud density. The SOTA performances of HAIS on both ScanNet v2 and S3DIS prove the high generalization ability. <ref type="figure">Fig. 6</ref> visually shows the effectiveness of the hierarchical aggregation and intra-instance prediction. For objects with large sizes and fragmentary point clouds, grouping all points together is quite challenging. We can observe that with the proposed hierarchical aggregation and intrainstance prediction, precise instance segmentation masks are obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Qualitative Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>To validate the design of HAIS, we perform a series of ablation studies on the ScanNet validation set.</p><p>Ablation on the Hierarchical Aggregation and Intrainstance Prediction Network Tab. 3 proves the effectiveness of the hierarchical aggregation and intra-instance prediction network. The intra-instance prediction promotes results by 2.7% AP , 2.4% AP 50 and 0.3% AP 25 . And the set aggregation further improves results by 1.0% AP , 0.7% AP 50 and 0.7% AP 25 .</p><p>Using Masks to Filter Points and Calculate IoU In the intra-instance prediction network, masks are used to assist certainty score predictions, i.e., filtering out features of background and calculating IoU which is the supervision </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Whole val set inference time (sec) Per-frame inference time (msec) SGPN <ref type="bibr" target="#b40">[41]</ref> 49433 158439 ASIS <ref type="bibr" target="#b41">[42]</ref> 56757 181913 GSPN <ref type="bibr" target="#b43">[44]</ref> 3963 12702 3D-SIS <ref type="bibr" target="#b16">[17]</ref> 38841 124490 3D-BoNet <ref type="bibr" target="#b42">[43]</ref> 2871 9202 OccuSeg <ref type="bibr" target="#b14">[15]</ref> 594 1904 PointGroup <ref type="bibr" target="#b19">[20]</ref> 141 452 GICN <ref type="bibr" target="#b27">[28]</ref> 2688 8615 HAIS 128 410 <ref type="table">Table 6</ref>. The inference time on the validation set of ScanNet v2. For fair comparison, the inference time is measured on the same type of GPU (Titan X). Our HAIS achieves much better inference speed than other methods. signal of the instance certainty, as shown in <ref type="figure">Fig. 5</ref>. An alternative method is directly using the whole instance features without filtering background points to predict scores and using the IoU between the original input instance and the GT to supervise the instance certainty. Ablation experiments in Tab. 4 show that, using masks to filter points and calculate IoU improves the results. Filtering features with the mask can avoid the influence of the background noise. And masks are much more accurate than original input instances. The IoU between the mask and GT is more suitable to be the supervision signal of the certainty score.</p><p>Filtering Mask Training Samples As shown in Tab. 5, compared with using all the instances as mask training baseline w/ intra-ins. pred. w/ hierarchical aggr. ground truth w/ hierarchical aggr. &amp; intra-ins. pred. <ref type="figure">Figure 6</ref>. Qualitative results of challenging cases of ScanNet v2 <ref type="bibr" target="#b5">[6]</ref>. Key regions are circled with red. The hierarchical aggregation and intra-instance prediction contribute to more fine-grained predictions, especially for objects with large sizes and fragmentary point clouds.</p><p>samples, it's better to filter out low quality instances with the IoU threshold of 0.5. Low quality instances usually covers few foreground points but a large amount of background points. These instances may bring ambiguity to the instance-level refinement. It's beneficial to filter them out during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Inference Speed</head><p>For real-life applications, e.g., mixed reality and autonomous driving, the inference speed of the whole network is of critical importance. We evaluate the efficiency of HAIS and compare it with other methods, as shown in Tab. 6. The single scene inference time is highly correlated to the number of points in the point cloud and varies a lot. Following the evaluation method of <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b27">28]</ref>, we use the whole validation set inference time of ScanNet v2 for fair comparison on the efficiency. HAIS only takes 128 seconds to infer all the 312 scans in the validation set, achieving the highest efficiency among all methods. On average, per scan inference latency of HAIS is 410 ms. Point-wise prediction network, point aggregation, set aggregation and the intra-instance prediction network takes 172, 125, 4, 109 ms, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We propose HAIS, a concise bottom-up approach for 3D instance segmentation. We introduce the hierarchical aggregation to generate instance predictions in a twostep manner and the intra-instance prediction for more finegrained instance predictions. Experiments on ScanNet v2 and S3DIS demonstrate the effectiveness and generalization of our method. HAIS also retains much better inference speed than all existing methods, showing its practicability in most scenarios, especially latency-sensitive ones.</p><p>In this supplementary material, we provide the detailed inference latency of main individual components of HAIS and compare it with other methods. Besides, we provide more qualitative results to demonstrate the effectiveness of HAIS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Detailed Inference Time</head><p>Tab. 7 shows the inference time of main components of different methods. Compared with other methods which require time-consuming clustering and post processing procedures, our HAIS keeps a much more efficient pipeline. The point-wise prediction network, point aggregation, set aggregation and intra-instance prediction network takes 172, 125, 4 and 109 ms, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Additional Qualitative Results</head><p>We show more qualitative results on the validation split of the ScanNet v2 dataset in <ref type="figure" target="#fig_8">Fig. 7</ref>. The predicted center shift vectors of some points are not accurate and a large amount of instance fragments come into being. By introducing the hierarchical aggregation and intra-instance prediction, HAIS generates fine-grained instance predictions. <ref type="table">Table 7</ref>. Inference time of main components of different methods on the ScanNet v2 validation set. For fair comparison, data in this table is measured on the same type of GPU (Titan X).   <ref type="bibr" target="#b5">[6]</ref>. From left to right: input point cloud, ground truth semantic label, predicted semantic label, shifted coordinate, ground truth instance mask and predicted instance mask. Best viewed in color.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>An input point cloud, ground truth instance masks and 3D instance prediction results without &amp; with hierarchical aggregation. As shown in the key region circled with red, for objects with large sizes and fragmentary point clouds, the predictions are easy to be over-segmented. The proposed hierarchical aggregation combines incomplete instances with fragments to form complete instance predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>The framework of HAIS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Illustrations of hierarchical aggregation. Points with different colors belong to different categories. Black points belong to background. (a): Points distributed in real 3D space. (b): After applying the center shift vector to each point, points belong to the same instance are closer in 3D space. (c): Point aggregation. Aggregating points into sets based on fixed spatial clustering bandwidth. (d): Set aggregation. Primary instances absorb surrounding fragments with dynamic clustering bandwidth to form complete instances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Distribution of instance size. The instance size is defined as the number of points inside an instance. Blue, green and red correspond to point aggregation results, set aggregation results and ground truth, respectively. The statistics are based on the ScanNet v2<ref type="bibr" target="#b5">[6]</ref> validation set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Algorithm 1 : 2 index = ? 1 3d 6 c m frag ? c n prim &lt; d min then 7 index = n 8 d min = c m frag ? c n prim 9 Figure 5 .</head><label>12167895</label><figDesc>Set aggregation. N frag is the number of fragments. N prim is the number of primary instances. Data: Fragments: {I 1 frag , I 2 frag , ..., I Nfrag frag } Primary instances: {I 1 prim , I 2 prim , ..., I Nprim prim } Centers of fragments: {c 1 frag , c 2 frag , ..., c Nfrag frag } Centers of primary instances: {c 1 prim , c 2 prim , ..., c Nprim prim } Class labels of fragments : {L 1 frag , L 2 frag , ..., L Nfrag frag } Class labels of primary instances: {L 1 prim , L 2 prim , ..., L Nprim prim } Dynamic set aggregation bandwidths: {r 1 set , r 2 set , ..., r Nprim set } Result: A set of refined instances: {I 1 prim , I 2 prim , ..., I Nprim prim } 1 for m = 1 ? N frag do min = +? 4 for n = 1 ? N prim do 5if L m frag == L n prim and The details of the intra-instance prediction network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>Qualitative results on ScanNet v2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>existing 2D 1 http://kaldir.vc.in.tum.de/scannet_benchmark/ semantic_instance_3d ? Xinggang Wang is the corresponding author.</figDesc><table><row><cell>point cloud</cell><cell>w/o hierarchical aggrega?on</cell></row><row><cell>ground truth</cell><cell>w/ hierarchical aggrega?on</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>50.0 51.7 46.7 22.8 42.2 13.3 40.5 11.1 20.5 24.1 7.5 23.3 30.6 44.5 43.9 45.7 97.4 23.0 3D-SIS [17] 38.2 100.0 43.2 24.5 19.0 57.7 1.3 26.3 3.3 32.0 24.0 7.5 42.2 85.7 11.7 69.9 27.1 88.3 23.5 MASC [26] 44.7 52.8 55.5 38.1 38.2 63.3 0.2 50.9 26.0 36.1 43.2 32.7 45.1 57.1 36.7 63.9 38.6 98.0 27.6 PanopticFusion [32] 47.8 66.7 71.2 59.5 25.9 55.0 0.0 61.3 17.5 25.0 43.4 43.7 41.1 85.7 48.5 59.1 26.7 94.89.5 80.0 48.0 67.6 14.4 73.7 35.4 44.7 40.0 36.5 70.0 100.0 56.9 83.6 59.9 100.0 47.3 HAIS 69.9 100.0 84.9 82.0 67.5 80.8 27.9 75.7 46.5 51.7 59.6 55.9 60.0 100.0 65.4 76.7 67.6 99.4 56.0 Quantitative comparison on the testing set of ScanNet v2 [6] benchmark. Our HAIS achieves the SOTA performance, outperforming all other methods by a large margin.</figDesc><table><row><cell>usually require dense</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Point aggr. Set aggr. Intra-ins. pred. AP AP50 AP25 39.8 61.0 74.6 42.5 63.4 74.9 43.5 64.1 75.6 Ablation results on the ScanNet v2 validation set. The hierarchical aggregation and intra-instance prediction bring significant gains in terms of AP , AP50 and AP25.</figDesc><table><row><cell>Using masks to filter points and calculate IoU</cell><cell>AP</cell><cell cols="2">AP50 AP25</cell></row><row><cell></cell><cell>41.9</cell><cell>63.1</cell><cell>74.9</cell></row><row><cell></cell><cell>43.5</cell><cell>64.1</cell><cell>75.6</cell></row><row><cell cols="4">Table 4. Ablation results on ScanNet v2 validation set for evaluat-</cell></row><row><cell cols="4">ing the effectiveness of using masks to filter points and calculate</cell></row><row><cell>IoU.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Mask training samples AP</cell><cell cols="2">AP50 AP25</cell></row><row><cell>All</cell><cell>42.8</cell><cell>63.3</cell><cell>74.4</cell></row><row><cell>IoU &gt; 0.5</cell><cell>43.5</cell><cell>64.1</cell><cell>75.6</cell></row><row><cell cols="4">Table 5. Ablation results on ScanNet v2 validation set for evaluat-</cell></row><row><cell cols="4">ing the effectiveness of filtering mask training samples.</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">3d semantic parsing of large-scale indoor spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Amir Roshan Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Brilakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep watershed transform for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Semantic instance segmentation with a discriminative loss function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davy</forename><surname>Bert De Brabandere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02551</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Wanli Ouyang, Chen Change Loy, and Dahua Lin. Hybrid task cascade for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Boundary-preserving mask R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Scannet: Richly-annotated 3d reconstructions of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Instance-sensitive fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">R-FCN: object detection via region-based fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Alireza Fathi, Bastian Leibe, and Matthias Nie?ner. 3d-mpa: Multi-proposal aggregation for 3d semantic instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Bokeloh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dilated point convolutions: On the receptive field size of point convolutions on 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodora</forename><surname>Kontogianni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shusheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Shan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.01928</idno>
		<title level="m">Bin Feng, and Wenyu Liu. Instances as queries</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Semantic instance segmentation via deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><forename type="middle">Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10277</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">and Laurens van der Maaten. 3d semantic segmentation with submanifold sparse convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Engelcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Occuseg: Occupancy-aware 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<title level="m">Mask R-CNN. PAMI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">3d-sis: 3d semantic instance segmentation of RGB-D scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mask scoring R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaojin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongchao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Acquisition of localization confidence for accurate object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruixuan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tete</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pointgroup: Dual-set point grouping for 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Recurrent pixel embedding for instance grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">3d instance segmentation via multi-task metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Lahoud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">R</forename><surname>Oswald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">GS3D: an efficient 3d object detection framework for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fully convolutional instance-aware semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">MASC: multi-scale affinity with sparse convolution for 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasutaka</forename><surname>Furukawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.04478</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Path aggregation network for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifang</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning gaussian instance segmentation in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Hung</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shang-Yi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shao-Chi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwann-Tzong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyng-Luh</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.09860</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SGDR: stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Voxnet: A 3d convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><forename type="middle">A</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Partnet: A largescale benchmark for fine-grained and hierarchical part-level 3d object understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subarna</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Panopticfusion: Online volumetric semantic mapping at the level of stuff and things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaku</forename><surname>Narita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Seno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoya</forename><surname>Ishikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohsuke</forename><surname>Kaji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Instance segmentation by jointly optimizing spatial embeddings and clustering bandwidth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davy</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><forename type="middle">De</forename><surname>Brabandere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">JSIS3D: joint semanticinstance segmentation of 3d point clouds with multi-task pointwise networks and multi-value conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quang-Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duc</forename><forename type="middle">Thanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binh-Son</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Roig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai-Kit</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Faster R-CNN: towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Octnet: Learning deep 3d representations at high resolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Osman Ulusoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Segcloud: Semantic segmentation of 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">B</forename><surname>Tchapmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
		<idno>3DV</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">SGPN: similarity group proposal network for 3d point cloud instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiangui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Associatively segmenting instances and semantics in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Learning object bounding boxes for 3d instance segmentation on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Markham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Trigoni</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">GSPN: generative shape proposal network for 3d instance segmentation in point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minhyuk</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Embedmask: Embedding coupling for one-stage instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaojin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianjia</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.01954</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
