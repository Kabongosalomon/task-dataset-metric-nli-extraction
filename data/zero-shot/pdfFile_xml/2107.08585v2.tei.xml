<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rethinking binary hyperparameters for deep transfer learning for image classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo</forename><surname>Plested</surname></persName>
							<email>j.plested@unsw.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of New</orgName>
								<address>
									<addrLine>South Wales Northcott Dr</addrLine>
									<postCode>2612</postCode>
									<settlement>Campbell</settlement>
									<region>ACT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuyang</forename><surname>Shen</surname></persName>
							<email>xuyang.shen@anu.edu.au</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Australian National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Gedeon</surname></persName>
							<email>tom.gedeon@anu.edu.au</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Australian National University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Rethinking binary hyperparameters for deep transfer learning for image classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The current standard for a variety of computer vision tasks using smaller numbers of labelled training examples is to fine-tune from weights pre-trained on a large image classification dataset such as ImageNet. The application of transfer learning and transfer learning methods tends to be rigidly binary. A model is either pre-trained or not pre-trained. Pre-training a model either increases performance or decreases it, the latter being defined as negative transfer. Application of L2-SP regularisation that decays the weights towards their pre-trained values is either applied or all weights are decayed towards 0. This paper re-examines these assumptions. Our recommendations are based on extensive empirical evaluation that demonstrate the application of a non-binary approach to achieve optimal results. (1) Achieving best performance on each individual dataset requires careful adjustment of various transfer learning hyperparameters not usually considered, including number of layers to transfer, different learning rates for different layers and different combinations of L2SP and L2 regularization. (2) Best practice can be achieved using a number of measures of how well the pre-trained weights fit the target dataset to guide optimal hyperparameters. We present methods for non-binary transfer learning including combining L2SP and L2 regularization and performing non-traditional fine-tuning hyperparameter searches. Finally we suggest heuristics for determining the optimal transfer learning hyperparameters. The benefits of using a non-binary approach are supported by final results that come close to or exceed state of the art performance on a variety of tasks that have traditionally been more difficult for transfer learning.</p><p>Preprint. Under review. arXiv:2107.08585v2 [cs.CV] 30 Aug 2021 1. More closely related datasets can be better than more source data for pre-training <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b32">33]</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Convolutional neural networks (CNNs) have achieved many successes in image classification in recent years <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>. It has been consistently demonstrated that CNNs work best when there is abundant labelled data available for the task and very deep models can be trained <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b13">14]</ref>. However, there are many real world scenarios where the large amounts of training data required to obtain the best performance cannot be met or are prohibitively expensive. Transfer learning has been shown to improve performance in a wide variety of computer vision tasks, particularly when the source and target tasks are closely related and the target task is small <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b36">37]</ref>. It has become standard practice to pre-train on Imagenet 1K for many different tasks where the available labeled datasets are orders of magnitude smaller than Imagenet 1K <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b8">9]</ref>. Several papers published in recent years have questioned this established paradigm. They have shown that when the target dataset is very different from Imagenet 1K and a reasonable amount of data is available, training from scratch can match or even out perform pre-trained and fine-tuned models <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b21">22]</ref>.</p><p>The standard transfer learning strategy is to transfer all layers apart from the final classification layer, and either use a single initial learning rate and other hyperparameters for fine-tuning all layers, or freeze some layers. Given that lower layers in a deep neural network are known to be more general and higher layers more specialised <ref type="bibr" target="#b38">[39]</ref>, we argue that the binary way of approaching transfer learning and fine-tuning is counter intuitive. There is no intuitive reason to think that all layers should be treated the same when fine-tuning, or that pre-trained weights from all layers will be applicable to the new task. If transferring all layers results in negative transfer, could transferring some number of lower more general layers improve performance? If using an L2SP weight decay on all transferred layers for regularisation decreases performance over decaying towards 0, might applying the L2SP regularisation to some number of lower layers that are more applicable to the target dataset result in improved performance?</p><p>We performed extensive experiments across four different datasets to:</p><p>? re-examine the assumptions that transfer learning hyperparameters should be binary, and ? find the optimal settings for number of layers to transfer, initial learning rates for different layers, and number of layers to apply L2SP regularisation vs decaying towards 0.</p><p>We developed methods for non-binary transfer learning including combining L2SP and L2 regularization and performing non-traditional fine-tuning hyperparameter searches. We show that the optimal settings result in significantly better performance than binary settings for all datasets except the most closely related. Finally we suggest heuristics for determining the optimal transfer learning hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The standard transfer learning strategy is to transfer all layers apart from the final classification layer, then use a search strategy to find the best single initial learning rate and other hyperparameters. Several studies include extensive hyperparameter searches over learning rate and weight decay <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22]</ref>, momentum <ref type="bibr" target="#b17">[18]</ref>, and L2SP <ref type="bibr" target="#b20">[21]</ref>. This commonly used strategy originates from various works showing that performance on the target task increases as the number of layers transferred increases <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2]</ref>. All these works were completed prior to advances in residual networks <ref type="bibr" target="#b12">[13]</ref>, and other advances to improve learning for deep CNN architectures, and searches for optimal combinations of learning rates and number of layers to transfer were not performed. Additionally, in two of the works layers that were not transferred were discarded completely rather than reinitialising and training them from scratch. This resulted in smaller models with less layers transferred and a strong bias towards better results when more layers were transferred <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Further studies have shown the combination of a lower learning rate and fewer layers transferred may be optimal <ref type="bibr" target="#b29">[30]</ref>. However, again modern residual networks were not used and only very similar source and target datasets were selected.</p><p>It has been shown that the similarity between source and target datasets has a strong impact on performance for transfer learning:</p><p>4. L2SP regularization, where the weights are decayed towards their pre-trained values rather than 0 during fine-tuning, improves performance when the source and target dataset are closely related, but hinders it when they are less related <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b36">37]</ref> 5. Momentum should be lower for more closely related source and target datasets <ref type="bibr" target="#b17">[18]</ref>.</p><p>These five factors demonstrate the importance of the relationship between the source and target dataset in transfer learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>We performed evaluations on four different small target datasets, each being less than 10,000 training images. We chose one that is very similar to Imagenet 1K that transfer learning and sub methods have traditionally performed best on. This is used as a baseline for comparison to show that the default methods that perform badly on the other datasets chosen do perform well on this one. For each of the other target datasets it has been shown that traditional transfer learning strategies:</p><p>? do not perform well on them and/or ? they are very different to the source dataset used for pre-training.</p><p>We used the standard available train, validation and test splits for the three datasets for which they were available. For Caltech256-30 we used the first 30 items from each class for the train split, the next 20 for the validation split and the remainder for the test split.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Source dataset</head><p>We used Imagenet 1K as the source dataset as it is most commonly used source dataset and therefore the most suitable to demonstrate our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Target datasets</head><p>These are the final datasets that we transferred the models to and measured performance on. We used a standard 299 ? 299 image size for all datasets.</p><p>Most similar to Imagenet 1K We chose Caltech 256-30 (Caltech) <ref type="bibr" target="#b9">[10]</ref> as the most similar to Imagenet. It contains 256 different general subordinate and superordinate classes. As our focus is on small target datasets, we chose the smallest commonly used split with 30 examples per class.</p><p>Fine-grained Fine-grained object classification datasets contain subordinate classes from one particular superordinate class. We chose two where standard transfer learning has performed badly <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b14">15]</ref>. Very different to Imagenet 1K We evaluated performance on another dataset that is intuitively very different to Imagenet 1K as it consists of images depicting adjectives instead of nouns.</p><p>? Describable Textures (DTD) <ref type="bibr" target="#b4">[5]</ref>: consists of 3,760 training examples of texture images jointly annotated with 47 attributes. The texture images are collected "in the wild" by searching for texture adjectives on the web.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model</head><p>Inception v4 <ref type="bibr" target="#b35">[36]</ref> was selected for evaluation as it has been shown to have state of the art performance for transferring from Imagenet 1K to a broad range of target tasks <ref type="bibr" target="#b14">[15]</ref>.</p><p>Our code is adapted from <ref type="bibr" target="#b37">[38]</ref> and we used the publicly available pre-trained Inception v4 model. Our code is available at https://anonymous.4open.science/r/ Non-binary-deep-transfer-learning-for-image-classification-872D. We did not experiment with pre-training settings, for example removing regularization settings as suggested by <ref type="bibr" target="#b14">[15]</ref>, as it was beyond the scope of this work and the capacity of our compute resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation metric</head><p>We used top-1 accuracy for all results for easiest comparison with existing results on the chosen datasets. Graphs showing ablation studies with different hyperparameters show results on one run. Final reported results are averages and standard deviations over four runs. For all experiments we used single crop and for our final comparison to state of the art for each dataset we used an ensemble of all four runs and 10-crop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Compute resources</head><p>The experiments were run on compute nodes containing four Nvidia V100 GPUs and two 24-core Intel Xeon Scalable 'Cascade Lake' processors.</p><p>Each individual experiment in the ablation studies ran on one GPU and 12 cores from one processor. Running time varied between approximately six hours for DTD to one day for Caltech.</p><p>Each final experiment was run on a full compute node with four GPUs and two 24-core processors. Runnng time varied between approximately one day for DTD and Aircraft to two days for Caltech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Assessing the suitability of the fixed features</head><p>We first examined performance using the pre-trained Inception v4 model as a fixed feature extractor for comparison and insight into the suitability of the pre-trained features. We trained a simple fully connected neural network classification layer for each dataset and compared it to training the full model from random initialization. The comparisons for all datasets are shown in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>The class normalized Fisher score on target datasets using the pre-trained but not fine-tuned weights, was used as a measure of how well the pre-trained weights separate the classes in the target dataset <ref type="bibr" target="#b6">[7]</ref>. A larger normalized Fisher score shows more separation between classes in the feature space.</p><formula xml:id="formula_0">F (W) = T r s ?1 w s B /N c where s ?1</formula><p>w is the inverse of the within class covariance, s B is the between class covariance and N c is the number of classes for the target dataset being measured. See <ref type="bibr" target="#b6">[7]</ref> for further details.</p><p>We also calculated domain similarity between the fixed features of the source and target domain using the earth mover distance (EMD) <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b28">29]</ref> and applying the procedure defined in <ref type="bibr" target="#b5">[6]</ref>.</p><p>The domain similarity calculated using the EMD has been shown to correlate well with the improvement in performance on the target task from pre-training with a particular source dataset <ref type="bibr" target="#b5">[6]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Default settings</head><p>For the first experiment we transferred all but the final classification layer and trained all layers at the same learning rate as per standard transfer learning practice. We performed a search using the validation set to find the optimal single fine-tuning learning rate for each dataset. The results in <ref type="figure" target="#fig_1">Figure  1</ref> show the accuracy for each learning rate for each dataset.</p><p>The optimal single learning rate for Caltech, the most similar dataset to ImageNet, is an order of magnitude lower than the optimal learning rate for the fine-grained classification tasks Stanford Cars and Aircraft. This shows that the optimal weights for Caltech are much closer to the pre-trained values. The surprising result was that the optimal learning rate for DTD was very similar to Caltech and also an order of magnitude lower than Stanford Cars and Aircraft. Final results on the test set for each dataset are shown in <ref type="table" target="#tab_1">Table 2</ref>.  To the best of our knowledge the combination of learning rate and number of layers reinitialized when performing transfer learning has not been examined in modern residual models. To examine the relationship between learning rate and number of layers reinitialized, we searched for the optimal learning rate for each of 1-3 blocks of layers reinitialized across each of the four datasets. One layer is the default with the final classification layer only being reinitialized. Two and three involve reinitializing an additional one or two Inception C blocks of layers respectively as well as the final layer. For consistency we refer to both the final classification layer and the Inception C blocks as layers. <ref type="figure" target="#fig_4">Figure 4</ref>.3 shows the performance of fine-tuning with various combinations of learning rate and layers reinitialized. The optimal learning rate when reinitializing more than one layer is always lower than when reinitializing only the final classification layer. Also the optimal number of layers to reinitialize is more than one for all datasets except Cars. <ref type="table" target="#tab_2">Table 3</ref> shows the final results for the optimal learning rate and accuracy for each number of layers reinitialized.</p><p>Reinitializing more layers has a more significant effect when the optimal learning rate for reinitializing just one layer is higher Caltech and DTD have an order of magnitude lower optimal learning rates than Cars and Aircraft, but reinitializing more layers for the former results in a significant increase in accuracy whereas there is none for the latter. This result initially seems counter intuitive as Cars and Aircraft are less similar to Imagenet than Caltech and DTD. However, a lower learning rate tempers the ability of the upper layers of the model to specialise to the new domain and even very closely related source and target domains have different final classes and thus optimal feature spaces. The combination of a lower learning rate and reinitializing more layers likely allows the models to keep the closely related lower and middle layers and create new specialist upper layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Lower learning rates for lower layers works better when optimal learning rate is higher</head><p>Conventionally learning rates for different layers are set so that either all layers are fine-tuned with the same learning rate or some are frozen. The thinking is that as lower layers are more general and higher layers more task specific <ref type="bibr" target="#b38">[39]</ref> the lower layers do not need to be fine-tuned. Recent work has  shown that fine-tuning tends to work better in most cases <ref type="bibr" target="#b29">[30]</ref>. However, setting different learning rates for different layers is not generally considered. We examined the effects of applying lower learning rates to lower layers that are likely to generalise better to the target task. <ref type="figure" target="#fig_4">Figure 4</ref> shows that for the Stanford Cars and Aircraft where the optimal initial learning rate is higher, setting lower learning rates for lower layers significantly improves performance whereas for Caltech and DTD it does not. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">L2SP</head><p>The L2SP regularizer decays pre-trained weights towards their pre-trained values rather than towards zero during fine-tuning. In the standard transfer learning paradigm with only the final classification reinitialized, when the L2SP regularizer is applied the final classification layer only is decayed towards 0.</p><p>The values ? and ? are tuneable hyperparameters to control the amount of regularization applied to the pre-trained and randomly initialized layers respectively.</p><p>The original experiments showing the effectiveness of the L2SP regularizer <ref type="bibr" target="#b20">[21]</ref> were done on target datasets that are extremely similar to the source datasets used. They showed that a high level of regularization decaying towards the pre-trained weights is beneficial on these datasets. It has since been shown that the L2SP regularizer can result in minimal improvement or even worse performance when the source and target datasets are less related <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>Our results shown in <ref type="figure" target="#fig_4">Figure 4</ref> align with the original paper <ref type="bibr" target="#b20">[21]</ref> for the dataset Caltech showing that standard L2SP regularization does result in an improvement in performance over L2 regularization.</p><p>Our results also align with <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b36">37]</ref> in showing that for the datasets we have chosen to be different from Imagenet, and known to be more difficult to transfer to, L2SP regularization performs worse than L2 regularization. In general the lower the setting for alpha (the L2SP regularization hyperparameter) the better the performance.</p><p>We relaxed the binary assumption that L2SP regularization must be applied to all pre-trained layers. We used L2SP regularization for lower layers that we expected to be more similar to the source  dataset and L2 regularization for upper layers to allow them to specialise to the target dataset. We searched for the optimal combinations of L2SP and L2 weight regularization along with the ? and ? hyperparameters for each dataset. We show the best settings for number of layers and amount of L2SP regularization in <ref type="table" target="#tab_4">Table 5</ref> and graph the optimal settings compared to the best default settings in <ref type="figure" target="#fig_5">Figure 5</ref>.</p><p>We make the following observations:</p><p>1. A combination of L2SP and L2 regularization is optimal for most settings of the L2SP regularization hyperparameter (?) for all datasets except Caltech.</p><p>2. When more layers are trained with L2 rather than L2SP regularization the optimal L2 regularization hyperparameter (?) is lower as the squared sum of the weights in these layers will be larger for the same model.</p><p>Further experiments were performed to search for the combination of optimal L2SP vs L2 regularization settings with optimal number of layers transferred and different learning rates for different layers. These results are also shown in <ref type="table" target="#tab_4">Table 5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Final optimal settings and how to predict them</head><p>The final results and optimal settings are shown in <ref type="table" target="#tab_5">Table 6</ref> and <ref type="figure" target="#fig_6">Figure 6</ref>. <ref type="table" target="#tab_6">Table 7</ref> shows a clear distinction between target datasets that are more similar to the source dataset and for which the pre-trained weights are better able to separate the classes in feature space and those that are less similar with pre-trained weights that fit the target task poorly. The best measure for determining   <ref type="bibr" target="#b19">[20]</ref> 96.0 (@448) <ref type="bibr" target="#b30">[31]</ref> 93.9 (@448) <ref type="bibr" target="#b40">[41]</ref> 78.9 <ref type="bibr" target="#b2">[3]</ref> whether the pre-trained weights are well suited is a comparison of the performance achieved with fixed pre-trained features and that achieved through training from random initialization. As this method is computationally intensive a reasonable alternative may be the normalized Fisher Ratio, but as the differences are not as pronounced in all cases it should be further investigated on more datasets to see how reliable it is as a heuristic. The EMD measure of domain similarity is a poor predictor of the suitability of the pre-trained weights.</p><p>Targets datasets for which the pre-trained weights are well suited need:</p><p>? a much lower learning rate for fine-tuning,</p><p>? more than one layer to be reinitialized from random weights, and</p><p>? some or all layers trained with L2SP regularization.</p><p>Target datasets where the pre-trained weights are not well suited need:</p><p>? a much higher learning rate for fine-tuning with a lower learning rate for lower layers,</p><p>? only the final classification layer reinitialized, and ? L2 rather than L2SP regularization.</p><p>Using the above best practice, non-binary transfer learning procedures we achieved state of the art or close to, on three out of the four datasets. We used publicly available pre-trained weights and no additional methods for either pre-training or fine-tuning.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Traditional binary assumptions about transfer learning hyperparameters should be discarded in favour of a tailored approach to each individual dataset. These assumptions include transferring all possible layers or none, training all layers at the same learning rate or freezing some, and using L2SP regularization or L2 regularization for all layers. Our work demonstrates that optimal transfer learning non-binary hyperparameters are dataset dependent and strongly influenced by how well the pre-trained weights fit the target task. For a particular dataset, optimal non-binary transfer learning hyperparameters can be determined based on the difference between model performance when fixed features are used and when the full model is trained from random initialization as shown in <ref type="table" target="#tab_6">Table  7</ref>. We recommend using the settings shown on the left in this table for target datasets where the difference is negative and settings shown on the right for positive differences. Target datasets for which the pre-trained weights are well suited and target datasets for which they are not result in large differences in this value. These differences should still be pronounced even if suboptimal learning hyperparameters are used for this initial test due to limited resources for hyperparameter search. This heuristic for determining optimal hyperparameters should be useful in most transfer learning for image classification cases. The normalized Fisher Ratio may be useful in some cases, however, care should be taken because the differences are not as pronounced. The EMD domain similarity measure should not be used to determine transfer learning hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Broader Impact</head><p>This research is focused on improving transfer learning for small target image classification datasets. The positive impacts are easy to observe in improved performance of models utilising transfer learning in a wide range of real world applications. For example, faster and more accurate medical diagnostics where there is limited data available.</p><p>However, improvements to image classification models can have positive or negative impacts. More accurate models could reduce errors but result in overconfidence and more reliance on results in areas where the full limitations are not well understood and taken into account. Improved image classification models could also be used in areas with potential negative impacts, for example:</p><p>? use of intrusive facial recognition systems</p><p>? discrimination based on subtle items such as religious symbols 7 Limitations and future work</p><p>The main aim of this work is to highlight the need for a non-binary approach to achieving optimal performance in transfer learning applied to image classification on small target datasets. The relationship between the source and the target dataset and how well the pre-trained weights fit the target task has been shown to be important to transfer learning performance numerous times <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b17">18]</ref>. However, the guidance as to how to set transfer learning hyperparameters based on the heuristics presented in this paper is based only on the experiments on the four datasets outlined in this paper. Care should be taken if applying this guidance to new datasets, particularly outside of image classification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>?</head><label></label><figDesc>Stanford Cars (Cars): Contains 196 different makes and models of cars with 8,144 training examples and 8,041 test examples [16]. ? FGVC Aircraft (Aircraft): Contains 100 different makes and models of aircraft with 6,667 training examples and 3,333 test examples [23].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Optimal learning rates for each dataset. Left to right Caltech, Cars, Aircraft, DTD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Number of layers reinitialized versus learning rate. Left to right Caltech, Cars, Aircraft, DTD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Lower learning rates for lower layers. Left to right Caltech, Cars, Aircraft, DTD. Legend shows number of layers reinitialized, high learning rate, low learning rate. X axis is number layers trained starting with the low learning rate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>L2SP with default settings. Left to right Caltech, Cars, Aircraft, DTD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Best default L2SP optimal L2SP settings. Left to right Caltech, Cars, Aircraft, DTD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Optimal settings versus best default settings. Left to right Caltech, Cars, Aircraft, DTD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Domain measures</figDesc><table><row><cell></cell><cell>trained from</cell><cell>fixed features</cell><cell>EMD domain</cell><cell>normalised</cell><cell>state of the art</cell></row><row><cell></cell><cell>random initial-</cell><cell>classification</cell><cell>similarity</cell><cell>Fisher score</cell><cell></cell></row><row><cell></cell><cell>ization</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Caltech</cell><cell>67.2</cell><cell>83.4</cell><cell>0.568</cell><cell>1.35</cell><cell>84.9 [20]</cell></row><row><cell>Cars</cell><cell>92.7</cell><cell>64.2</cell><cell>0.536</cell><cell>1.18</cell><cell>96.0 (@448) [31]</cell></row><row><cell>Aircraft</cell><cell>88.8</cell><cell>59.9</cell><cell>0.557</cell><cell>0.83</cell><cell>93.9 (@448) [41]</cell></row><row><cell>DTD</cell><cell>66.8</cell><cell>74.6</cell><cell>0.540</cell><cell>3.47</cell><cell>78.9 [3]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Final results default settings</figDesc><table><row><cell></cell><cell>Caltech</cell><cell>Stanford Cars</cell><cell>Aircraft</cell><cell>DTD</cell></row><row><cell>Learning rate</cell><cell>0.0025</cell><cell>0.025</cell><cell>0.025</cell><cell>0.002</cell></row><row><cell>Accuracy</cell><cell>83.</cell><cell></cell><cell></cell><cell></cell></row></table><note>69?0.0784 94.59?0.110 93.78?0.137 77.30 ?0.726 4.3 Optimal learning rate decreases as more layers are reinitialized and transferring all possible layers often reduces performance on the target task</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Final optimal learning rate for each number of layers reinitialized</figDesc><table><row><cell></cell><cell>Caltech</cell><cell>Cars</cell><cell>Aircraft</cell><cell>DTD</cell></row><row><cell>1 layer lr</cell><cell>0.0025</cell><cell>0.025</cell><cell>0.025</cell><cell>0.002</cell></row><row><cell>Accuracy</cell><cell>83.69?0.078</cell><cell>94.59?0.110</cell><cell>93.78?0.137</cell><cell>77.30 ?0.726</cell></row><row><cell>2 layers lr</cell><cell>0.015</cell><cell>0.015</cell><cell>0.02</cell><cell>0.001</cell></row><row><cell>Accuracy</cell><cell>84.31?0.114</cell><cell>94.59? 0.205</cell><cell>93.56?0.942</cell><cell>78.92 ?0.191</cell></row><row><cell>3 layers lr</cell><cell>0.015</cell><cell>0.015</cell><cell>0.02</cell><cell>0.0015</cell></row><row><cell>Accuracy</cell><cell>83.57?0.104</cell><cell>94.46?0.348</cell><cell>92.96?1.588</cell><cell>78.90?0.243</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Optimal learning rates for each number of layers reinitialized with different learning rates for lower layers. Learning rates are in the format (high layers learning rate, low layers learning rate, number of low layers)</figDesc><table><row><cell></cell><cell>Caltech</cell><cell>Cars</cell><cell>Aircraft</cell><cell>DTD</cell></row><row><cell>Default accuracy</cell><cell>83.69?0.0784</cell><cell>94.59?0.110</cell><cell>93.78?0.137</cell><cell>77.30?0.726</cell></row><row><cell>1 layer lrs</cell><cell cols="2">0.002 0.001 12 0.025 0.01 8</cell><cell>0.025 0.015 10</cell><cell>0.0025 0.0015 10</cell></row><row><cell>Accuracy</cell><cell>83.95?0.196</cell><cell>94.86?0.0460</cell><cell>94.32 ?0.144</cell><cell>77.753?0.456</cell></row><row><cell>2 layers lrs</cell><cell cols="2">0.002 0.001 12 0.025 0.01 8</cell><cell>0.025 0.015 10</cell><cell>0.0015 0.001 14</cell></row><row><cell>Accuracy</cell><cell>84.15?0.553</cell><cell>94.78 ?0.132</cell><cell>94.17 ?0.311</cell><cell>78.59?0.127</cell></row><row><cell>3 layers lrs</cell><cell cols="2">0.002 0.001 12 0.025 0.01 10</cell><cell cols="2">0.01 0.025 0.01 8 0.0015 0.001 12</cell></row><row><cell>Accuracy</cell><cell>83.46?0.143</cell><cell cols="2">94.83 ?0.0832. 94.50 ?0.192</cell><cell>78.84 ?0.464</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Best default and optimal L2SP settings and results</figDesc><table><row><cell></cell><cell>Caltech</cell><cell>Cars</cell><cell>Aircraft</cell><cell></cell><cell>DTD</cell></row><row><cell>L2</cell><cell>83.694</cell><cell>94.59</cell><cell>93.78</cell><cell></cell><cell>77.30</cell></row><row><cell>Default L2SP 1</cell><cell>0.01 0.01</cell><cell>0.0001 0.01</cell><cell cols="2">0.0001 0.01</cell><cell>0.0001 0.01</cell></row><row><cell>new layer ?, ?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>result</cell><cell>84.52</cell><cell>94.42</cell><cell>93.29</cell><cell></cell><cell>78.32</cell></row><row><cell>Optimal L2SP 1</cell><cell>0.01 0.01</cell><cell>0.01 0.001 L2SP</cell><cell>0.0001</cell><cell>0.001</cell><cell>0.001 0.001</cell></row><row><cell>new layer ?, ?</cell><cell>L2SP layers all</cell><cell>layers 10</cell><cell cols="2">L2SP layers 10</cell><cell>L2SP layers 10</cell></row><row><cell>result</cell><cell>84.52</cell><cell>94.57</cell><cell>93.86</cell><cell></cell><cell>78.32</cell></row><row><cell>Optimal L2SP</cell><cell>0.01 0.01</cell><cell>0.01 0.001</cell><cell cols="2">0.0001 0.001</cell><cell>0.001 0.001 1.0</cell></row><row><cell>overall ?, ?</cell><cell>L2SP layers all</cell><cell>L2SP layers 10</cell><cell cols="2">L2SP layers 10</cell><cell>L2SP layers 14</cell></row><row><cell>result</cell><cell>84.52</cell><cell>94.65</cell><cell>94.22</cell><cell></cell><cell>78.90</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Optimal settings versus best default settings</figDesc><table><row><cell></cell><cell>Caltech</cell><cell>Cars</cell><cell>Aircraft</cell><cell>DTD</cell></row><row><cell cols="2">Default settings 0.0025</cell><cell>0.025</cell><cell>0.025</cell><cell>0.002</cell></row><row><cell>Default result</cell><cell>83.69</cell><cell>94.59</cell><cell>93.78</cell><cell>77.30</cell></row><row><cell>Default L2SP</cell><cell>84.52</cell><cell>94.42</cell><cell>93.29</cell><cell>78.32</cell></row><row><cell cols="2">Optimal settings 1 new layer lr</cell><cell>1 new layer</cell><cell>3 new layers</cell><cell cols="2">new layers 2</cell></row><row><cell></cell><cell>0.0025 L2SP</cell><cell>high lr 0.025 low</cell><cell>FC lr 0.01</cell><cell>lr 0.002</cell></row><row><cell></cell><cell>0.01 0.01</cell><cell>lr 0.01</cell><cell>high lr 0.025 low</cell><cell>L2SP</cell><cell>0.001</cell></row><row><cell></cell><cell></cell><cell>low layers 8</cell><cell>lr 0.01</cell><cell>0.001</cell></row><row><cell></cell><cell></cell><cell>no L2SP</cell><cell>low layers 8</cell><cell cols="2">L2SP layers 14</cell></row><row><cell></cell><cell></cell><cell></cell><cell>no L2SP</cell><cell></cell></row><row><cell>Optimal result</cell><cell>84.52</cell><cell>94.86</cell><cell>94.50</cell><cell>78.90</cell></row><row><cell>Ensemble</cell><cell>85.94</cell><cell>95.35</cell><cell>95.11</cell><cell>79.79</cell></row><row><cell>State of the art</cell><cell>84.9</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Predicting optimal settings based on pre-trained features</figDesc><table><row><cell></cell><cell cols="2">Caltech DTD</cell><cell cols="2">Cars Aircraft</cell></row><row><cell>Fisher ratio</cell><cell>1.35</cell><cell>3.47</cell><cell>1.18</cell><cell>0.83</cell></row><row><cell>EMD similarity</cell><cell>0.568</cell><cell cols="2">0.540 0.536</cell><cell>0.557</cell></row><row><cell>Random initialisation</cell><cell>-16.2</cell><cell>-7.8</cell><cell>28.5</cell><cell>28.9</cell></row><row><cell>minus fixed features</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Optimal learning rate</cell><cell>Low</cell><cell>Low</cell><cell>High</cell><cell>High</cell></row><row><cell>L2SP</cell><cell>Yes</cell><cell>Yes</cell><cell>No</cell><cell>No</cell></row><row><cell>More layers reiniti-</cell><cell>Yes</cell><cell>Yes</cell><cell>No</cell><cell>No</cell></row><row><cell>ailized</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Low layers at low</cell><cell>No</cell><cell>No</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>learning rate</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">. A multi-step pre-training process where the interim dataset is smaller and more closely related to the target dataset can outperform a single step pre-training process when originating from a very different, large source dataset<ref type="bibr" target="#b26">[27]</ref>.3. Self-supervised pre-training on a closely related source dataset can be better than supervised training on a less closely related dataset<ref type="bibr" target="#b41">[42]</ref>.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Analyzing the performance of multilayer neural networks for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pulkit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="329" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Factors of transferability for a generic convnet representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Sharif Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josephine</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuto</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1790" to="1802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Best practices for fine-tuning visual classifiers to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vashisht</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Beijbom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="435" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Describing textures in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mircea</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sammy</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3606" to="3613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Large scale fine-grained categorization and domain-specific transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4109" to="4118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Introduction to statistical pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukenaga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Academic Press</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>San Diego</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Borrowing treasures from the wealthy: Deep transfer learning through selective joint fine-tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1086" to="1095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Caltech256 object category dataset. California Institute of Technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Spottune: transfer learning through adaptive fine-tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhui</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tajana</forename><surname>Rosing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4805" to="4814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.08883</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Rethinking imagenet pre-training. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Big transfer (bit): General visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.11370</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Do better imagenet models transfer better?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2661" to="2671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International IEEE Workshop on 3D Representation and Recognition</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Rethinking the hyperparameters for fine-tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Bhotika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.11770</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep facial expression recognition: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihong</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Affective Computing</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Delta: Deep learning transfer using feature map with attention for convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanchao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Huan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09229</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Explicit inductive bias for transfer learning with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franck</forename><surname>Davoine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.01483</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Exploring the limits of weakly supervised pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="181" to="196" />
		</imprint>
	</monogr>
	<note>Ashwin Bharambe, and Laurens van der Maaten</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Fine-grained visual classification of aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>Toyota Technological Institute at Chicago</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep face recognition: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iacopo</forename><surname>Masi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prem</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 31st SIBGRAPI conference on graphics, patterns and images (SIBGRAPI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="471" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep learning in radiology: An overview of the concepts and a survey of the state of the art with focus on mri</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maciej</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Mazurowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashirbani</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><forename type="middle">R</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bashir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of magnetic resonance imaging</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="939" to="954" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Comparison of deep transfer learning strategies for digital pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Mormont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Geurts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rapha?l</forename><surname>Mar?e</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2262" to="2271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep learning for emotion recognition on small datasets using transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Wei</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viet</forename><forename type="middle">Dung</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassilios</forename><surname>Vonikakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Winkler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM on international conference on multimodal interaction</title>
		<meeting>the 2015 ACM on international conference on multimodal interaction</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="443" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Domain adaptive transfer learning with specialist models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiquan</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiyi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.07056</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A unified approach to the change of resolution: Space and gray-level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shmuel</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Werman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hillel</forename><surname>Rom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="739" to="742" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An analysis of the interaction between transfer learning protocols in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo</forename><surname>Plested</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Gedeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Neural Information Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="312" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Ridnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hussam</forename><surname>Lawen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asaf</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itamar</forename><surname>Friedman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.13630</idno>
		<title level="m">Tresnet: High performance gpu-dedicated architecture</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The earth mover&apos;s distance as a metric for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yossi</forename><surname>Rubner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="121" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep transfer learning for art classification problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthia</forename><surname>Sabatelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Geurts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Dsod: Learning deeply supervised object detectors from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Gang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yurong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1919" to="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Learning object detectors from scratch with gated recurrent feature pyramids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangliang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.00886</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Towards making deep transfer learning never hurt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruosi</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Huan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="578" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Pytorch image models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Wightman</surname></persName>
		</author>
		<ptr target="https://github.com/rwightman/pytorch-image-models" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">How transferable are features in deep neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hod</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3320" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Scratchdet: Training single-shot object detectors from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longyin</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liefeng</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2268" to="2277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning attentive pairwise interaction for fine-grained classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiqin</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yali</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="13130" to="13137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Rethinking pre-training and self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06882</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
