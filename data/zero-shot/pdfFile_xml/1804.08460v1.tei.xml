<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mixing Context Granularities for Improved Entity Linking on Question Answering Data across Entity Categories</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniil</forename><surname>Sorokin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab (UKP) and Research Training Group AIPHES</orgName>
								<orgName type="institution">Technische Universit?t Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab (UKP) and Research Training Group AIPHES</orgName>
								<orgName type="institution">Technische Universit?t Darmstadt</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Mixing Context Granularities for Improved Entity Linking on Question Answering Data across Entity Categories</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The first stage of every knowledge base question answering approach is to link entities in the input question. We investigate entity linking in the context of a question answering task and present a jointly optimized neural architecture for entity mention detection and entity disambiguation that models the surrounding context on different levels of granularity.</p><p>We use the Wikidata knowledge base and available question answering datasets to create benchmarks for entity linking on question answering data. Our approach outperforms the previous state-of-the-art system on this data, resulting in an average 8% improvement of the final score. We further demonstrate that our model delivers a strong performance across different entity categories.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge base question answering (QA) requires a precise modeling of the question semantics through the entities and relations available in the knowledge base (KB) in order to retrieve the correct answer. The first stage for every QA approach is entity linking (EL), that is the identification of entity mentions in the question and linking them to entities in KB. In <ref type="figure">Figure 1</ref>, two entity mentions are detected and linked to the knowledge base referents. This step is crucial for QA since the correct answer must be connected via some path over KB to the entities mentioned in the question.</p><p>The state-of-the-art QA systems usually rely on off-the-shelf EL systems to extract entities from the question <ref type="bibr" target="#b32">(Yih et al., 2015)</ref>. Multiple EL systems are freely available and can be readily applied what are taylor swift's albums ?</p><p>Taylor Swift Q462 album Q24951125 <ref type="bibr">Red, 1989, etc.</ref> PERFORMER INSTANCE OF <ref type="figure">Figure 1</ref>: An example question from a QA dataset that shows the correct entity mentions and their relationship with the correct answer to the question, Qxxx stands for a knowledge base identifier for question answering (e.g. DBPedia Spotlight 1 , AIDA 2 ). However, these systems have certain drawbacks in the QA setting: they are targeted at long well-formed documents, such as news texts, and are less suited for typically short and noisy question data. Other EL systems focus on noisy data (e.g. S-MART, <ref type="bibr" target="#b31">Yang and Chang, 2015)</ref>, but are not openly available and hence limited in their usage and application. Multiple error analyses of QA systems point to entity linking as a major external source of error <ref type="bibr" target="#b2">(Berant and Liang, 2014;</ref><ref type="bibr" target="#b22">Reddy et al., 2014;</ref><ref type="bibr" target="#b32">Yih et al., 2015)</ref>.</p><p>The QA datasets are normally collected from the web and contain very noisy and diverse data <ref type="bibr" target="#b1">(Berant et al., 2013)</ref>, which poses a number of challenges for EL. First, many common features used in EL systems, such as capitalization, are not meaningful on noisy data. Moreover, a question is a short text snippet that does not contain broader context that is helpful for entity disambiguation. The QA data also features many entities of various categories and differs in this respect from the Twitter datasets that are often used to evaluate EL systems.</p><p>In this paper, we present an approach that tackles the challenges listed above: we perform entity mention detection and entity disambiguation jointly in a single neural model that makes the whole process end-to-end differentiable. This ensures that any token n-gram can be considered as a potential entity mention, which is important to be able to link entities of different categories, such as movie titles and organization names.</p><p>To overcome the noise in the data, we automatically learn features over a set of contexts of different granularity levels. Each level of granularity is handled by a separate component of the model. A token-level component extracts higher-level features from the whole question context, whereas a character-level component builds lower-level features for the candidate n-gram. Simultaneously, we extract features from the knowledge base context of the candidate entity: character-level features are extracted for the entity label and higher-level features are produced based on the entities surrounding the candidate entity in the knowledge graph. This information is aggregated and used to predict whether the n-gram is an entity mention and to what entity it should be linked.</p><p>Contributions The two main contributions of our work are: (i) We construct two datasets to evaluate EL for QA and present a set of strong baselines: the existing EL systems that were used as a building block for QA before and a model that uses manual features from the previous work on noisy data.</p><p>(ii) We design and implement an entity linking system that models contexts of variable granularity to detect and disambiguate entity mentions. To the best of our knowledge, we are the first to present a unified end-to-end neural model for entity linking for noisy data that operates on different context levels and does not rely on manual features. Our architecture addresses the challenges of entity linking on question answering data and outperforms state-of-the-art EL systems.</p><p>Code and datasets Our system can be applied on any QA dataset. The complete code as well as the scripts that produce the evaluation data can be found here: https://github.com/UKPLab/ starsem2018-entity-linking. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation and Related Work</head><p>Several benchmarks exist for EL on Wikipedia texts and news articles, such as ACE <ref type="bibr" target="#b0">(Bentivogli et al., 2010)</ref> and CoNLL-YAGO <ref type="bibr" target="#b15">(Hoffart et al., 2011)</ref>. These datasets contain multi-sentence documents and largely cover three types of entities: Location, Person and Organization. These types are commonly recognized by named entity recognition systems, such as Stanford NER Tool . Therefore in this scenario, an EL system can solely focus on entity disambiguation. In the recent years, EL on Twitter data has emerged as a branch of entity linking research. In particular, EL on tweets was the central task of the NEEL shared task from 2014 to 2016 <ref type="bibr" target="#b24">(Rizzo et al., 2017)</ref>. Tweets share some of the challenges with QA data: in both cases the input data is short and noisy. On the other hand, it significantly differs with respect to the entity types covered. The data for the NEEL shared task was annotated with 7 broad entity categories, that besides Location, Organization and Person include Fictional Characters, Events, Products (such as electronic devices or works of art) and Things (abstract objects). <ref type="figure" target="#fig_0">Figure 2</ref> shows the distribution of entity categories in the training set from the NEEL 2014 competition. One can see on the diagram that the distribution is mainly skewed towards 3 categories: Location, Person and Organization. Figure 2 also shows the entity categories present in two QA datasets. The distribution over the categories is more diverse in this case. The WebQuestions dataset includes the Fictional Character and Thing categories which are almost absent from the NEEL dataset. A more even distribution can be observed in the GraphQuestion dataset that features many Events, Fictional Characters and Professions. This means that a successful system for EL on question data needs to be able to recognize and to link all categories of entities. Thus, we aim to show that comprehensive modeling of different context levels will result in a better generalization and performance across various entity categories.</p><p>Existing Solutions The early machine learning approaches to EL focused on long well-formed documents <ref type="bibr" target="#b4">(Bunescu and Pasca, 2006;</ref><ref type="bibr" target="#b8">Cucerzan, 2007;</ref><ref type="bibr" target="#b14">Han and Sun, 2012;</ref><ref type="bibr" target="#b10">Francis-Landau et al., 2016)</ref>. These systems usually rely on an off-theshelf named entity recognizer to extract entity mentions in the input. As a consequence, such approaches can not handle entities of types other than those that are supplied by the named entity recognizer. Named entity recognizers are normally trained to detect mentions of Locations, Organizations and Person names, whereas in the context of QA, the system also needs to cover movie titles, songs, common nouns such as 'president' etc.</p><p>To mitigate this, Cucerzan (2012) has introduced the idea to perform mention detection and entity linking jointly using a linear combination of manually defined features. <ref type="bibr" target="#b17">Luo et al. (2015)</ref> have adopted the same idea and suggested a probabilistic graphical model for the joint prediction. This is essential for linking entities in questions. For example in "who does maggie grace play in taken?", it is hard to distinguish between the usage of the word 'taken' and the title of a movie 'Taken' without consulting a knowledge base. <ref type="bibr" target="#b29">Sun et al. (2015)</ref> were among the first to use neural networks to embed the mention and the entity for a better prediction quality. Later, <ref type="bibr" target="#b10">Francis-Landau et al. (2016)</ref> have employed convolutional neural networks to extract features from the document context and mixed them with manually defined features, though they did not integrate it with mention detection. <ref type="bibr" target="#b26">Sil et al. (2018)</ref> continued the work in this direction recently and applied convolutional neural networks to cross-lingual EL.</p><p>The approaches that were developed for Twitter data present the most relevant work for EL on QA data. <ref type="bibr" target="#b12">Guo et al. (2013b)</ref> have created a new dataset of around 1500 tweets and suggested a Structured SVM approach that handled mention detection and entity disambiguation together.  describe the winning system of the NEEL 2014 competition on EL for short texts: The system adapts a joint approach similar to <ref type="bibr" target="#b12">Guo et al. (2013b)</ref>, but uses the MART gradient boosting algorithm instead of the SVM and extends the feature set. The current state-of-the-art system for EL on noisy data is S-MART <ref type="bibr" target="#b31">(Yang and Chang, 2015)</ref> which extends the approach from  to make structured predictions. The same group has subsequently applied S-MART to extract entities for a QA system <ref type="bibr" target="#b32">(Yih et al., 2015)</ref>.</p><p>Unfortunately, the described EL systems for short texts are not available as stand-alone tools. Consequently, the modern QA approaches mostly rely on off-the-shelf entity linkers that were designed for other domains. <ref type="bibr" target="#b23">Reddy et al. (2016)</ref> have employed the Freebase online API that was since deprecated. A number of question answering systems have relied on DBPedia Spotlight to extract entities <ref type="bibr" target="#b16">(Lopez et al., 2016;</ref><ref type="bibr" target="#b7">Chen et al., 2016)</ref>. DB-Pedia Spotlight <ref type="bibr" target="#b19">(Mendes et al., 2011)</ref> uses document similarity vectors, word embeddings and manually defined features such as entity frequency. We are addressing this problem in our work by presenting an architecture specifically targeted at EL for QA data.</p><p>The Knowledge Base Throughout the experiments, we use the Wikidata 3 open-domain KB <ref type="bibr" target="#b30">(Vrande?i? and Kr?tzsch, 2014)</ref>. Among the previous work, the common choices of a KB include Wikipedia, DBPedia and Freebase. The entities in Wikidata directly correspond to the Wikipedia articles, which enables us to work with data that was previously annotated with DBPedia. Freebase was discontinued and is no longer up-todate. However, most entities in Wikidata have been annotated with identifiers from other knowledge sources and databases, including Freebase, which establishes a link between the two KBs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Entity Linking Architecture</head><p>The overall architecture of our entity linking system is depicted in <ref type="figure">Figure 3</ref>. From the input question x we extract all possible token n-grams N up to a x = what are taylor swift's albums?</p><p>Step 1. consider all n-grams</p><formula xml:id="formula_0">N = ngrams(x), i = 0 i &lt; |N |, n = N [i]</formula><p>Step 2. entity candidates for an n-gram C = entity candidates(n)</p><p>wikidata Full text search</p><p>Step 3. score the n-gram with the model p n , p c = M(x, n, C)</p><formula xml:id="formula_1">i = i + 1</formula><p>Step 4. compute the global assignment of entities G = global assignment(p n , p c , n, x|n ? N ) <ref type="figure">Figure 3</ref>: Architecture of the entity linking system certain length as entity mention candidates (Step 1). For each n-gram n, we look it up in the knowledge base using a full text search over entity labels <ref type="bibr">(Step 2)</ref>. That ensures that we find all entities that contain the given n-gram in the label. For example for a unigram 'obama', we retrieve 'Barack Obama', 'Michelle Obama' etc. This step produces a set of entity disambiguation candidates C for the given ngram n. We sort the retrieved candidates by length and cut off after the first 1000. That ensures that the top candidates in the list would be those that exactly match the target n-gram n.</p><p>In the next step, the list of n-grams N and the corresponding list of entity disambiguation candidates are sent to the entity linking model (Step 3). The model jointly performs the detection of correct mentions and the disambiguation of entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Variable Context Granularity Network</head><p>The neural architecture (Variable Context Granularity, VCG) aggregates and mixes contexts of different granularities to perform a joint mention detection and entity disambiguation. <ref type="figure" target="#fig_1">Figure 4</ref> shows the layout of the network and its main components. The input to the model is a list of question tokens x, a token n-gram n and a list of candidate entities C. Then the model is a function M(x, n,C) that produces a mention detection score p n for each n-gram and a ranking score p c for each of the candidates c ? C: p n , p c = M(x, n,C).</p><p>Dilated Convolutions To process sequential input, we use dilated convolutional networks (DCNN). <ref type="bibr" target="#b27">Strubell et al. (2017)</ref> have recently shown that DCNNs are faster and as effective as recurrent models on the task of named entity recognition. We define two modules: DCNN w and DCNN c for processing token-level and character-level input respectively. Both modules consist of a series of convolutions applied with an increasing dilation, as described in <ref type="bibr" target="#b27">Strubell et al. (2017)</ref>. The output of the convolutions is averaged and transformed by a fully-connected layer.</p><p>Context components The token component corresponds to sentence-level features normally defined for EL and encodes the list of question tokens x into a fixed size vector. It maps the tokens in x to d w -dimensional pre-trained word embeddings, using a matrix W ? R |V w |?d w , where |V w | is the size of the vocabulary. We use 50-dimensional GloVe embeddings pre-trained on a 6 billion tokens corpus <ref type="bibr" target="#b21">(Pennington et al., 2014)</ref>. The word embeddings are concatenated with d p -dimensional position embeddings P w ? R 3?d p that are used to denote the tokens that are part of the target n-gram. The concatenated embeddings are processed by DCNN w to get a vector o s .</p><p>The character component processes the target token n-gram n on the basis of individual characters. We add one token on the left and on the right to the target mention and map the string of characters to d z -character embeddings, Z ? R |V z |?d z . We concatenate the character embeddings with d p -dimensional position embeddings P z ? R |x|?d p and process them with DCNN c to get a feature vector o n .</p><p>We use the character component with the same learned parameters to encode the label of a candidate entity from the KB as a vector o l . The parameter sharing between mention encoding and entity label encoding ensures that the representation of a mention is similar to the entity label.</p><p>The KB structure is the highest context level included in the model. The knowledge base structure component models the entities and relations that are connected to the candidate entity c. First, we map a list of relations r of the candidate entity to d r -dimensional pre-trained relations embeddings, using a matrix R ? R |V r |?d r , where |V r | is the number of relation types in the KB. We transform the relations embeddings with a single fullyconnected layer f r and then apply a max pooling operation to get a single relation vector o r per entity. Similarly, we map a list of entities that are immediately connected to the candidate entity e  to d e -dimensional pre-trained entity embeddings, using a matrix E ? R |V e |?d e , where |V e | is the number of entities in the KB. The entity embeddings are transformed by a fully-connected layer f e and then also pooled to produce the output o e . The embedding of the candidate entity itself is also transformed with f e and is stored as o d . To train the knowledge base embeddings, we use the TransE algorithm <ref type="bibr" target="#b3">(Bordes et al., 2013)</ref>.</p><p>Finally, the knowledge base lexical component takes the labels of the relations in r to compute lexical relation embeddings. For each r ? r, we tokenize the label and map the tokens x r to word embeddings, using the word embedding matrix W.</p><p>To get a single lexical embedding per relation, we apply max pooling and transform the output with a fully-connected layer f rl . The lexical relation embeddings for the candidate entity are pooled into the vector o rl .</p><p>Context Aggregation The different levels of context are aggregated and are transformed by a sequence of fully-connected layers into a final vector o c for the n-gram n and the candidate entity c. The vectors for each candidate are aggregated into a matrix O = [o c |c ? C]. We apply element-wise max pooling on O to get a single summary vector s for all entity candidates for n.</p><p>To get the ranking score p c for each entity candidate c, we apply a single fully-connected layer g c on the concatenation of o c and the summary vector s: p c = g c (o c s). For the mention detection score for the n-gram, we separately concatenate the vectors for the token context o s and the character context o n and transform them with an array of fully-connected layers into a vector o t . We concatenate o t with the summary vector s and apply another fully-connected layer to get the mention detection score p n = ? (g n (o t s)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Global entity assignment</head><p>The first step in our system is extracting all possible overlapping n-grams from the input texts. We assume that each span in the input text can only refer to a single entity and therefore resolve overlaps by computing a global assignment using the model scores for each n-gram (Step 4 in <ref type="figure">Figure 3</ref>).</p><p>If the mention detection score p n is above the 0.5-threshold, the n-gram is predicted to be a correct entity mention and the ranking scores p c are used to disambiguate it to a single entity candidate. N-grams that have p n lower than the threshold are filtered out.</p><p>We follow <ref type="bibr" target="#b11">Guo et al. (2013a)</ref> in computing the global assignment and hence, arrange all n-grams selected as mentions into non-overlapping combinations and use the individual scores p n to compute the probability of each combination. The combination with the highest probability is selected as the final set of entity mentions. We have observed in practice a similar effect as descirbed by <ref type="bibr" target="#b27">Strubell et al. (2017)</ref>, namely that DCNNs are able to capture dependencies between different entity mentions in the same context and do not tend to produce overlapping mentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Composite Loss Function</head><p>Our model jointly computes two scores for each n-gram: the mention detection score p n and the disambiguation score p c . We optimize the parameters of the whole model jointly and use the loss function that combines penalties for the both scores for all n-grams in the input question:</p><formula xml:id="formula_2">L = ? n?N ? c?C n M (t n , p n ) + t n D(t c , p c ),</formula><p>where t n is the target for mention detection and is either 0 or 1, t c is the target for disambiguation and ranges from 0 to the number of candidates |C|.</p><p>For the mention detection loss M , we include a weighting parameter ? for the negative class as the majority of the instances in the data are negative:</p><formula xml:id="formula_3">M (t n , p n ) = ?t n log p n ??(1?t n ) log(1? p n )</formula><p>The disambiguation detection loss D is a maximum margin loss:</p><formula xml:id="formula_4">D(t c , p c ) = ? |C| i=0 max(0, (m ? p c [t c ] + p c [i])) |C| ,</formula><p>where m is the margin value. We set m = 0.5, whereas the ? weight is optimized with the other hyper-parameters. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Architecture comparison</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Datasets</head><p>We compile two new datasets for entity linking on questions that we derive from publicly available question answering data: WebQSP <ref type="bibr" target="#b33">(Yih et al., 2016)</ref> and GraphQuestions <ref type="bibr" target="#b28">(Su et al., 2016)</ref>. WebQSP contains questions that were originally collected for the WebQuestions dataset from web search logs <ref type="bibr" target="#b1">(Berant et al., 2013)</ref>. They were manually annotated with SPARQL queries that can be executed to retrieve the correct answer to each question. Additionally, the annotators have also selected the main entity in the question that is central to finding the answer. The annotations and the query use identifiers from the Freebase knowledge base.</p><p>We extract all entities that are mentioned in the question from the SPARQL query. For the main entity, we also store the correct span in the text, as annotated in the dataset. In order to be able to use Wikidata in our experiments, we translate the Freebase identifiers to Wikidata IDs.</p><p>The second dataset, GraphQuestions, was created by collecting manual paraphrases for automatically generated questions <ref type="bibr" target="#b28">(Su et al., 2016)</ref>. The dataset is meant to test the ability of the system to understand different wordings of the same question. In particular, the paraphrases include various references to the same entity, which creates a challenge for an entity linking system. The following P R F1</p><p>Heuristic baseline 0.286 0.621 0.392 Simplified VCG 0.804 0.654 0.721 VCG 0.823 0.646 0.724 are three example questions from the dataset that contain a mention of the same entity:</p><p>(1) a. what is the rank of marvel's iron man? b. iron-man has held what ranks? c. tony stark has held what ranks?</p><p>GraphQuestions does not contain main entity annotations, but includes a SPARQL query structurally encoded in JSON format. The queries were constructed manually by identifying the entities in the question and selecting the relevant KB relations. We extract gold entities for each question from the SPARQL query and map them to Wikidata.</p><p>We split the WebQSP training set into train and development subsets to optimize the neural model. We use the GraphQuestions only in the evaluation phase to test the generalization power of our model. The sizes of the constructed datasets in terms of the number of questions and the number of entities are reported in <ref type="table">Table 1</ref>. In both datasets, each question contains at least one correct entity mention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation Methodology</head><p>We use precision, recall and F1 scores to evaluate and compare the approaches. We follow <ref type="bibr" target="#b5">Carmel et al. (2014)</ref> and <ref type="bibr" target="#b31">Yang and Chang (2015)</ref> and define the scores on a per-entity basis. Since there are no mention boundaries for the gold entities, an extracted entity is considered correct if it is present in the set of the gold entities for the given question. We compute the metrics in the micro and macro setting. The macro values are computed per entity class and averaged afterwards.</p><p>For the WebQSP dataset, we additionally perform a separate evaluation using only the information on the main entity. The main entity has the information on the boundary offsets of the correct mentions and therefore for this type of evaluation, we enforce that the extracted mention has to over-emb. size filter size d w d z d e d r d p DCNN w DCNN c ? 50 25 50 50 5 64 64 0.5 <ref type="table">Table 3</ref>: Best configuration for the VCG model lap with the correct mention. QA systems need at least one entity per question to attempt to find the correct answer. Thus, evaluating using the main entity shows how the entity linking system fulfills this minimum requirement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baselines</head><p>Existing systems In our experiments, we compare to DBPedia Spotlight that was used in several QA systems and represents a strong baseline for entity linking 4 . In addition, we are able to compare to the state-of-the-art S-MART system, since their output on the WebQSP datasets was publicly released 5 . The S-MART system is not openly available, it was first trained on the NEEL 2014 Twitter dataset and later adapted to the QA data <ref type="bibr" target="#b32">(Yih et al., 2015)</ref>. We also include a heuristics baseline that ranks candidate entities according to their frequency in Wikipedia. This baseline represents a reasonable lower bound for a Wikidata based approach.</p><p>Simplified VCG To test the effect of the end-toend context encoders of the VCG network, we define a model that instead uses a set of features commonly suggested in the literature for EL on noisy data. In particular, we employ features that cover (1) frequency of the entity in Wikipedia, (2) edit distance between the label of the entity and the token n-gram, (3) number of entities and relations immediately connected to the entity in the KB, (4) word overlap between the input question and the labels of the connected entities and relations, (5) length of the n-gram. We also add an average of the word embeddings of the question tokens and, separately, an average of the embeddings of tokens of entities and relations connected to the entity candidate. We train the simplified VCG model by optimizing the same loss function in Section 3.3 on the same data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Practical considerations</head><p>The hyper-parameters of the model, such as the dimensionality of the layers and the size of embed- <ref type="bibr">4</ref> We use the online end-point:</p><p>http://www. dbpedia-spotlight.org/api 5 https://github.com/scottyih/STAGG    <ref type="table">Table 3</ref> lists the main selected hyperparameters for the VCG model 6 and we also report the results for each model's best configuration on the development set in <ref type="table" target="#tab_2">Table 2</ref>. We observe that our model achieves the most gains in precision compared to the baselines and the previous stateof-the-art for QA data. VCG constantly outperforms the simplified VCG baseline that was trained by optimizing the same loss function but uses manually defined features. Thereby, we confirm the advantage of the mixing context granularities strategy that was suggested in this work. Most importantly, the VCG model achieves the best macro result which indicates that the model has a consistent performance on different entity classes. We further evaluate the developed VCG architecture on the GraphQuestions dataset against the DBPedia Spotlight. We use this dataset to evaluate VCG in an out-of-domain setting: neither our system nor DBPedia Spotlight were trained on it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head><p>The results for each model are presented in <ref type="table" target="#tab_5">Table 5</ref>. We can see that GraphQuestions provides a much more difficult benchmark for EL. The VCG model shows the overall F-score result that is better than the DBPedia Spotlight baseline by a wide margin. It is notable that again our model achieves higher precision values as compared to other approaches and manages to keep a satisfactory level of recall.</p><p>Analysis In order to better understand the performance difference between the approaches and the gains of the VCG model, we analyze the results per entity class (see <ref type="figure" target="#fig_2">Figure 5</ref>). We see that the S-MART system is slightly better in the disambiguation of Locations, Person names and a similar category of Fictional Character names, while it has  <ref type="table">Table 6</ref>: Ablation experiments for the VCG model on WEBQSP a considerable advantage in processing of Professions and Common Nouns. Our approach has an edge in such entity classes as Organization, Things and Products. The latter category includes movies, book titles and songs, which are particularly hard to identify and disambiguate since any sequence of words can be a title. VCG is also considerably better in recognizing Events. We conclude that the future development of the VCG architecture should focus on the improved identification and disambiguation of professions and common nouns.</p><p>To analyze the effect that mixing various context granularities has on the model performance, we include ablation experiment results for the VCG model (see <ref type="table">Table 6</ref>). We report the same scores as in the main evaluation but without individual model components that were described in Section 3.</p><p>We can see that the removal of the KB structure information encoded in entity and relation embeddings results in the biggest performance drop of almost 10 percentage points. The character-level information also proves to be highly important for the final state-of-the-art performance. These aspects of the model (the comprehensive representation of the KB structure and the character-level information) are two of the main differences of our approach to the previous work. Finally, we see that excluding the token-level input and the lexical information about the related KB relations also decrease the results, albeit less dramatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We have described the task of entity linking on QA data and its challenges. The suggested new approach for this task is a unifying network that models contexts of variable granularity to extract features for mention detection and entity disambiguation. This system achieves state-of-the-art results on two datasets and outperforms the previous best system used for EL on QA data. The results further verify that modeling different types of context helps to achieve a better performance across various entity classes (macro f-score).</p><p>Most recently, <ref type="bibr" target="#b20">Peng et al. (2017)</ref> and <ref type="bibr" target="#b34">Yu et al. (2017)</ref> have attempted to incorporate entity linking into a QA model. This offers an exciting future direction for the Variable Context Granularity model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Distribution of entity categories in the NEEL 2014, WebQSP and GraphQuestions datasets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>The architecture of the Variable Context Granularity Network for a single n-gram and an entity candidate. The output vectors (o c , o t ) are aggregated over all n-grams for the global assignment</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Performance accross entity classes on WEBQSP test dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Evaluation results on the WEBQSP development dataset (all entities)</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Evaluation results on the WEBQSP test dataset, the m prefix stands for macro</figDesc><table><row><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>DBPedia Spotlight</cell><cell cols="3">0.386 0.453 0.417</cell></row><row><cell>VCG</cell><cell cols="3">0.589 0.354 0.442</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>: Evaluation results on GRAPHQUESTIONS</cell></row><row><cell>dings, are optimized with random search on the</cell></row><row><cell>development set. The model was particularly sen-</cell></row><row><cell>sitive to tuning of the negative class weight ? (see</cell></row><row><cell>Section 3.3).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc>lists results for the heuristics baseline, for the suggested Variable Context Granularity model (VCG) and for the simplified VCG baseline on the test set of WebQSP. The simplified VCG model outperforms DBPedia Spotlight and achieves a result very close to the S-MART model. Considering only the main entity, the simplified VCG model produces results better than both DBPedia Spotlight and S-MART. The VCG model delivers the best F-score across the all setups.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.dbpedia-spotlight.org 2 https://www.mpi-inf.mpg.de/yago-naga/aida/ arXiv:1804.08460v1 [cs.CL] 23 Apr 2018</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">At the moment, Wikidata contains more than 40 million entities and 350 million relation instances: https://www.wikidata.org/wiki/Special: Statistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">The complete list of hyper-parameters and model characteristics can be found in the accompanying code repository.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been supported by the German Research Foundation as part of the Research Training Group Adaptive Preparation of Information from Heterogeneous Sources (AIPHES) under grant No. GRK 1994/1, and via the QA-EduInf project (grant GU 798/18-1 and grant RI 803/12-1).</p><p>We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan X Pascal GPU used for this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Extending English ACE 2005 corpus annotation with ground-truth links to Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Giuliano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Pianta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Tymoshenko</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W10-" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Collaboratively Constructed Semantic Resources at the 23rd International Conference on Computational Linguistics (Coling)</title>
		<meeting>the 2nd Workshop on Collaboratively Constructed Semantic Resources at the 23rd International Conference on Computational Linguistics (Coling)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic Parsing on Freebase from Question-Answer Pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D13-1160" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic Parsing via Paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P14-1133</idno>
		<ptr target="https://doi.org/10.3115/v1/P14-1133" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1415" to="1425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Translating Embeddings for Modeling Multi-Relational Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<meeting><address><addrLine>Lake Tahoe, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using Encyclopedic Knowledge for Named Entity Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Pasca</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/E06-1002" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL)<address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ERD&apos;14: Entity Recognition and Disambiguation Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-June (</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">)</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1145/2600428.2600734</idno>
		<ptr target="https://doi.org/10.1145/2600428.2600734" />
	</analytic>
	<monogr>
		<title level="j">In ACM SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="63" to="77" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">E2E: An End-to-End Entity Linking System for Short and Noisy text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-June</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricky</forename><surname>Loynd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the the 4thWorkshop on Making Sense of Microposts co-located with the 23rd International World Wide Web Conference</title>
		<meeting>the the 4thWorkshop on Making Sense of Microposts co-located with the 23rd International World Wide Web Conference<address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="62" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Semantic Graph based Topic Model for Question Retrieval in Community Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joemon</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dell</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/2835776.2835809</idno>
		<ptr target="https://doi.org/10.1145/2835776.2835809" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM International Conference on Web Search and Data Mining (WSDM)</title>
		<meeting>the 9th ACM International Conference on Web Search and Data Mining (WSDM)<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Large-Scale Named Entity Disambiguation Based on Wikipedia Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silviu Cucerzan</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D07-1074" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="708" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The MSR System for Entity Linking at TAC 2012</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silviu Cucerzan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analysis Conference (TAC)</title>
		<meeting>the Text Analysis Conference (TAC)<address><addrLine>Gaithersburg, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="14" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Capturing Semantic Similarity for Entity Linking with Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Francis-Landau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1150</idno>
		<ptr target="https://doi.org/10.18653/v1/N16-1150" />
	</analytic>
	<monogr>
		<title level="m">Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1256" to="1261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">To Link or Not to Link? A Study on End-to-End Tweet Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emre</forename><surname>Kcman</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N13-1122" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1020" to="1030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Microblog entity linking by leveraging extra posts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013</title>
		<meeting>the 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<ptr target="http://www.aclweb.org/anthology/D13-1085" />
		<title level="m">Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<biblScope unit="page" from="863" to="868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An entity-topic model for entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D12-1010" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="105" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Robust Disambiguation of Named Entities in Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">Amir</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilaria</forename><surname>Bordino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hagen</forename><surname>F?rstenau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilyana</forename><surname>Taneva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Thater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D11-1072" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="782" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">QuerioDALI: Question answering over dynamic and linked knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierpaolo</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Kotoulas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiewen</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46547-0_32</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46547-032" />
	</analytic>
	<monogr>
		<title level="m">The Semantic Web -15th International Semantic Web Conference</title>
		<meeting><address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="363" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Joint Named Entity Recognition and Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaiqing</forename><surname>Nie</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1104</idno>
		<ptr target="https://doi.org/10.18653/v1/D15-1104" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP Natural Language Processing Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P14-5010</idno>
		<ptr target="https://doi.org/10.3115/v1/P14-5010" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics (ACL): System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics (ACL): System Demonstrations<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">DBpedia Spotlight: Shedding Light on the Web of Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andr?s</forename><surname>Garc?a-Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<idno type="DOI">10.1145/2063518.2063519</idno>
		<ptr target="https://doi.org/10.1145/2063518.2063519" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Semantic Systems (I-Semantics)</title>
		<meeting>the 7th International Conference on Semantic Systems (I-Semantics)<address><addrLine>Graz, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Maximum Margin Reward Networks for Learning from Explicit and Implicit Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1252</idno>
		<ptr target="https://doi.org/10.18653/v1/D17-1252" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2358" to="2368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
		<ptr target="https://doi.org/10.3115/v1/D14-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Large-scale Semantic Parsing without Question-Answer Pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/Q14-1030" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="377" to="392" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Transforming Dependency Structures to Logical Forms for Semantic Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>T?ckstr?m</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/Q16-1010" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="127" to="140" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Mark Steedman, and Mirella Lapata</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Lessons learnt from the Named Entity rEcognition and Linking (NEEL) Challenge Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Rizzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Varga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marieke</forename><surname>Van Erp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amparo Elizabeth Cano</forename><surname>Basave</surname></persName>
		</author>
		<idno type="DOI">10.3233/SW-170276</idno>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="667" to="700" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<idno type="DOI">10.3233/SW-170276</idno>
		<ptr target="https://doi.org/10.3233/SW-170276" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Neural Cross-Lingual Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avirup</forename><surname>Sil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gourab</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wael</forename><surname>Hamza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<meeting><address><addrLine>New Orleans, LA, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fast and Accurate Entity Recognition with Iterated Dilated Convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1283</idno>
		<ptr target="https://doi.org/10.18653/v1/D17-1283" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2670" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On Generating Characteristic-rich Question Sets for QA Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Sadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mudhakar</forename><surname>Srivatsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Izzeddin</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zenghui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1054</idno>
		<ptr target="https://doi.org/10.18653/v1/D16-1054" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="562" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modeling mention, context and entity with neural networks for entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhou</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Wikidata: A Free Collaborative Knowledgebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Vrande?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Kr?tzsch</surname></persName>
		</author>
		<idno type="DOI">10.1021/ac60289a702</idno>
		<ptr target="https://doi.org/10.1021/ac60289a702" />
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">S-MART: Novel Tree-based Structured Learning Algorithms Applied to Tweet Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P15-1049</idno>
		<ptr target="https://doi.org/10.3115/v1/P15-1049" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="504" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semantic Parsing via Staged Query Graph Generation: Question Answering with Knowledge Base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P15-1128</idno>
		<ptr target="https://doi.org/10.3115/v1/P15-1128" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1321" to="1331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The Value of Semantic Parse Labeling for Knowledge Base Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jina</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Suh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-2033</idno>
		<ptr target="https://doi.org/10.18653/v1/P16-2033" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="201" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Improved Neural Relation Detection for Knowledge Base Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kazi Saidul Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1053</idno>
		<ptr target="https://doi.org/10.18653/v1/P17-1053" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="571" to="581" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
