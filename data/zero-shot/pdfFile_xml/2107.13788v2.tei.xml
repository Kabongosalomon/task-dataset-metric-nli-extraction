<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Probabilistic Monocular 3D Human Pose Estimation with Normalizing Flows</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Wehrbein</surname></persName>
							<email>wehrbein@tnt.uni-hannover.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Leibniz University Hannover</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Rudolph</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Leibniz University Hannover</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Leibniz University Hannover</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of British Columbia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Probabilistic Monocular 3D Human Pose Estimation with Normalizing Flows</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>3D human pose estimation from monocular images is a highly ill-posed problem due to depth ambiguities and occlusions. Nonetheless, most existing works ignore these ambiguities and only estimate a single solution. In contrast, we generate a diverse set of hypotheses that represents the full posterior distribution of feasible 3D poses. To this end, we propose a normalizing flow based method that exploits the deterministic 3D-to-2D mapping to solve the ambiguous inverse 2D-to-3D problem. Additionally, uncertain detections and occlusions are effectively modeled by incorporating uncertainty information of the 2D detector as condition. Further keys to success are a learned 3D pose prior and a generalization of the best-of-M loss. We evaluate our approach on the two benchmark datasets Human3.6M and MPI-INF-3DHP, outperforming all comparable methods in most metrics. The implementation is available on GitHub 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Estimating the 3D pose of a human from a single monocular image is an active research field in computer vision. It has many applications e.g. in human computer interaction, animation, medicine and surveillance. A common approach is to decouple the problem into two stages. In the first stage, a 2D pose detector is used to estimate 2D keypoints which are then lifted to 3D joint locations in the second stage. By utilizing a 2D pose detector pretrained on diverse and richly annotated data, the 3D pose estimator becomes invariant to different scenes varying in lighting, background and clothing. However, reconstructing the correct 3D pose from 2D joint detections is a highly ill-posed problem because of depth ambiguities and occluded body parts. While some ambiguities can be resolved by utilizing information from the image (e.g. difference in shading due to depth disparity) or by exploiting known proportions of the human body, such as joint angle and bone length constraints, there <ref type="bibr">Figure 1</ref>. Our model generates diverse 3D pose hypotheses that are consistent with the input image. Compared to <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b39">40]</ref> we achieve a higher diversity mainly where 2D detections are uncertain, in this case for the occluded left arm. For visualization purposes, more than three hypotheses are shown only for the highly ambiguous left arm. still remain scenarios where multiple plausible 3D poses are consistent with the same image. <ref type="figure">Fig. 1</ref> shows such a situation where the left arm is occluded by the upper body and therefore its position cannot be determined unambiguously. Nevertheless, most existing works ignore the ambiguities by assuming that only a single solution exists. In contrast, we model monocular 3D human pose estimation as an ambiguous inverse problem with multiple feasible solutions. Thus, in this work, we propose to estimate the full posterior distribution of plausible 3D poses conditioned on a monocular image.</p><p>Recently, few methods <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b39">40]</ref> have been proposed that follow the line of research to explicitly generate multiple 3D pose hypotheses from the 2D input. However, they only consider 2D joint coordinates and ignore the uncertainty of the 2D detector. While it is reasonable to infer depth ambiguities based on 2D coordinates only, directly modeling occlusions and uncertain detections is not meaningful. Fortunately, most 2D human joint detectors encode valuable information about uncertainties of the location of human joints in the predicted heatmaps. Instead of discarding this information, we propose to explicitly extract and utilize the uncertainties of the 2D detector from the estimated heatmaps. As shown in <ref type="figure">Fig. 1</ref>, this enables us to effectively model the uncertainties of the 2D detector together with the inherent depth ambiguities.</p><p>In this work, we propose a normalizing flow based method inspired by the framework for solving ambiguous inverse problems from Ardizzone et al. <ref type="bibr" target="#b2">[3]</ref>. A normalizing flow <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47]</ref> is a sequence of bijective transformations which allows evaluation in both directions. We propose to view 3D human pose estimation from a single image as an ambiguous inverse problem, since it is a deterministic forward process (i.e. projection of the 3D pose to 2D) with multiple different inverse mappings. Constructing a bijection between a 3D pose and the combination of a 2D pose with a latent vector allows to utilize the 3D-to-2D mapping (forward process) during training. Intuitively, depth information that otherwise gets lost in the forward process is encoded in the latent vector. Repeatedly sampling the latent vector and computing the inverse path of the normalizing flow generates arbitrary many 3D pose hypotheses that approximate the true posterior distribution. To incorporate the uncertainty information from the heatmaps, we employ a conditional variant of normalizing flows <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b51">52]</ref>. We extract the uncertainty information by fitting 2D Gaussians to the heatmaps which are then used to form a conditioning vector. We optimize the model in both directions. The forward path learns the 3D-to-2D mapping and to produce latent vectors following a predefined distribution. For the inverse path, we utilize the 3D pose discriminator of <ref type="bibr" target="#b48">[49]</ref> to penalize anthropometrically unfeasible poses. Additionally, we apply a loss enforcing the 3D pose hypotheses to reflect the uncertainties of the 2D detector. Motivated by common practice in particle filters, we further propose a generalization of the best-of-M loss <ref type="bibr" target="#b15">[16]</ref> that minimizes the distance between the mean of the k best hypotheses and the corresponding ground truth.</p><p>We evaluate our approach on the two benchmark datasets Human3.6M <ref type="bibr" target="#b18">[19]</ref> and MPI-INF-3DHP <ref type="bibr" target="#b32">[33]</ref> and outperform all comparable methods in most metrics. Given the focus on ambiguous examples, we further evaluate on a subset of Human3.6M containing only samples with a high degree of 2D detector uncertainty. On this subset, our method outperforms the competitors by a large margin. To summarize, our contributions are:</p><p>? To the best of our knowledge, we are the first to employ a normalizing flow based method for modeling the posterior distribution of 3D poses given a single image.</p><p>? Uncertainty information from the predicted heatmaps of the 2D detector is incorporated into our method, enabling to effectively model occlusions and uncertain detections.</p><p>? We propose a generalization of the best-of-M loss that noticeably improves prediction performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In this section, we first give an overview of recent work in 3D human pose estimation focused on twostage approaches. Afterwards, existing methods for multihypotheses 3D pose generation are discussed, followed by an overview of relevant work on normalizing flows. While there has been recent interest in estimating the 3D human body shape from monocular images <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b54">55]</ref>, this work focuses on predicting the 3D locations of a set of predefined joints.</p><p>Lifting 2D to 3D: Our approach belongs to the vast body of work that estimate 3D poses from the output of a 2D pose detector <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b53">54]</ref>. These twostage approaches decouple the difficult problem of 3D depth estimation from the easier 2D pose localization. Furthermore, it allows to use both indoor and in-the-wild data for training the 2D detector, which effectively reduces the bias towards sterile indoor scenes. Akhter and Black <ref type="bibr" target="#b0">[1]</ref> learn a pose-conditioned joint angle limit prior to restrict invalid 3D pose reconstructions. They perform 3D pose estimation using an over-complete dictionary of poses. Moreno-Noguer <ref type="bibr" target="#b33">[34]</ref> casts the problem as a regression between 2D and 3D poses represented as distance matrices. Lifting 2D to 3D joints was further sparked by Martinez et al. <ref type="bibr" target="#b31">[32]</ref>, who employ a simple fully-connected network to lift 2D detections to 3D poses, surprisingly outperforming past approaches. Due to its simplicity and strong performance, it serves as a popular baseline for many following works.</p><p>Unlike the above mentioned approaches that assume a unimodal posterior distribution and only predict a single 3D pose for each input, we are able to generate a diverse set of plausible 3D poses. Additionally, anatomical constraints are learned implicitly by utilizing a strong 3D pose discriminator. In contrast to previous works that integrate uncertainty information of the 2D detector (e.g. <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b53">54]</ref>), we fit a 2D Gaussian to each heatmap instead of using only the maximum value of each heatmap as confidence score, thus better capturing the uncertainty distribution.</p><p>Multi-Hypotheses 3D Human Pose Estimation: There are early works <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref> that extensively analyze and discuss the ambiguities of monocular 3D human pose estimation and sample multiple 3D poses via heuristics. More recently, Jahangiri and Yuille <ref type="bibr" target="#b19">[20]</ref> propose to generate multiple hypotheses from a predicted seed 3D pose by uniformly sampling from learned occupancy matrices <ref type="bibr" target="#b0">[1]</ref>. Furthermore, they impose bone length constraints and re- <ref type="figure">Figure 2</ref>. An overview of our proposed method. We employ a normalizing flow consisting of affine coupling blocks <ref type="bibr" target="#b10">[11]</ref> for generating multiple 3D pose hypotheses. By constructing a bijection between a 3D pose and the concatenation of a 2D pose with a latent vector, we can exploit the 3D-to-2D mapping (forward path) during training. The model is optimized in both directions, whereas at inference, only the path from 2D to 3D (inverse path) is computed. Arbitrary many 3D pose hypotheses can be generated by repeatedly sampling the latent vector from a known distribution and computing the inverse path. Uncertainty information of the 2D detector in form of fitted Gaussians is incorporated by conditioning the coupling blocks. The architecture of a single coupling block is visualized in the gray box. For visualization purposes, only the forward computation of the coupling block is shown. ject hypotheses with 2D reprojection error larger than some threshold. Li and Lee <ref type="bibr" target="#b27">[28]</ref> employ a mixture density network (MDN) <ref type="bibr" target="#b5">[6]</ref> to learn the multimodal posterior distribution. The conditional mean of each Gaussian kernel then denotes one 3D pose hypothesis. Oikarinen et al. <ref type="bibr" target="#b34">[35]</ref> utilize the semantic graph neural network of <ref type="bibr" target="#b55">[56]</ref> to improve upon the MDN approach of <ref type="bibr" target="#b27">[28]</ref>. Contrary to our normalizing flow based approach, the number of generated hypotheses needs to be specified a priori and is fixed for every input. Furthermore, when increasing the number of generated hypotheses, significantly more computational resources are required. Sharma et al. <ref type="bibr" target="#b39">[40]</ref> employ a conditional variational autoencoder to synthesize diverse 3D pose hypotheses conditioned on a 2D pose detection. They also propose to derive joint-ordinal depth relations from the image to rank the 3D pose samples. In contrast to <ref type="bibr" target="#b19">[20]</ref>, our normalizing flow based approach does not need to incorporate computationally heavy rejection sampling or requires to define the number of generated 3D pose hypotheses a priori. Our method is more flexible and is able to model any posterior distribution without requiring explicit hard constraints. Moreover, we are the only ones to incorporate the uncertainty information of the 2D detector, enabling us to significantly improve on highly ambiguous cases and to inherently handle an arbitrary number of occluded joints.</p><p>Normalizing Flows: A normalizing flow <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47</ref>] is a sequence of bijective transformations that transforms a simple tractable distribution into a complex target data distribution. Because of the bijectivity, evaluation in both directions is possible. Namely, sampling data from the modeled distribution as well as exact density estimation (i.e. assigning a likelihood to each data point). Most common state-of-the-art flow architectures are based on autoregressive models that utilize the Bayesian chain rule to decompose the density <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b38">39]</ref>. For a more comprehensive introduction, we refer the reader to <ref type="bibr" target="#b23">[24]</ref>.</p><p>Ardizonne et al. <ref type="bibr" target="#b2">[3]</ref> extend the real-valued nonvolume preserving (Real-NVP) transformations from Dinh et al. <ref type="bibr" target="#b10">[11]</ref> to the task of computing posteriors for ambiguous inverse problems. Given such an ambiguous inverse problem, they propose to learn the well-understood forward process in a supervised manner and encode otherwise lost information in additional latent variables. Thus, they learn a bijective mapping between the target data distribution and the joint distribution of latent variables and forward process solutions. Due to invertibility, the inverse is implicitly learned. By repeatedly sampling the latent variables from a simple tractable distribution, they can approximate the full posterior. Inspired by their work, we adopt and extent their framework for modeling the full posterior distribution of plausible 3D poses conditioned on a monocular image. We introduce a conditioning vector, a learnable prior and two additional loss functions.</p><p>To the best of our knowledge, the only previous works in human pose estimation utilizing normalizing flows are <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b54">55]</ref>. However, they employ normalizing flows as 3D pose prior and not for directly modeling the posterior distribution of 3D poses conditioned on an image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>Our aim is to learn the full posterior distribution of plausible 3D poses conditioned on a monocular image. We follow the popular two-stage approach by first applying a stateof-the-art 2D joint detector <ref type="bibr" target="#b44">[45]</ref> and subsequently using its output to estimate corresponding 3D pose hypotheses. The core idea is that instead of conditioning the posterior distribution only on the 2D detections, we additionally utilize uncertainty information extracted from the predicted heatmaps in a novel way. This enables to effectively model the uncertainties of the 2D detector together with the inherent depth ambiguities.</p><p>An overview of the proposed method is shown in <ref type="figure">Fig. 2</ref>. To learn the posterior distribution, we employ a normalizing flow to construct a bijective mapping between a 3D pose x ? R 3J and the concatenation of a 2D pose y ? R 2J with a latent vector z ? R J , where J is the number of joints in one pose. The introduction of the latent vector z allows to utilize the well-defined forward process of projecting a 3D pose to its 2D observation during training. Intuitively, z captures depth information that is otherwise lost in the mapping from 3D to 2D. Instead of simply using the argmax of the heatmaps, we incorporate the uncertainty information of the 2D detector by conditioning the normalizing flow on Gaussians fitted to the heatmaps. At inference, the full posterior is approximated by repeatedly sampling z from the distribution of latent variables and computing the inverse path. If the forward process is simulated successfully, all generated hypotheses reproject to the corresponding 2D pose observation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Conditional Normalizing Flow</head><p>As normalizing flow we adopt the Real-NVP <ref type="bibr" target="#b10">[11]</ref> affine coupling block architecture. This architecture can straightforwardly be extended to incorporate a conditional input <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b51">52]</ref>. A single coupling block is shown in the gray box in <ref type="figure">Fig. 2</ref>. The input u in is split into two parts u in,1 and u in,2 . Subsequently, u in,1 and u in,2 undergo a scale and translation transformation parameterized by the functions s i and t i (i ? {1, 2}) on two separate paths. The outputs u out,1 and u out,2 are concatenated to form the overall output of the coupling block. Given the heatmap condition?, further encoded into the conditioning vector c = h ? (?), the forward path of a coupling block is defined as</p><formula xml:id="formula_0">u out,2 = u in,2 e s1(uin,1,c) + t 1 (u in,1 , c) u out,1 = u in,1 e s2(uout,2,c) + t 2 (u out,2 , c),<label>(1)</label></formula><p>where denotes the element-wise multiplication. The exponential function is used to prevent multiplication by zero, which ensures the invertibility of the block. Note that s i and t i represent functions that do not need to be invertible. The only restriction is that their produced output matches the dimensions of the data on the corresponding path in the coupling block. Instead of regressing the scale and translation coefficients separately, we employ a fully-connected network that jointly predicts them by splitting its output. By construction, the coupling block can be trivially inverted without any computational overhead. The overall network consists of multiple chained blocks, each followed by a predefined random permutation which shuffles the path assignment of the variables. The output of the last block is split to form the 2D pose y and the latent vector z. Following Ardizzone et al. <ref type="bibr" target="#b3">[4]</ref>, we adopt a parameterized soft clamping mechanism to prevent instabilities caused by the exponential function in the coupling block. The soft clamping is defined as</p><formula xml:id="formula_1">? ? (r) = 2? ? arctan r ? ,<label>(2)</label></formula><p>and is applied as the last layer of s 1 and s 2 . It prevents scaling components of exploding magnitude by restricting the output to the interval (??, ?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Heatmap Condition</head><p>Recent 2D detectors are optimized by applying a supervised loss between the predicted heatmap and a groundtruth heatmap consisting of a 2D Gaussian centered at the joint location. This leads to the predicted heatmaps being a valuable source of uncertainty of the 2D detector. Instead of estimating 3D poses solely based on 2D joint coordinates, we incorporate the uncertainties of the 2D detector encoded in the estimated heatmaps. Specifically, we fit a 2D Gaussian to each predicted heatmap to best capture the uncertainty distribution. The fitting process is done using non-linear least squares. As initial parameters, we set the amplitude to 1, the mean of each Gaussian to the corresponding regressed 2D joint location and the covariance matrix to a diagonal matrix with ? 2</p><formula xml:id="formula_2">x = ? 2 y = ? 2 gt , where ? 2</formula><p>gt is the ground-truth variance used for training the 2D detector. For each image, the fitted coefficients are stacked to form a single vector. We discard the Gaussian coefficients for the hip joints, since the typical alignment of the root joint of the 3D poses heavily reduces the possible variances in these joints. Thus, the heatmap conditioning vector is denoted as? ? R 6(J?3) . We employ a fully-connected network as encoding network h ? that further encodes? into c = h ? (?). For the 3D pose hypotheses to best reflect the uncertainties of the 2D detector, we explicitly optimize the network to match the 2D Gaussian distributions in the xand y-direction of the 3D hypotheses for each joint. Let ? ? R 2?2 be the covariance matrix of a single joint estimated from the positions of that joint in the L produced hypotheses. Defining ? ? R 2?2 as the covariance matrix of the fitted 2D Gaussian of the corresponding heatmap, we minimize a masked lower bound Root Mean Square Error (RMSE) between both covariance matrices:</p><formula xml:id="formula_3">L HM ?,? = m ? max 0, ? 1,1 ?? 1,1 2 + max 0, ? 2,2 ?? 2,2 2 + ? 1,2 ?? 1,2 2 1 2 ,<label>(3)</label></formula><p>where the masking scalar m is defined as</p><formula xml:id="formula_4">m = 1 ? 1,1 &gt; ? t ? ? 2,2 &gt; ? t 0 otherwise .<label>(4)</label></formula><p>Thus, the loss has no influence if the 2D detector is certain about the location of the specific joint, indicated by a fitted Gaussian with standard deviations smaller than the threshold ? t . To not unnecessarily restrict the network, we only penalize the diagonal entries of the covariance matrices if they are smaller than the corresponding ground-truth values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Optimization</head><p>The core idea of the optimization procedure is to train the 3D-to-2D mapping (forward path) in a supervised manner, while the highly ambiguous 2D-to-3D mapping (inverse path) is learned implicitly due to the invertibility of the normalizing flow and supported by additional supervision with the inverse process. Each training iteration consists of first calculating the forward path, followed by L computations of the inverse path and two additional, one for the discriminator and one for the deterministic 3D reconstruction. The gradients from both directions are accumulated before performing a parameter update. Note that due to the Real-NVP coupling block architecture, both directions can be computed efficiently.</p><p>Forward Path: In the forward process, the network predicts the corresponding 2D joint detections given a 3D pose. This is optimized using the L 1 distance:</p><formula xml:id="formula_5">L 2D = y ?? 1 ,<label>(5)</label></formula><p>where y is the ground-truth and? the estimated 2D observation. The estimated latent variables are optimized to follow a zero-mean isotropic Gaussian p Z = N (0, I) and to be independent from the distribution of 2D observations p Y . Both properties are enforced by minimizing the Maximum Mean Discrepancy (MMD) <ref type="bibr" target="#b13">[14]</ref> between the joint distribution of network outputs q(y, z) and the product of marginal distributions p Y and p Z .</p><formula xml:id="formula_6">Given samplesV = {v i } n i=1 drawn i.i.d. from q(y, z) and V = {v i } n i=1 with v i = [y, z]</formula><p>and y ? p Y , z ? p Z , the unbiased estimator of the squared MMD with kernel ? is</p><formula xml:id="formula_7">L MMD = MMD 2 u (V ,V ) = 1 n(n ? 1) n i =j ? (v i , v j ) + 1 n(n ? 1) n i =j ? (v i ,v j ) ? 2 n 2 n i,j=1 ? (v i ,v j ) .<label>(6)</label></formula><p>Following <ref type="bibr" target="#b2">[3]</ref>, we block the gradients of L MMD with respect to y to prevent the predictions of y from deteriorating. Inverse Path: Given a 2D pose y, a latent vector z is drawn from the base distribution p Z and concatenated to form the input [y, z] of the inverse path. By repeatedly sampling z ? p Z , arbitrary many 3D pose hypotheses can be created. Although L 2D and L MMD are in theory sufficient to best approximate the true posterior distribution <ref type="bibr" target="#b2">[3]</ref>, we apply additional losses to the inverse path to improve convergence. To penalize geometrically unfeasible 3D pose hypotheses, we introduce a discriminator network and adopt the Improved Wasserstein GAN training procedure of <ref type="bibr" target="#b14">[15]</ref>. The inverse path acts as the generator by producing 3D poses that minimize the negated output of the discriminator. This loss is denoted as L gen . The architecture of the discriminator is taken from <ref type="bibr" target="#b48">[49]</ref>, including a Kinematic Chain Space layer <ref type="bibr" target="#b47">[48]</ref> encoding bone lengths and angular representations. Additionally, we generate a 3D pose for each 2D input by using the corresponding latent vector z det produced in the forward path. Note that contrary to sampling a latent vector z ? p Z , when using the estimated latent vector z det , it is reasonable to apply a supervised loss L det linking a 2D input to a single 3D pose, since the combination of a predicted latent vector and matching 2D pose detection should correspond to the single exact solution of the ambiguous inverse problem. We minimize the L 1 distance between the ground-truth 3D pose x and the estimated 3D posex det</p><formula xml:id="formula_8">L det = x ?x det 1 .<label>(7)</label></formula><p>To further guide the optimization process, we propose a generalization of the best-of-M loss <ref type="bibr" target="#b15">[16]</ref>. Given a set of 3D pose hypotheses H = {x i } L i=1 generated from the same 2D input, we select the subset H topk ? H consisting of the k pose hypotheses with the lowest Mean Per Joint Position Error (MPJPE) to the corresponding ground-truth pose x. We then minimize the L 1 distance between the ground-truth pose x and the mean of the k best hypotheses:</p><formula xml:id="formula_9">L MB = x ? x?H topkx k 1 .<label>(8)</label></formula><p>Overall: In total, the objective function of our normalizing flow is</p><formula xml:id="formula_10">L NF =L 2D + L gen + ? MMD L MMD + ? det L det + ? MB L MB + ? HM L HM ,<label>(9)</label></formula><p>where ? MMD , ? det , ? MB and ? HM represent the weights of the corresponding losses. The discriminator network is optimized to distinguish between the 3D poses produced by the normalizing flow and 3D poses from the training set by minimizing the WGAN-GP objective function <ref type="bibr" target="#b14">[15]</ref>. The encoding network h ? is jointly optimized with the normalizing flow by propagating gradients from L NF through h ? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and Evaluation Metrics</head><p>Human3.6M <ref type="bibr" target="#b18">[19]</ref> is the largest video pose dataset for 3D human pose estimation. It features 7 professional actors performing 15 different activities, such as Sitting, Walking and Smoking. For each frame, accurate 2D and 3D joint locations and camera parameters are provided. We follow the standard protocols and evaluate on every 64 th frame of subjects 9 and 11. Protocol 1 computes the Mean Per Joint Position Error (MPJPE) between the reconstructed and ground-truth 3D joint coordinates directly, whereas Protocol 2 first applies a rigid alignment between the poses (PMPJPE). We additionally show results for the Correct Poses Score (CPS) metric proposed by <ref type="bibr" target="#b49">[50]</ref>. It considers a pose as correct if and only if all joints have a Euclidean distance to the ground-truth below a threshold value ?. CPS is then defined as the area under curve for ? ? [0 mm, 300 mm]. Instead of evaluating the reconstruction joint by joint, the CPS considers the whole pose. Compared to other common metrics, it is better suited to detect wrongly estimated poses that could negatively influence downstream tasks.</p><p>Human3.6M Ambiguous (H36MA): To focus evaluation on highly ambiguous examples, we select a subset 2 of the Human3.6M test split according to the uncertainties of the 2D detector. This subset only contains samples for which at least one fitted Gaussian has a standard deviation larger than 5 px, which holds true for 6.4% of all samples in the test split. These samples are extremely challenging since the joint detector gives inaccurate or wrong results.</p><p>MPI-INF-3DHP (3DHP) <ref type="bibr" target="#b32">[33]</ref> is a 3D human pose dataset containing annotated images recorded in three different settings: studio with green screen, studio without green screen and outdoors. We evaluate on the test split without utilizing the training data to assess the generalization capability of our network. Following previous works, the Percentage of Correct Keypoints (PCK) under 150 mm is adopted as the metric for 3DHP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>2D Detector: We use the publicly available HRNet <ref type="bibr" target="#b44">[45]</ref> pretrained on MPII <ref type="bibr" target="#b1">[2]</ref> as our 2D joint detector and finetune it on Human3.6M. Target ground-truth heatmaps are created with ? gt = 2 px.</p><p>Data Preprocessing: We center each 2D pose to its mean and divide it by its standard deviation. The 3D poses are processed in metres and also mean centered individually. Before evaluation, 3D poses are zero-centered around the hip joint to follow the standard protocols.</p><p>Network Details: The normalizing flow consists of 8 coupling blocks with fully-connected networks, denoted as subnetworks, as scale and translation functions. Each subnetwork upscales its input to 1024 dimensions with a fullyconnected layer. This is followed by a ReLU and a second fully-connected layer with dimension 48. The condition encoding network h ? follows the same design with 256 and 56 as output dimensions of the fully-connected layers. We set the clamping parameter inside the coupling blocks to ? = 2.0. For L MMD , we follow <ref type="bibr" target="#b2">[3]</ref> and employ a mixture of inverse multiquadratics kernels</p><formula xml:id="formula_11">? im S (v,v) = b?S b b + v ?v 2<label>(10)</label></formula><p>with bandwidth parameters S = {0.0025, 0.04, 0.81}. Training: The overall network is trained for 155 epochs using Adam <ref type="bibr" target="#b21">[22]</ref> with an initial learning rate of 1 ? 10 ?4 and momentum values ? 1 = 0.5 and ? 2 = 0.9. The learning rate is halved after 150 epochs, and a batch size of 64 is used. To improve optimization stability, we clip the gradients in the range <ref type="bibr">[?15, 15]</ref>. During training, the covariance matrices are computed from L = 200 3D pose hypotheses and the standard deviation threshold for the masking of L HM (Eq. 4) is set to ? t = 1.05 ? ? gt = 2.1. The weights of the different losses are set to ? MMD = 10, ? det = ? MB = 4 and ? HM = 750, and the number of best hypotheses selected in L MB to k = 5. Since we estimate 3D poses in metric scale, there needs to be a conversion factor defined to relate between covariance matrices from pose hypotheses and from heatmaps. We empirically found a good conversion factor to be 1 px = 10 mm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluation on Human3.6M</head><p>We follow previous works and report metrics for the best 3D pose hypothesis generated by our network. This is especially reasonable for ambiguous examples, where multiple diverse 3D poses form a correct solution for the 3D pose reconstruction. Therefore, instead of validating whether predictions are equal to a specific solution, we evaluate if that specific solution is contained in the set of predictions. Additionally, we show results for 3D poses generated with an all-zero latent vector z 0 . Since we sample z from N (0, I) during training, such poses are approximately the highest likelihood solutions. Following <ref type="bibr" target="#b39">[40]</ref>, we produce M = 200 hypotheses for each 2D input. The results of our approach and other state-of-the-art methods are shown in <ref type="table" target="#tab_0">Table 1</ref> outperform every competitor and achieve a clear improvement of 4.1% and 10.7% over the previous best scores under Protocol 1 and Protocol 2. Note that Li et al. <ref type="bibr" target="#b27">[28]</ref> only show detailed results for M = 5, but state that their model performance does not significantly improve when increasing M . We generated the numbers for <ref type="bibr" target="#b39">[40]</ref> under Protocol 2 (row marked with *) using their publicly available model, code and data, because they only report scores for the PMPJPE on subject 11. Outperforming the single prediction baseline of <ref type="bibr" target="#b31">[32]</ref> with z 0 generated poses (i.e. M = 1) shows that our model is additionally able to give strong single predictions.</p><p>To evaluate the performance on highly ambiguous examples, we compute results for the challenging subset H36MA. We use the publicly available code from <ref type="bibr" target="#b39">[40]</ref> and <ref type="bibr" target="#b27">[28]</ref> to compare with their approaches. As is shown in Table 2, we outperform both competitors significantly and by a larger margin than on the whole test set. This emphasizes the ability of our model to generate diverse hypotheses for highly ambiguous examples. We argue that the CPS is especially meaningful in this setting, since high individual joint errors that often occur for challenging poses cannot be averaged out as in e.g. MPJPE or PCK.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Transfer to MPI-INF-3DHP</head><p>To assess the generalization capability of our model, we evaluate on MPI-INF-3DHP. Note that neither the 2D detector nor the normalizing flow is trained on this dataset. The results are shown in <ref type="table">Table 3</ref>. Even though <ref type="bibr" target="#b27">[28]</ref> use the ground-truth 2D joints provided by the dataset, we clearly outperform them in all three settings. We also achieve com-  <ref type="table">Table 3</ref>. Quantitative results on MPI-INF-3DHP. We outperform the approach from <ref type="bibr" target="#b27">[28]</ref> by a large margin which even uses ground truth 2D joint positions. Note that <ref type="bibr" target="#b28">[29]</ref> is trained weakly supervised and therefore specifically built for transfer learning. However, we still achieve on par results and even outperform them in the challenging outdoor sequences.</p><p>petitive performance compared to the weakly supervised approach from <ref type="bibr" target="#b28">[29]</ref> that focuses on transfer learning. Our strong results for outdoor scenes further emphasize the generalization capability to different settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Sample Diversity</head><p>Heatmap Variance: We visually inspect the distribution of generated joint locations and compare them with the corresponding fitted Gaussians in <ref type="figure" target="#fig_0">Fig. 3</ref>. For visualization purposes, only three hypotheses are shown for all joints except the one with the highest uncertainty. As can be seen, the uncertainties of the 2D detector are reflected in the 3D hypotheses.</p><p>Depth Ambiguities: Even though variance in the depth direction is not explicitly optimized, our model learns to generate feasible hypotheses with varying depth. In fact, the standard deviation of the hypotheses averaged over all joints in the test set of Human3.6M is highest in the depth direction with 42.4 mm, compared to 18.3 mm and 17.3 mm in the xand y-directions. Ankle, elbow and wrist joints account for the highest amount of variance. A visual example of meaningful depth diversity is given in <ref type="figure" target="#fig_1">Fig. 4</ref>.</p><p>Sample Set Size and Noise Baseline: In <ref type="figure">Fig. 5</ref>, we plot the MPJPE on the subset H36MA with increasing number of samples. The best hypothesis performance of our model continues to improve significantly, further enlarging the gap to <ref type="bibr" target="#b39">[40]</ref>. To validate that our approach is superior to directly    <ref type="figure">Figure 5</ref>. Evaluation results on the subset H36MA for an increasing number of hypotheses. Our model further improves and enlarges the gap to <ref type="bibr" target="#b39">[40]</ref> and to a noise baseline. sampling from the fitted Gaussians, we also plot results for a sampling baseline. The baseline is constructed by adding noise sampled from the fitted Gaussians to each joint of the z 0 predictions. A constant Gaussian for the depth dimension is assumed. Evidently, the performance of this baseline saturates earlier and at a higher error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Ablation Studies</head><p>To quantify the influence of our proposed components and loss functions, we remove them individually and show the results in <ref type="table">Table 4</ref>. As can be seen, the removal of each component leads to a degradation in performance. When removing the heatmap condition, a large drop in the CPS can be observed. This shows that some individual joints cannot be reconstructed without the uncertainty information of the 2D detector. Providing the condition alone already leads to a significant improvement of the CPS, indicating that the network can automatically leverage the informa- tion to model ambiguities. Adding L HM further improves all metrics. The importance of the discriminator becomes especially evident when considering the worst hypothesis error instead of the best. For example, Protocol 2 computed for the worst hypothesis deteriorates from 86.8 mm to 284.1 mm without the discriminator. Thus, the adversarial training procedure ensures the feasibility of the generated poses. <ref type="table">Table 4</ref> also shows the influence of the number of best hypotheses k selected for computing L MB . Note that L MB with k = 1 is equivalent to the typical best-of-M loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper presents a normalizing flow based method for the ambiguous inverse problem of 3D human pose estimation from 2D inputs. We exploit the bijectivity of the normalizing flow by utilizing the known 3D to 2D projection during training. By incorporating uncertainty information from the heatmaps of a 2D pose detector, valuable information is maintained which is discarded by previous approaches. As demonstrated, the generated hypotheses reflect these uncertainties and additionally show meaningful diversity along the ambiguous depth of the joints. Furthermore, the introduction of a 3D pose discriminator ensures the geometrical feasibility of the poses and a proposed generalization of the best-of-M loss improves the performance. Experimental results show that our method outperforms all previous multi-hypotheses approaches in most metrics, especially on a challenging subset of Human3.6M containing highly ambiguous examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Qualitative Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Condition Influence</head><p>To further show the influence of the heatmap condition and of the loss LHM that forces the network to reflect the 2D detector uncertainty in the 3D hypotheses, we present several qualitative results in <ref type="figure" target="#fig_3">Fig. 7</ref>. Evidently, incorporating the heatmap condition alone already leads to meaningful diversity along the xand ydirections. Additionally optimizing LHM further increases the meaningful diversity of the pose hypotheses such that the uncertainties of the 2D detector as well as the depth ambiguities are modeled best.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Competitor Comparison</head><p>In <ref type="figure" target="#fig_4">Fig. 8</ref>, we show additional qualitative results comparing our method with the competing methods <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b39">40]</ref>. As can be seen, our method achieves significantly higher diversity mainly for occluded joints. The competing methods are unable to effectively model occlusions and uncertain detections. They only achieve significant diversity along the ambiguous depth of the joints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. High Confidence Detections</head><p>If the 2D detector has a high degree of confidence for the 2D pose detection in a given image, then low variance in the generated 3D hypotheses along the xand ydirections is expected. To validate this, we show qualitative results for images from Hu-man3.6M and MPI-INF-3DHP with low 2D detector uncertainty in <ref type="figure" target="#fig_5">Fig. 9</ref>. The generated hypotheses are shown from two perspectives such that diversity along the image and depth directions can be seen. Evidently, the hypotheses vary only slightly along the image directions and thus are all consistent with the input image. They show meaningful diversity along the ambiguous depth of the joints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Captured 2D Detector Uncertainty</head><p>In the following, we want to further verify that fitting a Gaussian to the heatmap can capture the uncertainty of the 2D detector well. Therefore, for each joint in the test split of Human3.6M, we show the mean of the standard deviations of the fitted Gaussian together with the 2D error in <ref type="figure">Fig. 6</ref>. As can be seen, the variances of the Gaussians correlate with the 2D error and thus are a good surrogate for the uncertainty of the 2D detector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performance Lower Number of Samples</head><p>To assess the influence of the number of generated hypotheses and make our approach better comparable to Li et al. <ref type="bibr" target="#b27">[28]</ref>, we evaluate on Human3.6M under Protocol 1 (MPJPE) and Protocol 2 (PMPJPE) for lower number of hypotheses in two different settings. However, we want to emphasize that our main goal is to model the full posterior distribution, which requires a larger number of samples. Instead of sampling from their model, Li et al. <ref type="bibr" target="#b27">[28]</ref> take the means of the Gaussian kernels as pose predictions. Thus, for better comparison, we emulate this by running K-Means <ref type="figure">Figure 6</ref>. Computed for all joints in the test split of Human3.6M.  on our M = 200 generated hypotheses. Additionally, we compare the performance when sampling from <ref type="bibr" target="#b27">[28]</ref> in <ref type="table" target="#tab_4">Table 5</ref> (rows marked with *). We outperform them in almost every setting and metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Inference Time</head><p>For inference time measurements, we run the code with Py-Torch 1.7.1 on a NVIDIA GeForce RTX 3090 (CUDA 11.4). The majority of the inference time comes from the 2D detector (32 ms) and the Gaussian fitting process (70 ms). Due to batch processing, generating multiple hypotheses brings nearly no overhead, with an inference time of 4.6 ms for a single and 5.1 ms for 1000 samples.   <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b39">40]</ref>. For visualization purposes, more than three hypotheses are shown only for the most ambiguous joint. The model from Li et al. <ref type="bibr" target="#b27">[28]</ref> can only generate five pose hypotheses. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>The uncertainties of the 2D detector are successfully reflected in the 3D pose hypotheses. For visualization purposes, we only show the fitted Gaussian and a high number of hypotheses for the joint with highest uncertainty.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Depth ambiguities can be modeled together with the uncertainties of the 2D detector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>z 0 + noise Sharma et al. [40] Ours</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 .</head><label>7</label><figDesc>Qualitative results of our full model, model without LHM, and the model without condition. For visualization purposes, more than three hypotheses are shown only for the most ambiguous joint.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 .</head><label>8</label><figDesc>Comparison with competing methods</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 .</head><label>9</label><figDesc>Qualitative results for images from Human3.6M and MPI-INF-3DHP with low 2D detector uncertainty. For each image, 50 pose hypotheses are generated and shown from two perspectives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Detailed results of MPJPE in millimetres on Human3.6M under Protocol 1 (no rigid alignment) and Protocol 2 (rigid alignment). Our model achieves state-of-the-art results, outperforming all other methods in nearly every activity. All scores are taken from the referenced papers, except the row marked with * which is computed using the publicly available official code and model from<ref type="bibr" target="#b39">[40]</ref>. The number of samples estimated by the respective approaches is denoted as M .</figDesc><table><row><cell>. We</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Table 4. Ablation studies on the subset H36MA.</figDesc><table><row><cell>Method</cell><cell cols="4">MPJPE? PMPJPE? PCK? CPS?</cell></row><row><cell>w/o condition</cell><cell>71.7</cell><cell>57.2</cell><cell>91.2</cell><cell>137.6</cell></row><row><cell>w/o L HM</cell><cell>72.4</cell><cell>56.2</cell><cell>92.2</cell><cell>157.3</cell></row><row><cell>w/o L gen</cell><cell>73.6</cell><cell>58.2</cell><cell>92.5</cell><cell>165.5</cell></row><row><cell>w/o L MB</cell><cell>76.0</cell><cell>58.5</cell><cell>91.6</cell><cell>161.4</cell></row><row><cell>L MB (k = 1)</cell><cell>71.8</cell><cell>54.9</cell><cell>92.6</cell><cell>167.4</cell></row><row><cell>L MB (k = 10)</cell><cell>70.7</cell><cell>54.9</cell><cell>93.3</cell><cell>168.3</cell></row><row><cell>L MB (k = 50)</cell><cell>71.0</cell><cell>55.2</cell><cell>93.1</cell><cell>168.0</cell></row><row><cell>Ours (Full)</cell><cell>71.0</cell><cell>54.2</cell><cell cols="2">93.4 171.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Results on Human3.6M under Protocol 1 (MPJPE) and Protocol 2 (PMPJPE). The scores for the rows marked with * are computed by sampling from the models.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/twehrbein/Probabilistic-Monocul ar-3D-Human-Pose-Estimation-with-Normalizing-Flows</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Information about the exact composition of the subset can be found in the official GitHub repository.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pose-conditioned joint angle limits for 3d human pose reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ijaz</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">2d human pose estimation: New benchmark and state of the art analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Analyzing inverse problems with invertible neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Lynton Ardizzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><forename type="middle">J</forename><surname>Kruse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Wirkert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">W</forename><surname>Rahner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><forename type="middle">S</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lena</forename><surname>Klessen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Maier-Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ullrich</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>K?the</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynton</forename><surname>Ardizzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>L?th</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Kruse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ullrich</forename><surname>K?the</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02392</idno>
		<title level="m">Guided image generation with conditional invertible neural networks</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">3d multibodies: Fitting sets of plausible 3d human models to ambiguous image data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Biggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Ehrhadt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Novotny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Mixture density networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
		<respStmt>
			<orgName>Aston University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Keep it SMPL: Automatic estimation of 3D human pose and shape from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">3d human pose estimation = 2d pose estimation + matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Hang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Optimizing network structure for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Ci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">NICE: non-linear independent components estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Density estimation using real NVP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning pose grammar to encode human body configuration for 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoshu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Made: Masked autoencoder for distribution estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A kernel twosample test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><forename type="middle">J</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Smola</surname></persName>
		</author>
		<idno>2012. 5</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="issue">25</biblScope>
			<biblScope unit="page">13</biblScope>
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multiple choice learning: Learning to produce multiple structured outputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abner</forename><surname>Guzm?n-Rivera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">In the wild human pose estimation using explicit 2d features and intermediate 3d representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikhsanul</forename><surname>Habibie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Exploiting temporal information for 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imtiaz</forename><surname>Mir Rayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Human3.6m: Large scale datasets and predictive methods for 3d human sensing in natural environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generating multiple diverse hypotheses for human 3d pose consistent with 2d joint detections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Jahangiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision Workshops</title>
		<imprint>
			<publisher>ICCVW</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">End-to-end recovery of human shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Improved variational inference with inverse autoregressive flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Durk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Normalizing flows: An introduction and review of current methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Kobyzev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Brubaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Vibe: Video inference for human body pose and shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Athanasiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to reconstruct 3d human pose and shape via model-fitting in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Proposal maps driven mcmc for estimating human body pose in static images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Mun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generating multiple hypotheses for 3d human pose estimation with mixture density network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Weakly supervised generative network for multiple 3d human pose hypotheses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hybrik: A hybrid analytical-neural inverse kinematics solution for 3d human pose and shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiefeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Cascaded deep monocular 3d human pose estimation with evolutionary training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shichao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Pratama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Keung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwang-Ting</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A simple yet effective baseline for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julieta</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayat</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Monocular 3d human pose estimation in the wild using improved cnn supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on 3D Vision (3DV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">3d human pose estimation from a single image via distance matrix regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesc</forename><surname>Moreno-Noguer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tuomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">C</forename><surname>Oikarinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sohrob</forename><surname>Hannah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kazerounian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.13668</idno>
		<title level="m">Graphmdn: Leveraging graph structure and deep learning to solve inverse problems</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Masked autoregressive flow for density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theo</forename><surname>Pavlakou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
		<idno>2017. 3</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Vibe: Video inference for human body pose and shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Learning Research (PMLR)</title>
		<meeting>Machine Learning Research (PMLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Same same but differnet: Semi-supervised defect detection with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Monocular 3d human pose estimation by generation and ordinal ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><forename type="middle">Teja</forename><surname>Varigonda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashast</forename><surname>Bindal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Physcap: Physically plausible monocular 3d motion capture in real time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soshi</forename><surname>Shimada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladislav</forename><surname>Golyanik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<idno>2020. 2</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Single image 3d human pose estimation from noisy observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Simo-Serra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramisa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Aleny?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Torras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Moreno-Noguer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Covariance scaled sampling for monocular 3d body tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Kinematic jump processes for monocular 3d human tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A family of nonparametric density estimation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><forename type="middle">G</forename><surname>Tabak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristina</forename><forename type="middle">V</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Density estimation by dual ascent of the log-likelihood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><forename type="middle">G</forename><surname>Tabak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Vanden-Eijnden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Mathematical Sciences</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A kinematic chain space for monocular motion capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanno</forename><surname>Ackermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision Workshops (EC-CVW)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Repnet: Weakly supervised training of an adversarial reprojection network for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Canonpose: Self-supervised monocular 3d human pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petrissa</forename><surname>Zell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Not all parts are created equal: 3d pose estimation by modelling bi-directional dependencies of body parts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoli</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00042</idno>
		<title level="m">Learning likelihoods with conditional normalizing flows</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Ghum &amp; Ghuml: Generative 3d human shape and articulated pose models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">Gabriel</forename><surname>Bazavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep kinematics analysis for monocular 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenbo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiancheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Weakly supervised 3d human pose and shape reconstruction with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">Gabriel</forename><surname>Bazavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Semantic graph convolutional networks for 3d human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubbasir</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
