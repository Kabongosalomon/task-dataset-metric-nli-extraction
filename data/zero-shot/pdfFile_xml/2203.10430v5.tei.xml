<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">g2pW: A Conditional Weighted Softmax BERT for Polyphone Disambiguation in Mandarin</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Chang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SUN Financial Holding CO., LTD</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chuan</forename><surname>Chang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SUN Financial Holding CO., LTD</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ren</forename><surname>Yeh</surname></persName>
							<email>yryeh@nknu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="institution">SUN Financial Holding CO., LTD</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">National Kaohsiung Normal University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">g2pW: A Conditional Weighted Softmax BERT for Polyphone Disambiguation in Mandarin</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T14:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms: polyphone disambiguation</term>
					<term>grapheme to phoneme</term>
					<term>weighted softmax</term>
					<term>BERT</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Polyphone disambiguation is the most crucial task in Mandarin grapheme-to-phoneme (g2p) conversion. Previous studies have approached this problem using pre-trained language models, restricted output, and extra information from Part-Of-Speech (POS) tagging. Inspired by these strategies, we propose a novel approach, called g2pW, which adapts learnable softmax-weights to condition the outputs of BERT with the polyphonic character of interest and its POS tagging. Rather than using the hard mask as in previous works, our experiments show that learning a soft-weighting function for the candidate phonemes benefits performance. In addition, our proposed g2pW does not require extra pre-trained POS tagging models while using POS tags as auxiliary features since we train the POS tagging model simultaneously with the unified encoder. Experimental results show that our g2pW outperforms existing methods on the public CPP dataset. All codes, model weights, and a user-friendly package are publicly available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Mandarin grapheme-to-phoneme (G2P), which converts Chinese texts into pronunciation (Bopomofo or Pinyin), is a crucial component of Mandarin text-to-speech (TTS) systems. In Mandarin G2P conversion, the most important task is to distinguish the pronunciation of a polyphonic character, called polyphone disambiguation. Specifically, polyphone disambiguation aims to identify the correct pronunciation of the given polyphonic characters within a sentence. According to previous studies, polyphone disambiguation approaches typically can be divided into rule-based and learning-based approaches.</p><p>The rule-based approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> heavily rely on linguistic experts to maintain robust dictionaries and complex predefined rules. Typically, such frameworks segment texts into word pieces, disambiguate the pronunciation of the word pieces matched in dictionaries, and apply hand-crafted rules to determine the pronunciation of the undetermined polyphonic characters. However, rule-based approaches often fail due to word pieces having distinctive meanings. For example, "?"? ? ? (translate: used "by" you) and "?"??? (translate: service "for" you) have the same word piece "?" but different meanings and pronunciations (??2 and ??4).</p><p>On the other hand, the learning-based approaches take contextual information into account to determine the pronunciation of a polyphonic character, such as learned statistical rules <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, Decision Tree <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, Maximum Entropy Model <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, and deep learning approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>. Among the learning-based approaches, deep learning meth- ods have achieved significant performance for extracting contextual features in polyphone disambiguation. For example, <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref> adopted bidirectional Long Short-Term Memory (BiLSTM) layers to obtain neighboring contextual features for the character of interest. <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b9">[10]</ref> leveraged additional Part-Of-Speech (POS) tagging and Word2Vec embeddings to obtain more information within a sentence. The sequence-to-sequence model with distant supervision is applied for polyphone disambiguation <ref type="bibr" target="#b11">[12]</ref>. In <ref type="bibr" target="#b12">[13]</ref>, the MASK-BASED approach applied word segmentation and POS tagging within a sentence and restricted the outputs by a weighted-softmax function.</p><p>Rather than training prediction models from scratch, recently the pre-trained language model (PLM) has taken advantage of self-supervised learning on vast volumes of unlabeled text data and benefited from downstream tasks after fine-tuning, with examples such as BERT <ref type="bibr" target="#b17">[18]</ref>. Many studies <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref> have shown that polyphone disambiguation can be improved by leveraging PLM in the polyphone disambiguation problem. For example, <ref type="bibr" target="#b16">[17]</ref> considered the lattice information to improve performance based on pre-trained BERT.</p><p>Based on the above-mentioned literature, PLM, restricted output, and extra information from POS tagging have benefited the polyphone disambiguation problem. Inspired by these strategies, we propose a novel approach, called g2pW, which adapts learnable softmax-Weights to condition the outputs of BERT with the polyphonic character of interest and its POS tagging, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Instead of applying the hard mask to softmax-weights as in <ref type="bibr" target="#b12">[13]</ref>, our g2pW learns a softweighting function for the candidate phonemes. Specifically, our g2pW applies the auxiliary features, such as the character of interest and its POS tagging, to learn an embedding for conditioning the weights in the softmax function. It is worth noting that, unlike previous works <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13]</ref>, our g2pW does not need an extra pre-trained POS tagging model. We train our polyphone disambiguation and POS tagging models simultaneously with the unified encoder (BERT). In our framework, we use the predicted POS tag from our joint-trained tagging model as the input for the conditional weight layer. Only a simple text is required for the input of our g2pW, and the simple architecture benefits the inference time. In our experiments, we show that our framework outperforms existing methods on the public CPP dataset <ref type="bibr" target="#b10">[11]</ref>. To evaluate the generalization ability of our proposed framework, we also created a new Mandarin polyphone dataset annotated by experts, called MPB (Mandarin Polyphones with Bopomofo). The details will be addressed in Section 3. The contributions of this work are summarized as follows:</p><p>? We propose a novel grapheme-to-phoneme model (g2pW) that adapts learnable softmax-weights to condition the outputs of BERT with the polyphonic character of interest and the POS tag extracted from the jointtrained tagging model.</p><p>? Our proposed g2pW outperforms existing methods on the public CPP dataset and achieves 99.08% accuracy.</p><p>? We released all codes 1 , model weights trained from the MPB dataset 1 , and a user-friendly package on PyPi 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Proposed method</head><p>As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, our proposed g2pW includes four components: (a) encoding, (b) phoneme prediction, (c) the conditional weight layer, and (d) POS prediction. We briefly describe the whole procedure of our framework. For the input of our g2pW, only a raw sentence and the position of the polyphonic character are required. To concentrate the nearby characters of the target polyphonic character, we truncated the raw sentence with a predefined window size lwin centered on the target character. The truncated text is also added with special tokens ([CLS] and [SEP]) before being forwarded to the encoder (BERT). After obtaining the contextual embedding of the target character et from the encoder, the feedforward networks W ph and Wpos transform et into the inputs of the phoneme prediction e ph and the inputs of POS prediction epos. It is worth noting that we extracted the POS tag of the target character directly from our joint-trained POS model. Once the POS tag is obtained, we re-encode the target character and its POS tag to generate the conditional weight wc from the conditional weight layer to constrain the output of the phoneme prediction model. Detailed descriptions are provided in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Phoneme prediction with weighted softmax</head><p>As shown in <ref type="figure" target="#fig_0">Figure 1</ref>(b), we apply a weighted softmax in our phoneme prediction model. Let n be the number of the phoneme labels and suppose that the conditional weights wc = {w1, w2, ..., wn} are calculated from conditional weight layer.</p><p>1 https://github.com/GitYCC/g2pW 2 https://pypi.org/project/g2pw The weighted softmax is denoted as follows:</p><formula xml:id="formula_0">y ph,i = wi ? exp{[W ph (et)]i} n j=1 wj ? exp{[W ph (et)]j} ,<label>(1)</label></formula><p>where? ph,i and [W ph (et)]i respectively represent the probability and logit of the i-th phoneme label. In our g2pW, the weighted softmax aims to condition the output of the phoneme prediction model by specific prior knowledge, such as what pronunciations we should focus on. We provide a detailed description in the next section. Given the weighted softmax from the conditional weight layer, the phoneme loss can be expressed as follows:</p><formula xml:id="formula_1">L ph = CrossEntropy(? ph , y ph ),<label>(2)</label></formula><p>where y ph is the ground truth of the phonemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Conditional weight layer</head><p>In our conditional weight layer, we adopt two strategies to obtain the learnable weights for conditioning the output of the phoneme prediction model. One is to reduce the possible label set by giving the target character. For example, there are only two possible pronunciations of ?, and we only need to determine the prediction from these two candidates. To tackle this problem, a weighted softmax with the hard mask/binary mask can be used to restrict outputs <ref type="bibr" target="#b12">[13]</ref>. That is, the weights of the non-candidate labels are set to zero as w h in <ref type="figure" target="#fig_1">Figure 2</ref>. Besides the hard mask, we further learn a soft-weighting function for the candidate labels. Specifically, we use the encodings of the target character and its POS tag as the auxiliary features to learn the soft-weighting function as shown in <ref type="figure" target="#fig_0">Figure 1</ref> (c) and <ref type="figure" target="#fig_1">Figure 2</ref>. Suppose the target character chart and its POS tag post are given, our soft-weights ws can be learned as follows:</p><formula xml:id="formula_2">ws = ?cross ? Ecross(chart ? post) ? ? char ? E char (chart) ? ?pos ? Epos(post) ? b,<label>(3)</label></formula><p>where ? is a tensor product which maps a pair (ui, vj) [ui ? u and vj ? v] to an element of u ? v and ? is an elementwise addition. Ecross, E char , and Epos are the learnable linear projection, and b is the learnable bias term. Note that ?cross, ? char , ?pos ? {0, 1} are hyper-parameters determined by experiments shown in <ref type="table" target="#tab_1">Table 2</ref>(b) of Section 3.3. In our experiments, we set ?cross = 1, ? char = 1, and ?pos = 0.</p><p>Once ws is determined, the conditional weight wc is denoted as follows:</p><formula xml:id="formula_3">wc = w h sigmoid(ws),<label>(4)</label></formula><p>where w h,i = 1, if candidate phoneme 0, otherwise <ref type="bibr" target="#b4">(5)</ref> and is element-wise multiplication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">POS prediction</head><p>Instead of using an extra pre-trained POS tagging model, we train the POS tagging model and phoneme prediction model simultaneously with the unified encoder (BERT) as shown in <ref type="figure" target="#fig_0">Figure 1(d)</ref>. In our joint-trained POS tagging task, we have 11 tags, including the unknown tag (UNK), adjective (A), conjunction (C), adverb (D), interjection (I), noun (N), preposition (P), particle (T), verb (V), DE, and SHI. The loss function of our POS tagging model is denoted as follows:</p><formula xml:id="formula_4">Lpos = CrossEntropy(?pos, ypos),<label>(6)</label></formula><p>where ypos is the ground truth of POS tagging and?pos is the predicted probability of POS tagging.</p><p>In our implementation, we adopt a teacher mode that directly assigns the ground truth y ph to the conditional weight layer during training. At the inference stage, we choose the POS tag with highest probability for the target character. In our proposed g2pW, the total loss can be expressed as follows:</p><formula xml:id="formula_5">L total = L ph + ? ? Lpos,<label>(7)</label></formula><p>where ? is the weight that controls the trade-off between L ph and Lpos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>In our experiments, we evaluate our g2pW with our proposed MPB dataset and public CPP dataset. We provide the implementation details in Section 3.1. The details of the MPB dataset are presented in Section 3.2. In Section 3.3, we use the MPB dataset to determine the hyperparameters in our g2pW. In Section 3.4, we use the public CPP dataset to benchmark our framework with existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Implementation details</head><p>In our g2pW, the framework learns phoneme prediction, conditional weight layer, and POS prediction on top of the pretrained encoder (BERT). Huggingface 3 provides the pre-trained BERT model, and the details of BERT are identical to the BERTBASE model (12 layers and 768 hidden sizes) described in <ref type="bibr" target="#b17">[18]</ref>. Rather than freezing the weights of BERT, we trained our g2pW and fine-tuned BERT simultaneously. For the input of our model, we set the window size lwin to truncate the raw text to a subtext with a length of 32 in our experiments. We use the Adam optimizer and set the learning rate to 5e-5. The model is validated after every 200 iterations with a batch size of 256. Once 10,000 iterations is reached, the model with the highest validation accuracy is used for prediction. In our joint-trained POS tagging model, the tags are extracted from Ckiptagger 4 for training. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The MPB dataset</head><p>In our experiments, we first evaluate our g2pW with our inhouse Mandarin Polyphone dataset with Bopomofo (MPB). Experts annotated all the pronunciations of the polyphonic characters in the MPB dataset using the <ref type="bibr" target="#b10">[11]</ref> format. The MPB dataset includes 2,610,344 sentences and 436 polyphonic characters. Most polyphones are associated with 2 or 3 pronunciations, and only 17 polyphonic characters had fewer than 10 sentences in the dataset. In our experiment, we sample the sentences stratified by the polyphone and split them into the training, development, and test sets with a ratio of 10:1:1. More details are described in <ref type="table" target="#tab_0">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Experiments on the MPB dataset</head><p>In our g2pW, (?cross, ? char , ?pos) in (3) and ? in <ref type="formula" target="#formula_5">(7)</ref> are two crucial hyper-parameters. In this experiment, we evaluate our g2pW with the MPB dataset and determine these hyperparameters.</p><p>Evaluation with different (?cross, ? char , ?pos). To determine the optimal combination of (?cross, ? char , ?pos), we intuitively assigned ? as 0.1 since the main objective of our task is phoneme prediction. By fixing the value of ?, we present results of all the combinations of (?cross, ? char , ?pos) in <ref type="table" target="#tab_1">Table 2</ref>(a) and show that (?cross, ? char , ?pos) = (1, 1, 0) achieves the highest accuracy. Therefore, we use this combination in our g2pW.</p><p>Evaluation with different ?.</p><p>Once the optimal (?cross, ? char , ?pos) is determined, we further search for a proper ?. As mentioned in Section 2.3, ? is the weight that controls the trade-off between L ph and Lpos. This experiment searches the optimal ? between 0.01 to 1 since the main objective is phoneme prediction. As shown in <ref type="table" target="#tab_1">Table 2</ref>(b), a larger ? achieves more accurate POS tagging. However, overemphasizing the loss of the POS tagging task will sacrifice the performance of phoneme prediction. In <ref type="table" target="#tab_1">Table 2</ref>(b), according to the highest accuracy, we chose ? = 0.1 in our g2pW.  Contribution investigation within our framework. In Table 2(c), we first compare our g2pW with the baseline in which the pure fine-tuned BERT is used. Our g2pW provides an accuracy improvement of 0.14% from the baseline.</p><p>On the other hand, as shown in <ref type="table" target="#tab_0">Table 1</ref>(c), the accuracy of a particular character with larger cardinality will dominate the accuracies of other characters with smaller cardinality. Thus, we also reported the averaged accuracy by characters:</p><formula xml:id="formula_6">1 C c accuracy({(? ph , y ph ) | chart = c})</formula><p>where C is the number of all polyphonic characters. As shown in <ref type="table" target="#tab_1">Table 2</ref>(c), our g2pW provides a significant improvement of 4.07% to the test averaged accuracy by character compared with the baseline.</p><p>As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, our g2pW is composed of several critical components, such as the hard mask, conditional weight layer, and joint-trained POS tagging task. According to the results from the baseline model, removing all these components will sacrifice performance. In the following experiments, we investigate the discrete contributions of these components. The first experiment removeds the conditional weight layer and directly uses the hard mask in the weighted softmax. Compared to g2pW, removing the conditional weight layer will decrease accuracy, as shown in the second row of Table 2(c). The second experiment removes the POS joint-training tagging task and obtains worse performance, as shown in the third row of Table 2(c). The third and final experiment removes the remaining hard mask in our framework (i.e., the baseline model). We set w h in (4) by a vector filled with the scalar value 1. From the result of the baseline model, removing the hard mask has a significantly negative impact on performance. It is worth noting that our g2pW still can provide further improvements on top of the significant performance achieved by using the hard mask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Public benchmark</head><p>In our final experiment, we compare our proposed g2pW with existing approaches by using the public CPP dataset <ref type="bibr" target="#b10">[11]</ref>. The implementation details and experimental settings are the same as the experiments of the MPB dataset described in Section 3.1. From the results of <ref type="table" target="#tab_2">Table 3</ref>, our g2pW achieves 99.08% test accuracy and outperforms the existing approaches. Compared with the state-of-the-art method, PDF (with BERT) <ref type="bibr" target="#b16">[17]</ref>, our g2pW improves 0.25% testing accuracy. It is worth noting that PDF (with BERT) requires an extra dictionary to extract the lattice information while only raw sentences are required as the input in our g2pW.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The framework of g2pW includes four components: (a) encoding, (b) phoneme prediction, (c) the conditional weight layer, and (d) POS prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The structure of the conditional weight layer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the MPB dataset</figDesc><table><row><cell></cell><cell cols="2">(a) Dataset division</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Train</cell><cell>Dev.</cell><cell>Test</cell></row><row><cell>sentences (#)</cell><cell cols="4">2,175,097 217,597 217,650</cell></row><row><cell cols="2">polyphonic char.s (#)</cell><cell>436</cell><cell cols="2">433</cell><cell>435</cell></row><row><cell cols="2">(b) Frequency of polyphonic</cell><cell cols="3">(c) Frequency of polyphonic</cell></row><row><cell cols="2">characters according to the</cell><cell cols="3">characters according to the size</cell></row><row><cell cols="2">numbers of pronunciations</cell><cell cols="2">of sentences</cell></row><row><cell cols="2">pronunc. polyphonic</cell><cell cols="2">sentences</cell><cell>polyphonic</cell></row><row><cell>(#)</cell><cell>char.s (#)</cell><cell>(#)</cell><cell></cell><cell>char.s (#)</cell></row><row><cell>2</cell><cell>379</cell><cell cols="2">0 ? 10 1</cell><cell>17</cell></row><row><cell>3</cell><cell>48</cell><cell cols="2">10 1 ? 10 2</cell><cell>73</cell></row><row><cell>4</cell><cell>5</cell><cell cols="2">10 2 ? 10 3</cell><cell>119</cell></row><row><cell>5</cell><cell>2</cell><cell cols="2">10 3 ? 10 4</cell><cell>156</cell></row><row><cell>6</cell><cell>2</cell><cell cols="2">10 4 ? 10 5</cell><cell>69</cell></row><row><cell>total</cell><cell>436</cell><cell cols="2">10 5 ? 10 6</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell>total</cell><cell></cell><cell>436</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Experimental results on the MPB dataset (a) Evaluation with different (?cross, ? char , ?pos)</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) Evaluation with different ?</cell></row><row><cell>Hard</cell><cell cols="2">Learnable Weight</cell><cell>POS</cell><cell>Dev. / Test</cell><cell></cell><cell>Hard</cell><cell cols="2">Learnable Weight</cell><cell>POS</cell><cell>Dev. / Test</cell><cell>Test POS</cell></row><row><cell cols="3">Mask (?cross, ? char , ?pos )</cell><cell>Joint</cell><cell>Acc. (%)</cell><cell></cell><cell cols="3">Mask (?cross, ? char , ?pos )</cell><cell>Joint</cell><cell>Acc. (%)</cell><cell>Acc. (%)</cell></row><row><cell></cell><cell cols="2">(0, 1, 0)</cell><cell cols="2">?=0.1 99.62 / 99.62</cell><cell></cell><cell></cell><cell></cell><cell>(1, 1, 0)</cell><cell>?=.01 99.62 / 99.60</cell><cell>95.73</cell></row><row><cell></cell><cell cols="2">(0, 0, 1)</cell><cell cols="2">?=0.1 99.63 / 99.63</cell><cell></cell><cell></cell><cell></cell><cell>(1, 1, 0)</cell><cell>?=.02 99.64 / 99.62</cell><cell>96.40</cell></row><row><cell></cell><cell cols="2">(0, 1, 1)</cell><cell cols="2">?=0.1 99.63 / 99.63</cell><cell></cell><cell></cell><cell></cell><cell>(1, 1, 0)</cell><cell>?=.05 99.62 / 99.62</cell><cell>97.14</cell></row><row><cell></cell><cell cols="2">(1, 0, 0)</cell><cell cols="2">?=0.1 99.63 / 99.62</cell><cell></cell><cell></cell><cell></cell><cell>(1, 1, 0)</cell><cell>?=0.1 99.64 / 99.64</cell><cell>97.48</cell></row><row><cell></cell><cell cols="2">(1, 1, 0)</cell><cell cols="2">?=0.1 99.64 / 99.64</cell><cell></cell><cell></cell><cell></cell><cell>(1, 1, 0)</cell><cell>?=0.2 99.63 / 99.61</cell><cell>97.72</cell></row><row><cell></cell><cell cols="2">(1, 0, 1)</cell><cell cols="2">?=0.1 99.62 / 99.63</cell><cell></cell><cell></cell><cell></cell><cell>(1, 1, 0)</cell><cell>?=0.5 99.62 / 99.61</cell><cell>97.92</cell></row><row><cell></cell><cell cols="2">(1, 1, 1)</cell><cell cols="2">?=0.1 99.61 / 99.61</cell><cell></cell><cell></cell><cell></cell><cell>(1, 1, 0)</cell><cell>?=1.0 99.60 / 99.59</cell><cell>97.91</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">(c) Contribution investigation within our framework</cell></row><row><cell></cell><cell>System</cell><cell>Hard</cell><cell cols="2">Learnable Weight</cell><cell>POS</cell><cell cols="4">Test Acc. Test Averaged Accuracy Test POS</cell></row><row><cell></cell><cell></cell><cell cols="3">Mask (?cross, ? char , ?pos)</cell><cell>Joint</cell><cell></cell><cell>(%)</cell><cell cols="2">by Characters (%)</cell><cell>Acc. (%)</cell></row><row><cell></cell><cell>g2pW</cell><cell></cell><cell></cell><cell>(1, 1, 0)</cell><cell>?=0.1</cell><cell cols="2">99.64</cell><cell>95.25</cell><cell>97.48</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>?</cell><cell>?=0.1</cell><cell cols="2">99.61</cell><cell>94.47</cell><cell>97.46</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>?</cell><cell>?</cell><cell cols="2">99.60</cell><cell>94.63</cell><cell>-</cell></row><row><cell></cell><cell>baseline</cell><cell>?</cell><cell></cell><cell>?</cell><cell>?</cell><cell cols="2">99.50</cell><cell>91.18</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Benchmarks on the CPP dataset</figDesc><table><row><cell>System</cell><cell cols="2">Year Test Acc. (%)</cell></row><row><cell>g2pM (BiLSTM) [11]</cell><cell>2020</cell><cell>97.31</cell></row><row><cell cols="2">Distant supervision [12] 2020</cell><cell>97.51</cell></row><row><cell>MASK-BASED [13]</cell><cell>2020</cell><cell>97.68</cell></row><row><cell>g2pM (BERT) [11]</cell><cell>2020</cell><cell>97.85</cell></row><row><cell>BERT with LSTM [17]</cell><cell>2021</cell><cell>98.04</cell></row><row><cell>PDF (with BERT) [17]</cell><cell>2021</cell><cell>98.83</cell></row><row><cell>g2pW</cell><cell></cell><cell>99.08</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://huggingface.co/bert-base-chinese 4 https://github.com/ckiplab/ckiptagger</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We propose a novel grapheme-to-phoneme model (g2pW) that adapts learnable softmax-weights to condition the outputs of BERT. In our experiments, we show the conditional weighted softmax conditioned with the polyphonic character of interest and its POS tagging improves performance of polyphone disambiguation. From the results, we also show that our g2pW outperforms existing methods on the public CPP dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Acknowledgements</head><p>This work was supported in part by the E.SUN Financial Holding CO., LTD. of Taiwan and the Ministry of Science and Technology of Taiwan under Grants MOST 108-2221-E-017-008-MY3.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Processing of polyphone character in chinese tts system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chinese Information</title>
		<imprint>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="33" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Disambiguation of chinese polyphonic characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiangsheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Weidong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shiwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First International Workshop on MultiMedia Annotation (MMA)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An efficient way to learn rules for grapheme-to-phoneme conversion in chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zirong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Eric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Chinese Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Disambiguating effectively chinese polyphonic ambiguity based on unify approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-L</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICMLC</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Polyphonic word disambiguation with machine learning approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Genetic and Evolutionary Computing (ICGEC)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Polyphone disambiguation based on treeguided tbl</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Engineering and Applications</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="137" to="140" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Inequality maximum entropy classifier with character features for polyphone disambiguation in mandarin tts systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno>IV-705-IV-708</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing -ICASSP &apos;07</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Polyphone disambiguation based on maximum entropy model in mandarin grapheme-to-phoneme conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Key Engineering Materials</title>
		<imprint>
			<biblScope unit="page" from="1043" to="1048" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A bi-directional lstm approach for polyphone disambiguation in mandarin chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Symposium on Chinese Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Polyphone disambiguation for mandarin chinese using conditional neural network with multi-level embedding features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">g2pm: A neural grapheme-to-phoneme conversion package for mandarin chi-nese based on a new open benchmark dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distant supervision for polyphone disambiguation in mandarin chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTER-SPEECH</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A mask-based model for mandarin chinese polyphone disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Disambiguation of chinese polyphones in an end-to-end framework with semantic features extracted by pre-trained bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>in IN-TERSPEECH</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Pre-trained text representations for improving front-end text processing in mandarin text-to-speech synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Polyphone disambiguition in mandarin chinese with semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Pdf: Polyphone disambiguation in chinese by using flat</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Bert: Pretraining of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">in arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
