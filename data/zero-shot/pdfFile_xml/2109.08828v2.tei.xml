<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Perspective-taking and Pragmatics for Generating Empathetic Responses Focused on Emotion Causes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunwoo</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byeongchang</forename><surname>Kim</surname></persName>
							<email>byeongchang.kim@vl.snu.ac.krgunhee@snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunhee</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Perspective-taking and Pragmatics for Generating Empathetic Responses Focused on Emotion Causes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T07:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Empathy is a complex cognitive ability based on the reasoning of others' affective states. In order to better understand others and express stronger empathy in dialogues, we argue that two issues must be tackled at the same time: (i) identifying which word is the cause for the other's emotion from his or her utterance and (ii) reflecting those specific words in the response generation. However, previous approaches for recognizing emotion cause words in text require sub-utterance level annotations, which can be demanding. Taking inspiration from social cognition, we leverage a generative estimator to infer emotion cause words from utterances with no word-level label. Also, we introduce a novel method based on pragmatics to make dialogue models focus on targeted words in the input during generation. Our method is applicable to any dialogue models with no additional training on the fly. We show our approach improves multiple best performing dialogue agents on generating more focused empathetic responses in terms of both automatic and human evaluation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Empathy is one of the hallmarks of social cognition. It is an intricate cognitive ability that requires high-level reasoning on other's affective states. The intensity of expressed empathy varies depending on the depth of reasoning. According to <ref type="bibr" target="#b21">Sharma et al. (2020)</ref>, weak empathy is accompanied by generic expressions such as "Are you OK?" or "It's just terrible, isn't it?", while stronger empathy reflects the other's specific situation: "How is your headache, any better?" or "You must be worried about the job interview". In order to respond with stronger empathy, two issues must be tackled: reasoning (i) where to focus on the interlocutor's utterance (for the reason behind the emotion) and (ii) how to generate utterances that focus on such words.</p><p>Firstly, which words should we focus on when empathizing with others? As empathy relates to other's emotional states, the reasons behind emotions (emotion cause) should be identified. Imagine you are told "I got a gift from a friend last vacation!" with a joyful face. The likely words that can be the causes of his/her happiness are "gift" and "friend". On the other hand, "vacation" has less to do with the emotion. If you respond "How was your vacation?", the interlocutor may think you are not interested; rather, it is better to say "Wow, what was the gift?" or "Your friend must really like you." by focusing on the emotion cause words.</p><p>We humans do not rely on word-level supervision for such affective reasoning. Instead, we put ourselves in the other's shoes and simulate what it would be like. Perspective-taking is this act of considering an alternative point of view for a given situation. According to cognitive science, perspectivetaking and simulation are key components in empathetic reasoning <ref type="bibr">(Davis, 1983;</ref><ref type="bibr">Batson et al., 1991;</ref><ref type="bibr" target="#b19">Ruby and Decety, 2004)</ref>. Taking inspiration from these concepts, we propose to train a generative emotion estimator for simulating the other's situation and identifying emotion cause words.</p><p>Secondly, after reasoning which words to focus on, the problem of how to generate focused responses still remains. Safe responses that can be adopted to any situations might hurt other's feelings. Generated utterances need to convey the impression that concerns the specific situation of the interlocutor. Such communicative reasoning is studied in the field of computational pragmatics. The Rational Speech Acts (RSA) framework <ref type="bibr">(Frank and Goodman, 2012)</ref> formulates communication between speaker and listener as probabilistic reasoning. It has been applied to many tasks to increase the informativeness of generated text grounded on inputs <ref type="bibr">(Andreas and Klein, 2016;</ref><ref type="bibr">Fried et al., 2018;</ref><ref type="bibr">Cohn-Gordon and Goodman, 2019;</ref><ref type="bibr" target="#b22">Shen et al., 2019)</ref>. That is, RSA allows the input to be more reflected in the generated output.</p><p>However, controlling the RSA framework to re-flect specific parts of the input remains understudied. We introduce a novel method for the RSA framework to make models focus on targeted words in the interlocutor's utterance during generation. In summary, we recognize emotion cause words in dialogue utterances with no word-level labels and generate stronger empathetic responses focused on them without additional training. Our major contributions are as follows:</p><p>(1) We identify emotion cause words in dialogue utterances by leveraging a generative estimator. Our approach requires no additional emotion cause labels other than the emotion label on the whole sentence, and outperforms other baselines.</p><p>(2) We introduce a new method of controlling the Rational Speech Acts framework <ref type="bibr">(Frank and Goodman, 2012)</ref> to make dialogue models better focus on targeted words in the input context to generate more specific empathetic responses.</p><p>(3) For evaluation, we annotate emotion cause words in emotional situations from the validation and test set of EmpatheticDialogues dataset <ref type="bibr" target="#b15">(Rashkin et al., 2019)</ref>. We publicly release our EMOCAUSE evaluation set for future research.</p><p>(4) Our approach improves model-based empathy scores <ref type="bibr" target="#b21">(Sharma et al., 2020)</ref> of three recent dialogue agents, MIME <ref type="bibr">(Majumder et al., 2020)</ref>, DodecaTransformer , and Blender <ref type="bibr" target="#b17">(Roller et al., 2021)</ref> on EmpatheticDialogues. User studies also show that our approach improves human-rated empathy scores and is more preferred in A/B tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Empathetic dialogue modeling. Incorporating user sentiment is one of early attempts for empathetic conversation generation <ref type="bibr" target="#b25">(Siddique et al., 2017;</ref><ref type="bibr" target="#b23">Shi and Yu, 2018)</ref>. <ref type="bibr" target="#b15">Rashkin et al. (2019)</ref> collect a large-scale English empathetic dialogue dataset named EmpatheticDialogues. The dataset is now adopted in other dialogue corpus such as DodecaDialogue  and BST <ref type="bibr" target="#b26">(Smith et al., 2020)</ref>. As a result, pretrained large dialogue agents such as DodecaTransformer  and Blender <ref type="bibr" target="#b17">(Roller et al., 2021)</ref> now show empathizing capabilities. Empathyspecialized dialogue models are another stream of research. Diverse architectures have been adopted, including emotion recognition <ref type="bibr" target="#b7">(Lin et al., 2020)</ref>, mixture of experts <ref type="bibr" target="#b6">(Lin et al., 2019)</ref>, emotion mimicry <ref type="bibr">(Majumder et al., 2020)</ref> and persona <ref type="bibr" target="#b30">(Zhong et al., 2020)</ref>. <ref type="bibr" target="#b3">Li et al. (2020)</ref> use lexicon to extract emotion-related words from utterances and feed them to a GAN-based agent.</p><p>We aim to improve both pretrained large dialogue agents and empathy-specialized ones by making them focus on emotion cause words in context.</p><p>Emotion Cause (Pair) Extraction. The emotion cause extraction (ECE) task predicts causes in text spans, given an emotion. Cause spans have been collected from Chinese microblogs and news <ref type="bibr" target="#b0">(Gui et al., 2014</ref><ref type="bibr">(Gui et al., , 2016</ref>, English novels <ref type="bibr">(Gao et al., 2017)</ref>, and English dialogues <ref type="bibr">(Poria et al., 2020)</ref>. <ref type="bibr" target="#b28">Xia and Ding (2019)</ref> propose a task of extracting pairs of both emotion and its cause spans. Previous works tackle these tasks via supervised learning with question-answering <ref type="bibr">(Gui et al., 2017</ref><ref type="bibr">), jointlearning (Chen et al., 2018</ref>, co-attention <ref type="bibr" target="#b4">(Li et al., 2018)</ref>, and regularization <ref type="bibr">(Fan et al., 2019)</ref>.</p><p>Compared to those tasks, we recognize emotion cause words with no word-level labels using a generative estimator. Our method does not require word-level labels other than the emotion labels of the whole sentences. We then generate more specific empathetic responses focused on them.</p><p>Rational Speech Acts (RSA) framework. The RSA framework (Frank and Goodman, 2012) has been applied to many NLP tasks including <ref type="bibr">referencing (Andreas and Klein, 2016;</ref><ref type="bibr" target="#b29">Zarrie? and Schlangen, 2019)</ref>, captioning <ref type="bibr" target="#b27">(Vedantam et al., 2017;</ref><ref type="bibr">Cohn-Gordon et al., 2018</ref><ref type="bibr">), navigating (Fried et al., 2018</ref>, translation (Cohn-Gordon and Goodman, 2019), summarization <ref type="bibr" target="#b22">(Shen et al., 2019)</ref>, and dialogue <ref type="bibr">(Kim et al., 2020)</ref>. It can improve informativeness of generated utterances better grounded on inputs (e.g. images, texts).</p><p>Compared to previous use of RSA, we propose an approach that can control the models to focus on targeted words from the given input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Identifying Emotion Cause Words with Generative Emotion Estimation</head><p>Our approach consists of two steps: (i) recognizing emotion cause words from utterances with no word-level labels ( ?3), and (ii) generating empathetic responses focused on those words ( ?4). In this section, we first train a generative emotion estimator to identify emotion cause words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Why Generative Emotion Estimator?</head><p>We leverage a generative model by taking inspiration from perspective-taking (i.e. simulating one-self in other's shoes) to reason emotion causes; not requiring word-level labels. Our idea is to estimate the emotion cause weight of each word in the utterance while satisfying the following three desiderata.</p><p>(1) Do not require word-level supervision for learning to identify emotion cause words in the utterances. Humans do not need word-level labels to infer the probable causes associated with the other's emotion during conversation.</p><p>(2) Simulate the observed interlocutor's situation within the model. Simulation theory (ST) from cognitive science explains that this mental imitation helps understanding the internal mental states of others <ref type="bibr">(Gallese et al., 2004)</ref>. Much evidence for ST is found from neuroscience including mirror neurons <ref type="bibr" target="#b16">(Rizzolatti and Craighero, 2004)</ref>, action-perception coupling <ref type="bibr">(Decety and Chaminade, 2003)</ref>, and empathetic perspective-taking <ref type="bibr" target="#b19">(Ruby and Decety, 2004)</ref>.</p><p>(3) Reason other's internal emotional states in Bayesian fashion. Studies from cognitive science argue that human reasoning of other's affective states and minds can be described via Bayesian inference <ref type="bibr">(Griffiths et al., 2008;</ref><ref type="bibr" target="#b12">Ong et al., 2015;</ref><ref type="bibr" target="#b20">Saxe and Houlihan, 2017;</ref><ref type="bibr" target="#b13">Ong et al., 2019)</ref>.</p><p>Interestingly, a generative emotion estimator (GEE), which models P (C, E) = P (E)P (C|E) with text sequence (e.g. context) C and emotion E, satisfies all the above conditions. First, the generative estimator computes the likelihood of C by generating C given E, which can be viewed as a simulation of C. Second, it estimates P (E|C) via Bayes' rule. Finally, the association between the emotion estimate and each word comes for free by using the likelihood of each words; without using any word-level supervision. We use BART <ref type="bibr" target="#b2">(Lewis et al., 2020)</ref> to implement a GEE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training to Model Emotional Situations</head><p>Dataset. To train our GEE, we leverage the Em-patheticDialogues (Rashkin et al., 2019), a multiturn English dialogue dataset where the speaker talks about an emotional situation and the listener expresses empathy. An example is shown in Table 1. The emotion and the situation sentence are only visible to the speaker. Situations are collected beforehand by asking annotators to recall related experiences for a given emotion label. The dataset includes a rich suite of 32 emotion labels that are evenly distributed.</p><p>Emotion: Grateful Situation: I was grateful when my mother visited me for my birthday.</p><p>Speaker: It was my birthday, my mom came to surprise me. Listener: Aw that's so nice, how did she surprise you? Speaker: She showed up to my house and brought me a cake. Listener: Cakes! yessss winning. :)  Training. Given an emotion label E, GEE is trained to generate its corresponding emotional situation C = {w 1 , ..., w T }, where w i is a word. As a result, our GEE learns the joint probability P (C, E). The trained GEE shows perplexity of 13.6 on the test situations of EmpatheticDialogues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Recognizing Emotions</head><p>Once trained, GEE can predict P (E|C = c) for a word sequence c (e.g. utterance) using Bayes' rule:</p><formula xml:id="formula_0">P (E|C = c) ? P (C = c|E)P (E).</formula><p>(1)</p><p>We compute the likelihood P (C = c|E) by GEE's generative ability as described in ?3.1. Since emotions in EmpatheticDialogues are almost evenly distributed, we set the prior P (E) to a uniform distribution. Finally, we find the emotion with the highest likelihood of the given sequence c.</p><p>We comparatively report the emotion classification accuracy of GEE in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Weakly Supervised Emotion Cause Word Recognition</head><p>We introduce how GEE can recognize emotion cause words solely based on emotion labels without word-level annotations. For a given word sequence c = {w 1 , w 2 , ..., w T } (e.g. utterance), GEE can reason the association P (W |E =?) of each word w t in the sequence c to the recognized emotion? in Bayesian fashion:</p><formula xml:id="formula_1">P (W |E =?) ? P (E =?|W )P (W ). (2)</formula><p>The emotion likelihood is computed as</p><formula xml:id="formula_2">P (?|W = w t ) = E w&lt;t [P (?|w t , w &lt;t )] (3) ? P (w t |?, w &lt;t )P (?) e ?E P (w t |e , w &lt;t )P (e ) ,</formula><p>where w &lt;t is the partial utterance up to time step t ? 1. Since computing the expectation over all possible partial utterance w &lt;t is intractable, we approximate it by a single sample. We build set E to include? and emotions with the two lowest probability of P (E|C = c) when recognizing emotion in Eq.(1). We assume the marginal P (W ) is uniform. We choose the top-k words reasoned by GEE as emotion cause words, and focus on them during empathetic response generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Controlling the RSA framework for Focused Empathetic Responses</head><p>We introduce how to control the Bayesian Rational Speech Acts (RSA) framework (Frank and Goodman, 2012) to focus on targeted words in the context during response generation. We first preview the basics of RSA for dialogues ( ?4.1). We then present how to control the RSA with word-level focus ( ?4.2), where our major contribution lies. <ref type="figure">Figure 1</ref> is the overview of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Rational Speech Acts Framework</head><p>Applying the RSA framework is computing the posterior of the dialogue agent's output distribution over words each time step. Hence, it is applicable to any existing pretrained dialogue agents on the fly, with no additional training. The RSA framework formulates communication as a reference game between speaker and listener. Based on recursive Bayesian formulation, the speaker (i.e. dialogue model) reasons about the listener's belief of what the speaker is referring to. We follow the approach of <ref type="bibr">Kim et al. (2020)</ref> for adopting RSA to dialogues. Our goal here is to update a base speaker S 0 to a pragmatic speaker S 1 that focuses more on the emotion cause words in dialogue context c (i.e. dialogue history).</p><p>Base Speaker S 0 . Let c and u t denote dialogue context and the output word of the model at time step t, respectively. The base speaker S 0 is a dialogue agent that outputs u t for a dialogue context and partial utterance u &lt;t : S 0 (u t |c, u &lt;t ). As described, one can use any dialogue models for S 0 .</p><p>Pragmatic Listener L 0 . The pragmatic listener is a posterior distribution over which dialogue con- text the speaker is referring to. It is defined in terms of the base speaker S 0 and a prior distribution p t (C) over the context in Bayesian fashion:</p><formula xml:id="formula_3">? { ! , " , # , ? , $%! , $ } Dialogue Context GEE: ( | = ) 1. Emotion Recognition GEE: ( | = ) 2. Emotion Cause Recognition ! , " , ? , # , $ , ? , % , &amp; Top-k words GEE (~; ? &amp; , ' , ( ) 3. Sample Distractor Contexts ? { ! , ? , 5 &amp; , 5 ' , ? , 5 ( , $ } Distractors for Pragmatic Listener ! Pragmatic Speaker: ! ( | ) ? * * ( | ) Empathetic Response focused on &amp; , ' , ( *</formula><formula xml:id="formula_4">L 0 (c|u ?t , p t ) ? S 0 (u t |c, u &lt;t ) ? ? p t (c) c ?C S 0 (u t |c , u &lt;t ) ? ? p t (c )</formula><p>. <ref type="formula">(4)</ref> The shared world C is a finite set comprising the given dialogue context c and other contexts (coined as distractors) different from c. Our contribution lies in how to build world C to endow the dialogue agent with controllability to better focus on targeted words, which we discuss in ?4.2. We update prior p t+1 (C) with L 0 from time step t as follows: p t+1 (C) = L 0 (C|u ?t , p t ). ? is the rationality parameter which controls how much the base speaker's distribution is taken into account. We note that L 0 is simply a distribution computed in Bayesian fashion, not another separate model. Pragmatic Speaker S 1 . Integrating L 0 with S 0 , we obtain the pragmatic speaker S 1 :</p><formula xml:id="formula_5">S 1 (u t |c, u &lt;t ) ? L 0 (c|u ?t , p t ) ? ? S 0 (u t |c, u &lt;t ). (5)</formula><p>Since the pragmatic speaker S 1 is forced to consider how its utterance is perceived by the listener (via L 0 ), it favors words that have high likelihood of the given context c over other contexts in shared world C. Similar to Eq. 4, ? is the rationality parameter for S 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Endowing Word-level Control for RSA to Focus on Targeted Words in Context</head><p>We aim to make dialogue models focus on targeted words from the input (i.e. dialogue context) during generation via shared world C. The shared world C consists of the given dialogue context c and other distractor contexts. It is used for computing the likelihood of the given context c in Eq. 4. Previous works of RSA in NLP manually (or randomly) select pieces of text (e.g. sentences) entirely different from the given input (Cohn-Gordon and Goodman, 2019; <ref type="bibr" target="#b22">Shen et al., 2019;</ref><ref type="bibr">Kim et al., 2020)</ref>. In our context, it means distractors will be totally different contexts from c in the dataset. For example, when given a context "I got a gift from my friend.", a distractor might be "Today, I have an exam at school.". Although such type of distractors helps improve the specificity of the model's generated outputs, it is difficult to finely control which words the models should be specific about.</p><p>Our core idea is to build distractors by replacing the emotion cause words in c with different words via sampling with GEE. It can enhance the controllability of the RSA by making models focus on targeted words (e.g. emotion cause words recognized by GEE) from the dialogue context.</p><p>For a dialogue context c = {w 1 , ..., w T } where w i is a word, GEE outputs top-k emotion cause words regarding the recognized emotion? 1 from context c, denoted by W gee . Next, we concatenate the least likely n emotions from GEE with the context c removing the top-k emotion cause words: [? ?1 , ...,? ?n ; c ? W gee ], which is input to GEE. We then sample different words (w i ,w j , . . . ,w k ) from GEE's output in place of W gee to construct a distractorc. For example, given a context c "I was sick from the flu" and "sick, flu" as the top-2 emotion cause words, a sampled distractorc can be "I was laughing from the relief ". We use these altered contexts {c 1 , ...,c i } as distractors for the shared world C in the pragmatic listener L 0 (Eq. 4). We set n and cardinality of world C to 3 (i.e. C = {c,c 1 ,c 2 }). We run experiments and find the best k (= 5) (see Appendix).</p><p>The only difference between the original context c and the sampled distractorc is those emotion cause words. The pragmatic speaker S 1 (Eq. 5) prefers to generate words that have a higher likelihood of the given context c (including the original emotion cause words W gee ) than the distractor contextc. As a result, the pragmatic agent can generate    utterances more focused on those original emotion cause words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EMOCAUSE:</head><p>Emotion Cause Words Evaluation Set</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Collecting Annotations</head><p>To evaluate the performance of GEE, we annotate emotion cause words 1 in the situations of validation and test set in EmpatheticDialogues (Rashkin et al., 2019) ( ?3.2). Using Amazon Mechanical Turk, we ask three workers to vote which words (e.g. object, action, event, concept) in the situation sentence are the cause words to the given emotion.</p><p>Since explicit emotion words in the text (e.g. happy, disappointed) are not cause words of emotion, we discourage workers from selecting them.</p><p>Annotators are required to have a minimum of 1000 HITs, 95% HIT approval rate, and be located at one of [AU, CA, GB, NZ, US]. We pay the annotators $0.15 per description. To further ensure quality, only annotators who pass the qualification test are invited to annotate. Nevertheless, speculations for emotion causes are subjective and can vary among annotators. Therefore, we use only unanimously selected words (i.e. earning all three votes) to ensure maximum objectivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Analysis</head><p>We analyze the characteristics of our emotion cause words in the EMOCAUSE evaluation set. In <ref type="table" target="#tab_4">Table 3</ref> and <ref type="figure">Figure 2</ref>, we compare the basic statistics of our annotation set and RECCON <ref type="bibr">(Poria et al., 2020)</ref>, which is an English dialogue dataset annotating emotion cause spans on the DailyDialog <ref type="bibr" target="#b5">(Li et al., 2017)</ref> and IEMOCAP (Busso et al., 2008) with a total of 8 emotions. Since our EMOCAUSE is based on emotional situations from an empathetic dialogue dataset (Rashkin et al., 2019), emotion causes play a more important role than in casual conversations from RECCON. While 74% of REC-CON's labels belong to a single emotion happy, EMOCAUSE provides a balanced range of 32 emotions labels. Therefore, our evaluation set presents a wider variety than RECCON. <ref type="table" target="#tab_5">Table 4</ref> shows some examples of the annotated emotion cause words. <ref type="table" target="#tab_6">Table 5</ref> reports the most frequent cause words for some emotions. We find "embarrassing" events happen frequently in toilets and in front of people. "Proud" and "disappointed" are closely related to children. Interestingly, phones are associated with "trusting", which may be due to smartphones containing sensitive personal information. More examples and results can be found in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We first evaluate our generative emotion estimator (GEE) on weakly-supervised emotion cause word recognition ( ?6.2). We then show our new controlling method for the RSA framework can improve best performing dialogue agents to generate more empathetic responses by better focusing on targeted emotion cause words ( ?6.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets and Experiment Setting</head><p>EmpatheticDialogues (ED) <ref type="bibr" target="#b15">(Rashkin et al., 2019)</ref>. This dataset is an English empathetic dialogue dataset with 32 diverse emotion types ( ?3.2). The task is to generate empathetic responses (i.e. responses from the listener's side in <ref type="table" target="#tab_0">Table 1</ref>) when only given the dialogue context (i.e. history) without emotion labels and situation descriptions. It contains 24,850 conversations partitioned into training, validation, and test set by 80%, 10%, 10%, respectively. We additionally annotate cause words for the given emotion for all situations in the validation and test set of EmpatheticDialogues ( ?5).</p><p>EmoCause ( ?5). We compare our GEE with four methods that can recognize emotion cause words with no word-level annotations: random, RAKE <ref type="bibr" target="#b18">(Rose et al., 2010)</ref>, EmpDG <ref type="bibr" target="#b3">(Li et al., 2020)</ref>, and <ref type="bibr">BERT (Devlin et al., 2019)</ref>. For random, we randomly choose words as emotion causes. RAKE is an automatic keyword extraction algorithm based on the word frequency and degree of co-occurrences. EmpDG leverages a rule-based method for capturing emotion cause words using EmoLex (Mohammad and Turney, 2013), a largescale lexicon of emotion-relevant words. Finally, we train BERT for emotion classification with the emotion labels in ED. For BERT, we select the words with the largest averaged weight of BERT's last attention heads for the classification token (i.e.</p><p>[CLS]). More details can be found in Appendix.</p><p>Dialogue models for base speakers. We experiment our approach on three recent dialogue agents: MIME <ref type="bibr">(Majumder et al., 2020)</ref>, Dodeca-Transformer , and Blender <ref type="bibr" target="#b17">(Roller et al., 2021)</ref>. MIME is a dialogue model explicitly targeting empathetic conversation by leveraging emotion mimicry. We select MIME, since it reportedly performs better than other recent empathy-specialized models <ref type="bibr" target="#b15">(Rashkin et al., 2019;</ref><ref type="bibr" target="#b6">Lin et al., 2019)</ref> on EmpatheticDialogues. Dode-caTransformer is a multi-task model trained on all DodecaDialogue tasks  (i.e. 12 dialogue tasks including ED, image and knowledge grounded ones) and finetuned on ED. Blender is one of the state-of-the-art open domain dialogue agent <ref type="bibr" target="#b17">(Roller et al., 2021)</ref> trained on Blended-SkillTalk dataset <ref type="bibr" target="#b26">(Smith et al., 2020)</ref> which adopts contexts from ED. We also finetune Blender on ED. For all models, we use the default hyperparameters from the official implementations. More details are in Appendix.  <ref type="table" target="#tab_8">Table 6</ref>: Comparison of emotion cause word recognition performance between our generative emotion estimator (GEE), random, RAKE <ref type="bibr" target="#b18">(Rose et al., 2010)</ref>, Em-pDG <ref type="bibr" target="#b3">(Li et al., 2020)</ref>, and BERT on our EMOCAUSE evaluation set ( ?5).</p><p>Automatic evaluation metrics. For weaklysupervised emotion cause word recognition, we report the Top-1, 3, 5 recall scores.</p><p>For EmpatheticDialogues, we report coverage and two scores for specific empathy expressions (Exploration, Interpretation) measured by pretrained empathy identification models <ref type="bibr" target="#b21">(Sharma et al., 2020)</ref>. The coverage score refers to the average number of emotion cause words included in the model's generated response.</p><p>The (i) Exploration and (ii) Interpretation are metrics for expressed empathy in text, introduced by <ref type="bibr" target="#b21">Sharma et al. (2020)</ref>. They both require responses to focus on the interlocutor's utterances and to be specific. (i) Explorations are expressions of active interest in the interlocutor's situation, such as "What happened?" or "So, did you pass the chemistry exam?". The latter is rated as a stronger empathetic response since it asks specifically about the interlocutor's situation. (ii) Interpretations are expressions of acknowledgments or understanding of the interlocutor's emotion or situation, such as "I know your feeling." or "I also had to speak in front of such audience, made me nervous." Expressions of specific understanding are considered to be more empathetic. RoBERTa models <ref type="bibr" target="#b8">(Liu et al., 2019)</ref> that are separately pretrained for each metric rate each agent's response by returning values of 0, 1, or 2. Higher scores indicate stronger empathy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Weakly-Supervised</head><p>Emotion Cause Word Recognition  BERT, GEE) perform better. Selecting words by BERT's attention weights does not attain better performance on capturing emotion cause words than GEE. The gap between GEE and other methods widens when the number of returned words from models is more than one (i.e. Top-3, 5).</p><p>We also evaluate human performance to measure the difficulty of the task. We randomly sample 100 examples from the test set and ask a human evaluator to select five best guesses for the emotion causes. As the performance gap between GEE and human is significantly large, there is much room for further improvement in weakly-supervised emotion cause recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Empathetic Response Generation</head><p>Results on Automatic Evaluation. <ref type="table" target="#tab_9">Table 7</ref> reports the performance of different dialogue agents on EmpatheticDialogues <ref type="bibr" target="#b15">(Rashkin et al., 2019)</ref> with automatic evaluation metrics. Our Focused S 1 significantly outperforms the base model S 0 in terms of Interpretation and Exploration scores that measure more focused and specific empathetic expression. We also test the plain pragmatic method (Plain S 1 ) that use random distractors as in previous works <ref type="bibr">(Cohn-Gordon et al., 2018;</ref><ref type="bibr">Kim et al., 2020)</ref>. The Focused S 1 consistently outperforms Plain S 1 on Interpretation score with similar or better Exploration scores. The Focused S 1 models show higher coverage scores than other mod-   <ref type="bibr">(Majumder et al., 2020)</ref> Focused S1 vs S0 46.7% 20.0% 33.3%</p><p>DodecaTransformer  Focused S1 vs S0 42.1%</p><p>28.8% 29.1%</p><p>Blender <ref type="bibr" target="#b17">(Roller et al., 2021)</ref> Focused S1 vs S0 44.6% 37.4% 18.0% <ref type="table">Table 9</ref>: Comparison of our approach (Focused S 1 ) with base speakers (S 0 ) on A/B test for empathetic response generation. The win and lose rates are based on Focused S 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Win Lose Tie</head><p>Blender <ref type="bibr" target="#b17">(Roller et al., 2021)</ref> Focused S1 vs Plain S1 39.6% 32.3% 28.0% <ref type="table" target="#tab_0">Table 10</ref>: Comparison of our approach (Focused S 1 ) with plain pragmatic approach (Plain S 1 ) on A/B test for reflecting the given emotion cause words. The win and lose rates are based on Focused S 1 . els, indicating they more reflect the context's emotion cause words in responses. As MIME is only trained on EmpatheticDialogues, its Exploration and Interpretations scores are lower than models pretrained on other larger corpus. As a result, we find our approach is effective in both large pretrained open domain dialogue models and empathyspecialized one. We also finetune DodecaTransformer and Blender with explicit emotion information (S 0 +Emotion). Following <ref type="bibr" target="#b15">Rashkin et al. (2019)</ref>, we concatenate the ground-truth emotion label to the dialogue context during training. At inference, the top predicted emotion from GEE is used. We find the Interpretation or Exploration scores of S 0 +Emotion models drop. Thus, simply adding Emotion: Angry Context: I just moved to this neighborhood and some dumb criminals shot my neighbors and ran into the woods! Emotion cause words from GEE: dumb, neighbors, shot, moved, ran S0: That's terrible. Did you get a chance to talk to them? Plain S1: Oh my god, that is horrible! Where are they? Focused S1: Oh my god, that is horrible! Did they get caught?</p><p>Emotion: Trusting Context: I'm a big believer in listening to your gut. Sometimes I might wonder where my intuition is leading me, but it always seems to be spot on.</p><p>Emotion cause words from GEE: believer, leading, intuition, wonder, spot S0: That's great. I'm glad you have a good intuition. Plain S1: Good for you. I have a gut feeling about a lot of things. Focused S1: That's great! I'm a big believer in intuition too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emotion: Proud</head><p>Context: We were living overseas at the times -the most impressive part was crossing the Grand Canal over a pontoon of boats to finish the marathon ;-) Emotion cause words from GEE: impressive, Canal, Grand, part, finish S0: Wow, that sounds like a lot of fun! I'm glad you had a good time! Plain S1: Wow, that sounds amazing! I bet you were so excited! Focused S1: Wow, that sounds amazing! I've never been to Europe, but I've heard of it. <ref type="table" target="#tab_0">Table 11</ref>: Examples of recognized emotion cause words from our GEE and responses from S 0 and Focused S 1 . We underline words where our Focused S 1 reflects the emotion cause words returned by GEE. 2 emotion information is insufficient to make models focus more on the interlocutor's emotional event.</p><p>Results on Human Evaluation. We conduct user study and A/B test via Amazon Mechanical Turk. We randomly sample 100 test examples, each rated by three unique human evaluators. Following previous works <ref type="bibr" target="#b15">(Rashkin et al., 2019;</ref><ref type="bibr" target="#b6">Lin et al., 2019;</ref><ref type="bibr">Majumder et al., 2020)</ref>, we rate empathy, relevance, and fluency of generated responses.</p><p>Given the dialogue context and model's generated response, evaluators are asked to rate each criterion in a 4-point Likert scale, where higher scores are better. We also run human A/B test to directly compare the Focused S 1 and base S 0 . We ask three unique human evaluators to vote which response is more empathetic. They can select tie if both responses are thought to be equal. <ref type="table" target="#tab_11">Table 8</ref> and 9 summarizes the averaged human rating and A/B test results on MIME <ref type="bibr">(Majumder et al., 2020)</ref>, DodecaTransformer , and Blender <ref type="bibr" target="#b17">(Roller et al., 2021)</ref>. Our Focused S 1 agents are rated more empathetic and relevant to the dialogue context than the base agent S 0 , with better fluency. Also, users prefer responses from our Focused S 1 agent over those from the base agent S 0 . The inter-rater agreement (Krippendorff's ?) for human rating and A/B test are 0.26 and 0.27, respectively; implying fair agreement.</p><p>In addition to the coverage score in <ref type="table" target="#tab_9">Table 7</ref>, we run A/B test on Blender <ref type="bibr" target="#b17">(Roller et al., 2021)</ref> to compare the Focused S 1 and Plain S 1 for reflecting the given emotion cause words in the responses. We random sample 200 test examples and ask three unique human evaluators to vote which response is more focused on the given emotion cause words from the context. <ref type="table" target="#tab_0">Table 10</ref> is the result of A/B test for focused response generation on Blender <ref type="bibr" target="#b17">(Roller et al., 2021)</ref>. Users rate that responses from Focused S 1 more reflect the emotion cause words than those from the Plain S 1 approach. Thus, both quantitative and qualitative results show that our Focused S 1 approach helps dialogue agents to effectively generate responses focused on given target words.</p><p>Examples of the recognized emotion cause words from GEE and generated responses are in <ref type="table" target="#tab_0">Table 11</ref>. Our Focused S 1 agent's responses reflect the context's emotion cause words returned from our GEE, implicitly or explicitly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We studied how to use a generative estimator for identifying emotion cause words from utterances based solely on emotion labels without word-level labels (i.e. weakly-supervised emotion cause word recognition). To evaluate our approach, we introduce EMOCAUSE evaluation set where we manually annotated emotion cause words on situations in EmpatheticDialogues <ref type="bibr" target="#b15">(Rashkin et al., 2019)</ref>. We release the evaluation set to the public for future research. We also proposed a novel method for controlling the Rational Speech Acts (RSA) framework <ref type="bibr">(Frank and Goodman, 2012)</ref> to make models generate empathetic responses focused on targeted words in the dialogue context. Since the RSA framework requires no additional training, our approach is orthogonally applicable to any pretrained dialogue agents on the fly. An interesting direction for future work will be reasoning how the interlocutor would react to the model's empathetic response. Such reasoning is an essential part for expressing empathy.  Experiments for emotion cause word recognition and emotion classification are run on one NVIDIA Quadro RTX 6000 GPU. Experiments for empathetic response generation are run on two GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Emotion Classification</head><p>We report the classification performance of emotion classifiers used in empathetic response generation. <ref type="table" target="#tab_0">Table 13</ref> shows the Top-1, 5 emotion classification accuracy for each model. For reference, <ref type="bibr">BERT (Devlin et al., 2019)</ref> shows 0.55 and 0.88 for Top-1 and 5 accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Top-1 Top-5</p><p>MoEL <ref type="bibr" target="#b6">(Lin et al., 2019)</ref> 0.38 0.74 MIME <ref type="bibr">(Majumder et al., 2020)</ref> 0.34 0.77 GEE (Ours) 0.40 0.77  <ref type="table" target="#tab_0">Table 14</ref> shows some selected examples of emotion cause words with given emotion and situation. <ref type="table" target="#tab_0">Table 15</ref> shows Top-10 frequent cause words per emotion. Interestingly, same words can be seen in both positive and negative emotions. For example, we can find the word interview on both "Anxious" and "Confident". "Anticipating" and "Disappointed" are closely related to vacation. This result shows that understanding the context is one of key prerequisites for emotion cause word recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Details of EMOCAUSE Evaluation Set</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emotion: Surprised</head><p>We just got a new puppy . My older dog knew to let that one out first when I get home from work .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emotion: Faithful</head><p>My boyfriend is going out with a bunch of people I do n't know tonight . But I trust him that he will be a good boy .   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>A dialogue example in EmpatheticDialogues.</figDesc><table><row><cell>Emotion: Joyful</cell></row><row><cell>GEE:</cell></row><row><cell>? I got accepted into a masters program in neuroscience.</cell></row><row><cell>Emotion: Angry</cell></row><row><cell>GEE:</cell></row><row><cell>? I was so mad at my cousin. He stole my daughters stuff.</cell></row><row><cell>Emotion: Grateful</cell></row><row><cell>GEE:</cell></row><row><cell>? The night my dad got me a new car was a magical time.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Example of sampled outputs from our generative emotion estimator (GEE) using Nucleus sampling.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Statistics of the EMOCAUSE evaluation set compared to RECCON(Poria et al., 2020). Utt denotes utterance.</figDesc><table><row><cell>RECCON</cell><cell></cell><cell></cell><cell>Happy 74%</cell><cell></cell><cell></cell></row><row><cell>EMOCAUSE</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0%</cell><cell>20%</cell><cell>40%</cell><cell>60%</cell><cell>80%</cell><cell>100%</cell></row><row><cell cols="7">Figure 2: Emotion ratio of RECCON and our EMO-</cell></row><row><cell cols="3">CAUSE evaluation set.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Emotion</cell><cell></cell><cell></cell><cell cols="2">Situation</cell><cell></cell></row><row><cell>Surprised</cell><cell cols="6">Man, I did not expect to see a bear on the road today.</cell></row><row><cell>Afraid</cell><cell cols="5">I have to take a business trip next week, I'm not looking forward to flying.</cell></row><row><cell>Sad</cell><cell cols="6">I feel sad that I am spending so much time this late on the internet.</cell></row></table><note>Joyful I'm excited I get to go to Disney in October!</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Examples of annotated emotion cause words.</figDesc><table><row><cell cols="2">Embarrassed pant, fell, dropped, people, tripped, toilet</cell></row><row><cell>Nostalgic</cell><cell>old, childhood, memory, friend, back</cell></row><row><cell>Trusting</cell><cell>friend, gave, best, daughter, money, phone</cell></row><row><cell>Anxious</cell><cell>job, interview, exam, new, presentation</cell></row><row><cell>Proud</cell><cell>graduated, daughter, college, son, school</cell></row><row><cell cols="2">Disappointed not, son, car, failed, get, job, hard, friend</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note>The most frequent cause words for each emo- tion. Other emotions can be found in Appendix.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>compares the recall of different methods on</cell></row><row><cell>our EMOCAUSE evaluation set ( ?5). Our GEE out-</cell></row><row><cell>performs all other alternative methods. RAKE per-</cell></row><row><cell>forms better than EmpDG that uses a fixed lexicon</cell></row><row><cell>of emotion-relevant words. Compared to RAKE,</cell></row><row><cell>methods leveraging dense word representations (i.e.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell>: Comparison of our approach (Focused S 1 )</cell></row><row><cell>with other speakers on EmpatheticDialogues (Rashkin</cell></row><row><cell>et al., 2019). Exploration, and Interpretation scores are</cell></row><row><cell>evaluated by pretrained RoBERTa models from Sharma</cell></row><row><cell>et al. (2020).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Comparison of our approach (Focused S 1 ) with base speakers (S 0 ) on human rating.</figDesc><table><row><cell>Model</cell><cell>Win</cell><cell>Lose</cell><cell>Tie</cell></row><row><cell>MIME</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 12 :</head><label>12</label><figDesc>Comparison of different k values for topk emotion cause words on generating empathetic responses in EmpatheticDialogues (Rashkin et al., 2019).</figDesc><table><row><cell>Exploration and Interpretation scores are evaluated</cell></row><row><cell>by pretrained RoBERTa models from Sharma et al.</cell></row><row><cell>(2020).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 13</head><label>13</label><figDesc></figDesc><table><row><cell>: Comparison of emotion classification accu-</cell></row><row><cell>racy from different models trained on EmpatheticDia-</cell></row><row><cell>logues (Rashkin et al., 2019).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>GuiltyI made a really inappropriate joke about someone I work with to other coworkers and it got back to them . I feel really bad about it .</figDesc><table><row><cell>Emotion: Anticipating</cell></row><row><cell>I am really waiting on getting my tax returns this year I</cell></row><row><cell>could use new carpet</cell></row><row><cell>Emotion: Trusting</cell></row><row><cell>I trust my own intuitions when it comes to my health .</cell></row><row><cell>Emotion: Embarrassed</cell></row><row><cell>i was super late for my meeting on tuesday</cell></row><row><cell>Emotion: Sad</cell></row><row><cell>My girlfriend 's cat is sick with Cancer . I do n't think she</cell></row><row><cell>'s going to make it for much longer and I 'm really shaken</cell></row><row><cell>up by it .</cell></row><row><cell>Emotion: Proud</cell></row><row><cell>I put in a lot of effort and energy and I found a new job .</cell></row><row><cell>It 's an online teaching position and I feel so good about</cell></row><row><cell>myself .</cell></row><row><cell>Emotion: Terrified</cell></row><row><cell>Driving down the highway during a heavy thunderstorm</cell></row><row><cell>and a car crash happens in front of me where a car flips</cell></row><row><cell>over .</cell></row><row><cell>Emotion: Confident</cell></row><row><cell>I studied all night for my final exam</cell></row><row><cell>Emotion:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 14 :</head><label>14</label><figDesc>Examples of our annotated emotion cause words. Words with background color are selected as emotion cause words by annotators. , died, away, lost, friend, father, job, cancer, cat Disappointed 2.59 not, son, car, failed, get, hard, job, n't, birthday, vacation Disgusted 2.47 dog, poop, threw, friend, dead, food, roach, puked, eat, animal Embarrassed 2.73 pant, fell, dropped, people, tripped, stuck, slipped, toilet, front, friend Excited 1.95 vacation, new, friend, first, trip, car, puppy, see, won, coming Faithful 2.09 loyal, girlfriend, husband, year, relationship, boyfriend, family, friend, married, good Furious 2.58 car, dog, neighbor, hit, broke, without, son, room, accident, cheated Grateful 2.42 friend, helped, life, job, family, good, help, husband, work, parent Guilty 2.64 ate, stole, friend, forgot, money, candy, eating, cake, bar, girlfriend Hopeful 1.91 job, promotion, future, new, better, get, interview, ticket, college, well Impressed 2.30 friend, daughter, guy, car, new, well, man, brother, world, backflip Jealous 2.66 friend, car, new, husband, girl, girlfriend, bought, got, boyfriend, won Joyful 2.18 first, child, wife, friend, family, together, daughter, baby, birthday, trip Lonely 2.18 friend, alone, moved, husband, family, myself, away, wife, went, left Nostalgic 2.59 old, childhood, friend, memory, game, school, child, family, back, comic Prepared 2.00 ready, packed, studied, exam, everything, supply, ingredient, studying, set, all Proud 2.40 graduated, college, daughter, job, first, son, school, brother, won, new Sad 2.39 dog, died, passed, away, cat, sick, friend, not, lost, put Sentimental 2.40 old, picture, passed, photo, dog, childhood, school, away, toy, found Surprised 2.29 friend, party, birthday, found, baby, car, gift, home, pregnant, won Terrified 2.28 night, dog, tornado, car, bad, chased, someone, storm, fly, crash Trusting 2.17 friend, best, daughter, drive, car, brother, sister, card, dog, phone</figDesc><table><row><cell>Emotion</cell><cell cols="2">#Label/Utt Top-10 frequent emotion cause words</cell></row><row><cell>Afraid</cell><cell>2.12</cell><cell>alone, night, spider, house, noise, movie, dark, storm, hurricane, heard</cell></row><row><cell>Angry</cell><cell>2.62</cell><cell>car, dog, neighbor, friend, husband, brother, not, stole, hit, kid</cell></row><row><cell>Annoyed</cell><cell>2.59</cell><cell>dog, people, cat, work, loud, late, night, sister, neighbor, friend</cell></row><row><cell>Anticipating</cell><cell>2.04</cell><cell>new, waiting, vacation, coming, son, job, forward, next, friend, back</cell></row><row><cell>Anxious</cell><cell>2.05</cell><cell>interview, job, exam, presentation, big, dentist, going, test, girlfriend, back</cell></row><row><cell>Apprehensive</cell><cell>2.11</cell><cell>job, nervous, new, first, interview, driving, moving, car, day, night</cell></row><row><cell>Ashamed</cell><cell>2.48</cell><cell>stole, ate, friend, forgot, girlfriend, missed, drunk, bad, money, mistake</cell></row><row><cell>Caring</cell><cell>2.49</cell><cell>dog, sick, care, wife, friend, home, helped, puppy, girlfriend, baby</cell></row><row><cell>Confident</cell><cell>1.95</cell><cell>exam, studied, job, interview, win, test, well, prepared, good, answer</cell></row><row><cell>Content</cell><cell>2.04</cell><cell>life, good, happy, relaxing, watching, weekend, back, breakfast, family, live</cell></row><row><cell>Devastated</cell><cell>2.42</cell><cell>dog, passed</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 15 :</head><label>15</label><figDesc>Number of emotion cause words per utterance and Top-10 frequent emotion cause words for each emotion.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">As existing works annotate emotion cause spans for a given emotion label, we also coin our annotations as emotion cause words. However, in terms of "causality", we note that the true cause of the given emotion can be annotated only by the original annotator of the emotion label.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Since Grand Canal is a famous tourist attraction in Venice, Italy, the word 'Europe' is closely related to it. We note that there is another famous Grand Canal in China. This might be a bias in BART, since it is trained on English datasets.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/csurfer/rake-nltk 4 https://github.com/qtli/EmpDG 5 https://parl.ai 6 https://github.com/declare-lab/MIME 7 https://github.com/behavioral-data/ Empathy-Mental-Health</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their helpful comments. This research was supported by Samsung Research Funding Center of Samsung Electronics under project number SRFCIT2101-01. The compute resource and human study are supported by Brain Research Program by National Research Foundation of Korea (NRF) (2017M3C7A1047860). Gunhee Kim is the corresponding author.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Implementation Details</head><p>Weakly-supervised emotion cause word recognition. We use rake-nltk 3 to implement RAKE <ref type="bibr" target="#b18">(Rose et al., 2010)</ref>, and the official code of Em-pDG 4 from the authors <ref type="bibr" target="#b3">(Li et al., 2020)</ref>. We respectively finetune <ref type="bibr">BERT-based-uncased (Devlin et al., 2019)</ref> for BERT-Attention and BART-large <ref type="bibr" target="#b2">(Lewis et al., 2020)</ref> for our generative emotion estimator (GEE). We set a learning rate to 3e-5 for BERT-Attention and 1e-5 for GEE. Other than the learning rate, we follow the default hyperparameters in ParlAI framework 5 <ref type="bibr" target="#b10">(Miller et al., 2017)</ref>. We select the best performing checkpoint using the Top-1 recall for emotion cause word recognition on the validation set. We run experiments 5 times with different random seeds and report averaged scores on <ref type="table">Table 6</ref>.</p><p>Dialogue models. We use MIME <ref type="bibr">(Majumder et al., 2020)</ref>, DodecaTransformer , and Blender 90M <ref type="bibr" target="#b17">(Roller et al., 2021)</ref> as dialogue models for base speakers. For MIME, we use the codes and pretrained weights of the authors' official implementation 6 as is. For DodecaTransformer and Blender, we use the ParlAI framework with the default hyperparameters and finetune them on EmpatheticDialogues <ref type="bibr" target="#b15">(Rashkin et al., 2019)</ref>. We select the best performing checkpoint via perplexity on the validation set.</p><p>During inference, we use greedy decoding and set RSA parameter ? and ? to 2.0 and 0.9 for MIME, 3.0 and 0.9 for DodecaTransformer, and 4.0 and 0.9 for Blender. We select the best performing ? and ? from the candidates of [1.0, 2.0, 3.0, 4.0] and [0.5, 0.6, 0.7, 0.8, 0.9, 1.0] with one trial for each. Inference on the test set of EmpatheticDialogues takes 0.4 hours with Blender 90M base speaker.</p><p>Evaluation metrics. To compute Exploration and Interpretation scores <ref type="bibr" target="#b21">(Sharma et al., 2020)</ref>, we separately finetune RoBERTa-base for each score using the author's official code 7 .</p><p>Sensitivity to k of top-k emotion cause words. In all experiments, we use k = 5, which is found by validation with k = 1, 2, 4, 8 using Blender <ref type="bibr" target="#b17">(Roller et al., 2021)</ref> on EmpatheticDialogues <ref type="bibr" target="#b15">(Rashkin et al., 2019)</ref>. <ref type="table">Table 12</ref> summarizes the results.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Emotion Cause Detection with Linguistic Construction in Chinese Weibo Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NLPCC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">2020. Will I Sound Like Me? Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunwoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byeongchang</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunhee</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">BART: Denoising Sequence-to-Sequence Pre-Training for Natural Language Generation, Translation, and Comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Em-pDG: Multi-resolution Interactive Empathetic Dialogue Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qintong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Co-Attention Neural Network Model for Emotion Cause Analysis with Emotional Context Awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangju</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisong</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daling</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuzi</forename><surname>Niu</surname></persName>
		</author>
		<editor>IJC-NLP</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MoEL: Mixture of Empathetic Listeners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaojiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamin</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CAiRE: An End-to-End Empathetic Chatbot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaojiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Alexander Gelbukh, Rada Mihalcea, and Soujanya Poria. 2020. MIME: MIMicking Emotions for Empathetic Response Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankun</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepanway</forename><surname>Ghosal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.06476</idno>
		<title level="m">ParlAI: A Dialog Research Software Platform</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Crowdsourcing a Word-Emotion Association Lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="436" to="465" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Affective Cognition: Exploring Lay Theories of Emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Desmond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamil</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah D</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="141" to="162" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Computational Models of Emotion Inference in Theory of Mind: A Review and Roadmap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Desmond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamil</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah D</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="338" to="357" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepanway</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Bhardwaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samson</forename><surname>Yu Bai Jian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romila</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niyati</forename><surname>Chhaya</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.11820</idno>
		<title level="m">Alexander Gelbukh, and Rada Mihalcea. 2020. Recognizing Emotion Cause in Conversations</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards Empathetic Opendomain Conversation Models: A New Benchmark and Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">Michael</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-Lan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Boureau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Mirror-Neuron System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giacomo</forename><surname>Rizzolatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laila</forename><surname>Craighero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="169" to="192" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Recipes for Building an Open-Domain Chatbot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic Keyword Extraction from Individual Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendy</forename><surname>Cowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text mining: applications and theory</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">How would You Feel Versus How do You Think She would Feel? A Neuroimaging Study of Perspective-taking with Social Emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Perrine</forename><surname>Ruby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Decety</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="988" to="999" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Formalizing Emotion Concepts within a Bayesian Model of Theory of Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><forename type="middle">Dae</forename><surname>Houlihan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Psychology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="15" to="21" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Miner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Atkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Althoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pragmatically Informative Text Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sentiment Adaptive End-to-End Dialog Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Dialogue Dodecathlon: Open-domain Knowledge and Image Grounded Conversational Agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-Lan</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Zara Returns: Improved Personality Induction and Adaptation by an Empathetic Virtual Agent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Onno</forename><surname>Farhad Bin Siddique</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Kampman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anik</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Can You Put it All Together: Evaluating Conversational Agents&apos; Ability to Blend Skills</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">Michael</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-Lan</forename><surname>Boureau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Context-Aware Captions from Context-Agnostic Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Chechik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Emotion-Cause Pair Extraction: A New Task to Emotion Analysis in Texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixiang</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Know What You Don&apos;t Know: Modeling a Pragmatic Speaker that Refers to Objects of Unknown Categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sina</forename><surname>Zarrie?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schlangen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Towards Persona-Based Empathetic Conversational Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peixiang</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
