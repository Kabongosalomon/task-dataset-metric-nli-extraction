<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic Relation-aware Graph Network Proliferation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaofei</forename><surname>Cai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Key Lab of Intell. Info. Process</orgName>
								<orgName type="department" key="dep2">Inst. of Comput. Tech</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Li</surname></persName>
							<email>liang.li@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Key Lab of Intell. Info. Process</orgName>
								<orgName type="department" key="dep2">Inst. of Comput. Tech</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinzhe</forename><surname>Han</surname></persName>
							<email>xinzhe.han@vipl.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Key Lab of Intell. Info. Process</orgName>
								<orgName type="department" key="dep2">Inst. of Comput. Tech</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
							<email>jluo@cs.rochester.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Rochester</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Jun</forename><surname>Zha</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
							<email>qmhuang@ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Key Lab of Intell. Info. Process</orgName>
								<orgName type="department" key="dep2">Inst. of Comput. Tech</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic Relation-aware Graph Network Proliferation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph neural architecture search has sparked much attention as Graph Neural Networks (GNNs) have shown powerful reasoning capability in many relational tasks. However, the currently used graph search space overemphasizes learning node features and neglects mining hierarchical relational information. Moreover, due to diverse mechanisms in the message passing, the graph search space is much larger than that of CNNs. This hinders the straightforward application of classical search strategies for exploring complicated graph search space. We propose Automatic Relation-aware Graph Network Proliferation (ARGNP) for efficiently searching GNNs with a relation-guided message passing mechanism. Specifically, we first devise a novel dual relation-aware graph search space that comprises both node and relation learning operations. These operations can extract hierarchical node/relational information and provide anisotropic guidance for message passing on a graph. Second, analogous to cell proliferation, we design a network proliferation search paradigm to progressively determine the GNN architectures by iteratively performing network division and differentiation. The experiments on six datasets for four graph learning tasks demonstrate that GNNs produced by our method are superior to the current state-of-the-art handcrafted and search-based GNNs. Codes are available at https://github.com/phython96/ARGNP.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Graph neural networks (GNNs), as a dominant paradigm to handle graph-structured data, have significantly promoted the performance in many relation reasoning tasks, such as molecular prediction <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b24">25]</ref>, social network analysis <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b40">41]</ref>, 3D point cloud recognition <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b54">55]</ref>, * Corresponding author. object detection <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b22">23]</ref>, semantic segmentation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b53">54]</ref>, few-shot learning <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b60">61]</ref>, etc. Despite their great success, the architectures of GNNs are usually manually designed, which requires tremendous expert knowledge and intensive trial and error. To explore advanced GNN architectures and reduce the human intervention, researchers attempt to automate the design process with the help of neural architecture search (NAS) <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b65">66]</ref> and have achieved superior performance. This is known as graph neural architecture search, where there are two most critical components: (1) graph search space and (2) search strategy.</p><p>The graph search space defines which graph neural networks can be represented in principle, determining the upper bound of networks' reasoning capability. Current graph search space mainly focuses on designing node-learning operations, which is categorized into macro search space <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b43">44]</ref> and micro search space <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b65">66]</ref>. The former explores the combinations of existing message passing mechanisms (i.e., using general-purpose GNNs as candidate operations), while the latter emphasizes the construction for novel ones (i.e., designing fine-grained operations such as node aggregating and feature combining functions). However, they all neglect mining the latent hierarchical relational information associated with edges. In fact, relational information can provide anisotropic guidance for message aggregation of neighboring nodes, which is critical for constructing relation-guided message passing mechanisms. Motivated by this, in this paper, we explore designing micro graph search space from the perspective of learning both hierarchical relation and node features.</p><p>The search strategy details how to explore search space, determining the search efficiency and effect. Some early works <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b65">66]</ref> apply reinforcement learning (RL) based strategy to search for GNNs by building, training, and evaluating various graph neural architectures from scratch, which is extremely time-consuming. Recently, due to the high computational efficiency, one-shot differentiable strategies <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37]</ref> have attracted a lot of interest, which consists of three stages: supernet training, subnet searching, and subnet retraining. They boost the search efficiency from the parameter sharing among subnets and supertnet. Using the auxiliary supernet can avoid training each child graph neural architecture individually, but this may cause severe subnet interference <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b63">64]</ref>. Besides, it is limited in searching large GNN architectures due to the quadratic complexity of storing and training the supernet. As a compromise, researchers introduce the cell trick where the architecture is a stack of several same building blocks <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">40]</ref>. This shifts the searching objective from the whole architecture to small cells but seriously narrows the original search space. The above limitations, i.e. the subnet interference, the high space-time complexity and the shrink of search space, bring a severe negative impact for graph neural architecture search.</p><p>In this paper, we propose the Automatic Relation-aware Graph Network Proliferation (ARGNP) to efficiently search the optimal GNN architectures with a relation-guided message passing mechanism. First, we design a dual relationaware graph search space comprising both relation and node search space, as shown in <ref type="figure">Figure 2</ref>. The relation search space introduces diverse relation-mining operations to extract relational information hidden in edgeconnected nodes. It allows arbitrary valid connection modes among relation-mining operations and forms the hierarchical relation-learning structure. Different connection modes result in the group of relation features with different message-passing preferences, which favors different graph tasks. The node search space defines a series of nodelearning operations which implements the anisotropic message aggregation under the guidance of relation features.</p><p>Second, analogous to cell proliferation, we devise a novel search paradigm called network proliferation to progressively explore the graph search space. Instead of directly optimizing the global supernet, we search the final graph neural architecture by iteratively performing network division and network differentiation. <ref type="figure">Figure 1</ref> shows one iteration process. During network division, each intermediate feature vertex is divided into two parts. One retains original operations and connections while the other builds a local supernet. Network differentiation aims to differentiate the local supernet into a specific subnet. Theoretically, we proved that such a search paradigm achieves the linear space-time complexity. This enables our search to thoroughly free from the cell trick. The network proliferation decomposes the training of global supernet into sequential local supernets optimization, which alleviates the interference among child graph neural architectures.</p><p>Our contributions are summarized as follows: (1) A novel dual relation-aware graph search space comprising both node and relation search space. It can derive GNNs with a relation-guided message passing mechanism. (2) A network proliferation search paradigm. It sequentially performs network division and differentiation to explore the optimal GNN architecture within linear space-time complexity.</p><p>(3) Experiment results on six datasets for four classical graph learning tasks show that our method outperforms human-crafted and other search-based GNNs by a large margin. The code will be released publicly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Graph Neural Networks (GNNs) have been successfully applied to operate on the graph-structure data <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b61">62]</ref>. Current GNNs are constructed on message passing mechanisms and can be categorized into two groups, isotropic and anisotropic. Isotropic GNNs <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b58">59]</ref> aim at extending the original convolution operation to graphs. Anisotropic GNNs enhance the original models with anisotropic operations on graphs <ref type="bibr" target="#b44">[45]</ref>, such as gating and attention mechanism <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b61">62]</ref>. Anisotropic methods usually achieve better performance, since they can weigh the importance of edges according to the node features and implement the adaptive feature aggregation.</p><p>Neural Architecture Search (NAS) aims at automatically finding the optimal neural architectures specific to dataset <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b66">67]</ref>. Search space and strategy are the most essential components in NAS. Search space defines which architectures can be represented in principle. Search strategy details how to explore the search space. Methods can be mainly categorized into three groups, i.e., reinforcement learning (RL) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b66">67]</ref>, evolutionary algorithms (EA) <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50]</ref> and gradient-based (GB) <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b59">60]</ref>. Benefiting from the high efficiency, gradient-based differentiable search strategies attracted the attention of increasing researchers.</p><p>Graph Neural Architecture Search (GNAS) is proposed to automatically find the best GNNs for the given specific graph task. The current GNAS methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b65">66]</ref> mainly focus on designing graph search space by introducing neighbor aggregation, activation functions, etc., but neglect the importance of relation mining. To our best knowledge, we are the first to take mining relational information into account during devising graph search space. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>node-learning operations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminaries</head><p>A graph neural architecture uses graph-structured data as input and outputs high-dimensional node and edge features (relation features). The input data can be represented as {G, V in , E in }, where G is the input graph structure with n nodes and m edges, V in ? R n?d V denotes the input node features, E in ? R m?d E denotes the input edge features, d V and d E denote the feature dimension. Notably, if there is no original edge feature in the dataset, we initalize E in with [1, ? ? ? , 1] ? R m?1 for subsequent relation learning. Our dual relation-aware graph search space comprises both node and edge search space. The derived computation structure of node or relation search space is a directed acyclic graph (DAG). To avoid confusion, the node and edge in the DAG is renamed to "vertex" and "link", where "vertex" denotes an intermediate features (V i or E j ), the "link" is associated with an operation o or a mixture operation?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Relation-aware Graph Search Space</head><p>In this subsection, we detail how our dual relation-aware graph search space is devised. As shown in <ref type="figure">Figure 2</ref>, it comprises node search space and relation search space. These two spaces are not individual in essence, instead, they communicate information with each other. The relational information is extracted from node features. In turn, it provides anisotropic guidance for learning better node features. Node search space. The computation structure derived by node search space is a directed acyclic graph, which consists of an ordered sequence of N +4 vertices, which consti-</p><formula xml:id="formula_0">tutes the set {V in0 , V in1 , V 1 , ? ? ? , V N , V out0 , V out1 }.</formula><p>Each vertex is a latent representation denoted as V i (i.e., node features in a GNN layer, as shown in the left of <ref type="figure">Figure  2</ref>), where i is its topological order in the DAG. In order to be compatible with the cell trick, we introduce two input vertices and two output vertices. V in0 and V in1 are the outputs of previous two cells while V out0 and V out1 are the inputs of post two cells. In fact, our method can thoroughly free from the cell trick. In this situation, we</p><formula xml:id="formula_1">have V in0 = V in1 , V out0 = V out1 . Each directed link (i, j) in the DAG is associated with one node-learning operation o (i,j) V , that transforms the information from V i to V j , guided by relation features E i . The transformed information is de- noted as V i?j = o (i,j) V (V i , E i , f i,j ), where f i,j</formula><p>is an aggregating function which takes multiset as input, such as mean, max, sum, std, etc. We leverage feature-wise linear modulation (FiLM) mechanism <ref type="bibr" target="#b9">[10]</ref> to implement the anisotropic guidance of message propagation. This allows the model to dynamically up-weight and down-weight node features based on the relational information. Specifically, we compute an element-wise affine transformation ? and ? based on the input relation features E i and use it to modulate the incoming messages during message passing. Given a node t on the graph, its transformed feature V t i?j is formulated as follows</p><formula xml:id="formula_2">V t i?j = f i,j ({? s,t ?V s i + ? s,t |s ? N (t)}), ? s,t , ? s,t = g(E s,t i ; ?),<label>(1)</label></formula><p>where g(?) is a two-layer multilayer perceptron to compute affine transformation with the learnable parameters ?, N (t) denotes the set of neighbors of target node t on the graph. Following previous works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">40]</ref>, we allow two inputs for each intermediate vertex,</p><formula xml:id="formula_3">i.e., V i = V p1?i +V p2?i , where p 1 , p 2 ? {in 0 , in 1 , 1, 2, ? ? ? , i ? 1}.</formula><p>For each nodelearning operation, its aggregating function is optional. Different aggregating function f i,j captures different types of information. For example, sum captures the structural information <ref type="bibr" target="#b58">[59]</ref>, max captures the representative information, mean and std captures the statistical information from the neighboring nodes. The node search space has 8 candidate node-learning operations: V MAX, V SUM, V MEAN, V STD, V GEM2, V GEM3, skip-connect, and zero operation. We detail all eight node-learning operation options in the supplementary material.</p><formula xml:id="formula_4">X in0 X in1 X 1 X out0 X out1 differentiation (0) X in0 X in1 X 1 X out0 X out1 division (1) X in0 X in1 X 1 X 2 X out0 X out1 differentiation (1) X in0 X in1 X 1 X 2 X out0 X out1 division (2) X in0 X in1 X 1 X 2 X 3 X 4 X out0 X out1 differentiation (2) X in0 X in1 X 1 X 2 X 3 X 4 X out0 X out1</formula><p>Page 1 Relation search space. The computation structure derived by relation search space is also a directed acyclic graph with the same number of vertices. Each vertex E i is a latent relation representation (i.e., edge features in a GNN layer, as shown in the right of <ref type="figure">Figure 2</ref>). The directed link (i, j) in the DAG is associated with a relation-mining operation o</p><formula xml:id="formula_5">(i,j) E</formula><p>. It extracts relational information from node features V i . The extracted information is joined with E i to obtain higher order relation representation</p><formula xml:id="formula_6">E i?j = o (i,j) E (V i , E i , h i,j )</formula><p>. h i,j is a relation-mining function, such as substraction, hardmard product, gauss kernel, etc. Given a specific edge (s, t) on the graph, E s,t i?j can be computed using feature-wise linear modulation (FiLM):</p><formula xml:id="formula_7">E s,t i?j = ? s,t ? E s,t i + ? s,t , ? s,t , ? s,t = h i,j (V s i , V t i ; ?),<label>(2)</label></formula><p>where ? s,t , ? s,t is the affine transformation learned by h i,j , ? is the learnable parameters. This allows adaptive relational information fusion. Similar to node search space, we assume that each intermediate vertex has and only has two inputs, i.e., </p><formula xml:id="formula_8">E i = E p1?i + E p2?i , where p 1 , p 2 ? {in 0 , in 1 , 1, 2, ? ? ? , i ? 1}.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Network Proliferation Search Paradigm</head><p>We detail how the proposed network proliferation search paradigm explores a single search space (e.g., node or rela-</p><formula xml:id="formula_9">Algorithm 1 Network Proliferation Search Paradigm Input: a search algorithm A, architecture size S Output: a graph neural architecture defined by {V, L} Define: e(X s , X t , O) is a link from X s to X t with an operation O, where O ? {o,?},? is the mixture operation 1: V ? {X 1 } 2: L ? {e(X in0 , X 1 ,?), e(X in1 , X 1 ,?)} 3: while True do 4: // network differentiation 5: V r ? V ? {X in0 , X in1 } 6:</formula><p>Create a graph neural architecture G from {V r , L}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>Initialize G with new parameters <ref type="bibr">8:</ref> Perform search algorithm: L ? A(G) <ref type="bibr">9:</ref> if len(V) ? S then <ref type="bibr">10:</ref> return {V r , L} 11:</p><formula xml:id="formula_10">// network division 12: V tmp ? V, L tmp ? L, l ? len(V) 13: for X i in V tmp do 14: V ? V ? {X i+l } 15: L ? L ? {e(X i , X i+l ,?)} 16: for e(X s , X t , O)| t=i in L tmp do 17: L ? L ? {e(X s , X i+l ,?)} 18: L tmp ? L 19: for e(X s , X t , O)| s?Vtmp,s+l? =t in L tmp do 20: L ? L ? {e(X s+l , X t , O)}/{e(X s , X t , O)}</formula><p>tion search space) for simplicity. Since our dual relationaware graph search space comprising node and relation search space is symmetric, it can be generalized to search the whole dual space simultaneously.</p><p>Motivated by the observation that a well-performed small architecture can provide a good skeleton for building a larger one (shown in <ref type="figure" target="#fig_2">Figure 4</ref>), we can efficiently obtain the expected large architecture through iterative search . Boxplots of 8-layer architectures on ZINC. "R" and "S" denote the random and SGAS <ref type="bibr" target="#b31">[32]</ref> search strategies, respectively. e.g., architecture "RS" is constructed by sequentially performing random search, network division and SGAS search. The architecture size after the first and the second search is 4 and 8.</p><p>Comparing "RR" with "SR", "RS" with "SS", we find that a presearched architecture is useful for subsequent search.</p><p>based on the current small architecture. We detail this procedure in <ref type="figure" target="#fig_1">Figure 3</ref> and Algorithm 1. Each iterative search comprises of two subprocedures, i.e., network division, and network differentiation. Network division builds a 2? larger architecture based on the current architecture, where each feature vertex is divided into two parts. One part that retains original operations and connections is called parent vertex (X p ), whose role is to provide the architecture skeleton. The other one is called newly divided vertex (X n ), which joins X p and X p 's two input vertices X p1 , X p2 to build a local supernet. We define the mixture operation is parameterized by architectural parameters ? (i,j) as a softmax mixture over all the possible operations within the operation space O, i.e.,? (i,j) (</p><formula xml:id="formula_11">X i ) = o?O exp(? (i,j) o ) o ? ?O exp(? (i,j) o ? ) o(X i ).</formula><p>The local supernet contains three mixture operations, which is represented as follows,</p><formula xml:id="formula_12">X n =? (p,n) (X p ) +? (p1,n) (X p1 ) +? (p2,n) (X p2 ). (3)</formula><p>Since the local supernet contains C 2 3 ? |O| candidate local subnets, we need to discretize it to one specific subnet. This is called network differentiation. During this procedure, we can adopt any search algorithms <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b59">60]</ref>, that can discretize the supernet to the subnet. After the network differentiation, each mixture operation in the architecture is replaced with one specific operation. The algorithm terminates until the size of the architecture reaches the predefined threshold.</p><p>Next, we analyze the complexity of our network proliferation search paradigm. The running time and occupied memory are proportional to the number of operations. It requires log(N ) iterations for searching for architecture with N feature vertices. During the i-th iteration, there are 2 i?1 ? 2 operations and 2 i?1 ? 3 mixture operations, i.e., 2 i + 3 ? 2 i?1 |O| operations in total. So the whole complexity is O(</p><formula xml:id="formula_13">log(N ) i=1 2 i + 3 ? 2 i?1 |O|) = O(N |O|).</formula><p>Compared with vanilla DARTS <ref type="bibr" target="#b39">[40]</ref> (O(N 2 |O|) complexity), our method reduces the complexity from quadratic to linear. This enables ours to directly search for large neu-ral architectures without relying on the cell trick, and this also enlarges the global search space. For example, we try to search for an architecture with N = 16, |O| = 8. In general, due to the high complexity, the DARTS stacks 4 cells with 4 feature vertices in each of them, resulting in 3.0 ? 10 9 candidate architectures. Compared with vanilla DARTS, our search paradigm can explore up to 3.4 ? 10 36 candidate architectures using comparable resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setups</head><p>Dataset. We evaluate our method on six datasets, i.e., ZINC <ref type="bibr" target="#b25">[26]</ref>, CLUSTER <ref type="bibr" target="#b16">[17]</ref>, CIFAR10 <ref type="bibr" target="#b29">[30]</ref>, TSP <ref type="bibr" target="#b16">[17]</ref>, ModelNet10 <ref type="bibr" target="#b55">[56]</ref>, ModelNet40 <ref type="bibr" target="#b55">[56]</ref> across four different graph learning tasks (node classification, edge classification, graph classification and graph regression). ZINC is one popular real-world molecular dataset of 250K graphs, whose task is graph property regression, out of which we select 12K for efficiency following works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17]</ref>. CLUS-TER is the node classification tasks generated via Stochastic Block Models <ref type="bibr" target="#b0">[1]</ref>, which are used to model communications in social networks by modulating the intra-community and extra-community connections. CIFAR10 is the original classical image classification dataset and converted into graphs using superpixel <ref type="bibr" target="#b1">[2]</ref> algorithm to test graph classification task. TSP dataset is based on the classical Travelling Salesman Problem, which tests edge classification on 2D Euclidean graphs to identify edges belonging to the optimal TSP solution. ModelNet is a dataset for 3D object recognition with two variants, ModelNet10 and Mod-elNet40, which comprise objects from 10 and 40 classes, respectively. We sample 1024 points for each object as input and use k-NN algorithm to construct the edges (k = 9 by default unless it is specified). Searching settings. The original architecture is initialized with 2 feature vertices. We perform network proliferation for 4 iterations to obtain a sequence of GNN architectures with the size of {2, 4, 8, 16}. Specifically, we choose SGAS <ref type="bibr" target="#b31">[32]</ref> as the search strategy that can differentiate the local supernet to a specific subnet. During the network differentiation, after warming up for 10 epochs, SGAS begins to simultaneously determine one node-learning operation and one relation-mining operation for every 5 epochs. Thus, the search epoch is set to {25, 25, 45, 85} for 4 sequential iterations. To carry out the architecture search, we hold out half of the training data as the validation set. For one-shot differentible search strategies (SGAS <ref type="bibr" target="#b31">[32]</ref> and DARTS <ref type="bibr" target="#b39">[40]</ref>), there are operation weights w and architectural parameters ? to be optimized. We use momentum SGD to optimize the weights w, with initial learning rate ? w = 0.025 (anneald down to zero following a cosine schedule without restart), momentum 0.9, and weight <ref type="table">Table 1</ref>. Comparison with state-of-the-art architectures on the CLUSTER, ZINC, CIFAR10 and TSP datasets. m ? denotes the architecture is mannually designed. The indicator E denotes whether the architecture can learn edge feature. The ARGNP without edge feature means that the relation space is removed from relation-aware graph search space. Note that mean and standard deviation are computed across 4 independently searched GNN architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Node Level</head><p>Graph Level Edge Level decay 3 ? 10 ?4 . We use Adam <ref type="bibr" target="#b27">[28]</ref> as the optimizer for ?, with initial learning rate ? ? = 3 ? 10 ?4 , momentum ? = (0.5, 0.999) and weight decay 10 ?3 .</p><formula xml:id="formula_14">Architecture CLUSTER ZINC CIFAR10 TSP E Metric Params Search Metric Params Search Metric Params Search Metric Params Search (AA %) ? (M) (day) (MAE) ? (M) (day) (OA %) ? (M) (day) (F1) ? (M)<label>(day</label></formula><p>Training settings. We follow all the training settings (data splits, optimizer, metrics, etc.) in work <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17]</ref>. Specifically, we adopt Adam <ref type="bibr" target="#b27">[28]</ref> with the same learning rate decay for all runs. The learning rate is initialized with 10 ?3 , which is reduced by half if the validation loss stops decreasing after 20 epochs. The weight decay is set to 0. The dropout is set to 0.5 to alleviate the overfitting. Our architectures are all trained for 400 epochs with a batch size of 32. We report the mean and standard deviation of the metric on the test dataset of 4 discovered architectures. These experiments are run on a single NVIDIA GeForce RTX 3090 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results and Analysis</head><p>In <ref type="table">Table 1</ref> and <ref type="table" target="#tab_3">Table 2</ref>, we compare our ARGNP with the state-of-the-art hand-crafted and search-based GNN architectures on the CLUSTER, ZINC, CIFAR10, TSP, Mod-elNet10, and ModelNet40 datasets. The evaluation metric is the average accuracy (AA) for CLUSTER, mean absolute error (MAE) for ZINC, F1-score (F1) for TSP. For CI-FAR10, ModelNet10, and ModelNet40, we use the overall accuracy (OA) as the evaluation metric. To make a fair comparison, we also report the architecture parameters, the search cost, and the mean and standard deviation of all the metrics. We can see that, on all the six datasets for four classical graph learning tasks, the GNN architec-tures discovered by our ARGNP surpass the state-of-theart architectures by a large margin in terms of both mean and standard deviation. Compared with the state-of-theart search-based method GNAS-MP <ref type="bibr" target="#b11">[12]</ref>, our searched architecture can easily achieve better performance with only 1 10 ? 1 4 parameters. This benefits from that the relationaware graph search space can mine hierarchical relation information (such as local structural similarity) to guide anisotropic message passing. Moreover, the network proliferation search paradigm can efficiently and effectively explore the proposed search space. We visualize the bestperformed GNN architecture with the size of 4 in <ref type="figure">Figure 5</ref>, which is searched on the ModelNet40 dataset. Other examples are provided in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation of Search Space</head><p>We study the influence of the relation search space in our proposed relation-aware graph search. First, we construct a search space variant by removing the relation search space. Then we perform GNN architecture search on this variant using the network proliferation search paradigm and obtain a sequence of GNN architectures with the size of {2, 4, 8, 16}. These GNN architectures are evaluated on six datasets. For a fair comparison, we increase the dimension of the node features to keep the architectural parameters comparable. As shown in <ref type="table">Table 1</ref> and <ref type="table" target="#tab_3">Table 2</ref>, the best performance of the search space variant without relation learning descends by a large margin. Under all the differ-</p><formula xml:id="formula_15">V_{in0} V1 V_Max(+E_{in0}) V2 V_Sum(+E_{in0}) V_{in1} V_Max(+E_{in1}) V3 V_Max(+E_{in1}) Vout V_Max(+E1) V_Gem3(+E2) V4 V_Max(+E2) V_Max(+E3) E_{in0} E1 E_Sub(+V_{in0}) E2 E_Had(+V_{in0}) E_{in1} E_Sub(+V_{in1}) E3 E_Sub(+V_{in1}) E4 E_Sub(+V_{in1}) Eout E_Had(+V1) E_Sum(+V2)</formula><p>E_Had(+V3) <ref type="figure">Figure 5</ref>. The best GNN architecture with the network size of 4 searched on the ModelNet40 dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation of Search Paradigm</head><p>To investigate the effectiveness of our Network Proliferation Search Paradigm (NPSP), we conduct the ablation experiments on ZINC dataset around network size, search strategy, whether to use cell trick and whether to use NPSP. We run 14 different experiments and report the results in <ref type="table" target="#tab_4">Table 3</ref>. We observe the following phenomena. First, the cell trick improves the search efficiency but weakens the expressive capability of graph search space. This results from its original assumption where the GNN architecture is a stack of the same building cells that narrows our relation-aware graph search space. Therefore, the search strategy with the cell trick performs worse than that without it, which is demonstrated by the contrast between exp 2 and exp 3, exp 5 and exp 6. Second, our NPSP can both significantly improves the search efficiency and search effect with different search strategies. The performance improvement benefits from that the NPSP can alleviate the subnet interference and mitigate the shrink of search space by breaking away from the cell assumption. The efficiency improvement lies in that NPSP shifts the training object from global supernet to sequential local supernets. They are supported by exp 4, 7, 11, and 14, where NPSP achieves the best performance with less time cost under all the experimental settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Visualizing Hierarchical Features</head><p>To better demonstrate the effectiveness of the relation learning, we provide relation and node features visualization on ModelNet40 dataset. During the inference, we feed forward one 3D pointcloud object into the network with </p><formula xml:id="formula_16">the input {V in0 , V in1 , E in0 , E in1 }, where V in0 = V in1 ? R 1024?3 are the 3D coordinates and E in0 = E in1 = 1 ? R (1024?9)?1</formula><p>are the pseudo relation features. The hierarchical node/relation features generated from each layer is denoted as {V 1 , ? ? ? , V 4 } and {E 1 , ? ? ? , E 4 }, respectively. For better visualization on the point cloud graph, we reduce the feature dimension to 1 through principal component analysis (PCA). The edges with a similar color are considered to have the same message passing preferences, while the nodes with a similar color are considered to belong to a similar cluster. A visualization example from ARGNP and a version without relation learning architecture are shown in <ref type="figure" target="#fig_3">Figure 6A</ref> and 6B, respectively. <ref type="figure" target="#fig_3">Figure 6A</ref>, ARGNP can capture the structural information and well discriminate different parts of the object (e.g., the legs, desktop, and border of the table in V</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>As shown in</head><formula xml:id="formula_17">(A) 4</formula><p>). In contrast, as shown in <ref type="figure" target="#fig_3">Figure 6B</ref>, the original GNN without relation learning architecture can only gradually propagate the node information through the input graph based on 3D coordinates. As a result, the similar nodes that are distant in the 3D space can not be well clustered (e.g., 4 legs of the table in V ). The above comparison shows that the relation features can guide better message passing mechanisms to learn more effective node features. To show the role of the relation learning more specifically, accompanied with the searched GNN in <ref type="figure">Figure 5</ref>, we analyze the features in <ref type="figure" target="#fig_3">Figure 6A</ref>. For example, the E (A) 1 is learned by substraction operation. The substraction operation is similar to an "border detection" operation that can discriminate the directions between two nodes. In this way, the ARGNP can directly distinguish groups of parallel components of an object (e.g., legs, parallel borders, etc. in V (A) 2</p><p>). However, without using the relation features, it requires numerous rounds of message passing which may cause the over smoothing problem. With the help of relation learning, the components with similar structures can be well clustered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper proposes the automatic relation-aware graph network proliferation (ARGNP) method to design the optimal GNN architectures by devising a novel relation-aware graph search space and a network proliferation search paradigm. The search space significantly improves the upper bound of the discovered GNN's reasoning capability while the proliferation search paradigm promotes search efficiency and effectiveness. Experiments show that ARGNP achieves superior performance for four tasks on six datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Search Space Details</head><p>In this section, we first detail how node-learning operations and relation-learning operations are formulated. Then we introduce the design of task-based layers for different graph learning tasks. V ? R n?d V , E ? R m?d E are node features and relation features that are fed forward to nodelearning and relation-learning operations, respectively. n and m are the number of nodes and edges of the input graph data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Node-learning Operations</head><p>As discussed in the body content, a node-learning operation o</p><formula xml:id="formula_18">(i,j) V computes the transformed information from feature vertex V i to V j , which is denoted as V i?j = o (i,j) V (V i , E i , f i,j )</formula><p>. Specifically, given node t on the graph, its transformed node feature V t i?j is formulated as</p><formula xml:id="formula_19">V t i?j = f i,j ({? s,t ?V s i + ? s,t |s ? N (t)}), ? s,t , ? s,t = g(E s,t i ; ?),<label>(4)</label></formula><p>where, N (t) denotes the set of neighbors of target node t on the graph, f i,j is an aggregating function. g(?) is a two-layer multilayer perceptron to compute the affine transformation with the learnable parameters ? =</p><formula xml:id="formula_20">W 1 W 2 W k W b , which is formulated as ? s,t ? s,t = ?(?(E s,t i W 1 )W 2 ) W k W b ,<label>(5)</label></formula><p>where ?(?) is the rectified linear unit. The difference between different node-learning operations lies in the choice of message aggregating functions. We design 8 candidate aggregating function options, i.e., V MEAN, V SUM, V MAX, V STD, V GEM2, V GEM3, zero and skip-connect for capturing different types of information. For clarity, we denote M s,t as the modulated incoming message from node t to node s, where M s,t = ? s,t ? V s i + ? s,t . The mean aggregation of neighboring messages is denoted as</p><formula xml:id="formula_21">? t (M ) = 1 |N (t)| s?N (t) M s,t .<label>(6)</label></formula><p>V MEAN is the average of neighboring messages, which captures the mean statistics of neighboring messages <ref type="bibr" target="#b20">[21]</ref>, written as V t i?j = ? t (M ).</p><p>V SUM is the sum of neighboring messages, which captures local structural information <ref type="bibr" target="#b58">[59]</ref>, written as</p><formula xml:id="formula_23">V t i?j = |N (t)| ? ? t (M ).<label>(8)</label></formula><p>V MAX is the max of neighboring messages, which captures the representative information <ref type="bibr" target="#b58">[59]</ref>, written as</p><formula xml:id="formula_24">V t i?j = max s?N (t) M s,t .<label>(9)</label></formula><p>V STD is the standard deviation of input feature set, which captures the stability of neighboring messages <ref type="bibr" target="#b14">[15]</ref>, i.e.,</p><formula xml:id="formula_25">V t i?j = ReLU (? t (M 2 ) ? ? t (M )) + ?,<label>(10)</label></formula><p>where ReLU is the rectified linear unit used to avoid negative values caused by numerical errors and ? is a small positive number to ensure the output is differentiable <ref type="bibr" target="#b14">[15]</ref>. Moreover, we also introduce Generalized Mean Pooling (GeM) for aggregating messages, which can focus on learning to propagate the prominent message <ref type="bibr" target="#b6">[7]</ref>, written as</p><formula xml:id="formula_26">GeM t (M , ?) = ? ReLU (? t (M ? )) + ?,<label>(11)</label></formula><p>where ? is the hyper parameter. Here, we adopt two widely used parameters to construct the node-learning operations, i.e., V GEM2 and V GEM3.</p><formula xml:id="formula_27">V GEM2: V t i?j = GeM t (M , 2).<label>(12)</label></formula><p>V GEM3:</p><formula xml:id="formula_28">V t i?j = GeM t (M , 3).<label>(13)</label></formula><p>skip-connect is to enhance the central node information and mitigate the gradient vanishing, written as</p><formula xml:id="formula_29">V t i?j = V t i .<label>(14)</label></formula><p>zero operation is included in the search space to indicate a lack of connection. Links that are important should have a low weight in the zero operation <ref type="bibr" target="#b31">[32]</ref>. It is formulated as</p><formula xml:id="formula_30">V t i?j = 0. ? V t i .<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Relation-mining Operations</head><p>A relation-mining operation o</p><formula xml:id="formula_31">(i,j) E computes the trans- formed relational information E i?j = o (i,j) E (V i , E i , h i,j )</formula><p>. h i,j is a relation-mining network, such as substraction, hardmard product, gauss kernel, etc. Specifically, given a specific edge (s, t) on the graph, E s,t i?j is computed using feature-wise linear modulation: </p><formula xml:id="formula_32">E s,t i?j = ? s,t ? E s,t i + ? s,t , ? s,t , ? s,t = h i,j (V s i , V t i ; ?),<label>(16)</label></formula><formula xml:id="formula_33">? s,t ? s,t = ?(?(h * (V s i , V t i )W 1 )W 2 ) W k W b ,<label>(17)</label></formula><p>where ?(?) is the rectified linear unit. The difference between different relation-mining operations lies in the choice of relation functions h * (?, ?). We design 8 candidate relation functions, i.e., E SUB, E GAUSS, E HAD, E MAX, E SUM, E MEAN, skip-connect, and zero for capturing different types of relational information. E SUB captures the relative change between two nodes. Its relation function is computed as</p><formula xml:id="formula_34">h * (V s i , V t i ) = V s i ? V t i<label>(18)</label></formula><p>E GAUSS measures the distance between the central node and its neighboring nodes:</p><formula xml:id="formula_35">h * (V s i , V t i ) = exp( |V s i ? V t i | 2 2? )<label>(19)</label></formula><p>E HAD emphasizes on learning the commonalities between the central node and its neighbors:</p><formula xml:id="formula_36">h * (V s i , V t i ) = V s i ? V t i (20) E SUM: h * (V s i , V t i ) = V s i + V t i (21) E MAX: h * (V s i , V t i ) = max(V s i , V t i )<label>(22)</label></formula><p>E MEAN:</p><formula xml:id="formula_37">h * (V s i , V t i ) = V s i + V t i 2<label>(23)</label></formula><p>skip-connect operation is to enhance the original relational information and mitigate the gradient vanishing, written as</p><formula xml:id="formula_38">? s,t ? s,t = 1 0 (24)</formula><p>zero operation is included in the search space to indicate a lack of connection. Links that are important should have a low weight in the zero operation <ref type="bibr" target="#b31">[32]</ref>. It is formulated as ? s,t ? s,t = 0 0 (25)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Task-based Layer</head><p>We design the final network layers depending on the specific task. Suppose there are 8 node feature vertices {V 1 , ? ? ? , V 8 } and 8 relation feature vertices {E 1 , ? ? ? , E 8 } in our GNN architecture, we compute the global node features V g and global edge features E g using the following formula</p><formula xml:id="formula_39">V g = ?(BN ([V 1 || ? ? ? ||V 8 ] W V )), E g = ?(BN ([E 1 || ? ? ? ||E 8 ] W E )),<label>(26)</label></formula><p>where</p><formula xml:id="formula_40">W V ? R d V ?d V , W E ? R d E ?d E</formula><p>are the learnable parameters, BN denotes batch normalization operation, ?(?) is the rectified linear unit, [?||?] denotes the feature concatenation operation. The global graph representation G g is computed using mean-pooling readout operation over global node features and global edge features, i.e.,</p><formula xml:id="formula_41">G g = ? ? 1 |V g | i?Vg V i g 1 |E g | (s,t)?Eg E s,t g ? ? ,<label>(27)</label></formula><p>where |V g | is the number of nodes, |E g | is the number of edges. Notably, this is different from the traditional GNN architecture whose global graph representation is only constructed on the readout of node features. Since our method can learn both node features and relation features, they are all leveraged to construct the global graph representation. This helps the graph representation embeds more useful relational information.</p><p>Node-level task layer. For node classification task, the prediction of node i is done as follows</p><formula xml:id="formula_42">y i = V i g C V ,<label>(28)</label></formula><p>where C V ? R d V ?n V is the node classifier, n V is the number of node classes. Edge-level task layer. For edge classification task, our method naturally makes prediction based on deep relation features E g , formally written as</p><formula xml:id="formula_43">y s,t = E s,t g C E ,<label>(29)</label></formula><p>where C E ? R d E ?n E is the edge classifier, n E is the number of edge classes. This is better than traditional GNN works <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b58">59]</ref> that concatenate the entity features as edge features, since the independent edge feeatures (associated with the relational information) are more discriminitive for edge-level tasks.</p><p>Graph-level task layer. For graph classification and regression tasks, we make the prediction based on the global graph representation, i.e.,</p><formula xml:id="formula_44">y = G g C G ,<label>(30)</label></formula><p>where C G ? R (d V +d E )?n G , n G is the number of graph classses. If it is graph regression task, then n G = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Network Differentiation Details</head><p>An architecture is represented as a directed acyclic graph (DAG) with {V, L}, where V = {X i } is the set of feature vertices and L = {e(X i , X j , O)} is the set of directed links. Each directed link e(X i , X j , O) can transform the features from X i to X j using an operation O, where O is either a specific operation o or a mixture operation?. The mixture operation? (i,j) is parameterized by architectural parameters ? (i,j) as a softmax mixture over all the possible operations within the operation space O, i.e.,</p><formula xml:id="formula_45">o (i,j) (X i ) = o?O exp(? (i,j) o ) o ? ?O exp(? (i,j) o ? ) o(X i ).<label>(31)</label></formula><p>For each operation o (i,j) , it is associated with the network weights w (i,j) . The network differentiation aims to differentiate the local supernets into several specific subnets. Specifically, after network division and before network differentiation, the current architecture contains two kinds of links e(X i , X j , o) and e(X i , X j ,?). After network differentiation, there is only one kind of links, i.e., e(X i , X j , o), where a valid architecture is obtained. This procedure can be implemented by some differentiable architecture search strategies (DARTS <ref type="bibr" target="#b39">[40]</ref>, SGAS <ref type="bibr" target="#b31">[32]</ref>, etc.). Taking DARTS as an example, the learning procedure of the architectural parameters involves a bi-level optimization problem, i.e.,</p><formula xml:id="formula_46">min A L val (W * (A), A),<label>(32)</label></formula><formula xml:id="formula_47">s.t.W * (A) = argmin W L train (W, A),<label>(33)</label></formula><p>where L train and L val are the training and validation loss, respectively. W is the set of network weigths {w (i,j) } and A is the set of the architectural parameters {? (i,j) }. DARTS <ref type="bibr" target="#b39">[40]</ref> proposes to solve the bi-level problem by a first/second order approximation. At the end of the search, the final architecture is derived by selecting the operation with the highest weight for each mixture operation, i.e.,</p><formula xml:id="formula_48">o (i,j) ? argmax o?O ? (i,j) o .<label>(34)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Visualizing Hierarchical Features</head><p>In this section, we provide more examples of the learned relation and node features on ModelNet40. The visualization results are reported in <ref type="figure">Figure 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Searched Architectures</head><p>We illustrate our searched GNN architectures using the proposed network proliferation search paradigm in <ref type="figure">Figure  8</ref> <ref type="bibr">, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26.</ref>        </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 Figure 1 .</head><label>11</label><figDesc>One iteration of the proposed network proliferation search paradigm. F (?) denotes the intermediate feature vertex in an architecture. The edges with different colors are associated with different operations. FY is the newly divided part of FX , which joins F1, F2 and FX to build a local supernet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Illustration of network proliferation search paradigm. It comprises two procedures of network divison and differentiation. The edges with different colors are associated with different operations. A group of dashed edges denotes a mixture operation. A local supernet comprises of three mixture operations pointing to one feature vertex. (i) denotes the i-th iteration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4</head><label>4</label><figDesc>Figure 4. Boxplots of 8-layer architectures on ZINC. "R" and "S" denote the random and SGAS [32] search strategies, respectively. e.g., architecture "RS" is constructed by sequentially performing random search, network division and SGAS search. The architecture size after the first and the second search is 4 and 8. Comparing "RR" with "SR", "RS" with "SS", we find that a presearched architecture is useful for subsequent search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Visualization of the learned hierarchical features for 3D point cloud recognition (taking table as an example). Relation features with different edge color distribution have different message passing preferences. Node features with different node color distribution represent different clustering effects.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .Figure 8 .</head><label>78</label><figDesc>Visualization of the learned hierarchical relation and node features for 3D point cloud recognition. Relation features with different edge color distributions have different message-passing preferences. Node features with different node color distributions represent different clustering effects. Illustration of the searched architecture with the size of 2 on the ZINC dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Illustration of the searched architecture with the size of 4 on the ZINC dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 .Figure 11 .</head><label>1011</label><figDesc>Illustration of the searched architecture with the size of 8 on the ZINC dataset. Illustration of the searched architecture with the size of 16 on the ZINC dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 12 .Figure 13 .</head><label>1213</label><figDesc>Illustration of the searched architecture with the size of 2 on the CLUSTER dataset. Illustration of the searched architecture with the size of 4 on the CLUSTER dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 14 .Figure 15 .Figure 16 .Figure 17 .</head><label>14151617</label><figDesc>Illustration of the searched architecture with the size of 8 on the CLUSTER dataset. Illustration of the searched architecture with the size of 16 on the CLUSTER dataset. Illustration of the searched architecture with the size of 2 on the TSP dataset. Illustration of the searched architecture with the size of 4 on the TSP dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 18 .Figure 19 .Figure 20 .Figure 21 .Figure 22 .Figure 23 .Figure 24 .Figure 25 .Figure 26 .</head><label>181920212223242526</label><figDesc>Illustration of the searched architecture with the size of 8 on the TSP dataset. Illustration of the searched architecture with the size of 16 on the TSP dataset. Illustration of the searched architecture with the size of 2 on the CIFAR10 dataset. Illustration of the searched architecture with the size of 4 on the CIFAR10 dataset. Illustration of the searched architecture with the size of 8 on the CIFAR10 dataset. Illustration of the searched architecture with the size of 16 on the CIFAR10 dataset. Illustration of the searched architecture with the size of 2 on the ModelNet10 dataset. Illustration of the searched architecture with the size of 4 on the ModelNet10 dataset. Illustration of the searched architecture with the size of 8 on the ModelNet10 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Our dual relation-aware graph search space. It comprises node and relation search space. The vertex Vi and vertex Ej denote a group of node and relation features on the graph, respectively. +Ej means that learning node features require the guidance of relation features. +Vi means that the node features are required when extracting relational information.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">relation-mining operations</cell></row><row><cell></cell><cell cols="2">Vin 0</cell><cell>+Ein 0</cell><cell>+Ein 1</cell><cell cols="2">Vin 1</cell><cell></cell><cell cols="2">Ein 0</cell><cell>+Vin 0</cell><cell></cell><cell>+Vin 1</cell><cell>Ein 1</cell></row><row><cell></cell><cell>+Ein 0</cell><cell>V3</cell><cell>+E1</cell><cell>V1 +E3</cell><cell>V2</cell><cell>+Ein 1</cell><cell>V</cell><cell>+Vin 0</cell><cell>E3</cell><cell>+V1</cell><cell>E1</cell><cell>+V1</cell><cell>E2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>E</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">+E3</cell><cell cols="3">+E2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>V4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>E4</cell><cell></cell></row><row><cell>node features (V i )</cell><cell cols="2">Vout 0</cell><cell></cell><cell></cell><cell cols="2">Vout 1</cell><cell></cell><cell cols="2">Eout 0</cell><cell></cell><cell></cell><cell></cell><cell>Eout 1</cell><cell>relation features (E j )</cell></row><row><cell></cell><cell cols="6">A. Node Search Space</cell><cell></cell><cell cols="6">B. Relation Search Space</cell></row><row><cell>Figure 2.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Comparision with state-of-the-art architectures on the ModelNet10 and ModelNet40 datasets at 3D point cloud recognition task. L denotes the size of GNN architecture. ? 93.20 ?0.24 91.11 ?0.24 1.80 0.03 ARGNP 4 ? 93.86 ?0.25 91.30 ?0.22 2.27 0.04 ARGNP 8 ? 94.23 ?0.22 91.85 ?0.18 3.20 0.15 ARGNP 2 ? 95.07 ?0.31 92.47 ?0.23 2.50 0.04 ARGNP 4 ? 95.35 ?0.23 92.80 ?0.19 3.05 0.06 ARGNP 8 ? 95.87 ?0.22 93.33 ?0.15 4.15 0.20</figDesc><table><row><cell></cell><cell></cell><cell cols="2">ModelNet10 ModelNet40</cell><cell></cell><cell></cell></row><row><cell cols="2">Architecture L E</cell><cell>Metric</cell><cell>Metric</cell><cell cols="2">Params Search</cell></row><row><cell></cell><cell>(#)</cell><cell>(OA %) ?</cell><cell>(OA %) ?</cell><cell cols="2">(M) (Day)</cell></row><row><cell>3DmFV [6]</cell><cell>/ /</cell><cell>95.2</cell><cell>91.6</cell><cell>45.77</cell><cell>m ?</cell></row><row><cell cols="2">PointNet++ [47] / /</cell><cell>N/A</cell><cell>90.7</cell><cell>1.48</cell><cell>m ?</cell></row><row><cell>PCNN [3]</cell><cell>/ /</cell><cell>N/A</cell><cell>92.3</cell><cell>8.20</cell><cell>m ?</cell></row><row><cell cols="2">PointCNN [35] / /</cell><cell>N/A</cell><cell>92.2</cell><cell>0.60</cell><cell>m ?</cell></row><row><cell>DGCNN [55]</cell><cell>/ /</cell><cell>N/A</cell><cell>92.2</cell><cell>1.84</cell><cell>m ?</cell></row><row><cell>KPConv [52]</cell><cell>/ /</cell><cell>N/A</cell><cell>92.9</cell><cell>14.3</cell><cell>m ?</cell></row><row><cell>SGAS [32]</cell><cell>9 ?</cell><cell>N/A</cell><cell cols="2">92.93 ?0.19 8.87</cell><cell>0.19</cell></row><row><cell cols="6">ARGNP 2 ent network size settings, relation learning can significantly</cell></row><row><cell cols="6">improve the capability of graph reasoning. Interestingly,</cell></row><row><cell cols="6">this improvement is also observed on the CLUSTER, CI-</cell></row><row><cell cols="6">FAR10, and ModelNet datasets which don't have original</cell></row><row><cell cols="6">edge features. Taking the CLUSTER dataset as an exam-</cell></row><row><cell cols="6">ple, it aims at identifying the community clusters, where the</cell></row><row><cell cols="6">graphs represent the community networks. The edges play</cell></row><row><cell cols="6">a role in connecting two nodes and have no original mean-</cell></row><row><cell cols="6">ingful features. In this case, relation learning can mine hier-</cell></row><row><cell cols="6">archical relational information by extracting local structural</cell></row><row><cell cols="6">similarities between nodes. This can help distinguish be-</cell></row><row><cell cols="6">tween intra-community and extra-community connections</cell></row><row><cell cols="5">for learning better discriminative node features.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Performance of the relation-aware graph search space under different settings. Cell is an indicator of whether to use the cell trick. NPSP is an indicator of whether to use the network proliferation search. OOM denotes out of memory.</figDesc><table><row><cell>ZINC</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>? s,t , ? s,t is the affine transformation learned by h i,j with the learnable parameters ? = W 1 W 2 W k W b and relation function h</figDesc><table /><note>* (?, ?)</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Community detection and stochastic block models: recent developments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Abbe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="6446" to="6531" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Slic superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radhakrishna</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Appu</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>S?sstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Point convolutional neural networks by extension operators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matan</forename><surname>Atzmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haggai</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Designing neural network architectures using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otkrist</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02167</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Directional graph networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominique</forename><surname>Beaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saro</forename><surname>Passaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Vincent L&amp;apos;etourneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Three-dimensional point cloud classification in real-time using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhak</forename><surname>Ben-Shabat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lindenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anath</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3145" to="3152" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multigrain: a unified image embedding for classes and instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<idno>abs/1902.05509</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving graph neural network expressivity via subgraph isomorphism counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Bouritsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Frasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<idno>abs/2006.09252, 2020. 1</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Residual gated graph convnets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Laurent</surname></persName>
		</author>
		<idno>abs/1711.07553</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Gnn-film: Graph neural networks with feature-wise linear modulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.00332</idno>
		<title level="m">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rethinking graph neural architecture search from message-passing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaofei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jincan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beichen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengjun</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1294" to="1303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Darts-: robustly stepping out of performance collapse without indicators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shun</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.01027</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Principal neighbourhood aggregation for graph nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Cavalleri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominique</forename><surname>Beaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;apos;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Velickovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Benchmarking graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Prakash Dwivedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<idno>abs/2003.00982, 2020. 1</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Prakash Dwivedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chaitanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00982</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Benchmarking graph neural networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Graph neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<idno>abs/1704.01212</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning region features for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the european conference on computer vision (ECCV)</title>
		<meeting>the european conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="381" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Milenas: Efficient neural architecture search via mixed-level reformulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haishan</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11990" to="11999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Relation networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3588" to="3597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Class-wise dynamic graph convolution for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihao</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Edge-augmented graph transformers: Global selfattention is enough for graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><forename type="middle">J</forename><surname>Md Shamim Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Subramanian</surname></persName>
		</author>
		<idno>abs/2108.03348, 2021. 1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Zinc: a free tool to discover chemistry for biology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teague</forename><surname>Irwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sterling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><forename type="middle">S</forename><surname>Mysinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan G</forename><surname>Bolstad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Coleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1757" to="1768" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Edge-labeling graph neural network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongmin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><forename type="middle">Dong</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization. CoRR, abs/1412</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">6980</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<idno>abs/1609.02907</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Large-scale point cloud semantic segmentation with superpoint graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Landrieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Simonovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4558" to="4567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sgas: Sequential greedy architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guohao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guocheng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Itzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Delgadillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sgas: Sequential greedy architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guocheng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Itzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Delgadillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><forename type="middle">K</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1617" to="1627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Spatial pyramid based graph reasoning for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qijie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiancheng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8947" to="8956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pointcnn: Convolution on x-transformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingchao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhan</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Relevance-aware anomalous users detection in social network via graph neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yipeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoning</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shulong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhao</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifeng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">One-shot graph neural architecture search with dynamic search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zean</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI, 2021. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingqiu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kechen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.06035</idno>
		<title level="m">Darts+: Improved differentiable architecture search with early stopping</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Hierarchical representations for efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisantha</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.00436</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Darts: Differentiable architecture search. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1806" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Content matters: A gnn-based model combined with text semantics for social network cascade prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PAKDD</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Encoding sentences with graph convolutional networks for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04826</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5115" to="5124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Autostg: Neural architecture search for predictions of spatio-temporal graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheyi</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodu</forename><surname>Songyu Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zheng</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Proceedings of the Web Conference 2021, 2021. 1, 2</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameters sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melody</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4095" to="4104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Sanja Fidler, and Raquel Urtasun. 3d graph neural networks for rgbd semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5199" to="5208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the aaai conference on artificial intelligence</title>
		<meeting>the aaai conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4780" to="4789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Large-scale evolution of image classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherry</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><forename type="middle">Leon</forename><surname>Suematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kurakin</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2902" to="2911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garcia</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Satorras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bruna</surname></persName>
		</author>
		<idno>abs/1711.04043</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Kpconv: Flexible and deformable convolution for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Emmanuel</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatriz</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6410" to="6419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Graph attention networks. ArXiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;apos;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1710.10903</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Graph attention convolution for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaolin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenman</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Shan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10288" to="10297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Transactions On Graphics (tog)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1912" to="1920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.09926</idno>
		<title level="m">Snas: stochastic neural architecture search</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Snas: Stochastic neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<idno>abs/1812.09926</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">How powerful are graph neural networks? ArXiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<idno>abs/1810.00826</idno>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Pc-darts: Partial channel connections for memory-efficient differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<idno>abs/1907.05737</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Dpgn: Distribution propagation graph network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erjin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13387" to="13396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Factorizable graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiding</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zunlei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingli</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchao</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deeper insights into weight sharing in neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuge</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zejun</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanlu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaming</forename><surname>Yang</surname></persName>
		</author>
		<idno>abs/2001.01431</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Acenas: Learning to rank ace neural architectures with weak supervision of weight sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuge</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenqian</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanlu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><forename type="middle">Lyna</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotian</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Yang</surname></persName>
		</author>
		<idno>abs/2108.03001</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Simplifying architecture search for graph neural network. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanning</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Auto-gnn: Neural architecture search of graph neural networks. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaixiong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingquan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01578</idno>
		<title level="m">Neural architecture search with reinforcement learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
