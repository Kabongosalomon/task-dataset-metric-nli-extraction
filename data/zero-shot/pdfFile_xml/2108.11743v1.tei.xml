<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Spatio-Temporal Dynamic Inference Network for Group Activity Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangjie</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Control Science and Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Ni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Control Science and Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Laboratory of Industrial Control Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mang</forename><surname>Wang</surname></persName>
							<email>wangmang.wm@alibaba-inc.com</email>
							<affiliation key="aff2">
								<orgName type="department">DAMO Academy</orgName>
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Spatio-Temporal Dynamic Inference Network for Group Activity Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Group activity recognition aims to understand the activity performed by a group of people. In order to solve it, modeling complex spatio-temporal interactions is the key. Previous methods are limited in reasoning on a predefined graph, which ignores the inherent person-specific interaction context. Moreover, they adopt inference schemes that are computationally expensive and easily result in the over-smoothing problem. In this paper, we manage to achieve spatio-temporal person-specific inferences by proposing Dynamic Inference Network (DIN), which composes of Dynamic Relation (DR) module and Dynamic Walk (DW) module. We firstly propose to initialize interaction fields on a primary spatio-temporal graph. Within each interaction field, we apply DR to predict the relation matrix and DW to predict the dynamic walk offsets in a jointprocessing manner, thus forming a person-specific interaction graph. By updating features on the specific graph, a person can possess a global-level interaction field with a local initialization. Experiments indicate both modules' effectiveness. Moreover, DIN 1 achieves significant improvement compared to previous state-of-the-art methods on two popular datasets under the same setting, while costing much less computation overhead of the reasoning module.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Group activity recognition (GAR) aims to infer an overall activity performed by a group of people in the scene <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b47">48]</ref>. It has aroused research interests due to various applications, including surveillance/sports video analysis, social scene understanding, etc. The critical problem that lies in GAR is to infer a grouplevel activity representation given a video clip, which asks for elaborately designed reasoning modules. The red bounding box annotated with a star is the person performing the key action for the activity. The grey arrow denotes the key interaction linking the starred person and the semantically important person, which is always not aligned in the spatial or temporal domain. The person indices do not start from 1 because we only illustrate part of the images.</p><p>Recently proposed reasoning modules mainly incorporate spatio-temporal interactive factors to get a refined activity representation. Modeling of agents' interactions has been widely studied. The mostly adopted methods are recurrent neural networks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b48">49]</ref>, the attention mechanism <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b18">19]</ref> and graph neural networks (GNNs) <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b43">44]</ref>. GNNs have been a frequently adopted method in GAR <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b30">31]</ref>, which performs message passing on a constructed semantic graph and achieves competitive results on publicly available benchmarks.</p><p>However, previous methods using GNNs stick to a paradigm that models the interaction between individuals on a predefined graph as shown in <ref type="figure">Figure 2</ref>. It is a feasible way but bears several drawbacks: i) Those who interact with a given person should be person-specific but not predefined. Like in <ref type="figure" target="#fig_0">Figure 1</ref>, a person will interact with people depending on their own context: the 8th person in the left video interacts with the 9th person who is about to spike the ball; the 10th person in the right video interacts with the 9th person who is about to set the ball. A predefined graph can not suit every person's inference. ii) Previous predefined graph models infer interactions on a fully-connected <ref type="bibr" target="#b42">[43]</ref> or criss-cross <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b30">31]</ref> graph which is shown in <ref type="figure">Figure   Figure 2</ref>. Visualizations of three inference schemes in spatiotemporal domain with GNNs for GAR. The green node denotes the feature to be updated. The purple nodes denote features involved in updating the green node. (a) Fully-connected graph inference. (b) Criss-cross graph inference. (c) Proposed person-specific dynamic graph inference, which is unique for every green node. The dashed box is an example of an initialized interaction field. 2(a) and (b). It easily results in the over-smoothing <ref type="bibr" target="#b26">[27]</ref> that makes features indistinguishable and damages the performance. Also, it costs overmuch computation overhead if expanding to long video clips or expanding to a scenario with too many people in the scene.</p><p>Aiming at solving the drawbacks mentioned above, inspired by <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b49">50]</ref>,we present Dynamic Inference Network (DIN), which contains Dynamic Relation (DR) and Dynamic Walk (DW). These two modules combined can predict a person-specific interaction graph for better modeling interactions as shown in <ref type="figure">Figure 2</ref>(c). For a given person feature on a spatio-temporal graph, we set a spatio-temporal interaction field around it as an initialization, which is shared between DR and DW. This interaction field determines the people to be involved in inferring the interaction graph. The initialized field size will not increase if the spatial or temporal axis expands, which reduces the computation.</p><p>Within this initialized interaction field, we use DR to predict a person-specific relation matrix, denoting the interaction relations between persons. The features in the interaction field endow the relations with an interaction context. Then, to facilitate the model to learn from complex spatiotemporal interactions, we use DW to predict dynamic walk offsets for every feature within the field. The dynamic walks allow for the locally initialized interaction field to form a graph that enables global-level interactions. The proposed modules are easy for deployment onto any widely used backbones to form a pipeline named DIN. Besides, previous methods seldom make computational complexity analysis, which is a significant evaluation for a designed module. In this paper, we present computational complexity analysis and show that our modules cost less computation overhead while performing better.</p><p>To summarize, our contributions are listed as follows:</p><p>? We propose DIN to construct person-specific interaction graphs in the spatio-temporal domain, which are not predefined and can also serve as a general approach for modeling interactions. ? We propose DR that predicts person-specific relation matrices and DW that allows for the locally initialized interaction field to update features globally. Both are proved useful by experiments. ? We prove by experiments that a small size of initialized interaction field is sufficient for existing datasets. We use a case visualization to exemplify that interaction graphs can capture the key person and key interactions, and a locally initialized interaction field can cover a global-level interaction field with proposed modules. ? DIN achieves state-of-the-art performances under the setting of the same backbone and input modality on two widely used benchmarks, while costing much less computation overhead of the reasoning module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Group Activity Recognition Group activity recognition was firstly proposed in <ref type="bibr" target="#b8">[9]</ref>. Following works <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b1">2]</ref> were basically to extract hand-crafted features (e.g., HOG <ref type="bibr" target="#b11">[12]</ref>) and apply graphical models to infer group activity representations. With the boom of deep learning, methods incorporating convolution neural networks (CNNs) and recurrent neural networks (RNNs) have proved effective. For example, the works of <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b3">4]</ref> managed to model the temporal dynamics in action level or group level via RNNs on CNN features. The works of <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b35">36]</ref> applied RNNs to the modeling of person interactions. The attention mechanism also proved its effectiveness in GAR. The works of <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b38">39]</ref> combined RNNs with attention mechanisms to capture the key features in the spatial or temporal domain. Specifically, the self-attention mechanism was introduced to learn the temporal evolution and spatial interactions <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b30">31]</ref>.</p><p>GNNs, which inferred on graph-structured data, attracted researchers' attention in GAR. ARG <ref type="bibr" target="#b42">[43]</ref> firstly proposed to use graph convolution networks (GCNs) to learn person interactions on a spatio-temporal graph. Later, several works <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b46">47]</ref> improved the previous fullyconnected graph to a criss-cross one when modeling relations and aggregating features. However, they all ignored the person-specific interaction context. Our work is partly inspired by deformable convolution <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b50">51]</ref>, whose relations are not conditioning on the person features. Moreover, related work like DGMN <ref type="bibr" target="#b49">[50]</ref> which mentioned 'dynamic' constrained in implicit pixel-level spatial feature enhancement, while our pipeline suits video processing and agentlevel spatio-temporal reasoning.</p><p>Modeling of Interactions The modeling of interactions is significant in understanding a complex system with multiple objects/agents <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Many research areas inherently involve the modeling of interactions like trajectory prediction <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b33">34]</ref>, human object interaction <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b13">14]</ref> and scene graph generation <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b6">7]</ref>. In GAR, modeling interactions is crucial in understanding their overall activity <ref type="bibr" target="#b3">[4]</ref>. Among <ref type="figure">Figure 3</ref>. The overall pipeline of Dynamic Inference Network. Generally, it consists of two stages: i) Spatio-temporal feature extraction, ii) Reasoning module. Note that there will be T ? N unique interaction graphs for updating. In our codebase, the first stage is shared with previous methods. The main variations are in the Reasoning Module. We only illustrate 4 bounding boxes in the image for clarity. their adopted methods, GNNs have been a frequently chosen method. Some related works like EvolveGCN <ref type="bibr" target="#b29">[30]</ref> explored a better representation learning strategy on evolving graphs and EvolveGraph <ref type="bibr" target="#b25">[26]</ref> explored a prediction method to adjust the structure of one graph. However, we focus on the exploration of constructing dynamic agent-specific graphs based on their interaction field. The proposed modules are general approaches to tackle the modeling of interactions in related problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>In this section, we firstly outline the pipeline of DIN. Then, we give a brief review of previous GNN reasoning modules for GAR. Finally we introduce the modules that we propose to dynamically infer the group activity. To better present the idea, we specifically present the feature updating method for the ith person feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dynamic Inference Network</head><p>The integrated framework, which we denote as Dynamic Inference Network (DIN), is illustrated in <ref type="figure">Figure 3</ref>. The DIN takes in a short clip of videos, which is fed into a selected backbone network to extract visual features. For the backbone network, we mainly experiment on ResNet-18 <ref type="bibr" target="#b17">[18]</ref> and VGG-16 <ref type="bibr" target="#b36">[37]</ref> to demonstrate the effectiveness of our proposed module and to seek for a fair comparison with previous methods. Then RoIAlign <ref type="bibr" target="#b16">[17]</ref> is applied to extract the person features aligned with bounding boxes, which are then embedded to a D-dimension space. We stack the person features to form X ? R T ?N ?D , where T, N denotes the temporal steps (i.e., temporal dimension) and number of annotated people in each frame (i.e., spatial dimension) respectively. Note that the spatial dimension is ordered by people's coordinates following <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b14">15]</ref>. It is then arranged into a Spatio-Temporal graph (ST graph). The proposed DR and DW dynamically predict a specific interaction graph for a selected feature (T ? N interaction graphs in total). Thus, we can operate feature updating accordingly.</p><p>After the above inference, we can perform a global pooling to get the final group representation, which contains a max-pooling layer along the spatial dimension and an average pooling layer along the temporal dimension. The training objective is the cross-entropy loss for group activities. Although many previous methods like <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b14">15]</ref> use additional cross-entropy loss for individual actions, the action labels are actually ill-defined <ref type="bibr" target="#b46">[47]</ref> and expensive in labeling. We use cheap group activity labels while still achieving competitive results.</p><p>Although computational complexity analysis in Section 4 already indicates that DR and DW bring in limited parameters and FLOPs apart from the backbone and the embedding layer, we take a step further to seek for a lighter reasoning module. In practice, we apply pointwise convolution <ref type="bibr" target="#b19">[20]</ref> before the reasoning module to reduce the dimension of X from D to D l . We name this model Lite DIN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Recap of Previous GNN Reasoning</head><p>We start the recap by introducing Actor Relation Graph (ARG) in <ref type="bibr" target="#b42">[43]</ref>. The spatio-temporal feature extraction stage for ARG is identical to the DIN as illustrated in <ref type="figure">Figure  3</ref>. It uses a fully-connected graph as illustrated in <ref type="figure">Figure  2</ref>(a). The spatial and temporal dimension of person features X are collapsed to one, denoted as</p><formula xml:id="formula_0">X = {x i } T N i=1 with x i ? R D .</formula><p>Their pairwise relations can be denoted as R = {r i,j |i, j = 1, ..., T N } with r i,j ? R 1 , which can be computed by</p><formula xml:id="formula_1">r i,j = ?(x i ) T ?(x j ) ? D r (1) r i,j = softmax j (r i,j ) = exp(r i,j ) T N q=1 exp(r i,q )<label>(2)</label></formula><p>where ? and ? are linear transformations functions, i.e., ?(x i ) = W ? x i with W ? ? R Dr?D and ?(x i ) is similarly defined; D r is the dimension of the embedding space; softmax j defines a softmax function along the index j to get the normalized relationsr i,j . We do not formulate distance mask here for clarity. <ref type="figure">Figure 4</ref>. Details of DR and DW on creating the person-specific interaction graph for ith person. For the given person, DR predicts a relation matrix and DW predicts the dynamic walk offsets to endow the interaction graph with a global interaction field, both based on an initialized interaction field (we set it to 3 ? 3 as an example).</p><p>We perform one-layer ARG to update the person feature as</p><formula xml:id="formula_2">x (l+1) i = Ng g=1 ? T N j=1r i,j x (l) j w (g) + x (l) i (3)</formula><p>where N g , g, l denote the number of graphs in one layer, the graph index and the layer index respectively; ? is an activation function (ReLU in our implementation); w (g) ? R D?D is the graph-specific trainable transformation matrix. Note that w (g) andr i,j are also layer-specific but for the purpose of clarity, we omit this superscript l. Similar thing is done for learnable parameters and relations in following equations.</p><p>After the feature updating, we finally perform a global pooling operation on the reshaped X (l+1) ? R T ?N ?D to get the final group representation z ? R D . The Cross Inference Block proposed in <ref type="bibr" target="#b45">[46]</ref> ameliorates the fullyconnected inference by criss-cross inference as shown in <ref type="figure">Figure 2</ref>(b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Dynamic Relation</head><p>Before we dive into the proposed modules, we present the definition for the interaction field. The Interaction Field is a region upon an ST graph that is involved in inferring the interaction features. One example of the interaction field is shown using a dashed box on the ST graph in <ref type="figure">Figure  4</ref>. Our proposed modules, i.e. DR and DW, jointly process features within this field to infer person-specific interaction graphs. The initialized interaction field covers a selected person's spatio-temporal neighborhoods, which provides direct interaction cues. More complex initializations are left for future exploration.</p><p>We propose Dynamic Relation (DR) to infer the relation matrix for the person-specific interaction graph. An illustration of DR is shown in the upper branch of <ref type="figure">Figure 4</ref>. 'Dynamic' in DR refers to the fact that the relation matrix is dependent on the features in the initialized interaction field, rather than sticks to the same when updating every feature.</p><p>To infer the dynamic relations within this field, we adopt convolution following <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b49">50]</ref>. For a selected ith feature on the original ST graph, we denote u i ? R (K?D) as the stacking features within its interaction field and denote K as the interaction field size, e.g., K = 9 if the interaction field is 3 ? 3. We rewrite the convolution in a matrix form as</p><formula xml:id="formula_3">A i = W a u i + b a<label>(4)</label></formula><p>where W a ? R K?(K?D) is the linear projection matrix for inferring relations; b a ? R K is the bias parameters. A i = {a i,k |k = 1, ..., K} with a i,k ? R 1 is the relation matrix for ith feature, where k enumerates K features in ith feature's initialized field. Similar to Eq.2,? i,k is the normalized a i,k along the index k, i.e.,? i,k = softmax k (a i,k ). Instead of updating the features in a fully-connected graph or criss-cross graph, we update the features within the initialized field as</p><formula xml:id="formula_4">x (l+1) i = ? K k=1? i,k x (l) k w + x (l) i<label>(5)</label></formula><p>Note that we do not incorporate multiple graphs due to its excessive parameters and trivial improvement <ref type="bibr" target="#b42">[43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Dynamic Walk</head><p>Although DR has successfully inferred their relations with all person features in the initialized interaction field, it still follows a predefined message passing route, which lacks the ability for person-specific interaction modeling. Moreover, previous methods manage to model long-range spatio-temporal dependency by a fixed graph in a fullyconnected or criss-cross scheme, which consumes excessive computational resources. We propose a Dynamic Walk (DW) module that enables features within the interaction field to execute dynamic walks on the primary ST graph. An illustration of DW is shown in the lower branch of <ref type="figure">Figure 4</ref>. Through DW, we hope to model complex spatiotemporal dependency using a size-limited interaction field. 'Dynamic' in DW refers to the fact that the interaction graph is dependent on the features in the initialized interaction field, which is not predefined anymore.</p><p>To allow for dynamic walk, we need to predict their spatio-temporal dynamic walk offsets. For a selected ith person feature, we denote the dynamic walk offsets for all features within the interaction field as ?P i = {?p i,k |k = 1, ..., K} with ?p i,k ? R 2 . We predict the dynamic walk offsets as</p><formula xml:id="formula_5">?P i = W p u i + b p<label>(6)</label></formula><p>where W p ? R (K?2)?(K?D) is the linear projection matrix for predicting dynamic walk offsets; b p ? R (K?2) is the bias term. Similar to DR, this predicts the dynamic walk offsets for all features within the field and it is instantiated by convolution. Using the predicted offsets, we can obtain the dynamic-walked features by performing dynamic walk on the ST graph. Note that the dynamic-walked features are clamped to be within the range of the ST graph. As the dynamic walk offsets are constantly fractional, a bilinear sampler <ref type="bibr" target="#b22">[23]</ref> is adopted to sample dynamic-walked features. We denote the coordinate of the kth feature in the ith interaction field as p i,k ? R 2 . Dynamic-walked features Y i = {y i,k |k = 1, ..., K} with y i,k ? R D can be formulated as</p><formula xml:id="formula_6">y i,k = T m=1 N n=1</formula><p>x (m?1)N +n ?(m, n, p i,k , ?p i,k )</p><p>?(m, n,</p><formula xml:id="formula_8">p i,k , ?p i,k ) = max(0, 1 ? |m ? p T i,k ? ?p T i,k |) ?max(0, 1 ? |n ? p N i,k ? ?p N i,k |)<label>(8)</label></formula><p>where superscript 'T ' and 'N ' denotes the temporal and spatial coordinate. Based on the dynamic-walked features, we can update the ith feature as</p><formula xml:id="formula_9">x (l+1) i = ? K k=1? i,k y (l) i,k w + x (l) i<label>(9)</label></formula><p>Note that in the above formulation, we combine the DR and DW to form the final dynamic updating function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we first present datasets and implementation details for GAR. Next, we perform quantitative analysis to explore the contributions of our modules and variances of different interaction field initializations, and to prove the superiority in terms of computational complexity. Then, we compare our methods with previous state-of-the-art methods. Finally, we provide visualizations to understand DIN better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiment Settings</head><p>Datasets So far, there are two widely used datasets in group activity recognition, namely Volleyball dataset (VD) <ref type="bibr" target="#b21">[22]</ref> and Collective Activity dataset (CAD) <ref type="bibr" target="#b8">[9]</ref>.</p><p>The Volleyball dataset comprises of 3,493 training clips and 1,337 testing clips, which are trimmed from 55 videos of volleyball matches. For each short clip, it provides three kinds of annotations: i) coordinates of players' bounding boxes in the center frame of a given clip; ii) individual action labels for the annotated person: blocking, digging, falling, jumping, moving, setting, spiking, standing and waiting, which are not used in our experiments; iii) group activity labels for the given clip: right set, right spike, right pass, right winpoint, left set, left spike, left pass and left winpoint. To perform feature extraction on the whole clip, we use the tracklets provided by <ref type="bibr" target="#b3">[4]</ref>. Two metrics are used for evaluating the performance of a model, i.e., MCA (%) which is short for Multi-class Classification Accuracy and MPCA (%) which is short for Mean Per Class Accuracy.</p><p>The Collective Activity dataset comprises of 44 videos containing varying number of frames from 194 to 1,814 frames. Similar to VD, it is labelled with three levels of annotations: i) coordinates of people's bounding boxes on the center frame of every ten frames; ii) individual action labels for the annotated person: NA, crossing, waiting, queueing, walking and talking, which are not used in our experiments; iii) group activity labels for every ten frames: crossing, waiting, queueing, walking and talking. We follow <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46]</ref> to merge the class crossing and walking into moving. Similarly, we use the tracklets from <ref type="bibr" target="#b3">[4]</ref>. Traintest split follows <ref type="bibr" target="#b31">[32]</ref>. MPCA is used for evaluation on this dataset due to class imbalance.</p><p>Implementation Details For VD, we use video images with resolution H ? W = 720 ? 1280. For CAD, we use video images with resolution H ? W = 480 ? 720. For both datasets, we use video clips which contain T = 10 frames each following <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b20">21]</ref>. The maximum number of people in the scene is N = 12 for VD and N = 13 for CAD. We use person feature with embedding dimension D = 1024. For Lite DIN, we use the embedding dimension D l = 128. The convolution operations for DR and DW are initialized by zero vectors <ref type="bibr" target="#b10">[11]</ref>. When applying convolution on the graph, we use zero paddings to maintain a fixed interaction field size. We follow <ref type="bibr" target="#b42">[43]</ref> to initialize the backbone of DIN model with parameters from the base model. We do not use any action label supervision. For the training of VD, we employ Adam optimizer whose learning rate starts with 1 ? 10 ?4 and decay rate is 1 3 every 10 epochs. For the training of CAD, we employ the same optimizer whose learning rate starts and stays with 5 ? 10 ?5 . We run 30 epochs in total. The hyper-parameter for Adam is ? 1 = 0.9, ? 2 = 0.999 and ? = 10 ?8 . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Quantitative Analysis</head><p>In this subsection, we conduct experiments on VD. We set the backbone for quantitative analysis to ResNet-18.</p><p>DR and DW We first conduct ablation study to demonstrate the efficacy of proposed modules. We use a fixed initialized interaction field of 3 ? 3 and following models:</p><p>? Base model: It consists of a backbone network, RoIAlign, the global pooling layer and a final classification layer. ? DIN w/ DR: It contains a backbone, RoIAlign, DR module, a global pooling layer and a classification layer. It allows for a relation matrix prediction within the interaction field. ? DIN w/ DW: It contains a backbone, RoIAlign, DW module, a global pooling layer and a classification layer. It allows for a dynamic walk prediction to expand its interaction field. ? DIN w/ DR+DW: It is defined analogously with above models. It allows for a dynamic relation prediction based on the original features in the field as illustrated in <ref type="figure">Figure 4</ref>. ? DIN w/ DR+DW * : It is defined analogously with DIN w/ DR+DW, except that it allows for a dynamic relation prediction based on dynamic-walked features, i.e., Y i . The results for the above models are shown in <ref type="table" target="#tab_0">Table 1</ref>. The table indicates that incorporating any proposed modules can significantly improve the performance. Compared to ARG <ref type="bibr" target="#b42">[43]</ref>, the result for DIN w/ DR indicates the superiority of joint processing and a small interaction field. The result for DIN w/ DW indicates the superiority of personspecific interaction graphs. We find that DIN w/ DR and DIN w/ DW show similar improvements compared to the base model. We consider it is because that after we perform the dynamic walk on a graph, the bilinear sampler defines the feature interpolation by bilinear weights, which is, to some extent, one kind of dynamic relations. These weights are determined by the dynamic walk offsets, which are not as straightforward as DR. The partial ability of dynamic relations and a global interaction graph enable DIN w/ DW to perform similarly with DIN w/ DR.</p><p>Combining DR and DW, the DIN model is endowed with more dynamicity and larger interaction fields, thus perform- ing even better. Specifically, DIN w/ DR+DW performs slightly better than DIN w/ DR+DW * , which indicates the initialized interaction field provides sufficient information for predicting relations.</p><p>Computational Complexity Analysis In this subsection, we present the parameters and FLOPs that the reasoning module contains. Note that the reasoning module that we define does not include the backbone and the person feature embedding layer, as we mainly focus on an efficient reasoning module in this paper. Since previous methods' reported results vary in the input modality, backbones and implementation details, we re-implement them to fit into our framework and codebase while ensuring consistency to the original paper and their publicly available codes. We use an initialized interaction field of 3 ? 3 for all our proposed modules. For a fair comparison, we set all their backbones to ResNet-18. The results are listed in <ref type="table" target="#tab_1">Table 2</ref>. Besides, we present the statistics for the backbone and person feature embedding as a reference: 24.8M #Params, 674.6 GFLOPs for 720 ? 1280 resolution and 24.8M #Params, 254.9 GFLOPs for 480 ? 720 resolution. The result has shown that the model with DR or DW alone achieves higher performances than previous methods, at the same time, reduces the computational complexity of the reasoning module. By combining DR and DW, our model benefits from the dynamicity of person-specific relation matrices and the dynamic walk offsets, thus achieving better performance. Note that the model with DR+DW adds very little computation cost compared to the model with DR or DW alone.  <ref type="table">Table 3</ref>. Results for increasing initialized interaction fields using three models. Backbone: ResNet-18. Computational cost for the backbone and embedding layer is not included. K = 9, 25, 49, 81 for 4 interaction fields and D l = D 8 .</p><p>tion matrix A i . We set D r = D. We can observe that i) the previous pairwise interaction model EDP which predicts relations using only two persons, performs slightly worse than DR and cost higher computation overhead; ii) If comparing EDP to ARG, it shows a small initialized field ameliorates the over-smoothing that ARG has due to fully-connected inference, and achieves better performances.</p><p>Initialized Interaction Field for DIN and its Variants To model the spatio-temporal interactions among people, an interaction field with appropriate size should be selected. We mainly provide with experiments on DIN and its two variants to choose an appropriate size: i) single interaction field that is initialized to cover a certain spatio-temporal domain, e.g., 3 ? 3; ii) stacking layers that separately cover spatial and temporal domain (ST factorised model), e.g., 1 ? 3 and 3 ? 1; iii) lite model that covers a certain spatiotemporal domain. The results for increasing interaction field sizes are shown in <ref type="table">Table 3</ref>. It indicates that i) Larger interaction field sizes will not result in a good performance. ii) Similarly, stacking layers to separately model spatial and temporal interactions also result in slightly worse results. We consider they are due to the over-smoothing problem <ref type="bibr" target="#b26">[27]</ref> caused by stacking layers or too dense connections, which brings about excessive similarity between person features. iii) ST factorised and lite model both distinctly reduce the cost by reducing the exponent of K and the value of D to D l , while both maintaining better results than previous methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparisons with the State-of-the-Art</head><p>In this subsection, we compare our models with previous state-of-the-art models. For a fair comparison, we only adopt RGB images as our model input and adopt a single backbone.</p><p>Performance on Volleyball dataset The result is shown in <ref type="table">Table 4</ref>. Generally, our methods can achieve impressive results on this dataset. For methods using ResNet-18, our method can surpass them by 1.7%. For methods us- ing VGG-16, our methods can surpass them by 2.2%. If considering the computational overhead of DR and DW, our models show more superiority. Our models generally cost less computational overhead and perform better than RNN-based models like <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b34">35]</ref>, due to a better representation from jointly modeling of spatial-temporal interaction. Our models outperform GNN-based methods like <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b14">15]</ref>, which ascribes to the dynamicity of the proposed modules. Method <ref type="bibr" target="#b42">[43]</ref>   achieve results on par with previous best methods, thus revealing the merits of introducing dynamicity.</p><p>Confusion Matrices The confusion matrices of VGG-16 models on VD and CAD are respectively shown in <ref type="figure" target="#fig_1">Figure 5(a)</ref> and (b). For VD, the modeling of dynamic spatial long-range interactions enables the model to distinguish left activities from right activities. Compared with confusion matrices from methods <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b45">46]</ref>, our methods performs well for pass and set activities. We ascribe it to the dynamic interaction modeling between spatio-temporal persons, because pass and set activities involve a person passing the ball and a person catching the ball. For CAD, compared with confusion matrices of methods <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b45">46]</ref>, our methods distinguish the waiting well. Previous methods mistake waiting for moving a lot because they fail to distinguish the temporal variations of people, which we tackle well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Qualitative Analysis</head><p>Group interaction graph First, we visualize the group interaction graph for one example in the upper right image of <ref type="figure" target="#fig_1">Figure 5</ref>(c), which sums all person-specific interaction graphs. It shows the people whom others interact more with to form the activity. If we sum along the temporal axis, we can find a key person (5th person, the red box in the group interaction graph) with the highest weight. In this example, it is the person performing setting action, which is significant in the left set group activity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Person interaction graph</head><p>We take a step further by visualizing the key person's interaction graph in the lower right image of <ref type="figure" target="#fig_1">Figure 5</ref>(c), which sums his interaction graphs in different temporal steps (T graphs in total). It indicates that our modules enable global-level interactions though we initialize the interaction field locally. As shown in the person interaction graph, the yellow boxes are two of key interactions with the key person. In this example, they might spike the ball set from the key person.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Works</head><p>In this paper, we propose the Dynamic Inference Network to address the problems of inference on a predefined graph and inference in a computationally expensive way. With limited computation overhead, our model can achieve competitive results on publicly available datasets. Experiments have shown that person-specific interaction context is effective in inferring group activities. More challenging tasks and efficient inference models are left for future exploration. Moreover, this paper focus on the reasoning of person features, while a decent dynamic model incorporating visual context <ref type="bibr" target="#b47">[48]</ref> are left for future exploration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Examples of right set and right pass group activity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 .</head><label>5</label><figDesc>(a) The confusion matrix for Volleyball dataset using VGG-16 as a backbone. (b) The confusion matrix for Collective Activity dataset using VGG-16 as a backbone. (c) Visualizations of a left set activity example. The upper left image is the starting image of the video clip. The upper right is the corresponding group interaction graph. The lower right is the interaction graph of the 5th person (key person, the red box in the group interaction graph). The lower left illustrates two of the 5th person's key interactions (yellow boxes in the 5th person's interaction graph).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Ablation study on the usage of DR and DW. Experiments are conducted on VD. The backbone is set to ResNet-18.</figDesc><table><row><cell>Model</cell><cell cols="2">MCA MPCA</cell></row><row><cell>Base model</cell><cell>87.8</cell><cell>88.4</cell></row><row><cell>DIN w/ DR</cell><cell>92.1</cell><cell>92.3</cell></row><row><cell>DIN w/ DW</cell><cell>92.0</cell><cell>92.5</cell></row><row><cell>DIN w/ DR+DW</cell><cell>93.1</cell><cell>93.3</cell></row><row><cell>DIN w/ DR+DW *</cell><cell>92.9</cell><cell>93.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Computational complexity analysis. Their backbones are set to ResNet-18. #Params and FLOPs for the backbone and the embedding layer are not included.</figDesc><table><row><cell cols="2">Reasoning Module #Params</cell><cell>FLOPs</cell><cell cols="2">MCA MPCA</cell></row><row><cell>PCTDM [45]</cell><cell>26.235M</cell><cell>6.298G</cell><cell>90.3</cell><cell>90.5</cell></row><row><cell>ARG [43]</cell><cell>25.182M</cell><cell>5.436G</cell><cell>91.1</cell><cell>91.4</cell></row><row><cell>AT [15]</cell><cell>5.245M</cell><cell>1.260G</cell><cell>90.0</cell><cell>90.2</cell></row><row><cell>HiGCIN[46]</cell><cell>1.051M</cell><cell>184.992G</cell><cell>91.4</cell><cell>92.0</cell></row><row><cell>SACRF [31]</cell><cell>29.422M</cell><cell>76.757G</cell><cell>90.7</cell><cell>91.0</cell></row><row><cell>EDP</cell><cell>3.146M</cell><cell>0.755G</cell><cell>91.6</cell><cell>91.6</cell></row><row><cell>DR</cell><cell>1.140M</cell><cell>0.272G</cell><cell>92.1</cell><cell>92.3</cell></row><row><cell>DW</cell><cell>1.222M</cell><cell>0.291G</cell><cell>92.0</cell><cell>92.5</cell></row><row><cell>DR+DW</cell><cell>1.305M</cell><cell>0.311G</cell><cell>93.1</cell><cell>93.3</cell></row><row><cell>Lite DR+DW</cell><cell>0.180M</cell><cell>0.042G</cell><cell>92.6</cell><cell>92.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .Table 5 .</head><label>45</label><figDesc>Comparisons with previous state-of-the-art methods on Volleyball dataset. We mark with '-' if results are not provided. Comparisons with previous state-of-the-art methods on Collective Activity datatset.</figDesc><table><row><cell>Method</cell><cell cols="2">Backbone</cell><cell cols="2">MCA MPCA</cell></row><row><cell>SBGAR [28]</cell><cell cols="2">Inception-v3</cell><cell>66.9</cell><cell>67.6</cell></row><row><cell>SSU [4]</cell><cell cols="2">Inception-v3</cell><cell>89.9</cell><cell>-</cell></row><row><cell>CERN-2 [35]</cell><cell cols="2">VGG-16</cell><cell>83.3</cell><cell>83.6</cell></row><row><cell>SPA+KD [40]</cell><cell cols="2">VGG-16</cell><cell>89.3</cell><cell>89.0</cell></row><row><cell>PCTDM [45]</cell><cell cols="2">ResNet-18</cell><cell>90.3</cell><cell>90.5</cell></row><row><cell>stagNet [32]</cell><cell cols="2">VGG-16</cell><cell>89.3</cell><cell>-</cell></row><row><cell>CRM [3]</cell><cell>I3D</cell><cell></cell><cell>92.1</cell><cell>-</cell></row><row><cell>ARG [43]</cell><cell cols="2">ResNet-18</cell><cell>91.1</cell><cell>91.4</cell></row><row><cell>PRL [21]</cell><cell cols="2">VGG-16</cell><cell>91.4</cell><cell>91.8</cell></row><row><cell>AT [15]</cell><cell cols="2">ResNet-18</cell><cell>90.0</cell><cell>90.2</cell></row><row><cell>SACRF [31]</cell><cell cols="2">ResNet-18</cell><cell>90.7</cell><cell>91.0</cell></row><row><cell>STBiP * [48]</cell><cell cols="2">Inception-v3</cell><cell>91.3</cell><cell>-</cell></row><row><cell>HiGCIN [46]</cell><cell cols="2">ResNet-18</cell><cell>91.4</cell><cell>92.0</cell></row><row><cell></cell><cell cols="2">VGG-16</cell><cell>93.6</cell><cell>93.8</cell></row><row><cell>Ours-DIN</cell><cell cols="2">ResNet-18</cell><cell>93.1</cell><cell>93.3</cell></row><row><cell></cell><cell cols="2">VGG-16</cell><cell>93.2</cell><cell>93.4</cell></row><row><cell>Ours-Lite DIN</cell><cell cols="2">ResNet-18</cell><cell>92.6</cell><cell>92.8</cell></row><row><cell>Method</cell><cell></cell><cell cols="3">Backbone MPCA</cell></row><row><cell cols="2">HDTM[22]</cell><cell cols="2">AlexNet</cell><cell>89.7</cell></row><row><cell cols="2">CERN-2[35]</cell><cell cols="2">VGG-16</cell><cell>88.3</cell></row><row><cell cols="2">Recurrent Modeling[42]</cell><cell cols="2">VGG-16</cell><cell>89.4</cell></row><row><cell cols="2">PCTDM[45]</cell><cell cols="2">AlexNet</cell><cell>92.2</cell></row><row><cell cols="2">stagNet[32]</cell><cell cols="2">VGG-16</cell><cell>89.1</cell></row><row><cell cols="2">SPA+KD[40]</cell><cell cols="2">VGG-16</cell><cell>92.5</cell></row><row><cell>ARG[43]</cell><cell></cell><cell cols="2">ResNet-18</cell><cell>92.3</cell></row><row><cell>PRL[21]</cell><cell></cell><cell cols="2">VGG-16</cell><cell>93.8</cell></row><row><cell cols="2">HiGCIN[46]</cell><cell cols="2">ResNet-18</cell><cell>93.0</cell></row><row><cell>Ours-DIN</cell><cell></cell><cell cols="2">VGG-16 ResNet-18</cell><cell>95.9 95.3</cell></row><row><cell cols="2">Ours-Lite DIN</cell><cell cols="2">VGG-16 ResNet-18</cell><cell>94.0 93.8</cell></row></table><note>* denotes results without visual context for fair comparison.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>even uses 16 graphs for reasoning but still trails our model. Performance on Collective Activity dataset The result is shown in Table 5. With our proposed modules, the model with a VGG-16 backbone outperforms other methods by 2.1% and a ResNet-18 backbone by 2.3%. Note that Lite DIN which costs little extra computation can already</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social lstm: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kratarth</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="961" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hirf: Hierarchical random field for collective activity recognition in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">Rabie</forename><surname>Amer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinisa</forename><surname>Todorovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="572" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convolutional relational machine for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sina</forename><forename type="middle">Mokhtarzadeh</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mina</forename><forename type="middle">Ghadimi</forename><surname>Atigh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmad</forename><surname>Nickabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7892" to="7901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Social scene understanding: End-to-end multi-person action localization and collective activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timur</forename><surname>Bagautdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Fleuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4315" to="4324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Interaction networks for learning about objects, relations and physics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Neural Information Processing Systems</title>
		<meeting>the 30th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4509" to="4517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A compositional object-based approach to learning physical dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.00341</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Knowledge-embedded routing network for scene graph generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianshui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riquan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6163" to="6171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A unified framework for multi-target tracking and collective activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="215" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">What are they doing?: Collective activity classification using spatio-temporal relationship among people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khuram</forename><surname>Shahid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1282" to="1289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning context for collective activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khuram</forename><surname>Shahid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3273" to="3280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="764" to="773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navneet</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE computer society conference on computer vision and pattern recognition (CVPR&apos;05)</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dual attention network for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijie</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3146" to="3154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Drg: Dual relation graph for human-object interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="696" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Actor-transformers for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirill</forename><surname>Gavrilyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Sanford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrsan</forename><surname>Javan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Cees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="839" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Piotr Doll?r, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Vain: Attentional multi-agent predictive modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yedid</forename><surname>Hoshen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.06122</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Progressive relation learning for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guyue</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="980" to="989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A hierarchical deep temporal model for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mostafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Muralidharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1971" to="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Spatial transformer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2017" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Social roles in hierarchical models for human activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1354" to="1361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Discriminative latent models for recognizing contextual group activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Robinovitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1549" to="1562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evolvegraph: Multi-agent trajectory prediction with dynamic relational reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiho</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems (NeurIPS)</title>
		<meeting>the Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deeper insights into graph convolutional networks for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qimai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao-Ming</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sbgar: Semantics based group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mooi Choo</forename><surname>Chuah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2876" to="2885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Transferable interactiveness knowledge for human-object interaction detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong-Lu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao-Shu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3585" to="3594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Evolvegcn: Evolving graph convolutional networks for dynamic graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldo</forename><surname>Pareja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giacomo</forename><surname>Domeniconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toyotaro</forename><surname>Suzumura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Kanezashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Schardl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Leiserson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="5363" to="5370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Empowering relational network by selfattention augmented conditional random fields for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adhi</forename><surname>Rizard Renanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yie</forename><surname>Pramono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen Hsien</forename><surname>Tarng Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="71" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">stagnet: An attentive semantic rnn for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengshi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="101" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning human-object interactions by graph parsing neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxiong</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbing</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="401" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noriaki</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1349" to="1358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cern: confidence-energy recurrent network for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianmin</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinisa</forename><surname>Todorovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5523" to="5531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Hierarchical long short-term concurrent memory for human interaction recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangbo</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guojun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Stochastic prediction of multiagent interactions from partial observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Per</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09641</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Coherence constrained graph lstm for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangbo</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Mining semantics-preserving attention for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM international conference on Multimedia</title>
		<meeting>the 26th ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1283" to="1291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Social attention: Modeling attention in human crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Vemula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Muelling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE international Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4601" to="4607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Recurrent modeling of interaction context for collective activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3048" to="3056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning actor relation graphs for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gangshan</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9964" to="9974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Scene graph generation by iterative message passing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danfei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5410" to="5419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Participation-contributed temporal dynamic model for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangbo</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zechao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM international conference on Multimedia</title>
		<meeting>the 26th ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1292" to="1300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Higcin: Hierarchical graph-based cross inference network for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangbo</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Social adaptive module for weakly-supervised group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangbo</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="208" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning visual context for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangjie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Ni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="3261" to="3269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Neural motifs: Scene graph parsing with global context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5831" to="5840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Dynamic graph message passing networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3726" to="3735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deformable convnets v2: More deformable, better results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xizhou</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9308" to="9316" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
