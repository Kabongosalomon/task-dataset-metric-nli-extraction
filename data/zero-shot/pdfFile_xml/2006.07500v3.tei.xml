<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Domain Generalization using Causal Matching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Divyat</forename><surname>Mahajan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shruti</forename><surname>Tople</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Sharma</surname></persName>
						</author>
						<title level="a" type="main">Domain Generalization using Causal Matching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T14:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the domain generalization literature, a common objective is to learn representations independent of the domain after conditioning on the class label. We show that this objective is not sufficient: there exist counter-examples where a model fails to generalize to unseen domains even after satisfying class-conditional domain invariance. We formalize this observation through a structural causal model and show the importance of modeling within-class variations for generalization. Specifically, classes contain objects that characterize specific causal features, and domains can be interpreted as interventions on these objects that change non-causal features. We highlight an alternative condition: inputs across domains should have the same representation if they are derived from the same object. Based on this objective, we propose matching-based algorithms when base objects are observed (e.g., through data augmentation) and approximate the objective when objects are not observed (MatchDG). Our simple matching-based algorithms are competitive to prior work on out-of-domain accuracy for rotated MNIST, Fashion-MNIST, PACS, and Chest-Xray datasets. Our method MatchDG also recovers ground-truth object matches: on MNIST and Fashion-MNIST, top-10 matches from MatchDG have over 50% overlap with ground-truth matches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Domain generalization is the task of learning a machine learning model that can generalize to unseen data distributions, after training on more than one data distributions. For example, a model trained on hospitals in one region may be deployed to another, or an image classifier may be deployed on slightly rotated images. Typically, it is assumed that Proceedings of the 38 th International Conference on Machine Learning, PMLR 139, 2021. Copyright 2021 by the author(s). the different domains share some "stable" features whose relationship with the output is invariant across domains <ref type="bibr" target="#b34">(Piratla et al., 2020)</ref> and the goal is to learn those features. A popular class of methods aim to learn representations that are independent of domain conditional on class <ref type="bibr">(Li et al., 2018c;</ref><ref type="bibr" target="#b16">Ghifary et al., 2016;</ref><ref type="bibr">Hu et al., 2019)</ref>, based on evidence of their superiority <ref type="bibr" target="#b38">(Zhao et al., 2019)</ref> to methods that learn representations that are marginally independent of domain <ref type="bibr" target="#b30">(Muandet et al., 2013;</ref><ref type="bibr" target="#b14">Ganin et al., 2016)</ref>.</p><p>In this work, we show that the class-conditional domaininvariant objective for representations is insufficient. We provide counter-examples where a feature representation satisfies the objective but still fails to generalize to new domains, both theoretically and empirically. Specifically, when the distribution of the stable features to be learnt varies across domains, class-conditional objective is insufficient to learn the stable features (they are optimal only when the distribution of stable features is the same across domains). Differing distributions of stable features within the same class label is common in real-world datasets, e.g., in digit recognition, the stable feature shape may differ based on people's handwriting, or medical images may differ based on variation in body characteristics across people. Our investigation reveals the importance of considering withinclass variation in the stable features.</p><p>To derive a better objective for domain generalization, we represent the within-class variation in stable features using a structural causal model, building on prior work (Heinze-Deml &amp; Meinshausen, 2019) from single-domain generalization. Specifically, we construct a model for the data generation process that assumes each input is constructed from a mix of stable (causal) and domain-dependent (non-causal) features, and only the stable features cause the output. We consider domain as a special intervention that changes the non-causal features of an input, and posit that an ideal classifier should be based only on the causal features. Using d-separation, we show that the correct objective is to build a representation that is invariant conditional on each object, where an object is defined as a set of inputs that share the same causal features (e.g., photos of the same person from different viewpoints or augmentations of an image in different rotations, color or background). When the object variable is observed (e.g., in self-collected data or by dataset augmentation), we propose a perfect-match regularizer for arXiv:2006.07500v3 <ref type="bibr">[cs.</ref>LG] 29 Jun 2021 domain generalization that minimizes the distance between representations of the same object across domains.</p><p>In practice, however, the underlying objects are not always known. We therefore propose an approximation that aims to learn which inputs share the same object, under the assumption that inputs from the same class have more similar causal features than those from different classes. Our algorithm, MatchDG is an iterative algorithm that starts with randomly matched inputs from the same class and builds a representation using contrastive learning such that inputs sharing the same causal features are closer to one another. While past work has used contrastive loss to regularize the empirical risk minimization (ERM) objective , we demonstrate the importance of a two-phase method that first learns a representation independent of the ERM loss, so that classification loss does not interfere with the learning of stable features. In datasets with data augmentations, we extend MatchDG to also use the perfect object matches obtained from pairs of original and augmented images (MDGHybrid).</p><p>We evaluate our matching-based methods on rotated MNIST and Fashion-MNIST, PACS and Chest X-ray datasets. On all datasets, the simple methods MatchDG and MDGHybrid are competitive to state-of-the-art methods for out-ofdomain accuracy. On the rotated MNIST and Fashion-MNIST datasets where the ground-truth objects are known, MatchDG learns to makes the representation more similar to their ground-truth matches (about 50% overlap for top-10 matches), even though the method does not have access to them. Our results with simple matching methods show the importance of enforcing the correct invariance condition.</p><p>Contributions. To summarize, our contributions include: 1). An object-invariant condition for domain generalization that highlights a key limitation of previous approaches, 2). When object information is not available, a two-phase, iterative algorithm to approximate object-based matches. Also, the code repository can be accessed at: https:// github.com/microsoft/robustdg</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Learning common representation. To learn a generalizable classifier, several methods enforce the learnt representation ?(x) to be independent of domain marginally or conditional on class label, using divergence measures such as maximum mean discrepancy <ref type="bibr" target="#b30">(Muandet et al., 2013;</ref><ref type="bibr">Li et al., 2018b;</ref>, adversarial training with a domain discriminator <ref type="bibr" target="#b14">(Ganin et al., 2016;</ref><ref type="bibr" target="#b38">Li et al., 2018d;</ref><ref type="bibr" target="#b3">Albuquerque et al., 2020a)</ref>, discriminant analysis <ref type="bibr" target="#b16">(Ghifary et al., 2016;</ref><ref type="bibr">Hu et al., 2019)</ref>, and other techniques .</p><p>Among them, several works <ref type="bibr" target="#b38">(Zhao et al., 2019;</ref><ref type="bibr">Johansson et al., 2019;</ref><ref type="bibr" target="#b2">Akuzawa et al., 2019)</ref> show that the class-conditional methods <ref type="bibr">(Li et al., 2018c;</ref><ref type="bibr" target="#b16">Ghifary et al., 2016;</ref><ref type="bibr">Hu et al., 2019)</ref> are better than those that enforce marginal domain-invariance of features <ref type="bibr" target="#b30">(Muandet et al., 2013;</ref><ref type="bibr" target="#b14">Ganin et al., 2016;</ref><ref type="bibr">Li et al., 2018b;</ref><ref type="bibr" target="#b3">Albuquerque et al., 2020a)</ref>, whenever there is a varying distribution of class labels across domains. We show that the class-conditional invariant is also not sufficient for generalizing to unseen domains.</p><p>Causality and domain generalization. Past work has shown the connection between causality and generalizable predictors <ref type="bibr" target="#b33">(Peters et al., 2016;</ref><ref type="bibr" target="#b10">Christiansen et al., 2020)</ref>. There is work on use of causal reasoning for domain adaptation <ref type="bibr" target="#b17">(Gong et al., 2016;</ref><ref type="bibr" target="#b21">Heinze-Deml &amp; Meinshausen, 2019;</ref><ref type="bibr" target="#b26">Magliacane et al., 2018;</ref><ref type="bibr" target="#b36">Rojas-Carulla et al., 2018)</ref> that assumes Y ? X direction and other work <ref type="bibr" target="#b33">Peters et al., 2016)</ref> on connecting causality that assumes X ? Y . Our SCM model unites these streams by introducing Y true and labelled Y and develop an invariance condition for domain generalization that is valid under both interpretations. Perhaps the closest to our work is by <ref type="bibr" target="#b21">(Heinze-Deml &amp; Meinshausen, 2019)</ref> who use the object concept in single-domain datasets for better generalization. We extend their SCM to the multi-domain setting and use it to show the inconsistency of prior methods. In addition, while (Heinze-Deml &amp; Meinshausen, 2019) assume objects are always observed, we also provide an algorithm for the case when objects are unobserved.</p><p>Matching and Contrastive Loss. Regularizers based on matching have been proposed for domain generalization. <ref type="bibr" target="#b29">(Motiian et al., 2017)</ref> proposed matching representations of inputs from the same class.  used a contrastive (triplet) loss to regularize the ERM objective. In contrast to regularizing based on contrastive loss, our algorithm MatchDG proceeds in two phases and learns a representation independent of the ERM objective. Such an iterative 2-phase algorithm has empirical benefits, as we will show in Suppl. D.4. Additionally, we propose an ideal object-based matching algorithm when objects are observed.</p><p>Other work. Others approaches to domain generalization include meta-learning <ref type="bibr" target="#b38">(Li et al., 2018a;</ref><ref type="bibr" target="#b7">Balaji et al., 2018)</ref>, dataset augmentation <ref type="bibr">(Volpi et al., 2018;</ref><ref type="bibr">Shankar et al., 2018)</ref>, parameter decomposition <ref type="bibr" target="#b34">(Piratla et al., 2020;</ref><ref type="bibr" target="#b38">Li et al., 2017)</ref>, and enforcing domain-invariance of the optimal P (Y |?(x)) <ref type="bibr" target="#b1">Ahuja et al., 2020)</ref>. We empirically compare our algorithm to some of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Insufficiency of class-conditional invariance</head><p>Consider a classification task where the learning algorithm has access to i.i.d. data from m domains, The CDM predictor is domain-invariant given the class label but does not generalize to the target domain; b) Colors denote the two ground-truth class labels. For class prediction, the linear feature exhibits varying level of noise across domains. The stable slab feature also has noise but it is invariant across domains.</p><formula xml:id="formula_0">{(d i , x i , y i )} n i=1 ? (D m , X<label>,</label></formula><p>P m (D, X, Y ). The domain generalization task is to learn a single classifier that generalizes well to unseen domains d ? D m and to new data from the same domains <ref type="bibr">(Shankar et al., 2018)</ref>. The optimum classifier can be written as:</p><formula xml:id="formula_1">f * = arg min f ?F E (d,x,y)?P [l(y (d) , f (x (d) ))], where (d, x, y) ? P over (D, X , Y).</formula><p>As mentioned above, a popular line of work enforces that the learnt representation ?(x) be independent of domain conditional on the class <ref type="bibr">(Li et al., 2018c;</ref><ref type="bibr" target="#b16">Ghifary et al., 2016;</ref><ref type="bibr">Hu et al., 2019)</ref>, ?(x) ? ? D|Y . Below we present two counter-examples showing that the class-conditional objective is not sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">A simple counter-example</head><p>We construct an example where ?(x) ? ? D|Y , but still the classifier does not generalize to new domains. Consider a two dimensional problem where x 1 = x c + ? d ; x 2 = ? d where x c and ? d are unobserved variables, and ? d varies with domain ( <ref type="figure" target="#fig_0">Figure 1(a)</ref>). The true function depends only on the stable feature x c , y = f (x c ) = I(x c ? 0). Suppose there are two training domains with ? 1 = 1 for domain 1 and ? 2 = 2 for domain 2, and the test domain has ? 3 = 0 (see <ref type="figure" target="#fig_0">Figure 1</ref>(a)). Suppose further that the conditional distribution of X C given Y is a uniform distribution that changes across domains: for domain 1, X c |Y = 1 ? U(1, 3); X c |Y = 0 ? U(?2, 0); and for domain 2, X c |Y = 1 ? U(0, 2); X c |Y = 0 ? U(?3, ?1). Note that the distributions are picked such that ?(x 1 , x 2 ) = x 1 satisfies the conditional distribution invariant, ?(x) ? ? D|Y . The optimal ERM classifier based on this representation, (I(x 1 ? 1.5) has 100% train accuracy on both domains. But for the test domain with ? d = 0; X c |Y = 1 ? U(0, 2); X c |Y = 0 ? U (?2, 0), the classifier fails to generalize. It obtains 62.5% test accuracy (and 25% accuracy on the positive class), even though its representation satisfies class-conditional domain invariance. In comparison, the ideal representation is x 1 ? x 2 which attains 100% train accuracy and 100% test domain accuracy, and does not satisfy the class-conditional invariant.</p><p>The above counter-example is due to the changing distribution of x c across domains. If P (X c |Y ) stays the same across domains, then class-conditional methods would not incorrectly pick x 1 as the representation. Following <ref type="bibr" target="#b2">(Akuzawa et al., 2019)</ref>, we claim the following (proof in Suppl. B.3). Proposition 1. Under the domain generalization setup as above, if P (X c |Y ) remains the same across domains where x c is the stable feature, then the class-conditional domaininvariant objective for learning representations yields a generalizable classifier such that the learnt representation ?(x) is independent of the domain given x c . Specifically, the entropy H(d|x c ) = H(d|?, x c ).</p><p>However, if P (X C |Y ) changes across domains, then we cannot guarantee the same: H(d|x c ) and H(d|?, x c ) may not be equal. For building generalizable classifiers in such cases, this example shows that we need an additional constraint on ?, H(d|x c ) = H(d|?, x c ); i.e. domain and representation should be independent conditioned on x c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">An empirical study of class-conditional methods</head><p>As a more realistic example, consider the slab dataset introduced for detecting simplicity bias in neural networks <ref type="bibr">(Shah et al., 2020)</ref> that contains a feature with spurious correlation. It comprises of two features and a binary label; (x 1 ) has a linear relationship with the label and the other feature (x 2 ) has a piece-wise linear relationship with the label which is a stable relationship. The relationship of the linear feature with the label changes with domains (A.1); we do so by adding noise with probability = 0 for domain 1 and = 0.1 for domain 2. On the third (test) domain, we add noise with probability 1 (see <ref type="figure" target="#fig_0">Figure 1</ref>(b)). We expect that methods that rely on the spurious feature x 1 would not be able to perform well on the out-of-domain data.</p><p>The results in <ref type="table">Table 1</ref> (implementation details in Appendix A.1) show that ERM is unable to learn the slab feature, as evident by poor generalization to the target domain, de-spite very good performance on the source domains. We also show that methods based on learning invariant representations by unconditional (DANN, MMD, CORAL) and conditional distribution matching (CDANN, C-MMD, C-CORAL), and matching same-class inputs (Random-Match) <ref type="bibr" target="#b29">(Motiian et al., 2017)</ref> fail to learn the stable slab feature. Note that Proposition 1 suggested the failure of conditional distribution matching (CDM) algorithms when the distribution of stable feature (slab feature) is different across the source domains. However, the slab dataset has similar distribution of stable feature (slabs) across the source domains, yet the CDM algorithms fail to generalize to the target domain. It can be explained by considering the spurious linear feature, which can also satisfy the CDM constraint by "shifting" the y-conditional distributions along the linear feature. We conjecture that the model may first learn the linear feature due to its simplicity <ref type="bibr">(Shah et al., 2020)</ref>, and then retain the spurious linear feature upon further optimization since it satisfies the CDM constraint. This shows that the CDM methods can empirically fail even when there is an equal distribution of stable features across domains.</p><p>How can we ensure that a model learns the stable, generalizable feature x 2 ? We turn to our example above, where the required invariant was that the representation ?(x) should be independent of domain given the stable feature. We apply this intuition and construct a model that enforces that the learnt representation be independent of domain given x 2 . We do so by minimizing the 2 -norm of the representations for data points from different domains that share the same slab value (details of the PerfectMatch method in Section 4.3). The results improve substantially: out-of-domain accuracy is now 78%.</p><p>In the next section, we formalize the intuition of conditioning on stable features x c using a causal graph, and introduce the concept of objects that act as proxies of stable features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">A Causal View of Domain Generalization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data-generating process</head><p>Figure 2(a) shows a structural causal model (SCM) that describes the data-generating process for the domain generalization task. For intuition, consider a task of classifying the type of item or screening an image for a medical condition. Due to human variability or by design (using data augmentation), the data generation process yields variety of images for each class, sometimes multiple views for the same object. Here each view can be considered as a different domain D, the label for item type or medical condition as the class Y , and the image pixels as the features X. Photos of the same item or the same person correspond to a common object variable, denoted by O. To create an image, the data-generating process first samples an object and view <ref type="table">Table 1</ref>. Slab Dataset: Source domains with noisy linear component with probability 0.0 and 0.1, target domain with noise 1.0. Mean and standard deviation over 10 different seed values for each method. The results for DANN <ref type="bibr" target="#b14">(Ganin et al., 2016)</ref>, <ref type="bibr">CDANN (Li et al., 2018d)</ref>, <ref type="bibr">MMD, C-MMD (Li et al., 2018b)</ref>, CORAL, C-CORAL <ref type="bibr">(Sun &amp; Saenko, 2016)</ref> were computed by using their implementations in DomainBed <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Source <ref type="formula" target="#formula_3">1</ref>    (domain) that may be correlated to each other (shown with dashed arrows). The pixels in the photo are caused by both the object and the view, as shown by the two incoming arrows to X. The object also corresponds to high-level causal features X C that are common to any image of the same object, which in turn are used by humans to label the class Y . We call X C as causal features because they directly cause the class Y .</p><p>The above example is typical of a domain generalization problem; a general SCM is shown in <ref type="figure" target="#fig_2">Figure 2</ref>(b), similar to the graph in <ref type="bibr" target="#b21">(Heinze-Deml &amp; Meinshausen, 2019)</ref>. In general, the underlying object for each input x may not be observed. Analogous to the object-dependent (causal) features X C , we introduce a node for domain-dependent high-level features of the object X A . Changing the domain can be seen as an intervention: for each observed x where d = d , such that all correspond to the same object (and thus share the same X C ). For completeness, we also show the true unobserved label of the object which led to its generation as Y true (additional motivation for the causal graph is in Suppl. B.1). Like the object O, Y may be correlated with the domain D. Extending the model in <ref type="bibr" target="#b21">(Heinze-Deml &amp; Meinshausen, 2019)</ref>, we allow that objects can be correlated with the domain conditioned on Y true . As we shall see, considering the relationship of the object node becomes the key piece for developing the invariant condition. The SCM corresponds to the following nonparametric equations.</p><formula xml:id="formula_2">o := go(ytrue, o, od ) xc = gxc(o) xa := gxa(d, o, xa) x := gx(xc, xa, x)y := h(xc, y )</formula><p>where g o , g xc , g xa , g x and h are general non-parametric functions. The error od is correlated with domain d whereas o , xa , x and y are mutually independent error terms that are independent of all other variables. Thus, noise in the class label is independent of domain. Since x c is common to all inputs of the same object, g xc is a deterministic function of o. In addition, the SCM provides conditionalindependence conditions that all data distributions P must satisfy, through the concept of d-separation (Suppl. B.2) and the perfect map assumption <ref type="bibr" target="#b32">(Pearl, 2009</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Identifying the invariance condition</head><p>Since X C is unobserved, this implies that we need to learn it through a representation function ? : X ? C. Together, h(?(x)) leads to the desired classifer f : X ? Y.</p><p>Negative result on identification. Identification of causal features is a non-trivial problem <ref type="bibr" target="#b26">(Magliacane et al., 2018)</ref>. We first show that x C is unidentifiable given observed data P (X, Y, D, O) over multiple domains. Given the same probability distribution P (X, Y, D, O), multiple values of X C are possible. Substituting for o in the SCM equations, we obtain, </p><formula xml:id="formula_4">y = h(g xc (o), y ); x = g x (g xc (o), g xa (d, o, xa ), x</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">A "perfect-match" invariant</head><p>In the absence of identifiability, we proceed to find an invariant that can characterize X c . By the d-separation criterion, we see that X C satisfies two conditions: 1)</p><formula xml:id="formula_5">X C ? ? D|O, 2) X C ? ? O;</formula><p>where O refers to the object variable and D refers to a domain. The first is an invariance condition: X C does not change with different domains for the same object.</p><p>To enforce this, we stipulate that the average pairwise distance between ?(x) for inputs across domains for the same object is 0,</p><formula xml:id="formula_6">?(j,k)=1;d =d dist(?(x (d) j ), ?(x (d ) k )) = 0.</formula><p>Here ? : X ? X ? {0, 1} is a matching function that is 1 for pairs of inputs across domains corresponding to the same object, and 0 otherwise. However, just the above invariance will not work: we need the representation to be informative of the object O (otherwise even a constant ? minimizes the above loss). Therefore, the second condition stipulates that X C should be informative of the object, and hence about Y . We add the standard classification loss, leading to constrained optimization,</p><formula xml:id="formula_7">fperfectmatch = arg min h,? m d=1 L d (h(?(X)), Y ) s.t. ?(j,k)=1;d =d dist(?(x (d) j ), ?(x (d ) k )) = 0 (2) where L d (h(?(X), Y )) = n d i=1 l(h(?(x (d) i ), y (d) i ).</formula><p>Here f represents the composition h ? ?. E.g., a neural network with ?(x) as its rth layer, and h being the rest of the layers.</p><p>Note that there can be multiple ?(x) (e.g., linear transformations) that are equally good for the prediction task. Since x c is unidentifiable, we focus on the set of stable representations that are d-separated from D given O. Being independent of domain given the object, they cannot have any association with X a , the high-level features that directly depend on domain ( <ref type="figure" target="#fig_2">Figure 2b</ref>). The proof for the next theorem is in Suppl. B.5.</p><p>Theorem 1. For a finite number of domains m, as the number of examples in each domain n d ? ?, 1. The set of representations that satisfy the condition</p><formula xml:id="formula_8">?(j,k)=1;d =d dist(?(x (d) j ), ?(x (d )</formula><p>k )) = 0 contains the optimal ?(x) = X C that minimizes the domain generalization loss in (1). 2. Assuming that P (X a |O, D) &lt; 1 for every high-level feature X a that is directly caused by domain, and for P-admissible loss functions <ref type="bibr" target="#b28">(Miller et al., 1993</ref>) whose minimization is conditional expectation (e.g., 2 or crossentropy), a loss-minimizing classifier for the following loss is the true function f * , for some value of ?.</p><formula xml:id="formula_9">fperfectmatch = arg min h,? m d=1 L d (h(?(X)), Y )+ ? ?(j,k)=1;d =d dist(?(x (d) j ), ?(x (d ) k )) (3)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Past work: Learning common representation</head><p>Using the SCM, we now compare the proposed invariance condition to domain-invariant and class-conditional domain-invariant objectives. d-separation results show that both these objectives are incorrect: in particular, the classconditional objective ?(x) ? ? D|Y is not satisfied by X C , (X C ? ? D|Y true ) due to a path through O. Even with infinite data across domains, they will not learn the true X C . The proof is in Suppl. B.6.</p><p>Proposition 3. The conditions enforced by domaininvariant (?(x) ? ? D) or class-conditional domaininvariant (?(x) ? ? D|Y ) methods are not satisfied by the causal representation X C . Thus, without additional assumptions, the set of representations that satisfy any of these conditions does not contain X C , even as n ? ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">MatchDG: Matching without objects</head><p>When object information is available, Eq. (3) provides a loss objective to build a classifer using causal features. However, object information is not always available, and in many datasets there may not be a perfect "counterfactual" match based on same object across domains. Therefore, we propose a two-phase, iterative contrastive learning method to approximate object matches.</p><p>The object-invariant condition from Section 4.2 can be interpreted as matching pairs of inputs from different domains that share the same X C . To approximate it, our goal is to learn a matching ? : X ?X ? {0, 1} such that pairs having ?(x, x ) = 1 have low difference in x c and x c . We make the following assumption.</p><formula xml:id="formula_10">Assumption 1. Let (x (d) i , y), (x (d )</formula><p>j , y) be any two points that belong to the same class, and let (x (d) k y ) be any other point that has a different class label. Then the distance in causal features between x i and x j is smaller than that between x i and x k or x j and x k : dist(x</p><formula xml:id="formula_11">(d) c,i , x (d ) c,j ) ? dist(x (d) c,i , x (d ) c,k ) and dist(x (d) c,j , x (d ) c,i ) ? dist(x (d) c,j , x (d ) c,k ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Two-phase method with iterative matches</head><p>To learn a matching function ?, we use unsupervised contrastive learning from <ref type="bibr" target="#b9">(Chen et al., 2020;</ref><ref type="bibr" target="#b20">He et al., 2019)</ref> and adapt it to construct an iterative MatchDG algorithm that updates the both the representation and matches after each epoch. The algorithm relies on the property that two inputs from the same class have more similar causal features than inputs from different classes.</p><p>Contrastive Loss. To find matches, we optimize a contrastive representation learning loss that minimizes distance between same-class inputs from different domains in comparison to inputs from different classes across domains. Adapting the contrastive loss for a single domain <ref type="bibr" target="#b9">(Chen et al., 2020)</ref>, we consider positive matches as two inputs with the same class but different domains, and negative matches as pairs with different classes. For every positive match pair (x j , x k ), we propose a loss where ? is </p><formula xml:id="formula_12">, b) = ?(x a ) T ?(x b )/ ?(x a ) ?(x b ) is the cosine similarity. l(xj, x k ) = ? log e sim(j,k)/? e sim(j,k)/? + B i=0,y i =y j e sim(j,i)/? (4)</formula><p>Iterative matching. Our key insight is to update the positive matches during training. We start training with a random set of positive matches based on the classes, but after every t epochs, we update the positive matches based on the nearest same-class pairs in representation space and iterate until convergence. Hence for each anchor point, starting with an initial set of positive matches, in each epoch a representation is learnt using contrastive learning; after which the positive matches are themselves updated based on the closest same-class data points across domains in the representation. As a result, the method differentiates between data points of the same class instead of treating all of them as a single unit. With iterative updates to the positive matches, the aim is to account for intra-class variance across domains and match data points across domains that are more likely to share the same base object. In Suppl. D.6, we compare the gains due to the proposed iterative matching versus standard contrastive training.</p><p>Obtaining the final representation completes Phase I of the algorithm. In Phase II, we use this representation to compute a new match function based on closest same-class pairs and apply Eq.</p><p>(3) to obtain a classifier regularized on those matches.</p><p>The importance of using two phases. We implement MatchDG as a 2-phase method, unlike previous methods <ref type="bibr" target="#b29">(Motiian et al., 2017;</ref><ref type="bibr" target="#b12">Dou et al., 2019)</ref> that employed class-based contrastive loss as a regularizer with ERM. This is to avoid the classification loss interfering with the goal of learning an invariant representation across domains (e.g., in datasets where one of the domains has many more samples than others). Therefore, we first learn the match function using only the contrastive loss. Our results in Suppl. D.4 show that the two-phase method provides better overlap with ground-truth perfect matches than optimizing classification and matching simultaneously.</p><p>To implement MatchDG we build a p ? q data matrix containing q ? 1 positive matches for each input and then sample mini-batches from this matrix. The last layer of the contrastive loss network is considered as the learnt representation (see Algorithm 1; details are in Suppl. C.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">MDG Hybrid</head><p>While MatchDG assumes no information about objects, it can be easily augmented to incorporate information about known objects. For example, in computer vision, a standard practice is to augment data by performing rotations, horizontal flips, color jitter, etc. These self-augmentations provide us with access to known objects, which can included as perfect-matches in MatchDG Phase-II by adding another regularizer to the loss from Eq 3. We name this method MDGHybrid and evaluate it alongside MatchDG for datasets where we can perform self augmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Evaluation</head><p>We evaluate out-of-domain accuracy of MatchDG on two simulated benchmarks by <ref type="bibr" target="#b34">Piratla et al. (2020)</ref>, Rotated MNIST and Fashion-MNIST, on PACS dataset <ref type="bibr" target="#b38">(Li et al., 2017)</ref>, and on a novel Chest X-rays dataset. In addition, using the simulated datasets, we inspect the quality of matches learnt by MatchDG by comparing them to groundtruth object-based matches. For PACS and Chest X-rays, we also implement MDGHybrid that uses augmentations commonly done while training neural networks. We compare to 1) ERM: Standard empirical risk minimization, 2) ERM-RandMatch that implements the loss from Eq.</p><p>(3) but with randomly selected matches from the same class <ref type="bibr" target="#b29">(Motiian et al., 2017)</ref>, 3) other state-of-the-art methods for each dataset. For all matching-based methods, we use the cross-entropy loss for L d and 2 distance for dist in Eq.</p><p>(3). Details of implementation and the datasets are in Suppl. C.1. All the numbers are averaged over 3 runs with standard deviation in brackets.</p><p>Rotated MNIST &amp; Fashion-MNIST. The datasets contain rotations of grayscale MNIST handwritten digits and fashion article images from 0 ? to 90 ? with an interval of 15 ? (Ghifary et al., 2015), where each rotation angle represents a domain and the task is to predict the class label. Since different domains' images are generated from the same base image (object), there exist perfect matches across domains. Following CSD, we report accuracy on 0 ? and 90 ? together as the test domain and the rest as the train domains; since these test angles, being extreme, are the hardest to generalize to (standard setting results are in Suppl. D.1, D.2).</p><p>PACS. This dataset contains total 9991 images from four domains: Photos (P), Art painting (A), Cartoon (C) and Sketch (S). The task is to classify objects over 7 classes. Following , we train 4 models with each domain as the target using Resnet-18, Resnet-50 and Alexnet.</p><p>Chest X-rays. We introduce a harder real-world dataset based on Chest X-ray images from three different sources: NIH (Wang et al., 2017), ChexPert (Irvin et al., 2019) and RSNA (rsn, 2018). The task is to detect whether the image corresponds to a patient with Pneumonia (1) or not (0). To create spurious correlation, all images of class 0 in the training domains are translated vertically downwards; while no such translation is done for the test domain.</p><p>Model Selection. While using a validation set from the test domain may improve classification accuracy, it goes against the problem motivation of generalization to unseen domains. Hence, we use only data from source domains to construct a validation set (except when explicitly mentioned in <ref type="table">Table 4</ref>, to compare to past methods that use test domain validation). The last column shows the accuracy for an oracle method, ERM-PerfMatch that has access to ground-truth perfect matches across domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Rotated MNIST and Fashion MNIST</head><p>MatchDG's accuracy lies between ERM-RandMatch and ERM-PerfMatch, indicating the benefit of learning a matching function. As the number of training domains decrease, the gap between MatchDG and baselines is highlighted: with 3 source domains for rotFashionMNIST, MatchDG achieves accuracy of 43.8% whereas the next best method ERM-RandMatch achieves 38.4%.</p><p>We also evaluate on a simpler 2-layer LeNet <ref type="bibr" target="#b29">(Motiian et al., 2017)</ref>, and the model from <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref> to compare MatchDG to prior works (Ilse et al., 2020; <ref type="bibr" target="#b14">Ganin et al., 2016;</ref><ref type="bibr">Shankar et al., 2018;</ref><ref type="bibr" target="#b18">Goodfellow et al., 2014)</ref>; the results are in Suppl. D.1, D.2.</p><p>Why MatchDG works? We compare the matches returned by MatchDG Phase I (on Resnet-18 network) to the groundtruth perfect matches and find that it has significantly higher overlap than matching based on ERM loss <ref type="table">(Table 3)</ref>. We report three metrics on the representation learnt: percentage of MatchDG matches that are perfect matches, %-age of inputs for which the perfect match is within the top-10 ranked MatchDG matches, and mean rank of perfect matches measured by distance over the MatchDG representation.</p><p>On all three metrics, MatchDG finds a representation whose MatchDG vs. IRM on zero training error. Since neural networks often achieve zero training error, we also evaluate the effectiveness of the MatchDG regularization under this regime. <ref type="figure" target="#fig_7">Fig. 3</ref> shows the matching loss term as training proceeds for rotMNIST and rotFashionMNIST. Even  after the model achieves zero training error, we see that plain ERM objective is unable to minimize the matching loss (and thus MatchDG penalty is needed). This is because MatchDG regularization depends on comparing the (last layer) representations, and zero training error does not mean that the representations within each class are the same. In contrast, regularizations that are based on comparing loss between training domains such as the IRM penalty can be satisfied by plain ERM as the training error goes to zero ( <ref type="figure" target="#fig_7">Fig. 3(b)</ref>); similar to </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">PACS dataset</head><p>ResNet-18. On the PACS dataset with ResNet-18 architecture <ref type="table">(Table 4)</ref>, our methods are competitive to state-of-the- ResNet-50. We implement MatchDG on Resnet50 model <ref type="table">(Table 5</ref>) used by the ERM in DomainBed. Adding MatchDG loss regularization improves the accuracy of DomainBed, from 85.7 to 87.5 with MDGHybrid. Also, MDGHybrid performs better than the prior approaches us- ing Resnet50 architecture, except RSC <ref type="bibr" target="#b24">(Huang et al., 2020)</ref>, whose results (87.83) are close to ours (87.52). Note that we chose a subset of the best-performing baselines for <ref type="table">Table 4</ref>, 5; an extensive comparison with other works is in Suppl. E.1. Suppl. E.2 gives the results using AlexNet network, and a t-SNE plot ( <ref type="figure" target="#fig_13">Figure 5</ref>) to show the quality of representation learnt by MatchDG. <ref type="table" target="#tab_6">Table 6</ref> provides results for the Chest X-rays dataset, where the spurious correlation of vertical translation with the class label in source domains may lead the models to learn an unstable relationship. With RSNA as the target domain, ERM obtains 79.8%, 81.8% accuracy on the source domains while its accuracy drops to 55.1% for the target domain. In contrast, MDGHybrid obtain the highest classification accuracy (8 % above ERM), followed by CSD and MatchDG; while methods like ERM and IRM are more susceptible to spurious correlation. However, on ChexPert as the target domain, CSD and IRM do better than ERM while matchingbased methods are not effective. We conjecture these varying trends might be due to the inherent variability in images in the source domains, indicating the challenges of building domain generalization methods for real-world datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Chest X-rays dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We presented a causal view of domain generalization that provides an object-conditional objective. Simple matchingbased methods perform competitively to state-of-the-art methods on PACS, indicating the importance of choosing the right invariance. The proposed MatchDG uses certain assumptions when objects are unknown. More work needs to be done to develop better matching methods, as indicated by the mixed results on the Chest-Xrays dataset. Dataset The synthetic slab dataset (Section 3.2) consists of a binary label y and 2-dimensional features; one feature has a linear relationship with y while the other has a more complex "slab" relationship with y. The features vary in their simplicity, a measure of the simplicity of the feature is given by the number of linear pieces in the optimal classification/decision curve <ref type="figure" target="#fig_0">(Figure 1, (Shah et al., 2020)</ref>). Hence, the linear features are simpler as they only have 1 linear piece in the optimal decision boundary, as opposed to the slab features that have k linear pieces in the piecewise linear optimal decision boundary.</p><p>The synthetic slab dataset was introduced for detecting simplicity bias in neural networks <ref type="bibr">(Shah et al., 2020)</ref>, to demonstrate that neural networks trained with SGD learn the simpler linear feature as opposed to the slab feature. We extend this dataset for the domain generalization (DG) task, by making the linear block features spurious due to domaindependent noise addition as described below. The effect of the slab feature on y remains the same across domains. Presence of the spurious linear feature should enable an ideal DG algorithm to differentiate it from the stable slab feature, and break the simplicity bias in neural networks. However, the invariance introduced by different DG methods can have a big impact. Using this dataset, we show that the classconditional distribution matching constraint is not sufficient (section 3.2); it is possible to satisfy the constraint using the spurious linear feature too.</p><p>The linear block features contain the positive (y=1) and the negative (y=0) labels sampled from uniform distributions U (0.1, 1.0) and U (?1.0, ?0.1) respectively. To make the linear features spurious, we add noise to the linear features s.t. data points are sampled from U (?0.1, 0.1) with probability p, and sampled from U (0.1, 1.0) (y=1) or U (?1.0, ?0.1) (y=0) with probability 1 ? p. The k-slab feature ranges from [-1, 1] and within it has different "slabs" corresponding to uniform distributions of the feature's value, conditioned on class label y. The labels for these slabs alternate between positive (y=1) and negative (y=0) as the numeric value of the slab feature increases. The length for each slab is given by 2?m * (k?1) k where k is the total number of slabs, and m is the margin between two slabs. We also a constant (domain independent) noise to the relationship between the slab feature and the class label by flipping the original label with probability p s .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source and Target Domains</head><p>We generate two source data domains with noise probabilities p as 0.0 and 0.1, and generate the target domain with complete noise p = 1.0, rendering the linear block feature not informative of the label in the target domain. However, the slab block features have a stable relationship with the labels across the multiple source and target domains. We choose k = 7, m = 0.1, and p s = 0.1 for the slab block features in our experiments. We sample 1k data points per domain, which leads to 2k training data points (source domain with p as 0.0 and 0.1), and 1k test data points (target domain with p as 1.0). Also, for hyperparameter tuning (model selection), we sample additional 250 data points per source domain as the validation set.</p><p>Model Architecture The overall architecture consists of a representation network along with a classification network, detailed below. Input Dim refers to the input data dimension, which is 2 dimensional (linear block feature, slab block feature). Num Classes refers to the total number of output classes, which is binary classification for the synthetic slab dataset. We refer a fully connected dense layer by FC layer, with the input and output dimensions for that layer in brackets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Representation Network</head><p>? FC layer: (Input Dim, 100)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? ReLU activation</head><p>Classification Network</p><p>? FC layer: (100, 100) For methods like DANN <ref type="bibr" target="#b14">(Ganin et al., 2016)</ref>, and <ref type="bibr">CDAAN (Li et al., 2018d)</ref>, which also require domain discriminators, we use the same architecture for them as that of the classification network.</p><p>Methods We use Cross-Entropy for the classification loss in ERM and all the other methods. The regularization penalty of all the methods is placed on the output of the representation network.  <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref>. We extended the implementation of MMD and CORAL from DomainBed to their class conditional versions, C-MMD, and C-CORAL. The extension to class conditional version was done by computing their respective penalty over domains conditioned on a particular class label.</p><p>For RandMatch <ref type="bibr" target="#b29">(Motiian et al., 2017)</ref> and PerfMatch, we use l 2 distance for dist in <ref type="figure" target="#fig_7">(Eq: 3)</ref>. The match function ? in the RandMatch algorithm is defined as randomly matching any two data points across domains with the same class label. For the PerfMatch algorithm, the match function ? accepts two data points across domains with the same slab id as valid matches (the slab id corresponds to the value of the causal feature: two inputs with the same slab id have similar causal features).</p><p>Note on method selection Our objective with the synthetic slab dataset is to compare the performance of conditional distribution matching (CDM) methods to that of Hyperparameter Tuning All the methods were trained using SGD, with batch size 128, learning rate 0.1 and weight decay 5e-4. We train each method for 100 epochs and do early stopping based on the validation loss.</p><p>Further details regarding the tuning of hyperparameters specific to each method's regularization technique are provided in <ref type="table" target="#tab_8">Table 7</ref>. The loss objective of all the methods can be written as ERM + ?*Regularization Penalty; and we provide the optimal values and grid range for the hyperparam ? in <ref type="table" target="#tab_8">Table 7</ref>. Also, some methods like DANN, C-DANN have additional hyperparams, which are specified in the same table. The grid search range for methods that were implemented using DomainBed <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref> is taken from the <ref type="table" target="#tab_10">Table 8</ref> in the DomainBed paper.</p><p>A.2. Simple counter-example and its relationship to the MatchDG assumption.</p><p>The MatchDG method depends on Assumption 1 (Section 5) which requires that same-class inputs across domains are closer in causal features than different-class inputs. Note that the example in Section 3.1 does not satisfy this assumption. However, there exist many variations of the setup that do follow the MatchDG assumption, and still classconditional methods cannot recover the true causal feature. For instance, by setting |x c | = |x c | + ? where ? &gt; 1.5 and ? 1 = ? + 1, ? 2 = ? + 2 for domain 1 and domain 2 respectively, the train domains satisfy the MatchDG assumption.</p><p>Overall, the goal of the simple example in Section 3.1 is to show that there exist datasets where class-conditional methods would not work, but Perfect-Match does. MatchDG's assumption works in a subset of these datasets. In future work, matching-based methods can be developed that relax the MatchDG assumption. Given these differences, we construct a causal graph ( <ref type="figure" target="#fig_2">Figure  2</ref>) that includes both Y true and Y (as in (Heinze-Deml &amp; Meinshausen, 2019)), and is consistent with both viewpoints about the direction of the causal mechanism. Importantly, all d-separation results reported in the main text hold true irrespective of whether we choose Y or Y true as the class label. We use Y as the label in the main text, since it corresponds to many settings where the observed class label is a result of a (possibly noisy) manual labelling process.</p><p>In addition, we chose to represent X C and X A as near-tofinal features, that are combined using a simple operation to generate the observed features X. Under this representation, the object O does cause X A ; X A is produced by combination of the domain and the object. Another equally valid construction is to assume that X A contains only the domain information, and a more complex operation generates the observed features using X C (object information) and X A . The corresponding causal graph will omit the edge from object O to X A . Both these graphs are allowed by our framework. All d-separation results reported in the main text hold true irrespective of whether there exists an edge from O to X A .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. D-separation</head><p>We first expand on the d-separation definition, providing a few examples that illustrate conditional independence implications of specific graph structures in <ref type="figure">Figure 4</ref>. We use these three conditions for the proofs below.</p><formula xml:id="formula_13">A B C (a) Chain: A ? ? B; A ? ? B|C A B C (b) Fork: A ? ? B; A ? ? B|C A B C (c) Collider: A ? ? B; A ? ? B|C Figure 4</formula><p>. Causal graphs with the node C as a chain, fork, or a collider. By the d-separation criteria, A and B are conditionally independent given C in (a) and (b). In (c) however, A and B are independent but become conditionally dependent given C.</p><p>Definition 1. d-separation <ref type="bibr" target="#b32">(Pearl, 2009</ref>): Let A,B,C be the three non-intersecting subsets of nodes in a causal graph G. For any path between two nodes, a collider is a node where arrows of the path meet head-to-head. A path from A to B is said to be blocked by C if either a non-collider on the path is in C, or there is a collider on the path and neither the collider nor its descendants are in C.</p><p>If all paths from A to B are blocked, then A is d-separated from B by C: dsep(A, B, C) ? A ? ? B|C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3. Proof of Proposition 1</head><p>Proposition 1 relates to the domain generalization setup, as described in Section 3.1, where the causal feature determines y label without any noise. The distribution of the non-causal feature varies across domains. The proof uses the entropy formulation of distribution-matching methods, as done by <ref type="bibr" target="#b2">Akuzawa et al. (2019)</ref>. Proposition 1. Under the domain generalization setup as above, if P (X c |Y ) remains the same across domains where x c is the stable feature, then the class-conditional domaininvariant objective for learning representations yields a generalizable classifier such that the learnt representation ?(x) is independent of the domain given x c . Specifically, the entropy H(d|x c ) = H(d|?, x c ).</p><p>Proof. We can write class-conditional invariant models as optimizing two objectives: minimize the error on the training data (ERM objective), and learn a representation ?(x) that is independent of domain given the class label (classconditional invariant).</p><p>Let us focus on the second objective, which be interpreted as 2) maximizing the entropy of domain given class label and representation H(d|y, ?(x)). Let ? 2 be the optimal representation for the class-conditional invariant. We can write,</p><formula xml:id="formula_14">? 2 = arg max ? H(d|y, ?(x))<label>(5)</label></formula><p>Since H(d|y, ?(x)) ? H(d|y) using the property of entropy, the optimal ? 2 satisfies,</p><formula xml:id="formula_15">H(d|y, ? 2 (x)) = H(d|y)<label>(6)</label></formula><p>Now two cases arise; x c ? ? D|Y or x c ? ? D|Y . We assume the former. If X C is independent of domain conditioned on the class label, then</p><formula xml:id="formula_16">H(d|y) = H(d|y, x c )<label>(7)</label></formula><p>Here domain d is independent of both x c and ? 2 (x), conditional on y. Since causal features x c cannot be caused by the representation ? 2 (x), it cannot be a collider (Definition 1) in any graph connecting d, x c and ? 2 (x). Therefore, conditioning on it does not remove the independence between d and ? 2 (x)|y (conditioned on y). Hence, we condition on Eq 6 with x c and obtain,</p><formula xml:id="formula_17">H(d|y, x c ) = H(d|y, x c , ? 2 (x))<label>(8)</label></formula><p>Plugging it into the above equations, we obtain</p><formula xml:id="formula_18">H(d|y) = H(d|y, x c ) = H(d|y, x c , ? 2 (x))<label>(9)</label></formula><p>Also since there is no label noise, x c can achieve zero error for predicting the label y. That is, x c contains all information about y, and thus we can remove y from the above equation,</p><formula xml:id="formula_19">H(d|x c ) = H(d|? 2 (x), x c )<label>(10)</label></formula><p>This implies that the learnt representation ? 2 (x) is independent of the domain given x c ; thus ? 2 (x) depends on x c and not on any other feature that changes with domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3.1. REMARKS BASED ON PROPOSITION 1</head><p>If x c is not independent of domain given class label. However, if X C is not independent of domain given the class label (i.e., P (x c |y) changes across domains), then H(d|y) &gt; H(d|y, x c ). Using the equality from Eq 8, we obtain,</p><formula xml:id="formula_20">H(d|y) = H(d|y, ? 2 (x)) &gt; H(d|y, x c ) H(d|y, ? 2 (x)) ? H(d|? 2 (x), y, x c )<label>(11)</label></formula><p>After removing y as in Eq. 10, H(d|x c ) and H(d|? 2 , x c ) may not be equal. In particular, the ground-truth representation ? GT (x) = x c does not satisfy the class-conditional invariant: H(d|y, ? GT (x)) = H(d|y, x c ) = H(d|y).</p><p>Hence, to learn x c as the representation, we need a separate constraint, H(d|x c ) = H(d|?, x c ); i.e. domain and representation should be independent conditioned on x c .</p><p>Implications for the slab dataset (Section 3.2). In the slab dataset, x c = x 2 and x 2 is independent of the domain given the class label (X 2 ? ? D|Y ). We also see that ?(x) = x 2 satisfies the class-conditional invariant: H(d|y, x 2 ) = H(d|y) since X 2 ? ? D|Y . By Proposition 1, the classconditional invariant should lead to a representation that satisfies H(d|x c ) = H(d|?(x), x c ). However, the same constraint can also be achieved by setting ?(x) = x 1 by shifting the distribution of x 1 slightly. And since there is a simple, linear correlation between x 1 and the class label y, empirically class-conditional methods end up learning a representation dependent on x 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4. Proof of Proposition 2</head><p>Proposition 2. Given observed data distribution P (Y, X, D, O) that may also include data obtained from interventions on domain D, multiple values of X C yield exactly the same observational and interventional distributions and hence X c is unidentifiable.</p><p>Proof. To prove non-identifiability, it is sufficient to show a counter-example where the same structural equations (and hence same observed and interventional distributions over Y, X, D, O) correspond to two different values of X C .</p><p>From Section 4.1, the SCM leads to the following structural equations,</p><formula xml:id="formula_21">o := g o (y true , o , od ) x c := g xc (o) x a := g xa (d, o, xa ) x := g x (x c , x a , x )y := h(x c , y )</formula><p>Substituting for x c in the SCM equations, we obtain,</p><formula xml:id="formula_22">y = h(g xc (o), y ) x = g x (g xc (o), g xa (d, o, xa ), x )<label>(12)</label></formula><p>Given a value of object variable o, note that g xc determines x c . We now proceed to show that different values of g xc are possible given the same structural equations between the observed variables Y, X, D, O. Specifically, by choosing g x and h appropriately, different values of g xc can lead to the same observed values for <ref type="bibr">(y, d, o, x)</ref>.</p><p>A simple counter-example. Suppose the following SCM equations,</p><formula xml:id="formula_23">y = h(g xc (o)) x = g 1 (g xc (o)) + g 2 (o, d)<label>(13)</label></formula><p>Introducing h * = h ? g xc and g * 1 = g 1 ? g xc , we can rewrite the above equations as,</p><formula xml:id="formula_24">y = h * (o) x = g * 1 (o) + g 2 (o, d)<label>(14)</label></formula><p>then any g xc is applicable as long as we set h such that h(g xc )(o) = h * (o) and set g 1 such that g 1 (g xc (o)) = g * 1 (o). In particular, if the SCM equations are y = o, x = o + o * d, and we define h = g 1 = g ?1 xc , then g xc can be any invertible function. Hence, different values of x c = g xc (o) will lead to the same structural equations over Y, X, D, O, and therefore the same observed and interventional distributions. k )) = 0 contains the optimal ?(x) = X C that minimizes the domain generalization loss in (1). 2. Assuming that P (X a |O, D) &lt; 1 for every high-level feature X a that is directly caused by domain, and for P-admissible loss functions <ref type="bibr" target="#b28">(Miller et al., 1993)</ref> whose minimization is conditional expectation (e.g., 2 or crossentropy), a loss-minimizing classifier for the following loss is the true function f * , for some value of ?.</p><formula xml:id="formula_25">fperfectmatch = arg min h,? m d=1 L d (h(?(X)), Y )+ ? ?(j,k)=1;d =d dist(?(x (d) j ), ?(x (d ) k )) (3)</formula><p>Proof. CLAIM 1. The matching condition can be written as:</p><formula xml:id="formula_26">C(?) = min ? d,d ?Dm lim n d ?? n d ?? ?(j,k)=1;d =d dist(?(x (d) j ), ?(x (d ) k ))<label>(15)</label></formula><p>where ?(j, k) = 1 for pairs of inputs x j and x k from two different domains d and d that correspond to the same object. The distance metric dist is non-negative, so the optimal ? is when C(?) is zero. As in the SCM from <ref type="figure" target="#fig_2">Figure 2(b)</ref>, let X c represent a feature vector such that it is generated based only on the object O and that it leads to the optimal classifier in (1). From Sections 4.1 and 4.2, we know that X c ? ? D|O and that x c = g xc (o). Thus, x c is the same for inputs from the same object and we can write:</p><formula xml:id="formula_27">dist(x (d) c,j , x (d ) c,k ) = 0 ?d, d ? D m such that ?(j, k) = 1<label>(16)</label></formula><p>Hence, ?(x) = x c leads to zero regularizer term and is one of the optimal minimizers for C(?).</p><p>CLAIM 2. Further, we show that any other optimal ? is either a function of x c or a constant for all inputs. We prove by contradiction.</p><p>Let X A represent the set of unobserved high-level features that are generated based on both the object O and the domain D. From the SCM from <ref type="figure" target="#fig_2">Figure 2(b)</ref>, a feature vector X a ? X A is independent of X c given the object, X a ? ? X c |O, and x a = g xa <ref type="figure">(d, o, xa )</ref>. Further, let there be an optimal ? a (x) for C(?) such that it depends on some X a ? X A (and is not trivially a constant function). Since ? a is optimal, ). Due to domain-dependent variation, with nonzero probability, the high-level X a features are not the same for these two input data points, x</p><formula xml:id="formula_28">? a (x (d) j ) = ? a (x</formula><formula xml:id="formula_29">(d) a,l = x (d )</formula><p>a,i . Since ? is a deterministic function of x that is not independent of X a , if an input x has a different X a , its value of ?(x) will also be different. Thus, with non-zero probability, we obtain that</p><formula xml:id="formula_30">?(x (d) l ) = ?(x (d ) i</formula><p>), unless the effect of X a is a constant function. Hence, a contradiction and optimal ? cannot depend on any X a ? X A that are generated based on the domain.</p><p>Therefore, an optimal solution to C(?) can only depend on X c . However, any function of X c is optimal, including trivial functions like the constant function (that will have low accuracy). Below we show that using the ERM term in (3) ensures that the optimal solution contains only those functions of X C that also maximize accuracy.</p><p>Using <ref type="formula" target="#formula_40">(2)</ref>, the empirical optimizer function can be written as (where we scale the loss by a constant n = d n d , the total number of training data points):</p><formula xml:id="formula_31">f pmatch = arg min h,? 1 n m d=1 lim n d ?? L d (h(?(X)), Y ) (17) s.t. ?(j,k)=1;d =d dist(?(x (d) j ), ?(x (d ) k )) = 0 (18) = arg min h,? 1 n m d=1 lim n d ?? L d (h(?(X c )), Y ) = arg min f 1 n m d=1 lim n d ?? L d (f (X c ), Y )<label>(19)</label></formula><p>where ?(X c ) denotes all functions of X c that are optimal for (15), and the last equality is because h ? ? can be written as f = h ? ?. Since we assume that L is a P-admissible loss function, its minimizer is the conditional expected value. Thus, for any domain d, arg min f lim n d ?? 1</p><formula xml:id="formula_32">n d L d (f (X c ), Y ) = E[Y |X c , D]. Further, by d-separation, Y ? ? D|X c . Therefore, E[Y |X c , D] = E[Y |X c ].</formula><p>The above equation indicates that the loss minimizer function on any domain is independent of the domain. Thus, for the m training domains, we can write:</p><formula xml:id="formula_33">arg min f ?F lim n d ?? 1 n d L d (f (X c ), Y ) = arg min f ?F E[l(f (x c ), y)] = E[Y |X c ] ?d ? D m<label>(20)</label></formula><p>Now <ref type="formula" target="#formula_3">(19)</ref> can be rewritten as,</p><formula xml:id="formula_34">f pmatch = arg min f 1 n m d=1 lim n d ?? L d (f (X c ), Y ) n d n d = arg min f m d=1 lim n d ?? L d (f (X c ), Y ) n d n d n<label>(21)</label></formula><p>From the equation above, the loss forf pmatch can be considered as a weighted sum of the average loss on each training domain where the weights are all positive. Since E[Y |X c ] minimizes the average loss on each domain as n d ? ?, it will also minimize the overall weighted loss for all values of the weights. Therefore, for any dataset over m domains in D m , E[Y |X c ] is the optimal function that minimizes the overall loss.</p><p>Moreover, we can also write f * as: </p><formula xml:id="formula_35">f * = arg min f ?F E (d,</formula><p>where we utilize <ref type="bibr">(20)</ref> and that the loss function is Padmissible. Hence, f * = E[Y |X c ] is the loss-miniziming function for the loss in <ref type="bibr">(19)</ref>.</p><p>Finally, using a Lagrangian multiplier, minimizing the following soft constraint loss is equivalent to minimizing (18), for some value of ?.</p><formula xml:id="formula_37">f pmatch = lim ?d?Dmn d ?? arg min h,? m d=1 L d (h(?(X)), Y ) + ? ?(j,k)=1;d =d dist(?(x (d) j ), ?(x (d ) k )) (23)</formula><p>The result follows.</p><p>Comment on Theorem 1. In the case where the effect of a domain is also deterministic, it is possible that P (X a |O, D) = 1 (e.g., in artificially created domains like Rotated-MNIST where every object is rotated by the exact same amount in each domain). In that case Theorem 1 does not apply and it is possible to learn a representation ? a that depends on X a ? X A and still minimizes C(?) to attain C(?) = 0. For example, with two training domains on Rotated-MNIST dataset (0 ? , ? ? ), it is possible to learn a representation that simply memorizes to "un-rotate " the ? angle back to 0 ? . Such a representation will fail to generalize to domains with different rotation angles, but nonetheless minimizes C(?) by attaining the exact same representation for each object.</p><p>In practice, we conjecture that such undesirable ? a are avoided by model-size regularization during training. As the number of domains increase, it may be simpler to learn a single transformation (representation) based on X c (and independent of X c features like angle) than learn separate angle-wise transformations for each train domain.</p><p>B.6. Proof of Proposition 3 <ref type="bibr">det et al., 2013;</ref><ref type="bibr">Li et al., 2018b;</ref><ref type="bibr" target="#b14">Ganin et al., 2016)</ref>. Using d-separation on the SCM from <ref type="figure" target="#fig_2">Figure 2(b)</ref>, X C ? ? D is not sufficient since O blocks the path between X C and D. While <ref type="bibr" target="#b38">(Zhao et al., 2019)</ref> argue that this condition fails when Y is correlated with D, our analysis shows that domain-invariant methods require a stronger condition that both class label and actual objects sampled be independent of domain.</p><formula xml:id="formula_38">Domain-invariant representations. (?(x) ? ? D) (Muan</formula><p>Class-conditional domain-invariant.</p><p>(?(x) ? ? D|Y .) <ref type="bibr">(Li et al., 2018c;</ref><ref type="bibr" target="#b16">Ghifary et al., 2016;</ref><ref type="bibr" target="#b38">Li et al., 2018d)</ref> Even in the ideal case where we observe Y true , d-separation on the SCM reveals that X C ? ? D|Y true due to a path through O. Thus, having the same distribution per class is not consistent with properties of X C .</p><p>Below we prove these results formally.</p><p>Proposition 3. The conditions enforced by domaininvariant (?(x) ? ? D) or class-conditional domaininvariant (?(x) ? ? D|Y ) methods are not satisfied by the causal representation X C . Thus, without additional assumptions, the set of representations that satisfy any of these conditions does not contain X C , even as n ? ?.</p><p>Proof. As in the SCM from <ref type="figure" target="#fig_2">Figure 2(b)</ref>, let X c represent an unobserved high-level feature vector such that it is generated based only on the object O and that it leads to the optimal classifier in (1). From Sections 4.1 and 4.2, we know that X c ? ? D|O and that x c = g xc (o). Following a similar proof to Theorem 1 (Claim 1), we check whether ?(x) = x c satisfies the invariance conditions required by the two methods.</p><p>1. Domain-invariant: The required condition for a representation is that ? DI (x) ? ? D. But using the dseparation criteria on the SCM in <ref type="figure" target="#fig_2">Figure 2</ref>(b), we find that X c ? ? D due to a path through Object O.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Class-conditional domain-invariant:</head><p>The required condition for a representation is that ? CDI ? ? D|Y . However using the d-separation criteria on the SCM, we find that X c ? ? D|Y due to a path through Object O that is not blocked by Y (nor by Y true if it is observed).</p><p>Therefore, under the conditions proposed by these methods, X c or any function of X c is not an optimal solution without making any additional assumptions. Hence, even with infinite samples, a method optimizing for these conditions will not retrieve X c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Evaluation and implementation details</head><p>In this section we describe implementation details for our proposed methods. We also discuss the evaluation protocol, including details about hyperparameters and crossvalidation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Implementation details</head><p>For the implementation of ERM-PerfMatch in Eq.</p><p>(3); we use the cross-entropy loss for L d and l 2 distance for dist in <ref type="figure" target="#fig_7">Eq. (3)</ref>. Similarly, we implement the ERM-RandMatch with a match function ? in Eq.</p><p>(3) that randomly matches data points across domains with the same class, For both methods, we consider the representation ?(x) to be the last layer of the network. That is, we take h to be identity function in Eq.</p><p>(3) for simplicity. It is also possible to use the second-last or any other previous layer as a representation, but the last layer performed well in our experiments.</p><p>Also, given a fixed data point, the match function ? could select multiple data points as potential matches for it. In this case we use Eq. (3) with stochastic matching, where we randomly select one match out of the potential multiple matches.</p><p>We use SGD to optimize the loss for all the datasets, with details about learning rate, epochs, batch size, weight decay etc. provided in the section C.3 ahead. For all the different methods, we sample batches from the data matrix consisting of data points matched across domains; hence we ensure an equal number of data points from each source domain in a batch. When training with MatchDG, the underlying architecture for Phase 2 is kept the same for ERM, RandMatch, PerfMatch for the respective task; with the details mentioned below for each dataset. The details for the Phase-1 architecture are specified in section C.3, <ref type="table" target="#tab_17">Table 9</ref>.</p><p>Rotated MNIST &amp; Fashion-MNIST. The datasets contain rotations of grayscale MNIST handwritten digits and fashion article images from 0 ? to 90 ? with an interval of 15 ? (Ghifary et al., 2015), where each rotation angle represents a domain and the task is to predict the class label. For Table 2, we follow the setup in CSD <ref type="bibr" target="#b34">(Piratla et al., 2020)</ref>, we report accuracy on 0 ? and 90 ? together as the test domain and the rest as the train domains. We use 2, 000 and 10, 000 training samples from each domain for rotated MNIST and Fashion-MNIST, and train models using Resnet-18 architecture (without pre training). We choose this as our primary setup and select 0 ? and 90 ? as our target domain, since these are known to be the most difficult domains to generalize (Piratla et al., 2020; <ref type="bibr" target="#b29">Motiian et al., 2017)</ref>.</p><p>Further, we also evaluate on other setups of Rotated MNIST in prior works <ref type="bibr" target="#b29">(Motiian et al., 2017;</ref><ref type="bibr" target="#b19">Gulrajani &amp; Lopez-Paz, 2020)</ref>, which involve six domains (0 ? , 15 ? , 30 ? , 45 ? , 60 ? , 75 ? ), and evaluate for each domain being the target domains with the remaining five used as source domains. We sample 1000 data points for each domain and evaluate using the LeNet architecture <ref type="table">(Table 11)</ref> as per the setup proposed by <ref type="bibr" target="#b29">(Motiian et al., 2017)</ref>. Similarly, we sample all the 70,000 images in MNIST and evaluate using the custom architecture <ref type="table" target="#tab_3">(Table 12)</ref> as per the setup proposed by <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref>.</p><p>Another important distinction between different setups above is the use of different digits for the source and the target domains ( <ref type="bibr" target="#b34">(Piratla et al., 2020)</ref>, <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref>), as opposed to the use of same digits across the source and the target domains in setup of <ref type="bibr" target="#b29">(Motiian et al., 2017)</ref> which makes the task easier as it leaks information about the target domains.</p><p>Finally, for all the different setups proposed above, we create an additional validation set for each domain with 20% percent size as of the training set for that domain. We use the validation set from the source domains for hyper parameter tuning.</p><p>PACS. This dataset contains total 9991 images from four domains: Photos (P), Art painting (A), Cartoon (C) and Sketch (S). The task is to classify objects over 7 classes. Following , we train 4 models with each domain as the target using Resnet-18 <ref type="table">(Table 4)</ref>, Resnet-50 <ref type="table">(Table 5)</ref> and Alexnet <ref type="table" target="#tab_10">(Table 18)</ref>, with each architecture pre-trained on ImageNet. We also the following data augmentations <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref> while training: Random Crop, Horizontal Flip, Color Jitter, and Random Gray Scale.</p><p>Chest X-ray. We use Chest X-rays images from three different sources: NIH (Wang et al., 2017), ChexPert <ref type="bibr">(Irvin et al., 2019)</ref> and RSNA (rsn, 2018). The task is to detect whether the image corresponds to a patient with Pneumonia (1) or not (0). For ease of interpretation, we balance the data such that there are equal number of images per class in each domain. Since majority of the images in each domain correspond to the class (0), we sample a subset of the images to ensure that there is no class imbalance in each domain. The dataset size for the different splits on each domain are described below: Following prior works <ref type="bibr" target="#b11">(Cohen et al., 2020)</ref>, we use the pretrained DenseNet-121 architecture for classification. We use the following data augmentations: Random Crop and Random Horizontal Flip. We further create spurious correlations, all the images of the class 0 in the training domains are translated vertically downwards; while no such translation is done for the test domain. We translate the images in each source domain by a fixed amount, which varies over different source domains (NIH (45), ChexPert (35), RSNA <ref type="formula" target="#formula_3">(15)</ref>). This leads to a downward shift in the position of lungs in the images for the class 0 as compared to those for class 1, which could lead to models utilizing this spurious relative difference in position of lungs for the classifications task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1.1. MATCHDG IMPLEMENTATION DETAILS:</head><p>The MatchDG algorithm proceeds in two phases. Initialization: We construct matches of pairs of same-class data points from different domains. Hence, given each data point we randomly select another data point with the same class from another domain. The matching for each class across domains is done relative to a base domain; which is chosen by taking the domain that has the highest number of samples for that class. This is done to avoid missing out on data points when there is class imbalance across domains. Specifically, we iterate over classes and for each class, we match data points randomly across domains w.r.t a base domain for that class. This leads to matrix M of size (N , K), where N refers to the updated domain size ( sum of the size of base domain for all the classes ) and K refers to the total number of domains. We describe the two phases below:</p><p>Phase 1: We samples batches (B, K) from the matched data matrix M, where B is the batch size. For each data point x i in the batch, we minimize the contrastive loss from (4) by selecting its matched data points across domains as the positive matches and consider every data point with a different class label from x i to be a negative match.</p><p>After every t epochs, we periodically update the matched data matrix by using the representations learnt by contrastive loss minimization. We follow the same procedure of selecting a base domain for each class, but instead of randomly matching data points across domains, we find the nearest neighbour for the data point in base domain among the data points in the other domains with the same class label based on the l 2 distance between their representations.</p><p>At the end of Phase I, we update the matched data matrix based on l 2 distance over the final representations learnt. We call these matches as the inferred matches.</p><p>Phase 2: We train using the loss from Eq. (3), with the match function ? based on the inferred matches generated from Phase 1 (ERM + Inferred Match). We train the network from scratch in Phase 2 and use the representations learnt in Phase 1 to only update the matched data matrix.</p><p>The updated data matrix based on representations learnt in Phase 1 may lead to many-to-one matches from the base domain to the other domains. This can lead to certain data points being excluded from the training batches. Therefore, we construct batches such that each batch consists of two parts. The first is sampled as in Phase 1 from the matched data matrix. The second part is sampled randomly from all train domains. Specifically, for each batch (B, K) sampled from the matched data matrix, we sample an additional part of size B with data points selected randomly across domains. The loss for the second part of the batch is simply ERM, along with ERM + InferredMatch Loss on the first part of the batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Metrics for evaluating quality of learnt matches</head><p>Here we describe the three metrics used for measuring overlap of the learnt matches with ground-truth "perfect"  <ref type="bibr">, 5, 15, 20]</ref> matches.</p><p>Overlap %: Percentage of matches (j, k) as per the perfect match strategy ? that are also consistent with the learnt match strategy ? .</p><formula xml:id="formula_39">?(j,k)=1;d =d ? (j, k) ?(j,k)=1;d =d 1<label>(24)</label></formula><p>Top-10 Overlap %: Percentage of matches (j, k) as per the perfect match strategy ? that are among the Top-10 matches for the data point j w.r.t the learnt match strategy ? i.e. S 10 ? (j) <ref type="bibr">25)</ref> Mean Rank: For the matches (j, k) as per the perfect match strategy ?, compute the mean rank for the data point j w.r.t the learnt match strategy ? i.e. S ? (j)</p><formula xml:id="formula_40">?(j,k)=1;d =d 1[k ? S 10 ? (j)] ?(j,k)=1;d =d 1<label>(</label></formula><formula xml:id="formula_41">?(j,k)=1;d =d Rank[k ? S ? (j)] ?(j,k)=1;d =d 1 (26)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3. HyperParameter Tuning</head><p>To select hyperparameters, prior works <ref type="bibr" target="#b8">Carlucci et al., 2019;</ref><ref type="bibr" target="#b38">Li et al., 2018a</ref>) use leave-one-domainout validation, which means that the hyperparameters are tuned after looking at data from the unseen domain. Such a setup is violates the premise of the domain generalization task that assumes that a model should have no access to the test domain. Therefore, in this work, we construct a validation set using only the source domains and use it for hyper parameter tuning. In the case of PACS, we already have access to the validation indices for each domain and use them to construct a validation set based on the source domains. For Rotated &amp; Fashion MINST, Chest X-ray datasets, we create validation set for each source domain as described in the section B.1 above. Hence, the model does not have <ref type="table" target="#tab_17">Table 9</ref>. MatchDG Phase 1 training details for all the datasets.We did not do hyper parameter tuning as we did for other methods, hence we mention the default value for each hyper parameter that we used. Please note we still did early stopping, the Total Epochs in the table reflects the max budget for training. The specific archiecture used for Phase 1 training is also mentioned for each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Hyper Parameter Default Value</p><p>Rotated &amp; Fashion MNIST  <ref type="table" target="#tab_3">(Table 2)</ref>, LeNet <ref type="table">(Table 11)</ref>, Custom CNN <ref type="table" target="#tab_3">(Table 12)</ref> PACS We perform a grid search over pre-defined values for each hyper parameter and report the optimal values along with the values used for grid search in <ref type="table" target="#tab_10">Table 8</ref>. Further, we do early stopping based on the validation accuracy on source domains and use the models which obtain the best validation accuracy.</p><p>For the case of MatchDG Phase-1, we do not perform grid search and use default values for each hyper parameter (Table 9). We still do early stopping for MatchDG Phase-1, based on the metric Top-10 Overlap (Section B.2) over the validation set of source domains. Since we require perfect matches for the evaluation of the metric Top-10 Overlap, we create prefect matches using the self augmentations (Section B.1) for each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4. Reproducing Results from Prior Work</head><p>MNIST and Fashion MNIST The results for MASF, CSD, and IRM in <ref type="table" target="#tab_3">Table 2</ref> were computed using their code which is available online 123 . The MASF code was hardcoded to run for PACS dataset; which has 3 source domains that gets divided into 2 meta train and 1 meta test domain. Their code requires atleast 2 meta train domains; which leads to an issue for only 2 source domains <ref type="bibr">(30,</ref><ref type="bibr">45)</ref>. In <ref type="table" target="#tab_3">Table 2</ref>  The results for prior approaches in <ref type="table">Table 11</ref> are taken from <ref type="bibr">(Shankar et al., 2018)</ref>, <ref type="bibr">(Ilse et al., 2020)</ref>. For the results using DomainBed setup in <ref type="table" target="#tab_3">Table 12</ref>, the results for prior approaches are taken from <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref>.</p><p>PACS We did not generate results for the prior approaches for PACS by developing or using existing implementations. All the results for the prior approaches on PACS were taken from the respective papers as specified in the <ref type="table" target="#tab_8">Table 17, 18</ref>.</p><p>Chest X-ray The results for the prior approaches CSD, IRM were generated using the implementations of both of the methods available on github 1,3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Additional Evaluation on Rotated MNIST and Fashion-MNIST</head><p>Here we present results for additional experiments on Rotated MNIST and Fashion-MNIST datasets using MatchDG.</p><p>D.1. Comparing MatchDG with prior work on the LeNet Network <ref type="table">Table 11</ref> compares the accuracy results for MatchDG with prior work on the LeNet architecture <ref type="bibr" target="#b29">(Motiian et al., 2017)</ref>. In this setup, there are six domains in total   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3. Accuracy Results using a fraction of perfect matches</head><p>To show the importance of learning a good match function, we present the results of approaches with match function capturing some fixed percentage of perfect matches in the <ref type="table" target="#tab_18">Table 13</ref>. For both Rotated &amp; Fashion MNIST, we observe that the approaches that contain a higher proportion of perfect matches perform better in terms of accuracy on target domains. Hence, the quality of the match function leads to monotonic effect on the generalization performance of the matching approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4. Quality of representation learnt in the classification phase</head><p>In addition to <ref type="table">Table 3</ref> that shows metrics for Phase 1 of MatchDG, we compute the metrics for the classification phase (Phase 2) of MatchDG. Specifically, we compute the Overlap, Top-10 overlap and the Mean Rank metrics (Section C.2) for matched pairs of inputs based on the representation learnt at the end of the classification phase. <ref type="table" target="#tab_19">Table 14</ref> shows the matching metrics for MatchDG and compares it to the matches based on the representations (last layers) learnt by the ERM-PerfMatch and ERM-RandMatch methods. For both Rotated- <ref type="table">Table 11</ref>. Accuracy for Rotated MNIST datasets using the LeNet architecture as proposed in <ref type="bibr" target="#b29">(Motiian et al., 2017)</ref>. The results for the prior approaches CCSA <ref type="bibr" target="#b29">(Motiian et al., 2017)</ref>, D-MTAE , LabelGrad <ref type="bibr" target="#b18">(Goodfellow et al., 2014)</ref>, DAN <ref type="bibr" target="#b14">(Ganin et al., 2016)</ref>, and CrossGrad <ref type="bibr">(Shankar et al., 2018)</ref> are taken from  <ref type="table" target="#tab_3">Table 12</ref>. Accuracy for Rotated MNIST datasets using the DomainBed setup as proposed in <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref>. The results for the approaches IRM <ref type="formula" target="#formula_40">(</ref>  We compute the metric for the default instantiation of Phase 1 of MatchDG initialized with random matches and compare it to an oracle version of MatchDG initialized with perfect matches. In addition, we compare the metrics for matches generated using baseline ERM (last layer of the network) in order to understand its effectiveness as a matching strategy in Phase 1. <ref type="table" target="#tab_20">Table 15</ref> shows the metrics for Phase 1 of MatchDG with 2K images from the Fashion-MNIST dataset, and reproduces the metrics for the 10K dataset from <ref type="table">Table 3</ref> for ease of comparison. We observe that the mean rank of perfect matches improves for the smaller dataset. Similarly, the overlap and top-10 overlap also increase for the smaller dataset. A possible reason is that there are fewer alternative matches to the perfect match as the number of samples is reduced. That said, while the overlap with perfect matches may decrease as sample size increases, the accuracy of the resultant classifier may still increase due to higher sample size.</p><p>D.6. Iterative updating of matches in Phase-1 of MatchDG</p><p>In Section 5.1, we proposed Phase 1 of the MatchDG algorithm with iterative updates to the computed matches. Here we compare the quality of matches learnt at the end of Phase 1 with or without using the iterative updating. Without the iterative updates, the matches always remain the same as the random matches with which the algorithm was initialized. <ref type="table" target="#tab_6">Table 16</ref> shows metrics computed at the end of Phase 1 of MatchDG using both an iterative approach vs. a noniterative approach. The iterative approach provides a 2? improvement on the overlap with perfect matches for rotated MNIST and Fashion-MNIST datasets. Since higher overlap in the inferred matches results in better classification accuracy in Phase 2 (as shown in <ref type="table" target="#tab_18">Table 13</ref>), we conclude that using the iterative approach improves the domain generalization capability of MatchDG.   <ref type="table">(Table 4</ref>, 5) in the main text by adding comparison with more prior approaches. We observe that MDGHybrid beats most of the prior approaches on both the ResNet-18 and ResNet-50 evaluation, except DDEC <ref type="bibr" target="#b6">(Asadi et al., 2019)</ref>, and RSC <ref type="bibr" target="#b24">(Huang et al., 2020)</ref>. However, as stated in the main paper, DDEC <ref type="bibr" target="#b6">(Asadi et al., 2019)</ref> rely on data from additional source like Behance BAM! dataset and we are also not sure about the validation mechanism used by them. If the validation mechanism used by them includes data from the target domain during validation, then MatchDG (Test), MDGHybrid (Test) obtain better accuracy than them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2. AlexNet Results</head><p>Finally, we compare RandMatch and MatchDG to prior work on generalization accuracy for the PACS dataset using the AlexNet architecture. As in <ref type="table" target="#tab_8">Table 17</ref>, the task is to generalize to a test domain after training on the remaining three domains.</p><p>For all test domains,  <ref type="bibr" target="#b24">(Huang et al., 2020)</ref> achieve higher accuracy than MatchDG. Since MatchDG outperforms most of the prior work on the same dataset when trained using ResNet-18, ResNet-50 architecture <ref type="table" target="#tab_8">(Table 17)</ref>, we speculate that MatchDG requires a powerful underlying network architecture to use matches effectively for classification. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3. T-SNE Plots</head><p>Beyond accuracy, we investigate the quality of representations learnt by MatchDG using t-SNE <ref type="bibr" target="#b25">(Maaten &amp; Hinton, 2008)</ref> in <ref type="figure" target="#fig_13">Figure 5</ref>. Comparing the Phase I models for the easiest (Photo) and hardest (Sketch) unseen domains <ref type="figure" target="#fig_13">(Figs. 5a,b</ref>), we find that MatchDG achieves a higher overlap between train and test domains for Photo than Sketch, highlighting the difficulty of generalizing to the Sketch domain, even as classes are well-separated in the training domains for both models <ref type="figure" target="#fig_13">(Figs. 5c,d)</ref>.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Y) n where d i ? D m and D m ? D is a set of m domains. Each training input (d, x, y) is sampled from an unknown distribution Domain Generalization using Causal Matching (a) Simple Example (b) Slab Dataset (Slab (y-axis) is the stable feature) Two datasets showing the limitations of class-conditional domain-invariance objective. a)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Structural causal models for the data-generating process. Observed variables are shaded; dashed arrows denote correlated nodes. Object may not be observed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>are a set of (possibly unobserved) counterfactual inputs x (d ) j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>From Figure 2</head><label>2</label><figDesc>(b), X C is the node that causes Y . Further, by d-separation, the class label is independent of domain conditioned on X C , Y ? ? D|X C . Thus our goal is to learn y as h(x c ) where h : C ? Y. The ideal loss-minimizing function f * can be rewritten as (assuming x c is known): arg min f E (d,x,y) l(y, f (x)) = arg min h E[l(y, h(xc))]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>(a) MatchDG Penalty during training (b) IRM Penalty during training</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 .</head><label>3</label><figDesc>MatchDG regularization penalty is not trivially minimized even as the training error goes to zero.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Fig. (5) from (Krueger et al., 2020) where ERM can minimize IRM penalty on Colored MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Linear</head><label></label><figDesc>Block Feature: p l (x|y = 0) = U (?0.1, 0.1) with prob. p U (?1.0, ?0.1) with prob. 1 ? p p l (x|y = 1) = U (?0.1, 0.1) with prob. p U (0.1, 1.0) with prob. 1 ? p Slab Block Feature: Let k be the total number of slabs, and m be the margin between two slabs. Slab length: L = 2?m * (k?1) k Start index: I(i) = ?1 + i * L p s (x|y = 0) = U (I(i), I(i) + L) for i ? {0, 2, 4, ...} p s (x|y = 1) = U (I(i), I(i) + L) for i ? {1, 3, 5, ...}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>For</head><label></label><figDesc>the methods DANN (Ganin et al., 2016), CDANN (Li et al., 2018d), MMD (Li et al., 2018b), CORAL (Sun &amp; Saenko, 2016), we used their implementation available in DomainBed</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Perfect Match. We chose the above mentioned CDM methods for experimentation since the other CDM methods(Li  et al., 2018c;<ref type="bibr" target="#b16">Ghifary et al., 2016;</ref> Hu et al., 2019)  mentioned in the related works (Section 2, main paper) did not have their implementation publicly available. We found the implementation ofCDANN (Li et al., 2018d)  in the Do-mainBed<ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref> repository, which also provided implementation for the unconditional distribution matching methods like MMD(Li et al., 2018b), and CORAL(Sun &amp; Saenko, 2016). Hence, we extended MMD and CORAL to their class-conditional variant using their original implementation from the DomainBed repository.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>B.</head><label></label><figDesc>Theory and Proofs B.1. Constructing the causal graphWhen considering classification tasks, there are two viewpoints on whether the features cause the class label, or whether the class labels cause the features.<ref type="bibr" target="#b17">(Gong et al., 2016;</ref><ref type="bibr" target="#b26">Magliacane et al., 2018;</ref><ref type="bibr" target="#b36">Rojas-Carulla et al., 2018)</ref> assume a generative process where the true class label determines the features in the observed data. In contrast,<ref type="bibr" target="#b33">(Peters et al., 2016;</ref><ref type="bibr" target="#b5">Arjovsky et al., 2019)</ref> consider a generative process where the features are used to assign a label, e.g., when manually labelling a set of images. We believe that both mechanisms are possible, depending on the context. In particular, it is plausible that the true class label Y true causes the features, but it is not observed. Instead, what is observed is the output of a manual labelling process, where the features are used to label each input with its class Y.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>B. 5 .</head><label>5</label><figDesc>Proof of Theorem 1 Theorem 1. For a finite number of domains m, as the number of examples in each domain n d ? ?, 1. The set of representations that satisfy the condition ?(j,k)=1;d =d dist(?(x</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>k</head><label></label><figDesc>) for all d, d such that ?(j, k) = 1, where inputs x j and x k correspond to the same object. Let us assume that there exists at least one object o for which the effect of domain is stochastic. That is, due to domain-dependent variation, P (X a = x a |D = d, O = o) &lt; 1. for some d and o. Now consider a pair of inputs x object o such that ?(l, i) = 1, and their corresponding representations are ? a (x (d) l ) and ? a (x (d ) i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>x,y) [l(y, f (x))] = arg min h?F E (d,x,y) [l(y, h(x c ))] = arg min h?F E (x,y) [l(y, h(x c )] = E[Y |X c ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc><ref type="bibr" target="#b5">Arjovsky et al., 2019)</ref>, DRO<ref type="bibr" target="#b37">(Sagawa et al., 2019</ref>), Mixup (Xu et al., 2019 Yan et al., 2020;, MLDG (Li et al., 2018a), CORAL (Sun &amp; Saenko, 2016), MMD (Li et al., 2018b), DANN (Ganin et al., 2016), C-DANN (Li et al., 2018d) are taken from<ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 5 .</head><label>5</label><figDesc>The t-SNE plots for visualizing features learnt in MatchDG Phase 1. (a)-(c) are for Photo as the target domain and (b)-(d) are for Sketch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>, S-MLDG (Li et al., 2020), D-SAM (D'Innocente &amp; Caputo, 2018), MMLD (Matsuura &amp; Harada, 2020), DDAIG (Zhou et al., 2020) SagNet (Nam et al., 2019), DDEC (Asadi et al., 2019), DANN (Ganin et al., 2016), C-DANN (Li et al., 2018d), DRO (Sagawa et al., 2019), Mixup (Xu et al., 2019; Yan et al., 2020; Wang et al., 2020), IRM (Arjovsky et al., 2019), MLDG (Li et al., 2018a), MMD (Li et al., 2018b), CORAL (Sun &amp; Saenko, 2016), were taken from the DomainBed<ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref> paper. For G2DM<ref type="bibr" target="#b3">(Albuquerque et al., 2020a)</ref>,<ref type="bibr" target="#b38">DGER (Zhao et al., 2020)</ref>, CSD<ref type="bibr" target="#b34">(Piratla et al., 2020)</ref>, MASF), EpiFCR (Li et al., 2019a, MetaReg<ref type="bibr" target="#b7">(Balaji et al., 2018)</ref>, RSC<ref type="bibr" target="#b24">(Huang et al., 2020)</ref> it was taken from their respective paper.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Algorithm 1 MatchDGIn: Dataset (di, xi, yi) n i=1 from m domains, ? , t Out: Function f : X ? Y Create random match pairs ?Y . Build a p * q data matrix M. Minimize the loss (3) with learnt match function ? to obtain f .</figDesc><table><row><cell>Phase I</cell></row><row><cell>while notconverged do</cell></row><row><cell>for batch ? M do</cell></row><row><cell>Minimize contrastive loss (4).</cell></row><row><cell>end for</cell></row><row><cell>if epoch % t == 0 then</cell></row><row><cell>Update match pairs using ? epoch .</cell></row><row><cell>end if</cell></row><row><cell>end while</cell></row><row><cell>Phase II</cell></row><row><cell>Compute matching based on ?.</cell></row></table><note>a hyperparameter, B is the batch size, and sim(a</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table /><note>shows classification accuracy on rotMNIST and rotFashionMNIST for test domains 0 ? &amp; 90 ? using Resnet-18 model. On both datasets, MatchDG outper- forms all baselines.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .Table 3 .</head><label>23</label><figDesc>Accuracy for Rotated MNIST &amp; Fashion-MNIST datasets on target domains of 0 ? and 90 ? . Accuracy for CSD<ref type="bibr" target="#b34">(Piratla et al., 2020)</ref>, MASF, IRM are reproduced from their code. Results for the other versions of Rotated MNIST with all test angles (LetNet<ref type="bibr" target="#b29">(Motiian et al., 2017)</ref>, DomainBed<ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref>) are in Suppl. D.1, D.2. Overlap with perfect matches. top-10 overlap and the mean rank for perfect matches for MatchDG and ERM over all training domains. Lower is better for mean rank. For both rotMNIST and rotFashionMNIST datasets, about 50% of the inputs have their perfect match within top-10 ranked matches based on the representation learnt by MatchDG Phase I. About 25% of all matches learnt by MatchDG are perfect matches. For comparison, we also show metrics for an (oracle) MatchDG method that is initialized with perfect matches: it achieves better overall and Top-10 values. Similar results for MatchDG Phase 2 are in Suppl. D.4. Mean rank for rotFashionMNIST may be higher because of the larger sample size 10, 000 per domain; metrics for training with 2000 samples are in Suppl. D.5. To see how the overlap with perfect matches affects accuracy, we simulate random matches with 25%, 50% and 75% overlap with perfect matches (Suppl. Tbl. D.3). Accuracy increases with the fraction of perfect matches, indicating the importance of capturing good matches.</figDesc><table><row><cell cols="2">Dataset Source</cell><cell>ERM</cell><cell>MASF</cell><cell>CSD</cell><cell>IRM</cell><cell>RandMatch MatchDG PerfMatch (Oracle)</cell></row><row><cell>Rotated</cell><cell>15, 30, 45, 60, 75</cell><cell cols="5">93.0 (0.11) 93.2 (0.2) 94.5 (0.35) 92.8 (0.53) 93.4 (0.26) 95.1 (0.25)</cell><cell>96.0 (0.41)</cell></row><row><cell>MNIST</cell><cell cols="6">30, 45, 60 76.2 (1.27) 69.4 (1.32) 77.7 (1.88) 75.7 (1.11) 78.3 (0.55) 83.6 (1.44)</cell><cell>89.7 (1.68)</cell></row><row><cell></cell><cell>30, 45</cell><cell cols="5">59.7 (1.75) 60.8 (1.53) 62.0 (1.31) 59.5 (2.61) 63.8 (3.92) 69.7 (1.30)</cell><cell>80.4 (1.79)</cell></row><row><cell>Rotated Fashion</cell><cell>15, 30, 45, 60, 75</cell><cell cols="5">77.9 (0.13) 72.4 (2.9) 78.7 (0.38) 77.8 (0.02) 77.0 (0.42) 80.9 (0.26)</cell><cell>81.6 (0.46)</cell></row><row><cell>MNIST</cell><cell cols="6">30, 45, 60 36.1 (1.91) 29.7 (1.73) 36.3 (2.65) 37.8 (1.85) 38.4 (2.73) 43.8 (1.33)</cell><cell>54.0 (2.79)</cell></row><row><cell></cell><cell>30, 45</cell><cell cols="5">26.1 (1.10) 22.8 (1.26) 24.2 (1.69) 26.6 (1.06) 26.9 (0.34) 33.0 (0.72)</cell><cell>41.8 (1.78)</cell></row><row><cell cols="2">Dataset Method</cell><cell>Overlap (%)</cell><cell>Top 10 Overlap (%)</cell><cell>Mean Rank</cell><cell></cell></row><row><cell></cell><cell>ERM</cell><cell>15.8 (0.42)</cell><cell>48.8 (0.78)</cell><cell>27.4 (0.89)</cell><cell></cell></row><row><cell>MNIST</cell><cell>MatchDG (Default)</cell><cell>28.9 (1.24)</cell><cell>64.2 (2.42)</cell><cell>18.6 (1.59)</cell><cell></cell></row><row><cell></cell><cell>MatchDG (PerfMatch)</cell><cell>47.4 (2.25)</cell><cell>83.8 (1.46)</cell><cell>6.2 (0.61)</cell><cell></cell></row><row><cell>Fashion MNIST</cell><cell>ERM MatchDG (Default)</cell><cell>2.1 (0.12) 17.9 (0.62)</cell><cell>11.1 (0.63) 43.1 (0.83)</cell><cell>224.3 (8.73) 89.0 (3.15)</cell><cell></cell></row><row><cell></cell><cell>MatchDG (PerfMatch)</cell><cell>56.2 (1.79)</cell><cell>87.2 (1.48)</cell><cell>7.3 (1.18)</cell><cell></cell></row><row><cell cols="5">matches are more consistent with ground-truth perfect</cell><cell></cell></row><row><cell>matches.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .Table 5 .</head><label>45</label><figDesc>Accuracy on PACS with ResNet 18 (default), and Resnet 18 with test domain validation. The results for JiGen,DDAIG (Zhou et al., 2020), SagNet<ref type="bibr" target="#b31">(Nam et al., 2019)</ref>, DDEC<ref type="bibr" target="#b6">(Asadi et al., 2019)</ref>, were taken from the Do-mainBed<ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref> paper. For G2DM<ref type="bibr" target="#b3">(Albuquerque et al., 2020a)</ref>, CSD<ref type="bibr" target="#b34">(Piratla et al., 2020)</ref>, RSC<ref type="bibr" target="#b24">(Huang et al., 2020)</ref> it was taken from the respective paper. Extensive comparison with other works and std. dev. in results is in Supp E.1. Accuracy on PACS with architecture ResNet 50. The results for IRM, CORAL (Sun &amp; Saenko, 2016), were taken from the DomainBed<ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2020)</ref> paper. The result for RSC<ref type="bibr" target="#b24">(Huang et al., 2020)</ref> was taken from their paper. Comparison with other works in Supp E.1. MDGHybrid (ResNet50) 98.36 86.74 82.32 82.66 87.52 art results averaged over all domains. The MDGHybrid has the highest average accuracy across domains, except compared to DDEC and RSC. These works do not disclose their model selection strategy (whether the results are using source or test domain validation). Therefore, we also report results of MatchDG and MDGHybrid using test domain validation, where MDGHybrid obtains comparable results to the best-performing method. In addition, with DDEC (Asadi et al., 2019), it is not a fair comparison since they use additional style transfer data from Behance BAM! dataset during training.</figDesc><table><row><cell></cell><cell>P</cell><cell>A</cell><cell>C</cell><cell>S</cell><cell>Average.</cell></row><row><cell>ERM</cell><cell cols="4">95.38 77.68 78.98 74.75</cell><cell>81.70</cell></row><row><cell>JiGen</cell><cell>96.0</cell><cell cols="3">79.42 75.25 71.35</cell><cell>80.41</cell></row><row><cell>G2DM</cell><cell cols="4">93.75 77.78 75.54 77.58</cell><cell>81.16</cell></row><row><cell>CSD</cell><cell>94.1</cell><cell>78.9</cell><cell>75.8</cell><cell>76.7</cell><cell>81.4</cell></row><row><cell>DDAIG</cell><cell cols="4">95.30 84.20 78.10 74.70</cell><cell>83.10</cell></row><row><cell>SagNet</cell><cell cols="4">95.47 83.58 77.66 76.30</cell><cell>83.25</cell></row><row><cell>DDEC</cell><cell cols="4">96.93 83.01 79.39 78.62</cell><cell>84.46</cell></row><row><cell>RSC</cell><cell cols="4">95.99 83.43 80.31 80.85</cell><cell>85.15</cell></row><row><cell>RandMatch</cell><cell cols="4">95.37 78.16 78.83 75.13</cell><cell>81.87</cell></row><row><cell>MatchDG</cell><cell cols="4">95.93 79.77 80.03 77.11</cell><cell>83.21</cell></row><row><cell>MDGHybrid</cell><cell cols="4">96.15 81.71 80.75 78.79</cell><cell>84.35</cell></row><row><cell>G2DM (Test)</cell><cell cols="4">94.63 81.44 79.35 79.52</cell><cell>83.34</cell></row><row><cell cols="5">RandMatch (Test) 95.57 79.09 79.37 77.60</cell><cell>82.91</cell></row><row><cell>MatchDG (Test)</cell><cell cols="4">96.53 81.32 80.70 79.72</cell><cell>84.56</cell></row><row><cell cols="5">MDGHybrid (Test) 96.67 82.80 81.61 81.05</cell><cell>85.53</cell></row><row><cell></cell><cell>P</cell><cell>A</cell><cell>C</cell><cell>S</cell><cell>Average.</cell></row><row><cell cols="2">DomainBed (ResNet50) 97.8</cell><cell>88.1</cell><cell>77.9</cell><cell>79.1</cell><cell>85.7</cell></row><row><cell>IRM (ResNet50)</cell><cell>96.7</cell><cell>85.0</cell><cell>77.6</cell><cell>78.5</cell><cell>84.4</cell></row><row><cell>CORAL (ResNet50)</cell><cell>97.6</cell><cell>87.7</cell><cell>79.2</cell><cell>79.4</cell><cell>86.0</cell></row><row><cell>RSC (ResNet50)</cell><cell cols="4">97.92 87.89 82.16 83.35</cell><cell>87.83</cell></row><row><cell cols="5">RandMatch (ResNet50) 97.89 82.16 81.68 80.45</cell><cell>85.54</cell></row><row><cell>MatchDG (ResNet50)</cell><cell cols="4">97.94 85.61 82.12 78.76</cell><cell>86.11</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Chest X-Rays data. As an upper bound, training ERM on the target domain itself yields 73.8%, 66.5%, and 59.9% accuracy for RSNA, ChexPert, and NIH respectively.</figDesc><table><row><cell></cell><cell>RSNA</cell><cell>ChexPert</cell><cell>NIH</cell></row><row><cell>ERM</cell><cell cols="3">55.1 (2.93) 60.9 (0.51) 53.4 (1.36)</cell></row><row><cell>IRM</cell><cell cols="3">57.0 (0.75) 63.3 (0.25) 54.6 (0.88)</cell></row><row><cell>CSD</cell><cell cols="3">58.6 (1.63) 64.4 (0.88) 54.7 (0.13)</cell></row><row><cell cols="4">RandMatch 56.3 (3.38) 55.3 (2.25) 53.1 (0.13)</cell></row><row><cell>MatchDG</cell><cell cols="3">58.2 (1.25) 59.0 (0.25) 53.2 (0.65)</cell></row><row><cell cols="4">MDGHybrid 64.3 (0.75) 60.6 (0.25) 57.6 (0.13)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Ilse, M., Tomczak, J. M., Louizos, C., and Welling, M. Diva: Domain invariant variational autoencoders. In Medical Imaging with Deep Learning, pp. 322-348. PMLR, 2020. Irvin, J., Rajpurkar, P., Ko, M., Yu, Y., Ciurea-Ilcus, S., Chute, C., Marklund, H., Haghgoo, B., Ball, R., Shpanskaya, K., et al. Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pp. 590-597, 2019. Yang, Y., Song, Y.-Z., and Hospedales, T. M. Deeper, broader and artier domain generalization. In Proceedings of the IEEE international conference on computer vision, pp. 5542-5550, 2017. Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learning to generalize: Meta-learning for domain generalization. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018a. Li, D., Zhang, J., Yang, Y., Liu, C., Song, Y.-Z., and Hospedales, T. M. Episodic training for domain generalization. In Proceedings of the IEEE International Conference on Computer Vision, pp. 1446-1455, 2019a. Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. Sequential learning for domain generalization. arXiv preprint arXiv:2004.01377, 2020. Li, H., Jialin Pan, S., Wang, S., and Kot, A. C. Domain generalization with adversarial feature learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5400-5409, 2018b. Li, Y., Gong, M., Tian, X., Liu, T., and Tao, D. Domain generalization via conditional invariant representations. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018c. Li, Y., Tian, X., Gong, M., Liu, Y., Liu, T., Zhang, K., and Tao, D. Deep domain generalization via conditional invariant adversarial networks. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 624-639, 2018d. Shah, H., Tamuly, K., Raghunathan, A., Jain, P., and Netrapalli, P. The pitfalls of simplicity bias in neural networks. arXiv preprint arXiv:2006.07710, 2020. Shankar, S., Piratla, V., Chakrabarti, S., Chaudhuri, S., Jyothi, P., and Sarawagi, S. Generalizing across domains via cross-gradient training. In International Conference on Learning Representations, 2018. Sun, B. and Saenko, K. Deep coral: Correlation alignment for deep domain adaptation. In European conference on computer vision, pp. 443-450. Springer, 2016. Advances in Neural Information Processing Systems, 33, 2020. Zhou, K., Yang, Y., Hospedales, T. M., and Xiang, T. Deep domain-adversarial image generation for domain generalisation. In AAAI, pp. 13025-13032, 2020.</figDesc><table><row><cell>Johansson, F. D., Sontag, D., and Ranganath, R. Support and</cell></row><row><cell>invertibility in domain-invariant representations. In The</cell></row><row><cell>22nd International Conference on Artificial Intelligence and Statistics, pp. 527-536, 2019. Krueger, D., Caballero, E., Jacobsen, J.-H., Zhang, A., Bi-nas, J., Priol, R. L., and Courville, A. Out-of-distribution generalization via risk extrapolation (rex). arXiv preprint arXiv:2003.00688, 2020. V., and Savarese, S. Generalizing to unseen domains via adversarial data augmentation. In Advances in Neural Li, D., Volpi, R., Namkoong, H., Sener, O., Duchi, J. C., Murino, Information Processing Systems, pp. 5334-5344, 2018.</cell></row></table><note>Li, Y., Yang, Y., Zhou, W., and Hospedales, T. M. Feature- critic networks for heterogeneous domain generalization. arXiv preprint arXiv:1901.11448, 2019b.Wang, H., He, Z., Lipton, Z. C., and Xing, E. P. Learning robust representations by projecting superficial statistics out. arXiv preprint arXiv:1903.06256, 2019. Wang, X., Peng, Y., Lu, L., Lu, Z., Bagheri, M., and Sum- mers, R. M. Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classi- fication and localization of common thorax diseases. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2097-2106, 2017. Wang, Y., Li, H., and Kot, A. C. Heterogeneous domain generalization via domain mixup. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 3622-3626. IEEE, 2020. Xu, M., Zhang, J., Ni, B., Li, T., Wang, C., Tian, Q., and Zhang, W. Adversarial domain adaptation with domain mixup. arXiv preprint arXiv:1912.01805, 2019. Yan, S., Song, H., Li, N., Zou, L., and Ren, L. Improve un- supervised domain adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020. Zhao, H., Combes, R. T. d., Zhang, K., and Gordon, G. J. On learning invariant representation for domain adaptation. arXiv preprint arXiv:1901.09453, 2019. Zhao, S., Gong, M., Liu, T., Fu, H., and Tao, D. Domain generalization via entropy regularization.A. Synthetic Data (Slab Dataset and Simple Counter-example)A.1. Implementation Details for the Slab Dataset</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 .</head><label>7</label><figDesc>Hyper parameter selection details for the slab dataset. We mention the Optimal Value for each hyper parameter and the Range used for grid search. We leave the optimal value for Epochs as blank since we do early stopping based on the validation loss, with the total number of epochs for each model as 100.</figDesc><table><row><cell>Method</cell><cell>Hyper Parameter</cell><cell>Optimal Value</cell><cell>Range</cell></row><row><cell></cell><cell>Lambda</cell><cell>0.01</cell><cell>[0.01, 0.1, 1.0, 10.0, 100.0]</cell></row><row><cell>DANN</cell><cell>Gradient Penalty</cell><cell>0.1</cell><cell>[0.01, 0.1, 1.0, 10.0]</cell></row><row><cell></cell><cell>Discriminator Steps</cell><cell>4</cell><cell>[1, 2, 4, 8]</cell></row><row><cell></cell><cell>Lambda</cell><cell>0.01</cell><cell>[0.01, 0.1, 1.0, 10.0, 100.0]</cell></row><row><cell>CDANN</cell><cell>Gradient Penalty</cell><cell>1.0</cell><cell>[0.01, 0.1, 1.0, 10.0]</cell></row><row><cell></cell><cell>Discriminator Steps</cell><cell>2</cell><cell>[1, 2, 4, 8]</cell></row><row><cell>MMD</cell><cell>Lambda</cell><cell>0.1</cell><cell>[0.1, 1.0, 10.0]</cell></row><row><cell>C-MMD</cell><cell>Lambda</cell><cell>0.1</cell><cell>[0.1, 1.0, 10.0]</cell></row><row><cell>CORAL</cell><cell>Lambda</cell><cell>0.1</cell><cell>[0.1, 1.0, 10.0]</cell></row><row><cell>C-CORAL</cell><cell>Lambda</cell><cell>0.1</cell><cell>[0.1, 1.0, 10.0]</cell></row><row><cell cols="2">RandMatch Lambda</cell><cell>1.0</cell><cell>[0.1, 1.0, 10.0]</cell></row><row><cell>PerfMatch</cell><cell>Lambda</cell><cell>1.0</cell><cell>[0.1, 1.0, 10.0]</cell></row></table><note>? FC layer: (100, Num Classes)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 .</head><label>8</label><figDesc>Hyper parameter selection details for all the datasets. We mention the Optimal Value for each hyper parameter and the Range used for grid search. We leave the optimal value for Epochs as blank since we do early stopping based on validation loss, with the total number of epochs for model training specified in the Range column. For the dataset PACS, since the optimal values differ for different test domains, we represent them separately inTable 10</figDesc><table><row><cell>Dataset</cell><cell>Hyper Parameter</cell><cell>Optimal Value</cell><cell>Range</cell></row><row><cell>Rotated &amp; Fashion MNIST Table 2 (ResNet-18)</cell><cell>Total Epochs Learning Rate Batch Size</cell><cell>-0.01 16</cell><cell>25 [0.01] [16]</cell></row><row><cell></cell><cell>Weight Decay</cell><cell>0.0005</cell><cell>[0.0005]</cell></row><row><cell></cell><cell>Match Penalty</cell><cell>0.1</cell><cell>[0.1, 1.0]</cell></row><row><cell></cell><cell>IRM Penalty</cell><cell>1.0 (RotMNIST); 0.05 (FashionMNIST)</cell><cell>[0.05, 0.1, 0.5, 1.0, 5.0]</cell></row><row><cell></cell><cell>IRM Threshold</cell><cell>5 (RotMNIST), 0 (FashionMNIST)</cell><cell>[0, 5, 15, 20]</cell></row><row><cell>Rotated MNIST Table 11 (LeNet)</cell><cell>Total Epochs Learning Rate Batch Size</cell><cell>-0.01 16</cell><cell>100 [0.01] [16]</cell></row><row><cell></cell><cell>Weight Decay</cell><cell>0.0005</cell><cell>[0.0005]</cell></row><row><cell></cell><cell>Match Penalty</cell><cell>1.0</cell><cell>[0.1, 1.0]</cell></row><row><cell>Rotated MNIST Table 12 (DomainBed)</cell><cell>Total Epochs Learning Rate Batch Size</cell><cell>-0.01 128</cell><cell>25 [0.01] [16, 32, 64, 128]</cell></row><row><cell></cell><cell>Weight Decay</cell><cell>0.0005</cell><cell>[0.0005]</cell></row><row><cell></cell><cell>Match Penalty</cell><cell>1.0</cell><cell>[0.1, 1.0]</cell></row><row><cell>PACS</cell><cell>Total Epochs</cell><cell>-</cell><cell>50</cell></row><row><cell>Table 17, 18</cell><cell>Learning Rate</cell><cell>Table 10</cell><cell>[0.01, 0.001, 0.0005]</cell></row><row><cell>(ResNet-18, ResNet-50, AlexNet)</cell><cell>Batch Size</cell><cell>16</cell><cell>[16]</cell></row><row><cell></cell><cell>Weight Decay</cell><cell>0.0005</cell><cell>[0.0005]</cell></row><row><cell></cell><cell>Match Penalty</cell><cell>Table 10</cell><cell>[0.01, 0.1, 0.5, 1.0, 5.0]</cell></row><row><cell>Chest X-ray Table 6 (DenseNet-121)</cell><cell>Total Epochs Learning Rate Batch Size</cell><cell>-0.001 16</cell><cell>40 [0.01, 0.001] [16]</cell></row><row><cell></cell><cell>Weight Decay</cell><cell>0.0005</cell><cell>[0.0005]</cell></row><row><cell></cell><cell>Match Penalty</cell><cell>10.0 (RandMatch), 50.0 (MatchDG, MDGHybrid)</cell><cell>[0.1, 1.0, 10.0, 50.0]</cell></row><row><cell></cell><cell>IRM Penalty</cell><cell>10.0</cell><cell>[0.1, 1.0, 10.0, 50.0]</cell></row><row><cell></cell><cell>IRM Threshold</cell><cell>5</cell><cell>[0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell>Total Epochs</cell><cell>50</cell></row><row><cell></cell><cell>Learning Rate</cell><cell>0.01</cell></row><row><cell></cell><cell>Batch Size</cell><cell>64 (Table 2), 512 (Table 11, Table 12)</cell></row><row><cell>, 11, 12</cell><cell>Weight Decay</cell><cell>0.0005</cell></row><row><cell></cell><cell>?</cell><cell>0.05</cell></row><row><cell></cell><cell>Architecture</cell><cell>ResNet-18</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 17</head><label>17</label><figDesc></figDesc><table><row><cell></cell><cell>Total Epochs</cell><cell>50</cell></row><row><cell></cell><cell>Learning Rate</cell><cell>0.01</cell></row><row><cell></cell><cell>Batch Size</cell><cell>32</cell></row><row><cell>, 18</cell><cell>Weight Decay</cell><cell>0.0005</cell></row><row><cell></cell><cell>?</cell><cell>0.05</cell></row><row><cell></cell><cell>Architecture</cell><cell>ResNet-50</cell></row><row><cell></cell><cell>Total Epochs</cell><cell>50</cell></row><row><cell></cell><cell>Learning Rate</cell><cell>0.01</cell></row><row><cell>Chest X-ray</cell><cell>Batch Size</cell><cell>32</cell></row><row><cell>Table 6</cell><cell>Weight Decay</cell><cell>0.0005</cell></row><row><cell></cell><cell>?</cell><cell>0.05</cell></row><row><cell></cell><cell>Architecture</cell><cell>DenseNet-121</cell></row><row><cell cols="2">access to the data points from the target/test domains at the</cell><cell></cell></row><row><cell>time of training and validation.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 .</head><label>10</label><figDesc>Optimal values for hyper parameters on PACS. Batch Size (16), Weight Decay (0.0005) was consistent across different cases. The Match Penalty for the method MDGHybrid corresponds to (MatchDG penalty, PerfMatch penalty).</figDesc><table><row><cell cols="3">Architecture Hyper Parameter Test Domain ERM</cell><cell cols="3">RandMatch MatchDG(Phase 2) MDGHybrid</cell></row><row><cell></cell><cell>Photo</cell><cell>0.001</cell><cell>0.001</cell><cell>0.0005</cell><cell>0.0005</cell></row><row><cell>Learning Rate</cell><cell>Art Painting Cartoon</cell><cell>0.01 0.01</cell><cell>0.01 0.001</cell><cell>0.001 0.001</cell><cell>0.001 0.001</cell></row><row><cell>ResNet-18</cell><cell>Sketch</cell><cell>0.01</cell><cell>0.01</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>Table 4, 17</cell><cell>Photo</cell><cell>0</cell><cell>5.0</cell><cell>1.0</cell><cell>(0.1, 0.1)</cell></row><row><cell>Match Penalty</cell><cell>Art Painting Cartoon</cell><cell>0 0</cell><cell>0.1 5.0</cell><cell>5.0 1.0</cell><cell>(0.01, 0.1) (0.1, 0.1)</cell></row><row><cell></cell><cell>Sketch</cell><cell>0</cell><cell>0.5</cell><cell>0.5</cell><cell>(0.01, 0.1)</cell></row><row><cell></cell><cell>Photo</cell><cell cols="2">0.0005 0.0005</cell><cell>0.0005</cell><cell>0.0005</cell></row><row><cell>Learning Rate</cell><cell>Art Painting Cartoon</cell><cell>0.01 0.01</cell><cell>0.01 0.01</cell><cell>0.001 0.001</cell><cell>0.001 0.0005</cell></row><row><cell>ResNet-50</cell><cell>Sketch</cell><cell>0.01</cell><cell>0.01</cell><cell>0.0005</cell><cell>0.001</cell></row><row><cell>Table 5, 17</cell><cell>Photo</cell><cell>0</cell><cell>5.0</cell><cell>0.01</cell><cell>(0.1, 0.1)</cell></row><row><cell>Match Penalty</cell><cell>Art Painting Cartoon</cell><cell>0 0</cell><cell>0.1 0.01</cell><cell>0.1 0.01</cell><cell>(0.01, 0.1) (0.01, 0.1)</cell></row><row><cell></cell><cell>Sketch</cell><cell>0</cell><cell>0.1</cell><cell>5.0</cell><cell>(0.01, 0.1)</cell></row><row><cell>AlexNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>? , 15 ? , 30 ? , 45 ? , 60 ? , 75 ? ). For each test domain, the remaining five domains are used as source training domains. We observe that matching-based training methods RandMatch and MatchDG outperform prior work on the all the domains except the test domain 0, where MatchDG is competitive to the best performing approach DIVA. They also achieve accuracy almost equal to the oracle case PerfMatch for target angles (15 ? to 60 ? ) that lie in between the source domains.</figDesc><table><row><cell></cell><cell>Photo</cell><cell cols="2">0.0005 0.0005</cell><cell>0.0005</cell><cell>0.0005</cell></row><row><cell>Learning Rate</cell><cell>Art Painting Cartoon</cell><cell>0.001 0.001</cell><cell>0.001 0.001</cell><cell>0.001 0.001</cell><cell>0.001 0.001</cell></row><row><cell></cell><cell>Sketch</cell><cell cols="2">0.0005 0.001</cell><cell>0.001</cell><cell>0.001</cell></row><row><cell>Table 18</cell><cell>Photo</cell><cell>0</cell><cell>0.1</cell><cell>0.1</cell><cell>(0.1, 0.1)</cell></row><row><cell>Match Penalty</cell><cell>Art Painting Cartoon</cell><cell>0 0</cell><cell>0.1 0.5</cell><cell>1.0 1.0</cell><cell>(0.01, 0.1) (0.01, 0.1)</cell></row><row><cell></cell><cell>Sketch</cell><cell>0</cell><cell>0.5</cell><cell>0.1</cell><cell>(0.01, 0.1)</cell></row><row><cell>(0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>D.2. Comparing MatchDG on Domain Bed Benchmark</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 12</head><label>12</label><figDesc>compares the accuracy results for MatchDG with prior work on the setup proposed by<ref type="bibr" target="#b19">(Gulrajani &amp; Lopez- Paz, 2020)</ref>. This setup is similar to the setup in the section D.1, however, it uses a custom CNN architecture and all the 70, 000 images for each domain. For a fair comparison, we use the same custom CNN architecture for learning the match function during the MatchDG Phase-I.</figDesc><table><row><cell>Even un-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 9</head><label>9</label><figDesc>in (Shankar et al., 2018). The results for DIVA (Ilse et al., 2020) are taken from theTable 1 in their paper.</figDesc><table><row><cell>Algorithm</cell><cell>0</cell><cell>15</cell><cell>30</cell><cell>45</cell><cell>60</cell><cell>75</cell><cell>Average</cell></row><row><cell>ERM</cell><cell cols="6">88.2 (1.0) 98.6 (0.5) 97.7 (0.6) 97.5 (0.3) 97.0 (0.1) 85.6 (2.1)</cell><cell>94.1</cell></row><row><cell>CCSA</cell><cell>84.6</cell><cell>95.6</cell><cell>94.6</cell><cell>82.9</cell><cell>94.8</cell><cell>82.1</cell><cell>89.1</cell></row><row><cell>D-MTAE</cell><cell>82.5</cell><cell>96.3</cell><cell>93.4</cell><cell>78.6</cell><cell>94.2</cell><cell>80.5</cell><cell>87.6</cell></row><row><cell>LabelGrad</cell><cell>89.7</cell><cell>97.8</cell><cell>98.0</cell><cell>97.1</cell><cell>96.6</cell><cell>92.1</cell><cell>95.2</cell></row><row><cell>DAN</cell><cell>86.7</cell><cell>98.0</cell><cell>97.8</cell><cell>97.4</cell><cell>96.9</cell><cell>89.1</cell><cell>94.3</cell></row><row><cell>CrossGrad</cell><cell>88.3</cell><cell>98.6</cell><cell>98.0</cell><cell>97.7</cell><cell>97.7</cell><cell>91.4</cell><cell>95.3</cell></row><row><cell>DIVA</cell><cell cols="6">93.5 (0.3) 99.3 (0.1) 99.1 (0.1) 99.2 (0.1) 99.3 (0.1) 93.0 (0.4)</cell><cell>97.2</cell></row><row><cell cols="7">RandMatch 91.0 (0.9) 99.7 (0.2) 99.6 (0.1) 99.4 (0.1) 99.7 (0.1) 93.1 (1.1)</cell><cell>97.1</cell></row><row><cell>MatchDG</cell><cell cols="6">93.0 (0.5) 99.5 (0.3) 99.9 (0.1) 99.4 (0.1) 99.7 (0.3) 93.3 (1.1)</cell><cell>97.4</cell></row><row><cell cols="7">PerfMatch 96.5 (0.6) 99.1 (0.3) 99.2 (0.3) 98.6 (0.7) 98.6 (1.0) 94.9 (1.8)</cell><cell>97.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 13 .</head><label>13</label><figDesc>Accuracy</figDesc><table><row><cell>during training</cell><cell cols="2">results using a fraction of perfect matches</cell><cell>D.5. Matching metrics for Fashion-MNIST dataset with 2000 training samples per domain</cell></row><row><cell></cell><cell>MNIST</cell><cell>Fashion-MNIST</cell><cell>In the main text (Table 3), we computed matching metrics</cell></row><row><cell>RandMatch</cell><cell>93.4 (0.26)</cell><cell>77.0 (0.42)</cell><cell>for MatchDG (Phase 1) over the Fashion-MNIST dataset with 10000 samples per domain. Here we compute the same</cell></row><row><cell>Approx 25%</cell><cell>93.8 (0.48)</cell><cell>77.8 (0.79)</cell><cell>metrics for a smaller dataset with 2000 samples per domain.</cell></row><row><cell>Approx 50%</cell><cell>94.0 (0.42)</cell><cell>78.0 (0.78)</cell><cell></cell></row><row><cell>Approx 75%</cell><cell>94.7 (0.14)</cell><cell>78.9 (0.31)</cell><cell></cell></row><row><cell cols="2">PerfMatch (100%) 96.0 (0.41)</cell><cell>81.6 (0.46)</cell><cell></cell></row><row><cell cols="3">MNIST and Fashion-MNIST datasets, MatchDG ob-</cell><cell></cell></row><row><cell cols="3">tains mean rank, Top 10 overlap and total overlap be-</cell><cell></cell></row><row><cell cols="3">tween ERM-PerfMatch and ERM-RandMatch. As the</cell><cell></cell></row><row><cell cols="3">Fashion-MNIST dataset is more complex than the digits</cell><cell></cell></row><row><cell cols="3">dataset, we observe that the mean rank with different train-</cell><cell></cell></row><row><cell cols="3">ing techniques is higher than the corresponding values for</cell><cell></cell></row><row><cell cols="2">the Rotated-MNIST dataset.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 14 .</head><label>14</label><figDesc>Mean rank, Top-10 overlap, and overlap metrics for the matches learnt in the classification phase (Phase 2), when trained on all five source domains in the Rotated MNIST and FashionM-NIST datasets.</figDesc><table><row><cell>Dataset</cell><cell>Method</cell><cell cols="2">Overlap (%) Top 10 Overlap (%)</cell><cell>Mean Rank</cell></row><row><cell>Rotated MNIST</cell><cell>RandMatch MatchDG (Phase 2)</cell><cell>2.2 (0.18) 17.7 (0.97)</cell><cell>13.5 (0.36) 41.8 (2.89)</cell><cell>75.5 (1.65) 39.6 (3.58)</cell></row><row><cell></cell><cell>PerfMatch (Oracle)</cell><cell>78.2 (1.91)</cell><cell>95.5 (1.37)</cell><cell>1.84 (0.67)</cell></row><row><cell>Fashion MNIST (10k)</cell><cell>RandMatch MatchDG (Phase 2)</cell><cell>0.5 (0.04) 1.8 (0.13)</cell><cell>3.2 (0.17) 8.5 (0.56)</cell><cell>420.0 (7.27) 296.5 (9.94)</cell></row><row><cell></cell><cell>PerfMatch (Oracle)</cell><cell>9.2 (0.21)</cell><cell>30.5 (0.38)</cell><cell>114.7 (3.29)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 15 .</head><label>15</label><figDesc>Metrics computed at MatchDG (Phase 1) for Fashion-MNIST dataset with 2K and 10K sample size used for training. Lower is better for mean rank.</figDesc><table><row><cell>Dataset</cell><cell>Method</cell><cell cols="3">Overlap (%) Top 10 Overlap (%) Mean Rank</cell></row><row><cell>Fashion MNIST (2k)</cell><cell>ERM MatchDG (Default)</cell><cell>8.7 (0.14) 38.5 (2.11)</cell><cell>36.0 (1.41) 71.2 (0.91)</cell><cell>36.1 (1.66) 15.9 (0.54)</cell></row><row><cell></cell><cell>MatchDG (PerfMatch)</cell><cell>69.5 (10.8)</cell><cell>91.9 (5.8)</cell><cell>3.3 (2.4)</cell></row><row><cell>Fashion MNIST (10k)</cell><cell>ERM MatchDG (Default)</cell><cell>2.1 (0.12) 17.9 (0.62)</cell><cell>11.1 (0.63) 43.1 (0.83)</cell><cell>224.3 (8.73) 89.0 (3.15)</cell></row><row><cell></cell><cell>MatchDG (PerfMatch)</cell><cell>56.2 (1.79)</cell><cell>87.2 (1.48)</cell><cell>7.3 (1.18)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 16 .</head><label>16</label><figDesc>Overlap with perfect matches, top-10 overlap and the mean rank for perfect matches for Iterative and Non Iterative MatchDG over all training domains. Lower is better for mean rank.</figDesc><table><row><cell>Dataset</cell><cell cols="4">Method (Phase 1) Overlap (%) Top 10 Overlap (%) Mean Rank</cell></row><row><cell>MNIST</cell><cell>MatchDG (Iterative) MatchDG (Non Iterative)</cell><cell>28.9 (1.24) 12.3 (0.28)</cell><cell>64.2 (2.42) 37.9 (0.27)</cell><cell>18.6 (1.59) 37.8 (0.47)</cell></row><row><cell>Fashion</cell><cell>MatchDG (Iterative)</cell><cell>17.9 (0.62)</cell><cell>43.1 (0.83)</cell><cell>89.0 (3.15)</cell></row><row><cell>MNIST (10k)</cell><cell>MatchDG (Non Iterative)</cell><cell>7.7 (0.28)</cell><cell>23.8 (0.78)</cell><cell>153.9 (9.63)</cell></row><row><cell cols="4">E. Additional Evaluation on PACS</cell><cell></cell></row><row><cell cols="2">E.1. ResNet Results</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Table 17 extends the evaluation on PACS with ResNet-</cell></row><row><cell cols="2">18, ResNet-50</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 18</head><label>18</label><figDesc>shows that both RandMatch and MatchDG outperform the baseline ERM method. Averaging over the test domains, MDGHybrid provides improvement over MatchDG (70.46 versus 69.91). Moreover, on average MatchDG, MDGHybrid are better than many previous approaches D-MTAE (Ghifary et al., 2015), DBADG (Li et al., 2017), CIDDG (Li et al., 2018d), HEX (Wang et al., 2019) and FeatureCritic (Li et al., 2019b), but some other methods like MASF (Dou et al., 2019), DGER (Zhao et al., 2020), RSC</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 17 .</head><label>17</label><figDesc>Accuracy on PACS with ResNet 18 (default, top row set), Resnet 18 with test domain validation (middle row set), and ResNet 50 (bottom row set). The results for JiGen</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head></head><label></label><figDesc>MDGHybrid (ResNet50) 98.36 (0.06) 86.74 (1.01) 82.32 (0.76) 82.66 (0.48) 87.52</figDesc><table><row><cell></cell><cell>P</cell><cell>A</cell><cell>C</cell><cell>S</cell><cell>Average.</cell></row><row><cell>ERM</cell><cell cols="4">95.38 (0.86) 77.68 (0.35) 78.98 (0.59) 74.75 (1.70)</cell><cell>81.70</cell></row><row><cell>JiGen</cell><cell>96.0</cell><cell>79.42</cell><cell>75.25</cell><cell>71.35</cell><cell>80.41</cell></row><row><cell>MASF</cell><cell cols="4">94.99 (0.09) 80.29 (0.18) 77.17 (0.08) 71.69 (0.22)</cell><cell>81.04</cell></row><row><cell>G2DM</cell><cell>93.75</cell><cell>77.78</cell><cell>75.54</cell><cell>77.58</cell><cell>81.16</cell></row><row><cell>DGER</cell><cell cols="4">96.65 (0.21) 80.70 (0.71) 76.40 (0.34) 71.77 (1.27)</cell><cell>81.38</cell></row><row><cell>CSD</cell><cell>94.1 (0.2)</cell><cell>78.9 (1.1)</cell><cell>75.8 (1.0)</cell><cell>76.7 (1.2)</cell><cell>81.4</cell></row><row><cell>EpiFCR</cell><cell>93.9</cell><cell>82.1</cell><cell>77.0</cell><cell>73.0</cell><cell>81.5</cell></row><row><cell>MetaReg</cell><cell>95.5 (0.24)</cell><cell>83.7 (0.19)</cell><cell>77.2 (0.31)</cell><cell>70.3 (0.28)</cell><cell>81.7</cell></row><row><cell>S-MLDG</cell><cell>94.80</cell><cell>80.50</cell><cell>77.80</cell><cell>72.80</cell><cell>81.50</cell></row><row><cell>D-SAM</cell><cell>94.30</cell><cell>79.48</cell><cell>77.13</cell><cell>75.30</cell><cell>81.55</cell></row><row><cell>MMLD</cell><cell>96.09</cell><cell>81.28</cell><cell>77.16</cell><cell>72.29</cell><cell>81.83</cell></row><row><cell>DDAIG</cell><cell>95.30</cell><cell>84.20</cell><cell>78.10</cell><cell>74.70</cell><cell>83.10</cell></row><row><cell>SagNet</cell><cell>95.47</cell><cell>83.58</cell><cell>77.66</cell><cell>76.30</cell><cell>83.25</cell></row><row><cell>DDEC</cell><cell>96.93</cell><cell>83.01</cell><cell>79.39</cell><cell>78.62</cell><cell>84.46</cell></row><row><cell>RSC</cell><cell>95.99</cell><cell>83.43</cell><cell>80.31</cell><cell>80.85</cell><cell>85.15</cell></row><row><cell>RandMatch</cell><cell cols="4">95.37 (0.25) 78.16 (1.51) 78.83 (1.18) 75.13 (1.90)</cell><cell>81.87</cell></row><row><cell>MatchDG</cell><cell cols="4">95.93 (0.21) 79.77 (0.12) 80.03 (0.03) 77.11 (0.35)</cell><cell>83.21</cell></row><row><cell>MDGHybrid</cell><cell cols="4">96.15 (0.40) 81.71 (0.75) 80.75 (0.50) 78.79 (1.25)</cell><cell>84.35</cell></row><row><cell>G2DM (Test)</cell><cell>94.63</cell><cell>81.44</cell><cell>79.35</cell><cell>79.52</cell><cell>83.34</cell></row><row><cell>RandMatch (Test)</cell><cell cols="4">95.57 (0.17) 79.09 (1.09) 79.37 (0.89) 77.60 (0.87)</cell><cell>82.91</cell></row><row><cell>MatchDG (Test)</cell><cell cols="4">96.53 (0.05) 81.32 (0.38) 80.70 (0.54) 79.72 (1.01)</cell><cell>84.56</cell></row><row><cell>MDGHybrid (Test)</cell><cell cols="4">96.67 (0.20) 82.80 (0.32) 81.61 (0.06) 81.05 (1.01)</cell><cell>85.53</cell></row><row><cell>DomainBed (ResNet50)</cell><cell>97.8 (0.0)</cell><cell>88.1 (0.1)</cell><cell>77.9 (1.3)</cell><cell>79.1 (0.9)</cell><cell>85.7</cell></row><row><cell>MASF (ResNet50)</cell><cell cols="4">95.01 (0.10) 82.89 (0.16) 80.49 (0.21) 72.29 (0.15)</cell><cell>82.67</cell></row><row><cell>C-DANN (ResNet50)</cell><cell>97.0 (0.4)</cell><cell>84.0 (0.9)</cell><cell>78.5 (1.5)</cell><cell>71.8 (3.9)</cell><cell>82.8</cell></row><row><cell>MetaReg (ResNet50)</cell><cell>97.6 (0.31)</cell><cell>87.2 (0.13)</cell><cell>79.2 (0.27)</cell><cell>70.3 (0.18)</cell><cell>83.6</cell></row><row><cell>DRO (ResNet50)</cell><cell>98.0 (0.3)</cell><cell>86.4 (0.3)</cell><cell>79.9 (0.8)</cell><cell>72.1 (0.7)</cell><cell>84.1</cell></row><row><cell>Mixup (ResNet50)</cell><cell>97.7 (0.2)</cell><cell>86.5 (0.4)</cell><cell>76.6 (1.5)</cell><cell>76.5 (1.2)</cell><cell>84.3</cell></row><row><cell>IRM (ResNet50)</cell><cell>96.7 (0.3)</cell><cell>85.0 (1.6)</cell><cell>77.6 (0.9)</cell><cell>78.5 (2.6)</cell><cell>84.4</cell></row><row><cell>DANN (ResNet50)</cell><cell>97.6 (0.2)</cell><cell>85.9 (0.5)</cell><cell>79.9 (1.4)</cell><cell>75.2 (2.8)</cell><cell>84.6</cell></row><row><cell>MLDG (ResNet50)</cell><cell>97.0 (0.9)</cell><cell>89.1 (0.9)</cell><cell>78.8 (0.7)</cell><cell>74.4 (2.0)</cell><cell>84.8</cell></row><row><cell>MMD (ResNet50)</cell><cell>97.5 (0.4)</cell><cell>84.5 (0.6)</cell><cell>79.7 (0.7)</cell><cell>78.1 (1.3)</cell><cell>85.0</cell></row><row><cell>DGER</cell><cell cols="4">98.25 (0.12) 87.51 (1.03) 79.31 (1.40) 76.30 (0.65)</cell><cell>85.34</cell></row><row><cell>CORAL (ResNet50)</cell><cell>97.6 (0.0)</cell><cell>87.7 (0.6)</cell><cell>79.2 (1.1)</cell><cell>79.4 (0.7)</cell><cell>86.0</cell></row><row><cell>RSC (ResNet50)</cell><cell>97.92</cell><cell>87.89</cell><cell>82.16</cell><cell>83.35</cell><cell>87.83</cell></row><row><cell cols="5">RandMatch (ResNet50) 97.89 (0.11 ) 82.16 (0.19) 81.68 (0.45) 80.45 (0.19)</cell><cell>85.54</cell></row><row><cell>MatchDG (ResNet50)</cell><cell cols="4">97.94 (0.27) 85.61 (0.81) 82.12 (0.69) 78.76 (1.13)</cell><cell>86.11</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Microsoft Research, India 2 Microsoft Research, UK.. Correspondence to: Divyat Mahajan &lt;divyatmahajan@gmail.com&gt;.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. We would like to thank Adith Swaminathan, Aditya Nori, Emre Kiciman, Praneeth Netrapalli, Tobias Schnabel, Vineeth Balasubramanian and the reviewers who provided us valuable feedback on this work. We also thank Vihari Piratla who helped us with reproducing the CSD method and other baselines.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Kaggle: Rsna pneumonia detection challenge</title>
		<ptr target="https://www.kaggle.com/c/rsna-pneumonia-detection-challenge" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Invariant risk minimization games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dhurandhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.04692</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adversarial invariant feature learning with accuracy constraint for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Akuzawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Iwasawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="315" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Generalizing to unseen domains via distribution matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Darvishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mitliagkas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Improving out-of-distribution generalization via multi-task self-supervised pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.13525</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">D. Invariant risk minimization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Towards shape biased unsupervised representation learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Sarfi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hosseinzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Karimpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eftekhari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.08245</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards domain generalization using meta-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Metareg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="998" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2229" to="2238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A causal framework for distribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Jakobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gnecco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">2006</biblScope>
		</imprint>
	</monogr>
	<note>arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">On the limits of cross-domain generalization in automated x-ray prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hashir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bertrand</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.02497</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Domain generalization via model-agnostic learning of semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>De Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6447" to="6458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Domain generalization with domain-specific aggregation modules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="187" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2551" to="2559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scatter component analysis: A unified framework for domain adaptation and domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1414" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Domain adaptation with conditional transferable components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2839" to="2848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<title level="m">Explaining and harnessing adversarial examples</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.01434</idno>
		<title level="m">search of lost domain generalization</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.05722</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heinze-Deml</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Meinshausen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.11469</idno>
		<title level="m">Conditional variance penalties and domain shift robustness</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Domain generalization via multidomain discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in artificial intelligence: proceedings of the</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<publisher>NIH Public Access</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Selfchallenging improves cross-domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02454</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Domain adaptation by using causal inference to predict invariant conditional distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Magliacane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Ommen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Claassen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bongers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Versteeg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10846" to="10856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Domain generalization using a mixture of multiple latent domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Matsuura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11749" to="11756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On loss functions which minimize to conditional expected values and posterior probabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1404" to="1408" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5715" to="5725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Reducing domain gap via style-agnostic networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yoo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.11645</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Causality</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Causal inference by using invariant prediction: identification and confidence intervals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>B?hlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="947" to="1012" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Efficient domain generalization via common-specific low-rank decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Netrapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference of Machine Learning (ICML) 2020</title>
		<meeting>the International Conference of Machine Learning (ICML) 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Correlation-aware adversarial domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baktashmotlagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sridharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page">107124</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Invariant models for causal transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rojas-Carulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1309" to="1342" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.08731</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The results for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dbadg (li</surname></persName>
			<affiliation>
				<orgName type="collaboration">RSC</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">Table 18. Accuracy results on the PACS dataset trained with Alexnet (default, top row set), and Alexnet with test domain validation (bottom row set)</title>
		<meeting><address><addrLine>REx</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
	<note>MetaReg (Balaji. Huang et al., 2020) were taken from the respective paper</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Method/Test Domain Photo Art Painting Cartoon Sketch Average</title>
		<idno>ERM 85.29 (0.22) 64.23 (0.18) 66.61 (0.88) 59.25 (0.83</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Randmatch</surname></persName>
		</author>
		<idno>Test) 86.04 (0.47) 67.35 (0.32) 69.71 (0.56) 64.66 (1.08) 71.94</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matchdg</surname></persName>
		</author>
		<idno>Test) 86.52 (0.43) 67.99 (0.56) 69.92 (0.09) 65.64 (1.48) 72.52</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mdghybrid</surname></persName>
		</author>
		<idno>Test) 87.03 (0.29) 67.97 (0.79) 71.06 (0.43) 67.19 (0.44) 73.31</idno>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
