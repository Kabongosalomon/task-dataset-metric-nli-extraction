<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SimPLE: Similar Pseudo Label Exploitation for Semi-Supervised Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>Hu</surname></persName>
							<email>zijianhu@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyu</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuefeng</forename><surname>Hu</surname></persName>
							<email>xuefengh@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ram</forename><surname>Nevatia</surname></persName>
							<email>nevatia@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SimPLE: Similar Pseudo Label Exploitation for Semi-Supervised Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A common classification task situation is where one has a large amount of data available for training, but only a small portion is annotated with class labels. The goal of semi-supervised training, in this context, is to improve classification accuracy by leverage information not only from labeled data but also from a large amount of unlabeled data. Recent works [2, 1, 26] have developed significant improvements by exploring the consistency constrain between differently augmented labeled and unlabeled data. Following this path, we propose a novel unsupervised objective that focuses on the less studied relationship between the high confidence unlabeled data that are similar to each other. The new proposed Pair Loss minimizes the statistical distance between high confidence pseudo labels with similarity above a certain threshold. Combining the Pair Loss with the techniques developed by the MixMatch family <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b25">26]</ref>, our proposed SimPLE algorithm shows significant performance gains over previous algorithms on CIFAR-100 and Mini-ImageNet <ref type="bibr" target="#b30">[31]</ref>, and is on par with the state-of-the-art methods on CIFAR-10 and SVHN. Furthermore, SimPLE also outperforms the state-of-the-art methods in the transfer learning setting, where models are initialized by the weights pre-trained on ImageNet <ref type="bibr" target="#b14">[15]</ref> or DomainNet-Real[23]. The code is available at github.com/zijian-hu/SimPLE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep learning has recently achieved state-of-the-art performance on many computer vision tasks. One major factor in the success of deep learning is the large labeled datasets. However, labeling large datasets is very expensive and often not feasible, especially in domains that require expertise to provide labels. Semi-Supervised Learning (SSL), on the other hand, can take advantage of partially labeled data, which is much more readily available, as shown in <ref type="figure">figure 1</ref>.</p><p>A critical problem in semi-supervised learning is how to generalize the information learned from limited label data * Equal contributions; names ordered alphabetically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Labeled Data</head><p>Unlabeled Data <ref type="figure">Figure 1</ref>: Illustration of an image set with a limited amount of labeled images among a large number of unlabeled images. Unlike unsupervised learning methods that only exploit the structure from unlabeled data, and supervised learning methods that only look at the limited amount of labeled data, semi-supervised learning utilizes information from both labeled and unlabeled data.</p><p>to unlabeled data. Following the continuity assumption that close data have a higher probability of sharing the same label <ref type="bibr" target="#b3">[4]</ref>, many approaches have been developed <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b7">8]</ref>, including the recently proposed Label Propagation <ref type="bibr" target="#b13">[14]</ref>. Another critical problem in semi-supervised learning is how to directly learn from the large amount of unlabeled data. Maintaining consistency between differently augmented unlabeled data has been recently studied and proved to be an effective way to learn from unlabeled data in both self-supervised learning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11]</ref> and semi-supervised learning <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b31">32]</ref>. Other than consistency regularization, a few other techniques have also been developed for the semi-supervised learning to leverage the unlabeled data, such as entropy minimization <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b9">10]</ref> and generic regularization <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>The recently proposed MixMatch <ref type="bibr" target="#b1">[2]</ref> combined the above techniques and designed a unified loss function to let the model learn from differently augmented labeled and unlabeled data, together with the mix-up <ref type="bibr" target="#b34">[35]</ref> technique, which encourages convex behavior between samples to increase models' generalization ability. ReMixMatch <ref type="bibr" target="#b0">[1]</ref> further improves the MixMatch by introducing the Distribution Alignment and Augmentation Anchoring techniques, which al-   <ref type="figure">Figure 2</ref>: An overview of the proposed SimPLE algorithm. SimPLE optimizes the classification network with three training objectives: 1) supervised loss L X for augmented labeled data; 2) unsupervised loss L U that aligns the strongly augmented unlabeled data with pseudo labels generated from weakly augmented data; 3) Pair Loss L P that minimizes the statistical distance between predictions of strongly augmented data, based on the similarity and confidence of their pseudo labels.</p><formula xml:id="formula_0">Z F F 6 p S U z d A A 9 C 5 j O C l Z b c b o D V k G C e X v Z q 0 1 6 h i M y S X X Y c G y L T Q s h y z j S x 7 f J p y Y K W i W Y o V v b r 7 + y p + l L r F V 6 7 / Y g k A Q 0 V 4 V j K j o V i 5 a Z Y K E Y 4</formula><p>lows the model to accommodate and leverage from the heavily augmented samples. FixMatch <ref type="bibr" target="#b25">[26]</ref> simplifies its previous works by introducing a confidence threshold into its unsupervised objective function and achieves state-ofthe-art performance over the standard benchmarks.</p><p>However, while Label Propagation <ref type="bibr" target="#b13">[14]</ref> mainly focuses on the relationship between labeled data to unlabeled data, and the MixMatch family <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b25">26]</ref> primarily focuses on the relationship between differently augmented unlabeled samples, the relationship between different unlabeled samples is less studied.</p><p>In this paper, we propose to take advantage of the relationship between different unlabeled samples. We introduce a novel Pair Loss, which minimizes the distance between similar unlabeled samples of high confidence.</p><p>Combining the techniques developed by the MixMatch family <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b25">26]</ref>, we propose the SimPLE algorithm. As shown in figure 2, the SimPLE algorithm generates pseudo labels of unlabeled samples by averaging and sharpening the predictions on multiple weakly augmented variations of the same sample. Then, we use both the labels and pseudo labels to compute the supervised cross-entropy loss and unsupervised L2 distance loss. These two terms push the decision boundaries to go through low-density areas and encourage consistency among different variations of the same samples. Finally, with the newly proposed Pair Loss, we harness the relationships among the pseudo labels of different samples by encouraging consistency among different unlabeled samples which share a great similarity.</p><p>Our contribution can be described in four folds:</p><p>? We propose a novel unsupervised loss term that leverages the information from high confidence similar un-labeled data pairs.</p><p>? Combining the techniques from MixMatch family <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b25">26]</ref> with the new Pair Loss, we developed the novel SimPLE algorithm for semi-supervised learning.</p><p>? We performed extensive experiments on the standard benchmarks and demonstrated the effectiveness of the proposed Pair Loss. SimPLE outperforms the state-ofthe-art methods on CIFAR100 and Mini-ImageNet and on par with the state-of-the-art methods on CIFAR10, SVHN.</p><p>? We also evaluated our algorithm in a realistic setting where SSL methods are applied on pre-trained models, where the new proposed SimPLE algorithm also outperforms the current state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Consistency Regularization</head><p>Consistency regularization is widely used in the field of SSL. It refers to the idea that a model's response to an input should remain consistent, when perturbations are used on the input or the model. The idea is first proposed in <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b24">25]</ref>. In its simplest form, the regularization can be achieved via the loss term:</p><formula xml:id="formula_1">p model (y|A(x); ?) ? p model (y|A(x); ?) 2 2 (1)</formula><p>The stochastic transformation A(x) can be either domainspecific data augmentation <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b0">1]</ref>, drop out <ref type="bibr" target="#b24">[25]</ref>, random max pooling <ref type="bibr" target="#b24">[25]</ref>, or adversarial transformation <ref type="bibr" target="#b21">[22]</ref>. A further extension of this idea is to "perturb" the model, p model , instead of the input. The perturbation can be a time ensembling of model at different time step <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">28]</ref>, or an adversarial perturbation on model's parameter ? <ref type="bibr" target="#b35">[36]</ref>. Also, many works choose to minimize cross entropy instead of the L 2 norm [22, 32, 1, 26].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Augmentation Anchoring</head><p>Augmentation Anchoring is first proposed by ReMixMatch <ref type="bibr" target="#b0">[1]</ref> and further developed in FixMatch <ref type="bibr" target="#b25">[26]</ref>. It is a form of consistency regularization that involves applying different levels of perturbations to the input. A model's response to a slightly perturbed input is regarded as the "anchor", and we try to align model's response to a severely perturbed input to the anchor. For example, we can slightly perturb the input by applying an "easy" augmentation such as horizontal flipping and severely perturb the input by applying a "hard" augmentation such as Gaussian blurring. As the model's response to a slightly perturbed input is less unstable, including Augmentation Anchoring increases the stability of the regularization process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Pseudo-labeling</head><p>Pseudo labels are artificial labels generated by the model itself and are used to further train the model. Lee <ref type="bibr" target="#b16">[17]</ref> picks the class with the highest predicted probability by the model as the pseudo label. However, pseudo labels are only used during the fine-tuning phase of the model, which has been pre-trained. When we minimize the entropy on pseudo labels, we encouraged decision boundaries among clusters of unlabeled samples to be in the low-density region, which is requested by low-density separation assumption <ref type="bibr" target="#b3">[4]</ref>. In this paper, for simplicity, we use a single lower case letter, p ? ? N (the N -probability simplex), to represent either a hard label (a one-hot vector) or a soft label (a vector of probabilities). A simple yet powerful extension of pseudo-labeling is to filter pseudo labels based on a confidence threshold <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26]</ref>. We define the confidence of a pseudo label as the highest probability of it being any class (i.e., max i (p i )). For simplicity, from now on, we will use max(p) as a shorthand notation for the confidence of any label p. With a predefined confidence threshold ? c , we reject all pseudo labels whose confidence is below the threshold (i.e., max(p) &lt; ? c ). The confidence threshold allows us to focus on labels with high confidence (low entropy) that are away from the decision boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Label Propagation</head><p>Label propagation is a graph-based idea that tries to build a graph whose nodes are the labeled and unlabeled samples, and edges are weighted by the similarity between those samples <ref type="bibr" target="#b3">[4]</ref>. Although it is traditionally considered as a transductive method <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b36">37]</ref>, recently, it has been used in an inductive setting as a way to give pseudo labels. In <ref type="bibr" target="#b13">[14]</ref>, the authors measure the similarity between feature representations of labeled and unlabeled samples embedded by a CNN. Then, each sample is connected with the K neighbors with the highest similarity to construct the affinity graph. After pre-training the model in a supervised fashion, they train the model and propagate the graph alternatively. The idea of using K nearest neighbors to build a graph efficiently is proposed in <ref type="bibr" target="#b7">[8]</ref>, as most edges in the graph should have a weight close to 0. Our similarity threshold, ? c , takes a similar role.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>To take full advantage of the vast quantity of unlabeled samples in SSL problems, we propose the SimPLE algorithm that focuses on the relationship between unlabeled samples. In the following section, we first describe the semi-supervised image classification problem. Then, we develop the major components of our methods and incorporate everything into our proposed SimPLE algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem Description</head><p>We define the semi-supervised image classification problem as following. In a L-class classification setting, let</p><formula xml:id="formula_2">X = ((x b , y b ) ; b ? (1, . . . , B)) be a batch of labeled data, and U = (u b ; b ? (1, . . . , B)</formula><p>) be a batch of unlabeled data. Let p model (? | x; ?) denote the model's predicted softmax class probability of input x parameterized by weight ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Augmentation Strategy</head><p>Our algorithm uses Augmentation Anchoring <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26]</ref>, in which pseudo labels come from weakly augmented samples act as "anchor", and we align the strongly augmented samples to the "anchor". Our weak augmentation, follows that of MixMatch <ref type="bibr" target="#b1">[2]</ref>, ReMixMatch <ref type="bibr" target="#b0">[1]</ref>, and FixMatch <ref type="bibr" target="#b25">[26]</ref>, contains a random cropping followed by a random horizontal flip. We use RandAugment <ref type="bibr" target="#b5">[6]</ref> or a fixed augmentation strategy that contains difficult transformations such as random affine and color jitter as strong augmentation. For every batch, RandAugment randomly selects a fixed number of augmentations from a predefined pool; the intensity of each transformation is determined by a magnitude parameter. In our experiments, we find that method can adapt to high-intensity augmentation very quickly. Thus, we simply fix the magnitude to the highest value possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Pseudo-labeling</head><p>Our pseudo labeling is based on the label guessing technique used in <ref type="bibr" target="#b1">[2]</ref>. We first take the average of the model's predictions of several weakly augmented versions of the same unlabeled sample as its pseudo label. As the prediction is averaged from K slight perturbations of the same </p><formula xml:id="formula_3">X = ((x b , y b ) ; b ? (1, . . . , B)), batch of unlabeled examples U = (u b ; b ? (1, . . . , B))</formula><p>, sharpening temperature T , number of weak augmentations K, number of strong augmentations K strong , confidence threshold ? c , similarity threshold ? s .</p><formula xml:id="formula_4">2: for b = 1 to B do 3:x b = A weak (x b )</formula><p>Apply weak data augmentation to x b 4:</p><formula xml:id="formula_5">for k = 1 to K do 5:? b,k = A weak (u b )</formula><p>Apply k th round of weak data augmentation to u b 6: end for 7:</p><formula xml:id="formula_6">for k = 1 to K strong do 8:? b,k = A strong (u b )</formula><p>Apply k th round of strong augmentation to u b 9:</p><p>end for 10:</p><formula xml:id="formula_7">q b = 1 K K k=1 p model (? |? b,k ; ?)</formula><p>Compute average predictions across all weakly augmented u b using EMA <ref type="bibr" target="#b10">11</ref>:</p><formula xml:id="formula_8">q b = Sharpen(q b , T )</formula><p>Apply temperature sharpening to the average prediction 12: end for 13:</p><formula xml:id="formula_9">X = ((x b , y b ) ; b ? (1, . . . , B))</formula><p>Weakly augmented labeled examples and their labels <ref type="bibr" target="#b13">14</ref></p><formula xml:id="formula_10">:? = ((? b,k , q b ) ; b ? (1, . . . , B) , k ? (1, . . . , K strong ))</formula><p>Strongly augmented unlabeled examples, guessed labels 15:</p><formula xml:id="formula_11">L X = 1 |X | x,y?X H (y, p model (? | x; ?))</formula><p>Compute supervised loss <ref type="bibr" target="#b15">16</ref>:</p><formula xml:id="formula_12">L U = 1 L|? | u,q?? 1 (max(q)&gt;?c) q ? p model (? | u; ?) 2 2</formula><p>Compute thresholded unsupervised loss <ref type="bibr" target="#b1">[2]</ref> or a single perturbation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26]</ref>, the guessed pseudo label should be more stable. Then, we use the sharpening operation defined in <ref type="bibr" target="#b1">[2]</ref> to increase the temperature of the label's distribution:</p><formula xml:id="formula_13">17: L P = PairLoss ? , ? c , ? s Compute Pair Loss 18: return L X + ? U L U + ? P L P Compute loss L fromX and? input instead of K severe perturbation</formula><formula xml:id="formula_14">Sharpen(p, T ) := p 1 T 1 p 1 T<label>(2)</label></formula><p>As the peak of the pseudo label's distribution is "sharpened", the network will push this sample further away from the decision boundary. Additionally, following the practice of MixMatch <ref type="bibr" target="#b1">[2]</ref>, we use the exponential moving average of the model at each time step to guess the labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Loss</head><p>Our loss consists of three terms: the supervised loss L X , the unsupervised loss L U , and the Pair Loss L P .</p><formula xml:id="formula_15">L = L X + ? U L U + ? P L P (3) L X = 1 |X | x,y?X H (y, p model (? | x; ?)) (4) L U = u,q?? 1 (max(q)&gt;?c) q ? p model (? | u; ?) 2 2 L ?<label>(5)</label></formula><p>L X calculates the cross-entropy of weakly augmented labeled samples; L U represents the L 2 distance between strongly augmented samples and their pseudo labels, filtered by confidence threshold. Notice that L U only enforces consistency among different perturbations of the same samples but not consistency among different samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Pair Loss</head><p>As we aim to exploit the relationship among unlabeled samples, we hereby introduce a novel loss term, Pair Loss, that allows information to propagate implicitly between different unlabeled samples. In Pair Loss, we use a high confidence pseudo label of an unlabeled point, p, as an "anchor." All unlabeled samples whose pseudo labels are similar enough to p need to align their predictions under severe perturbation to the "anchor." <ref type="figure">Figure 3</ref> offers an overview of this selection process. During this process, the similarity threshold "extended" our confidence threshold in an adaptive manner, as a sample whose pseudo label confidence is below the threshold can still be selected by the loss and be pushed to a higher confidence level. Formally, we defined the Pair Loss as following:</p><formula xml:id="formula_16">L P = 1 K B 2 i,j?[|U |],i =j (v l ,q l )=U i (vr,qr)=U j ? ?c (max (q l )) ? ? ?s (f sim (q l , q r )) ? f dist (q l , p model (? | v r ; ?))<label>(6)</label></formula><p>Here, ? c and ? s denote the confidence threshold and similarity threshold respectively. ? t (x) = 1 (x&gt;t) x is a hard  </p><formula xml:id="formula_17">q l q r max (q l ) &lt; ? c f sim (q l , q r ) &lt; ? s v r &lt; l a</formula><formula xml:id="formula_18">min ? f dist (q, p ? (y | v r ))</formula><p>Confidence Similarity q l p ? (y|v r ) <ref type="figure">Figure 3</ref>: Pair Loss Overview. Given a pseudo label q l (red) which is a probability vector representing the guessed class distribution, if the highest entry in q l surpasses the confidence threshold ? c , q l will become an "anchor". Then, for any pseudo label and image tuple q r (light blue) and v r (dark blue), if the overlapping proportion (i.e. similarity) between q l and q r is greater than the confidence threshold ? s , this tuple (q r , v r ) will contribute toward the Pair Loss by pushing model's prediction of a strongly augmented version of v r to the "anchor" q l (green arrow). During this process, if either threshold can not be satisfied, q l , q r , v r will be rejected.</p><p>threshold function controlled by threshold t. f sim (p, q) measures the similarity between two probability vectors p, q by Bhattacharyya coefficient <ref type="bibr" target="#b2">[3]</ref>. The coefficient is bounded between [0, 1], and represents the size of the overlapping portion of the two discrete distributions:</p><formula xml:id="formula_19">f sim (p, q) = ? p ? q<label>(7)</label></formula><p>f dist (p, q) measures the distance between two probability vectors p, q. As f sim (p, q) ? [0, 1], we choose the distance function to be f dist (p, q) = 1 ? f sim (p, q).</p><p>Although based on analysis, we found that cos(cos ?1 ( ? ? c ) + cos ?1 (? s )) 2 is the infimal confidence a label need to have for it to be selected by both thresholds, such low confidence label are rarely selected in practice. Based on empirical evidence, we believe this is caused by the fact a label p that can pass through the high confidence threshold typically has a near one-hot distribution. Thus, for another label q to fall in the similarity threshold of q, it must also have relatively high confidence.</p><p>Due to this property, the Pair Loss is not very sensitive to the choices of hyperparameters ? s , ? c , which we will show empirically in section 4.3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Motivation for Different Loss Formulations</head><p>We follow MixMatch <ref type="bibr" target="#b1">[2]</ref> in choosing supervised loss L X and unsupervised loss L U terms. We use the Bhattacharyya coefficient <ref type="bibr" target="#b2">[3]</ref> in our Pair Loss because it measures the overlap between two distributions and allows a more intuitive selection of the similarity threshold ? s . Although we believe that the Bhattacharyya coefficient <ref type="bibr" target="#b2">[3]</ref> is more suitable than L 2 distance (or 2 ? L 2 ) to measure the similarity between two distributions, we keep the L 2 distance in unsupervised loss term to provide a better comparison with MixMatch <ref type="bibr" target="#b1">[2]</ref>. Moreover, as cross-entropy measures the entropy and is asymmetric, it is not a good distance measurement between distributions. In our experiments, we observe that SimPLE with L 2 Pair Loss has 0.53% lower test accuracy than the original.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">SimPLE Algorithm</head><p>By putting together all the components introduced in this section, we now present the SimPLE algorithm. During training, for a mini-batch of samples, SimPLE first augment labeled and unlabeled samples with both weak and strong augmentations. The pseudo labels of the unlabeled samples are obtained by averaging and then sharpening the models' predictions on the weakly augmented unlabeled samples. Finally, we optimize the loss terms based on augmented samples and pseudo labels. During testing, SimPLE uses the exponential moving average of the weights of the model to make predictions, as the way done by MixMatch in <ref type="bibr" target="#b1">[2]</ref>. <ref type="figure">Figure 2</ref> gives an overview of SimPLE, and the complete algorithm is in algorithm 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-100</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Unless specified otherwise, we use Wide ResNet 28-2 <ref type="bibr" target="#b32">[33]</ref> as our backbone and AdamW <ref type="bibr" target="#b19">[20]</ref> with weight decay for optimization in all experiments. We also use the exponential moving average (EMA) of the network parameter of every training step for evaluation and label guessing.   <ref type="table">Table 3</ref>: Mini-ImageNet Top-1 Test Accuracy. * : using our implementation. ? : The score is reported in <ref type="bibr" target="#b13">[14]</ref> and using its own implementation.</p><p>To have a fair comparison with MixMatch, we implemented an enhanced version of MixMatch by combing it with Augmentation Anchoring <ref type="bibr" target="#b0">[1]</ref>. To report test accuracy, we take the checkpoint with the highest validation accuracy and report its test accuracy. By default, our experiments have fixed hyperparameters ? c = 0.95, ? s = 0.9 and EMA decay to 0.999. Mini-ImageNet: Mini-ImageNet is first introduced in [31] for few-shot learning. The dataset contains 100 classes where each class has 600 images of size 84 ? 84. For SSL evaluation, our protocol follows that of <ref type="bibr" target="#b13">[14]</ref>, in which 500 images are selected from each class to form the training set, and the leftover 100 images are used for testing. Since <ref type="bibr" target="#b13">[14]</ref> do not specify its validation set split, we use a total of 7200 training images (72 per class) as validation set; this is of the same validation set size as <ref type="bibr" target="#b30">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and Evaluations</head><p>DomainNet-Real <ref type="bibr" target="#b22">[23]</ref>: DomainNet-Real has 345 categories with unbalanced numbers of images per class following a long tail distribution. We use this dataset for transfer learning experiments in section 4.3.1. For our evaluations, we resize the image to 84 ? 84 and use 11-shot per class (a total of 3795) for the labeled training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Baseline Methods</head><p>We compare with the following baseline methods: Fix-Match <ref type="bibr" target="#b25">[26]</ref>, MixMatch <ref type="bibr" target="#b1">[2]</ref>, ReMixMatch <ref type="bibr" target="#b0">[1]</ref>, VAT <ref type="bibr" target="#b20">[21]</ref>, MeanTeacher <ref type="bibr" target="#b28">[29]</ref>, and Label Propagation <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>For all datasets, our labeled and unlabeled set split is done by randomly sample the same number of images from all classes without replacement. In general, our hyperparameter choices follows that of MixMatch <ref type="bibr" target="#b1">[2]</ref> and FixMatch <ref type="bibr" target="#b25">[26]</ref>.</p><p>CIFAR-100: We set the loss weight to ? U = 150, ? P = 150. As shown in table 1, we find that SimPLE has sig-  <ref type="bibr" target="#b25">[26]</ref>, we include experiments using the same optimizer (SGD), hyperparameters, and backbone network (WRN 28-8 with 23M parameters). With a larger backbone, our method still provides improvements over baseline methods. SimPLE is better than FixMatch by 0.7% and takes only 4.7 hours of training for convergence, while FixMatch takes about 8 hours to converge. We consider convergence is achieved when the validation accuracy reaches 95% of its highest value. CIFAR-10, SVHN: For CIFAR-10, we set ? U = 75 and ? P = 75; we set ? U = ? P = 250 for SVHN. For both datasets, we use SGD with cosine learning rate decay <ref type="bibr" target="#b17">[18]</ref> with decay rate set to 7? <ref type="bibr" target="#b15">16</ref> following that of FixMatch <ref type="bibr" target="#b25">[26]</ref>. In table 2, we find that SimPLE is on par with ReMix-Match <ref type="bibr" target="#b0">[1]</ref> and FixMatch <ref type="bibr" target="#b25">[26]</ref>. ReMixMatch, FixMatch, and SimPLE are very close to the fully supervised baseline with less than 1% difference in test accuracy. SimPLE is less effective on these domains because the leftover samples are difficult ones whose pseudo labels are not similar to any of the high confidence pseudo labels. In this case, no pseudo labels can pass the two thresholds in Pair Loss and contribute to the loss. We observe that the percentage of pairs in a batch that passes both thresholds stabilizes early in the training progress (the percentage is 12% for SVHN and 10% for CIFAR-10). Thus, Pair Loss does not bring much performance gain as it does in the more complicated datasets.</p><p>Mini-ImageNet: To examine the scalability of our method, we conduct experiments on Mini-ImageNet. Mini-ImageNet is a more complex dataset because its categories and images are sampled directly from ImageNet. Although the image size is scaled down to 84 ? 84, it is still much more complicated than CIFAR-10, CIFAR-100, and SVHN. Therefore, Mini-ImageNet is an excellent candidate to illustrate the scalability of SimPLE.</p><p>In addition to WRN 28-2 experiments on Mini-ImageNet, we also apply the SimPLE algorithm on ResNet-18 <ref type="bibr" target="#b11">[12]</ref> for a fair comparison with prior works. The results are in table 3. In general, our method outperforms all other methods by a large margin on Mini-ImageNet regardless of backbones. Our method scales with the more challenging dataset.  <ref type="table">Table 5</ref>: ImageNet-1K pre-trained model transfer to DomainNet-Real. All experiments use ResNet-50. The model is converged when its validation accuracy reaches 95% of its highest validation accuracy. ? : using labeled training set only. * : using our implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">SSL for Transfer Learning Task</head><p>In real-world applications, a common scenario is where the target task is similar to existing datasets. Transfer learning is helpful in this situation if the target domain has sufficient labeled data. However, this is not guaranteed. Therefore, SSL methods need to perform well when starting from a pre-trained model on a different dataset. Another benefit of using a pre-trained model is having fast convergence, which is important for time-sensitive applications.</p><p>Since prior SSL methods often neglect this scenario, in this section, we evaluate our algorithm, MixMatch <ref type="bibr" target="#b1">[2]</ref> and supervised baseline in the transfer setting. The supervised baseline only uses labeled training data and parameter EMA for evaluation. All transfer experiments use fixed augmentations.</p><p>Our first experiment is the adaptation from DomainNet-Real to Mini-ImageNet; the result is in table 4. We observe that the pre-trained models are on par with training from   <ref type="bibr" target="#b6">[7]</ref> to DomainNet-Real. Since ImageNet-1K pre-trained ResNet-50 <ref type="bibr" target="#b11">[12]</ref> is readily available in many machine learning libraries (e.g., PyTorch), we evaluate the performance and the convergence speed using ImageNet-1K pre-trained ResNet-50 to mimic real-world applications.</p><p>On DomainNet-Real, MixMatch is about 7% lower than the supervised baseline, while SimPLE has 8% higher accuracy than the baseline. MixMatch Enhanced, despite having Augmentation Anchoring, does not outperform MixMatch.</p><p>It is clear that SimPLE perform well in pre-trained setting and surpasses MixMatch and supervised baselines by a large margin. This behavior is consistent across datasets and network architectures. MixMatch, on the other hand, does not improve performance in the pre-trained setting.</p><p>Compared to training from scratch, the pre-trained models do not always provide performance improvements since the pre-trained models might have domain bias that is not easy to overcome. For example, in our DomainNet-Real to Mini-ImageNet experiment, the pre-trained test accuracy is slightly lower than training from scratch. However, the convergence speed is significantly faster (?8 to 10 times) when starting from a pre-trained model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Ablation Study over CIFAR-100</head><p>In this section, we conducted ablation studies on CIFAR-100 with WRN 28-2 to evaluate the effectiveness of different parts of our system. The results are available in table 6. We choose CIFAR-100 because it has a reasonable number of classes (reasonably complicated) and a small image size (fast enough for training).</p><p>We observe that Pair Loss significantly improves the performance. With a more diverse augmentation policy or in-creasing the number of augmentations, the advantage of the Pair Loss is enhanced. Also, SimPLE is robust to threshold change. One possible explanation for the robustness is that since a pair must pass both thresholds to contribute to the loss, changing one of them may not significantly affect the overall number of pairs that pass both thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We proposed SimPLE, a semi-supervised learning algorithm. SimPLE improves on previous works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b25">26]</ref> by considering a novel unsupervised objective, Pair Loss, which minimizes the statistical distance between high confidence pseudo labels with similarity above a certain threshold. We have conducted extensive experiments over the standard datasets and demonstrated the effectiveness of the SimPLE algorithm. Our method shows significant performance gains over previous state-of-the-art algorithms on CIFAR-100 and Mini-ImageNet <ref type="bibr" target="#b30">[31]</ref>, and is on par with the state-of-the-art methods on CIFAR-10 and SVHN. Furthermore, SimPLE also outperforms the state-of-the-art methods in the transfer learning setting, where models are initialized by the weights pre-trained on ImageNet <ref type="bibr" target="#b14">[15]</ref>, or DomainNet-Real [23].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgement</head><p>This material is based on research sponsored by Air Force Research Laboratory (AFRL) under agreement number FA8750-19-1-1000. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation therein. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of Air Force Laboratory, DARPA or the U.S. Government.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation Detail</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Hyperparameters</head><p>As mentioned in section 4, our hyperparameters are almost identical to that of MixMatch <ref type="bibr" target="#b1">[2]</ref> and FixMatch <ref type="bibr" target="#b25">[26]</ref>. We use the same network architecture and similar hyperparameters as FixMatch for CIFAR-10, SVHN, and CIFAR-100 (WRN . We conducted ablation study on WRN 28-2 with hyperparameters similar to that of MixMatch for simplicity. We also evaluated SimPLE on Mini-ImageNet with WRN 28-2 and ResNet 18. We use the same ? (beta distribution parameter for mix-up <ref type="bibr" target="#b34">[35]</ref>) and T (temperature for sharpening) across all experiments. Notice that only MixMatch and MixMatch Enhanced use mix-up.</p><p>The full detail of our hyperparameters choices can be found in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Optimization</head><p>For CIFAR-10, SVHN, and CIFAR-100 (WRN 28-8), we use SGD with Nesterov momentum set to 0.9. We also use cosine learning rate decay <ref type="bibr" target="#b17">[18]</ref> with a decay rate of 7? <ref type="bibr" target="#b15">16</ref> following FixMatch. For CIFAR-100 (WRN 28-2), Mini-ImageNet, and transfer experiments, we use AdamW <ref type="bibr" target="#b19">[20]</ref> without learning rate scheduling follows that of MixMatch. Details are available in table 7, 8 and 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Augmentations</head><p>Our augmentations are implemented on GPU with Kornia <ref type="bibr" target="#b23">[24]</ref>. In    <ref type="bibr" target="#b5">[6]</ref>, we follows the exact same settings as FixMatch <ref type="bibr" target="#b25">[26]</ref>. Note that we only reported the changed augmentation parameters while the omitted values are the same as the default parameters in Kornia <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Further Analysis on Pair Loss</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Analysis on Confidence Threshold</head><p>Theorem 1 ?p, q ? ? N , if ? ?c (max (p)) ? ? ?s (f sim (p, q)) &gt; 0, then max (q) &gt; cos(cos ?1 ( ? ? c ) + cos ?1 (? s )) 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transformation Description Parameter Random Horizontal Flip</head><p>Horizontally flip an image randomly with a given probability p p = 0.5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random Resized Crop</head><p>Random crop on given size and resizing the cropped patch to another scale = (0.8, 1), ratio = (1, 1)</p><p>Random 2D GaussianBlur Creates an Gaussian filter for image blurring. The blurring is randomly applied with probability p p = 0.5, kernel size = (3, 3), sigma = (1.5, 1.5)</p><p>Color Jitter Randomly change the brightness, contrast, saturation, and hue of given images contrast = (0.75, 1.5)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random Erasing</head><p>Erases a randomly selected rectangle for each image in the batch, putting the value to zero p = 0.1   <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random Affine</head><p>Since ? ?c (max (p)) ? ? ?s (f sim (p, q)) &gt; 0, we have: max (p) &gt; ? c f sim (p, q) &gt; ? s Denote j = arg max i p i , i.e., the confidence of p is attained at the j-th coordinate, p j = max(p).</p><p>Denote e j ? ? n as the elementary vector with the j-th element to be 1 and all other elements to be 0.</p><p>In the square root probability space, we have:</p><p>? e j ? p = max ? p &gt; ? ? c ? p ? q &gt; ? s Notice, because p 1 = q 1 = e j 1 = 1, we have ? p 2 = ? q 2 = ? e j 2 = 1. Therefore, ? p, ? q,</p><p>and ? e j are on the unit n-sphere S n . Denote the geodesic distance between any two points x, y ? S n as d Sn (x, y) = cos ?1 ( x y x 2 ? y 2 ) = cos ?1 (x y) .</p><formula xml:id="formula_20">d Sn ? p, ? e j &gt; cos ?1 ( ? ? c ) d Sn ? p, ? q &gt; cos ?1 (? s )</formula><p>As the geodesic distance preserves triangular inequality:</p><formula xml:id="formula_21">d Sn ? q, ? e j ? d Sn ( ? q, ? p) + d Sn ? p, ? e j &gt; cos ?1 ( ? ? c ) + cos ?1 (? s ) ? q j =</formula><p>? q ? e j &gt; cos(cos ?1 ( ? ? c ) + cos ?1 (? s )) max(q) ? q j &gt; cos(cos ?1 ( ? ? c ) + cos ?1 (? s )) 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. More on Pair Loss</head><p>In this section, we provide additional information to two existing ablation studies in table 6 on CIFAR-100, to demonstrate the effectiveness of Pair Loss in encouraging more unlabeled samples to have accurate and high confidence predictions. Specifically, we compare the performance of the SimPLE algorithm with and without the Pair Loss enabled in the following measurements: 1) the percentage of unlabeled samples with high confidence pseudo labels; 2) the percentage of unlabeled sample pairs that pass both confidence and similarity thresholds; 3) the percentage of false-positive unlabeled sample pairs that pass both confidence and similarity thresholds but are in different categories.  <ref type="figure" target="#fig_6">figure 4</ref>, the ratio of pairs that pass both the confidence threshold and similarity threshold is increased by 16.67%, with a consistently nearly 0% false positive rate, which indicates that Pair Loss encourages the model to make more consistent and similar predictions for unlabeled samples from the same class. As shown in <ref type="figure" target="#fig_7">figure 5</ref>, with Pair Loss, the percentage of unlabeled sample with high confidence labels is increased by 7.5%, and the prediction accuracy is increased by 2% as shown in table 6. These two results indicate that Pair Loss encourages the model to make high confidence and accurate predictions on more unlabeled samples, which follows our expectation that Pair Loss aligns samples with lower confidence pseudo labels to their similar high confidence counterparts during the training and improves the prediction accuracy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " p b 1 U e L E 9 i c H 6 u J Q C L e 0 x h i 9 m h j I = " &gt; A A A B 9 H i c d V D L S g M x F L 1 T X 7 W + q o I b N 8 E i u B p m i q X t r t S N C x c t 2 A e 0 Q 8 m k a R u a e Z h k C m X o d 7 h x o Y h L / Q q / w J 0 b v 8 V M W 0 F F T w g c z r m X n B w 3 5 E w q y 3 o 3 U i u r a + s b 6 c 3 M 1 v b O 7 l 5 2 / 6 A p g 0 g Q 2 i A B D 0 T b x Z J y 5 t O G Y o r T d i g o 9 l x O W + 7 4 I v F b E y o k C / x r N Q 2 p 4 + G h z w a M Y K U l p + t h N S K Y x 1 e 9 9 q y X z V l m u V Q o n 5 e Q Z V p z J C R f 1 A f Z S y V X O a p / s O f q a 6 2 X f e v 2 A x J 5 1 F e E Y y k 7 t h U q J 8 Z C M c L p L N O N J A 0 x G e M h 7 W j q Y 4 9 K J 5 6 H n q F T r f T R I B D 6 + g r N 1 e 8 b M f a k n H q u n k x C y t 9 e I v 7 l d S I 1 K D k x 8 8 N I U Z 8 s H h p E H K k A J Q 2 g P h O U K D 7 V B B P B d F Z E R l h g o n R P G V 3 C 1 0 / R / 6 S Z N + 2 C a d V 1 G 1 V Y I A 3 H c A J n Y E M R K n A J N W g A g R u 4 h X t 4 M C b G n f F o P C 1 G U 8 Z y 5 x B + w H j 5 B C V 0 l g 0 = &lt; / l a t e x i t &gt; L X &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 f V N J Q g W G 0 x 9 o E S 3 S K 5 h V H 2 L N U Q = " &gt; A A A B 9 H i c d V D L S g M x F M 3 4 r P V V F d y 4 C R b B 1 Z C x j F N 3 p W 5 c u G j B P q A d S i b N t K G Z h 0 m m U I Z + h x s X i r j U r / A L 3 L n x W 8 y 0 C i p 6 I H A 4 5 1 7 u y f F i z q R C 6 M 1 Y W F x a X l n N r e X X N z a 3 t g s 7 u 0 0 Z J Y L Q B o l 4 J N o e l p S z k D Y U U 5 y 2 Y 0 F x 4 H H a 8 k b n m d 8 a U y F</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>n e a 7 i a Q x J i M 8 o B 1 N Q x x Q 6 a a z 0 F N 4 p J U + 9 C O h X 6 j g T P 2 + k e J A y k n g 6 c k s p P z t Z e J f X i d R f t l N W R g n i o Z k f s h P O F Q R z B q A f S Y o U X y i C S a C 6 a y Q D L H A R O m e 8 r q E r 5 / C / 0 n z x L R s E 9 V 1 G 1 U w R w 4 c g E N w D C z g g A q 4 A D X Q A A R c g x t w B + 6 N s X F r P B i P 8 9 E F 4 3 N n D / y A 8 f w B M r S W F w = = &lt; / l a t e x i t &gt; L P &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E 2 H b E g d B + 5 l S P e 7 n 3 m 7 l Y V I u p F A = " &gt; A A A B 9 H i c d V D L S g M x F M 3 U V 6 2 v q u D G T b A I r o b U Y j u z K 3 X j w k U L 9 g H t U D J p p g 3 N P E w y h T L 0 O 9 y 4 U M S l f o V f 4 M 6 N 3 2 K m V V D R A 4 H D O f d y T 4 4 b c S Y V Q m 9 G Z m l 5 Z X U t u 5 7 b 2 N z a 3 s n v 7 r V k G A t C m y T k o e i 4 W F L O A t p U T H H a i Q T F v s t p 2 x 2 f p 3 5 7 Q o V k Y X C l p h F 1 f D w M m M c I V l p y e j 5 W I 4 J 5 c t l v z v r 5 A j J t u 2 R X E E R m B Z V t y 9 I E l c o I W b B o o j k K 1 Y P G O 3 u q v d T 7 + d f e I C S x T w N F O J a y W 0 S R c h I s F C O c z n K 9 W N I I k z E e 0 q 6 m A f a p d J J 5 6 B k 8 1 s o A e q H Q L 1 B w r n 7 f S L A v 5 d R 3 9 W Q a U v 7 2 U v E v r x s r z 3 I S F k S x o g F Z H P J i D l U I 0 w b g g A l K F J 9 q g o l g O i s k I y w w U b q n n C 7 h 6 6 f w f 9 I 6 N Y t n J m r o N m p g g S w 4 B E f g B B R B B V T B B a i D J i D g G t y A O 3 B v T I x b 4 8 F 4 X I x m j M + d f f A D x v M H S s C W J w = = &lt; / l a t e x i t &gt; L U</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 algorithm 1 :</head><label>11</label><figDesc>SimPLE Input: Batch of labeled examples and their one-hot labels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Dog</head><label></label><figDesc>Cat Fish Frog &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 u r Q a C x z b X 0 6 Y l m h a d T 1 Q D q S I / M = " &gt; A A A B 7 X i c b Z D L S g M x F I b P 1 F u t t 6 o b w U 2 w C F 2 V G U F 0 Z 8 G N y w r 2 A u 1 Q M m m m j c 1 l S D J C K X 0 H N y 4 U c a v P 4 S O 4 8 w l 8 C s H 0 s t D W H w I f / 3 8 O O e d E C W f G + v 6 n l 1 l a X l l d y 6 7 n N j a 3 t n f y u 3 s 1 o 1 J N a J U o r n Q j w o Z y J m n V M s t p I 9 E U i 4 j T e t S / H O f 1 O 6 o N U / L G D h I a C t yV L G Y E W 2 f V W h a n b d L O F / y S P x F a h G A G h Y v v d / V 1 8 C Y q 7 f x H q 6 N I K q i 0 h G N j m o G f 2 H C I t W W E 0 1 G u l R q a Y N L H X d p 0 K L G g J h x O p h 2 h Y + d 0 U K y 0 e 9 K i i f u 7 Y 4 i F M Q M R u U q B b c / M Z 2 P z v 6 y Z 2 v g 8 H D K Z p J Z K M v 0 o T j m y C o 1 X R x 2 m K b F 8 4 A A T z d y s i P S w x s S 6 A + X c E Y L 5 l R e h d l I K T k v + t V 8 o F 2 G q L B z C E R Q h g D M o w x V U o A o E b u E e Hu H J U 9 6 D 9 + y 9 T E s z 3 q x n H / 7 I e / 0 B n e 6 T h Q = = &lt; / l a t e x i t &gt; ? c Dog Cat Fish Frog Dog Cat Fish Frog &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 5 i B S 7 l 2 R 6 G B u A Y 8 B P b v C Z b w X E E o = " &gt; A A A B 7 X i c d V D J S g N B E O 2 J W 4 x b 1 I v g p T E I O Q 0 z o s S c D H j x G M E s k A y h p 9 O T t O l l 6 O 4 R w p B / 8 O J B E a / 6 H X 6 C N 7 / A r x D s L E I U f V D w e K + K e l V h z K g 2 n v f u Z B Y W l 5 Z X s q u 5 t f W N z a 3 8 9 k 5 d y 0 R h U s O S S d U M k S a M C l I z 1 D D S j B V B P G S k E Q 7 O x 3 7 j h i h N p b g y w 5 g E H P U E j S h G x k r 1 t k F J R 3 f y B d / 1 J o C e W 7 Y o H c 9 I 2 Y f f V u H s 8 1 V + 7 L 3 w a i f / 1 u 5 K n H A i D G Z I 6 5 b v x S Z I k T I U M z L K t R N N Y o Q H q E d a l g r E i Q 7 S S d o R P L R K F 0 Z S 2 R I G T t T 5 i R R x r Y c 8 t J 0 c m b 7 + 7 Y 3 F v 7 x W Y q L T I K U i T g w R e L o o S h g 0 E o 5 P h 1 2 q C D Z s a A n C i t q s E P e R Q t j Y B + X m n / A / q R + 5 / o n r X X q F S h F M k Q X 7 4 A A U g Q 9 K o A I u Q B X U A A b X 4 B b c g w d H O n f O o / M 0 b c 0 4 s 5 l d 8 A P O 8 x c 8 2 5 P z &lt; / l a t e x i t &gt; ? s Dog Cat Fish Frog</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " P 0 m n r d 2 a R R T 6 A 2 w s r 8 9 p W v n s t i 4 = " &gt; A A A C Q H i c b V B N S + R A E O 3 4 7 a w f o x 6 9 N I o w g o z J g u h R 8 O J R w X G E y R A 6 n c p M Y 6 e T 7 a 6 I Q 8 j V f + N P 8 O J P 2 N u e v X h Q x J t 4 s j M z w q 5 u Q d O P 9 + p R V S / M p D D o u n + c i c m p 6 Z n Z u f n a j 4 X F p e X 6 y u q 5 S X P N o c V T m e q L k B m Q Q k E L B U q 4 y D S w J J T Q D i + P K r 1 9 B d q I V J 3 h I I N u w n p K x I I z t F R Q b / u J U I G P f U B G 4 6 D w E a 6 x i O x g W p a + h B g b v 3 b 8 h G E / z Y q s 0 q v O T 2 l g 3 R G 9 C g p d + l r 0 + r g 9 / m p B f d N t u s O i 3 4 E 3 B p u H G 7 v 3 N 2 + 3 W y d B / b c f p T x P Q C G X z J i O 5 2 b Y L Z h G w S W U N T 8 3 k D F + y X r Q s V C x B E y 3 G A Z Q 0 i 3 L R D R O t X 0 K 6 Z D 9 2 1 G w x J h B E t r O 6 h T z V a v I / 2 m d H O O D b i F U l i M o P h o U 5 5 J i S q s 0 a S Q 0 c J Q D C x j X w u 5 K e Z 9 p x t F m X o X g f T 3 5 O z j / 2 f T 2 m u 6 p T a N B R j V H 1 s k G a R C P 7 J N D c k x O S I t w c k c e y B N 5 d u 6 d R + f F e R 2 1 T j h j z x r 5 p 5 z 3 D 3 f G t a Q = &lt; / l a t e x i t &gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Random affine transformation of the image keeping center invariant degrees = (?25, 25), translate = (0.2, 0.2), scale = (0.8, 1.2), shear = (?8, 8)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Ratio of pairs pass both confidence and similarity thresholds. The green line is SimPLE and the grey line is SimPLE without Pair LossFrom</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Ratio of high confidence prediction. The green line is SimPLE and the grey line is SimPLE without Pair Loss</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table><row><cell>Method</cell><cell cols="2">10000 labels Backbone</cell></row><row><cell>MixMatch  *</cell><cell>64.01%</cell><cell>WRN 28-2</cell></row><row><cell>MixMatch Enhanced</cell><cell>67.12%</cell><cell>WRN 28-2</cell></row><row><cell>SimPLE</cell><cell>70.82%</cell><cell>WRN 28-2</cell></row><row><cell>MixMatch  ? [26] ReMixMatch  ? [26]</cell><cell>71.69% 76.97%</cell><cell>WRN 28-8 WRN 28-8</cell></row><row><cell>FixMatch [26]</cell><cell>77.40%</cell><cell>WRN 28-8</cell></row><row><cell>SimPLE</cell><cell>78.11%</cell><cell>WRN 28-8</cell></row></table><note>CIFAR-100 Top-1 Test Accuracy.* : using our implementation.? : reported in FixMatch [26].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>CIFAR-10 and SVHN Top-1 Test Accuracy. All experiments use WRN 28-2. ? : The accuracy is reported in ReMixMatch<ref type="bibr" target="#b0">[1]</ref> and using its own implementation. ? : Fully supervised baseline using all the labels and simple augmentation (flip-and-crop).</figDesc><table><row><cell>Mini-ImageNet</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>CIFAR-10: A dataset with 60K images of shape 32 ? 32 evenly distributed across 10 classes. The training set has 50K images, and the test set contains 10K images. Our validation set size is 5000 for CIFAR-10. The results are available in table 2. SVHN: SVHN consists of 10 classes. Its training set has 73257 images, and the test set contains 26032 images. Each image in SVHN is 32 ? 32. Our validation set size is 5000 for SVHN. The results are available in table 2. CIFAR-100: Similar to CIFAR-10, CIFAR-100 also has 50K training images and 10K test images but with 100 classes. The image size is 32 ? 32, the same as CIFAR-10. Our validation set size is 5000 for CIFAR-100. The results are available in table 1.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>DomainNet-Real pre-trained model transfer to Mini-ImageNet. All experiments use WRN 28-2. The model is converged when its validation accuracy reaches 95% of its highest validation accuracy.</figDesc><table><row><cell></cell><cell cols="2">Transfer: DomainNet-Real to Mini-ImageNet</cell></row><row><cell>Method</cell><cell>4000 labels</cell><cell>Convergence step</cell></row><row><cell>Supervised w/ EMA  ?</cell><cell>48.83%</cell><cell>4K</cell></row><row><cell>MixMatch  *  from scratch MixMatch  *</cell><cell>50.31% 53.39%</cell><cell>150K 69K</cell></row><row><cell>MixMatch Enhanced  *  from scratch MixMatch Enhanced  *</cell><cell>52.83% 55.75%</cell><cell>734K 7K</cell></row><row><cell>SimPLE from scratch</cell><cell>59.92%</cell><cell>338K</cell></row><row><cell>SimPLE</cell><cell>58.73%</cell><cell>53K</cell></row><row><cell></cell><cell></cell><cell>:</cell></row><row><cell>using our implementation.</cell><cell></cell><cell></cell></row><row><cell cols="2">nificant improvement on CIFAR-100. For better compar-</cell><cell></cell></row><row><cell>ison with</cell><cell></cell><cell></cell></row></table><note>? : using labeled training set only.*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>: Ablation on CIFAR-100. All experiments use WRN 28-2</cell></row><row><cell>scratch but converge 5 ? 100 times faster. Under transfer setting, SimPLE is 7.57% better than MixMatch and 9.9%</cell></row><row><cell>better than the supervised baseline.</cell></row><row><cell>The experiment in table 5 is for transferring from</cell></row><row><cell>ImageNet-1K</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>table 7</head><label>7</label><figDesc></figDesc><table><row><cell cols="4">and 8. Our transfer experiment configura-</cell></row><row><cell>tions are in table 9.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">CIFAR-10 SVHN CIFAR-100</cell></row><row><cell>? c</cell><cell></cell><cell>0.95</cell><cell></cell></row><row><cell>? s</cell><cell></cell><cell>0.9</cell><cell></cell></row><row><cell>? U ? P lr</cell><cell>75 75</cell><cell>250 250 0.03</cell><cell>150 150</cell></row><row><cell>K</cell><cell>7</cell><cell></cell><cell>4</cell></row><row><cell>T</cell><cell></cell><cell>0.5</cell><cell></cell></row><row><cell>?</cell><cell></cell><cell>0.75</cell><cell></cell></row><row><cell>weight decay</cell><cell>0.0005</cell><cell></cell><cell>0.001</cell></row><row><cell>batch size</cell><cell></cell><cell>64</cell><cell></cell></row><row><cell>EMA decay</cell><cell></cell><cell>0.999</cell><cell></cell></row><row><cell>backbone</cell><cell cols="2">WRN 28-2</cell><cell>WRN 28-8</cell></row><row><cell>optimizer</cell><cell></cell><cell>SGD</cell><cell></cell></row><row><cell>Nesterov</cell><cell></cell><cell>True</cell><cell></cell></row><row><cell>momentum</cell><cell></cell><cell>0.9</cell><cell></cell></row><row><cell>lr scheduler</cell><cell cols="3">cosine decay</cell></row><row><cell>lr decay rate</cell><cell></cell><cell>7? / 16</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Hyperparameters for CIFAR-10, SVHN, and CIFAR-100 (with WRN 28-8).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>table 10</head><label>10</label><figDesc></figDesc><table><row><cell>, we list the transformations used by</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table><row><cell cols="3">Hyperparameters for CIFAR-100 (WRN 28-2) and</cell></row><row><cell>Mini-ImageNet.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>DN-R to M-IN</cell><cell>IN-1K to DN-R</cell></row><row><cell>? c</cell><cell></cell><cell>0.95</cell></row><row><cell>? s</cell><cell></cell><cell>0.9</cell></row><row><cell>? U ? P feature lr</cell><cell>0.0002</cell><cell>300 300 0.00002</cell></row><row><cell>classifier lr</cell><cell></cell><cell>0.002</cell></row><row><cell>K</cell><cell></cell><cell>2</cell></row><row><cell>T</cell><cell></cell><cell>0.5</cell></row><row><cell>?</cell><cell></cell><cell>0.75</cell></row><row><cell>weight decay</cell><cell></cell><cell>0.02</cell></row><row><cell>batch size</cell><cell></cell><cell>16</cell></row><row><cell>EMA decay</cell><cell></cell><cell>0.999</cell></row><row><cell>backbone</cell><cell>WRN 28-2</cell><cell>ResNet 50</cell></row><row><cell>optimizer</cell><cell></cell><cell>AdamW</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table><row><cell>Hyperparameters for Transfer: DomainNet-Real to</cell></row><row><cell>Mini-ImageNet (DN-R to M-IN) and Transfer: ImageNet-</cell></row><row><cell>1K to DomainNet-Real (IN-1K to DN-R) experiments.</cell></row><row><cell>the fixed augmentations of table 4 and 5. For RandAug-</cell></row><row><cell>ment</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc></figDesc><table /><note>Augmentation details. Applied in order. Descriptions are from</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">ReMix-Match: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">MixMatch: A Holistic Approach to Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On a measure of divergence between two multinomial populations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sankhy?: The Indian Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="401" to="406" />
			<date type="published" when="1933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schlkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</meeting>
		<imprint>
			<date type="published" when="2020-06" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Low-shot learning with large-scale diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Self-ensembling for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">H</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Momentum Contrast for Unsupervised Visual Representation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Keeping the neural networks simple by minimizing the description length of the weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Drew</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Camp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth annual conference on Computational learning theory</title>
		<meeting>the sixth annual conference on Computational learning theory</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="5" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Label propagation for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Tolias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Yannis Avrithis, and Ondrej Chum</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Im-ageNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<title level="m">Temporal Ensembling for Semi-Supervised Learning. arXiv: Neural and Evolutionary Computing</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Decoupled weight decay regularization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: A regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shin-Ichi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Moment matching for multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingchao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinxun</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xide</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1406" to="1415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kornia: an open source differentiable computer vision library for pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgar</forename><surname>Riba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ponsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Rublee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><forename type="middle">R</forename><surname>Bradski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Winter Conference on Applications of Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehran</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1171" to="1179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<title level="m">FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence. arXiv: Learning</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Partially labeled classification with markov random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Szummer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017-01" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interpolation Consistency Training for Semi-supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="3635" to="3641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
		<editor>Edwin R. Hancock Richard C. Wilson and William A. P. Smith</editor>
		<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="87" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.12281</idno>
		<title level="m">Three mechanisms of weight decay regularization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">mixup: Beyond Empirical Risk Minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">WCP: Worst-Case Perturbations for Semi-Supervised Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning with Local and Global Consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengyong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2003-12" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
