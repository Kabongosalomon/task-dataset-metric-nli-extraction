<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Differentiable Hierarchical Graph Grouping for Multi-Person Pose Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Jin</surname></persName>
							<email>jinsheng@sensetime.com</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
							<email>qianchen@sensetime.com</email>
							<affiliation key="aff1">
								<orgName type="department">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
							<email>wanli.ouyang@sydney.edu.au</email>
							<affiliation key="aff3">
								<orgName type="institution">The University of Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
							<email>pluo@cs.hku.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Differentiable Hierarchical Graph Grouping for Multi-Person Pose Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Human Pose Estimation</term>
					<term>Graph Neural Network</term>
					<term>Grouping</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2[0000?0001?5736?7434] , Wentao Liu 2 ?[0000?0001?6587?9878] , Abstract. Multi-person pose estimation is challenging because it localizes body keypoints for multiple persons simultaneously. Previous methods can be divided into two streams, i.e. top-down and bottom-up methods. The top-down methods localize keypoints after human detection, while the bottom-up methods localize keypoints directly and then cluster/group them for different persons, which are generally more efficient than top-down methods. However, in existing bottom-up methods, the keypoint grouping is usually solved independently from keypoint detection, making them not end-to-end trainable and have sub-optimal performance. In this paper, we investigate a new perspective of human part grouping and reformulate it as a graph clustering task. Especially, we propose a novel differentiable Hierarchical Graph Grouping (HGG) method to learn the graph grouping in bottom-up multi-person pose estimation task. Moreover, HGG is easily embedded into main-stream bottom-up methods. It takes human keypoint candidates as graph nodes and clusters keypoints in a multi-layer graph neural network model. The modules of HGG can be trained end-to-end with the keypoint detection network and is able to supervise the grouping process in a hierarchical manner. To improve the discrimination of the clustering, we add a set of edge discriminators and macro-node discriminators. Extensive experiments on both COCO and OCHuman datasets demonstrate that the proposed method improves the performance of bottom-up pose estimation methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Multi-person pose estimation aims at localizing 2d keypoints of an unknown number of people in an image. It has attracted much research interest because of its significance in various real-world applications, such as human behavior understanding, human-computer interaction, and action recognition. <ref type="figure">Fig. 1</ref>. Hierarchical Graph Grouping embeds grouping procedure with the keypoint candidate proposal network. All modules are differentiable and can be trained end-to-end. Keypoint candidates are grouped in a multi-layer graph neural network, which enables to directly supervise the final grouping results.</p><p>Current pose estimation methods perform keypoints detection in two routes. The top-down methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b45">46]</ref> first detect human bounding boxes and then estimate keypoints for each person. It performs a single person pose estimation to all human candidates, so it is often time-consuming. Contrarily, bottom-up pose estimation approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b32">33]</ref> follow the keypoints detectionand-grouping pipeline: detecting keypoints at the first stage and grouping them into individuals at the second stage. These methods are more efficient and have gained increasing attention in the industry. Previous works generally treat the grouping stage as post-processing by using integer linear programming <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b34">35]</ref>, heuristic greedy parsing <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b32">33]</ref>, or clustering <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31]</ref>. But they are not able to be trained end-to-end, which is in conflict with deep learnings philosophy of learning everything together. Previous bottom-up methods generally learn some substitute indicators which may reflect the grouping accuracy, resulting in suboptimal solutions. For example, associate embedding (AE) <ref type="bibr" target="#b28">[29]</ref> produces the permutation-invariant associative embedding (a vector representation) for each keypoint, and learns by pushing apart the embedding of different people and pulling closer that of the same instance. Although it uses the associative embedding which encodes pairwise relationship to group keypoints, the grouping procedure itself is still offline, and no direct supervision is applied to the grouping results. There is a mismatch between the pairwise loss and the accuracy of the greedy parsing used at inference time. Even though the pairwise loss is low, the parsing results can still be possibly wrong, and vice versa.</p><p>A better choice is to directly supervise the grouping process. However, one major challenge is that the previous keypoint grouping procedure is often not dif-ferentiable, and thus is hard to be integrated with keypoint detection. Moreover, how to deal with the flexible number of keypoints is still an open problem.</p><p>In this paper, we present a simple and elegant solution for bottom-up multiperson pose estimation. In the proposed method, the whole network, composed of a keypoint detection network and a grouping network, is fully end-to-end trainable, and able to flexibly deal with the grouping problem of a variable number of human instances. To achieve this, we first reformulate the grouping problem as the graph clustering problem. A graph corresponds to an image, where the nodes denote the keypoint proposals, and edges denote whether the two keypoints belong to the same person. The graph structure is adaptive to different input images instead of constructing a static graph, so it is able to dynamically group various numbers of keypoints into various numbers of human instances. Especially, we propose the Online Hierarchical Graph Clustering (OHGC) algorithm, which makes the process of grouping keypoints learnable and can be easily embedded into main-stream bottom-up methods. The HGG method initializes the graph from the keypoint proposal network and groups pairs of most relative nodes in each iteration through the OHGC algorithm.</p><p>In OHGC, keypoints are clustered step-by-step. Each keypoint proposal starts in its own graph node, and the cluster pairs are merged. This forms a pose hierarchy, from small fractions to the whole body. This enables the model to pay more attention to global consistency and learn effective features for predicting the pairwise relation. The group operations are fully differentiable, so OHGC can make the whole network (including keypoint detection and grouping) end-toend trainable. By directly supervising the grouping results, the grouping loss is back-propagated to the previous keypoint detection network, which will further improve the feature representation ability of the keypoint detection network.</p><p>Moreover, we propose the edge discriminator to strengthen the local relationship of keypoints, and the macro-node discriminator to enforce global consistency. It can further increase the discrimination of body-keypoint relational features, leading to better grouping accuracy.</p><p>The main contributions of this work are thus three-fold.</p><p>-We reformulate the task of multi-person pose estimation as a graph clustering problem and present the first fully end-to-end trainable framework with grouping supervision for bottom-up multi-person pose estimation.</p><p>-We propose edge discriminators and macro-node discriminators to learn both local and global pairwise relation features and boost the grouping accuracy.</p><p>-The experimental results show that the proposed method outperforms the baseline by a large margin and achieves comparable performance with the state-of-the-art bottom-up pose estimation methods on COCO dataset. Moreover, the proposed method achieves the state of the art performance on the OCHuman datasets (41.8/36.0 mAP for val and test respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Multi-person Pose Estimation in Images</head><p>Top-down methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b45">46]</ref> decompose the multi-person pose estimation task into two sub-tasks:(1) Human detection and (2) Pose Estimation in the region of a single human. First, the person detector predicts a bounding box for every human instance in the image. Second, the box is cropped and resized from the image. Third, single-person pose estimation is applied to predict the keypoints for the cropped person. In addition, some work such as Mask R-CNN <ref type="bibr" target="#b15">[16]</ref> crop the feature instead of raw images to boost efficiency. In summary, top-down methods are dominant in state-of-the-art methods but they often have higher computational complexity overhead, especially when the number of human instances increases. This is because they need to repeatedly run the single-person pose estimation for every instance. Furthermore, because the pose estimation is dependent on the detection, it is difficult for these methods to recover the pose of an instance if it is missing in the detection results.</p><p>Bottom-up approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35]</ref> first detect all keypoint candidates in an image, then assemble/group them into full-body keypoints of each instance. Such bottom-up methods are usually efficient, and are capable of achieving real-time performance. To aid the follow-up keypoint association, most bottom-up methods learn descriptors to encode keypoint pairwise relations and to distinguish different instances. PAF <ref type="bibr" target="#b2">[3]</ref> learns part-affinity-fields, encoding both the location and orientation of keypoint pairs; GPN <ref type="bibr" target="#b30">[31]</ref> learns 2D offset fields, linking keypoints to the corresponding human centers; Person-Lab <ref type="bibr" target="#b32">[33]</ref> introduces long-range, mid-range and short-range offsets between pairwise keypoints; AE <ref type="bibr" target="#b28">[29]</ref> learns the associative embedding for each keypoint and similar embedding indicates higher possibility of belonging to the same person. The grouping process is generally formulated as a post-processing optimization problem and solved by graph partitioning <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b34">35]</ref>, heuristic greedy decoding algorithm <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b32">33]</ref> or spectral clustering <ref type="bibr" target="#b30">[31]</ref>. In summary, bottom-up methods can benefit from sharing convolutional computation, as a result, being faster than top-down methods. Nevertheless, the post-processing of grouping is heuristic and involves many hyper-parameters. Since the pose estimation and post-processing are not jointly learned, they cannot collaborate and adapt to each other. Instead of regarding the grouping as a pure post-processing procedure, we propose to train grouping with pose estimation jointly in an end-to-end fashion, enabling the error signals for grouping to be back-propagated.</p><p>Single-stage pose estimation. With recent advantages of single-shot object detection and instance segmentation <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b51">52]</ref>, some single-stage pose estimation methods are proposed. CenterNet <ref type="bibr" target="#b51">[52]</ref> firstly transfer pose estimation as human center detection and keypoint regression. However, it still needs keypoint detection and projection to improve performance. SPM <ref type="bibr" target="#b31">[32]</ref> proposes a structured pose representation to divide the keypoints hierarchically. In this way, it can ease the difficulty of long-range regression. Similarly, DirectPose <ref type="bibr" target="#b39">[40]</ref>, based on FCOS <ref type="bibr" target="#b40">[41]</ref>, directly do human center classification and keypoint regression without relying on bounding box. KPAlign is proposed to overcome the feature misalignment between convolutional features and keypoint predictions. However, keypoint regression is not very precise in the above methods, especially under the restriction of High IoU. In comparison, our method retains higher precision, especially under more strict metrics (AP 75 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Representation for Pose Estimation</head><p>The graph representation for human pose estimation is not new. For singleperson pose estimation, many work <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b48">49]</ref> have been based on various graphical models such as pictorial structure, Mixtures-of-parts, Markov Random Fields (MRF) or Conditional Random Fields (CRF). In these works, the graph nodes represent keypoints and the edges encode the pairwise relationships between keypoints. Since all the keypoints belong to the same human instance, no grouping process is required. Moreover, the number of keypoints of a single person is always fixed, therefore the graph structure, in terms of the number of nodes and the connectivity of edges, is fixed.</p><p>Multi-person pose estimation is much more challenging. <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b43">44]</ref>, the pose estimation problem is cast as a graph partitioning based integer linear programming (ILP) problem. However, the optimization process is offline and very time-consuming. Song et al. <ref type="bibr" target="#b36">[37]</ref> proposed a method for end-to-end minimum cost multicut problem. Unlike their works which focus on the CRF optimization, we solve the keypoint grouping task by direct graph clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Graph Neural Networks</head><p>This paper reformulates the multi-person pose estimation task using the graph representation and applies graph neural networks to this problem. Graph Neural Networks (GNN) is initially introduced in <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b35">36]</ref> and has become a popular tool for efficient message passing and modeling global relations <ref type="bibr" target="#b6">[7]</ref>. Most of GNN models can be categorized into two types: spectral approaches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b24">25]</ref> and nonspectral approaches <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b44">45]</ref>. This work is related to <ref type="bibr" target="#b44">[45]</ref>, which efficiently models the edge features. To solve the task of multi-person pose estimation, based on <ref type="bibr" target="#b44">[45]</ref> we develop a hierarchical clustering method, which takes the body structure constraints into consideration and models the whole grouping process.</p><p>More recently, GNN models have been applied to model the human body structure. Yan et al. <ref type="bibr" target="#b47">[48]</ref> proposes the spatial-temporal graph convolutional networks for skeleton-based action recognition. Zhang et al. <ref type="bibr" target="#b49">[50]</ref> proposes to use PGNN to learn the structured representation of keypoints for single-person pose estimation. However, previous works only deal with the single person case, where the structure of the graph is fixed. The multi-person case is more challenging, since the number of keypoints and the number of people vary in different images and even in different grouping stages. We have to develop a dynamic graph interaction model to effectively handle such problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Overview An overview of our proposed hierarchical graph grouping (HGG) framework is illustrated in <ref type="figure">Fig 2.</ref> Our HGG framework consists of two stages, i.e. the keypoint candidate proposal stage and the keypoint grouping stage.</p><p>In the keypoint candidate proposal stage, all keypoint candidates are detected and corresponding feature maps are extracted. Following AE <ref type="bibr" target="#b28">[29]</ref>, we use a 4-stacked hourglass <ref type="bibr" target="#b29">[30]</ref> as the backbone of the keypoint candidate proposal network. The keypoint proposal network then provides keypoint candidates and raw relational feature embedding for the keypoints grouping module.</p><p>In the keypoint grouping stage, we build a graph neural network using the candidates and relational features extracted from the former stage. An online hierarchical graph clustering (OHGC) algorithm is devised to cluster keypoints iteratively. In each iteration, OHGC updates the pairwise relation features and clusters nodes into a macro-node by maximizing the weighted edge score. The graph is updated and pruned with respect to the macro-nodes. Contrary to integer linear programming or bipartite matching, the proposed method is fully differentiable and is able to be trained end-to-end with keypoint detection.</p><p>We proposed two kinds of the discriminator to strengthen the grouping procedure, the edge discriminator and the macro-node discriminator. In each iteration, the edge discriminator is introduced to classify whether the pair of nodes belong to the same person. The pairwise relation features and the edge scores are updated accordingly. After each iteration of grouping, a macro-node discriminator is applied to each cluster to discriminate between a correctly-clustered macronode (in which all nodes belong to the same person) and a wrongly-clustered one. In this way, the whole online grouping procedure is fully supervised.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Hierarchical Graph Grouping</head><p>Previous work <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b34">35]</ref> cast the problem of multi-person pose grouping as graph partitioning, and solve it by optimizing an integer linear programming (ILP) problem. However, the optimization process is performed offline and the grouping procedure is not able to be supervised with the keypoint candidate proposal network. In this paper, we rethink this problem from the perspective of graph clustering and solve it with supervised learning. We follow the online agglomerative graph clustering setting. Each keypoint candidate starts with being its own cluster and closest pairs of clusters are merged iteratively. As a result, the keypoint candidates are grouped into several clusters, where each cluster contains all the keypoints of a single person. We are able to directly supervise the final grouping results. In the following sections, we will give a detailed description of the graph construction and hierarchical graph grouping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Construction</head><p>We construct a graph on top of the keypoint candidate proposal network. In the graph G = {V, E}, the "vertices" {V} = {v i } i=1:N represent keypoint candidates and the "edges" {E} = {e i1,i2 } i1=1:N,i2=1:N represent the pairwise relationship between the two candidates (the possibility of <ref type="figure">Fig. 2</ref>. The keypoint grouping stage of HGG framework. We construct a graph on top of the keypoint candidate proposal network, perform message passing with GNNs, and group the candidates iteratively. Edge discriminators and macronode discriminators are applied to improve the grouping performance.</p><p>belonging to the same person or not). Note that the graph is constructed dynamically, as the graph may have different number of nodes and edges for different images. We choose the fully-connected graph that densely connects every pair of the keypoints with different keypoint types. The keypoints with the same type (both "head"s) are disconnected. Compared to other sparse graph configurations (such as the tree-structure), the fully-connected graph is able to avoid over-segment of a person during occlusion, i.e. dividing a single pose into several clusters. For example, when a person's torso is occluded or missing, the link between the head and the foot will be helpful to connect the upper and the lower parts. Moreover, since the number of keypoints in an image is only about 30 on average, the computational cost of constructing such a dense graph is almost negligible. Each vertex v i ? {V} in the graph is initialized with the concatenation of the following features: (1) the relational embedding features of the keypoint, (2) the one hot feature that encodes the keypoint type, (3) the (x, y) coordinates of the keypoint normalized to [0, 1]. Both visual features and spatial features are preserved.</p><p>Online Hierarchical Graph Clustering Algorithm OHGC algorithm is given in Algorithm 1. Given the initial graph, an interaction GNN (Graph Neural Network) is trained to extract the relational features via message passing between vertices. As shown in <ref type="figure">Fig. 3</ref>, our GNN utilizes a stack of EdgeConv <ref type="bibr" target="#b44">[45]</ref> layers for effective feature learning. In each EdgeConv layer, the edge feature is mapped from the concatenation of features of nodes (linked by the edge) using a fully-connected layer, and the node features are updated by aggregating the features of the associated edges. A three-layer MLP (Multi-layer Perceptron) with Dropout is adopted to further extract high-level node features. As the output, we get representative features of each of the vertex which is used for grouping.</p><p>Previous graph clustering algorithms mainly focus on the keypoint-level pairwise relationship, without considering the higher-order term, i.e. the relation between two clusters of body parts. We instead propose to model the whole grouping process and design a hierarchical graph clustering algorithm. OHGC repeatedly performs graph feature aggregation, edge proximity update, node clustering and graph pruning, until all the edges are cut.</p><p>In each iteration, feature aggregation is applied to each of the macro-node (the set of previously grouped nodes) by averaging all features in the set. The proximity score between macro-nodes is measured by the edge discriminator (see Sec.3.2). After updating the edge weights, we use graclus clustering <ref type="bibr" target="#b8">[9]</ref> to match each vertex with its neighbors by (approximately) maximizing the edge weights. This finds the most confident pairs and carries out the clustering action. As a result, a group of "low-level" nodes is clustered into a "higher-level" macro-node. The number of clusters is reduced by half. For COCO dataset, the number of keypoint types is J = 17, so the grouping will stop in no more than log 2 17 = 5 iterations. After that, a macro-node discriminator (see Sec.3.2) is applied to each cluster to discriminate between a correctly-clustered macro-node (in which all nodes belong to the same person) and a wrongly-clustered one. The grouping procedure should satisfy the following two constraints. 1) A keypoint cannot be assigned to more than one person, i.e. two people share a single "head" keypoint. 2) A person cannot have more than one keypoints of the same type, i.e. a person containing two "head" keypoints. To avoid infeasible clustering, we perform graph pruning to remove infeasible edges after each grouping iteration. If two (macro-)nodes contain the same type of nodes, the edge in between is pruned. This grouping procedure repeats until all edges are pruned.</p><p>This grouping procedure naturally forms a hierarchy, from isolated keypoints to a whole body. The model learns to first group easy-to-group parts, then perform cluster in the macro-node level. As the grouping continues, the graph gradually gets coarsened. Finally, the nodes will be clustered into K groups, indicating K human instances. The model learns to group from easy to hard, in a curriculum fashion <ref type="bibr" target="#b0">[1]</ref>. Unlike the previous curriculum learning paradigm which requires to manually set curriculum phases, our curriculum tasks are automatically generated during training and well adjusted to the models current capability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Grouping Discriminators</head><p>In OHGC, two types of discriminators are introduced to further improve the grouping performance. In each iteration, we utilize the edge discriminator to update proximity scores and the macro-node discriminator to suppress the incorrectly grouped macro-nodes. We use the same discriminators in each clustering loop iteration. The network architectures are demonstrated in <ref type="figure">Fig. 3</ref>. Binary cross-entropy (BCE) loss is used to train. Edge Discriminator. Edges preserve local but discriminate keypoint-to-keypoint relationship. In order to improve the discrimination ability of the pairwise relation feature, we introduce a shared edge discriminator at each iteration. The edge discriminator is a two-class discriminator that is used to directly classifying the states of the edges: whether the edge is connected (label 1) or not (label 0). Connected edge means the two keypoints belong to the same person. As shown in <ref type="figure">Fig. 3</ref>, the edge discriminator is implemented as a three-layer MLP (Multi-layer Perceptron) with Dropout. The input is the concatenated features of two linked (macro-)nodes (2 ? 64 = 128?D), and the output is the 1-D edge score. Experiments show that the edge discriminator helps to increase the discrimination of body-keypoint relational features, leading to better grouping accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Online Hierarchical Graph Clustering</head><p>Macro-node Discriminator. We propose the macro-node discriminator to directly supervise the grouping procedure. After each grouping iteration, the nodes are clustered into macro-nodes. We apply a shared macro-node discriminator to each macro-node to classify whether all keypoint candidates in the group belong to the same person (label 1) or not (label 0). Both the final human-level grouping results and the intermediate part-level grouping results are supervised. This provides denser supervision signals, facilitating the model training. The discriminator takes the aggregated macro-node features (64-D) as input and forwards it into a three-layer MLP to discriminate positive vs negative macro-nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Implementation Details</head><p>Keypoint Proposal Network. The keypoint proposal network generates both 2D Gaussian confidence heatmaps as well as the pairwise relational feature maps. 2D Gaussian confidence heatmaps <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31]</ref> are used to encode the keypoint locations and the ground truth confidence map for an image is calculated as the maximum of every person. We follow <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b28">29]</ref> to apply keypoint NMS and parse the heatmaps to generate keypoint candidates. The pairwise relational feature maps are learned with push/pull losses, by pushing features of different people apart and pulling together features extracted from the same person. <ref type="figure">Fig. 3</ref>. The network architecture of GNN, the edge discriminator and the macroedge discriminator. The number of the input/output channels of MLP are given.</p><p>Training and Inference. We implement OHGC based on AE [29] 1 . The input size is set as 512 ? 512 and the output size is 128 ? 128. The keypoint proposal network is first pre-trained and the keypoint proposal network, GNN and the edge/macro-node discriminators are jointly trained in an end-to-end manner. The losses include keypoint detection loss, pairwise pull/push losses, binary cross-entropy (BCE) loss for discriminators. The weights to balance these losses are set as 1 : 1e ?3 : 1e ?5 . We use Adam with an initial learning rate 2e ?4 to train the model. During inference, flip testing and multi-scale testing is adopted. Unlike previous methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b28">29]</ref>, we do not use single-person refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Evaluation</head><p>To verify the effectiveness of the proposed HGG, we compare it with state-ofthe-art methods on two challenging datasets, i.e. MS-COCO <ref type="bibr" target="#b26">[27]</ref>, and OCHuman <ref type="bibr" target="#b50">[51]</ref>. We follow <ref type="bibr" target="#b19">[20]</ref> to use Average Percision (AP) to evaluate the methods.</p><p>MS-COCO Dataset <ref type="bibr" target="#b26">[27]</ref> contains over 200,000 images and 250,000 human instances and 1.7 million labeled keypoints in total, among which 150,000 instances are for training and 80,000 instances are for testing. Our models are trained on the train set only. The ablation studies are reported on the val set and the comparisons with other state-of-the-arts are reported on the test-dev.</p><p>OCHuman Dataset <ref type="bibr" target="#b50">[51]</ref> is a recently proposed benchmark to examine the limitations of human pose detection in highly challenging scenarios, which does not contain training samples and is intended to be used for evaluating existing models. It consists of 4731 images for validation and 8110 images for testing. The dataset contains only challenging cases of occlusion and the average IoU of the bounding boxes is 67%. Following <ref type="bibr" target="#b50">[51]</ref>, we train models on the training set of MS-COCO, and report the AP of them. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablation Study</head><p>We validate the effectiveness of key modules in HGG by conducting the following ablation studies. For fair comparisons, all models use Hourglass as the backbone network and are trained with the same data augmentation and training schedule. Effectiveness of End-to-End Learning. We compare the performance of the baseline Associate Embedding (AE) model and that with the grouping loss. The grouping loss is provided by the final level macro-node discriminator. As shown in <ref type="table" target="#tab_2">Table 2</ref> #1 and #3, end-to-end learning can increase the AP and the AR of the baseline by 0.6% and 1.3% respectively. #6 uses all these grouping losses to train the models, but uses original post-processing greedy grouping during inference. The improvement of #6 over #1 indicates that the grouping loss and end-to-end learning can improve the capability of Keypoint Proposal Network. Note that under this setting, the grouping module can be removed during inference without adding any additional computation overhead.</p><p>Effectiveness of the Edge Discriminator. The edge discriminator can enhance the keypoint relational features, thereby improving the grouping accuracy. To verify this, we compare the performance of models with and without the edge discriminator. As shown in <ref type="table" target="#tab_2">Table 2</ref> #1 and #4, we find that supervising the linkage of the edge will significantly improve the grouping performance by 2.0 mAP, demonstrating the effectiveness of the edge discriminator.</p><p>Effectiveness of the Macro-Node Discriminator. We evaluate two kinds of macro-node supervision, intermediate macro-node supervision and final macronode supervision. As shown in #4 and #5, the final macro-node supervision improves the grouping performance by 0.5 mAP. By performing intermediate supervision to the macro-node, the result is further improved by 0.3 mAP, shown in #5 and #9. In total, the full supervision boosts the performance by 0.8 mAP, showing the importance of supervising the whole grouping process. Effectiveness of GNN. To evaluate the interaction GNN, we add two baselines for comparison. Ours-GAT uses GAT <ref type="bibr" target="#b42">[43]</ref>, a popular graph neural network, for replacing EdgeConv. Ours-FC uses the multi-layer perception (dubbed FC for fully connected layers). For fair comparisons, these models have approximately the same parameter counts. As shown in #7, #8 and #9, both graph-based models perform better than Ours-FC baseline, because of more effective interactive message passing. Moreover, EdgeConv (60.4 AP) performs the best.</p><p>Comparisons of Different Graph Configurations. As shown in <ref type="figure" target="#fig_0">Fig 4a</ref>, four types of commonly used graph configurations <ref type="bibr" target="#b9">[10]</ref> (i.e. Tree, Bypass, Extended and Full) are compared. From Tree (the standard tree-structured model) to Full (the fully-connected graph), the graph gets denser. Bypass and Extended model adds some skip connections to the standard tree-structured model. As the complexity of the graph (or the number of connections) increases (Tree-Bypass-Extended-Full), the grouping accuracy increases from 56.1% to 60.4% mAP. In addition, the runtime of different graph configurations is almost the same. Therefore, we choose the fully-connected graph in our implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Qualitative Analysis</head><p>In <ref type="figure" target="#fig_1">Figure 5</ref>, we visualize the grouping procedure of OHGC algorithm. We use different colors to denote different clusters and dashed lines to highlight the macro-node merging process. OHGC starts with a set of keypoint candidates, each of which belongs to its own cluster. The grouping is performed iteratively. In each iteration, the most easy-to-group keypoints are merged. We show that the grouping procedure forms a pose hierarchy, from part to whole. Our method benefits from global supervision, which helps improve the grouping performance.</p><p>For failure cases, however, the current model is not able to recover false negatives or localization errors. Tiny people in images can lead to false negatives. Severe occlusion and non-typical poses may lead to localization errors. More testtime augmentation such as multi-scale testing, may mitigate these issues. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparisons with the State-of-the-art Methods</head><p>We compare our framework with the state-of-the-art methods on two large-scale multi-person pose estimation benchmarks. <ref type="table" target="#tab_1">Table 1a</ref> shows experimental results on MSCOCO test-dev set. We see that the proposed HGG model achieves overall 67.6 AP. which is slightly lower than the state-of-the-art method PersonLab <ref type="bibr" target="#b32">[33]</ref>. However, PersonLab uses extra annotations for instance segmentation. Moreover, we also compare our method with recent single-shot methods (SPM <ref type="bibr" target="#b31">[32]</ref> and DirectPose <ref type="bibr" target="#b39">[40]</ref>). Surprisingly, although ours are lower than them in AP 50 , in AP 75 ours are superior to them. This further indicates that our methods have advantages in scenarios that require high-precision pose estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results on MSCOCO dataset</head><p>Results on OCHuman Dataset To verify the robustness of HGG and other methods, we evaluate the proposed HGG model on the more challenging OCHuman dataset. We can see that our method achieves 41.8% and 36.0% mAP on val and test set, establishing a new state-of-the-art. Especially, HGG even outperforms top-down method SBL with 2.7 AP in test set, which further indicates our method is robust on more challenging scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Runtime Analysis</head><p>We analyze the time cost of the modules in HGG. Specifically, we evaluate our method on val set of MS-COCO and calculate the average time cost per image as shown in <ref type="figure" target="#fig_0">Fig. 4b</ref>. The results are tested using PyTorch with a batchsize of 1 on one GTX-1060 GPU in a single thread. We find that the time cost of the grouping module is only a small proportion of the total time cost. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we have reformulated the human pose estimation problem using the graph model and presented a full end-to-end learning framework named HGG. We have shown how we can combine the representative feature learning ability of CNN and the efficient long-range message passing as well as the relational feature learning capability of GNN. The macro-node discriminator and the edge discriminator are introduced to supervise the whole grouping process. We envision that the proposed framework can also be applied to other related problems such as multi-object tracking and instance segmentation. We expect to see more research in this direction in the near future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 4 .</head><label>4</label><figDesc>(a) Comparisons of different graph configurations on the COCO val set. Fully-connected graph (Full) performs the best among them. (b) Runtime analysis measured on one GTX-1060 GPU. The grouping module is very efficient compared to the keypoint proposal module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 5 .</head><label>5</label><figDesc>The grouping process visualization. We show the grouped keypoint clusters in each iteration. Different colors are used to indicate different clusters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>(a) Comparisons with both top-down and bottom-up methods on COCO2017 test-dev dataset. * means using single-person pose refinement. ? means using extra segmentation annotation. + means using multi-scale test. Not that our results are obtained without single-person pose refinement.(b) Comparisons with both top-down and bottom-up methods on OCHuman dataset. Our results are obtained without single-person pose refinement.</figDesc><table><row><cell>Method</cell><cell>AP AP 50 AP 75 AP M AP L AR</cell><cell></cell><cell></cell></row><row><cell>Top-down methods</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Mask-RCNN [16] 63.1 87.3 68.7 57.8 71.4 ?</cell><cell></cell><cell></cell></row><row><cell>G-RMI [34]</cell><cell>64.9 85.5 71.3 62.3 70.0 69.7</cell><cell></cell><cell></cell></row><row><cell>IPR [39] CPN [6]</cell><cell>67.8 88.2 74.8 63.9 74.0 ? 72.1 91.4 80.0 68.7 77.2 78.5</cell><cell cols="2">OCHuman Backbone Val Test</cell></row><row><cell>RMPE [12] CFN [17] SBL [46]</cell><cell>72.3 89.2 79.1 68.0 78.6 ? 72.6 86.1 69.7 78.3 64.1 ? 73.7 91.9 81.1 70.3 80.0 79.0</cell><cell cols="2">Top-down methods RMPE [12] Hourglass 38.8 30.7</cell></row><row><cell cols="2">HRNet-W48 [38] 75.5 92.5 83.3 71.9 81.5 80.5</cell><cell>SBL [46]</cell><cell>ResNet50 37.8 30.4</cell></row><row><cell cols="2">Bottom-up methods OpenPose  *  [3] AE  * + [29] PersonLab +? [33] 68.7 89.0 75.4 64.1 75.5 75.4 61.8 84.9 67.5 57.1 68.2 66.5 65.5 86.8 72.3 60.6 72.6 70.2 Directpose + [40] 64.8 87.8 71.1 60.4 71.5 ?</cell><cell cols="2">SBL [46] Bottom-up methods ResNet152 41.0 33.3 AE [29] Hourglass 32.1 29.5 AE + [29] Hourglass 40.0 32.8</cell></row><row><cell>SPM  * + [32]</cell><cell>66.9 88.5 72.9 62.6 73.1 ?</cell><cell>Ours</cell><cell>Hourglass 35.6 34.8</cell></row><row><cell>Ours +</cell><cell>67.6 85.1 73.7 62.7 74.6 71.3</cell><cell>Ours +</cell><cell>Hourglass 41.8 36.0</cell></row><row><cell></cell><cell>(a)</cell><cell></cell><cell>(b)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Ablation study of HGG's components on the COCO validation dataset."FinalM" means the final level macro-node discriminator. "Edge" means edge discriminator. " IntermM" means intermediate macro-node discriminator. "MS" means multi-scale testing.# Method Clustering FinalM Edge IntermM. MS AP AP 50 AP 75 AR AR 50 AR 75</figDesc><table><row><cell cols="2">1 AE [29]</cell><cell>57.6 79.7 62.6 62.1 81.4 66.1</cell></row><row><cell cols="2">2 AE [29]</cell><cell>65.6 85.1 71.9 69.1 86.7 74.2</cell></row><row><cell>3</cell><cell>Ours</cell><cell>58.2 80.8 63.9 63.4 83.5 68.0</cell></row><row><cell>4</cell><cell>Ours</cell><cell>59.6 81.3 65.1 64.2 83.0 69.0</cell></row><row><cell>5</cell><cell>Ours</cell><cell>60.1 81.6 66.0 64.5 83.4 69.6</cell></row><row><cell>6</cell><cell>Ours</cell><cell>59.6 81.9 65.5 63.9 83.3 68.4</cell></row><row><cell cols="2">7 Ours-FC</cell><cell>58.3 80.7 63.3 62.5 82.1 66.9</cell></row><row><cell cols="2">8 Ours-GAT</cell><cell>59.3 81.1 65.5 63.9 82.8 69.0</cell></row><row><cell>9</cell><cell>Ours</cell><cell>60.4 83.0 66.2 64.8 84.0 69.8</cell></row><row><cell>10</cell><cell>Ours</cell><cell>68.3 86.7 75.8 72.0 88.3 78.0</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/princeton-vl/pose-ae-train</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<title level="m">Curriculum learning. In: International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6203</idno>
		<title level="m">Spectral networks and locally connected networks on graphs</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Realtime multi-person 2d pose estimation using part affinity fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Detect what you can: Detecting and representing objects using holistic models and body parts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Articulated pose estimation by a graphical model with image dependent pairwise relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cascaded pyramid network for multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graphbased global reasoning networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shuicheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kalantidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Crf-cnn: Modeling structured information in human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Weighted graph cuts without eigenvectors a multilevel approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2007" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Doering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.04596</idno>
		<title level="m">Joint flow: Temporal flow fields for multi person tracking</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rmpe: Regional multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pictorial structures for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The representation and matching of pictorial structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Elschlager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.06870</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Mask r-cnn. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A coarse-fine network for keypoint localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Arttrack: Articulated multi-person tracking in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Levinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Campus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deepercut: A deeper, stronger, and faster multi-person pose estimation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">PoseTrack: A benchmark for human pose estimation and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ensafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07727</idno>
		<title level="m">Pose-track: Joint multi-person pose estimation and tracking</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-person articulated tracking with spatial and temporal embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Towards multi-person pose tracking: Bottom-up and top-down methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV PoseTrack Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Clustered pose and nonlinear appearance models for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>BMVC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Crowdpose: Efficient crowded scenes pose estimation and a new benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A cascaded inception of inception network with attention modulated feature fusion for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Associative embedding: End-to-end learning for joint detection and grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>NeurIPS</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Generative partition networks for multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07422</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Single-stage multi-person pose machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Personlab: Person pose estimation and instance segmentation with a bottom-up, partbased, geometric embedding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.08225</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Towards accurate multi-person pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.01779</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deepcut: Joint subset partition and labeling for multi person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks (TNN)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">End-to-end learning for graph decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09212</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Integral human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Directpose: Direct end-to-end multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.07451</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fcos: Fully convolutional one-stage object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Joint training of a convolutional network and a graphical model for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Graph attention networks. International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.00603</idno>
		<title level="m">Bi-directional graph structure information model for multi-person pose estimation</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Simple baselines for human pose estimation and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Polarmask: Single shot instance segmentation with polar representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.13226</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Spatial temporal graph convolutional networks for skeleton-based action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Articulated human detection with flexible mixtures of parts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2012" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Human pose estimation with spatial contextual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.01760</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Pose2seg: detection free human instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rosin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07850</idno>
		<title level="m">Objects as points</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
