<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">g2pM: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin Chinese Based on a New Open Benchmark Dataset</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyubyong</forename><surname>Park</surname></persName>
							<email>kyubyong.park@kakaobrain.com</email>
							<affiliation key="aff0">
								<orgName type="institution">KAIST</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seanie</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">KAIST</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kakao</forename><surname>Brain</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">KAIST</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">South</forename><surname>Korea</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">KAIST</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">g2pM: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin Chinese Based on a New Open Benchmark Dataset</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms: Grapheme-to-phoneme conversion</term>
					<term>Chinese polyphone disambiguation</term>
					<term>text-to-speech</term>
					<term>Python package</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conversion of Chinese graphemes to phonemes (G2P) is an essential component in Mandarin Chinese Text-To-Speech (TTS) systems. One of the biggest challenges in Chinese G2P conversion is how to disambiguate the pronunciation of polyphones-characters having multiple pronunciations. Although many academic efforts have been made to address it, there has been no open dataset that can serve as a standard benchmark for a fair comparison to date. In addition, most of the reported systems are hard to employ for researchers or practitioners who want to convert Chinese text into pinyin at their convenience. Motivated by these, in this work, we introduce a new benchmark dataset that consists of 99,000+ sentences for Chinese polyphone disambiguation. We train a simple Bi-LSTM model on it and find that it outperforms other preexisting G2P systems and slightly underperforms pre-trained Chinese BERT. Finally, we package our project and share it on PyPi.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Chinese grapheme to phoneme (G2P) conversion is a task that changes Chinese text into pinyin, an official Romanization system of Chinese. It is considered essential in Chinese Text-to-Speech (TTS) systems as unlike English alphabets, Chinese characters represent the meanings, not the sounds. A major challenge in Chinese G2P conversion is how to disambiguate the pronunciation of polyphones-characters having more than one pronunciation. In the example below, the first ? is pronounced de, which means the possessive particle "of", while the second one is pronounced d?, which denotes the "purpose".</p><p>? Input: ???? ? ??? ? ????? Translation: What is the purpose of coming today? Output: j?n ti?n l?i de m? d? sh? sh?n me ?</p><p>There have been many academic efforts to tackle this problem <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref>. However, we find there exist two main problems with them. First, there are no standard benchmark datasets for Chinese polyphone disambiguation. As shown in <ref type="table" target="#tab_0">Table 1</ref>, most past works collect copyright data from the Internet, and annotate themselves. Due to the lack of a public benchmark dataset, they report results on different datasets. This makes it hard to compare different models. Second, all of the reports in <ref type="table" target="#tab_0">Table 1</ref> do not lead to the release of source code or packages where researchers or practitioners can convert Chinese text into pinyin at their convenience. * Equal contribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Work Year Data Source</head><p>License Code Motivated by these, we construct and release a new Chinese polyphone dataset and a Chinese G2P library using it. Our contribution is threefold:</p><p>? We create a new Chinese polyphonic character dataset, which we call Chinese Polyphones with Pinyin (CPP). It is freely available via our GitHub repository 1 .</p><p>? With the CPP dataset, we train simple neural network models for the Chinese polyphonic character to pinyin task. We find that our best model outperforms other existing G2P systems.</p><p>? We build a user-friendly Chinese G2P Python library based on one of our models, and share it on PyPi.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>G2P There are several works for Chinese polyphone disambiguation. They can be categorized into the traditional rulebased approach <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref> and the data driven approach <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b9">10]</ref>. The rule-based approach chooses the pronunciation of the polyphonic character based on predefined complex rules along with a dictionary. However, this requires a substantial amount of linguistic knowledge. The data driven approach, by contrast, adopts statistical methods such as Decision Tree <ref type="bibr" target="#b2">[3]</ref> or Maximum Entropy Model <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b9">10]</ref>. Recently <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref> use bidirectional Long Short-Term Memory (LSTM) <ref type="bibr" target="#b10">[11]</ref> to extract diverse features on the character, word, and sentence level. However, as they depend on external tools such as a word segmenter and a Part-Of-Speech tagger which are not perfect, they are inherently prone to the cascading errors. Recently, some works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> consider graphemes to phonemes as sequence transduction and leverage encoder-decoder architecture to generate multilingual phonemes.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Chinese Characters and Polyphones</head><p>We explore what percentage of Chinese characters are polyphones to gauge how important the polyphone disambiguation task is in Chinese. We download the latest Chinese wiki dump file 2 and extract plain Chinese text with WikiExtractor 3 . All characters including white spaces except Chinese characters are removed. As shown in <ref type="table" target="#tab_2">Table 2</ref>, the remaining text consists of 17,720 unique characters, or 363M character instances. Meanwhile, we collect the list of polyphones from the open-source dictionary, CC-CEDICT 4 . According to it, 762 out of the 17,720 characters, which account for only 4.30%, turn out to be polyphones. However, they occur 67M times in the text, accounting for as much as 18.49%. This indicates that disambiguating polyphones is a serious problem in Chinese. The most frequent 100 polyphones and their frequencies are provided in Appendix for reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The CPP (Chinese Polyphones with Pinyin) Dataset</head><p>In this section, we introduce the CPP dataset-a new Chinese polyphonic character dataset for the polyphone disambiguation task.   <ref type="table">Table 4</ref>: The number of polyphones and sentences in the CPP dataset by the number of possible pronunciations</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Collection</head><p>We split the aforementioned Chinese text in Wikipedia into sentences. If a sentence contains any traditional Chinese characters, it is filtered out. Also, sentences whose length is more than 50 characters or less than 5 characters are excluded. Then, we leave only the sentences having at least one polyphonic character. A special symbol (U+2581) is added to the left and right of a polyphonic character randomly chosen in a sentence to mark the target polyphone. Finally, in order to balance the number of samples across the polyphones, we clip the minimum and maximum number of sentences for any polyphones to 10 and 250, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Human Annotation</head><p>We have two native Chinese speakers annotate the target polyphonic character in each sentence with appropriate pinyin. To make it easier, we provide them with a set of possible pronunciations extracted from CC-CEDICT for the polyphonic character. Next, we ask the annotators to choose the correct one among those candidates. It is worth noting that we do not split the data in half for assignment. Instead, we assign both of the annotators the same entire sentences. Then, we compare each of their annotation results, and discard the sentence if they do not agree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Data Split</head><p>As a result, 99,264 sentences, each of which includes a target polyphone with the correct pinyin annotation, remain. Subsequently, we group them by polyphones. For each group, we shuffle and split the sentences into training, development, and test sets at the ratio of 8:1:1. See <ref type="table" target="#tab_4">Table 3</ref> for details. An example whose target polyphone is ? and its correct pinyin is 'jiao3' is shown below, where the digit denotes Chinese phonetic tone.</p><p>? Sentence: ????? ? ??? Label: jiao3   We also present how many pronunciations the polyphones in the dataset can have in <ref type="table">Table 4</ref>. Among 623 polyphones in the dataset, 553 (88.8%) have two possible pronunciations. There are 60 (9.6%) polyphones in the dataset that can have three pronunciations, and the rest 10 can have up to five pronunciations. All things being equal, we suppose the more pronunciations a polyphone can have, the more challenging it is for a predictor to disambiguate its correct pronunciation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Statistics</head><p>Finally, we explore how dominant the most frequent pronunciation in each polyphone is. As shown prominently in <ref type="figure" target="#fig_1">Figure 2</ref>, 73.52% of polyphones are associated with a single prevalent pronunciation that accounts for more than 90% of all samples. This implies that majority vote-picking up the pronunciation that occurrs most frequently in the training set-would be a strong baseline. However, it is also important to remember there are still many that are less inclined to a dominant pronunciation so majority vote is less effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Method</head><p>We consider Chinese polyphone disambiguation as a classification problem and train a function, parameterized by neural networks, which maps a polyphonic character to its pronunciation.</p><p>We do not use any external language processing tools such as word segmenter, entity recognizer, or Part-Of-Speech tagger. Instead, we take as input a sequence of characters and train the network in the end-to-end manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Embedding</head><p>Let x = (x1, . . . , xT ) ? R T a sequence of characters, which represent a sentence. We map each character xt to the dense embedding vector et ? R d with a randomly initialized lookup matrix E ? R V?d , where V is the number of all characters and d is the dimension of the embedding vectors. We denote a sequence of character embedding vectors by e = (e1, . . . , eT ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Bidirectional LSTM Encoder</head><p>The bidirectional Long Short-Term Memory (Bi-LSTM) <ref type="bibr" target="#b10">[11]</ref> network is used to encode the contextual information of the polyphonic character. At any time step t, the representation ht is the concatenation of the forward hidden state ( ? ? h t) and the backward hidden state (</p><formula xml:id="formula_0">? ? h t). ? ? h t = ???? LSTM(et, ? ? h t?1) ? ? h t = ???? LSTM(et, ? ? h t?1) ht = concat( ? ? h t, ? ? h t)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Fully Connected Layers</head><p>We use two fully connected layers to transform the encoded information into the classification label. Let j the position index of the polyphonic character in the sentence. The concatenated hidden state hj (dotted line in <ref type="figure" target="#fig_2">Figure 3</ref>) is fed into the twolayered feedforward network followed by the softmax function, yielding the pinyin probability distribution? over all possible pinyin classes as follows: y = (?1, . . . ,?c) = softmax(g2(?(g1(hj))))</p><p>where g1 and g2 are fully connected layers, and ? is a non-linear activation function such as ReLU <ref type="bibr" target="#b13">[14]</ref>, and c is the number of possible pinyin classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Loss Function</head><p>Let y = (y1, . . . , yc) ? R c be a one-hot vector of a true label. We use cross-entropy as a loss function for training. In other words, we minimize the negative log-likelihood to find the optimal parameters ?, which we denote as?.</p><formula xml:id="formula_2">L(?) = ? c j=1 yj log(?j) (2) ? = arg min ? L(?)<label>(3)</label></formula><p>6. Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Training</head><p>We randomly initialize the character embedding matrix and fix its dimension to 64. To find the optimal hyperparameter val-   <ref type="table">Table 6</ref>: Test set accuracy of Chinese g2p systems ues, we vary the hidden size 5 in <ref type="bibr" target="#b15">(16,</ref><ref type="bibr">32,</ref><ref type="bibr">64)</ref> and the number of layers in the Bi-LSTM encoder in <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3)</ref>. The dimension of the last two fully connected layers is set to 64, and ReLU <ref type="bibr" target="#b13">[14]</ref> is used as the activation function.We train all the models with Adam optimizer <ref type="bibr" target="#b14">[15]</ref> and batch size 32 for 20 epochs. All the experiments are run five times with different random seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Evaluation</head><p>Hyperparameter Search <ref type="table" target="#tab_6">Table 5</ref> summarizes the development set accuracy of various models according to the hidden size and the number of layers in the Bi-LSTM encoder. We observe that the bigger the hidden size is, the higher the accuracy is, as expected. However, we get the better result when we use the fewer number of layers. The model of a single layer with 64 hidden units shows the best performance.</p><p>Baseline &amp; other systems As we mentioned earlier, we take so-called "majority vote" as a baseline. It decides the pronunciation of a polyphonic character by simply choosing the most frequent one in the training set. For example, ? can be pronounced lu?, g?, and lo, and their frequencies in the CPP training set are 63, 51, and 2, respectively. At test time, the majority vote system always picks up lu? for ?, irrespective of the context.</p><p>We also compare our model with three open-source Chinese G2P libraries: xpyinin 6 , pyinin 7 , and g2pC 8 . xpinyin and pypinyin are based on rules, while g2pC uses Conditional Random Fields (CRFs) <ref type="bibr" target="#b15">[16]</ref> for polyphone disambiguation. All of them are easily accessible through PyPi.</p><p>Finally, we test the pretrained Chinese BERT model <ref type="bibr" target="#b16">[17]</ref>. We take a finetuning approach; we attach a fully connected layer to the BERT network and feed the hidden state of the polyphonic character to it. We do not freeze any weights. Results Our model slightly underperforms Chinese BERT and outperforms all the other systems by large margin. As shown in <ref type="table">Table 6</ref>, ours reaches 97.31% accuracy on the test set, which is 4.33% point higher than the majority vote and 0.54 lower than <ref type="bibr" target="#b4">5</ref> The hidden size in this context refers to the size after the concatenation of the forward and backward hidden states. <ref type="bibr" target="#b5">6</ref>   <ref type="table">Table 7</ref>: Breakdown of g2pM. ? denotes the number of layers.</p><p>Chinese BERT. That our simple neural model shows comparable performance to the heavy BERT model, which has more than 102M parameters, tells us two things. One is that our model is simple but powerful enough. Another is that it is not too simple for the na?ve majority vote to beat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">g2pM: a Grapheme-to-Phoneme Conversion Library for Mandarin Chinese</head><p>We develop a simple Chinese G2P library in Python, dubbed g2pM, using our best Bi-LSTM model. The package provides an easy-to-use interface in which users can convert any Chinese sentence into a list of the corresponding pinyin. We share it on PyPi at https://pypi.org/project/g2pM/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Packaging</head><p>We implement g2pM purely in Python. In order to minimize the number of external libraries that must be pre-installed, we first re-write our Pytorch inference code in NumPy <ref type="bibr" target="#b17">[18]</ref>. Our best model is 1.7MB in size, and the package size is a little bigger, 2.1MB, as it includes some contents of CC-CEDICT. Details are shown in <ref type="table">Table 7</ref>. g2pM works like the following. Given a Chinese text, g2pM checks every character if it is a polyphonic character. If so, the neural network model returns its predicted pronunciation. Otherwise, the pronunciation of the (monophonic) character is retrieved from the dictionary contained in the package. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Usage</head><p>g2pM provides simple APIs for operation. With a few lines of code, users can convert any Chinese text into a sequence of pinyin. An example is available in <ref type="figure" target="#fig_3">Figure 4</ref>. More details are on the Github repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>We proposed a new benchmark dataset for Chinese polyphone disambiguation, which is freely and publicly available. We trained simple deep learning models, and created a Python package with one of them. We hope our dataset and library will be helpful for researchers and practitioners.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>shows how many sentence samples each of the polyphones in the CPP dataset has. 73.5% of polyphones (458 of 623) have 150-250 samples, while only 13.8%, i.e., 86 polyphones have less than 50 samples. Obviously, this comes from the differences in the frequency of polyphones.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The number of polyphones by the share of the most frequent pinyin for each polyphonic character.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Conceptual illustration of our models. A sequence of dense character embeddings are encoded with bidirectional LSTMs and the hidden state of the polyphonic character (redcolored) is fed to the feedforward network. It outputs the distribution of the pinyin candidates and finally the most probable one, "de5" here, is decided as the pronunciation of the character ?.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Usage example of g2pM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>[5] 2001 Ren Ming Daily</cell><cell>copyright N/A</cell></row><row><cell>[6] 2002 People Daily</cell><cell>copyright N/A</cell></row><row><cell cols="2">[7] 2008 Sinica and China Times copyright N/A</cell></row><row><cell>[8] 2009 People's Daily</cell><cell>copyright N/A</cell></row><row><cell>[3] 2010 People's Daily</cell><cell>copyright N/A</cell></row><row><cell>[2] 2011 People's Daily</cell><cell>copyright N/A</cell></row><row><cell>[9] 2004 People Daily</cell><cell>copyright N/A</cell></row><row><cell>[1] 2016 the Internet</cell><cell>copyright N/A</cell></row><row><cell>[4] 2019 Data Baker Ltd</cell><cell>copyright N/A</cell></row></table><note>: Summary of major past works. Note that most of them source the data from the Internet news articles so it is impossi- ble to access. [4] use a commercial company's internal dataset which is not freely available.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Percentage of Chinese polyphones in Wikipedia. A monophone is a character that has a single pronunciation.</figDesc><table><row><cell>Figure 1: The number of sentences for each polyphonic charac-</cell></row><row><cell>ters in CPP dataset. On average, a polyphonic character has</cell></row><row><cell>about 159 sentences.</cell></row><row><cell>Benchmark Dataset To the best of out knowledge, there are</cell></row><row><cell>no standard benchmark datasets for Chinese polyphone dis-</cell></row></table><note>ambiguation. In contrast, there are several public bench- mark datasets for English G2P such as CMUDict, Pronlex and NetTalk.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Basic statistics of CPP dataset</figDesc><table><row><cell cols="3"># Pronunciations # Polyphones # Sentences</cell></row><row><cell>Total</cell><cell>623 (100%)</cell><cell>99,264 (100%)</cell></row><row><cell>2</cell><cell>553 (88.8%)</cell><cell>87,584 (88.2%)</cell></row><row><cell>3</cell><cell>60 (9.6%)</cell><cell>10,162 (10.2%)</cell></row><row><cell>4-5</cell><cell>10 (1.6%)</cell><cell>1,518 (1.6%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>? 0.11 85.30 ? 4.50 32 96.64 ? 0.04 96.01 ? 0.14 95.75 ? 0.14 64 97.15 ? 0.09 97.09 ? 0.05 96.58 ? 0.07</figDesc><table><row><cell>H</cell><cell>L</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell cols="2">16</cell><cell>94.34 ? 0.17</cell><cell>92.99</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Development set accuracy of varying models by the hidden size (denoted as H) and the number of LSTM layers (denoted as L). Note that the model in bold face is the best one.</figDesc><table><row><cell>System</cell><cell>Test Accuracy</cell></row><row><cell>Majority vote</cell><cell>92.08</cell></row><row><cell>xpinyin (0.5.6)</cell><cell>78.56</cell></row><row><cell>pypinyin (0.36.0)</cell><cell>86.13</cell></row><row><cell>g2pC (0.9.9.3)</cell><cell>84.45</cell></row><row><cell>Chinese BERT</cell><cell>97.85</cell></row><row><cell>Ours</cell><cell>97.31</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/kakaobrain/g2pM arXiv:2004.03136v5 [cs.CL] 17 Sep 2020</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A bi-directional lstm approach for polyphone disambiguation in mandarin chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Symposium on Chinese Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Polyphone disambiguation based on maximum entropy model in mandarin grapheme-to-phoneme conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Key Engineering Materials</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Polyphonic word disambiguation with machine learning approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Polyphone disambiguation for mandarin chinese using conditional neural network with multi-level embedding features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Disambiguation of chinese polyphonic characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiangsheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Weidong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shiwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First International Workshop on MultiMedia Annotation (MMA2001)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An efficient way to learn rules for grapheme-to-phoneme conversion in chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zirong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Eric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2002 International Symposium on Chinese Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Disambiguating effectively chinese polyphonic ambiguity based on unify approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-L</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 International Conference on Machine Learning and Cybernetics (ICMLC)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improved grapheme-tophoneme conversion for mandarin tts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tsinghua Science and Technology</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Grapheme-to-phoneme conversion in chinese tts system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2004 International Symposium on Chinese Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Inequality maximum entropy classifier with character features for polyphone disambiguation in mandarin tts systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE International Conference on Acoustics, Speech and Signal Processing-ICASSP&apos;07</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Multilingual grapheme-to-phoneme conversion with byte representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lepird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Sathyendra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mouchtaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kunzmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural Machine Translation for Multilingual Grapheme-to-Phoneme Conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rohlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rastrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Agarap</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.08375</idno>
		<title level="m">Deep learning using rectified linear units (relu)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Pereira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Pre-training with whole word masking for chinese bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.08101</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gommers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Oliphant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Haberland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Burovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Weckesser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Van Der Walt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Jarrod</forename><surname>Millman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mayorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R J</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Polat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vand Erplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Laxalde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Perktold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cimrman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Henriksen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Quintero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Archibald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Van Mulbregt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">.</forename><surname>Contributors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
