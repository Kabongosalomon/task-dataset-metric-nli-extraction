<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hyperspectral Image Classification with Markov Random Fields and a Convolutional Neural Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyong</forename><surname>Cao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Feng</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Deyu</forename><surname>Meng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">John</forename><surname>Paisley</surname></persName>
						</author>
						<title level="a" type="main">Hyperspectral Image Classification with Markov Random Fields and a Convolutional Neural Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a new supervised classification algorithm for remotely sensed hyperspectral image (HSI) which integrates spectral and spatial information in a unified Bayesian framework. First, we formulate the HSI classification problem from a Bayesian perspective. Then, we adopt a convolutional neural network (CNN) to learn the posterior class distributions using a patch-wise training strategy to better use the spatial information. Next, spatial information is further considered by placing a spatial smoothness prior on the labels. Finally, we iteratively update the CNN parameters using stochastic gradient decent (SGD) and update the class labels of all pixel vectors using ?-expansion min-cut-based algorithm. Compared with other state-of-the-art methods, the proposed classification method achieves better performance on one synthetic dataset and two benchmark HSI datasets in a number of experimental settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Hyperspectral remote sensors capture digital images in hundreds of continuous narrow spectral bands to produce a highdimensional hyperspectral image (HSI). Since HSI provides detailed information on spectral and spatial distributions of distinct materials <ref type="bibr" target="#b48">[49]</ref>, it has been used for many applications, such as land-use mapping [10], <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b47">[48]</ref>, land-cover mapping [34], forest inventory <ref type="bibr" target="#b42">[43]</ref>, and urban-area monitoring <ref type="bibr" target="#b52">[53]</ref>. All these applications require the material class label of each hyperspectral pixel vector and thus HSI classification has been an active research topic in the field of remote sensing. The aim of HSI classification is to categorize each hyperspectral pixel vector into a discrete set of meaningful classes according to the image contents.</p><p>In the last few decades, many methods have been proposed for HSI classification. These methods can be roughly divided into two categories: spectral based methods and spectralspatial based methods. We first briefly review these HSI classification approaches and then discuss the contributions of our proposed method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract-This paper presents a new supervised classification algorithm for remotely sensed hyperspectral image (HSI) which integrates spectral and spatial information in a unified Bayesian framework. First, we formulate the HSI classification problem from a Bayesian perspective. Then, we adopt a convolutional neural network (CNN) to learn the posterior class distributions using a patch-wise training strategy to better use the spatial information. Next, spatial information is further considered by placing a spatial smoothness prior on the labels. Finally, we iteratively update the CNN parameters using stochastic gradient decent (SGD) and update the class labels of all pixel vectors using ?-expansion min-cut-based algorithm. Compared with other state-of-the-art methods, the proposed classification method achieves better performance on one synthetic dataset and two benchmark HSI datasets in a number of experimental settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Hyperspectral remote sensors capture digital images in hundreds of continuous narrow spectral bands to produce a highdimensional hyperspectral image (HSI). Since HSI provides detailed information on spectral and spatial distributions of distinct materials <ref type="bibr" target="#b48">[49]</ref>, it has been used for many applications, such as land-use mapping <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b47">[48]</ref>, land-cover mapping <ref type="bibr" target="#b33">[34]</ref>, forest inventory <ref type="bibr" target="#b42">[43]</ref>, and urban-area monitoring <ref type="bibr" target="#b52">[53]</ref>. All these applications require the material class label of each hyperspectral pixel vector and thus HSI classification has been an active research topic in the field of remote sensing. The aim of HSI classification is to categorize each hyperspectral pixel vector into a discrete set of meaningful classes according to the image contents.</p><p>In the last few decades, many methods have been proposed for HSI classification. These methods can be roughly divided into two categories: spectral based methods and spectralspatial based methods. We first briefly review these HSI classification approaches and then discuss the contributions of our proposed method. <ref type="bibr">Xiangyong</ref>  A. Related work: spectral vs spectral-spatial based methods Many classical HSI classification approaches are only based on spectral information <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b61">[62]</ref>. Among these methods, pure spectral classification without any band reduction has often been proposed in the literature <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b43">[44]</ref>. Besides, some other pure spectral methods which extract spectral feature first using some feature extraction methods, such as principal component analysis <ref type="bibr" target="#b39">[40]</ref>, independent component analysis <ref type="bibr" target="#b61">[62]</ref> and linear discriminant analysis <ref type="bibr" target="#b1">[2]</ref>, have also been proposed. However, these approaches only consider the spectral information and ignore the correlations among distinct pixels in the image, which tends to decrease their classification performance relative to those which consider both. In this paper we instead focus on designing a spectral-spatial based classification method.</p><p>Spectral-spatial based methods can help improve the classification performance since they incorporate additional spatial information from the HSI. It has been often observed that spatial information is often as crucial as spectral information in the HSI classification task <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b58">[59]</ref>. Therefore, spectral-spatial methods have been proposed that additionally consider spatial correlation information. One approach is to extract the spatial dependence in advance using a spatial feature extraction method before learning a classifier. The patchbased feature extraction method is a representative example of this approach <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b56">[57]</ref>. Here, features are extracted from groups of neighboring pixels using a subspace learning technique such as low-rank matrix factorization <ref type="bibr" target="#b63">[64]</ref>, dictionary learning <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b54">[55]</ref> or subspace clustering <ref type="bibr" target="#b31">[32]</ref>. Compared with the original spectral vector, the features extracted by patch-based methods have higher spatial smoothness with some reduced noise <ref type="bibr" target="#b11">[12]</ref>.</p><p>Another popular spectral-spatial approach to incorporate spatial information is using a Markov random field (MRF) to post-process the classification map. MRF is an undirected graphical model <ref type="bibr" target="#b3">[4]</ref> that has been applied in a variety of fields from physics to computer vision and machine learning. In particular, they have been widely used for image processing tasks such as image registration <ref type="bibr" target="#b69">[70]</ref>, image restoration <ref type="bibr" target="#b4">[5]</ref>, image compression <ref type="bibr" target="#b50">[51]</ref> and image segmentation <ref type="bibr" target="#b12">[13]</ref>. In the image segmentation task, MRFs encourage neighboring pixels to have the same class label <ref type="bibr" target="#b38">[39]</ref>. This has been shown to greatly improve the classification accuracy in HSI classification task <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b60">[61]</ref>.</p><p>Another family of spatial-spectral methods is based on spatial regularization (anisotropic smoothing) prior to spec-tral classification of the regularized image <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b44">[45]</ref>. Aside from these methods, some other spatial-spectral methods have also been proposed, such as 3-dimensional discrete wavelet transform <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b49">[50]</ref>, 3-dimensional Gabor wavelets <ref type="bibr" target="#b53">[54]</ref>, morphological profiles <ref type="bibr" target="#b2">[3]</ref>, attribute profiles <ref type="bibr" target="#b19">[20]</ref> and manifold learning methods <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b41">[42]</ref>.</p><p>Although the previous approaches perform well, a drawback to many of these approaches is that the extracted features are hand-crafted. Specifically, these approaches extract the features of the HSI by pre-specified strategies manually designed directly on data without using the label information and not via an "end-to-end" manner such as the deep learning approaches introduced here. Thus they highly depend on prior knowledge of the specific domain and are often sub-optimal <ref type="bibr" target="#b67">[68]</ref>. In the last few years, deep learning has been a powerful machine learning technique for learning data-dependent and hierarchical feature representations from raw data <ref type="bibr" target="#b24">[25]</ref>. Such methods have been widely applied to image processing and computer vision problems, such as image classification <ref type="bibr" target="#b36">[37]</ref>, image segmentation <ref type="bibr" target="#b12">[13]</ref>, action recognition <ref type="bibr" target="#b30">[31]</ref> and object detection <ref type="bibr" target="#b57">[58]</ref>.</p><p>Recently, a few deep learning methods have been introduced for the HSI classification task. For example, unsupervised feature learning methods such as stacked autoencoders <ref type="bibr" target="#b13">[14]</ref> and deep belief networks <ref type="bibr" target="#b16">[17]</ref> have been proposed. Although these two unsupervised learning models can extract deep hierarchical feature, the 3-dimensional (3D) patch must be first flattened into 1-dimensional (1D) vectors in order to satisfy the input requirement, thus losing some spatial information. A supervised autoencoder <ref type="bibr" target="#b40">[41]</ref> method that used label information during feature learning was also proposed. Similar methods have been proposed based on the convolutional neural network (CNN), for example, using a five-layer CNN trained on a 1D spectral vector without using spatial information <ref type="bibr" target="#b28">[29]</ref>, using a modified spectral-spatial deep CNN (SS-DCNN) <ref type="bibr" target="#b66">[67]</ref> with 3D patch input, or deep CNNs with spatial pyramid pooling (SPP) <ref type="bibr" target="#b26">[27]</ref> (SPP-DCNN) <ref type="bibr" target="#b65">[66]</ref>. Other methods based on CNNs <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b67">[68]</ref> and recurrent neural networks (RNNs) <ref type="bibr" target="#b45">[46]</ref> have also been proposed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Contributions of our approach</head><p>As mentioned, compared with the traditional spectral-spatial HSI classification methods, deep learning can directly learn data-dependent and hierarchical feature representation from raw data. Although all the above deep learning methods obtain good performance, none of them formulate the HSI classification task into a Bayesian framework, where deep learning and MRF are considered simultaneously. Therefore, in this paper we propose a new supervised HSI classification algorithm in a Bayesian framework based on deep learning and MRF. Our contributions are threefold: 1) We formulate the HSI classification problem from a Bayesian perspective and solve this problem by introducing an intermediate variable and other simplifications.</p><p>2) We propose a new model which combines a CNN with a smooth MRF prior. Specifically, the CNN is used to extract spectral-spatial features from 3D patches and the smooth MRF prior is placed on the labels to further exploit spatial information. Optimizing the final model can be done by iteratively updating CNN parameters and class labels of all the pixel vectors. In this way, we integrate the MRF with the CNN. To our knowledge, this is the first approach that integrates the MRF with the CNN for the HSI classification problem.</p><p>3) Our experimental results on one synthetic HSI dataset and two real HSI datasets demonstrate that the proposed method outperforms other state-of-the-art methods for the HSI classification problem, in particular the three deep learning methods SS-DCNN <ref type="bibr" target="#b66">[67]</ref>, SPP-DCNN <ref type="bibr" target="#b65">[66]</ref> and DC-CNN <ref type="bibr" target="#b67">[68]</ref>.</p><p>The rest of the paper is organized as follows: In Section 2 we formulate the HSI classification problem from a Bayesian perspective. In Section 3 we describe our proposed approach. In Section 4 we conduct experiments on one synthetic dataset and two benchmark real HSI datasets and compare with stateof-the-art methods. We conclude in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROBLEM FORMULATION</head><p>Before formulating the HSI classification problem, we first define the problem-related notations used throughout the paper.</p><p>1) Problem notation: Let the HSI dataset be H ? R h?w?d , where h and w are the height and width of the spatial dimensions, respectively, and d is the number of spectral bands. The set of class labels is defined as K = {1, 2, . . . , K}, where K is the number of classes for the given HSI dataset. The set of all patches extracted from HSI data H is denoted as X = {x 1 , x 2 , . . . , x n }, where x i ? R k?k?d , k is the patch size in the spatial dimension, n = hw represents the total number of extracted patches (sliding step is 1 and padding is used). Each patch x i is first fed into a CNN (shown in <ref type="figure" target="#fig_2">Fig.1</ref>) and then a flattened vector z i is output. The corresponding label of z i is y i ? K, which is the label of the spectral vector corresponding to the center of x i . For the purpose of simplicity, we denote (x i , y i ) as a sample, which doesn't mean all pixel vectors in x i belong to the same class y i but means that the extracted spatial-spectral feature vector z i belongs to class y i . In other words, we use the 3-D patches only to obtain spatial-spectral feature for the corresponding central pixel vector of this patch. The label set is defined as y = {y 1 , y 2 , . . . , y n }. We define the training set for class k as D  </p><formula xml:id="formula_0">l (1) , D (2) l (2) , . . . , D (K) l (K) }, where l = K k=1 l (k)</formula><p>n is the total number of training patches.</p><p>2) Problem setup: The goal of HSI classification is to assign a label y i to the central pixel vector of each patch x i , i = 1, 2, . . . , n. In the discriminative classification framework, the estimation of labels y for observations X can be obtained by maximizing a distribution P(y|X , ?), where ? is the parameters of classifier. In our framework, we seek to combine the spatial modeling power of a Markov random field with the discriminative power of deep learning. Therefore, we let this distribution be of the form</p><formula xml:id="formula_1">P(y|X , ?) = y P(y, y|X , ?) = y P(y| y)P( y|X , ?) = y P(y| y) n i=1 P( y i |x i , ?),<label>(1)</label></formula><p>where y = [ y T 1 ; y T 2 ; . . . ; y T n ] ? R n?K is an intermediate variable, in which each y i ? R K provides an initial probabilistic label pseudo-annotations for each patch x i . In our work, we define the distribution P( y i |x i , ?) as</p><formula xml:id="formula_2">P( y i |x i , ?) = 1, y i = f (x i ; ?) 0, otherwise<label>(2)</label></formula><p>where f is a classifier. After the pseudo-annotations y is obtained. Then, a second classifier P(y| y) takes this collection of pseudo-annotations y and outputs the classification label y = [ y 1 ; y 2 ; . . . ; y n ], which can be made as y = arg max y?K n P(y|X , ?). However, since a sum over all y is computationally intensive, we simplify this in two ways for computational convenience. First, instead of only learning y by maximizing P(y|X , ?), we learn a point estimate of the pairs ( y, y) by maximizing P(y, y|X , ?). A goal is then to solve ( y, y) = arg max</p><formula xml:id="formula_3">y, y log P(y| y) + n i=1 log P( y i |x i , ?) . (3)</formula><p>Our second simplification takes the form of breaking the optimization problem in Eq. (3) into two subproblems. First, we calculate label pseudo-annotations y based on the classifier f . Then, given the annotation values y, the current classification results y can be obtained by maximizing log P(y| y). Thus Eq.</p><p>(3) can be solved by the following steps:</p><formula xml:id="formula_4">y i = f (x i ; ? * ), i = 1, 2, . . . , n<label>(4)</label></formula><formula xml:id="formula_5">y = arg max y?K n log P(y| y).<label>(5)</label></formula><p>Here it should be emphasized that classifier f is first trained on the training data set D l and ? * is the learned parameters of the classifier. After obtaining the current classification labels y on the whole HSI, next we train the classifier again using all the patches X and their corresponding labels y. The two steps are iteratively implemented until some criteria are satisfied. In this way, we can make full use of the unlabeled patches and thus more information can be incorporated in our framework. In this paper, in order to fully utilize both spatial and spectral information of HSI, we design a new approach based on this classification framework. Specifically, we firstly adopt a convolutional neural network (CNN) as the classifier f , which can not only help to extract spectral-spatial features for HSI, but also can provide label pseudo-annotations y i for each x i . Then, we place a smoothness prior on labels y to further enforce spatial consistency. In the following section, we will introduce these two aspects in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HSI Patch</head><formula xml:id="formula_6">k x k x d</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class Probability Fully Connected Layer Convolutional Layer Max Pooling Layer Convolutional Layer Max Pooling Layer Fully Connected Layer Fully Connected Layer</head><p>5x5 @100 2x2 3x3 @300</p><p>2x2 200 100 K <ref type="figure" target="#fig_2">Fig. 1</ref>. The network structure of the CNN used as our discriminative classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED APPROACH</head><p>In this section, we first introduce the convolutional neural network (CNN) classifier for HSIs. Then, we further consider spatial information by placing a smoothness prior on the labels y and formulate the classification task as a labeling problem in an MRF. Finally, we summarize the proposed classification algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Discriminative CNN-based classifier</head><p>Convolutional neural networks (CNN) play an important role in many computer vision tasks. They consist of combinations of convolutional layers and fully connected layers. Compared with the standard fully connected feed-forward neural network (also called multi-layer perceptrons, MLP), CNNs exploit spatial correlation by enforcing a local connectivity pattern between neurons of adjacent layers to achieve better performance in many image processing problem, such as image denoising <ref type="bibr" target="#b62">[63]</ref>, image super-resolution <ref type="bibr" target="#b20">[21]</ref>, image deraining <ref type="bibr" target="#b23">[24]</ref> and image classification <ref type="bibr" target="#b36">[37]</ref>.</p><p>In this paper, we adopt the CNN structure shown in <ref type="figure" target="#fig_2">Figure 1</ref>. This network contains one input layer, two pairs of convolution and max pooling layers, two fully connected layers and one output layer (The tuning of the network structure will be discussed in Section IV). The detailed parameter settings in each layer are also shown in <ref type="figure" target="#fig_2">Figure 1</ref>. For the hyperspectral image classification task, each sample is a 3D patch of size k ? k ? d. Next, we introduce the flow of processing each sample patch x i at each layer of the CNN.</p><p>We note that there is no need to flatten the sample patch x i into a 1-dimensional vector before it is fed into the input layer. Therefore, the input size of the first layer is k ? k ? d. First, the sample patch is input into the first convolutional layer, followed by a max pooling operation. The first convolutional layer filters the k ? k ? d sample patch using 100 filters of size 5 ? 5 ? d. After this convolution, we have 100 feature maps each n 1 ? n 1 , where n 1 = k ? 4. We then perform max pooling on the combined set of features of size n 1 ? n 1 ? 100. The kernel size of the max pooling layer is 2 ? 2 and thus the pooled feature maps have size of n 2 ? n 2 ? 100, where n 2 = n 1 /2 . This set of pooled feature maps are then passed through a second pair of convolutional and max pooling layers. The convolutional layer contains 300 filters of size 3?3?100, which filters the pooled feature maps into new feature maps of size n 3 ?n 3 ?300, where n 3 = n 2 ?2. Again these new feature maps are input into the second max pooling layer with kernel size 2 ? 2 and turned into a second set of pooled feature maps of size n 4 ?n 4 ?300, where n 4 = n 3 /2 . Finally, the second pooled feature maps are flattened into a 1-dimensional vector x pool2 and input to the fully connected layer. The computation of the next three fully connected layers are as follows:</p><formula xml:id="formula_7">f (5) (x pool2 ) = ?(W (5) x pool2 + b (5) ), (6) f (6) (x pool2 ) = ?(W (6) f (5) (x pool2 ) + b (6) ), (7) f (7) (x pool2 ) = W (7) f (6) (x pool2 ) + b (7) ,<label>(8)</label></formula><p>where W <ref type="bibr" target="#b4">(5)</ref> , W <ref type="bibr" target="#b5">(6)</ref> and W <ref type="bibr" target="#b6">(7)</ref> are weight matrices, b <ref type="bibr" target="#b4">(5)</ref> , b <ref type="bibr" target="#b5">(6)</ref> and b <ref type="bibr" target="#b6">(7)</ref> are the biases of the nodes, and ?(.) is the non-linear activation function. In our network, the activation functions in the convolutional layers and fully connected layers are all selected to be the rectified linear unit (ReLU) function. In order to simplify the notation,</p><formula xml:id="formula_8">we denote W = {W (1) , W (3) , W (5) , W (6) , W (7) } and b = {b (1) , b (3) , b (5) , b (6) , b (7) }, where {W (1) , W (3) } and {b (1) , b (3)</formula><p>} are the weight matrices and biases in the convolutional layers respectively. Thus the aforementioned classifier parameters ? are {W, b} in the CNN.</p><p>The final vector f <ref type="bibr" target="#b6">(7)</ref> ? R K is then passed to the softmax (normalized exponential) function, which gives a distribution on the label. As defined previously, the label pseudo-annotations is y i for a given sample x i . Then the pseudo-classification label can be obtained according to y c i = arg max k?K y ik . Therefore, given the training set (D l in the first updating and then the whole (X , y)) where we represent each scalar label y i ? K of a training sample as a one-hot vector y i ? R K , the cross-entropy (CE) loss function can be computed as</p><formula xml:id="formula_9">E(W, b) = 1 l i CE(y i , y (W,b) i ), = ? 1 l i K k=1 y ik log y (W,b) ik ,<label>(9)</label></formula><p>where W and b is the parameter set defined above and here we denote y i as y</p><formula xml:id="formula_10">(W,b) i</formula><p>in order to emphasize that the pseudoannotations y i is based on the learned CNN. The optimization of the loss function Eq. (9) is conducted by using the stochastic gradient descent (SGD) algorithm. In the t th iteration, the weight and bias are updated by</p><formula xml:id="formula_11">W t+1 = W t ? ? ?E(W, b) ?W | Wt ,<label>(10)</label></formula><formula xml:id="formula_12">b t+1 = b t ? ? ?E(W, b) ?b | bt ,<label>(11)</label></formula><p>where the gradients with respect to W and b are calculated using the back-propagation algorithm <ref type="bibr" target="#b51">[52]</ref> and ? is the learning rate, which is set as 0.001 in our experiments. Here it should be noted that unlike some CNN applications, where the CNN parameters are first pre-trained on some samples prepared in advance and then fine-tuned on the new dataset, our proposed CNN-MRF method is directly applied to each dataset without pre-training. In all our experiments, the CNN weight parameters W are initialized by random standard normal distribution and the bias parameters b are initialized with zeros. In order to alleviate the issue of overfitting of the proposed CNN in the training phase, dropout strategy <ref type="bibr" target="#b55">[56]</ref> is also adopted in the 5 th and 6 th fully connected layers and the dropout rate is set as 0.5 in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Label smoothness prior and MRF optimization</head><p>After the label pseudo-annotations y are obtained using the current trained CNN. Then, we begin to present our core model based on the simplifications from Eq. 1 to Eq. 5. Specifically, in order to obtain the classification results y we need to solve the following optimization problem</p><formula xml:id="formula_13">y = arg max y?K n log P(y| y) = arg max y?K n log P( y|y) + log P(y) = arg max y?K n n i=1 log P( y i |y i ) + log P(y)<label>(12)</label></formula><p>where y can be regarded as new features for this problem, log P( y i |y i ) is the log-likelihood and P(y) is the label prior. Specifically, in our work, the log-likelihood log P( y i |y i ) is defined as</p><formula xml:id="formula_14">log P( y i |y i ) = K k=1 1{y i = k} log y ik ,<label>(13)</label></formula><p>where 1{?} is an indicator function.</p><p>In image segmentation tasks, it is probable that adjacent pixels have the same label. The exploitation of this naive prior information can often dramatically improve the segmentation performance. In this paper, we enforce a spatially smooth prior on labels y to encourage neighboring pixels to belong to the same class. This smoothness prior distribution on labels y is defined as</p><formula xml:id="formula_15">P(y) = 1 Z e ? n i=1 j?N (i) ?(yi?yj ) ,<label>(14)</label></formula><p>where Z is a normalization constant for the distribution, ? is the label smoothness parameter, N (i) is the neighboring pixels of pixel i and ?(?) is a function defined as: ?(0) = 1 and ?(y) = ?1 for y = 0. We note that the pairwise interaction terms ?(y i ? y j ) obtain higher probability when neighboring labels are equal than when they are not equal. In this way, this smoothness prior can encourage piecewise smooth segmentations. Based on Eq. (13) and Eq. <ref type="formula" target="#formula_1">(14)</ref>, the final classification model (12) is thus given by</p><formula xml:id="formula_16">y = arg max y?K n ? ? ? n i=1 K k=1 1{y i = k}log y ik +? n i=1 j?N (i) ?(y i ?y j ) ? ? ? .<label>(15)</label></formula><p>This objective function contains many pairwise interaction terms and is a challenging combinatorial optimization problem. It can also be regarded as an MRF model in which an undirected model graph G =&lt; V, E &gt; is defined on the whole image, where graph node sets V correspond to pixels, and the undirected edge set E represents the neighboring relationship between the pixels <ref type="bibr" target="#b8">[9]</ref>. We define a random variable y i on each node v i ? V, thus allowing the labels y to form a Markov random field. The objective function is its energy function, of which the first term represents the cost of a pixel being assigned with different classes. The larger the probability of a pixel belonging to a certain class, the more probable that the pixel is assigned the corresponding label. The second term of the energy function encourages the labels of neighboring pixels to be the same.</p><p>This optimization problem of the MRF is NP-hard. Many approximating algorithms have been proposed, such as the graph cut method <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b35">[36]</ref>, belief propagation <ref type="bibr" target="#b64">[65]</ref> and message passing <ref type="bibr" target="#b34">[35]</ref>. In this paper, we use the ?-expansion mincut method <ref type="bibr" target="#b7">[8]</ref> because of its good performance and fast computation speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. CNN-MRF classification algorithm</head><p>After introducing how to update CNN's parameters and compute class labels respectively, we can summarize our CNN-MRF classification algorithm in detail in Algorithm 1. Besides, the corresponding flowchart of this algorithm is also depicted in <ref type="figure" target="#fig_3">Figure 2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>To test the effectiveness of our proposed CNN-MRF classification algorithm in different scenarios, we conduct experiments on one synthetic dataset and two real-world benchmark datasets. <ref type="bibr" target="#b0">1</ref> For comparison, we consider several state-of-the-art HSI classification methods, including support vector machine graph-cut method (SVM-GC), subspace multinomial logistic regression with multilevel logistic prior (MLRsubMLL) <ref type="bibr" target="#b1">2</ref>  <ref type="bibr" target="#b37">[38]</ref> and support vector machine based on the 3-dimensional discrete wavelet transform method (SVM-3DDWT-GC) <ref type="bibr" target="#b2">3</ref>  <ref type="bibr" target="#b11">[12]</ref>. It should be noted that the competing methods SVM-GC and MLRsubMLL are methods that integrate the MRF into the SVM and MLRsub methods, respectively. In order to distinguish the classification methods with MRF and without MRF, we denote them as classification methods and regularized classification methods, respectively. Besides, we also compare with three deep learning methods: SS-DCNN <ref type="bibr" target="#b66">[67]</ref>, SPP-DCNN <ref type="bibr" target="#b65">[66]</ref> and DC-CNN <ref type="bibr" target="#b67">[68]</ref>. Our proposed CNN-MRF approach is implemented in Python using the Tensorflow <ref type="bibr">[</ref>  library on a server with Nvidia GeForce GTX 1080 and Tesla K40c. All non-deep algorithms are run in Matlab R2014b. For comparisons with other deep learning models, we use the best reported results for these algorithms. All methods are compared numerically using the following three criteria <ref type="bibr" target="#b11">[12]</ref>: overall accuracy (OA), average accuracy (AA) and the kappa coefficient (?). OA represents the number of correctly classified samples divided by the total number of test samples, AA denotes the average of individual class accuracies, and ? involves both omission and commission errors and gives a good representation of the the overall performance of the classifier. For all the three criteria, a larger value indicates a better classification performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Synthetic HSI data</head><p>In this section, we first generate a synthetic HSI dataset. Then, we use this dataset to evaluate in detail the sensitivity of performance to different parameters setting of our CNN structure. Finally, we compare our method with other competing methods on this dataset using the tunning CNN structure.</p><p>1) Generation of Synthetic HSI data: To generate a synthetic HSI data, five endmembers are first extracted randomly from a real scene with 162 bands in ranges 400?2500 nm, and then 40000 vectors are generated as a sum of Gaussian fields with constraints so as to respect the abundance-nonnegative-constraint (ANC) and abundancesum-to-one-constraint (ASC). Finally, this dataset is generated using a Generalized Bilinear Mixing Model (GBM) <ref type="bibr" target="#b68">[69]</ref>:</p><formula xml:id="formula_17">z = K i=1 a i e i + K?1 i=1 K j=i+1</formula><p>? ij a i a j e i e j + n, <ref type="bibr" target="#b15">(16)</ref> with class number K = 5. Here z is the simulated pixel vector, ? ij are selected uniformly from [0, 1], e i , i = 1, . . . , 5 are the five end-members, n is the Gaussian noise with an SNR of 30 dB, a i ? 0 and K i=1 a i = 1.</p><p>2) Impact of parameter settings: In this section, we evaluate in detail the sensitivity of performance to different parameters settings of our CNN structure. In the following experiments, we use the synthetic dataset and randomly choose 1% training samples from each class as training data and the remaining for testing.</p><p>(1) Kernel Size: First, we test the impact of different kernel sizes. We fix the kernel size of the second layer as 3 and evaluate the performance by varying the kernel size in the first layer. <ref type="table" target="#tab_2">Table I</ref> shows these results. From this table we can conclude that larger kernel sizes can obtain better results. This is because more structure and texture can be captured using a larger kernel size. Therefore, in our experiments, we set the kernel size of the first layer as 5. (2) Network Width: Next, we evaluate the impact of network width in the convolutional layer on the classification results. Fixing the network width of the first convolutional layer to 100, we test the performance by changing the width of the second convolutional layer. These results are displayed in <ref type="table" target="#tab_2">Table II</ref>. It can be observed that the results are not very sensitive to the network width and thus in our experiments, we select 200 as the default setting of the network width in the second convolutional layer. (3) Network Depth: We also conduct experiments to test the impact of different network depths by reducing or adding non-linear layers. We train and test on 5 networks with depths 5, 7, 9, 11 and 13. The experimental results are summarized in <ref type="table" target="#tab_2">Table III</ref>. From this table it can be seen that increasing the network depth does not always generate better results, which may be a result of the gradient vanishing problem <ref type="bibr" target="#b27">[28]</ref> encountered by deeper neural networks. For this experiment, the best performance can be achieved by setting the network depth to 7, which we use as the default setting for the network depth in our experiments. (4) Patch Size: We also investigate the performances of our proposed method with respect to different data patch sizes k = {1, 3, 5, 9, 13}. These results are shown in <ref type="table" target="#tab_2">Table IV</ref>. As can be seen, a larger patch size of the sample generates better results. This is because more spatial information is incorporated into the training process. However, it also takes more computation time to train the network with an increasing patch size. Thus we choose 9 as the default setting of patch size as a tradeoff between performance and the running time.  For other parameters, such as the kernel size in max pooling layer which is set as 2, the number of nodes in the two fully connected layers, which are set as 200 and 100 respectively, we observe consistent performance under variations. Therefore, we didn't report their impact to the performance in this section. The learning rate ? is set as 0.001 and the batch size n batch is set as 100 for synthetic and Indian Pines dataset since consistent performance is also observed under variations. While for Pavia University dataset the learning rate is set to 0.0001 and the batch size n batch is set as 150. For the following experiments, we adopt the same network structure.</p><p>3) Experimental result of the synthetic HSI data: Using the parameter settings above for the CNN structure, we compare our CNN-MRF method with other competing methods. The final classification results are shown in <ref type="table" target="#tab_2">Table VI</ref>. From <ref type="table" target="#tab_2">Table  VI</ref>, we see that the proposed CNN-MRF method achieves better performance with respect to OA, AA and ? than other methods. We emphasize that all non-deep learning methods (namely SVM-GC, MLRsubMLL and SVM-3DDWT-GC) in this experiment use the MRF to post-process the classification map, and the differences between them and our method are the way to extract features and the iteratively updating the CNN parameters and class labels. Thus the improvement in our method here is due to the use of CNN and the integration of CNN with MRF. Comparing with other deep-learning method, our CNN-MRF method also outperforms them. For better visualization, we also demonstrate the final classification map in <ref type="figure" target="#fig_4">Figure 3</ref>. From <ref type="figure" target="#fig_4">Figure 3</ref>, we can see that the classification maps obtained by our method are visually closer to the ground truth map than the other methods, which is consistent with the quantitative metric OA.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Real HSI Data</head><p>We next test our method on two real HSI benchmark datasets, the Indian Pines dataset and Pavia University dataset, in a variety of experimental settings. To first evaluate our proposed CNN-MRF method in the scenario of limited training samples, we randomly choose 10% of the available labeled samples for each class from the reference data, which is an imbalanced training sample case, and use the remaining samples in each class for testing. The training and testing sets are summarized in <ref type="table" target="#tab_2">Table VII</ref>. This experiment is repeated 20 times for each method and the average performance is reported.</p><p>Additionally, some parameters need to be set in advance in these experiments. For the competing methods, their parame-  ters are set as their papers suggest: For SVM-based methods, the RBF kernel parameter ? and the penalty parameter C are tuned through 5-fold cross validation (? = 2 ?8 , 2 ?7 , . . . , 2 8 , C = 2 ?8 , 2 ?7 , . . . , 2 8 ). For SVM-GC and SVM-3DDWT-GC, the spatial smoothness parameter ? is set as 0.75 advised by <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b60">[61]</ref>. For MLRsubMLL, the smoothness parameter ? and the threshold parameter ? are set following <ref type="bibr" target="#b37">[38]</ref>. For our proposed CNN-MRF method, we adopt the same network structure as the synthetic HSI data. For the above experimental settings, in order to measure the performance improvement due to including spatial contextual information with the MRF, we also report the classification results of each method without using the MRF prior, and call these methods SVM, MLRsub, SVM-3DDWT and CNN, respectively. Classification maps on the Indian dataset are shown for all methods in <ref type="figure" target="#fig_7">Figure 5</ref>, and the accuracies (i.e. individual class accuracy, OA, AA and ?) are reported in <ref type="table" target="#tab_2">Table  VIII</ref>.</p><p>From <ref type="table" target="#tab_2">Table VIII</ref>, we highlight two main results. First, CNN-MRF and CNN, which are both deep learning methods, achieve the first and third best performance in terms of the three criteria (OA, AA and ?); CNN-MRF attains about 2% improvement in term of OA in this scenario, with SVM-3DDWT-GC trailing slightly behind (94.28%). And CNN falls behind SVM-3DDWT-GC only 0.23%. This means that using a CNN for classification without the MRF performs better than a MRF-based model with other classifier except the SVM classifier with 3DDWT features. The CNN therefore significantly helps for this problem. Moreover, as depicted in <ref type="figure" target="#fig_7">Figure 5</ref>, the classification maps of the CNN-based methods are noticeably closer to the ground truth map. Finally, directly comparing the MRF and non-MRF based methods, we can conclude that using an MRF prior significantly improves the classification accuracy of any particular classifier because it further embeds the spatial smoothness information into the segmentation stage. Therefore, the superior performance of our proposed CNN-MRF method can be explained by using the CNN and MRF strategies simultaneously to fully exploit the spectral and spatial information in a HSI.</p><p>2) ROSIS Pavia University Data: We perform similar experiments on a second real HSI dataset. This HSI was acquired by the Reflective Optics System Imaging Spectrometer (ROSIS) over the urban area of the University of Pavia in northern Italy on July 8, 2002. The original dataset consists of 115 spectral bands ranging from 0.43 to 0.86 ?m, of which 12 noisy bands are removed and only 103 bands are retained in our experiments. The scene has a spatial resolution of 1.3 m per pixel, and the spatial dimension is 610?340. There are 9 land cover classes in this scene and the number of each class is displayed in <ref type="table" target="#tab_2">Table IX</ref>. We show a sample band and the corresponding ground truth class map in <ref type="figure" target="#fig_8">Figure 6</ref>.</p><p>To evaluate the performance of our proposed CNN-MRF method using only a small number of labeled training samples, we randomly chose 40 samples for each class from the ground truth data for training, which gives a balanced training sample, and the remaining samples are used for testing. The related   statistics are also summarized in <ref type="table" target="#tab_2">Table IX</ref>. As previously, we repeat this experiment 20 times for each method and report the average performance. All parameters involved in the compared methods are tuned in the same way as the previous Indian Pines experiment. The network structure settings of the CNN are also the same. Classification and segmentation maps obtained by all methods on this dataset are illustrated in <ref type="figure" target="#fig_9">Figure  7</ref> and accuracies (i.e. individual class accuracy, OA, AA and ?) are summarized in <ref type="table" target="#tab_11">Table X</ref>.</p><p>From <ref type="table" target="#tab_11">Table X</ref>, we can conclude that, for this dataset, our CNN-MRF approach again achieves the best performance in terms of the three quantitative criteria. It is also worth noting that the CNN without MRF again performs third best with respect to OA and ?, which means that the CNN plays an important role in improving the classification accuracy. By using the MRF prior, CNN-MRF obtains about 2% improvement in terms of the OA compared with the CNN. However, for other classification algorithms we observe that the MRF can greatly boost classification accuracy. For example, MLRsubMLL has about 30% improvement according to OA compared with MLRsub. SVM-3DDWT-GC has the second best classification OA (94.12%) due to the 3D discrete wavelet transform (3DDWT), as has been previously studied in <ref type="bibr" target="#b11">[12]</ref>. Meanwhile, it can be seen from <ref type="figure" target="#fig_9">Figure 7</ref> that CNN-MRF obtains much smoother classification map than other methods, which is consistent with the results shown in <ref type="table" target="#tab_11">Table X</ref>. Consequently, improvement of our CNN-MRF approach can be explained by the use of CNN and MRF models simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Limited training data scenarios</head><p>To analyze the sensitivity of the proposed method to training sets consisting of limited training samples, we conduct additional experiments in which 0.1%, 0.2%, 0.3%, 0.4% and 0.5% of each class are randomly selected from the Pavia University data as training samples and the remaining are used for testing. For this experiment, we adopt the data augmentation technique <ref type="bibr" target="#b36">[37]</ref> to help the training process of the CNN. The  OA of all methods are displayed in <ref type="figure" target="#fig_10">Figure 8</ref>. From <ref type="figure" target="#fig_10">Figure  8</ref>(a), we observe that the classification results of the CNN method outperform the other methods for each training set size. Additionally, when the spatial prior is considered using the MRF, the classification results in <ref type="figure" target="#fig_10">Figure 8</ref>(b) significantly improve the corresponding classification results in <ref type="figure" target="#fig_10">Figure 8(a)</ref>, again indicating that the MRF is an important factor for improving the classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Study on the interaction between CNN and MRF</head><p>Furthermore, in order to clearly illustrate the interactive influence between CNN and MRF, we also report the OA of our method on the three datasets as a function of iteration. The results are shown in <ref type="table" target="#tab_2">Table XI</ref>. Specifically, in our experiments, we first train our CNN for 30 epochs using the training data D l . Then, we update the class labels y every 10 epochs. From <ref type="table" target="#tab_2">Table XI</ref>, it can be seen that the OA first increases quickly in the first 30 epochs. Then, the OA increases slowly for about 40 epochs. Finally, the OA decreases a little or has a slight fluctuation. Therefore, we conclude that the interaction between the CNN and MRF can help the final classification OA. In our experiments, we set the maximum epoch as 60 and report the output as the results of our method.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Comparison with other deep learning methods</head><p>In order to further evaluate the performance of our proposed CNN-MRF method, we compare with three recent deep learning HSI classification algorithms: SS-DCNN <ref type="bibr" target="#b66">[67]</ref>, SPP-DCNN <ref type="bibr" target="#b65">[66]</ref> and DC-CNN <ref type="bibr" target="#b67">[68]</ref>. We use the two previous real datasets for comparison. For fair comparison, we choose the training samples with same proportion as was done in <ref type="bibr" target="#b67">[68]</ref>. Specifically, for the Indian Pines dataset, we choose 10% samples from each class as training set, and for the Pavia University dataset we choose 5% samples from each class as training data. We also apply the data augmentation strategy in the two experiments since all deep learning algorithms can adopt this strategy. The results for each algorithm are displayed in <ref type="table" target="#tab_2">Table XII and Table XIII</ref>. <ref type="bibr" target="#b3">4</ref> Results for Indian Pines are shown in <ref type="table" target="#tab_2">Table XII</ref>, where it can be seen that our proposed CNN-MRF method achieves improved performance compared with other deep methods in terms of OA, AA and ?. We show results for the Pavia University data in <ref type="table" target="#tab_2">Table XIII</ref>. We again observe that our method achieves the best performance compared with other methods. From <ref type="table" target="#tab_2">Table XII</ref> and XIII, we can conclude that the running time of our proposed method is a potential drawback. Here the running time reported in this experiment includes both training and testing time. (This could be further addressed with high-performance computing resources and techniques.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Comparison with other label regularization methods</head><p>In order to evaluate the performance of MRF, we compare it with other label regularization methods, such as median filter <ref type="bibr" target="#b29">[30]</ref> and majority voting <ref type="bibr" target="#b6">[7]</ref>. The other two methods are implemented just by replacing the MRF optimization with median filter method and majority voting method in our algorithm framework (we call the two methods as CNN-MF and CNN-MV respectively). All the methods are compared on the above synthetic data, Indian Pines data and Pavia University data with the same experimental settings as shown earlier. For median filter and majority voting methods, we set the window size as {3,5,7} and report the best result. The experimental results are shown in Table XIV and <ref type="figure" target="#fig_11">Figure 9</ref>. <ref type="table" target="#tab_2">From Table XIV</ref> and <ref type="figure" target="#fig_11">Figure 9</ref>, we can easily observe that in MRF obtains the best performance comparing with other two simple label regularization methods on all the datasets. Thus we adopt MRF as the label regularization method in our algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>In this paper, we proposed a novel technique for HSI classification that incorporates both spectral and spatial infor-  mation in a unified Bayesian framework. Specifically, we use a convolutional neural network (CNN) in combination with a Markov random field to classify HSI pixel vectors in a way fully takes spatial and spectral information into account. We then efficiently learn the classfication result by iteratively updating the CNN parameters and the class labels of all HSI pixel vectors. Experimental results on one synthetic HSI dataset and two real benchmark HSI datasets show that our method outperforms state-of-the-art methods, including deep and non-deep models. In the future, we will further consider the HSI classification task in unsupervised settings. Besides, we will also try to extend our model to the popular deep generative models, such as variational autoencoder (VAE) <ref type="bibr" target="#b32">[33]</ref> and generative adversarial network (GAN) <ref type="bibr" target="#b25">[26]</ref>. Furthermore, we hope to design more powerful regularization regimes, extending the employed MRF one, for different application scenarios of this problem in our future research. We will also consider dimensionality reduction techniques in our methods to further make the method more efficiently computed, especially on large-scaled datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>l</head><label></label><figDesc>(k) = {(x 1 , y 1 ), . . . , (x l (k) , y l (k) )} and thus the entire training set can be denoted as D l = {D</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1</head><label>1</label><figDesc>CNN-MRF classification algorithm for HSI Input: HSI patches X , training data D l , learning rate ?, smoothness parameter ?, batch size n batch . Output: Labels y. 1: Train the CNN classifier using D l ; 2: Compute y on X and update label y = ?-Expansion( y,?). 3: Train the CNN classifier using {X , y}; 4: Compute y on X and update label y = ?-Expansion( y,?). 5: Repeat step 3 and 4 until the stopping criterion is satisfied.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>The flowchart of the proposed CNN-MRF algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Classification maps obtained by all competing methods on the synthetic dataset (overall accuracies are reported in parentheses).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1 )</head><label>1</label><figDesc>AVIRIS Indian Pines Data: This data set was gathered by the Airborne Visible/Infrared Imaging Spectrometer (AVIRIS) sensor over the Indian Pines test site in North-western Indiana in June 1992. The original dataset contains 220 spectral reflectance bands in the wavelength range 0.4?2.5 ?m, of which 20 bands cover the region of water absorption. Unlike other methods which remove the 20 polluted bands, we keep all 220 bands in our experiments. This HSI has a spectral resolution of 10 nm and a spatial resolution of 20 m by pixel, and the spatial dimension is 145?145. The ground truth contains 16 land cover classes. This dataset poses a challenging problem because of the significant presence of mixed pixels in all available classes and also because of the unbalanced number of available labeled pixels per class. A sample band of this dataset and the related ground truth categorization map are shown inFigure 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Indian Pines image and related ground truth categorization information. (a) The original HSI. (b) The ground truth categorization map (This figure is better seen by zooming on a computer screen.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Classification maps obtained by all methods on the Indian Pines dataset (overall accuracies are reported in parentheses).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 .</head><label>6</label><figDesc>Pavia University image and related ground truth categorization information. (a) The original HSI. (b) The ground truth categorization map. (This figure is better seen by zooming on a computer screen.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 7 .</head><label>7</label><figDesc>Classification maps obtained by all competing methods on the Pavia University dataset (overall accuracies are reported in parentheses).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8 .</head><label>8</label><figDesc>Overall accuracy (%) obtained by all competing methods with different proportions of training samples on Pavia University dataset. (a) Classification results. (b) Regularized classification results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Classification maps obtained by all competing methods on the Pavia University dataset (overall accuracies are reported in parentheses).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Cao, Deyu Meng, and Zongben Xu are with the School of Mathematics and Statistics, Xi'an Jiaotong University, Xi'an 710049, China (caox-iangyong45@gmail.com, dymeng@mail.xjtu.edu.cn, zbxu@mail.xjtu.edu.cn). Feng Zhou is with the National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China (fzhou@mail.xidian.edu.cn). Lin Xu is with the NYU Multimedia and Visual Computing Lab, New York University Abu Dhabi, UAE (xulinshadow@gmail.com). John Paisley is with the Department of Electrical Engineering &amp; Data Science Institute, Columbia University, New York, NY, USA (jpais-ley@columbia.edu). This research was supported in part by National Basic Research Program (973 Program) of China under Grant No. 2013CB329404 the National Natural Science Foundation of China under Grants 91330204, 11131006 and 61373114.</figDesc><table /><note>?Xiangyong Cao performed this work at Columbia University on a grant from the China Scholarship Council.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I OVERALL</head><label>I</label><figDesc>ACCURACY (%) WITH DIFFERENT KERNEL SIZES.</figDesc><table><row><cell>Kernel Size</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell></row><row><cell>OA</cell><cell cols="5">96.07 96.71 97.10 98.26 99.51</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II OVERALL</head><label>II</label><figDesc>ACCURACY (%) WITH DIFFERENT NETWORK WIDTHS.</figDesc><table><row><cell>Network Width</cell><cell>50</cell><cell>100</cell><cell>200</cell><cell>300</cell><cell>500</cell></row><row><cell>OA</cell><cell cols="5">99.27 99.36 99.51 99.32 99.35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III OVERALL</head><label>III</label><figDesc>ACCURACY (%) WITH DIFFERENT NETWORK DEPTHS.</figDesc><table><row><cell>Network Depth</cell><cell>5</cell><cell>7</cell><cell>9</cell><cell>11</cell><cell>13</cell></row><row><cell>OA</cell><cell cols="5">99.35 99.52 99.48 99.45 99.41</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV OVERALL</head><label>IV</label><figDesc>ACCURACY (%) WITH DIFFERENT PATCH SIZES. Smoothness parameter: Finally, we test the impact of different smoothness parameter ? on the obtained classification results.Table Vshows these results, where it can be observed that setting ? = 20 produces the best classification results. Thus we use this value in our experiments.</figDesc><table><row><cell>Patch Size</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>9</cell><cell>13</cell></row><row><cell>OA</cell><cell cols="5">95.12 96.40 98.13 99.43 99.52</cell></row><row><cell>(5)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE V OVERALL</head><label>V</label><figDesc>ACCURACY (%) WITH DIFFERENT SMOOTH PARAMETERS. 98.61 98.70 98.89 99.53 99.31 99.35</figDesc><table><row><cell>Smooth Parameter</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>50</cell></row><row><cell>OA</cell><cell>98.43</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VI OVERALL</head><label>VI</label><figDesc>ACCURACIES (%), AVERAGE ACCURACIES (%), KAPPA STATISTICS AND RUNNING TIME OF ALL COMPETING METHODS ON THE SYNTHETIC DATASET. Class SVM-GC [60] MLRsubMLL [38] SVM-3DDWT-GC [12] SS-DCNN [67] SPP-DCNN [66] DC-CNN [68] CNN-MRF</figDesc><table><row><cell>OA</cell><cell>96.44</cell><cell>97.92</cell><cell>93.89</cell><cell>94.75</cell><cell>95.63</cell><cell>98.78</cell><cell>99.55</cell></row><row><cell>AA</cell><cell>94.55</cell><cell>95.74</cell><cell>91.37</cell><cell>92.46</cell><cell>93.24</cell><cell>96.59</cell><cell>97.83</cell></row><row><cell>?</cell><cell>95.23</cell><cell>96.03</cell><cell>92.84</cell><cell>93.57</cell><cell>94.46</cell><cell>97.21</cell><cell>98.26</cell></row><row><cell></cell><cell>Ground-truth</cell><cell></cell><cell>SVM-GC (96.44%)</cell><cell cols="2">MLRsubMLL(97.92%)</cell><cell cols="2">SVM-3DDWT-GC 93.89%</cell></row><row><cell cols="2">SS-DCNN (94.75%)</cell><cell cols="2">SPP-DCNN (95.63%)</cell><cell cols="2">DC-CNN (98.78%)</cell><cell cols="2">CNN-MRF(99.55%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VII STATISTICS</head><label>VII</label><figDesc>OF THE INDIAN PINES DATA SET, INCLUDING THE NAME, THE NUMBER OF TRAINING, TEST AND TOTAL SAMPLES FOR EACH CLASS.</figDesc><table><row><cell></cell><cell>Class</cell><cell></cell><cell>Samples</cell><cell></cell></row><row><cell>No</cell><cell>Name</cell><cell cols="2">Train Test</cell><cell>Total</cell></row><row><cell>1</cell><cell>Alfalfa</cell><cell>5</cell><cell>41</cell><cell>46</cell></row><row><cell>2</cell><cell>Corn-no till</cell><cell>143</cell><cell cols="2">1285 1428</cell></row><row><cell>3</cell><cell>Corn-min till</cell><cell>83</cell><cell>747</cell><cell>830</cell></row><row><cell>4</cell><cell>Corn</cell><cell>24</cell><cell>213</cell><cell>237</cell></row><row><cell>5</cell><cell>Grass-pasture</cell><cell>49</cell><cell>434</cell><cell>483</cell></row><row><cell>6</cell><cell>Grass-trees</cell><cell>73</cell><cell>657</cell><cell>730</cell></row><row><cell>7</cell><cell>Grass-pasture-mowed</cell><cell>3</cell><cell>25</cell><cell>28</cell></row><row><cell>8</cell><cell>Hay-windrowed</cell><cell>48</cell><cell>430</cell><cell>478</cell></row><row><cell>9</cell><cell>Oat</cell><cell>2</cell><cell>18</cell><cell>20</cell></row><row><cell>10</cell><cell>Soybean-no till</cell><cell>98</cell><cell>847</cell><cell>972</cell></row><row><cell>11</cell><cell>Soybean-min till</cell><cell>246</cell><cell cols="2">2209 2455</cell></row><row><cell>12</cell><cell>Soybean-clean</cell><cell>60</cell><cell>533</cell><cell>593</cell></row><row><cell>13</cell><cell>Wheat</cell><cell>21</cell><cell>184</cell><cell>205</cell></row><row><cell>14</cell><cell>Woods</cell><cell>127</cell><cell cols="2">1138 1265</cell></row><row><cell cols="2">15 Buildings-Grass-Trees-Drives</cell><cell>39</cell><cell>347</cell><cell>386</cell></row><row><cell>16</cell><cell>Stone-Steel-Towers</cell><cell>10</cell><cell>83</cell><cell>93</cell></row><row><cell></cell><cell>Total</cell><cell cols="3">1025 9224 10249</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VIII INDIVIDUAL</head><label>VIII</label><figDesc>CLASS, OVERALL, AVERAGE ACCURACIES (%) AND KAPPA STATISTICS OF ALL METHODS ON THE INDIAN PINES IMAGE TEST SET.</figDesc><table><row><cell>Class</cell><cell cols="8">Classification algorithms SVM MLRsub SVM-3DDWT CNN SVM-GC [60] MLRsubMLL [38] SVM-3DDWT-GC [12] CNN-MRF Regularized Classification algorithms</cell></row><row><cell>1</cell><cell>73.17</cell><cell>46.34</cell><cell>63.41</cell><cell>85.23</cell><cell>95.12</cell><cell>95.12</cell><cell>82.93</cell><cell>86.52</cell></row><row><cell>2</cell><cell>62.65</cell><cell>40.93</cell><cell>89.81</cell><cell>90.17</cell><cell>68.48</cell><cell>50.04</cell><cell>95.56</cell><cell>91.46</cell></row><row><cell>3</cell><cell>52.88</cell><cell>26.24</cell><cell>91.97</cell><cell>93.43</cell><cell>56.49</cell><cell>13.12</cell><cell>95.72</cell><cell>96.35</cell></row><row><cell>4</cell><cell>32.39</cell><cell>17.37</cell><cell>80.75</cell><cell>84.19</cell><cell>77.00</cell><cell>15.02</cell><cell>95.77</cell><cell>96.22</cell></row><row><cell>5</cell><cell>91.24</cell><cell>70.97</cell><cell>96.77</cell><cell>98.76</cell><cell>94.47</cell><cell>73.04</cell><cell>96.54</cell><cell>99.48</cell></row><row><cell>6</cell><cell>92.09</cell><cell>94.37</cell><cell>98.78</cell><cell>99.43</cell><cell>97.72</cell><cell>98.93</cell><cell>99.39</cell><cell>99.82</cell></row><row><cell>7</cell><cell>36.00</cell><cell>18.18</cell><cell>56.00</cell><cell>74.52</cell><cell>34.42</cell><cell>37.25</cell><cell>0</cell><cell>78.00</cell></row><row><cell>8</cell><cell>95.58</cell><cell>96.51</cell><cell>100</cell><cell>98.74</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>98.84</cell></row><row><cell>9</cell><cell>0</cell><cell>22.22</cell><cell>94.44</cell><cell>100</cell><cell>0</cell><cell>0</cell><cell>88.89</cell><cell>100</cell></row><row><cell>10</cell><cell>61.44</cell><cell>25.06</cell><cell>88.44</cell><cell>91.71</cell><cell>75.06</cell><cell>19.68</cell><cell>92.22</cell><cell>94.26</cell></row><row><cell>11</cell><cell>86.92</cell><cell>78.23</cell><cell>95.79</cell><cell>95.59</cell><cell>95.47</cell><cell>88.82</cell><cell>98.05</cell><cell>96.48</cell></row><row><cell>12</cell><cell>76.36</cell><cell>16.51</cell><cell>94.93</cell><cell>89.97</cell><cell>99.44</cell><cell>16.51</cell><cell>98.31</cell><cell>91.85</cell></row><row><cell>13</cell><cell>91.85</cell><cell>93.48</cell><cell>94.57</cell><cell>98.64</cell><cell>98.37</cell><cell>99.46</cell><cell>98.37</cell><cell>98.85</cell></row><row><cell>14</cell><cell>97.01</cell><cell>99.38</cell><cell>97.72</cell><cell>97.88</cell><cell>97.45</cell><cell>99.91</cell><cell>99.03</cell><cell>98.36</cell></row><row><cell>15</cell><cell>48.13</cell><cell>4.32</cell><cell>79.83</cell><cell>89.95</cell><cell>76.66</cell><cell>60.52</cell><cell>89.91</cell><cell>91.54</cell></row><row><cell>16</cell><cell>91.57</cell><cell>77.11</cell><cell>75.90</cell><cell>96.83</cell><cell>98.80</cell><cell>83.13</cell><cell>72.29</cell><cell>97.85</cell></row><row><cell>OA</cell><cell>77.02</cell><cell>63.12</cell><cell>93.19</cell><cell>94.05</cell><cell>85.92</cell><cell>70.45</cell><cell>94.28</cell><cell>96.12</cell></row><row><cell>AA</cell><cell>68.08</cell><cell>50.57</cell><cell>87.44</cell><cell>92.97</cell><cell>76.91</cell><cell>56.82</cell><cell>87.69</cell><cell>94.75</cell></row><row><cell cols="2">Kappa 73.49</cell><cell>53.13</cell><cell>92.22</cell><cell>92.86</cell><cell>83.78</cell><cell>65.43</cell><cell>94.85</cell><cell>95.78</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE IX STATISTICS</head><label>IX</label><figDesc>OF THE PAVIA UNIVERSITY DATA SET, INCLUDING THE NAME, THE NUMBER OF TRAINING, TEST AND TOTAL SAMPLES FOR EACH CLASS.</figDesc><table><row><cell></cell><cell>Class</cell><cell></cell><cell>Samples</cell><cell></cell></row><row><cell>No</cell><cell>Name</cell><cell>Train</cell><cell>Test</cell><cell>Total</cell></row><row><cell>1</cell><cell>Asphalt</cell><cell>40</cell><cell>6591</cell><cell>6631</cell></row><row><cell>2</cell><cell>Meadows</cell><cell>40</cell><cell cols="2">18609 18649</cell></row><row><cell>3</cell><cell>Gravel</cell><cell>40</cell><cell>2059</cell><cell>2099</cell></row><row><cell>4</cell><cell>Trees</cell><cell>40</cell><cell>3024</cell><cell>3064</cell></row><row><cell>5</cell><cell>Painted metal sheets</cell><cell>40</cell><cell>1305</cell><cell>1345</cell></row><row><cell>6</cell><cell>Bare Soil</cell><cell>40</cell><cell>4989</cell><cell>5029</cell></row><row><cell>7</cell><cell>Bitumen</cell><cell>40</cell><cell>1290</cell><cell>1330</cell></row><row><cell>8</cell><cell>Self-Blocking Bricks</cell><cell>40</cell><cell>3642</cell><cell>3682</cell></row><row><cell>9</cell><cell>Shadows</cell><cell>40</cell><cell>907</cell><cell>947</cell></row><row><cell></cell><cell>Total</cell><cell>360</cell><cell cols="2">42416 42776</cell></row><row><cell></cell><cell>(a)</cell><cell></cell><cell>(b)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE X INDIVIDUAL</head><label>X</label><figDesc>CLASS, OVERALL, AVERAGE ACCURACIES (%) AND KAPPA STATISTICS OF ALL COMPETING METHODS ON THE PAVIA UNIVERSITY IMAGE TEST SET.</figDesc><table><row><cell>Class</cell><cell cols="4">Classification algorithms SVM MLRsub SVM-3DDWT CNN</cell><cell cols="4">Regularized classification algorithms SVM-GC [60] MLRsubMLL [38] SVM-3DDWT-GC [12] CNN-MRF</cell></row><row><cell>1</cell><cell>72.17</cell><cell>62.10</cell><cell>84.78</cell><cell>96.82</cell><cell>97.74</cell><cell>87.07</cell><cell>92.03</cell><cell>98.02</cell></row><row><cell>2</cell><cell>64.85</cell><cell>46.57</cell><cell>93.62</cell><cell>96.80</cell><cell>67.92</cell><cell>96.97</cell><cell>97.33</cell><cell>97.78</cell></row><row><cell>3</cell><cell>75.57</cell><cell>58.38</cell><cell>85.04</cell><cell>86.16</cell><cell>90.38</cell><cell>77.27</cell><cell>86.89</cell><cell>88.47</cell></row><row><cell>4</cell><cell>89.62</cell><cell>89.75</cell><cell>95.90</cell><cell>98.54</cell><cell>90.34</cell><cell>83.90</cell><cell>97.09</cell><cell>99.17</cell></row><row><cell>5</cell><cell>97.78</cell><cell>99.54</cell><cell>98.77</cell><cell>99.88</cell><cell>99.85</cell><cell>99.54</cell><cell>98.70</cell><cell>99.90</cell></row><row><cell>6</cell><cell>72.42</cell><cell>73.80</cell><cell>94.29</cell><cell>90.40</cell><cell>94.75</cell><cell>99.40</cell><cell>98.12</cell><cell>93.00</cell></row><row><cell>7</cell><cell>86.82</cell><cell>80.78</cell><cell>96.59</cell><cell>86.92</cell><cell>71.16</cell><cell>94.50</cell><cell>98.84</cell><cell>87.47</cell></row><row><cell>8</cell><cell>67.13</cell><cell>66.56</cell><cell>79.82</cell><cell>90.94</cell><cell>68.51</cell><cell>64.83</cell><cell>84.46</cell><cell>91.66</cell></row><row><cell>9</cell><cell>97.57</cell><cell>99.56</cell><cell>100</cell><cell>97.53</cell><cell>99.67</cell><cell>99.78</cell><cell>100</cell><cell>98.03</cell></row><row><cell>OA</cell><cell>73.41</cell><cell>61.36</cell><cell>91.27</cell><cell>94.82</cell><cell>80.21</cell><cell>91.13</cell><cell>94.12</cell><cell>96.18</cell></row><row><cell>AA</cell><cell>79.36</cell><cell>75.23</cell><cell>92.09</cell><cell>93.77</cell><cell>86.70</cell><cell>89.25</cell><cell>94.83</cell><cell>94.83</cell></row><row><cell cols="2">Kappa 66.23</cell><cell>53.26</cell><cell>88.55</cell><cell>93.89</cell><cell>75.09</cell><cell>88.19</cell><cell>93.55</cell><cell>94.62</cell></row><row><cell></cell><cell></cell><cell></cell><cell>SVM (73.41%)</cell><cell></cell><cell>MLRsub(61.36%)</cell><cell>SVM-3DDWT 91.27%</cell><cell>CNN(94.82%)</cell><cell></cell></row><row><cell></cell><cell>Ground-truth</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">SVM-GC (80.21%)</cell><cell>MLRsubMLL(91.13%)</cell><cell>SVM-3DDWT-GC 94.12%</cell><cell cols="2">CNN-MRF(96.18%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE XI THE</head><label>XI</label><figDesc>CHANGE OF OVERALL ACCURACY (%) AS EPOCH GOES. 96.72 98.85 99.44 99.52 99.58 99.44 99.30 99.12 99.25 Indian Pines 87.29 92.67 94.05 95.36 95.91 96.12 95.93 96.03 95.98 95.97 PaviaU 83.71 92.71 94.82 95.71 95.92 96.18 96.17 96.18 96.16 96.18</figDesc><table><row><cell>Epoch</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell><cell>50</cell><cell>60</cell><cell>70</cell><cell>80</cell><cell>90</cell><cell>100</cell></row><row><cell>Synthetic</cell><cell>92.53</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE XII OVERALL</head><label>XII</label><figDesc>ACCURACY, AVERAGE ACCURACY AND KAPPA COEFFICIENT (%) OF ALL THE DEEP LEARNING METHODS ON THE INDIAN PINES DATASET.</figDesc><table><row><cell></cell><cell cols="4">SS-DCNN [67] SPP-DCNN [66] DC-CNN [68] CNN-MRF</cell></row><row><cell>OA</cell><cell>90.76</cell><cell>91.60</cell><cell>98.76</cell><cell>99.32</cell></row><row><cell>AA</cell><cell>85.52</cell><cell>93.96</cell><cell>98.50</cell><cell>99.27</cell></row><row><cell>kappa(?)</cell><cell>89.44</cell><cell>90.43</cell><cell>98.58</cell><cell>99.21</cell></row><row><cell>Time</cell><cell>255.32</cell><cell>328.18</cell><cell>4860.57</cell><cell>1454.62</cell></row><row><cell></cell><cell></cell><cell>TABLE XIII</cell><cell></cell><cell></cell></row><row><cell cols="5">OVERALL ACCURACY, AVERAGE ACCURACY AND KAPPA COEFFICIENT (%)</cell></row><row><cell cols="5">OF ALL THE DEEP LEARNING METHODS ON THE PAVIA UNIVERSITY</cell></row><row><cell></cell><cell></cell><cell>DATASET.</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">SS-DCNN [67] SPP-DCNN [66] DC-CNN [68] CNN-MRF</cell></row><row><cell>OA</cell><cell>93.34</cell><cell>94.88</cell><cell>99.68</cell><cell>99.71</cell></row><row><cell>AA</cell><cell>92.20</cell><cell>93.29</cell><cell>99.50</cell><cell>99.55</cell></row><row><cell>kappa(?)</cell><cell>91.95</cell><cell>93.21</cell><cell>99.58</cell><cell>99.63</cell></row><row><cell>Time</cell><cell>266.11</cell><cell>333.90</cell><cell>3421.25</cell><cell>1156.43</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE XIV OVERALL</head><label>XIV</label><figDesc>ACCURACY (%) OF ALL THE LABEL REGULARIZATION METHODS ON THE SYNTHETIC, INDIAN PINES AND PAVIA UNIVERSITY</figDesc><table><row><cell></cell><cell></cell><cell>DATASETS.</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">CNN CNN+Median Filter CNN+Majority Voting CNN-MRF</cell></row><row><cell>Synthetic</cell><cell>98.89</cell><cell>93.92</cell><cell>94.10</cell><cell>99.25</cell></row><row><cell cols="2">Indian Pines 94.05</cell><cell>95.19</cell><cell>95.37</cell><cell>95.52</cell></row><row><cell>PaviaU</cell><cell>94.82</cell><cell>95.44</cell><cell>95.55</cell><cell>95.69</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The results for SS-DCNN, SPP-DCNN and DC-CNN are taken from<ref type="bibr" target="#b67">[68]</ref>. The running time ofTable VIII and Table XIIis different since data augmentation strategy is adopted in this experiment ofTable XII.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral images with regularized linear discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Bandos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="862" to="873" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral data from urban areas based on extended morphological profiles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Palmason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Sveinsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="480" to="491" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spatial interaction and the statistical analysis of lattice systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="page" from="192" to="236" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Robust image restoration algorithm using markov random field model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">B</forename><surname>Desai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphical Models and Image Processing</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="61" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Finding optimal neural networks for land use classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="337" to="341" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">MJRTYA Fast Majority Vote Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Moore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>Springer</publisher>
			<pubPlace>Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast approximate energy minimization via graph cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1222" to="1239" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interactive graph cuts for optimal boundary &amp; region segmentation of objects in nd images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-P</forename><surname>Jolly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Kernel-based methods for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1351" to="1362" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Robust support vector method for hyperspectral data classification and knowledge discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>G?mez-Chova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Calpe-Maravilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mart?n-Guerrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Soria-Olivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Alonso-Chord?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moreno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote sensing</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1530" to="1542" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Integration of 3-dimensional discrete wavelet transform and markov random field for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">226</biblScope>
			<biblScope unit="page" from="90" to="100" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.7062</idno>
		<title level="m">Semantic image segmentation with deep convolutional nets and fully connected crfs</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep learning-based classification of hyperspectral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected topics in applied earth observations and remote sensing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2094" to="2107" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification using dictionary-based sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3973" to="3985" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification via kernel sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="217" to="231" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral data based on deep belief network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2381" to="2392" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Artificial neural networks for land-cover classification and mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Civco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Geographical Information Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="186" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Manifold learning for multi-classifier systems via ensembles. Multiple Classifier Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="519" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral images by using extended morphological attribute profiles and independent component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Villa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="542" to="546" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image super-resolution using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="295" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multiscale representation and segmentation of hyperspectral imagery using geometric partial differential equations and algebraic multigrid methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Duarte-Carvajalino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>V?lez-Reyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2418" to="2434" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Advances in spectral-spatial classification of hyperspectral images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Tilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="652" to="675" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Clearing the skies: A deep network architecture for single-image rain removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2944" to="2956" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<ptr target="http://www.deeplearningbook.org" />
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Spatial pyramid pooling in deep convolutional networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="346" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The vanishing gradient problem during learning recurrent neural nets and problem solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="107" to="116" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep convolutional neural networks for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Sensors</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A fast two-dimensional median filtering algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Acoustics Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="18" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">3d convolutional neural networks for human action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="221" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Spectral-spatial hyperspectral image classification using regularized low-rank representation and sparse representation-based graph cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2473" to="2484" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Land-use and land-cover mapping using a gradable classification method. Remote Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukuyama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1544" to="1558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Convergent tree-reweighted message passing for energy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1568" to="1583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">What energy functions can be minimized via graph cuts?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zabin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="147" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Spectral-spatial hyperspectral image segmentation using subspace multinomial logistic regression and markov random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="809" to="823" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Semisupervised hyperspectral image segmentation using multinomial logistic regression with active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4085" to="4098" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Linear versus nonlinear pca for the classification of hyperspectral data based on the extended morphological profiles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Licciardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Marpu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="451" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral image using autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 9th International Conference on Information</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Local manifold learningbased k-nearest-neighbor for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4099" to="4109" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Hyperspectral tree species classification of japanese complex mixed forest with the aid of lidar data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Matsuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yokoya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iwasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2177" to="2187" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral remote sensing images with support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on geoscience and remote sensing</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1778" to="1790" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Efficiency of semi-implicit schemes for anisotropic diffusion in the hypercube</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mendez-Rial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martin-Herrero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2389" to="2398" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep recurrent neural networks for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ghamisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Effective semantic pixel labelling with convolutional networks and conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paisitkriangkrai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sherrah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Janney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V.-D</forename><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="36" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Support vector machines and object-based classification for obtaining land-use/cover cartography from hyperion hyperspectral imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Petropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kalaitzidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Vadrevu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Geosciences</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="99" to="107" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Recent advances in techniques for hyperspectral image processing. Remote sensing of environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Boardman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brazile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gamba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gualtieri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="110" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification based on structured sparse logistic regression and three-dimensional wavelet texture features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2276" to="2291" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Lossy compression of bilevel images based on markov random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Neuhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Pappas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">373</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning internal representations by error propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DTIC Document</title>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Hyperspectral remote sensing of urban areas: an overview of techniques and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Z</forename><surname>Shafri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Taherzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mansor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ashurov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research Journal of Applied Sciences, Engineering and Technology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1557" to="1565" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Three-dimensional gabor wavelets for pixel-based hyperspectral imagery classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5039" to="5046" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Spatial-aware dictionary learning for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Soltani-Farani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Rabiee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Hosseini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="527" to="541" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Structured priors for sparse-representation-based hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1235" to="1239" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deep neural networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2553" to="2561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral imagery based on partitional clustering techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2973" to="2987" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Svm-and mrf-based method for accurate classification of hyperspectral images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="736" to="740" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Graph-cut-based model for spectral-spatial classification of hyperspectral images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Geoscience and Remote Sensing Symposium (IGARSS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3418" to="3421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification with independent component discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Villa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jutten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Geoscience and remote sensing</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4865" to="4876" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Image denoising and inpainting with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="341" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral image based on low-rank decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2370" to="2380" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Constructing free-energy approximations and generalized belief propagation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Yedidia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2282" to="2312" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A deep learning framework for hyperspectral image classification using spatial pyramid pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="875" to="884" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral images using deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="468" to="477" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral imagery using a dual-channel convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="438" to="447" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Unsupervised classification in hyperspectral imagery with nonlocal total variation and primal-dual hybrid gradient algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tiard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dahlberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Bertozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2786" to="2798" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Linear intensity-based image registration by markov random fields and discrete optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zikic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Groher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kamen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="550" to="562" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
