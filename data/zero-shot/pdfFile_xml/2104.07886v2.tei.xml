<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-10">2021. October 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
							<email>penghao@buaa.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
							<email>psyu@uic.edu.</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruitong</forename><surname>Zhang</surname></persName>
							<email>rtzhang@buaa.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renyu</forename><surname>Yang</surname></persName>
							<email>r.yang1@leeds.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyi</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">RUITONG ZHANG</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">YINGTONG DOU</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">RENYU YANG</orgName>
								<orgName type="institution" key="instit2">University of Leeds</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">JINGYI ZHANG</orgName>
								<orgName type="institution" key="instit2">Beihang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">School of Cyber Science and Technology</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<addrLine>No. 37 Xue Yuan Road, Haidian District</addrLine>
									<postCode>100191</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">School of Cyber Science and Technology</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<addrLine>No. 37 Xue Yuan Road, Haidian District</addrLine>
									<postCode>100191</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">University of Leeds</orgName>
								<address>
									<postCode>LS2 9JT</postCode>
									<settlement>Leeds</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="department">School of Cyber Science and Technology</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<addrLine>No. 37 Xue Yuan Road, Haidian District</addrLine>
									<postCode>100191</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff11">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks</title>
					</analytic>
					<monogr>
						<title level="j" type="main">ACM Transactions on Information Systems</title>
						<meeting> <address><addrLine>1, Article</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="volume">1</biblScope>
							<biblScope unit="issue">1</biblScope>
							<biblScope unit="page">45</biblScope>
							<date type="published" when="2021-10">2021. October 2021</date>
						</imprint>
					</monogr>
					<note type="submission">Publication date: October 2021.</note>
					<note>A preliminary version [15] of this article appeared in the Proceedings of the 29th ACM International Conference on Information and Knowledge Management, Pages 315-324 (CIKM&apos;20). Authors&apos; addresses: H. Peng, ACM acknowledges that this contribution was authored or co-authored by an employee, contractor, or affiliate of the United States government. As such, the United States government retains a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so, for government purposes only. 1046-8188/2021/10-ART39 $15.00 https://doi.org/0000001.0000001 39:2 ? H. Peng et al.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS Concepts: ? Computing methodologies ? Artificial intelligence</term>
					<term>Machine learning approaches</term>
					<term>? Information systems ? Data mining</term>
					<term>Web applications Additional Key Words and Phrases: Graph neural network, multi-relational graph, reinforcement learning, node embedding, recursive optimization * This is the corresponding author</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph Neural Networks (GNNs) have been widely used for the representation learning of various structured graph data, typically through message passing among nodes by aggregating their neighborhood information via different operations. While promising, most existing GNNs oversimplified the complexity and diversity of the edges in the graph, and thus inefficient to cope with ubiquitous heterogeneous graphs, which are typically in the form of multi-relational graph representations. In this paper, we propose RioGNN, a novel Reinforced, recursive and flexible neighborhood selection guided multi-relational Graph Neural Network architecture, to navigate complexity of neural network structures whilst maintaining relation-dependent representations. We first construct a multi-relational graph, according to the practical task, to reflect the heterogeneity of nodes, edges, attributes and labels. To avoid the embedding over-assimilation among different types of nodes, we employ a label-aware neural similarity measure to ascertain the most similar neighbors based on node attributes. A reinforced relationaware neighbor selection mechanism is developed to choose the most similar neighbors of a targeting node within a relation before aggregating all neighborhood information from different relations to obtain the eventual node embedding. Particularly, to improve the efficiency of neighbor selecting, we propose a new recursive and scalable reinforcement learning framework with estimable depth and width for different scales of multi-relational graphs. RioGNN can learn more discriminative node embedding with enhanced explainability due to the recognition of individual importance of each relation via the filtering threshold mechanism. Comprehensive experiments on real-world graph data and practical tasks demonstrate the advancements of effectiveness, efficiency and the model explainability, as opposed to other comparative GNN models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The advancement of Graph Neural Networks (GNNs) enables the effective representation learning for a variety of areas <ref type="bibr" target="#b103">[104]</ref> including bioinformatics, chemoinformatics, social networks, natural language processing <ref type="bibr" target="#b75">[76,</ref><ref type="bibr" target="#b77">78]</ref>, social events <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b76">77]</ref>, recommender system <ref type="bibr" target="#b82">[83]</ref>, spatial-temporal traffic <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b79">80]</ref>, computer vision and physics <ref type="bibr" target="#b2">[3]</ref> where graphs are primarily the denotation. GNN models are proved to reach the performance target over massive datasets -citation networks <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b90">91]</ref>, biochemical networks <ref type="bibr" target="#b73">[74,</ref><ref type="bibr" target="#b123">123]</ref>, social networks <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b18">19]</ref>, knowledge graph <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b109">109]</ref>, commodity networks <ref type="bibr" target="#b78">[79]</ref>, API call networks <ref type="bibr" target="#b36">[37]</ref>, etc. -on different tasks, such as node classification <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b95">96]</ref>, node clustering <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b71">72]</ref>, link prediction <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b114">114]</ref>, graph classification <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b91">92,</ref><ref type="bibr" target="#b111">111]</ref>, etc. At the core of GNNs is to operate various aggregate functions <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b95">96,</ref><ref type="bibr" target="#b107">107]</ref> on the graph structure by passing node features to the neighbors; each node aggregates the feature vectors of its neighbors for computing and updating its new feature vector. Empirically, iterations of aggregation or message passing come into a node embedding vector -a numerical capture of both structural information within the node's multi-hop neighborhood and the attribute information -empowered by the label propagation mechanisms <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b122">122]</ref>.</p><p>Heterogeneous graphs are ubiquitous in real-world systems; a graph typically consists of nodes with multiple types and multi-relational edges between nodes. For example, in Yelp spam review data <ref type="bibr" target="#b83">[84]</ref>, there are heterogeneous nodes (e.g., businesses, reviews, users, etc.) and relations (e.g., posted by the same user, under the same product with the same star rating, and under the same product posted in the same month between two reviews). However, existing iterative aggregation mechanisms of GNNs have yet to elaborately consider the diversity of semantic relations and the usability of the proposed models. Homogeneous GNNs such as GraphSAGE <ref type="bibr" target="#b31">[32]</ref>, GCN <ref type="bibr" target="#b48">[49]</ref>, GAT <ref type="bibr" target="#b95">[96]</ref>, GIN <ref type="bibr" target="#b107">[107]</ref> ignore or simplify the diversity and complexity of the nodes and edges in practical networks, which is inadequate to represent the heterogeneity of data. To solve the above problem, relational GNNs <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b121">121]</ref> are proposed but fail to capture multiple hop or complex relations. Sampling-based heterogeneous GNNs guided by hand-crafted meta-paths <ref type="bibr" target="#b100">[101]</ref>, meta-graphs <ref type="bibr" target="#b108">[108]</ref> and meta-schema <ref type="bibr" target="#b35">[36]</ref> are solely based on data types and their structured connections. This drawback substantially impedes the generalization of such heterogeneous GNNs in practical fine-grained tasks -e.g., fraud detection <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14]</ref>, disease diagnosis <ref type="bibr" target="#b19">[20]</ref>, etc.where it is infeasible or inefficient to externalize the inherent entity relations through meta-structures such as meta-path, meta-graph and meta-schema. Take the detection and diagnosis of diabetes and its suspected diseases, based on the MIMIC-III dataset <ref type="bibr" target="#b43">[44]</ref>, as an example. Observably, a portion of patients with diabetes tends to have symptoms that cause glaucoma, while glaucoma patients do not often experience issues in blood sugar, insulin and other test indicators. Accordingly, one can easily define explicit relations such as having hyperglycemia score in the blood test, having high proteinuria scores in urine test, having symptoms of glaucoma in vision test, having high intraocular in pressure test, etc., between any two patients. It is far more useful to specify relations based on common attributes shared by entities, and less dependent upon strict entity connections as opposed to the meta-structure based approaches which have to leverage complicated automated generation technology <ref type="bibr" target="#b67">[68]</ref> or manual experience <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b61">62]</ref>. Hence, it is more effective to explore and exploit the explicit relations, stemming from task-specific characteristics, for carrying out downstream applications.</p><p>In an attempt to extend GNNs for supporting heterogeneous graph embedding, many approaches rely on a combination of sophisticated neural networks <ref type="bibr" target="#b99">[100]</ref>. For instance, HetGNN <ref type="bibr" target="#b113">[113]</ref> aggregates multi-modal features from heterogeneous neighbors by combining bi-LSTM, self-attention, and types combination. RSHN <ref type="bibr" target="#b121">[121]</ref> utilizes coarsened line graph neural network (CL-GNN) along with the message passing neural network (MPNN) to learn node and edge type embedding simultaneously. HGT <ref type="bibr" target="#b40">[41]</ref> leverages type dependent parameters based mutual attention, message passing, residual connection, target-specific aggregation function, etc. MAGNN <ref type="bibr" target="#b21">[22]</ref> makes use of meta-path sampling, intra-meta-path and inter-meta-path aggregation technologies to embed a node with the targeted type. Nevertheless, they lack the analysis of more practical or fine-grained application tasks and require strong domain knowledge to build the complex neural network structures. The usability of the proposed GNN model should also be designed in a more convenient way.</p><p>To this end, we propose RioGNN, a novel Reinforced, recursIve and scalable neighbOrhood selection guided multi-relational Graph Neural Network, to navigate complexity of customized neural network structures whilst maintaining relation-dependent representations. For domain task driven graph representation learning, we introduce multi-relational graph to reflect the heterogeneity of nodes, edges, attributes and labels. Herein, a relation is referred to as a specific type of edge between two nodes, connected with each other through explicit common attributes or implicit semantics, e.g., two products released in the same month, two movies directed by the same director, etc. Departing from heterogeneous information network (HIN) <ref type="bibr" target="#b86">[87]</ref>, the multi-relational graph is able to flexibly characterize and explicitly differentiate the edge types without the need for specifying semantic connectivity between any two nodes strictly following entity-associated meta-structures. For a given relation, we can conduct the sampling procedure upon the original graph for extracting neighbors for each node in the graph.</p><p>To diminish the complexity of neural network units, RioGNN optimizes the process of neighbor selection when aggregating neighbor information for a center node embedding. To avoid the embedding over-assimilation among different types of nodes, we first employ a label-aware neural similarity measure to ascertain the most similar neighbors based on node attributes. Particularly, this is achieved by a neural classifier that transforms the supervised signals (e.g., high-fidelity annotated labels) and original node features to calculate the node similarity. To follow up, we carry out a relation-aware neighbor selection to choose the most similar neighbors of a targeting node within a reinforced relation before aggregating all neighborhood information from different relations to obtain the eventual node embedding. To improve the neural classifier training efficiency, we optimize the filtering threshold within each relation through RSRL, a novel Recursive and Scalable Reinforcement Learning framework with estimatable depth and width for different scales of a heterogeneous graph in a recursive manner. Specifically, we exploit two general relation-aware RSRL methods -using both discrete and continuous strategies -for pinpointing the optimal number of neighbors of different relations. The discrete and continuous approaches can generally provide more choices in the face of different datasets and application scenarios. RSRL not only facilitates to learn discriminative node embeddings, but also makes the model more explainable as we can recognize the individual importance of each relation via the filtering thresholds. RSRL-based relation-aware neighbor selector can be integrated with any mainstream reinforcement learning models <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b102">103]</ref> and neighbor aggregation functions <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b95">96]</ref> used for specific scenarios.</p><p>We integrate the aforementioned techniques with the vanilla GNN as a layer of RioGNN and devise multilayered RioGNN to learn high-order node representations according to the specific requirements of downstream tasks. This paper mainly targets those tasks with node-level embedding and learns the multi-relation node representation in a semi-supervised manner. We evaluate the effectiveness, efficiency and explainability of RioGNN by applying it to two tasks of fraud detection and diabetes detection, using Yelp, Amazon and MIMIC-III datasets. Experiments assess how RioGNN underpins downstream tasks including transductive node-classification, inductive node-classification and node clustering. Results show that RioGNN significantly improves various downstream tasks over state-of-the-art GNNs as well as dedicated heterogeneous models by 0.70%-32.78%. We show that our RSRL framework not only boosts the learning time by up to 4.52x, but also achieves 4.90% improvement in node classification. We also evaluate the sensitivity of RioGNN to hyper-parameters in the above tasks. Finally, we carry out a series of case studies to showcase how RSRL automatically learns the importance and engagement of implicit relations in different tasks. The source code and datasets are publicly available at https://github.com/safe-graph/RioGNN. The contributions of this work are summarized as follows:</p><p>? The first task-driven GNN framework based on multi-relational graphs, making the best use of relational sampling, message passing, metric learning and reinforcement learning to guide neighbor selection within and across different relations. ? A flexible neighborhood selection framework that employs a reinforced relation-aware neighbor selector with label-aware neural similarity neighbor measures. ? A recursive and scalable reinforcement learning framework that learns the optimized filtering thresholds via estimable depth and width for different scales of graphs or tasks. ? The first study on the explainability of multi-relational GNNs from the perspective of importances of different relations.</p><p>We expand upon our preliminary work <ref type="bibr" target="#b14">[15]</ref>, by extending CAmouflage-REsistant GNN (CARE-GNN) model exclusively for fraud detectors against camouflaged fraudsters to a more general architecture underpinning a wide range of practical tasks. Specifically, the improvements encompass: 1) giving a full version of definition, motivation and aim of multiple relation graph neural networks under different practical tasks; expanding the labelaware similarity neighbor measure from one layer to multiple layers to select the similar neighbors; 2) proposing a novel recursive and scalable reinforcement learning framework to optimize the filtering threshold for each relation along with the GNN training process in a general and efficient manner, instead of the previous Bernoulli Multi-armed Bandit method; 3) leveraging both discrete and continuous strategies to find the optimal neighbors of different relations to be selected under the reinforcement learning framework; 4) carrying out extensive experiments on three representative and general-purpose datasets, not limited to the fraud detection scenario. Furthermore, more in-depth experimental results are discussed to demonstrate the effectiveness and efficiency of the proposed architecture. We supply the variances of the results of multi-relational graph representation learning. We also showcase the explanation of importances of different relations from a new perspective based on the filtering threshold of the proposed RSRL framework.</p><p>The paper is structured as follows: Section 2 outlines the preliminaries and the problem formulation, and Section 3 describes the technical details involved in RioGNN. Experimental setup and results are discussed in Section 4 and Section 5, respectively. Section 6 presents the related work before we conclude the paper in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND OVERVIEW 2.1 Problem Definition</head><p>In this section, we firstly define the multi-relational graph and multi-relational GNN. All important notations in this paper are summarized in <ref type="table" target="#tab_0">Table 1</ref>.</p><formula xml:id="formula_0">Definition 2.1. Multi-Relational Graph (MR-Graph). MR-Graph is defined as G = V, X, {E }| =1 , ,</formula><p>where V is the set of nodes { 1 , . . . , }, and n is the number of nodes in the graph. Each node has adimensional feature vector x ? R and X = {x 1 , . . . , x } represents a set of all node features. , = ( , ) ? E is an edge between and with a relation ? {1, ? ? ? , }, where R is the number of relations. Note that an edge can be associated with multiple relations, and there are different types of relations. is the set of labels for each node in V.</p><p>The multi-relational graph directly uses the elements to be classified as nodes, and the key relations of elements with different labels are used as multiple connections, which can be widely used in challenging classification tasks. It is worth noting that, departing from HIN, the multi-relational graph is able to flexibly characterize and explicitly differentiate the edge types without the need for specifying semantic connectivity between any two nodes strictly following entity-associated meta-structures. We exemplify its applicability by two real-world applications and compare the difference between the MR-Graph based modeling and the HIN-based approach:</p><p>Spam Review Detection. Spam reviews are referred to as those fabricated reviews posted to products or merchants with the intent of promoting their targets. Fraud detection has to identify spam reviews from organic ones. As spam comments add some special characters or simulate benign email behaviors (such as one user who posts spam emails while maintaining a certain frequency of organic comments) to avoid being found out, this brings challenges to distinguishing spam comments. We consider the comments with different labels as nodes, and different representative interactions as different types of connections to build a multi-relational graph, thereby transforming this problem into a two-classification problem. As shown in <ref type="figure">Figure 1(a)</ref>, an MR-Graph example depicts the organic reviews, spam reviews and their interactions extracted from the e-commerce review data <ref type="bibr" target="#b69">[70,</ref><ref type="bibr" target="#b83">84]</ref>. We extracted representative interactions between two reviews that are closely associated with the fraudulent behavior, and represented them as different types of edges -Belonging to the same user, Having the same star rating, Targeting the same product posted in the same month, Belonging to the same word count  level, Containing special characters and Targeting products located in the same city. As an alternative, traditional HIN-based modeling <ref type="figure">(Figure 1(b)</ref>) pays more attention to the relations outlined by structured connections. Disease Diagnosis. In the task of disease diagnosis, diabetes, stroke, and glaucoma are common diseases in middle-aged and elderly people, and their early symptom recognition is very important. However, because these three diseases have similar symptoms, it is difficult to distinguish patients in clinical practice. For example, the symptoms of stroke include loss of vision, sudden weakness and tingling sensations, which are similar to symptoms in patients with type II diabetes. In addition, one of the early symptoms of diabetes is blurred vision caused by changing fluid levels. Therefore, the eyes may change shape, disturbing the focusing ability of the eyes. Although this visual impairment may indicate diabetes, it is also true in glaucoma patients. Here, taking the patient as the node of the multi-relational graph and connecting the patients with different similar symptoms into different types of edges can convert the task into a multi-classification task. <ref type="figure" target="#fig_0">Figure 2</ref>(a) illustrates an MR-graph of patients for disease diagnosis. We believe to model and represent the relationship between the following types of patients: with "headache" symptoms, with "blurred vision" symptoms, with "hyperglycemia" test results, with "hypertension" test results, with a history of "metazolamide", etc. are more helpful for the diagnosis of diabetes and its suspected diseases of patients. Even, there may be multiple relationships between two patients. For example, Patient 5 and Patient 8 have two relationships of with "blurred vision" symptoms and with "hypertension" test results in common. Meanwhile, previous HIN-based Electronic Health Records (EHR) modelings <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b61">62]</ref> focused on the correlation and fusion of different attributes or types of data, and the corresponding methods are suitable for the diagnosis of all kinds of diseases. Moreover, there is a lack of fine-grained analysis of certain definite diseases. We also give an illustration of the heterogeneous Electronic Health Records graph in <ref type="figure" target="#fig_0">Figure 2</ref>(b). Definition 2.2. Multi-Relational GNN. Graph neural network (GNN) is a deep learning framework to embed graph-structured data via aggregating the information from its neighboring nodes <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b95">96]</ref>. Based on Definition 2.1, we can then outline a unified formulation of the Multi-Relational GNN from the perspective of multi-layer neighbor aggregation according to different relations. For a central node , the hidden or aggregated embedding of node at? layer is referred to as h ( ) :</p><formula xml:id="formula_1">h ( ) = (h ( ?1) ? ( ) ({h ( ?1) ? , : ( , ? ) ? E ( ) }| =1 )),<label>(1)</label></formula><p>where E ( ) denotes the edges under the relation at the -th layer, and h ( ?1)</p><formula xml:id="formula_2">? ,</formula><p>indicates to the aggregated embedding of neighboring node ? under relation .</p><p>denotes the aggregation function that maps the neighborhood information from different relations into a vector, e.g., mean aggregation <ref type="bibr" target="#b31">[32]</ref> and attention aggregation <ref type="bibr" target="#b95">[96]</ref>. ? is the operator that combines the information of node and its neighboring information through either concatenation or summation <ref type="bibr" target="#b31">[32]</ref>. We initialize the node embedding h (0) with the input d-dimensional feature vector . The GNN is trained with partially labeled nodes with binary classification loss functions. Instead of directly aggregating the neighbors for all relations, we separate the aggregation part as intra-relation aggregation and inter-relation aggregation process. During the intra-relation aggregation process, the embedding of neighbors under each relation is aggregated simultaneously. Then, the embeddings for each relation are combined during the inter-relation aggregation process. Finally, the node embeddings at the last layer are used for predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Problem Scope and Challenges</head><p>In practical applications, we model multi-relation graphs, and take actual problems as node classification tasks in a semi-supervised learning manner. After constructing a multi-relational graph according to domain knowledge, e.g., Spam Review Detection in <ref type="figure">Figure 1</ref>(a), Disease Diagnosis in <ref type="figure" target="#fig_0">Figure 2</ref>(a), etc., a multi-relational GNN can be trained. However, when we train more discriminative, effective and explainable node embedding, there are three main challenges facing the Multi-Relational GNNs:</p><p>How to cope with misbehaved nodes during neighbor aggregation in GNNs (Challenge 1). The input node features X, often extracted based on heuristic methods such as TF-IDF, Bag-of-Words, Doc2Vec, etc., are susceptible to such misbehavior as adversarial attacks, camouflages <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b88">89]</ref>, or simply imprecise feature selection. Consequently, the numerical embedding of a central node tends to be assimilated by misbehaved neighboring nodes. For instance, in the spam review detection task, adversarial or camouflaged behaviors are non-negligible noises that drastically reduce the accuracy of feature representation learning by GNNs. Either feature <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b52">53]</ref> or relational <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b119">119]</ref> camouflages could similarize the features of misbehaved and benign entities, and further mislead GNNs to generate uninformative node embeddings. In the medical disease diagnosis task, textual attribute based feature selection may not be able to extract high-level or fine-grained semantics, and thus easily lead to imprecise node characteristics. Hence, these issues necessitate an effective similarity measure to filter the neighbors before applying into any GNNs.</p><p>How to adaptively select the most suitable neighbor nodes based on the similarity measure (Challenge 2). Data annotation is expensive for most practical problems, and we cannot select all similar neighbors under each relationship through data labeling. The method of directly regarding the filtering threshold as a hyperparameter <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b112">112]</ref> is no longer valid for multiple relationship graphs with numerous noisy or misbehaved nodes. First, different relationships have different feature similarity and label similarity. Secondly, different relationships have different precision requirements for the filtering threshold. Therefore, an adaptive sampling mechanism must be designed so that the optimal number of similar neighbors can be selected for specific relationship requirements in a dynamic environment.</p><p>How to efficiently learn and optimize the filtering threshold in a continuous manner (Challenge 3). Our preliminary work <ref type="bibr" target="#b14">[15]</ref> adopts the Bernoulli multi-armed bandit framework <ref type="bibr" target="#b93">[94]</ref> with a fixed strategy to strengthen the learning of the filtering threshold. However, it is substantially limited by the observation range of the state and manually-specified strategies, and hence the final convergence result of the filtering threshold tends to be locally optimal. In addition, for maintaining the prediction accuracy, in the face of large-scale datasets, it is imperative to reduce the adjustment step size of the filtering threshold or use continuous action space. This procedure will undoubtedly expand the action space, leading to an increased number of convergence periods and a huge growth of calculation, possibly with a loss of accuracy. This issue therefore necessitates an automatic and efficient reinforcement learning framework that can quickly obtain sufficient and high-quality solutions. <ref type="figure" target="#fig_1">Figure 3</ref> depicts the RioGNN's overall architecture consisting of three key modules -label-aware similarity measurement (Section 3.1), similarity-aware neighbor selector (Section 3.2), and relation-aware neighbor aggregator (Section 3.3). In addition, we describe the overall algorithm and optimization in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Label-aware Neural Similarity Measure</head><p>Compared with unsupervised similarity metrics like Cosine Similarity <ref type="bibr" target="#b110">[110]</ref> or Neural Networks <ref type="bibr" target="#b110">[110]</ref>, many practical problems like financial fraud, disease diagnosis, etc., require extra domain knowledge (e.g., high-fidelity data annotations) to identify anomaly instances. To this end, we design a parameterized node similarity measure, i.e., label-aware neural similarity measure, using supervision signals from domain experts. AGCN <ref type="bibr" target="#b53">[54]</ref> employs a Mahalanobis distance plus a Gaussian kernel, while DIAL-GNN <ref type="bibr" target="#b9">[10]</ref> adopts the parameterized cosine similarity. NSN <ref type="bibr" target="#b55">[56]</ref> unitizes bilinear similarity based inner product and hyperspherical learning strategies. However, all of them have non-negligible time complexity ( ), where?denotes the average degree of nodes, often very high in real-world graphs, and represents the feature dimension. This leads to a loss of efficiency when discriminating the node representation learning.</p><p>Inspired by GraphMix <ref type="bibr" target="#b96">[97]</ref>, with a combination of Fully-Connected Network (FCN) and linear regularization, we adopt an FCN as the node label predictor at each layer of RioGNN, and use the 1 -distance between the prediction results of two nodes as the measure of the in-between similarity. It is a simple and efficient regularizer for semi-supervised node classification using GNNs. At the -th layer, when calculating the distance between one intermediate node and one of its neighbors ? under relation , i.e., the edge ( , ? ) ? E , we take their embedding in the previous layer h (l?1) as input, and apply the non-linear activation function (we use ? in our work). The distance between and ? is the 1 -distance of two embeddings:</p><formula xml:id="formula_3">D ( ) ( , ? ) = || ( ( ) h ( ?1) ) ? ( ( ) h ( ?1) ? )|| 1 .<label>(2)</label></formula><p>Inter-relation AGG Thus, the similarity of the two nodes can be defined as:</p><formula xml:id="formula_4">( ) ( , ? ) = 1 ? D ( ) ( , ? ).<label>(3)</label></formula><p>The time complexity of our approach can be reduced from ( ) to ( ). In general, the computational cost is low because for each node in the node set V, we do not use the combined embedding of its neighbors with -dimensional features to measure similarity like LAGCN <ref type="bibr" target="#b6">[7]</ref>, but only consider the label predicted by FCN based on its own feature.</p><p>To train similarity measure with a direct supervision signal from the labels, we define the cross entropy loss of the FCN in the -layer as:</p><formula xml:id="formula_5">L ( ) = ?? ?V ? ( ? ( ( ) (h ( ) ))).<label>(4)</label></formula><p>Further, we define the cross entropy loss of label-aware similarity measure for the entire network as:</p><formula xml:id="formula_6">L = ?? =1 L ( ) .<label>(5)</label></formula><p>During the training process, the similarity measure parameters of FCNs are directly updated through the loss function. It ensures that similar neighbors can be quickly selected within a few batches and facilitates to regularize the GNN training process.</p><p>In this subsection, we propose a label-aware similarity detection method for the first challenge in Sec. 2.2. This method is based on node labels to effectively avoid interference caused by bad node camouflage in actual scenes, and reduces the complexity of similarity, which provides a stable basis for subsequent neighbor filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Similarity-aware Adaptive Neighbor Selector</head><p>To select appropriate neighbors adaptively, we design a similarity-aware neighbor selector to filter misbehaved nodes stemming from adversarial behaviors or inaccurate feature extraction. More specifically, for each central node, the selector utilizes Top-p Sampling along with adaptive filtering thresholds to construct similar neighbors under each relation. Since the filter thresholds for different relations at different layers tend to be dynamically updated during the training phase, we propose RSRL, a recursive and scalable reinforcement learning framework to optimize the filtering threshold for each relation in an efficient manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Top-p</head><p>Sampling. Before aggregating the information from both central node and its neighborhood, we perform a Top-p sampling to filter the dissimilar neighbors according to different relations. A filtering threshold ? [0, 1] for relation at the -th layer indicates the selection ratio from all neighbors. For instance, all neighbor nodes under the relation are retained if is 1. More specifically, during the training phase, for a node in one batch under the relation , we first calculate a set of similarity scores { ( , ? )} by using Eq. 3 at -th layer where the edge ( , ? ) ? E . We then rank the neighbors of each central node in descending order, based on { ( , ? )}, and take the top ? |{ ( , ? )}| neighbors as the selected ones, i.e., N ( ), at the -th layer. The residual nodes will be discarded at the current batch and not attend the following aggregation process within the layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RL Tree 1 RL Tree 2</head><p>Unselected ! Unselected "</p><p>The best # at the current depth </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">RSRL Framework.</head><p>Previous work <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b112">112]</ref> regards the filtering threshold as a hyper-parameter, which is no longer valid for multi-relational graph with numerous noisy or misbehaved nodes. To solve this, our preliminary work <ref type="bibr" target="#b14">[15]</ref> adopted the Bernoulli multi-armed bandit framework <ref type="bibr" target="#b93">[94]</ref> with a fixed learning strategy and dynamically updated the filtering threshold. However, the effectiveness of this approach is largely impeded by the limited observation range of states and the manually-specified strategy. As a result, the final convergence outcome of the filtering threshold tends to be local optimal. In the face of larger-scale datasets, the maintenance of the prediction accuracy also needs to reduce the adjustment step size of the filtering threshold. This process will increase the number of convergence epochs, and bring in an increase in the amount of calculation and a loss of accuracy.</p><p>Overview. To address these problems, we propose a novel Recursive and Scalable Reinforcement Learning framework RSRL, upon traditional Reinforcement Learning based approaches <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b62">63]</ref>, to not only update strategies through the learning environment but also the recursive structure can be used to quickly and accurately meet the accuracy requirements of different relations. <ref type="figure" target="#fig_2">Figure. 4</ref> depicts the forest-based learning architecture. The specific process of a tree in each epoch is shown on the right, where and respectively represent the state and reward after the previous epoch, and (the example in the figure is 0.5) represents the predicted action in the current epoch. We formulate RSRL as an -layer Reinforcement Learning (RL) Forest, and define the -th layer forest as:</p><formula xml:id="formula_7">( ) = { ( ) }| =1 = {{ ( ) ( ) }| ( ) =1 }| =1 ,<label>(6)</label></formula><p>( ) actually indicates the process of obtaining the best relational filtering threshold combination at the -th layer. Each relation independently constructs a RL Tree ( ) with an adaptive depth ( ) = ?log ? and a width ( ) ( ) = 1 . is the weight parameter of depth first and breadth first, and is the maximum number of neighbors contained in the node in relation .</p><p>( ) performs a Reinforcement Learning ( ) ( ) for filtering the threshold with an accuracy ( ) ( ) at each depth. At the -th layer, ( ) acquires the best filtering threshold ( ) ( ) of neighbor nodes with higher accuracy than the previous depth of relation through multiple RL recursively, until the threshold for maximum accuracy requirements is found at the depth ( ) . The ( ) recursive process is expressed as:</p><formula xml:id="formula_8">( ) ( ) ( ) ( ) ? ????? ? { ( ) ( ?1) ? ( ) ( ) 2 , ( ) ( ?1) + ( ) ( ) 2 }.<label>(7)</label></formula><p>where ( ) ( ) represents the optimal proportion of neighbor nodes in the relation to be discarded when the depth of the RL tree is in the -th layer. The learning range of the RL module of each depth is the value within ? ( ) 2 of the filter threshold ( ) ( ?1) selected by the previous depth. When the recursive process reaches the maximum depth ( ) , we obtain the final filtering threshold ( ) of the relation in the -th layer. Considering that the complexity has a linear relationship with the size of the action space <ref type="bibr" target="#b16">[17]</ref>, this process carries out a precision recursion on RL actions and can reduce the time from ( ) to ( log ), where ? (1, ) and is the maximum node degree under relation .</p><p>Details of RL Process. We express an RL module as a Markov Decision Process &lt; , , , &gt; for the filtering threshold of a relation. and are the action space and state space, respectively; is the reward function, and is the iteration functions and termination conditions. To better deal with datasets with different sizes and diverse scenarios, we break down our solution into two distinct categories: Discrete Reinforcement Learning (D-RL) and Continuous Reinforcement Learning (C-RL).</p><p>? Action: We define the action space of ( ) ( ) by collecting all actions</p><formula xml:id="formula_9">( ) ( ) ? { ( ) ( ?1) ? ( ) ( ) 2 , ( ) ( ?1) + ( ) ( ) 2</formula><p>} when the relation is at the depth of the -th layer. The discrete scheme D-RL divides the action space into discrete actions on average. In the continuous scheme C-RL, the action space in -th depth is a continuous floating point number with the width of ( ) ( ) . The compatibility of the two types of action space can effectively adapt to a variety of reinforcement learning algorithms. Due to the low precision requirements of the filtering threshold for small and medium-scale datasets, discretization of actions can reduce the number of action explorations <ref type="bibr" target="#b46">[47]</ref> while meeting the basic accuracy requirements, which ensures efficient access to high-performance areas. For the dataset with large-scale neighbors, a large number of discrete actions that meet the high-precision requirements will affect the learning effect <ref type="bibr" target="#b16">[17]</ref>. We propose to generalize the filtering threshold to the continuous action space to improve the accuracy of large-scale data sets by reducing the spatial range multiple times.</p><p>? State: Since it is impossible to directly perceive the classification loss of GNN as the environment state, we calculate the average node distance of each epoch as the state through the distance measure of label perception (Eq. <ref type="formula" target="#formula_3">(2)</ref>). In the -th layer of the -th epoch, the state of relation in the -th depth is:</p><formula xml:id="formula_10">( ) ( ) ( ) = ( , ? ) ?E ( ) ( ) ( ) D ( ) ( , ? ) ( ) |E ( ) ( ) ( ) | ,<label>(8)</label></formula><p>where E ( ) ( ) ( ) is the set of edges filtered in the -th layer and -th depth of the -th epoch under relation . ? Reward: For each relation, the goal is to ascertain a filtering threshold ( ) ( ) so that the selected neighbor node and the central node are as close as possible. We therefore use the similarity (Eq. <ref type="formula" target="#formula_4">(3)</ref>) as the decisive factor within the reward function. In the -th layer of the -th epoch, the reward of relation to -th depth is:</p><formula xml:id="formula_11">( ) ( ) ( ) = ? ( ( , ? ) ?E ( ) ( ) ( ) S ( ) ( , ? ) ( ) |E ( ) ( ) ( ) | ),<label>(9)</label></formula><p>where is the weight parameter, and the meaning of E ( ) ( ) ( ) is the same as the definition in the state. ? Iteration and Termination: Before starting each epoch, RL observes the state ( ) ( ) ( ) of the environment after the previous epoch of action ( ) ( ) ( ?1) and obtains a reward ( ) ( ) ( ?1) . They are then used to update the iterative function (broadly refers to the function of strategy iteration or value iteration process of reinforcement learning) . The iterative function of each ( ) ( ) is as follows:</p><formula xml:id="formula_12">( ) ( ) ? ( ) ( ) ( ?1) , ( ) ( ) ( ) , ( ) ( ) ( ?1) , ( ) ( ) ( ?1) .<label>(10)</label></formula><p>Then we can use the iterative function to predict the action from the current state , which is the filtering threshold:</p><formula xml:id="formula_13">( ) ( ) ( ) = ( ) ( ) ( ) = ( ) ( ) ( ( ) ( ) ( ) ).<label>(11)</label></formula><p>Here, for the output of the action, the activation function of the classification type is used to represent them in D-RL, such as softmax. And in C-RL, we use the activation function of the return value type to represent them, such as ?. Since what we propose is a general framework applicable to a variety of reinforcement learning algorithms, the specific definition of the iterative function depends on the actual algorithm. We test the applicability of the RSRL framework to various mainstream reinforcement learning algorithms in Sec. 5.3. To improve the equalization efficiency, we assume the RL will be terminated as long as the same action appears three times in a row at the current accuracy ( ) ( ) . Specifically, in the -th layer of the -th epoch, the termination conditions of relation in the -th depth are defined as follows:</p><formula xml:id="formula_14">? ? ? ? ? ? ? { ( ) ( ) ( ) ? ( ) ( ) ( ?1) = 0}| = ?1 ? , ? &gt; 2. {| ( ) ( ) ( ) ? ( ) ( ) ( ?1) | &lt; ( ) ( ) }| = ?1 ? , ? &gt; 2.<label>(12)</label></formula><p>We formally define this deep switching condition or termination condition as ? = 3, and discuss parameter sensitivity in Section 5.5.</p><p>To acquire better training results, we use white-box methodology to test the results synchronously during the training process, and verify whether the convergence value is optimal for this round before starting a new round of RL for the same relation. If the value is negative, the filtering threshold with better performance in the historical version will be reviewed in the new round of optimization as the basis for the new round of action range. For this backtracking mechanism, we will conduct a sensitivity experiment in Section 5.5.</p><p>In this subsection, we overcome the second and third challenges mentioned in Sec. 2.2. Specifically, we use the similarity measure in the previous subsection to perform Top-p sampling for neighbors of each relation. Based on reinforcement learning, we use the agent to interact with the environment to make different relations to obtain different threshold combinations. This adaptive method is free from the help of data annotation. Furthermore, in order to meet the accuracy requirements of different relations while ensuring accuracy, we propose a recursive framework for optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Relation-aware Weighted Neighbor Aggregator</head><p>Based on the selection of similar neighbors for each relation, the next step is to aggregate all these neighbor information among relations, for a comprehensive embedding. Previous methods employ attention mechanisms <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b97">98]</ref> or weighting parameters <ref type="bibr" target="#b59">[60]</ref> to learn the relation weights during the aggregating procedure. To reduce the computational cost whilst retaining the relation importance information, we directly use the optimal filtering threshold ( ) learned by the RSRL process as the inter-relation aggregation weights. Formally, for central node , under relation at the -th layer, the intra-relation neighbor aggregation can be defined as follows:</p><formula xml:id="formula_15">h ( ) , = ( ( ) ({? h ( ?1) ? : ? ? N ( )})),<label>(13)</label></formula><p>where ? denotes the embedding bitwise summation operation for mean aggregator <ref type="bibr">( )</ref> , and N ( ) refers to the set of top ( ) nodes obtained by Eq. (10) under relation at the -th layer. The purpose of the intra-relation neighbor aggregation for the central node is to aggregate all neighborhood information under the relation at the previous layer into the embedding vector ? ( ) , . To follow up, we define inter-relation aggregation as below:</p><formula xml:id="formula_16">h ( ) = (h ( ?1) ? ( ) ({? ( ( ) ? h ( ) , )}| =1 )),<label>(14)</label></formula><p>where ? ( ) , indicates the intra-relation neighbor embedding at the -th layer and ( ) can be any type of aggregator. Here we directly use the ( ) optimized by the RSRL framework as the aggregation weight, and conduct experiments on other types of aggregation methods in Section 5.1.1 and Section 5.2.1.</p><p>In this subsection, in order to better deal with improper nodes to respond to Challenge 1 in Sec. 2.2, we divide the aggregation process into inter-relation and intra-relation, and use filtered neighbor nodes and filter thresholds of different relations to strengthen the influence of benign nodes during aggregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Put Them Together</head><p>We denote the final embedding of node as z = h ( ) , which is the output of RioGNN at the last layer. We also define the loss function of GNN in node classification task as the cross-entropy loss function:</p><formula xml:id="formula_17">L = ?? ?V ? ( ? ( ( ) (z ))).<label>(15)</label></formula><p>Algorithm 1: RemGNN: Reinforced Neighborhood Selection Guided Multiple Relation GNN.</p><p>Require : An undirected multi-relational graph with node features and labels: G = V, X, {E }| =1 , ; Number of layers, batches, epochs: , , ; Parameterized similarity measures: Together with the loss function of node classification and the loss function of the similarity measure in Eq. 4, we define the final loss function of RioGNN as follow:</p><formula xml:id="formula_18">{ ( ) (?, ?)}| =1 ; Filtering thresholds: = { ( ) 1 , . . . , ( ) }| =1 ; Intra-R aggregators: {AGG ( ) }| =1 , ? ? {1, . . . , }; Inter-R aggregators: {AGG ( ) }, ? ? {1, . . . , }; RL Module: { ( ) ( ) | =1 }, ? ? {1, . . . , }, ? ? {1, . . . , }. Ensure : Vector representations z , ? ? V . 1 // Initialization 2 h 0 ? x , ? ? V; (0) = 0.5, (0) = 0, E (0) = E, ? ? {1, . . . , } 3 { ( ) (0) ? [0, 1]}, ? ? {1, . . . , }, ? ? {1, . . . , } 4 //</formula><formula xml:id="formula_19">L RioGNN = L + ?? =1 L ( ) + * ||?|| 2 ,<label>(16)</label></formula><p>where and * are the weight parameters, and ||?|| 2 is the 2-norm of all model parameters.</p><p>Finally, based on the aforementioned study, Algorithm 1 outlines the training process of the proposed RioGNN which takes any given input multiple relation graph built upon a real-world practical problem. We employ the mini-batch training technique <ref type="bibr" target="#b27">[28]</ref> to cope with excessively large real-world graphs. We initialize the parameters of the label-aware similarity module, relation-aware neighbor select module, and relation-aware neighbor aggregator module, before training the RioGNN model at each epoch. For each batch of nodes, we first compute the neighbor similarities using Eq. (4) and then leverage the top-p sampling to filter the neighbors. Thereafter, we compute the intra-relation embeddings (by using Eq. <ref type="formula" target="#formula_1">(13)</ref>) and inter-relation embeddings (by using Eq. <ref type="formula" target="#formula_1">(14)</ref>), and define the loss functions (by using Eq. <ref type="formula" target="#formula_1">(16)</ref>) for the current batch. In the RSRL module, we allocate RL modules in sequence according to the maximum depth for each layer of each relation. In each RL module, each epoch will observe the environment state via Eq. (8) and get the reward via Eq. <ref type="bibr" target="#b8">(9)</ref>. Then the algorithm updates the iterative function through Eq. (10) and predict the filtering threshold via Eq. (11) of the current epoch through the updated iterative function. When an RL module reaches the convergence condition through Eq. (12) without targeting the maximum depth, we will recursively proceed to the next depth RL until all RL modules complete.</p><p>Time Complexity of RioGNN. The overall time complexity of Algorithm 1 is (|E | ? max({ log }| =1 )), where |E | is the number of edges, is the weight parameter of depth first and breadth first, and is the maximum number of neighbors contained in the node in relation . Here, (|E |) is the time complexity in one epoch. Specifically, the similarity measure (Line 10 in Algorithm 1) and aggregation (Line 13-15 in Algorithm 1) take a total of (|E | + |V |( + )) = (|E |), where is the average node degree and |V | is the number of nodes. The RSRL module (Line 21-29 in Algorithm 1) takes (|E | ) = (|E |). Each cross-entropy loss function (Line 8 and Line 16 in Algorithm 1) takes (| |). In addition, the number of epochs is affected by the action space of reinforcement learning, and the number of epochs required to achieve convergence is related to the action space with the greatest demand among several relations max({ log }| =1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL SETUP</head><p>In the following two sections, we conduct experiments to evaluate and test RioGNN. The experimental setup mainly revolves around the following six questions:</p><p>? Q1: How do we build multi-relational graphs in different scenarios (Section 4.2)?</p><p>? Q2: The effectiveness, efficiency and explainability of RioGNN in fraud detection tasks (Section 5.1).</p><p>? Q3: The effectiveness, efficiency and explainability of RioGNN in disease detection tasks (Section 5.2). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>We implement RioGNN with Pytorch. All experiments are running on Python 3.7.1, and a NVIDIA V100 NVLINK GPU with 32GB RAM. The operating system is Ubuntu 20.04.2. To improve the training efficiency and avoid overfitting, we employ mini-batch training and under-sampling techniques to train RioGNN and other baselines.</p><p>Specifically, under each mini-batch, we randomly sample the same number of negative instances as the number of positive instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Datasets and Graph Construction</head><p>We build different multi-relational graphs for experiments in two task scenarios and three datasets. <ref type="table" target="#tab_1">Table 2</ref> lists various statistical information of different dataset nodes and relationships. In addition to the number of nodes and the proportion of noisy nodes (Fraud%, Diabetes%) in different scenarios, we also give the number of edges with different relations. For each relationship in each dataset, we calculate the feature similarity of adjacent nodes based on the Euclidean distance (range 0 to 1) of the feature vector of adjacent nodes, and normalize the average feature similarity. The last column of <ref type="table" target="#tab_1">Table 2</ref> shows the average label similarity of each relationship, which is calculated based on whether two connected nodes have the same label. Yelp: is collected from the internal dataset published by Yelp.com, the largest business reviewing site in the United States. We use a subset of the YelpChi dataset collected and used by <ref type="bibr" target="#b69">[70]</ref>. This subset contains 45,954 user reviews of hotels and restaurants in the Chicago area. The reviews have been filtered (spam) and recommended (legal) by Yelp. In addition to containing information about the relations between users and products, the dataset also contains various metadata, including the text content of the review, timestamp, and star rating. We use 32 manual features including the ranking order of all product reviews, the absolute rating deviation from the product average, whether it is the only review of the user, the percentage of all uppercase words, the percentage of uppercase letters, the length of the review, the ratio of first-person pronouns, the ratio of exclamatory sentences, and subjective Word ratio, ratio of objective words, etc. used in <ref type="bibr" target="#b83">[84]</ref> as the original node features of the Yelp dataset. For specific relations, since previous research <ref type="bibr" target="#b69">[70,</ref><ref type="bibr" target="#b83">84]</ref> has shown opinion fraudsters (i.e., spammers) are connected in terms of users, products, review text, and time, we use reviews as nodes in the graph and design three relations:</p><p>? R-U-R: it connects reviews posted by the same user.</p><p>? R-T-R: it connects two reviews under the same product posted in the same month.</p><p>? R-S-R: it connects reviews under the same product with the same star rating (1-5 stars).</p><p>Amazon: is a subset of Amazon's product dataset <ref type="bibr" target="#b66">[67]</ref>. The Amazon dataset contains more than 34,000 consumer reviews, from which we extracted 11,949 product reviews under the musical instrument category. In addition, similar to <ref type="bibr" target="#b116">[116]</ref>, we mark users with useful voting rates greater than 80% as benign entities, and users with useful voting rates less than 20% as fraudulent entities. In terms of node feature selection, we use 25 manual features including the number of rated products, the length of the user name, the number and ratio of each rating level given by the user, the ratio of positive and negative reviews, the user's rating, the total number of useful and useless votes obtained by the user, the ratio of useful votes and useless votes, and Average value, median of useful and useless votes, minimum and maximum number of useful and useless votes, number of days between the user's first and last rating, same date indicator, comment text sentiment, etc. used in <ref type="bibr" target="#b116">[116]</ref> as the original node function of the Amazon data set. For specific relations, we design three kinds of relations for the multi-relational graph, as shown below:</p><p>? U-P-U: it connects users reviewing at least one same product.</p><p>? U-S-V: it connects users having at least one same star rating within one week.</p><p>? U-V-U: it connects users with the top 5% mutual review text similarities (measured by TF-IDF) among all users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Diagnosis of diabetes mellitus task.</head><p>We perform the binary classification task of diagnosis of diabetes mellitus on the processed MIMIC-III dataset resources. MIMIC-III: is a publicly available dataset <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b44">45]</ref> consisting of health records of 46,520 intensive care unit (ICU) patients over 11 years. We have extracted a total of 28,522 patient visits, and each record contains information such as age, diagnosis, microbiology, procedures, corpus, etc. We use a subset of the MIMIC-III dataset collected and used by <ref type="bibr" target="#b61">[62]</ref>, and construct our multi-relational graph for our task based on that. For each patient and visit, there is a unique ID to track its corresponding information. According to the diagnostic codes, we mark the medical records as diabetic or non-diabetic. Ages are split into groups using threshold 15, 30 and 64 as suggested in <ref type="bibr" target="#b63">[64]</ref>. Procedures and diagnoses are mapped into corresponding ICD-9-CM codes. Microbiology tests with culture-positive results are mapped into the names of organisms. We use the above four fields to form different relationships among visit nodes to construct a heterogeneous graph. Based on previous medical representation learning, we obtain the feature representation of each node based on the medical corpus obtained from the admission record. Due to the complexity of the medical knowledge field, we appropriately enlarge the selection range of the relationship to further test the filtering performance of our RSRL Framework for camouflaged neighbors. For specific relations, since the previous work <ref type="bibr" target="#b5">[6]</ref> has described the concept of different fields in detail, we design four kinds of relations for the multi-relational graph based on it, as shown below:</p><p>? V-A-V: it connects visits in the same age category.</p><p>? V-D-V: it connects visits having the same diagnoses.</p><p>? V-P-V: it connects visits with at least one same procedure code.</p><p>? V-M-V: it connects visits with at least one same microbiology code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Evaluation of Datasets.</head><p>We measure different datasets from the four metrics of node distribution, edge distribution, and feature similarity and label similarity. It can be observed that in fraud detection tasks, Yelp and Amazon have only 14.5% and 9.5% of fraud nodes, while mimic has a more balanced ratio. In addition, the different relations of the three datasets all have different number levels and uneven edge distribution. In addition, in the Yelp and Amazon datasets, edges with different relations have balanced feature similarity, but existing edges have higher feature similarity and lower label similarity. For instance, the average feature similarity of R-T-R is 0.79, but the label similarity is only 0.05. This shows that the fraudsters successfully pretends to be in benign entities and needs a more effective way to identify it. In general, these characteristics challenge the model's ability to learn from data sets in different situations. Specifically, Yelp and Amazon focus on the ability to challenge uneven data sets. Mimic focuses more on the ability of filtering high-density neighbor nodes. The relation matrix of MIMIC under each relation is denser, one order of magnitude higher than that of Yelp and Amazon. The first three models are compared as traditional GNN baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines and Variations</head><p>? GCN <ref type="bibr" target="#b48">[49]</ref>: is a representative of the spectral graph convolution method, which sets up a simple and wellbehaved hierarchical propagation rule for neural network models. This rule runs directly on the graph, and uses the first-order approximation of the Chebyshev polynomial to complete an efficient graph convolution architecture. ? GAT <ref type="bibr" target="#b95">[96]</ref>: is a neural network architecture combined with the attention mechanism that runs on graphstructured data. It uses masked self-attentional layers to give importance to the edges between nodes, help the model learn structural information, and assign different weights to different nodes in the neighborhood without expensive calculations and pre-definitions. ? Graph-SAGE <ref type="bibr" target="#b31">[32]</ref>: is a representative non-spectrogram method. For each node, this method provides a general inductive framework that samples and aggregates its local neighbors' features to generate the embedding instead of training a separate embedding. It improves the scalability and flexibility of GNNs.</p><p>The second ten baselines are the latest GNN models that handle multi-relational data or the datasets used in this article.</p><p>? RGCN <ref type="bibr" target="#b84">[85]</ref>: is a relational GCN model that uses Gaussian distribution as the hidden layer node feature representation, and relies on the attention mechanism to automatically assign the weight of each neighbor to aggregate neighbor information. ? GeniePath <ref type="bibr" target="#b58">[59]</ref>: is a scalable graph neural network model used to learn the adaptive receptive domain of neural networks defined on permutation invariant graph data. Through the breadth and depth exploration of an adaptive path layer, the model can sense the importance of neighboring nodes and extract and filter signals gathered from the neighborhood. ? Player2Vec <ref type="bibr" target="#b118">[118]</ref>: is an AHIN representation learning model that maps the attribute heterogeneous information network (AHIN) to a multi-view network, encodes the correlation between users described by different design meta-paths, and uses the attention mechanism to fuse embeddings from each view to form the final node representation. ? SemiGNN <ref type="bibr" target="#b97">[98]</ref>: is a semi-supervised attention graph neural network, in which a hierarchical attention mechanism is designed. Neighborhood information is integrated through node-level attention, and multiview data is integrated through view-level attention, resulting in better accuracy and interpretability. ? GAS <ref type="bibr" target="#b52">[53]</ref>: uses both a heterogeneous graph and a homogeneous graph to capture the local and global context of a comment, and is a meta-path based heterogeneous GCN model. In our scenario, meta-paths are enumerated from relations. ? FdGars <ref type="bibr" target="#b98">[99]</ref>: constructs a single homogeneous graph based on multiple relations and employs GNNs to aggregate neighborhood information. Compared with our work, this model lacks neighborhood selection. ? GraphConsis <ref type="bibr" target="#b60">[61]</ref>: is a model that combines context embedding with nodes, filters inconsistent neighbors and generates corresponding sampling probabilities. The embeddings of sampled nodes from each relation are fused using a relation attention mechanism. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>Multi-layer RL Module Action Space Recursion Inter-AGG</p><formula xml:id="formula_20">RioGNN 2 ? AC Discrete ? Threshold BIO-GNN ? BMAB Discrete ? Threshold ROO-GNN ? AC Discrete ? Threshold RIO-Att ? AC Discrete ? Attention RIO-Weight ? AC Discrete ? Weight RIO-Mean ? AC Discrete ? Mean RioGNN ? AC Discrete ? Threshold ? HAN [101]</formula><p>: is a hierarchical attention network aggregating neighbor information via different meta-paths.</p><p>Although the input data is heterogeneous, meta-paths are symmetrical in our scenario (i.e., the end nodes are of the same type), thus the model is regarded as a homogeneous model. ? GCT <ref type="bibr" target="#b12">[13]</ref>: is a basic model for learning the implicit EHR structure using Transformer. Using statistical data to guide the structure learning process solves the problem that existing methods require complete docking structure information. Specifically, they use the attention mask and prior knowledge to guide self-attention to learn the hidden EHR structure, and they can learn the underlying structure of the EHR together even when the structural information is missing. ? HSGNN <ref type="bibr" target="#b61">[62]</ref>: is a heterogeneous medical graph-based semi-supervised graph neural network, which combines both meta-path instance based similarity matrices and self-attention mechanism.</p><p>The third two baselines are the latest Reinforcement Learning guided GNN models. We respectively use the raw heterogeneous graph and the proposed multi-relation graph as the input of these models.</p><p>? GraphNAS <ref type="bibr" target="#b23">[24]</ref>: enables automatic search of the suitable graph neural architecture via reinforcement learning. This model uses a recurrent network to generate variable-length strings that describe the architectures of graph neural networks, and then trains the recurrent network with reinforcement learning to maximize the expected accuracy of the generated architectures. ? Policy-GNN <ref type="bibr" target="#b50">[51]</ref>: is a meta-policy framework that adaptively learns an aggregation policy to sample diverse iterations of aggregations for different nodes. To accelerate the learning process, we also use a buffer mechanism to enable batch training and parameter sharing mechanism to decrease the training cost.</p><p>The last baseline is from the preliminary version of this article.</p><p>? CARE-GNN <ref type="bibr" target="#b14">[15]</ref>: A layer of label-perceived similarity measure is used to find information-rich neighboring nodes. Then the Bernoulli Multi-armed Bandit (BMAB) mechanism is used to explore the optimal number of neighbors for each relationship.</p><p>Among those baselines, GCN, GAT, GraphSAGE, and GeniePath runs on the homogeneous graph (i.e., Relation ALL in <ref type="table" target="#tab_1">Table 2)</ref>, where all relations are merged together. GraphNAS and Policy-GNN runs on the raw heterogeneous graph. Other models run on the multi-relational graph. On the multi-relational graph, they process information from different relations in their methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Variations.</head><p>We have implemented many variants of the RioGNN model. The configurations of different variants are shown in <ref type="table" target="#tab_2">Table 3</ref>. In detail, the setting of the model variants mainly revolves around the key mechanisms of the three modules: Label-aware Similarity Measure, Similarity-aware Neighbor Selector, and Relation-aware Neighbor Aggregator.</p><p>The first one given is a variation of the unexpanded multi-layer version of the Label-aware Similarity Measure section.</p><p>? RioGNN 2 : It uses the Actor-Critic (AC) algorithm with a discrete strategy to recursively select the filter thresholds of different relationships, and uses the filter thresholds as relation weights to aggregate neighbors between different relations. But the Label-aware Similarity Measure uses a 2-layer structure for neighbor selection.</p><p>The next two methods are variants according to the Similarity-aware Neighbor Selector module.</p><p>? BIO-GNN: This variant is a method with the single-layer similarity-aware neighbor selection and uses filtering thresholds for aggregation between relations. But the Bernoulli Multi-armed Bandit (BMAB) algorithm of discrete strategy is used to recursively select the filtering threshold of relations. ? ROO-GNN: This variant is a method with the single-layer similarity-aware neighbor selection and uses filtering thresholds for aggregation between relations. But the Actor-Critic algorithm of discrete strategy is used to directly select the filter threshold of relationships. This method can be regarded as a non-recursive (one-depth) version of RioGNN.</p><p>The difference between the following three variants is reflected in the aggregation method between different relations of Relation-aware Neighbor Aggregator.</p><p>? RIO-Att: This variant uses single-layer similarity perception for neighbor selection, and uses the Actor-Critic algorithm with a discrete strategy to recursively select the filter thresholds of different relations. But it chooses the method of Attention <ref type="bibr" target="#b95">[96]</ref> when aggregating neighbors between different relations. ? RIO-Weight: This variant uses single-layer similarity perception for neighbor selection, and uses the Actor-Critic algorithm with a discrete strategy to recursively select the filter thresholds of different relations. But it chooses the method of Weight <ref type="bibr" target="#b59">[60]</ref> when aggregating neighbors between different relations. ? RIO-Mean: This variant uses single-layer similarity perception for neighbor selection, and uses the Actor-Critic algorithm with a discrete strategy to recursively select the filter thresholds of different relations. But it chooses the method of Mean <ref type="bibr" target="#b31">[32]</ref> when aggregating neighbors between different relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">RL Variations.</head><p>In order to better discuss the adaptability of the framework of this article to a variety of reinforcement learning algorithms, we conducted experiments on two action spaces (discrete and continuous) of different reinforcement learning algorithms. The first three reinforcement learning models are based on discrete action spaces. That is, in the process of constructing the reinforcement learning forest, a discrete filtering threshold is used as the action type of reinforcement learning.</p><p>? AC <ref type="bibr" target="#b49">[50]</ref>: Actor-Critic (AC) method combines the advantages of the value-based method and policy-based method. The value-based method is used to train the Q function to improve the sample utilization efficiency. The policy-based method is used to train the strategy, which is suitable for discrete and continuous action spaces. This kind of method can be regarded as an extension of the value-based method in the continuous action space, or as an improvement of the policy-based method to reduce the sampling variance. ? DQN <ref type="bibr" target="#b68">[69]</ref>: Deep Q-Learning (DQN) is a temporal-difference, value-based and off-policy reinforcement learning method. DQN approximately solves the dimensional disaster problem of Q-Learning method in the face of high-dimensional state and action through the function approximation. In addition, the traditional Q-Learning method uses samples with time series for single-step update, and the value is updated by the sample continuity. DQN uses random data for gradient descent due to trial and error to collect a large number of samples, which can break the correlation between data. ? PPO <ref type="bibr" target="#b85">[86]</ref>: Proximal Policy Optimization (PPO) restricts the update step size on the basis of Policy Gradient (PG) to prevent policy collapse and make the algorithm rise more steadily.</p><p>The next four reinforcement learning models are based on continuous action spaces. That is, in the process of constructing the reinforcement learning forest, a continuous filtering threshold is used as the action type of reinforcement learning.</p><p>? AC <ref type="bibr" target="#b49">[50]</ref>: We use the AC method to conduct variation experiments in both discrete action space and continuous action space. ? DDPG <ref type="bibr" target="#b54">[55]</ref>: Deep Deterministic Policy Gradient (DDPG) is an off-policy algorithm for continuous control developed by DeepMind, which is more sample efficient than PPO. DDPG trains a deterministic policy, that is, only one optimal action is considered in each state. ? SAC <ref type="bibr" target="#b35">[36]</ref>: Soft Actor-Critic (SAC) is an off-policy algorithm developed for Maximum Entropy Reinforcement learning. Compared with DDPG, Soft Actor-Critic uses stochastic policy, which has certain advantages over deterministic policies. Soft Actor-Critic has achieved outstanding results in the public benchmark and can be directly applied to real robots. ? TD3 <ref type="bibr" target="#b22">[23]</ref>: Twin Delayed Deep Deterministic policy gradient (TD3) is a temporal-difference, policy based and policy gradient reinforcement learning method. TD3 is an optimized version of DDPG. It uses two sets of networks to estimate the value, and the relatively smaller one is used as the update target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Model Training</head><p>We use unified embedding size <ref type="formula" target="#formula_5">(64)</ref>, batch size (1024 for Yelp, 256 for Amazon and MIMIC-III), learning rate (0.01), the similarity loss weight ( 1 = 2), L2 regularization weight ( 2 = 0.001) for all the models. Except for the comparative experiments specifically explained, other experiments that are not explained all use a 40% training ratio, under-sampling ratio 1 : 1, deep switching number 3, weight parameter of depth first and breadth first as 10, and a single-layer similarity perception structure with backtracking. For the reinforcement learning model, we use gamma (0.95), learning rate (0.001) as unified parameters and buffer capacity (5), batch size (1) as parameters for DDPG, DQN, SAC and TD3. We conduct the sensitivity study for deep switching number, backtracking setting, under-sampling ratio in Section 5.5. In addition, we also discuss weight parameter of depth first and breadth first in Section 5.3, and training ratio in Section 5.1 and Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Evaluation Metrics</head><p>We utilize ROC-AUC (AUC) <ref type="bibr" target="#b94">[95]</ref> and Recall to evaluate the overall performance of all classifiers. AUC is computed based on the relative ranking of prediction probabilities of all instances, which could eliminate the influence of imbalanced classes. The Recall is defined as:</p><formula xml:id="formula_21">= + ,<label>(17)</label></formula><p>where is True Positive, is False Negative. The AUC is defined as:</p><formula xml:id="formula_22">= 1 2 ?1 ?? =1 ( +1 ? ) ( + +1 ),<label>(18)</label></formula><p>where is True Posotive Rate ( = + ), is False Positive Rate ( = + ). And is False Positive, is True Negative. In the clustering task, we use Normalized Mutual Information (NMI) and Adjusted Rand Index (ARI) as the performance indicators. The ARI is defined as:</p><formula xml:id="formula_23">= ( 2 ) ? [ ( 2 ) ( 2 )]/( 2 ) 1 2 [ ( 2 ) ? ( 2 )] ? [ ( 2 ) ( 2 )]/( 2 ) ,<label>(19)</label></formula><p>where each represents the number of nodes located in class and cluster at the same time, is the number of the nodes in class and is the number of the nodes in cluster . The NMI is defined as:</p><formula xml:id="formula_24">= ( ; ) [ ( ) + ( )]/2 ,<label>(20)</label></formula><p>where is mutual information, is entropy. In inductive learning, in order to better measure the effectiveness, we add the F1 indicator to measure after the two indicators of AUC and Recall. F1 is defined as:  <ref type="table" target="#tab_4">Table 4</ref> shows the results of baseline experiments built on different types of graphs for the fraud detection task. To solve the diversity and heterogeneity of complex networks in actual fine-grained applications, we consider introducing a neural network with a multi-relational graph structure instead of a single relation structure. However, from the results of some of the baselines in the table, although GCN, GAT, GraphSAGE and GeniePath models run on a single relation graph, they are better than RGCN, Player2Vec and SemiGNN in terms of accuracy of the Yelp dataset, which are run on the multi-relational graphs. The observation above shows that the previous multi-relational GNNs are not suitable for constructing multi-relational graphs in the fraud detection task. Similar phenomena manifest in the Amazon dataset. Besides, GraphConsis, FdGars, CARE-GNN and RioGNN significantly outperform other models by 8.60%-32.78% over Yelp and Amazon datasets. This is because these four models sample the neighbors according to node features before aggregating them, indicating that the impurity neighbors will interfere with the aggregation process and the fraud detection task has a strong demand for neighbor sampling optimization. CARE-GNN and RioGNN have improved the AUC of 3.51%-21.65%, compared with the performance of GraphConsis and FdGars. This is because RioGNN can better use internal relations to solve downstream application problems through parameterized similarity measures and adaptive sampling thresholds, which shows that automated sampling has a significant improvement effect on fraud detection tasks. The more remarkable result is that the proposed RioGNN model improves the accuracy of 5.90% and 10.41% compared with CARE-GNN. It verifies the advantage of combining the label-aware neighbor similarity measure and the Recursive and Scalable Reinforcement Learning framework, which can effectively break through the limitations of the CARE-GNN state observation range and manually specified strategies. Meanwhile, RioGNN has a promising effectiveness on fraud detection tasks.</p><formula xml:id="formula_25">1 = 2 ? ? + ,<label>(21)</label></formula><p>Heterogeneous vs. Multi-relation. In order to further analyze the accuracy of the multi-relational graph, we conduct heterogeneous graph experiments and multi-relational graph experiments on the latest GNN model guided by reinforcement learning. From the results of the heterogeneous graph model GraphNAS , Policy-GNN and the multi-relationship graph model GraphNAS and Policy-GNN in <ref type="table" target="#tab_4">Table 4</ref>, it can be found that the multirelational graph compared with the heterogeneous graph brings an AUC improvement of 0.33%-1.71% in the Yelp and Amazon datasets. This confirms that in other similar models, the multi-relational graph we construct  still has obvious advantages. In addition, we found that GraphNAS and Policy-GNN, which are also based on reinforcement learning guidance and use the multi-relational graph, have no significant advantages in AUC and Recall. This is because GraphNAS and Policy-GNN do not adaptively sample different relations, which causes them to be limited by the complexity of the relationship between Yelp and Amazon datasets. And for Policy-GNN, since the one-hop neighbor information of Yelp and Amazon is already rich enough, more multi-hop strategies cannot bring significant benefits. Training Percentage. To measure the impact of the training ratio on the classification accuracy, we use four different ratios of 5% to 40% for experiments. It can be seen from <ref type="table" target="#tab_4">Table 4</ref> that most of the baseline performance changes are not necessarily related to the increase in training percentage. It indicates that the semi-supervised learning approach leveraging a small number of supervised signals is enough to train a good model. Moreover, in the four different training ratios of the Yelp dataset, the AUC fluctuation range of RioGNN is only within 1.57% compared to the 4.44% of CARE-GNN. In Amazon, both models have good stability. This is because the Amazon node features provide enough information to distinguish fraudsters, which is of higher quality than the Yelp dataset. It also verifies from another result that RioGNN has better stability and adaptability under complicated environments.</p><p>RioGNN Variants in Classification. To measure the positive impact of the newly added mechanism on the classification accuracy of fraud detection tasks, we compare several variants of RioGNN under the discrete strategy. The experiment sets the training data ratio to 40%, and the other settings are the same as Section 4.1. We show the experimental results of spam review classification in the Yelp dataset and suspicious user classification in the Amazon dataset as shown in <ref type="table" target="#tab_5">Table 5</ref>. From the results, the performance of all variants is better than the baseline model. Next, we will discuss the effects of different variants from three aspects.</p><p>Firstly, in the two datasets, except for the RioGNN 2 variant, all other variants only use the Label-aware Similarity Measure with a one-layer structure. From the results in <ref type="table" target="#tab_5">Table 5</ref>, the RioGNN 2 variant is lower than all other variants, but it performs better than all baselines. It can be found that in the fraud detection task, the increase in the number of layers does not bring about a significant increase in classification accuracy. This is limited by the dataset size of Yelp and Amazon, and the importance of information in multi-hop neighbors is low. We will continue to explore more multi-layer effects in Section 5.1.3.</p><p>Secondly, for the similarity-aware neighbor selector part, we observe the comparison results of the variant BIO-GNN without adaptive strategy optimization reinforcement learning algorithm and the single-depth structure variant ROO-GNN without the recursive framework for the RSRL framework. The second part of <ref type="table" target="#tab_5">Table 5</ref> gives evidence of partial optimization. The results of the BIO-GNN variant on the RioGNN model show that the automatic strategy optimization in Yelp and Amazon effectively improves the classification accuracy of 4.65% and 0.89%, and the BIO-GNN variant is also far better than most baseline models. This shows that the Markov Decision Process has a positive effect on searching for the filtering threshold of the aggregation process. Moreover, the reinforcement learning algorithm with dynamic iterative function and full action space learning process breaks the limitation of fixed strategy and observation range and obtains a better threshold selection effect, which also confirms the conjecture in Section 3.2.2. Besides, combining <ref type="figure" target="#fig_22">Figure 8</ref> with <ref type="table" target="#tab_5">Table 5</ref>, the accuracy of the ROO-GNN variant has little change compared with RioGNN, that is, the multi-depth structure of RioGNN can converge much quicker than the single-depth variant ROO-GNN whilst maintaining a higher accuracy rate. This also implies the stability of the recursive framework in terms of classification accuracy. Finally, from the results of the variation of the aggregation methods between the different relations in the third part of the <ref type="table" target="#tab_5">Table 5</ref>, RioGNN has apparent advantages over the other three on the Yelp dataset, and both RIO-Weight and RioGNN on the Amazon dataset have good results. It confirms that RioGNN does not need to train additional attention weights, and using the filtering threshold as an inter-relation aggregation weight can improve the performance of GNN and reduce the complexity of the model. Therefore, it can get the best performance compared with other variants. For the three variants, RIO-Weight has better results than the other two, but RioGNN can maintain better accuracy in the dataset of different quality and structure and has a certain degree of adaptability.</p><p>RioGNN Variants in Clustering. In order to explore the effectiveness of RioGNN in clustering tasks, we conduct clustering experiments on RioGNN and its variant models. The experiment set a fixed training rate of 40%. We cluster the node representations learned by RioGNN through K-Means. The results are shown in <ref type="table" target="#tab_6">Table 6</ref>. We respectively count the best values of NMI and ARI indicators within 500 epochs. It can be seen from the results that compared with RIO-GNN 2 and BIO-GNN, RioGNN's NMI and ARI indicators in the Yelp dataset increase at least 9.04% and 10.33% respectively. Similarly, the Amazon dataset has risen by at least 2.39% and 1.87%. This phenomenon is the same as the classification result, and is affected by the limitation of the size of the dataset, the choice of the action space, and the dynamic iterative function. In addition, the NMI and ARI of ROO-GNN in the Yelp dataset achieved the best results, while the RioGNN in the Amazon dataset exceeded the NMI and ARI of ROO-GNN by 3.45% and 2.31%. This is because the Yelp dataset is smaller than Amazon, so the optimization space of the recursive framework is also smaller. It shows that the recursive framework has better advantages in dense datasets. What is more noteworthy is that RioGNN in the clustering experiment exceeds the effect of all GNN aggregation variants. NMI and ARI exceed 0.17%-3.83% and 0.57%-7.65% in the Yelp dataset, and exceed 2.5%-5.5% and 1.67%-1.89% in the Amazon dataset. This shows that directly using the filtering threshold as the weight of the aggregation has obvious advantages in clustering tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Explainable RSRL Training</head><p>Process. This section focuses on the RSRL framework and discusses the explainability of the reinforcement learning process in detail. We show the change process of the RioGNN's filtering threshold and similarity score of the different relations before convergence during the training process on the Yelp and Amazon datasets. For a better comparison, we also conduct a similar analysis on ROO-GNN and BIO-GNN variants.</p><p>Filter Thresholds. In <ref type="table" target="#tab_1">Table 2</ref>, we observe that the average feature similarity for most relations in Yelp and Amazon are very high. However, there is a relation such as R-T-R, which has a low label similarity of 0.05, which indicates that fraudsters successfully disguised themselves. For this reason, we propose to filter the lower-ranked neighbors in the Top-p sampling through the filtering threshold. It can be seen from <ref type="figure" target="#fig_10">Figure 5</ref>     that the filtering thresholds of the three relations of the Yelp dataset are stable at [0.99, 0.093, 0.787], and the Amazon dataset converges to [0.071, 0.0712, 0.9997]. It shows that the filtering thresholds for different relations eventually converge to different values. The reason is that the label similarity and feature similarity of different relations are different in the same dataset. This result also can be verified from <ref type="table" target="#tab_1">Table 2</ref>. For instance, the label similarity difference between R-U-R and R-T-R is 0.85, but the feature similarity difference is only 0.04. The proposed framework builds a reinforcement learning tree for each relation, uses the similarity between the relations as a reward, and independently finds the appropriate filtering threshold. Due to the mutual influence between relations, a set of Nash equilibrium filtering thresholds will eventually be obtained, which is a sampling scheme that can best eliminate the interference of fraudsters <ref type="bibr" target="#b15">[16]</ref>. In the Nash equilibrium, it is impossible for all agents to obtain greater rewards only by changing their own strategies. In addition, in <ref type="figure" target="#fig_10">Figure 5</ref>      .169], respectively. Since the result of reinforcement learning is obtained by the connection strategy of all agents, there may be many different filter threshold combinations at each time the game between relations reaches the Nash equilibrium <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b81">82]</ref>. <ref type="figure" target="#fig_10">Figure 5</ref>(a) and <ref type="figure" target="#fig_10">Figure 5</ref>(c) show the changes in rewards obtained during the filtering threshold learning process for different relations. We observe that in the Yelp dataset, the relations R-S-R and R-U-R achieve better reward growth in the interest competition of the three relations. In contrast, the relation R-T-R eventually stabilizes at a relatively low reward. This is consistent with the actual scenario. Comments with the same star rating in the same product are important considerations for dividing spam comments, and comments by the same user usually have the same tendency. However, reviews published in the same month have a lower impact factor. The U-P-U and U-S-U of the similar Amazon dataset are more meaningful than the relation U-V-U. This means that users    who post similar content are more closely connected, and are considered an important observation factor when making user judgments. Recursive Framework. In the right column of <ref type="figure" target="#fig_15">Figure 6</ref>, we show the changes in the filtering thresholds of the two variants of RSRL, ROO-GNN and BIO-GNN on the Yelp dataset. Comparing RioGNN in <ref type="figure" target="#fig_10">Figure 5</ref>(b) with ROO-GNN in <ref type="figure" target="#fig_15">Figure 6(b)</ref>, it can be seen that RioGNN with the recursive framework of <ref type="figure" target="#fig_10">Figure 5</ref>(b) performs a more accurate filtering threshold search for each depth. For example, the relation R-U-R is first explored in the interval [0, 1] with an accuracy of 0.1 to obtain a convergence of 0.9. Then it searches for the convergence between [0.85, 0.95] to obtain the highest accuracy 0.01 of the relation R-U-R, and get the final convergence 0.99. The difference from RioGNN is the ROO-GNN model in <ref type="figure" target="#fig_15">Figure 6</ref>(b), where only one deep reinforcement learning is performed. For example, R-U-R directly explores the [0, 1] interval with the highest accuracy of 0.01 and obtains the final convergence value of 0.89. In addition to the difference mentioned above, we can also see whether there is a recursive reward change shown in <ref type="figure" target="#fig_10">Figure 5</ref>(a) and <ref type="figure" target="#fig_15">Figure 6</ref>(a). For RioGNN with recursion, all relations converge fully at 110 epochs, while ROO-GNN without recursion converges at 390 epochs. Furthermore, the rewards obtained by the two methods are basically the same. This solves the challenge we pose in Section 2.2, and explains that reducing the number of actions for each reinforcement learning can effectively accelerate the convergence of the model. The experimental results also show that the addition of recursion does not bring about a significant loss of accuracy, which is significant.</p><formula xml:id="formula_26">R ? T ? R(l1) R ? T ? R(l2) (b) R-T-R.</formula><p>Action Space and Iterative Function. In <ref type="figure" target="#fig_10">Figure 5</ref>(b) and <ref type="figure" target="#fig_15">Figure 6(d)</ref>, we present the BIO-GNN variant and RioGNN with dynamic iterative function and full action space learning process. It can be seen that, similar to RioGNN, BIO-GNN also recursively converges to 0.4 with an accuracy of 0.1 for the R-U-R relation and then converges to 0.33 with an accuracy of 0.01. But the difference from RioGNN is that this method has an average similarity score of 0.045 for the three relations, which is lower than RioGNN's 0.021. This means that the maximum filtering effect has not been achieved. In other respects, compared with the <ref type="figure" target="#fig_10">Figure 5</ref>(a) and <ref type="figure" target="#fig_15">Figure 6</ref>(a) that have obtained better performance, the R-T-R relation of <ref type="figure" target="#fig_15">Figure 6</ref>(c) has obtained a higher reward ratio in the competition. That is, the behaviors published in the same month are considered by BIO-GNN to be more important, which is contrary to the reality. So this explains the reason for the lower performance of BIO-GNN.  Meanwhile, these results demonstrates that dynamic learning can be observed globally, thereby obtaining more effect, which proves the conjecture in Section 3.2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Effectiveness and Efficiency</head><p>Evaluation. Next, we introduce the effectiveness and efficiency of multi-layer similarity perception modules and recursive neighbor selectors in fraud detection tasks on the two datasets. We use RioGNN with a two-layer perception structure to train for 500 epochs on the Yelp dataset, and select the first 250 epochs to show the changes in the scores of each layer in <ref type="figure" target="#fig_20">Figure 7</ref>. For the recursive framework, we analyze the AUC change trend of ROO-GNN, BIO-GNN variants and RioGNN on two datasets within 500 epochs <ref type="figure" target="#fig_22">(Figure 8</ref>). The dotted line in the figure indicates the average AUC of each variant after reaching stability. The specially marked points in the figure show the epoch numbers for different models to reach a certain AUC.</p><p>Multi-layer Analysis. We provide a multi-layer label-aware similarity neighbor measurement scheme to deal with data collections with more complex structures in the future. For the datasets in this article, the increase of multiple layers is limited by the datasets (one-hop neighbor information is enough for sampling), and the AUC gain brought by it is limited. However, we notice in <ref type="figure" target="#fig_20">Figure 7</ref> that as the number of layers increases, Layer 2 has a significant improvement in the similarity score of each relation compared to Layer 1. Among them, the similarity score of the relation R-U-R is 14.00 in the second level compared with the first level. In addition, the R-T-R and R-S-R are improved in 5.33 and 7.66. This is because we take the embedding of the neighbors of the previous layer as the input of the second layer, embedding more hops of neighbor relations. Rich neighbor information makes the performance of the similarity module better. This also shows that multi-layer joining can be a new deployment scheme in some datasets with insufficient embedded information of one-hop neighbors.</p><p>Multi-depth Analysis. In order to effectively speed up the optimization speed of the filtering threshold of each relation while ensuring the accuracy rate, we propose a recursive reinforcement learning learning framework. It can be seen from <ref type="figure" target="#fig_22">Figure 8</ref> that the RioGNN model has obvious advantages over ROO-GNN and BIO-GNN in both datasets. First of all, we observe the final convergence AUC size. In the Yelp dataset, RioGNN and BIO-GNN models are about 4.75% higher than ROO-GNN. In the Amazon dataset, RioGNN is better than the other two models by about 0.8%. And BIO-GNN finally converged AUC is generally low. In addition, in terms of computational efficiency, compared with the ROO-GNN model without recursion, RioGNN maintains a stable and rapid increase in AUC in both datasets. However, ROO-GNN has greater fluctuations. In the first 50 epochs of Yelp and the first 75 epochs of Amazon, there is no significant difference between them. In the Yelp dataset, the speedup of RioGNN compared to ROO-GNN is 2.14 when AUC reaches 78.5%, 2.99 when AUC reaches 81.5, and 2.10 when AUC reaches 83.1%. In Amazon, the speedup ratio is 3.19 when the AUC reaches 95.30%, and the speedup ratio is 4.52 when AUC reaches 95.4%. Compared with the BIO-GNN with limited action space and fixed strategy, Yelp and Amazon are also observed 8.81 and 1.71 times time savings at 78.5% and 95.3% AUC. This shows that the proposed recursive framework can achieve good efficiency while maintaining accuracy. And generally, the higher the AUC demand, the better the efficiency. The broader and flexible action space and the iterative function that automatically updates have more significant advantages in terms of efficiency and accuracy. Finally, we find that different optimization structures have different impact factors for different datasets. Due to the smaller scale and lower accuracy requirements of the Yelp dataset, whether it has a recursive structure has little effect on the final convergence AUC. But in Amazon, which has a larger scale and higher precision requirements, placing all actions at one depth causes a loss of accuracy. This also confirms the conjecture in Section 3.2.2 about the loss of accuracy caused by the excessively large action space, and confirms the advantages of the recursive structure in large-scale datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Overall Evaluation of Diagnosis of Diabetes Mellitus Task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Accuracy Analysis.</head><p>In this section, we conduct experiments to evaluate the accuracy of diagnosis of diabetes mellitus on the MIMIC-III dataset. As presented in <ref type="table" target="#tab_7">Table 7</ref>, we report the best test results of RioGNN and various baselines and variants in seven hundred epochs. It can be observed from the results that RioGNN performs better than other baselines and variants under most training ratios and indicators. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIMIC-III</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AUC</head><p>Recall 5% 10% 20% 40% 5% 10% 20% 40% GCN Single-relation vs. Multi-relation. In order to further prove the effectiveness of RioGNN in processing the multi-relational graph, we perform a baseline comparison on the more challenging task of diagnosis of diabetes mellitus. <ref type="table" target="#tab_7">Table 7</ref> shows the comparative results of RioGNN and the three types of baselines. Compared with the first type of baseline running on a single-relational graph: GCN, GAT and GraphSAGE, the model RioGNN is significantly better than them on the MIMIC-III dataset by 13.32%-18.30%. This result fully confirms that the fine-grained division of multi-relational graph and hierarchical aggregation based on different relations are very conducive to the completion of the node classification task. This point is completely consistent with the experimental conclusions on the fraud detection task. Furthermore, in order to show the performance of RioGNN when dealing with the multi-relational graph, we carry out the second type of baseline comparison experiment. Although GCT, HSGNN and HAN all run on heterogeneous graphs, and propose different ideas for processing heterogeneous relations, their accuracy rates are at least 8.77% lower than RioGNN. Due to the high density of neighbor nodes under each relation, the inability to effectively filter interfering nodes also brings difficulties to the final diagnosis task. Compared with RioGNN, it is obvious that they fail to filter out interfering neighbor nodes and produce a sufficiently strong positive effect on the final diagnosis. Interestingly, comparing the two types of baselines, we find that although the second type of baselines divides the heterogeneous relations to a certain extent, they are in most cases even worse than the first type of baselines running on a single-relational graph. The above results show that when dealing with the multi-relational graph, how to effectively select the appropriate neighbor nodes is particularly important, while RioGNN achieves this well through parameterized similarity measures and adaptive sampling thresholds. When it comes to the third type of baseline, CARE-GNN, we find that its accuracy is significantly higher than the first two types of baselines by 11.73%-17.70%, which means that fine-grained and multi-relational division of heterogeneous graphs is very necessary. Although CARE-GNN realizes automatic filtering and sampling of neighbor nodes to a certain extent, its diagnostic effect is lower than RioGNN due to the inability to adaptively select the best filtering threshold under each relation. The above shows that the proposed RSRL framework finds the optimal filtering threshold under each relation in the recursive process successfully, thus it performs outstandingly in downstream tasks.</p><p>Heterogeneous vs. Multi-relation. In synchronization with the fraud detection task, we also analyze the performance of GraphNAS and Policy-GNN models in heterogeneous graph and multi-relational graph in the disease detection task. From <ref type="table" target="#tab_7">Table 7</ref>, the same phenomenon as the fraud detection task can be obtained, that is, the introduction of the multiple relational graph on the Mimic dataset also has certain advantages compared with the heterogeneous graph. However, unlike Yelp and Amazon, GraphNAS and Policy-GNN are generally better than other baselines in terms of accuracy. We believe that the cause is the balanced features and labels of the Mimic dataset with different relations, and the higher aggregation requirements of the large-scale dataset for neighbor information.</p><p>Training Percentage. In order to measure the impact of the training ratio on the classification accuracy in the diagnosis of diabetes mellitus task, we still set four different training ratios ranging from 5% to 40%. It can be seen from <ref type="table" target="#tab_7">Table 7</ref> that the classification accuracy of RioGNN shows a steady upward trend as the training ratio increases. This shows that the training process of RioGNN has a very positive effect on the final classification accuracy. It can be seen intuitively, RioGNN has successfully achieved a good performance improvement in the process of reinforcement learning recursion by supervised signals, which is also in line with expectations. However, the accuracy of some baselines changes unrelated to the training percentage, which means that their training methods have great limitations in this task and fail to improve the performance of their models by increasing the supervised signal learning process. It also verifies that RioGNN has better explainability and can continuously improve the accuracy of diagnosis through learning more node features. Consistent with its performance under the previous fraud detection task, RioGNN still maintains strong stability and explainability and its accuracy rate surpasses the others at each training ratio.</p><p>RioGNN Variants in Classification. In order to further verify the impact of the proposed new mechanism on different tasks, we compare different performances of several variants of RioGNN under the discrete strategy in the context of diabetes diagnosis. We show the experimental results of diagnosis of diabetes mellitus on the MIMIC-III dataset in <ref type="table" target="#tab_8">Table 8</ref>. First of all, we compare three variants based on different aggregation methods on the MIMIC-III dataset. The results show that RioGNN is better than the other three variants, while RIO-Weight has better results than the other two, which is consistent with the results on Yelp dataset. We find that the choice of aggregation method is usually based on a specific dataset. As for different dataset, different relations have different ways of influencing the results, which lead to different aggregation methods. However, whether it is for Yelp, Amazon or MIMIC-III, the results show that RioGNN is superior to all aggregation variants, while RIO-Weight is second only. This point has a certain degree of universality. Next, we also focus on the performance of the RioGNN variant with two-layer structure, RioGNN 2 . Consistent with the previous results on Yelp and Amazon, the two-layer architecture doesn't bring very good performance improvements to the model on MIMIC-III. Compared with RioGNN, it can be found that the increase in the number of layers does not improve the final accuracy, indicating that the use of a single-layer structure based on the label-aware similarity measure for neighbor selection is optimal. However, in conjunction with <ref type="table" target="#tab_1">Table 2</ref>, it is noted that MIMIC-III dataset is denser than Yelp and Amazon, thus the effect of RioGNN 2 is very close to that of RioGNN. This shows that for denser relations, the second-order neighbors found by RioGNN 2 are more effective in the final result. To some extent, for too dense multi-relation graphs, second-order neighbors can be used as supplementary information for first-order neighbors. Finally, for the Label-aware Similarity Measure section, we observe the variant BIO-GNN without adaptive strategy optimization reinforcement learning algorithm and the single-depth structure variant ROO-GNN without the recursive framework for the RSRL framework again on MIMIC-III. It can be found from <ref type="table" target="#tab_8">Table 8</ref> and <ref type="table" target="#tab_7">Table 7</ref> that ROO-GNN performs significantly better than most baselines and variants, second only to RioGNN. This shows that Bernoulli Multi-armed Bandit (BMAB) algorithm of discrete strategy has strong adaptability in the process of recursively selecting the filtering threshold of relations. In contrast, the accuracy rate of ROO-GNN is 0.28% lower than BIO-GNN. Apart from that, <ref type="figure" target="#fig_26">Figure 10</ref> shows that as the training epoch increases, ROO-GNN fluctuates greatly in the range of 79.48%-81.43%, and can never be stable in a fixed smaller interval as RioGNN or BIO-GNN. That is to say, the multi-depth structure of RioGNN brings better convergence speed and excellent stability than the single-depth variant ROO-GNN while maintaining a higher accuracy rate. RioGNN Variants in Clustering. Similar to fraud detection, we also perform cluster analysis in the task of disease diagnosis. The best results of NMI and ARI within 700 epochs are recorded in <ref type="table" target="#tab_9">Table 9</ref>. It can be seen that compared with BIO-GNN and ROO-GNN, RioGNN brings at least 0.29% and 1.76% increase in NMI and ARI respectively. This proves that the RSRL framework also brings accuracy optimization for dense datasets in the clustering task. In addition, RioGNN has better performance on ARI indicators for variants that use different methods for aggregation. For the NMI indicator, the RIO-Weight effect has been improved. We believe this is because the MIMIC-III dataset has a smaller difference in weight between the relationships compared with Yelp and Amazon. Weight can distinguish different classes better than RioGNN, which directly uses the filtering threshold as the aggregation parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Explainable Reinforcement Learning Training</head><p>Process. This section focuses on the process of reinforcement learning and explains the convergence process of proposed RioGNN on the MIMIC-III dataset. We also present a comparative analysis of different variants to further explain the applicability of RioGNN.</p><p>The Effectiveness and Necessity of the RSRL Framework. This part demonstrates the validity and necessity of the proposed framework by comparing RioGNN with variants and its preliminary version CARE-GNN. It can be seen from the <ref type="figure" target="#fig_26">Figure 10</ref> that RioGNN performs better than CARE-GNN in almost every epoch, which proves that the RSRL framework has a positive effect on the final classification results on MIMIC-III. RioGNN can effectively filter suspected nodes by building a reinforcement learning tree for each relation and identify suspected nodes more accurately. Compared with RioGNN, the accuracy of ROO-GNN in <ref type="figure" target="#fig_25">Figure 9</ref> fluctuates significantly, and it is difficult to converge to a stable range, which proves the necessity to establish a recursive process. Through the RSRL process, the classification accuracy can be maintained in a relatively stable range. The experimental results show that RioGNN with the recursive framework performs better through a more accurate filtering threshold search for each depth. While ROO-GNN without recursion not only fails to converge within a finite number of epochs but also causes a loss of accuracy.</p><p>Filter Thresholds. To further test the proposed model's filtering performance against suspected neighbors, we deliberately extract four denser relations when designing the MIMIC-III dataset. Each relation is at least an order of magnitude higher than the Yelp or Amazon dataset, which means that the MIMIC-III dataset is more challenging for RioGNN's filtering performance. It can be seen from <ref type="figure" target="#fig_25">Figure 9</ref>       RioGNN converge to a stable value within 100 epochs. This indicates that the algorithm can obtain a set of Nash equalization filter thresholds in a very limited epoch through RSRL framework, and thus has good stability and high efficiency.</p><formula xml:id="formula_27">V M V V A V V P V V D V<label>(</label></formula><formula xml:id="formula_28">V M V V A V V P V V D V (b)</formula><formula xml:id="formula_29">V M V V A V V P V V D V</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Versatility Analysis of RSRL Framework</head><p>To better adapt to many task-driven scenarios, we implement a general RSRL reinforcement learning framework. In dealing with datasets of different sizes and types, different reinforcement learning algorithms and action space types can be flexibly matched. The depth and width of the reinforcement learning tree can be adaptively estimated for each relation. Algorithms and Action Space for Different Task Scenarios. In Section 5.1 and Section 5.2, we analyze the function variants ( <ref type="table" target="#tab_5">Table 5 and Table 8</ref>) and the difference between reinforcement learning algorithms under RSRL framework and traditional reinforcement learning <ref type="figure" target="#fig_22">(Figure 8</ref> and <ref type="figure" target="#fig_26">Figure 10</ref>) in terms of accuracy and  efficiency through a classical reinforcement learning algorithm, Actor-Critic. Here, in order to better explore the versatility of RioGNN for different reinforcement learning algorithms and the applicability of different reinforcement learning algorithms for different tasks, in <ref type="table" target="#tab_0">Table 10</ref> we select the current mainstream reinforcement learning algorithms for experiments, and record the best AUC value within 500 epochs. In addition, for the RSRL framework, we proposed two different action spaces for the construction of reinforcement learning forests in Section 3.2.2 to adapt to different task requirements. Different from the discrete action space, the reinforcement learning framework with continuous action space has continuous precision (that is, the highest floating-point number of the processor) in every action selection of reinforcement learning. This difference makes it have a better exploration effect in large-scale dataset. From the experimental results, PD3 algorithm continuous action space and two sets of networks to update the Q value achieves the best results in both Yelp and MIMIC-III dataset.</p><p>In the Amazon dataset, the best result is obtained from the more basic discrete action space AC. SAC and PPO are at a low level in the three datasets. In general, RioGNN is well-adapted to most reinforcement learning algorithms, and is a versatile framework for different types of dataset and task scenarios. Depth and Width for Different Task Scenarios. In Section 3.2.2, we define a depth and width adaptive parameter to adjust the size of the action space of each layer of the relation and the depth of the entire relation tree. In the previous experiment, we fixedly chose 10 as . In this section, in order to discuss the impact of the depth and width adaptive parameter on the accuracy and efficiency of the RioGNN model, we compare and analyze the AUC and convergence epoch sizes of the three dataset under different settings. As shown in <ref type="figure" target="#fig_27">Figure 11</ref>, we set the six values of 2, 4, 8, 10, 16, 20, and respectively record the maximum AUC and the corresponding epoch serial number obtained in 500 epochs. In the Yelp dataset, AUC achieves the maximum value when is 10, which is at least 1.33% better than other parameters. But in this case, it takes longer to reach this value. Therefore, we suggest that Yelp can be adaptively chosen to 8 or 10 for efficiency priority and accuracy priority. On the other hand, Amazon achieves better accuracy when is 8 or 10, and achieves better efficiency when is 2 or 4. The difference from the previous two is that the MIMIC-III dataset obtains a loss of accuracy and efficiency when is 8. Judging from these situations, RioGNN can be adapted to a dataset of different scales and different accuracy and efficiency biases by adjusting . This represents the versatility of the dataset size and task requirements. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Inductive Learning Analysis</head><p>In this section, we perform inductive learning on RioGNN, some representative baselines and variant models of RioGNN. In the previous experiment, we use transductive learning, that is, the graph passed into the model contains the test nodes. In inductive learning, we only pass the adjacency matrix of the nodes that need to be trained into the model, and record the best AUC, Recall and F1 indicators of Yelp and Amazon within 500 epochs and MIMIC-III within 700 epochs. From the results in <ref type="table" target="#tab_0">Table 11</ref>, it can be seen that RioGNN still has obvious advantages compared with GAT and GraphSAGE, where AUC, Recall and F1 increase by 17.34%-28.53%, 2.64%-23.30%, 13.29%-20.90%. In addition, RioGNN has a relatively stable evaluation index among many variants. Among them, the results on Yelp dataset are compared with those with transductive learning in <ref type="table" target="#tab_5">Table 5</ref>. In the inductive learning, the AUC and Recall rate of RioGNN constantly surpasses ROO-GNN variants although RioGNN is slightly lower than ROO-GNN in the transductive learning shown in <ref type="table" target="#tab_0">Table 11</ref>. This represents the stability of the performance of the recursive framework in challenging tasks and illustrates its advantages in small-scale scenarios. In the Amazon dataset, due to the expansion of the data scale, some variants are better evaluated in some aspects, but RioGNN is stable at a relatively high level from the comprehensive situation of AUC, Recall and F1. This situation similarly appears in MIMIC-III. It is worth noting that the BIO-GNN variants in the Amazon and MIMIC-III datasets achieve a good performance improvement compared with their situation in the transductive learning task. We believe this is because BMAB has a relatively weak learning ability compared to Actor-Critic, which reduces the dependence of the learned model on the training set, so it is more compatible with newly added nodes. Overall, RioGNN has good applicability in both transductive learning and inductive learning. <ref type="figure" target="#fig_0">Figure 12</ref> shows the test performance of the three hyper-parameters we introduce in Section 4.4 in three datasets. The first row of <ref type="figure" target="#fig_0">Figure 12</ref> shows the AUC and Recall of the training set of RioGNN at different sampling ratios (note that the test results come from an unbalanced test set). It can be seen that when the sampling ratio is 1 : 0.2, that is, when the negative samples are much smaller than the positive samples, overfitting occurs in all three datasets. Compared with 1 : 0.5 and 1 : 2 sampling ratios, 1 : 1 sampling show higher AUC and Recall indicators in all three datasets. The second row of <ref type="figure" target="#fig_0">Figure 12</ref> studies the backtracking structure we set in Section 3.2.2. From <ref type="figure" target="#fig_0">Figure 12</ref>(d), <ref type="figure" target="#fig_0">Figure 12</ref>(e) and <ref type="figure" target="#fig_0">Figure 12</ref>(f), models with backtracking settings bring stable performance in all datasets compared to models without backtracking. In the third row of <ref type="figure" target="#fig_0">Figure 12</ref>, we test different depth switching conditions. When the deep switching number is set to 3, AUC and Recall achieve good and balanced performance.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Hyper-parameter Sensitivity</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORK</head><p>In the past years, Graph Neural Networks (GNNs) and Reinforcement Learning (RL) technologies have received increasing attention and many upgraded algorithms have been proposed. Hence, the existing literature can be roughly classified into three categories: semi-supervised graph neural networks, RL, and RL-guided GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Semi-supervised Graph Neural Networks</head><p>According to the difference in data modeling for real-world graph data, we roughly divide the semi-supervised graph neural network methods into homogeneous graph neural networks, heterogeneous graph neural networks, and multiple graph learning models.</p><p>Homogeneous Graph Neural Networks. They are usually referred to those GNN methods that do not consider the data type of nodes or the attributes of the edges on the graph. Classical methods include GCN <ref type="bibr" target="#b48">[49]</ref>, Graph-SAGE <ref type="bibr" target="#b31">[32]</ref> and GAT <ref type="bibr" target="#b95">[96]</ref>. As discussed in the previous section, the GCN model defines the first successful graph convolutions in analogy to convolutional layers over Euclidean data, and is thus seen as a generalization of convolution neural networks (CNNs) for non-grid topologies. The Graph-SAGE model exploits sampling for obtaining a fixed number of neighbors for each node to generate node embedding via aggregation functions, which can be invariant if the permutations of node orderings, such as a mean, sum, or max function, are applied. Moreover, the Graph-SAGE model presents the first general inductive learning framework that continuously samples and aggregates its local neighbors' features to generate embedding for the new node. By contrast, the GAT model firstly adopts attention mechanisms to learn the relative weights between two connected nodes. The multi-head self-attention is further enforced to increase the model's expressive capability. Despite the powerful graph representation learning capability of these models, the main limitation is the ignorance of the diversity of data types and relationships manifesting in the real-world data and applications.</p><p>Heterogeneous Graph Neural Networks. Such approaches generally consider the heterogeneity of node types or edge types when aggregating feature information from node's local neighbors via neural networks. The classical meta-path and meta-graph based methods include GAS <ref type="bibr" target="#b52">[53]</ref>, HAN <ref type="bibr" target="#b100">[101]</ref>, Player2Vec <ref type="bibr" target="#b118">[118]</ref>, HSGNN <ref type="bibr" target="#b61">[62]</ref> and MAGNN <ref type="bibr" target="#b21">[22]</ref>. Considering the diversity of edges in real-world data, more relational graph neural network methods including R-GCN <ref type="bibr" target="#b84">[85]</ref>, SemiGNN <ref type="bibr" target="#b97">[98]</ref>, FdGars <ref type="bibr" target="#b98">[99]</ref> and GraphConsis <ref type="bibr" target="#b60">[61]</ref> are developed. Other heterogeneous graph neural networks, including HGT <ref type="bibr" target="#b40">[41]</ref>, GEM <ref type="bibr" target="#b59">[60]</ref>, HetSANN <ref type="bibr" target="#b37">[38]</ref>, etc., implement complex neural aggregations among heterogeneous neighbors. All these heterogeneous models are upgraded versions of the previous homogeneous models. Nevertheless, there is no literature exploring how to select neighbor nodes to build the most expressive, explanatory and stable aggregation.</p><p>Multiple Graph Learning Models. Apart from the above homogeneous and heterogeneous GNNs that solve single-graph representation learning, multi-graph neural network models <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b87">88,</ref><ref type="bibr" target="#b101">102,</ref><ref type="bibr" target="#b117">117]</ref> study fusing the multiple characterizes to comprehensively learn the embedding of graph data objects. MGAT <ref type="bibr" target="#b104">[105]</ref> explores both attention-based architecture for learning node representations from each single view and view-focused attention method to aggregate the view-wise node representations. A multi-view knowledge graph embedding <ref type="bibr" target="#b115">[115]</ref> is presented by using cross-view entity identity inference to capture the alignment information between two knowledge graphs. In order to filter out useless feature interactions, a Bayesian Personalized Feature Interaction Selection mechanism <ref type="bibr" target="#b7">[8]</ref> is designed under the Bayesian Variable Selection (BVS) theory in recommendation tasks. Moreover, a block-diagonal regularization <ref type="bibr" target="#b8">[9]</ref> is proposed to guide the item similarities in the top-N recommendation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Reinforcement Learning</head><p>With the development of technology, reinforcement learning algorithms have derived many different development directions. The more basic algorithms are value-based only Q-Learning <ref type="bibr" target="#b102">[103]</ref> and DQN <ref type="bibr" target="#b68">[69]</ref> algorithms, which use value functions to estimate and reduce the occurrence of local optimal situations. However, policy-based only algorithms such as PPO <ref type="bibr" target="#b85">[86]</ref> directly performs iterative calculation on the policy, which can achieve better convergence. The Actor-Critic type of reinforcement learning methods AC <ref type="bibr" target="#b49">[50]</ref>, DDPG <ref type="bibr" target="#b54">[55]</ref>, TD3 <ref type="bibr" target="#b22">[23]</ref>, and SAC <ref type="bibr" target="#b35">[36]</ref> combine the advantages of value-based and policy-based to train Q functions and strategies at the same time. In addition to the above division methods, from the perspective of action space types, DQN and Q-learning are suitable for discrete action spaces, DDPG, TD3, and SAC support continuous action spaces, while PPO and AC are suitable for both discrete and continuous action spaces. Or from the perspective of learning methods, reinforcement learning algorithms such as DDPG, DQN, SAC, and TD3 combine deep learning and use the fitting ability of neural networks to obtain better optimization. These different algorithms have different advantages, but also bring different limitations. For example, algorithms that only support discrete action spaces are incapable of continuous action space requirements, Actor-Critic type algorithms have inherited the desired shortcomings while absorbing the value-based method and the policy-based method. The framework that only supports the same reinforcement learning algorithm has limitations in adaptability to many types of tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Combination GNNs and RL</head><p>There are a few attempts to marry GNNs and RL. DGN+GNN <ref type="bibr" target="#b1">[2]</ref> is a model used to generalize unseen network topologies, where GNNs that model the network environment allow the DRL agent to operate on different networks. G2S+BERT+RL <ref type="bibr" target="#b10">[11]</ref> is a RL based graph-to-sequence model for natural question generation, where the answer information is utilized by an effective Deep Alignment Network and a novel bidirectional GNN is proposed to process the directed passage graph. Similarly, other work <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b89">90]</ref> investigates how to use GNNs to improve the generalization ability of RL. There are also numerous studies that leverage RL to optimize representation learning on graphs. For example, DeepPath <ref type="bibr" target="#b106">[106]</ref> a knowledge graph embedding and reasoning framework based on RL policy-based; the RL agent is trained to ascertain the reasoning paths in the knowledge base. RL-HGNN <ref type="bibr" target="#b120">[120]</ref> devises different meta-paths for any node in a HIN to learn its effective representations. It models the process of meta-path design as a Markov Decision Process by using a DRL-based policy network for adaptive meta-path selection. As opposed to RioGNN, the RL-HGNN model pays more attention to revealing meaningful meta-paths or relations in heterogeneous graph analysis. GraphNAS <ref type="bibr" target="#b23">[24]</ref> employs a search space covering sampling functions, aggregation functions and gated functions and uses RL to search graph neural architectures. Policy-GNN <ref type="bibr" target="#b50">[51]</ref> formulates the GNN training problem as a Markov Decision Process, and can adaptively learn an aggregation policy to sample diverse iterations of aggregations for different nodes. However, neither GraphNAS nor Policy-GNN models considers heterogeneous neighborhoods in aggregation although they pay more attention to neural architecture searching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE WORK</head><p>This paper studies RioGNN, a reinforced, recursive and flexible neighborhood selection guided multi-relational Graph Neural Network architecture, to learn more discriminative node embedding and respond to the explanation of the importance of different relations in spam review detection and disease diagnosis tasks, respectively. RioGNN designs a label-aware neural similarity neighbor measure and reinforced relation-aware neighbor selectors using reinforcement learning technology, respectively. To optimize the computational efficiency of the reinforcement neighbor selecting, we further design a recursive and scalable framework with estimable depth and width for different scales of multi-relational graphs. The conducted experiments on three real-world benchmark datasets suggest that RioGNN significantly, consistently and steadily outperforms the state-of-the-art alternatives across all the datasets. Our work shows the promise in learning a reinforced neighborhood aggregation for GNNs, potentially opening new avenues for future research in boosting the performance of GNNs with adaptive neighborhood selection and analysing the importance of different relations in message passing.</p><p>In the future, we aim to adopt a multi-agent RL algorithm to further enable the RioGNN to adaptively identify meaningful relations for each node, instead of the manual efforts in defining relations, for automated representation learning on heterogeneous data. In addition, it is also interesting to study how to extend our models to other tasks on graph data analysis and application, such as the personalized recommendation system, social network analysis, and etc. supported by UK EPSRC Grant (EP/T01461X/1) and UK White Rose University Consortium. Philip S. Yu is partially supported by NSF under grants III-1763325, III-1909323, III-2106758, and SaTC-1930941.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Graph Modeling in Disease Diagnosis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>RioGNN architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>((Fig. 4 .</head><label>4</label><figDesc>Maximum number of neighbors: 10 !% , D=1) (Maximum number of neighbors: 10 &amp;" , D=2) Maximum number of neighbors: 547, D=3) (Maximum number of neighbors: 84, D=2) One layer Reinforcement Learning Forest.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>16 L 17 L 29 (</head><label>161729</label><figDesc>Training process of the proposed RioGNN 5 for = 1, ? ? ? , do 6 for = 1, ? ? ? , do 7 for = 1, ? ? ? , do 8 L ( ) Simi ? Eq. (4) // Cross entropy loss of label-aware similarity measure 9 for = 1, ? ? ? , do 10 ( ) ( , ? ) ? Eq. (3) , ?( , ? ) ? E ( ?1) ; 11 // Edge set under relation r at the l-th layer 12 E ( ) ? top-p sampling (Section 3.2.1); 13 h ( ) , ? Eq. (13) ? ? V // Intra-relation aggregator 14 h ( ) ? Eq. (14) ? ? V ; // Inter-relation aggregator 15 z ? h ( ) , ? ? V ; // Batch node embeddings GNN ? Eq. (15); // Cross-entropy loss function of GNN RioGNN ? Eq. (16); // Final loss function of RioGNN 18 // RSRL Module: Markov Decision Process for filtering threshold 19 for = 1, ? ? ? , do 20 for = 1, ? ? ? , do 21 if ( ) &lt; ( ) then 22 // Judgement of the termination condition 23 if Eq. (12) is False then 24 ( ) ( ) ( ) , ( ) ( ) ( ?1) ? Eq. (8) and Eq. (9) // Calculate state and reward 25 ( ) ( ) ( ) ? Eq. (10); // Update RL iterative function 26 // the recursive process of optimal proportion of neighbor nodes 27 ( ) ( ) ( ) ? Eq. (11), ( ) ( ) ? { ( ) ( ?1) = ( ) + 1;// Update the depth of Reinforcement Learning Tree ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>? Q4: How do different task requirements match the universal RSRL framework (Section 5.3)? ? Q5: How does our model perform in clustering tasks and inductive learning (Section 5.2.1, Section 5.1.1 and Section 5.4)? ? Q6: Discussion of hyper-parameter sensitivity and effects on the model (Section 5.5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>4. 3 . 1</head><label>31</label><figDesc>Baselines. To verify the effectiveness of RioGNN in mitigating mutual interference between similar tasks and the model, we compare it with traditional and latest GNN baselines under semi-supervised learning settings. For all baseline models, we use the open-source implementations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Scores of RioGNN on Yelp.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Thresholds of RioGNN on Yelp.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Scores of RioGNN on Amazon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Thresholds of RioGNN on Amazon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 5 .</head><label>5</label><figDesc>The training scores and thresholds of RioGNN on Yelp and Amazon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Scores of ROO-GNN on Yelp.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Thresholds of ROO-GNN on Yelp.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Scores of BIO-GNN on Yelp.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>Thresholds of BIO-GNN on Yelp.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 6 .</head><label>6</label><figDesc>The training scores and thresholds of RioGNN variants on Yelp.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 6 (</head><label>6</label><figDesc>d), we also observe that different models are used under the same dataset, and they converge and combine with different filtering thresholds [0.99, 0.093, 0.787], [0.89, 0.001, 0.978], [0.34, 0.17, 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 7 .</head><label>7</label><figDesc>Scores of Multi-Layer RioGNN on Yelp.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>(a) AUC of Rio-GNN, BIO-GNN and ROO-GNN on Yelp. (b) AUC of RioGNN and RioGNN on Amazon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 8 .</head><label>8</label><figDesc>The impact of recursive framework on computational efficiency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>(b) and Figure 9(d) that the filtering</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>(d) Thresholds of BIO-GNN on MIMIC-III.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Fig. 9 .</head><label>9</label><figDesc>The training scores and thresholds of RioGNN vs BIO-GNN on MIMIC-III. thresholds of the four relations of RioGNN on the MIMIC-III dataset are stable at [0.88, 0.96, 0.32, 0.26], while BIO-GNN are stable at [0.35, 0.37, 0.36, 0.37]. Considering that the label similarity and feature similarity of different relations are different, the model's filtering strength for different relations is not the same. It is worth noting that there is a certain commonality between the relation filtering strength on RioGNN and BIO-GNN. Under RioGNN, the convergence thresholds of V-A-V and V-M-V are relatively similar, while V-P-V and V-D-V are relatively similar. Generally speaking, relations with high filtering thresholds can bring more positive guidance to the diagnosis result and are more explainable. From another perspective, a higher filtering threshold can prove the explainability and correctness of the selected relation, which is more conducive to us intuitively judging whether the choice of the relation is appropriate enough. It is clear from Figure 9 that these four relations of 0 25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 400 425 450 AUC of RioGNN,ROO-GNN and BIO-GNN on MIMIC-III.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Fig. 10 .</head><label>10</label><figDesc>The effectiveness and necessity of the RSRL framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Fig. 11 .</head><label>11</label><figDesc>Depth and Width for Different Task Scenarios.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Fig. 12 .</head><label>12</label><figDesc>Parameter sensitivity of under-sampling ratio, with &amp; without backtracking, deep switching number on Yelp, Amazon and MIMIC-III.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .Relational Disease Diagnosis GraphRelational Disease Diagnosis Graph Heterogeneous Disease Diagnosis Graph !</head><label>1</label><figDesc>Notations. The distance between node and ? at the -th layer RL state for relation at the -th layer in -th depth when the epoch is</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Symbol Definition</cell></row><row><cell cols="4">G; V; E; X Graph; Node set; Edge set; Node feature set</cell></row><row><cell></cell><cell></cell><cell></cell><cell>;</cell><cell>Label for node ; Node label set</cell></row><row><cell></cell><cell></cell><cell></cell><cell>;</cell><cell>Relation; Total number of relations</cell></row><row><cell></cell><cell></cell><cell></cell><cell>;</cell><cell>GNN layer number; Total number of layers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>;</cell><cell>Training batch number; Total number of batches</cell></row><row><cell></cell><cell></cell><cell></cell><cell>;</cell><cell>Training epoch number; Total number of epochs</cell></row><row><cell cols="2">V</cell><cell cols="2">; V</cell><cell>Nodes in the training set; Node set at batch</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell>( )</cell><cell>Edge set under relation at the -th layer</cell></row><row><cell></cell><cell></cell><cell>h</cell><cell>( )</cell><cell>The embedding of node at the -th layer</cell></row><row><cell></cell><cell></cell><cell>h</cell><cell>( ) ,</cell><cell>The embedding of node under relation at the -th layer</cell></row><row><cell cols="4">D ( ) ( , ? ) ( )</cell><cell>The depth of Reinforcement Learning Tree for relation at the -th layer</cell></row><row><cell></cell><cell></cell><cell cols="2">( ) ?</cell><cell>RL action space;</cell></row><row><cell>(D</cell><cell cols="3">( ) ( ) ) ( ) ( ) ( ) ( )</cell><cell>RL reward for relation at the -th layer in -th depth when the epoch is</cell></row><row><cell></cell><cell></cell><cell cols="2">( ) ( ) ( )</cell><cell>RL iterative function for relation at the -th layer in -th depth when the epoch is</cell></row><row><cell></cell><cell></cell><cell cols="2">N ( ) Nodeset after RL filtering for relation at the -th layer</cell></row><row><cell></cell><cell></cell><cell>AGG</cell><cell>( )</cell><cell>Intra-relation aggregator for relation at the -th layer</cell></row><row><cell></cell><cell></cell><cell>AGG</cell><cell>( )</cell><cell>Inter-relation aggregator at the -th layer</cell></row><row><cell></cell><cell></cell><cell></cell><cell>z</cell><cell>Final embedding for node</cell></row></table><note>( ) ( , ? ) The similarity between node and ? at the -th layer ( ) ? The filtering threshold for relation at the -th layer( ) The Reinforcement Learning Forest at the -th layer( ) The Reinforcement Learning Tree for relation at the -th layer( ) ( ) The Reinforcement Learning Module for relation at the -th layer in -th depth( ) (?) The width of Reinforcement Learning Tree for relation at the -th layer in -th depthFig. 1. Graph Modeling in Fraud Review Detection.(a) An MR-Graph for diabetes and disease detection.! (b) An example of heterogeneous Electronic Health Records (EHR) graph, reproduced from [62].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Dataset and graph statistics. Fraud Detection Task. We perform binary classification tasks, spam review detection and fraudulent user detection on the Yelp dataset and Amazon dataset, respectively.</figDesc><table><row><cell>Dataset</cell><cell>#Nodes (Fraud% / Diabetes%)</cell><cell>Relation</cell><cell>#Edges</cell><cell cols="2">Avg. Feature Avg. Label Similarity Similarity</cell></row><row><cell></cell><cell></cell><cell>R-U-R</cell><cell>49,315</cell><cell>0.83</cell><cell>0.90</cell></row><row><cell>Yelp</cell><cell>45,954 (14.5%)</cell><cell>R-T-R R-S-R</cell><cell>573,616 3,402,743</cell><cell>0.79 0.77</cell><cell>0.05 0.05</cell></row><row><cell></cell><cell></cell><cell>ALL</cell><cell>3,846,979</cell><cell>0.77</cell><cell>0.07</cell></row><row><cell></cell><cell></cell><cell>U-P-U</cell><cell>175,608</cell><cell>0.61</cell><cell>0.19</cell></row><row><cell>Amazon</cell><cell>11,944 (9.5%)</cell><cell>U-S-U U-V-U</cell><cell>3,566,479 1,036,737</cell><cell>0.64 0.71</cell><cell>0.04 0.03</cell></row><row><cell></cell><cell></cell><cell>ALL</cell><cell>4,398,392</cell><cell>0.65</cell><cell>0.05</cell></row><row><cell></cell><cell></cell><cell cols="2">V-A-V 152,901,492</cell><cell>0.62</cell><cell>0.54</cell></row><row><cell></cell><cell>28,522</cell><cell>V-D-V</cell><cell>19,183,922</cell><cell>0.63</cell><cell>0.54</cell></row><row><cell>MIMIC-III</cell><cell>(49.9%)</cell><cell cols="2">V-P-V 149,757,030</cell><cell>0.63</cell><cell>0.54</cell></row><row><cell></cell><cell></cell><cell>V-M-V</cell><cell>15,794,101</cell><cell>0.65</cell><cell>0.51</cell></row><row><cell></cell><cell></cell><cell>ALL</cell><cell>337,636,545</cell><cell>0.63</cell><cell>0.53</cell></row><row><cell>4.2.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Comparison of main functions of different variants.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>GCN 54.98 50.94 53.15 52.47 53.12 51.10 53.87 50.81 74.44 75.25 75.13 74.34 65.54 67.81 66.15 67.45 GAT 56.23 55.45 57.69 56.24 54.68 52.34 53.20 54.52 73.89 74.55 72.10 72.16 63.22 65.84 67.13 65.51 GraphSAGE 53.82 54.20 56.12 54.00 54.25 52.23 52.69 52.86 70.71 73.97 73.97 75.27 69.09 69.36 70.30 70.16 RGCN 50.21 55.12 55.05 53.38 50.38 51.75 50.92 50.43 75.12 74.13 75.58 74.68 64.23 67.22 65.08 67.68 GeniePath 56.33 56.29 57.32 55.91 52.33 54.35 54.84 50.94 71.56 72.23 71.89 72.65 65.56 66.63 65.08 65.41 Player2Vec 51.03 50.15 51.56 53.65 50.00 50.00 50.00 50.00 76.86 75.73 74.55 56.94 50.00 50.00 50.00 50.00 SemiGNN 53.73 51.68 51.55 51.58 52.28 52.57 52.16 50.59 70.25 76.21 73.98 70.35 63.29 63.32 61.28 62.89 GraphConsis 61.58 62.07 62.31 62.07 62.60 62.08 62.35 62.08 85.46 85.29 85.50 85.50 85.49 85.38 85.59 85.53 GAS 54.43 52.58 52.51 52.60 53.40 53.26 53.37 51.61 71.40 77.49 74.51 71.03 64.31 64.57 62.08 63.74 FdGars 61.77 62.15 62.81 62.66 62.83 62.16 62.73 62.40 85.58 85.41 85.88 85.81 85.83 85.73 85.84 85.93 GraphNAS 52.93 54.69 56.73 54.46 52.40 54.15 55.69 56.16 71.01 72.48 73.52 76.05 69.17 69.48 70.35 70.16 GraphNAS 53.26 55.31 57.15 55.59 53.69 55.47 56.04 57.00 72.41 73.04 73.58 76.25 70.36 70.53 71.73 71.88 Policy-GNN 54.04 55.73 59.30 60.60 53.08 55.35 58.75 59.99 72.20 73.30 74.11 77.20 70.10 71.20 73.08 74.44 Policy-GNN 55.75 56.29 60.01 61.52 54.15 56.16 58.95 60.33 73.69 74.06 75.29 78.85 71.34 72.46 74.55 76.70 CARE-GNN 71.26 73.31 74.45 75.70 67.53 67.77 68.60 71.92 89.54 89.44 89.45 89.73 88.34 88.29 88.27 88.48 RioGNN 81.97 83.72 82.31 83.54 75.33 75.78 75.51 76.19 95.44 95.41 95.63 96.19 90.17 89.48 89.51 89.82</figDesc><table><row><cell>Yelp</cell></row><row><cell>Models</cell></row></table><note>Fraud Detection results (%) compared to the baselines.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Fraud Detection classification results (%) compared to RioGNN variants.</figDesc><table><row><cell>Models</cell><cell>AUC</cell><cell>Yelp</cell><cell>Recall</cell><cell cols="2">Amazon AUC Recall</cell></row><row><cell>RioGNN 2</cell><cell>76.01</cell><cell></cell><cell>63.15</cell><cell>91.28</cell><cell>72.46</cell></row><row><cell>BIO-GNN</cell><cell>78.67</cell><cell></cell><cell>71.21</cell><cell>95.47</cell><cell>88.35</cell></row><row><cell>ROO-GNN</cell><cell>83.59</cell><cell></cell><cell>75.56</cell><cell>95.58</cell><cell>89.22</cell></row><row><cell>RIO-Att</cell><cell>78.65</cell><cell></cell><cell>71.69</cell><cell>93.97</cell><cell>83.78</cell></row><row><cell>RIO-Weight</cell><cell>80.40</cell><cell></cell><cell>72.83</cell><cell>96.25</cell><cell>89.61</cell></row><row><cell>RIO-Mean</cell><cell>77.84</cell><cell></cell><cell>71.43</cell><cell>94.57</cell><cell>89.47</cell></row><row><cell>RioGNN</cell><cell>83.54</cell><cell></cell><cell>75.55</cell><cell>96.19</cell><cell>88.66</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Fraud detection clustering results (%) compared to RioGNN variants.Dataset Metric RioGNN 2 BIO-GNN ROO-GNN RIO-Att RIO-Weight RIO-Mean RioGNN</figDesc><table><row><cell>Yelp</cell><cell>NMI ARI</cell><cell>3.18 6.12</cell><cell>9.36 11.84</cell><cell>12.39 16.61</cell><cell>9.80 11.88</cell><cell>12.05 15.88</cell><cell>8.39 8.80</cell><cell>12.22 16.45</cell></row><row><cell>Amazon</cell><cell>NMI ARI</cell><cell>58.87 76.53</cell><cell>59.83 77.38</cell><cell>57.81 76.09</cell><cell>55.76 76.54</cell><cell>58.76 76.73</cell><cell>58.72 76.51</cell><cell>61.26 78.40</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 .</head><label>7</label><figDesc>Diabetes Detection results (%) compared to the baselines.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 .</head><label>8</label><figDesc>Diabetes diagnosis classification results (%) compared to RioGNN variants.</figDesc><table><row><cell>Models</cell><cell>MIMIC-III AUC</cell><cell>Recall</cell></row><row><cell>RioGNN 2</cell><cell>81.06</cell><cell>72.28</cell></row><row><cell>BIO-GNN</cell><cell>81.29</cell><cell>72.75</cell></row><row><cell>ROO-GNN</cell><cell>81.01</cell><cell>72.34</cell></row><row><cell>RIO-Att</cell><cell>80.96</cell><cell>72.16</cell></row><row><cell>RIO-Weight</cell><cell>81.04</cell><cell>72.58</cell></row><row><cell>RIO-Mean</cell><cell>80.31</cell><cell>77.42</cell></row><row><cell>RioGNN</cell><cell>81.36</cell><cell>72.84</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 .</head><label>9</label><figDesc>Diabetes diagnosis clustering results (%) compared to RioGNN variants.</figDesc><table><row><cell>Dataset</cell><cell cols="8">Metric RioGNN 2 BIO-GNN ROO-GNN RIO-Att RIO-Weight RIO-Mean RioGNN</cell></row><row><cell>MIMIC-III</cell><cell>NMI ARI</cell><cell>19.01 7.15</cell><cell>19.81 8.27</cell><cell>19.13 8.11</cell><cell>17.17 6.24</cell><cell>20.22 9.01</cell><cell>19.86 7.51</cell><cell>20.10 10.03</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>Thresholds of RioGNN on MIMIC-III.</figDesc><table><row><cell>Scores</cell><cell>0.08 0.10 0.12 0.16 0.14</cell><cell></cell><cell></cell><cell></cell><cell>stable at 0.153 stable at 0.144 stable at 0.142 stable at 0.139</cell><cell>Thresholds</cell><cell>0.40 0.34 0.36 0.38</cell><cell></cell><cell></cell><cell>stable threshold=0.35 stable threshold=0.36 stable threshold=0.37 stable threshold=0.37</cell></row><row><cell></cell><cell>0.04 0.06</cell><cell></cell><cell></cell><cell></cell><cell>V M V V D V V P V V A V</cell><cell></cell><cell>0.30 0.32</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>25</cell><cell>50</cell><cell>75</cell><cell>100 125 150 175 200 Epoch</cell><cell></cell><cell>0</cell><cell>25</cell><cell>50</cell><cell>75</cell><cell>100 125 150 175 200 Epoch</cell></row><row><cell></cell><cell></cell><cell cols="4">(c) Scores of BIO-GNN on MIMIC-III.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 .</head><label>10</label><figDesc>Results (%) compared to different RL algorithms and strengthening strategies.</figDesc><table><row><cell></cell><cell>Methods</cell><cell>Yelp</cell><cell>Amazon</cell><cell>MIMIC-III</cell></row><row><cell>Discrete</cell><cell>AC [50] DQN [69] PPO [86]</cell><cell>83.54 84.08 80.52</cell><cell>96.19 95.13 94.99</cell><cell>81.36 80.96 80.98</cell></row><row><cell>Continuous</cell><cell>AC [50] DDPG [55] SAC [31] TD3 [23]</cell><cell>81.31 83.80 80.42 84.18</cell><cell>94.72 95.39 94.76 95.11</cell><cell>80.98 81.17 80.87 81.51</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 .</head><label>11</label><figDesc>Inductive learning results (%) compared to RioGNN variants.</figDesc><table><row><cell>Models</cell><cell cols="2">Yelp AUC Recall</cell><cell>F1</cell><cell cols="2">Amazon AUC Recall</cell><cell>F1</cell><cell cols="2">MIMIC-III AUC Recall</cell><cell>F1</cell></row><row><cell>GAT</cell><cell>55.94</cell><cell>51.79</cell><cell>47.25</cell><cell>72.33</cell><cell>65.86</cell><cell>60.17</cell><cell>63.89</cell><cell>59.13</cell><cell>56.78</cell></row><row><cell cols="2">GraphSAGE 53.85</cell><cell>51.78</cell><cell>44.36</cell><cell>74.91</cell><cell>70.02</cell><cell>65.32</cell><cell>63.89</cell><cell>69.99</cell><cell>59.24</cell></row><row><cell>RioGNN 2</cell><cell>79.45</cell><cell>71.86</cell><cell>63.58</cell><cell>92.01</cell><cell>83.65</cell><cell>86.24</cell><cell>79.01</cell><cell>69.77</cell><cell>69.64</cell></row><row><cell>BIO-GNN</cell><cell>79.49</cell><cell>71.86</cell><cell>63.58</cell><cell>95.07</cell><cell>88.19</cell><cell>86.51</cell><cell>81.21</cell><cell>72.81</cell><cell>72.64</cell></row><row><cell>ROO-GNN</cell><cell>82.15</cell><cell>74.23</cell><cell>67.73</cell><cell>94.79</cell><cell>87.43</cell><cell>88.67</cell><cell>81.01</cell><cell>72.39</cell><cell>72.23</cell></row><row><cell>RIO-Att</cell><cell>78.72</cell><cell>71.78</cell><cell>62.38</cell><cell>93.79</cell><cell>88.71</cell><cell>83.72</cell><cell>79.84</cell><cell>71.31</cell><cell>71.28</cell></row><row><cell cols="2">RIO-Weight 81.06</cell><cell>72.79</cell><cell>65.59</cell><cell>94.67</cell><cell>88.58</cell><cell>85.12</cell><cell>81.25</cell><cell>72.72</cell><cell>72.28</cell></row><row><cell>RIO-Mean</cell><cell>78.17</cell><cell>71.41</cell><cell>62.12</cell><cell>93.53</cell><cell>87.32</cell><cell>85.75</cell><cell>80.29</cell><cell>71.92</cell><cell>71.74</cell></row><row><cell>RioGNN</cell><cell>82.38</cell><cell>75.08</cell><cell>65.26</cell><cell>94.03</cell><cell>88.58</cell><cell>86.46</cell><cell>81.23</cell><cell>72.63</cell><cell>72.53</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021. Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks ? 39:7</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021.Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks ? 39:9</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021. Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks ? 39:11</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021.Reinforced Neighborhood Selection Guided Multi-Relational Graph NeuralNetworks ? 39:13</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021. Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks ? 39:19</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021. Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks ? 39:21</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021.Reinforced Neighborhood Selection Guided Multi-Relational Graph NeuralNetworks ? 39:23</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021. Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks ? 39:25</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021. Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks ? 39:27</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021. Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks ? 39:31</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021. Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks ? 39:37</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021. Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks ? 39:39</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Transactions on Information Systems, Vol. 1, No. 1, Article 39. Publication date: October 2021. Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks ? 39:41</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGMENT The authors of this paper are supported by NSFC through grants 62002007 and U20B2053, S&amp;T Program of Hebei through grant 20310101D, Fundamental Research Funds for the Central Universities. Renyu Yang is partially</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fraud detection system: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aisha</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anazida</forename><surname>Mohd Aizaini Maarof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zainal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="90" to="113" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning meets graph neural networks: Exploring a routing optimization use case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Almasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jos?</forename><surname>Su?rez-Varela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnau</forename><surname>Badia-Sampera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Rusek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pere</forename><surname>Barlet-Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Cabellos-Aparicio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.07421</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unveiling the predictive power of static structure in glassy systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Keck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Grabska-Barwi?ska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Donner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annette</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Obika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Demis</forename><surname>Back</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="448" to="454" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">HitFraud: a broad learning approach for collective fraud detection in heterogeneous information networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bokai</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mia</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siim</forename><surname>Viidu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE ICDM</title>
		<meeting>the IEEE ICDM</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="769" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Knowledge-Preserving Incremental Social Event Detection via Heterogeneous GNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3383" to="3395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-information Source HIN for Medical Concept Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the PAKDD</title>
		<meeting>the PAKDD</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="396" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Label-Aware Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiran</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zengde</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Senzhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CIKM</title>
		<meeting>the CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bayesian Personalized Feature Interaction Selection for Factorization Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGIR</title>
		<meeting>ACM SIGIR</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="665" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Block-Aware Item Similarity Models for Top-N Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Article. 26 pages</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.07832</idno>
		<title level="m">Deep iterative and adaptive learning for graph neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICLR</title>
		<meeting>the ICLR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cluster-GCN: An efficient algorithm for training deep and large graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lin</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGKDD</title>
		<meeting>the SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="257" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning the graphical structure of electronic health records with graph convolutional transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Dusenberry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerardo</forename><surname>Flores</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI</title>
		<meeting>the AAAI</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="606" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A review of recent advance in online spam detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Enhancing graph neural network-based fraud detectors against camouflaged fraudsters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM CIKM</title>
		<meeting>the ACM CIKM</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="315" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Robust Spammer Detection by Nash Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guixiang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sihong</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGKDD</title>
		<meeting>the SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="924" to="933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Dulac-Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Hado Van Hasselt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Sunehag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theophane</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Degris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Coppin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.07679</idno>
		<title level="m">Deep Reinforcement Learning in Large Discrete Action Spaces</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dougal</forename><surname>David K Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al?n</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan P</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS</title>
		<meeting>the NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2224" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Graph neural networks for social recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference</title>
		<meeting>the Web Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="417" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Survey of machine learning algorithms for disease diagnostic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meherwar</forename><surname>Fatima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maruf</forename><surname>Pasha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Learning Systems and Applications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Reinforcement learning for relation classification from noisy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the aaai conference on artificial intelligence</title>
		<meeting>the aaai conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiani</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiao</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the WWW</title>
		<meeting>the WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2331" to="2341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Addressing Function Approximation Error in Actor-Critic Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Fujimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Herke Van Hoof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meger</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning (Proceedings of Machine Learning Research</title>
		<meeting>the 35th International Conference on Machine Learning ( Machine Learning Research<address><addrLine>Stockholmsm?ssan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="1587" to="1596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09981</idno>
		<title level="m">Graphnas: Graph neural architecture search with reinforcement learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICML. PMLR</title>
		<meeting>the ICML. PMLR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A N</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hausdorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Mietus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PhysioBank, PhysioToolkit, and PhysioNet: components of a new research resource for complex physiologic signals</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page">215</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Attentional graph convolutional networks for knowledge concept recommendation in moocs in a heterogeneous view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jibing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGIR</title>
		<meeting>the ACM SIGIR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="79" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Yangqing Jia, and Kaiming He. 2017. Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Finding overlapping communities in networks by label propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Gregory</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New journal of Physics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">103018</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Attention based spatial-temporal graph convolutional networks for traffic flow forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI</title>
		<meeting>the AAAI</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="922" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuomas</forename><surname>Haarnoja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurick</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Hartikainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sehoon</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikash</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.05905</idno>
		<title level="m">Soft actor-critic algorithms and applications</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Pre-Training Graph Neural Networks for Cold-Start Users and Items Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongzhi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuiping</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the WSDM</title>
		<meeting>the WSDM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="265" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Graph Neural Networks and Reinforcement Learning for Behavior Generation in Semantic Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alois</forename><surname>Knoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Vehicles Symposium (IV). IEEE</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1589" to="1594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning with double Q-Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Hado Van Hasselt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI</title>
		<meeting>the AAAI</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2094" to="2100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">HeteSpaceyWalk: a heterogeneous spacey random walk for heterogeneous information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CIKM</title>
		<meeting>the CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Hawk: Rapid android malware detection through heterogeneous graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Hei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An attention-based graph neural network for heterogeneous structural learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiting</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hantao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yucheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieping</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI</title>
		<meeting>the AAAI</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4132" to="4139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Heteromed: Heterogeneous information network for medical diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anahita</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Majid</forename><surname>Sarrafzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CIKM</title>
		<meeting>the CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="763" to="772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multiagent Reinforcement Learning: Theoretical Framework and an Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junling</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth International Conference on Machine Learning (ICML &apos;98)</title>
		<meeting>the Fifteenth International Conference on Machine Learning (ICML &apos;98)<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="242" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Heterogeneous graph transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziniu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the WWW</title>
		<meeting>the WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2704" to="2710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jarom?r</forename><surname>Janisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom??</forename><surname>Pevn?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viliam</forename><surname>Lis?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.12462</idno>
		<title level="m">Symbolic Relational Deep Reinforcement Learning based on Graph Neural Networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Graph convolutional networks meet markov random fields: Semi-supervised community detection in attribute networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxiao</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixiong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI</title>
		<meeting>the AAAI</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="152" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Alistair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H Lehman</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengling</forename><surname>Li-Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><forename type="middle">Anthony</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger G</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alistair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengling</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><forename type="middle">Anthony</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger G</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mark</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>n.d.. Scientific Data ([n. d.</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Combating crowdsourced review manipulators: A neighborhood-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kaghazgaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caverlee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Squicciarini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the WSDM</title>
		<meeting>the WSDM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="306" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Action Space Shaping in Deep Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anssi</forename><surname>Kanervisto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Scheller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ville</forename><surname>Hautam?ki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE Conference on Games (CoG)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="479" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Simple embedding for link prediction in knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Seyed Mehran Kazemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS</title>
		<meeting>the NIPS</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4284" to="4295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICLR</title>
		<meeting>the ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Actor-critic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vijay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">N</forename><surname>Konda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS</title>
		<meeting>the NIPS</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1008" to="1014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Policy-GNN: Aggregation Optimization for Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwei-Herng</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daochen</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaixiong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD</title>
		<meeting>the ACM SIGKDD<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="461" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">GCN-GAN: A non-linear temporal link prediction model for weighted dynamic networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE INFOCOM</title>
		<meeting>the IEEE INFOCOM</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="388" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Spam review detection with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runshi</forename><surname>Zhou Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2703" to="2711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Adaptive Graph Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI</title>
		<meeting>the AAAI</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3546" to="3553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">J</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Tassa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.02971</idno>
		<title level="m">Continuous control with deep reinforcement learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>cs.LG</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Neural similarity learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Rehg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS</title>
		<meeting>the NIPS</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5025" to="5036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Advanced modularity-specialized label propagation algorithm for detecting communities in networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsuyoshi</forename><surname>Murata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<biblScope unit="volume">389</biblScope>
			<biblScope unit="page" from="1493" to="1500" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="6418" to="6425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Qi</surname></persName>
		</author>
		<title level="m">GeniePath: Graph Neural Networks with Adaptive Receptive Paths. Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019-07" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4424" to="4431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Heterogeneous graph neural networks for malicious account detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2077" to="2085" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Alleviating the Inconsistency Problem of Applying Graph Neural Network to Fraud Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGIR</title>
		<meeting>the SIGIR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1569" to="1572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Heterogeneous Similarity Graph Neural Network on Electronic Health Records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BigData</title>
		<meeting>the BigData</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">AgentGraph: Toward Universal Dialogue Management With Structured Deep Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tan</forename><surname>Bowen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Sishan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ga?i?</forename><surname>Milica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Kai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech, and Language Processing</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1378" to="1391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Population Analysis of Adverse Events in Different Age Groups Using Big Clinical Trials Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Eldredge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><forename type="middle">C</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><forename type="middle">A</forename><surname>Cisler</surname></persName>
		</author>
		<idno type="DOI">10.2196/medinform.6437</idno>
		<ptr target="https://doi.org/10.2196/medinform.6437" />
	</analytic>
	<monogr>
		<title level="j">JMIR Med Inform</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2016-10-17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Multi-view clustering with graph embedding for connectome analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guixiang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Ta</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixiang</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">D</forename><surname>Leow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><forename type="middle">B</forename><surname>Ragin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Drug similarity integration through attentive multi-view graph auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3477" to="3483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">From Amateurs to Connoisseurs: Modeling the Evolution of User Expertise through Online Reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian John Mcauley</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on World Wide Web</title>
		<meeting>the 22nd International Conference on World Wide Web<address><addrLine>Rio de Janeiro, Brazil; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="897" to="908" />
		</imprint>
	</monogr>
	<note>&apos;13)</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Discovering meta-paths in large heterogeneous information networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changping</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reynold</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silviu</forename><surname>Maniu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangda</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the WWW</title>
		<meeting>the WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="754" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">K</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">What Yelp Fake Review Filter Might Be Doing?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><surname>Glance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International AAAI Conference on Web and Social Media</title>
		<meeting>the International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Nathani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jatin</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charu</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Kaul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL. ACL</title>
		<meeting>the ACL. ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4710" to="4723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Adversarially regularized graph autoencoder for graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Shirui Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IJCAI</title>
		<meeting>the IJCAI</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2609" to="2615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Federated Knowledge Graphs Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM CIKM</title>
		<meeting>the ACM CIKM</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Senzhang Wang, and Lifang He. 2020. Motif-Matching Based Subgraph-Level Attentional Convolutional Network for Graph Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiran</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanxin</forename><surname>Ning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="5387" to="5394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Fine-grained event categorization with heterogeneous graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiran</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanxing</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunfeng</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IJCAI</title>
		<meeting>the IJCAI</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3238" to="3245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Large-scale hierarchical text classification with recursively regularized deep graph-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaopeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjiao</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the WWW</title>
		<meeting>the WWW</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1063" to="1072" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Streaming Social Event Detection and Evolution Discovery in Heterogeneous Information Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjan</forename><surname>Rajiv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Lifang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Hierarchical taxonomy-aware and attentional graph capsule RCNNs for large-scale multi-label text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Senzhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiran</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2505" to="2519" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Lifelong Property Price Prediction: A Case Study for the Toronto Real Estate Market</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Spatial temporal incidence dynamic graph neural networks for traffic flow forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md</forename><surname>Zakirul Alam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Bhuiyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Senzhang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="277" to="290" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Lime: Low-cost incremental learning for dynamic heterogeneous information networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Zomaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><surname>Ranjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Finding Multiple Nash Equilibria in Pool-Based Markets: A Stochastic EPEC Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pozo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Contreras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Power Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1744" to="1752" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Exploiting Cross-session Information for Session-based Recommendation with Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongzhi</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Collective opinion spam detection: Bridging review networks and metadata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shebuti</forename><surname>Rayana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGKDD</title>
		<meeting>the SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="985" to="994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ESWC</title>
		<meeting>the ESWC</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">A survey of heterogeneous information network analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yitong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="17" to="37" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Predicting citywide crowd flows in irregular regions using multi-view graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junkai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaofei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiuwen</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.10528</idno>
		<title level="m">Adversarial Attack and Defense on Graph Data: A Survey</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Combining deep reinforcement learning with graph neural networks for optimal VNF placement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Penghao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehua</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Letters</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="176" to="180" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Pairwise Learning for Name Disambiguation in Large-Scale Heterogeneous Academic Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Senzhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangxuan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE ICDM</title>
		<meeting>the IEEE ICDM</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="511" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">SUGAR: Subgraph Neural Network with Reinforcement Pooling and Self-Supervised Mutual Information Mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanxing</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference</title>
		<meeting>the Web Conference</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2081" to="2091" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Opinion spam detection based on heterogeneous information network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingcheng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Loparo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE ICTAI</title>
		<meeting>the IEEE ICTAI</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1156" to="1163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">An introduction to ROC analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fawcett</forename><surname>Tom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Graph attention networks. Proceedings of the ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Graphmix: Regularized training of graph neural networks for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11715</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">A Semi-supervised Graph Attentive Network for Financial Fraud Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanhui</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanming</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE ICDM</title>
		<meeting>the IEEE ICDM</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="598" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Fdgars: Fraudster detection via graph convolutional networks in online app review system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Xion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the World Wide Web Conference</title>
		<meeting>the World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="310" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.14867</idno>
		<title level="m">2020. A Survey on Heterogeneous Graph Embedding: Methods, Techniques, Applications and Sources</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Heterogeneous graph attention network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houye</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference</title>
		<meeting>the Web Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2022" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Survey on Deep Multi-Modal Data Analytics: Collaboration, Rivalry, and Fusion. ACM Transactions on Multimedia Computing, Communications, and Applications 17, 1s</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
	<note>25 pages</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Q-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jch</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="279" to="292" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S. Yu</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Mgat: Multi-view graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanqiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maoguo</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zedong</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page" from="180" to="189" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks</title>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">45</biblScope>
			<date type="published" when="2021-10" />
		</imprint>
	</monogr>
	<note>Publication date</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thien</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP. ACL</title>
		<meeting>the EMNLP. ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="564" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">How Powerful are Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICLR</title>
		<meeting>the ICLR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Meta-graph based hin spectral embedding: Methods, analyses, and insights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE ICDM</title>
		<meeting>the IEEE ICDM</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="657" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">KGSynNet: A Novel Entity Synonyms Discovery Framework with Knowledge Graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiying</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiqin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjian</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaijie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunfeng</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of DASFAA</title>
		<meeting>DASFAA<address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="174" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Unsupervised Anomaly Detection via Deep Metric Learning with End-to-End Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Selim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kozat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.05865</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Hierarchical graph representation learning with differentiable pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS</title>
		<meeting>the NIPS</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4800" to="4810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename><surname>Lingfei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J. Zaki</forename><surname>Mohammed</surname></persName>
		</author>
		<title level="m">Deep Iterative and Adaptive Learning for Graph Neural Networks. AAAI Workshops</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Heterogeneous graph neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongjin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananthram</forename><surname>Swami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitesh V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGKDD</title>
		<meeting>the SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="793" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Link prediction based on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS</title>
		<meeting>the NIPS</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5165" to="5175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Multi-view Knowledge Graph Embedding for Entity Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingbing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IJCAI</title>
		<meeting>the IJCAI</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5429" to="5435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">GCN-Based User Representation Learning for Unifying Robust Recommendation and Fraudster Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongzhi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Quoc Viet Nguyen Hung, Zi Huang, and Lizhen Cui. 2020</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="page" from="689" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Multi-view graph convolutional network and its applications on neuroimage analysis for parkinson&apos;s disease</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA Annual Symposium Proceedings</title>
		<imprint>
			<date type="published" when="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Key Player Identification in Underground Forums over Attributed Heterogeneous Information Network Embedding Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujie</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CIKM</title>
		<meeting>the CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="549" to="558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Smoke screener or straight shooter: Detecting elite sybil attacks in user-review social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NDSS</title>
		<meeting>the NDSS</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Te</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.13735</idno>
		<title level="m">Reinforcement Learning Enhanced Heterogeneous Graph Neural Network</title>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Relation structure-aware heterogeneous graph neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shichao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingquan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE ICDM</title>
		<meeting>the IEEE ICDM</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1534" to="1539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<title level="m" type="main">Learning from labeled and unlabeled data with label propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Predicting multicellular function through multi-layer tissue networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="190" to="198" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
