<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EmoBERTa: Speaker-Aware Emotion Recognition in Conversation with RoBERTa</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taewoon</forename><surname>Kim</surname></persName>
							<email>t.kim@vu.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Vrije Universiteit Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piek</forename><surname>Vossen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vrije Universiteit Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">EmoBERTa: Speaker-Aware Emotion Recognition in Conversation with RoBERTa</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present EmoBERTa: Speaker-Aware Emotion Recognition in Conversation with RoBERTa, a simple yet expressive scheme of solving the ERC (emotion recognition in conversation) task. By simply prepending speaker names to utterances and inserting separation tokens between the utterances in a dialogue, EmoBERTa can learn intra-and inter-speaker states and context to predict the emotion of a current speaker, in an end-to-end manner. Our experiments show that we reach a new state of the art on the two popular ERC datasets using a basic and straight-forward approach.</p><p>We've open sourced our code and models at https://github.com/tae898/erc.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The scope of emotion recognition is very wide, ranging from stills of face images, audio data to the actual utterances or text as in tweets. In this paper, we focus on emotion recognition in conversation (ERC), which is a subfield of emotion recognition. More specifically, the task is to predict the emotion of a current speaker who's engaging in a conversation with one person or more. Recognizing emotion is important to areas such as affective computing and human-robot communication, in which it can be an important feedback mechanism.</p><p>As humans use multiple sensory inputs to have a conversation (e.g., vision, voice, etc.) the ERC task can also include multiple modalities <ref type="bibr">(e.g., visual, audio, text, etc.)</ref>. Here, we report on our first experiments on the text modality, leaving using multiple modalities within our framework to future work.</p><p>Since the introduction of the Transformer <ref type="bibr" target="#b25">(Vaswani et al., 2017)</ref>, transformer-based deep neural network models have become the dominating neural network model in sequence modeling. Especially, pretrained encoder-only models such as BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref> and RoBERTa <ref type="bibr" target="#b15">(Liu et al., 2019)</ref> have shown that they can be success-fully fine-tuned for downstream tasks, such as sentence classification and question answering. ERC can be seen as a special case of sequence modeling, since emotions are expected to be triggered by a preceding event in any modality.</p><p>Our approach to ERC enriches such transformer models by including the speaker identity in the sequence information spanning multiple utterances. By adapting the RoBERTa sequence representation, we improve the SOTA on two popular benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Most of the existing works on ERC combine different kinds of neural network architectures (e.g., CNNs, RNNs, Transformers, GNNs, etc.) <ref type="bibr" target="#b13">(Li et al., 2020b)</ref>, <ref type="bibr" target="#b14">(Li et al., 2020c)</ref>, <ref type="bibr" target="#b8">(Ishiwatari et al., 2020)</ref>, , <ref type="bibr" target="#b7">(Hazarika et al., 2021)</ref>, <ref type="bibr" target="#b24">(Sheng et al., 2020)</ref>, <ref type="bibr" target="#b4">(Ghosal et al., 2020)</ref>, <ref type="bibr" target="#b5">(Ghosal et al., 2019)</ref>. The biggest downside of such approaches is that each part of the model is responsible for extracting their own features. These extracted features might not be ideal for the other parts of the model. Also, since these models are combinations of sub-models, it is hard to understand what each sub-model is contributing and how to improve the overall model. Some of the approaches try to take advantage of external knowledge bases <ref type="bibr" target="#b4">(Ghosal et al., 2020)</ref>, <ref type="bibr" target="#b29">(Zhong et al., 2019a)</ref>, which adds even more complexity to the model.</p><p>A substantial number of approaches are heavily based on RNNs (e.g., GRU) to model the sequence <ref type="bibr" target="#b9">(Jiao et al., 2019)</ref>, <ref type="bibr" target="#b17">(Lu et al., 2020)</ref>. The biggest problem with this is that it inherently decouples the word embedding extraction and the sequence modeling, whereas BERT-like models tackle them at once, often leading to a better performance. Also, they have to rely on external decontextualized word embedding extractors (e.g., GloVe <ref type="bibr" target="#b20">(Pennington et al., 2014)</ref> or word2vec <ref type="bibr" target="#b19">(Mikolov et al., 2013)</ref>). Furthermore, training an RNN is very inefficient since "backpropagation through time" has to wait until the last input of a sequence has been processed.</p><p>The approaches that are most closely related to us are HiTrans <ref type="bibr" target="#b12">(Li et al., 2020a)</ref> and DialogXL . HiTrans packs multiple utterances with [CLS] tokens prepended into one input sequence. This sequence is first fed into a BERT and then to another transformer. DialogXL is based on XLNet <ref type="bibr" target="#b28">(Yang et al., 2019)</ref>. Our approach differs in that we just use RoBERTa and encode the speaker information with multiple utterances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>Let's say a dialogue of M utterances is given and I interlocutors are engaging in a conversation. Then the dialogue can be expressed as a list of vectors:</p><formula xml:id="formula_0">dialogue = [x 1 , x 2 , ..., x M ],</formula><p>where an utterance x t contains several words (tokens). Each utterance x t is spoken by a unique speaker ? I. Since this is a supervised setup, every utterance x t has one corresponding label y t that is annotated by a human.</p><p>The simplest way to solve this problem is to come up with a function f that takes x t as an input and outputs the correct label y t . However, this doesn't take context into account. It's easily conceivable that the function f should also consider the past utterances [x 1 , x 2 , ..., x t?1 ] or even the future utterances [x t+1 , x t+2 , ..., x M ] to model the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">EmoBERTa</head><p>EmoBERTa starts from the pretrained roberta-large model <ref type="bibr" target="#b15">(Liu et al., 2019)</ref>. Since the task is basically a sequence classification task, we simply add a randomly initialized linear layer with the softmax nonlinearity to the first hidden state (this state corresponds to the [CLS] token) of the last layer of the pretrained model.</p><p>We chose RoBERTa, among the many BERTlike models, because its structure is not only relatively simple, but also it can deal with more than two segments. The original authors of RoBERTa simply used two &lt;/s&gt; tokens consecutively as [SEP] token, which separates the first and the second segments. Although the pretrained model has not been trained on more than two segments, we show that EmoBERTa can be generalized to three segments per input sequence.</p><p>The first, second, and third segments contain the past utterances, the current utterance, and the future utterances, respectively, in a dialogue. Each utterance is prepended with the name of a speaker so that the model is aware which utterance is spoken by whom. The task is to predict the emotion of the current utterance.</p><p>RoBERTa uses &lt;s&gt; and &lt;/s&gt; as [CLS] and [EOS] tokens, respectively. Building an input sequence for EmoBERTa is outlined in Algorithm 1. Example sequences can be found in <ref type="figure" target="#fig_1">Figure 1</ref>.</p><p>Algorithm 1: Building an input sequence 1 Given the current utterance</p><formula xml:id="formula_1">x t ? {x 1 , x 2 , ..., x M }; max_tokens = 512 ? 2; sequence = [SEP ] + tokenize(x t ) + [SEP ]; i = 1; while len(sequence) &lt;= max_tokens do Prepend speaker(x t?i ) + " : " + x t?i to sequence; Append speaker(x t+i ) + " : " + x t+i to sequence; i = i + 1; end Remove the last appended / prepended utterances; sequence = [CLS] + sequence + [EOS];</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>The loss is calculated as the sum of cross entropy loss and L 2 weight decay <ref type="bibr" target="#b11">(Krogh and Hertz, 1991)</ref>. We use adaptive gradient descent <ref type="bibr" target="#b10">(Kingma and Ba, 2015)</ref>, <ref type="bibr" target="#b16">(Loshchilov and Hutter, 2019)</ref> with gradual linear warmup learning rate scheduling <ref type="bibr" target="#b6">(Goyal et al., 2017)</ref>. The peak learning rate was determined using Optuna <ref type="bibr" target="#b0">(Akiba et al., 2019)</ref>. Mixed floating point precision was used to reduce the training time and increase the batch size <ref type="bibr" target="#b18">(Micikevicius et al., 2017)</ref>. See Appendix A.1 for the details (e.g., hyperparameters, training time, hardware, etc.). We mostly used the huggingface transformer pytorch library for training <ref type="bibr" target="#b27">(Wolf et al., 2020)</ref>.</p><p>Then the training loss function is</p><formula xml:id="formula_2">L(w) = ? 1 N N i=1 C?1 c=0 y (i) c log(? (i) c ) + ? 2 w 2 2</formula><p>(1) where y (i) , is a one-hot label vector,? (i) is the softmax output vector given the input x <ref type="bibr">(i)</ref> , N is the number of training data samples, C is the number of classes, ? is a L 2 regularization rate, and w are the weights of the model. In practice, the data samples are batched, and stochastic gradient descent is used.</p><p>Although the weights w were tuned to minimize the loss value, the final model is chosen where the weighted f 1 score on the validation split is the highest, since that's the metric that we report. We test EmoBERTa on the two popular ERC datasets. MELD ) is a multimodal (visual, audio, and text) and multi-party (more than two interlocutors in a dialogue) conversational dataset. It was collected from the TV series Friends. The seven emotions are neutral, joy, surprise, anger, sadness, disgust, and fear. Weighted f 1 score is used to evaluate the performance, as the class distribution is highly imbalanced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Evaluation Metrics</head><p>IEMOCAP <ref type="bibr">(Busso et al., 2008</ref>) is a multimodal (visual, audio, and text) and dyadic (only two interlocutors in a dialogue) conversational dataset. Ten actors participated in the data collection. Although the original dataset contains 11 different emotions, only six of them are used for evaluation. They are neutral, frustration, sadness, anger, excited, and happiness. As MELD, the class distribution is highly imbalanced and thus a weighted f 1 score will be used for evaluation. Unlike MELD, IEMOCAP does not officially have the names of the speakers. Therefore, we gave each actor a random name. See Appendix A.2 for the details.</p><p>Some statistics on train, val, and test splits of both datasets can be found at <ref type="table" target="#tab_0">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>We compare our model with the models we mentioned in Section 2. <ref type="table" target="#tab_2">Table 2</ref> shows the performance of our models and the baselines. Our models outperform the other models on both MELD and IEMOCAP. <ref type="bibr">Model</ref> MELD IEMOCAP BERT+MTL <ref type="bibr" target="#b13">(Li et al., 2020b)</ref> 61.90 -BiERU-lc <ref type="bibr" target="#b14">(Li et al., 2020c)</ref> 60.84 64.65 DialogueGCN <ref type="bibr" target="#b5">(Ghosal et al., 2019)</ref> 58.1 64.18 RGAT <ref type="bibr" target="#b8">(Ishiwatari et al., 2020)</ref> 60.91 65.22 CESTa  58.36 67.1 VHRED <ref type="bibr" target="#b7">(Hazarika et al., 2021)</ref> -58.6 SumAggGIN <ref type="bibr" target="#b24">(Sheng et al., 2020)</ref> 58.45 66.61 COSMIC <ref type="bibr" target="#b4">(Ghosal et al., 2020)</ref> 65.21 65.28 KET <ref type="bibr" target="#b30">(Zhong et al., 2019b)</ref> 58.18 59.56 BiF-AGRU <ref type="bibr" target="#b9">(Jiao et al., 2019)</ref> 58.1 63.5 Iterative <ref type="bibr" target="#b17">(Lu et al., 2020)</ref> 60.72 64.37 HiTrans <ref type="bibr" target="#b12">(Li et al., 2020a)</ref> 61.94 64.5 DialogXL  62  EmoBERTa shows very good results: max weighted f 1 scores (%) of 65.61 (MELD) and 68.57 (IEMOCAP) respectively and above the best reported SOTA, especially considering that no modifications were made to the original RoBERTa model architecture. We also trained a model without the speaker names prepended, which drops the performance: weighted f 1 scores (%) of 65.07 (MELD) and 64.02 (IEMOCAP) respectively, pro-viding evidence that encoding the speaker information helps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Quantitative Analysis</head><p>Especially on IEMOCAP dataset, although we had to come up with random names for the actors, EmoBERTa was able to learn what's important. As for IEMOCAP, the results were better using only past utterances, rather than using both past and future utterances. We believe that this is due to the fact that IEMOCAP has many more utterances than MELD, and thus we couldn't fit all the past and future utterances in one sequence, meaning that only using past utterances can fit more past utterances than aiming for both. Past utterances were apparently more useful than future utterances to predict the emotion of a current utterance.</p><p>There was a bigger performance gain by incorporating past and/or future utterances in IEMOCAP than <ref type="bibr">MELD (12.48 vs. 2.15)</ref>. We believe that this is due to the fact that the nature of IEMOCAP is more contextual than that of MELD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Qualitative Analysis</head><p>To get more insight in the value of encoding the speaker, we did a qualitative analysis on 10 correctly and 10 incorrectly classified random samples from each test split.</p><p>Our manual inspection shows that the model tries to learn the dynamics of the interlocutors in the beginning layer, as the current speaker tokens attend to the interlocutor tokens (We observed this behavior from all the 20 MELD and 20 IEMOCAP random test samples). As for MELD, in all 100% of the correctly classified samples, based on the top 10 attended tokens, the &lt;s&gt; token of the last layer attended to the speaker token of the target (current) utterance, whereas this ratio was only 60% for the incorrectly classified samples. This verifies that the current speaker token increasingly contains important information, as the tokens move on to the higher layers. <ref type="figure" target="#fig_1">Figure 1</ref> shows a visualization of one correctly and one incorrectly classified random samples.</p><p>As the &lt;s&gt; token in the last layer focuses on the current speaker and his/her utterance, we believe that this information is what the model finds most useful to make the final prediction.</p><p>Note that in the incorrectly classified example, the &lt;s&gt; token in the last layer does not focus on the current speaker but some random punctuation marks throughout the conversation, thus leading to an incorrect prediction.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we showed that our new model, EmoBERTa, outperforms other models in the ERC task. Since EmoBERTa can directly attend to the input tokens and interlocutor names, we can easily observe the attention coefficients to see which part of the dialogue the model finds most important to make a final classification. and Science through the Netherlands Organisation for Scientific Research, https://hybrid-intelligencecentre.nl. <ref type="figure">Figure 2</ref>: Two examples from the 20 randomly selected test samples are shown. The current speaker utterance, of which the emotion that the model has to predict, is in bold. The green highlighted tokens are the top 10 most attended tokens to the current speaker (i.e., WILLIAM and ELIZABETH, for <ref type="figure">Figure 2a</ref> and 2b, respectively.) in the beginning layer of the model. The yellow highlighted tokens are the top 10 most attended tokens to the [CLS] token (i.e. &lt;s&gt;) in the last layer. Unlike <ref type="figure" target="#fig_1">Figure 1</ref>, there is only one [SEP] token (i.e., &lt;/s&gt;&lt;/s&gt;), since this model only has two segments, past and current. Best viewed when zoomed in We see a similar behavior as in MELD. Again, in the incorrectly classified example, the &lt;s&gt; in the last layer does not attend to the current speaker.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>See Appendix A.3 for the random IEMOCAP test samples.&lt;s&gt;PHOEBE: I think she took it pretty well. You know Paolo's over there right now, so... ROSS: Ah...ooh! Well, looks like, uh, we kicked your butts. JOEY: No-no, she kicked our butts. You could be on the Olympic standing-there team. ROSS: Come on, two on one. CHANDLER: What are you still doing here? She just broke up with the guy, it's time for you to swoop in! ROSS: What, now? JOEY: Yes, now is when you swoop!&lt;/s&gt;&lt;/s&gt;JOEY: You gotta make sure that when Paolo walks out of there, the first guy Rachel sees is you, She's gotta know that you're everything he's not!&lt;/s&gt;&lt;/s&gt;JOEY: You're like, like the anti-Paolo! CHANDLER: My Catholic friend is right. CHANDLER: She's distraught. CHANDLER: You're there for her. CHANDLER: You pick up the pieces, and then you usher in the age of Ross!&lt;/s&gt; &lt;s&gt;PHOEBE: I think she took it pretty well. You know Paolo's over there right now, so... ROSS: Ah...ooh! Well, looks like, uh, we kicked your butts. JOEY: No-no, she kicked our butts. You could be on the Olympic standing-there team. ROSS: Come on, two on one. CHANDLER: What are you still doing here? She just broke up with the guy, it's time for you to swoop in! ROSS: What, now? JOEY: Yes, now is when you swoop!&lt;/s&gt;&lt;/s&gt;JOEY: You gotta make sure that when Paolo walks out of there, the first guy Rachel sees is you, She's gotta know that you're everything he's not!&lt;/s&gt;&lt;/s&gt;JOEY: You're like, like the anti-Paolo! CHANDLER: My Catholic friend is right. CHANDLER: She's distraught. CHANDLER: You're there for her. CHANDLER: You pick up the pieces, and then you usher in the age of Ross!&lt;/s&gt; (a) A correctly classified example. Both the prediction and the truth are joy.&lt;s&gt;CHANDLER: And you're upset because you didn't make your best friend cry? MONICA: I mean, all I'm asking for is just a little emotion! MONICA: Is that too much to ask after six years?! MONICA: I mean what? MONICA: Are-are-are Rachel and I not as close as you guys?! MONICA: I mean do we not have as much fun?! MONICA: Don't I deserve a few tears?!! MONICA: I mean we-we told Joey, he cried his eyes out!&lt;/s&gt;&lt;/s&gt;JOEY: Hey!&lt;/s&gt;&lt;/s&gt;JOEY: I did not cry my eyes out!! JOEY: Come on! JOEY: It's like the end of an era! JOEY: No more J-man and Channie's! CHANDLER: Okay, I gotta ask, who calls us that?!&lt;/s&gt; &lt;s&gt;CHANDLER: And you're upset because you didn't make your best friend cry? MONICA: I mean, all I'm asking for is just a little emotion! MONICA: Is that too much to ask after six years?! MONICA: I mean what? MONICA: Are-are-are Rachel and I not as close as you guys?! MONICA: I mean do we not have as much fun?! MONICA: Don't I deserve a few tears?!! MONICA: I mean we-we told Joey, he cried his eyes out!&lt;/s&gt;&lt;/s&gt;JOEY: Hey!&lt;/s&gt;&lt;/s&gt;JOEY: I did not cry my eyes out!! JOEY: Come on! JOEY: It's like the end of an era! JOEY: No more J-man and Channie's! CHANDLER: Okay, I gotta ask, who calls us that?!&lt;/s&gt; (b) An incorrectly classified example. The prediction is joy while the truth is anger.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Two examples from the 20 randomly selected test samples are shown. The current speaker utterance, of which the emotion that the model has to predict, is in bold. The green highlighted tokens are the top 10 most attended tokens to the current speaker (i.e., JOEY) in the beginning layer of the model. The yellow highlighted tokens are the top 10 most attended tokens to the [CLS] token (i.e., &lt;s&gt;) in the last layer. 3 . Best viewed when zoomed in.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The upper half of the table shows the number of dialogues and utterances of the datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="3">number of dialogues (utterances) train val test</cell></row><row><cell>MELD</cell><cell cols="2">1,038 (9,989) 114 (1,109)</cell><cell>280 (2,610)</cell></row><row><cell>IEMOCAP</cell><cell>100 (4,778)</cell><cell>20 (980)</cell><cell>31 (1,622)</cell></row><row><cell>Dataset</cell><cell cols="3">mean number of utterances per dialogue (std.) train val test</cell></row><row><cell>MELD</cell><cell>9.6 (5.8)</cell><cell>9.7 (5.4)</cell><cell>9.3 (5.7)</cell></row><row><cell cols="3">IEMOCAP 47.78 (16.47) 49.0 (17.44)</cell><cell>52.32 (17.36)</cell></row></table><note>2 . The bottom half shows the mean and the standard deviation of the number of utterances per dialogue. As shown, IEMOCAP has about 5 times more utterances per dia- logue than MELD.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>All of the reported values are weighted f 1 (%) score on the test splits. The best model and the best performance values are in bold. Since the values are stochastic in nature, we report the mean values of five random seeds.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The pretrained RoBERTa model can have a maximum of 512 tokens in one input sequence. The while loop terminates if there are no more available past / future utterances to add in the dialogue. We empirically found that capitalizing the names of the interlocutors leads to slightly better results.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The IEMOCAP dataset does not officially have train, val, and test splits. Therefore, we follow the splits used by<ref type="bibr" target="#b30">(Zhong et al., 2019b)</ref>, as these splits are widely used.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Since there are 16 attention heads used per layer in RoBERTa, the visualized weight coefficients are the mean values of them. Since RoBERTa uses a BPE tokenizer<ref type="bibr" target="#b22">(Sennrich et al., 2016)</ref>, the speaker names (e.g., JOEY) are often separated into more than one token (e.g., JO and EY). Therefore, we highlight the full names, even though only some parts of them are highlighted.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was (partially) funded by the Hybrid Intelligence Center, a 10-year programme funded by the Dutch Ministry of Education, Culture</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Training Details</head><p>We used GCP (Google Cloud Platform) Compute Engine to carry out our experiments. We used an NVIDIA Tesla V100 machine (disclaimer: we are supported by neither Google nor NVIDIA). This GPU has 16 GB of memory and depending on the length of the input sequence, we were able to fit 4 to 16 samples in one batch, using mixed precision. The pretrained roberta-large model has about 355 million parameters. We found that without mixed precision, it's very difficult to train this model, since it's a pretty big model.</p><p>We set the value of L 2 regularization rate as 0.01. Training was done for five epochs. No weights were frozen during the training. The learning rate scheduler was set to linearly increase in the first 20% of training and then linearly decrease in the remaining 80%.</p><p>Since the optimal peak learning rate highly depends on the batch size and the other hyperparameters, we used Optuna <ref type="bibr" target="#b0">(Akiba et al., 2019)</ref> to find its best value. 10% of the training data and the same amount of validation data were used to search for the best value. Optuna ran five trials and looked for the best learning rate, between 1e ? 6 and 1e ? 4, that minimizes the cross entropy loss on the validation data split.</p><p>The hyperparameters not mentioned here are all set to the default values.</p><p>One full five-epoch training took about 45 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 IEMOCAP Speaker Names</head><p>Since the IEMOCAP dataset was created in the US, we used the top five male and female American names over the past 100 years (https://www.ssa.gov/oact/ babynames/decades/century.html).</p><p>The female names used are Mary, Patricia, Jennifer, Linda, and Elizabeth. The male names used are James, John, Robert, Michael, and William.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Qualitative Analysis on IEMOCAP</head><p>Unlike MELD, only 20% of the correctly classified samples showed the behavior of the last layer &lt;s&gt; token attending to the current target speaker. This ratio was 10% for the incorrectly classified samples. We believe this is due to the fact that the speaker names in the test split of IEMOCAP (i.e., WILLIAM and ELIZABETH) were never seen during training.) <ref type="figure">Figure 2</ref> gives you a visualization of the qualitative analysis on the IEMOCAP dataset.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optuna: A next-generation hyperparameter optimization framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Akiba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shotaro</forename><surname>Sano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihiko</forename><surname>Yanase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 25rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Busso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bulut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Chun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ebrahim</forename><surname>Kazemzadeh</surname></persName>
		</author>
		<editor>Emily Mower Provost, S. Kim, J. N</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Iemocap: interactive emotional dyadic motion capture database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrikanth</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="335" to="359" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">COSMIC: COmmonSense knowledge for eMotion identification in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepanway</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.224</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2470" to="2481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Dialoguegcn: A graph convolutional neural network for emotion recognition in conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepanway</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niyati</forename><surname>Chhaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">F</forename><surname>Gelbukh</surname></persName>
		</author>
		<idno>abs/1908.11540</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Accurate, large minibatch SGD: training imagenet in 1 hour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<idno>abs/1706.02677</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note>Yangqing Jia, and Kaiming He</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Conversational transfer learning for emotion recognition. Information Fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.inffus.2020.06.005</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Relation-aware graph attention networks with relational position encodings for emotion recognition in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taichi</forename><surname>Ishiwatari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuki</forename><surname>Yasuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taro</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Goto</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.597</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7360" to="7370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Real-time emotion recognition via attention gated hierarchical memory network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxiang</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
		<idno>abs/1911.09075</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simple weight decay can improve generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">A</forename><surname>Hertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Neural Information Processing Systems, NIPS&apos;91</title>
		<meeting>the 4th International Conference on Neural Information Processing Systems, NIPS&apos;91<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="950" to="957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">HiTrans: A transformer-based context-and speaker-sensitive model for emotion detection in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijiang</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-main.370</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4190" to="4200" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-task learning with auxiliary speaker identification for conversational emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijiang</forename><surname>Liu</surname></persName>
		</author>
		<idno>abs/2003.01478</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bieru: Bidirectional emotional recurrent unit for conversational sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoxiong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<idno>abs/2006.00492</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>arxiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
	<note type="report_type">OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An iterative emotion interaction network for emotion recognition in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijian</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-main.360</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4078" to="4088" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paulius</forename><surname>Micikevicius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonah</forename><surname>Alben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">F</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Garc?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Mixed precision training. CoRR, abs/1710.03740</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Neural Information Processing Systems</title>
		<meeting>the 26th International Conference on Neural Information Processing Systems<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">MELD: A multimodal multi-party dataset for emotion recognition in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautam</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1050</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Dialogxl: All-in-one xlnet for multiparty conversation emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhou</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixian</forename><surname>Xie</surname></persName>
		</author>
		<idno>abs/2012.08695</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Summarize before aggregate: A global-to-local heterogeneous graph inference network for conversational emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongming</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhuang</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-main.367</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4153" to="4163" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Contextualized emotion recognition in conversation as sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="186" to="195" />
		</imprint>
	</monogr>
	<note>1st virtual meeting. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teven</forename><forename type="middle">Le</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Drame</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Quentin Lhoest, and Alexander Rush</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno>abs/1906.08237</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Knowledge-enriched transformer for emotion detection in textual conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peixiang</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Miao</surname></persName>
		</author>
		<idno>abs/1909.10681</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">WILLIAM: Oh, okay, yeah. ELIZABETH: So you know like late dinner and champagne and what not. WILLIAM: Were you in Chicago? ELIZABETH: Mm-hmm. WILLIAM: Downtown, was it beautiful? of course it was beautiful ELIZABETH: so beautiful, full moon. WILLIAM: What a guy. I can&apos;t believe it. So okay, so do you know any details? When&apos;s it going to be? Anything? ELIZABETH: I don&apos;t know. I guess next summer. WILLIAM: Am I in it? ELIZABETH: Yeah. Yeah, of course. WILLIAM: Okay, I certainly hope so, of course. ELIZABETH: So next fall I guess. WILLIAM: Next fall. ELIZABETH: Yeah, I like the autumn. WILLIAM: Are you going to do it in town or are you out of town? ELIZABETH: oh, We&apos;ll do it in town</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peixiang</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Miao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1016</idno>
	</analytic>
	<monogr>
		<title level="m">Spontaneous is awesome. ELIZABETH: It was really beautiful. WILLIAM: You&apos;ve got to love that. ELIZABETH: Yeah, we went to a really great jazz show, and um-WILLIAM: Nice, you love the jazz</title>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="165" to="176" />
		</imprint>
		<respStmt>
			<orgName>WILLIAM: Oh, okay. ELIZABETH: Yeah</orgName>
		</respStmt>
	</monogr>
	<note>WILLIAM: Okay, I certainly hope so, of course. ELIZABETH: So next fall I guess. WILLIAM: Next fall. ELIZABETH: Yeah, I like the autumn. WILLIAM: Are you going to do it in town or are you out of town? ELIZABETH: oh, We&apos;ll do it in town. WILLIAM: Oh, okay. ELIZABETH: Yeah, his family doesn&apos;t live too far away, so I think-WILLIAM: Yeah, where&apos;s he from again? ELIZABETH: He&apos;s from Chicago as well. WILLIAM: Oh he is, okay. ELIZABETH: Yeah.&lt;/s&gt;&lt;/s&gt;WILLIAM: Cool, perfect. Another Chicagoite, got to love it.&lt;/s&gt; &lt;s&gt;WILLIAM: Okay. That&apos;s okay, spontaneous is great. his family doesn&apos;t live too far away, so I think-WILLIAM: Yeah, where&apos;s he from again? ELIZABETH: He&apos;s from Chicago as well. WILLIAM: Oh he is, okay. ELIZABETH: Yeah.&lt;/s&gt;&lt;/s&gt;WILLIAM: Cool, perfect. Another Chicagoite, got to love it.&lt;/s&gt;</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Um-And you went through all your proper checkpoints? ELIZABETH: Yeah, I don&apos;t know where it was lost. I was coming from Africa, so. WILLIAM: So you haven&apos;t seen your bags since Africa. You flew threw Heath Row to here. ELIZABETH: Right. ELIZABETH: Yeah. WILLIAM: Okay. Well, let me see here. I-WILLIAM: It seems like it went through Heath Row. I see it here. uh-ELIZABETH: That&apos;s good. WILLIAM: But uh-I don&apos;t see it here in the airport yet. uh WILLIAM: I&apos;m not sure where it is. We can absolutely keep an eye out for for it for you. ELIZABETH: Well, I can&apos;t leave without it. I mean, Could you find out? WILLIAM: Well, I&apos;m not a miracle worker. I don&apos;t know what I can do for you. I don&apos;t have the bag right here. ELIZABETH: Right, well can you get on the computer maybe and like track it down and see when it&apos;s going to get here? WILLIAM: Well, as I told you, it left Heath Row and it seems to have arrived here. But if you can&apos;t find it, thenare you sure you know what your bag looks like? ELIZABETH: Yes, sir, I know what my bag looks like. WILLIAM: Okay, and what is that? What kind of bag is it? ELIZABETH: Um-It&apos;s a travel backpack</title>
	</analytic>
	<monogr>
		<title level="m">&lt;s&gt;WILLIAM: Okay, what flight were you on? ELIZABETH: Um-Seventeen. Coming from --WILLIAM: On what airline? ELIZABETH: It was Virgin Atlantic coming from London. WILLIAM: From London, okay. Um-And you went through all your proper checkpoints? ELIZABETH: Yeah, I don&apos;t know where it was lost. I was coming from Africa, so. WILLIAM: So you haven&apos;t seen your bags since Africa</title>
		<editor>ELIZABETH: Right. ELIZABETH: Yeah. WILLIAM: Okay</editor>
		<meeting><address><addrLine>London, okay</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>ELIZABETH: Well, I can&apos;t leave without it. I mean, Could you find out? WILLIAM: Well, I&apos;m not a miracle worker. I don&apos;t know what I can do for you. I don&apos;t have the bag right here. ELIZABETH: Right, well can you get on the computer maybe and like track it down and see when it&apos;s going to get here? WILLIAM: Well, as I told you, it left Heath Row and it seems to have arrived here. It&apos;s green and gray. It&apos;s got my name on it and my information. WILLIAM: And you couldn&apos;t find it?&lt;/s&gt;&lt;/s&gt;ELIZABETH: No, it didn&apos;t turn up at the baggage claim.&lt;/s&gt; (b) An incorrectly classified example. The prediction is neutral while the truth is frustration</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
