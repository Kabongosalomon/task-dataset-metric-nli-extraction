<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abduallah</forename><surname>Mohamed</surname></persName>
							<email>abduallah.mohamed@utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyao</forename><surname>Zhu</surname></persName>
							<email>deyao.zhu@kaust.edu.sa</email>
							<affiliation key="aff1">
								<orgName type="institution">KAUST</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Warren</forename><surname>Vu</surname></persName>
							<email>warren.vu@utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elhoseiny</surname></persName>
							<email>mohamed.elhoseiny@kaust.edu.sa</email>
							<affiliation key="aff1">
								<orgName type="institution">KAUST</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Equal advising</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Claudel</surname></persName>
							<email>christian.claudel@utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Equal advising</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Motion Prediction</term>
					<term>Motion Forecasting</term>
					<term>Deep Graph CNNs</term>
					<term>Evaluation</term>
					<term>Trajectory Forecasting</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Best-of-N (BoN) Average Displacement Error (ADE)/ Final Displacement Error (FDE) is the most used metric for evaluating trajectory prediction models. Yet, the BoN does not quantify the whole generated samples, resulting in an incomplete view of the model's prediction quality and performance. We propose a new metric, Average Mahalanobis Distance (AMD) to tackle this issue. AMD is a metric that quantifies how close the whole generated samples are to the ground truth. We also introduce the Average Maximum Eigenvalue (AMV) metric that quantifies the overall spread of the predictions. Our metrics are validated empirically by showing that the ADE/FDE is not sensitive to distribution shifts, giving a biased sense of accuracy, unlike the AMD/AMV metrics. We introduce the usage of Implicit Maximum Likelihood Estimation (IMLE) as a replacement for traditional generative models to train our model, Social-Implicit. IMLE training mechanism aligns with AMD/AMV objective of predicting trajectories that are close to the ground truth with a tight spread. Social-Implicit is a memory efficient deep model with only 5.8K parameters that runs in real time of about 580Hz and achieves competitive results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract. Best-of-N (BoN) Average Displacement Error (ADE)/ Final Displacement Error (FDE) is the most used metric for evaluating trajectory prediction models. Yet, the BoN does not quantify the whole generated samples, resulting in an incomplete view of the model's prediction quality and performance. We propose a new metric, Average Mahalanobis Distance (AMD) to tackle this issue. AMD is a metric that quantifies how close the whole generated samples are to the ground truth. We also introduce the Average Maximum Eigenvalue (AMV) metric that quantifies the overall spread of the predictions. Our metrics are validated empirically by showing that the ADE/FDE is not sensitive to distribution shifts, giving a biased sense of accuracy, unlike the AMD/AMV metrics. We introduce the usage of Implicit Maximum Likelihood Estimation (IMLE) as a replacement for traditional generative models to train our model, Social-Implicit. IMLE training mechanism aligns with AMD/AMV objective of predicting trajectories that are close to the ground truth with a tight spread. Social-Implicit is a memory efficient deep model with only 5.8K parameters that runs in real time of about 580Hz and achieves competitive results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Trajectory prediction is an essential component for multiple applications, such as autonomous driving <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b33">34]</ref>, augmented reality <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b39">40]</ref>, and robotics <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b2">3]</ref>. Typically, solving this problem requires a generative model to predict the future agent's trajectories. Though there are plenty of deep models and design architectures that tackle this problem, the evaluation method used is being questioned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Observed trajectory</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predictions close to ground truth</head><p>Predictions far from ground truth Ground truth</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sensitivity Test</head><p>Observed trajectory Ground truth <ref type="figure" target="#fig_8">Fig. 1</ref>: The current BoN ADE/FDE metrics are not sensitive to the predicted distribution. The BoN ADE/FDE only focuses on the closest sample to the ground truth. We can see for both the green and red predictions, the BoN ADE/FDE stays the same. On the other hand, the proposed AMD/AMV metrics changes based on how close the whole predicted distribution and it is spread with respect to the ground truth. This makes the AMD/AMV a better metric to evaluate the predictions.</p><p>Typically, two metrics are used to evaluate the trajectory predictions models. The first one is Average Displacement Error (ADE) <ref type="bibr" target="#b28">[29]</ref> which is the average L 2 distance between the predicted and ground truth trajectories. Lower ADE values means that the overall predicted trajectory is close to the ground truth. The other metric is the Final Displacement Error (FDE) <ref type="bibr" target="#b0">[1]</ref>, which is an L 2 distance between the two final predicted and ground truth locations. In other terms, it describes if the predicted agent reaches its last goal or not. Also, the lower the FDE is, the better the model in not accumulating errors during the predictions. This issue of accumulating errors, resulting in a higher FDE was noticed in prior works that used recurrent based architectures. Prior works introduced the idea of a full CNN based architecture <ref type="bibr" target="#b26">[27]</ref> to solve this error accumulation behavior. Yet, this ADE/FDE metric remains unsuitable for generative models. Generative models predict multiple samples of future trajectories, implicitly forming a predicted distribution. This generative behavior is suitable for the problem, as the motion of an agent or pedestrian can be a multi-modal with possible future trajectories. In order to use the ADE/FDE in generative settings, the works of <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9]</ref> introduced the concept of Best-of-N (BoN). BoN technique chooses from N samples the closest sample to the ground truth and calculates the ADE/FDE metric on it. This has a main issue of ignoring the set of generated samples. A model might generate an outlier sample that is luckily close enough to the ground truth, while the other samples are way off from the ground truth. This approach also fails in real-life applications, as there is a lack in the assessment of the predictions. Some important components, such as motion planning and collision avoidance, need a complete view of the predictions. Another issue we noticed that the recent models <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b22">23]</ref> which are state-of-the-art based on the ADE/FDE metric only differ by 1cm ADE and few centimeters FDE on the ETH <ref type="bibr" target="#b28">[29]</ref> and UCY <ref type="bibr" target="#b15">[16]</ref> datasets, one of the most commonly used datasets in this area. The 1cm difference between a previous SOTA model and the next one is so subtle and tiny that it can be an annotation error or an outlier sampling. Thus, there is a need for a new metric that can evaluate the whole predicted samples and have a sense of where the whole generated distribution is regarding the ground truth. Also, there is a need to quantify the uncertainty of the generated samples giving a view regarding the confidence of the model, something that is needed in real-life applications. For this, we introduce the usage of Mahalanobis Distance <ref type="bibr" target="#b23">[24]</ref> as a metric in this domain. We introduce two metrics, the Average Mahalanobis Distance (AMD) which evaluates how close a generated distribution is with respect to the ground truth, and the Average Maximum Eigenvalue (AMV) that evaluates the confidence of the predictions. The AMD quantifies how close a ground truth point is to a predicted distribution in a sense of standard deviation units. Also, AMD connects with ? 2 distribution, helping us to determine the confidence of our predictions when the generated distribution degree of freedom is known. The AMV depends on the maximum magnitude of the eigenvalues of the covariance matrix of the predicted distribution. It quantifies the spread of the prediction. Thus, we can tell if a model is more confident than another model by using it. So, our goal is to achieve a model that generates a distribution which is close to the ground truth and has a small spread of samples around the ground truth. This aim leads us to rethink the nature of generative models used in training motion prediction models. We can classify the used generative techniques into parametric and non-parametric ones. Parametric ones use Maximum Likelihood Estimation (MLE) to model the predicted trajectories as Gaussian or Gaussian Mixture Models (GMM). Generative Adversarial Networks (GANs) <ref type="bibr" target="#b7">[8]</ref> is an examples of non-parametric distributions. These approaches learn the distribution of the observed trajectories in order to generate the future ones. Yet, the primary goal of trajectory prediction models is the generated samples themselves. The MLE needs plenty of samples to converge, something we do not have in practice. While the GANs rely on the design of the discriminator and VAEs need to optimize the Evidence Lower Bound (ELBO). So, we needed a generative approach that only focuses on the generated samples and does not come with extra hassles. In this work, we show that Implicit Maximum Likelihood Estimation (IMLE) technique is an effective alternative to these approaches. IMLE focuses directly on the predicted trajectories, simplifying the optimization function. By using IMLE to train our introduced model Social-Implicit, the predicted trajectories improve in terms of quality and accuracy in comparison with prior works. Social-Implicit is a memory efficient deep model with only 5.8K parameters almost 55x less than the closest SOTA and runs in real-time almost 8.5x faster than the closest SOTA. This work is organized as follows: We start by literature review of recent relative works. Then we formulate the motion prediction problem, followed by an introduction and discussion for both new metrics AMD and AMV. Then we introduce the Trajectory Conditioned IMLE mechanism used in training our model Social-Implicit. We follow this by explaining the architecture of Social-Implicit. Lastly, we analyze the results of the new metrics on our model and recent SOTA ones accompanied with a sensitivity analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Literature Review</head><p>Trajectory Forecasting Models Recent works have proposed various models to forecast future trajectories. Based on their output formats, they can be roughly grouped into two categories. Explicitly modeling the future as a parametric distribution, or implicitly modeling the future as a non-parametric distribution. In the first category, methods model the future explicitly as continuous or discrete distribution <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref>. For example, S-LSTM <ref type="bibr" target="#b0">[1]</ref> and S-STGCNN <ref type="bibr" target="#b26">[27]</ref> use Gaussian distribution to model the future trajectory that are trained by Maximum Likelihood Estimation (MLE). Gaussian distribution is single-mode and cannot catch the multi-modality of the future. To tackle this issue, PRECOG <ref type="bibr" target="#b31">[32]</ref>, Trajectron++ <ref type="bibr" target="#b35">[36]</ref>, ExpertTraj <ref type="bibr" target="#b42">[43]</ref>, and AgentFormer <ref type="bibr" target="#b41">[42]</ref> learn a latent behavior distribution, which can be either discrete <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b42">43]</ref> or continuous <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b41">42]</ref>, to represent the agent multi-modality intent. In these works, the predicted Gaussian distribution is generated conditioned on the sampled latent intent. This type of method is usually based on Conditional VAE <ref type="bibr" target="#b36">[37]</ref>. Besides continuous distributions like Gaussian methods like MTP <ref type="bibr" target="#b4">[5]</ref> and LaneGCN <ref type="bibr" target="#b18">[19]</ref> use a discrete distribution to represent the future. These methods predict a fixed number of deterministic trajectories as the future candidates and use a categorical distribution to model their possibilities. In the second category, some methods model the future distribution in an implicit way. For example, S-GAN <ref type="bibr" target="#b8">[9]</ref>, So-Phie <ref type="bibr" target="#b34">[35]</ref>, S-BiGAT <ref type="bibr" target="#b12">[13]</ref> and DiversityGAN <ref type="bibr" target="#b9">[10]</ref> follows a Conditional GAN <ref type="bibr" target="#b6">[7]</ref> architecture. Instead of generating a distribution as the model output they predict a deterministic trajectory that is conditioned on a random sampled noise and is trained by an adversarial loss mechanism. Our proposed method Social-Implicit models the future distribution implicitly by training it using IMLE <ref type="bibr" target="#b16">[17]</ref> avoiding additional hassles like the discriminator in a GAN training mechanism.</p><p>Trajectory Forecasting Metrics Most of the trajectory forecasting methods are evaluated by the metric Average Displacement Error (ADE) <ref type="bibr" target="#b28">[29]</ref> or Final Displacement Error (FDE) <ref type="bibr" target="#b0">[1]</ref>. These two metrics are based on the L 2 distance of the whole temporal horizon (ADE) or the last time step (FDE) between the prediction and the ground truth trajectory. When the model generates a distribution as the output, the Best-of-N trick <ref type="bibr" target="#b8">[9]</ref> is applied to evaluate the best trajectory only from N sampled predictions. The mean ADE/FDE can be also used to evaluate the predictions, it is mostly suitable in single modality predictions and when the predictions are close to a Gaussian distribution. In multi-modality, when for example the predictions are contradictory to each other (turning left, turning  <ref type="bibr" target="#b11">[12]</ref>. KDE fits a kernel-based distribution from the prediction samples and estimates the negative log-likelihood of the ground truth as the evaluated score. Quehl et al. <ref type="bibr" target="#b29">[30]</ref> propose a synthesized metric that is a weighted sum of different similarity metrics to alleviate the metric bias. But their metric is only suitable for deterministic models. We propose two new metrics Average Mahalanobis Distance (AMD) and Average Maximum Eigenvalue (AMV) that are a better alternative for the BoN ADE/FDE in evaluating the predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Average Mahalanobis Distance (AMD) metric</head><p>We define the problem of trajectory prediction as follows: Given an observed trajectories of N agents across a sequence of observed time steps T o , the goal is to predict the next T p prediction time steps. The observed trajectories contain P points, where each point indicates the spatial location of an agent. In the pedestrian trajectory prediction problems the P is a 2D Cartesian locations (x,y). We denote the set of observation to be</p><formula xml:id="formula_0">d o = {p t | t ? T o } and the set of predictions to be d p = {p t | t ? T p }.</formula><p>To highlight the issue in the current BoN ADE/FDE, we start with <ref type="figure">Fig.</ref> 2 that illustrates the different types prediction models outputs. For deterministic models, it is straightforward to compute the ADE/FDE metrics defined in Equation 1. But for generative models, the ADE/FDE is being computed by the BoN approach. The BoN works by sampling N (usually 20) samples, selecting the closest sample to the ground truth, then using this sample to calculate the ADE/FDE. We can criticize this BoN approach in multiple aspects. The major concern is that it does not quantify the whole generated samples and only focuses on the closest one. This might disadvantage a model with a density that is surrounding the ground truth against another model with a density that is completely off the ground truth, but has one sample that is close to the ground truth. We can see this illustrated in the teaser <ref type="figure" target="#fig_8">Fig. 1</ref>. We base the other concern that with this method of BoN, one can run the metric a couple of times, getting a result that is 1 cm better than another model. In some extreme cases, a lucky random run might have a very low BoN ADE/FDE. The work of <ref type="bibr" target="#b11">[12]</ref> noticed this issue and introduced the usage of A Kernel Density Estimate (KDE) defined in Equation 1. The KDE is a kernel based tool that gets a non-parametric representation of the predictions' probability density. Then, the negative log likelihood of the ground truth is calculated and reported in logarithmic units (nats). Yet, there is a mix of limitations and concerns with the KDE metric. The main concern is that the KDE metric is sensitive to the choice of a kernel under the settings of low number of samples, which is the case in real-life datasets. <ref type="figure">Fig. 3</ref> illustrates the different choices of the kernel used in the KDE versus a variety of mixtures of distributions. We notice that when a Gaussian kernel is being used; it does not differentiate between different samples and might favour a model with a full GMM output in comparison with other outputs. We also notice, we might get a mixed results whenever a different choice of kernel is being used, such as with tophat kernel versus a Gaussian kernel. The work of <ref type="bibr" target="#b11">[12]</ref> was using KDE metrics with a Gaussian kernel. The other limitation of the KDE kernel is that it does not contain analytical properties that are easy to interpret. This limitation is because of the non-parametric nature of the KDE. Such properties of interest might be the probability moments and the confidence intervals.</p><formula xml:id="formula_1">ADE = 1 N ?Tp n?N t?Tp ?p n t ? p n t ?2, FDE = 1 N n?N ?p n Tp ? p n Tp ?2, KDE = ?1 N ?Tp n?N t?Tp log KDE(p n t , p n t )<label>(1)</label></formula><p>Where p n t is ground truth location of agent n ? N at predicted time step t ? T p andp n t is the predicted location. The new metric needs to be parametric that allows further analysis and insensitive to the way it calculates the distance. Thus, we introduce the usage of Mahalanobis distance. Mahalanobis distance can measure how far a point from a distribution is, while correlating the distance with the variance of the predictions. It also has analytical properties that connect it with the Chi-square distribution, in which one can evaluate the confidence of the predictions. Lastly, it depends on Gaussian distribution, which allows further analysis of the predicted moments. The Mahalanobis distance (MD) is defined as:</p><formula xml:id="formula_2">M D ?,?, p = (p ??) T? ?1 (p ??). Where,? is the mean of the prediction,</formula><p>? is the variance of the predicted distribution and p is the ground truth location. Originally, Mahalanobis distance was not designed for a GMM distribution. Yet, the work of <ref type="bibr" target="#b38">[39]</ref> extended MD into a GMM by formulating it as:</p><formula xml:id="formula_3">M D ? GMM ,?, p = (? GMM ? p) T? (? GMM ? p)<label>(2)</label></formula><p>Where?, the inverse covariances of each mixture components averaged and weighted probabilistically, is defined as</p><formula xml:id="formula_4">:? = K k=1? ?1 k? k p ? GMM p(x|k)dx K k=1? k p ? GMM p(x|k)dx ,</formula><p>where K is the number of mixture components,? k is the weight of the kth component and the mean of the GMM is defined as:? GMM = K k=1? k?k . The integral   term in? is tractable, as noted in <ref type="bibr" target="#b38">[39]</ref>. We notice that if the GMM contains only one component, the G will be the? ?1 , thus the Tipping's MD is a more generalized version of the original MD. Our approach is the following, whatever distribution or output produced by a model, we fit into a GMM. A question will be raised regarding the number of optimal mixture components K. This can be easily solved by using the Bayesian information criterion (BIC): BIC = m ln n ? 2 lnL GMM , where m is the number of parameters of the GMM model, n is the number of observed data points andL GMM is the likelihood function of the model. The lower the BIC is the better the fitted GMM model representing the data points. The best GMM is chosen automatically based on the BIC. Looking into the reason for sampling from a model that is already predicting the mean and variance of trajectories such as <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b26">27]</ref>, that we want to be fair. Fitting a GMM will carry out a sort of error, thus we want this error to be incorporated into all modes of measurements to have a unified metric. <ref type="figure">Fig. 5</ref> show this error. Because a deterministic model does not have a variance, we need a representation of the error in the model. We can train the deterministic model multiple times and fit the predictions to a GMM. Another proposal is to calculate the ensemble mean and variance and directly apply the MD distance without the GMM fit. The later approach might have an error that is equivalent to the GMM fit error, making the metric more fair. In the supplementary, we discuss both cases. We believe that evaluating a deterministic model versus a generative model is an open question that needs a further research and it is a limitation similar to the KDE <ref type="bibr" target="#b11">[12]</ref> limitation. Now, we define the Average Mahalanobis Distance (AMD):</p><formula xml:id="formula_5">AMD = 1 N ? T p n?N t?Tp M D ? n GMM,t ,? n t , p n t<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Average Maximum Eigenvalue (AMV) Metric</head><p>A major concern of the AMD metric is that it is highly correlated with the variance of the distribution. A model might predict future trajectories, with a huge on-practical variance having the ground truth close to the mean. This will lead to a very low AMD in comparison with another model with a higher variance. Another example is a model that predicts a huge variance that is in meters covering all the predicted points. This also will lead to an optimal AMD value. To counter this false behavior, we need our models to have a low AMD accompanied with a low variance aka a more certain model. Also, in practical application, we need to quantify the overall uncertainty of the predictions to have a holistic view of the performance. Thus, we introduce the usage of the eigenvalues of the covariance matrix. The largest magnitude eigenvalue of the covariance matrix is an indicator of the spread of the covariance matrix. <ref type="figure">Fig. 4</ref> illustrates two distributions, the one on the left has a smaller variance than the one on the right. We notice that the MD of a fixed point with respect to the left distribution is much higher when compared to the right distribution. Yet, the largest magnitude eigenvalue of the left distribution is way less than the right distribution, showing the spread of the predictions. So, to properly evaluate the models we need both of the AMD and a measurement of the spread. And as we discussed we can have a measurement of the spread directly from the prediction covariance matrix. Because of the framework we introduced in the AMD metric, we have a covariance matrix of the prediction. Something that was missing in the KDE metric. Now, we can introduce the AMV metric:</p><formula xml:id="formula_6">AMV = 1 N ? T p n?N t?Tp ? ? 1 (? n GMM,t )<label>(4)</label></formula><p>Where ? ? 1 is the eigenvalue with the largest magnitude from the matrix eigenvalues. The? GMM is the covariance matrix of the predicted GMM distribution defined as:</p><formula xml:id="formula_7">? GMM = K k=k? k?k + K k=1? k (? k ?? GMM )(? k ?? GMM ) T .</formula><p>Thus, the AMV becomes a metric that evaluates the overall spread of the predicted trajectories. A model with low AMD will have a predicted distribution that is closer to the ground truth. And a model with low AMV will be more certain in their predictions. Thus, a model with both low AMD/AMV average is preferred when compared with another model with a higher AMD/AMV average. For this we use the AM D+AM V 2 as an indicator of a good model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Trajectory Conditional Implicit Maximum Likelihood Estimation (IMLE) Mechanism</head><p>By induction from the goal of the AMD/AMV metric to have a model that generates samples that is close to the ground truth with low spread, we need a training mechanism that allows full control over the predicted samples as the main optimization goal. Typical training mechanism such as Maximum Likelihood Estimation (MLE) or its variants like maximizing evidence lower bound (ELBO) encourages the prediction samples to be close to some (ground truth) data sample. In this way, some data examples may be missed and lead to a mode dropping <ref type="bibr" target="#b16">[17]</ref>. Other methods, such as GANs, need to introduce additional modules like the discriminator and their training is usually unstable and need to be carefully tuned to reach a proper Nash's equilibrium. The work of <ref type="bibr" target="#b16">[17]</ref> introduced the concept of Implicit Maximum Likelihood Estimation (IMLE). IMLE encourages every target ground truth to be close to some predicted samples. Therefore, it leads to a predicted distribution that is better in covering the ground truth unlike MLE. IMLE trains a model via a simple mechanism: inject a noise into the model's input to predict multiple samples, select the one closest to the ground truth, and back propagate using this sample. Unlike other generative approaches, IMLE does not load the optimization objective with a specific training technique and keeps the training stable due to the simple distance-minimization-based optimization. Using IMLE as a training mechanism aligns with the AMD/AMV goals and focuses on the important product, the predicted output. Another point of view for IMLE is that it is a more advanced neural technique in comparison with estimation techniques such as Kalman filter where the process and measurement noises drive the model. We refer the reader to the original IMLE paper <ref type="bibr" target="#b16">[17]</ref> for a further discussion. The training mechanism is shown in Alg.1:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Trajectory Conditional Implicit Maximum Likelihood Estimation (IMLE) algorithm</head><p>Require:</p><formula xml:id="formula_8">The dataset D = (d i o , d i p )</formula><p>n i=1 and the model ?(.) with a sampling mechanism conditioned on the input Require: Choose a proper loss function L(.) such as mean squared error or L1 Initialize the model for e = 1 to Epochs do Pick a random batch (do, dp) from D Draw i.i.d. samplesdp 1 , . . . ,dp m from ?(do) ?(i) ? arg mini L dp ?dp i ?i ? m ? ? ? ? ?? ? ?(i) end for return ? 6 The Social-Implicit Model</p><p>In this section, we present the Social-Implicit model. The Social-Implicit is tiny in memory size with only 5.8K parameters with real run-time of 588Hz. The method comprises three concepts, Social-Zones, Social-Cell and Social-Loss. The Social-Zones: The Social-Zones cluster the observed agents trajectories based on their maximum change of speed. The average pedestrian speed is 1.2m/s <ref type="bibr" target="#b13">[14]</ref>. We noticed that we can cluster the motion of pedestrians into four groups. The first group is the motion-less group, where the pedestrian is waiting at the traffic light as an example. This group's maximum speed change is between 0-0.01m/s. While the second group is pedestrians with minimal motion, . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Motionless zone</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>High speed zone</head><p>Social-Implicit . .</p><p>. . <ref type="figure">Fig. 6</ref>: Social-Implicit model concept. The Social-Zones cluster the observed trajectories based on their maximum observed speed. Then each Social-Zone is processed by a Social-Cell. The model is trained using IMLE. aka someone who is shaking in place or a group of pedestrians greeting each other, typically this group's maximum change of speed is between 0.01-0.1m/s. The third group are pedestrians with an average walking speed, these pedestrians motion is between 0.1-1.2m/s. The last group is the running pedestrians, typically with a speed above the 1.2m/s average. When a deep model is trained on the stationary pedestrians alongside the faster ones, a bias towards the moving ones will exist in the predictions. This will force the model to predict the non-moving objects as moving ones. It is a sort of data imbalance, or in other terms, a zero(motionless)-inflated data issue. Hence, the concept of Social-Zones is needed to solve this issue. Empirically, we show that our model with the Social-Zones performs better than without it. The input to the Social-Zones is the observed trajectories and the output is clusters of pedestrians, each cluster is a graph of dimensions P ? T o ? N . The Social-Cell: The fundamental building unit of the Social-Implicit model is the Social-Cell. The Social-Cell is a 4 layers deep model that is simple and directly dealing with the spatio-temporal aspects of the observations. <ref type="figure">Fig. 7</ref> illustrates the structure of the Social-Cell. We notice the cell has two components, one that deals with each individual agent at a local level and one that deals with the whole agents at a global level. We generate the final output of the cell by combining the local and global streams via self-learning weights. Both local and global streams are two consecutive residually connected CNN layers. The first CNN is a spatial CNN, which creates an embedding of the spatial information of the observed agents. The second layer is a temporal CNN that treats the time aspect of the observed trajectories. It treats the time as a feature channel, allowing us to predict the next T p time steps without using a recurrent network <ref type="bibr" target="#b26">[27]</ref>. We found out that this simple architecture is as effective as much larger and complex models, resulting in a small memory size and real-run time capabilities. Each Social-Cell deals with a specific Social-Zone. The input is P ? T o ? N and the output is P ? T p ? N . The operations are shown in <ref type="figure">Fig. 7</ref>. The Social-Loss: The loss function of Social-Implicit exhibits several parts. The first part is the direct optimization objective of the IMLE mechanism that we discussed before. The second part is a triplet loss. This triplet loss considers the anchor to be the </p><formula xml:id="formula_9">+ ? ! ? " Spatial 2D CNN (K=3, P=1, ReLU) + ? ! ? + Noise Temporal 2D CNN (K=3, P=1) + ? ! ? ? " ? X + #!$%# X &amp;#!'%# ? " ? Predicted Trajectories</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Social-Zone</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Local Stream</head><p>Global Stream <ref type="figure">Fig. 7</ref>: Social-Cell model. The local and global stream has only two CNNs. P is the observed location, T o and T p is the observed and predicted time steps and N is the count of agents. Where K and P of the CNNs is the kernel and padding size.</p><p>closest sampled 1 p to the ground truth. The positive example is the next closest exampled 2 p to the ground truth. The negative exampled m p is the farthest sample from the ground truth. This helps in grouping the samples closer to the ground truth, resulting in a tighter distribution around the real trajectory. The last part of the loss is a geometric loss function that treats the predicted locations as a polygon. First, it ensures that the intra-distance between the predicted location matches the intra-distance between the ground truth locations. Second, it makes sure that the angles between the predicted points are the same as the angles between the ground truth points. It ensures that the predicted scene geometrically looks like the ground truth. We defines these losses in <ref type="bibr">Equation 5</ref>. The social aspects of the scene can be addressed beyond what we introduced which is an open research area.</p><formula xml:id="formula_10">L triplet = ?d 1 p ?d 2 p ? 1 ? ?d 1 p ?d m p ? 1 L G-distance = 1 Tp(Tp?1) 2 t?Tp j?Tp,j&gt;t ?p t ? p j ? 2 ? ?p t ?p j ? 2 1 L G-angle = 1 Tp(Tp?1) 2 t?Tp j?Tp,j&gt;t ?(p t , p j ) ? ?(p t ,p j ) 1<label>(5)</label></formula><p>Thus we define the Social-Loss as:</p><formula xml:id="formula_11">L = ?d p ?d 1 p ? 1 + ? 1 L triplet + ? 1 L G-distance + ? 3 L G-angle<label>(6)</label></formula><p>Where ? 1 = 0.0001, ? 2 = 0.0001 or 0.00001, ? 3 = 0.0001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments and Analysis</head><p>We analyze the behavior of the metrics on common pedestrian motion prediction models in terms of overall performance and sensitivity analysis. Then we analyze our model in terms of design components and performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Metrics Sensitivity Analysis &amp; Evaluation</head><p>We show that the BoN ADE/FDE metric is not sensitive to the change or shift in the distribution, while the AMD and KDE can quantify such a change. <ref type="figure" target="#fig_8">Fig. 1</ref> illustrates this concept. We tested different models by shifting their predicted samples using different amounts, specifically ?1cm and ?10cm. In all of the models, the BoN ADE/FDE metric did not change at all or had a very tiny subtle change. Unlike the metrics that measure the whole distribution, like AMD and KDE the shift of the predicted distribution is reflected into the metric. This concludes that the ADE/FDE metric is not sensitive to the change of the whole distribution, even on a tremendous change of 10cm, which sometimes can define a new SOTA model over another. So, the BoN ADE/FDE metric is incapable of evaluating the whole predicted trajectories. Also, the AMV metric stayed the same, this was expected as only shifting the predictions does not change the variance. We notice that the KDE of Trajectron++ is -ve unlike other models because Trajectron++ output is a GMM distribution which is a bias in the KDE metric due to the kernel choice as we discussed earlier.</p><p>To evaluate the metrics quantitatively, we report the AMD/AMV, KDE and ADE/FDE metrics on different motion prediction models using the ETH/UCY datasets. We chose classic ones such as S-GAN <ref type="bibr" target="#b8">[9]</ref> and S-STGCNN <ref type="bibr" target="#b26">[27]</ref>. We also chose more recent ones such Trajectron++ <ref type="bibr" target="#b35">[36]</ref> and ExpertTraj <ref type="bibr" target="#b42">[43]</ref>. From Tab. 1 we notice that the last two models, which are considered SOTA, differ by a few centimetres on the ADE/FDE metric. Yet, when we evaluate both of them using the AMD/AMV metrics, we notice that Trajectron++ is performing much better than the ExpertTraj model. From the AMD/AMV metric, Expert-Traj generates a tight distribution that does not surround the ground truth, which results in a higher AMD unlike the Trajectron++. Though, both of Ex-pertTraj and Trajectron++ have very close ADE/FDE metrics, the quality of the whole predicted samples is completely different. Examining the results of our model, Social-Implicit, we see that it has the lowest AMD/AMV. By digesting the results, the ADE/FDE metric is not an indicative of the overall performance of the models which correlates with the aforementioned sensitivity analysis. We test our model and metrics on Stanford Drone Dataset (SDD) <ref type="bibr" target="#b32">[33]</ref>. We follow the setting of a SOTA model DAG-Net <ref type="bibr" target="#b27">[28]</ref>. Experimental results in Tab 2 show that our model outperforms DAG-Net. This aligns with the results on the ETH/UCY datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Ablation Study of Social-Implicit</head><p>We conduct an ablation study of the Social-Implicit components. Specifically, the Social-Zones and the Social-Loss. Tab. 3 illustrates the results. We noticed <ref type="table">Table 1</ref>: For all metrics, the lower the better. The results are on the ETH/UCY datasets. M is a non reported model. NaN is failed computation. ExpertTraj ADE/FDE were taken from their paper. We notice sometimes, even if a model has a low ADE/FDE the AMD/AMV contradicts this by evaluating the overall generated samples.  that the existence of the Social-Zones enhanced the AMD metric by almost 40%. It also led to a good AMV value, which enhanced the overall AMD/AMV performance. We notice that the triplet loss alone with the Social-Zones leads improves AMD/AMV. The effect of geometric angle loss is more than the geometric distance loss in improving the AMD/AMV. While both work better together. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Inference and Memory analysis</head><p>Social-Implicit besides being the most accurate model when compared with other models on the AMD/AMV metrics, it is the smallest and the fastest in terms of parameters size and inference time. <ref type="table" target="#tab_5">Table 4</ref> shows these results. The closest SOTA is ExpertTraj which Social-Implicit is 55x smaller and 8.5x faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Social-Zones ablation</head><p>Tab. 5 shows the ablation of the number of zones. Different zones affects the model's performance. Also, the model is sensitive to the zone's speeds. For example, when we changed the last zone from 1.2m/s to 0.6m/s the results changed. The 1.2m/s reflects human average walking speed, thus the 0.6m/s does not suit the data, hence it leads to poor performance in comparison with the 1.2m/s. Parameters count Speed (s) S-GAN <ref type="bibr" target="#b8">[9]</ref> 46.3K (7.98x) 0.0968 (56.9x) S-STGCNN <ref type="bibr" target="#b26">[27]</ref> 7.6K (1.3x) 0.0020 (1.2x) Trajectron++ <ref type="bibr" target="#b35">[36]</ref> 128K (22.1x) 0.6044 (355.5x) ExpertTraj <ref type="bibr" target="#b42">[43]</ref> 323.3k (55.74x) 0.0144 (8.5x)</p><p>Social-Implicit (ours) 5.8K 0.0017 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Qualitative Results</head><p>In <ref type="figure" target="#fig_4">Fig. 8</ref>, we list two qualitative examples of our method and baseline models. In the first row, we see a pedestrian turns right at the end of the ground truth future. We notice that Social-Implicit and Trajectron++ cover the ground truth future well, whereas S-GAN and ExpertTraj give us an early turning prediction and concentrate away from the ground truth. The second row shows a zigzag walking pedestrian. Baseline models like S-STGCNN, Trajectron++, and ExpertTraj cannot generate good distributions to cover the ground truth trajectory, unlike ours and S-GAN. Although the prediction of ExpertTraj is close to the ground truth, ExpertTraj is over confident contradicting the ground truth. Qualitative results show that our predicted distribution are better. We also show multi-agent interaction in <ref type="figure" target="#fig_5">Fig 9.</ref> ExpertTraj is over-confident missing the ground-truth, S-STGCNN have wide variance with collision, Trajectron++ have ground-truth close to predicted distribution tail, while ours have the right balance. More qualitative results in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>We introduced the AMD and AMV metrics that evaluate the distribution generated by a trajectory prediction model. We showed that the BoN ADE/FDE metric gives out an inadequate evaluation of the generated distribution. Based on the objective of AMD/AMV metrics to have a model that generates samples  that are close to the ground truth with a tight variance, we introduced the usage of IMLE to train our model, Social-Implicit. We showed that Social-Implicit is a memory efficient model that runs in real-time and relies on several concepts such as Social-Zones, Social-Cell and Social-Loss to enhance the performance. Overall, we invite the motion prediction community to adapt the AMD/AMV to have a better evaluation of their methods.  first row and the second row, we see a pedestrian turning left in the past and going straight in the future. S-GAN in the first case and S-GAN, S-STGCNN, ExpertTraj in the second case think confidently that the pedestrian will turn right in the future. But the pedestrian actually goes straightly, which is correctly predicted by our method and Trajectron++. In the third case, S-GAN and S-STGCNN give us a too slow prediction and ExpertTraj gives us a too fast and overturning prediction. In contrast, the predicted distribution of our method and Trajectron++ covers the ground truth well. In the last case, ExpertTraj performs well by placing the predicted concentration on the ground truth. Ours has a wrong prediction following the original trend of the observed motion. In the first row and second row of the second <ref type="figure" target="#fig_7">Figure 13</ref>, the pedestrian has a sudden turn in the middle of the future. Although all the methods fail to predict this turning, the predicted distribution generated by our method covers the ground truth the best. The third row shows a pedestrian not moving. All the methods give us a close-to-no-movement prediction here. Among them, the movement of ExpertTraj is the smallest. Ours are second-smallest. The last row shows a pedestrian going straight but switching the lane in the middle of the future. Our method and Trajectron++ cover the ground truth trajectory well, while S-STGCNN misses the new lane and ExpertTraj generates a no-existing turn. Overall, though ADE/FDE metrics were stating that Trajectron++ and ExpertTraj are state of art methods, we showed several cases that show the density away from the ground truth. Thus, the ADE/FDE gives an inadequate sense of models' accuracy, unlike the AMD/AMV metrics, which quantifies the whole generated distribution. This correlates with the results in Table <ref type="bibr" target="#b0">[1]</ref> and our analysis of the experiments section where our model was performing the best on the ADM/AMV metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Qualitative Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Evaluation of Deterministic Models</head><p>We trained Social-STGCNN <ref type="bibr" target="#b26">[27]</ref> as a deterministic model on the ETH/UCY datasets. Instead of predicting a Gaussian distribution, it predicts the trajectory directory. The training used MSE as a loss function. We wanted to test two assumptions for evaluating a deterministic model. The first one is to train it multiple times and use ensemble to find the mean and variance per predicted trajectory. The other one adds up on the previous one by calculating the mean and variance but fits a GMM and then samples from this GMM. In this experiment, we trained Social-STGCNN 3 times using different random seeds. <ref type="table" target="#tab_8">Table 6</ref> shows the results. The AMD and AMV of the first setting was reported. The KDE was not because there is no method to compute it from a mean and variance without sampling, unlike our metric AMD which has this ability by directly plugging in the mean and variance into the Mahalanobis distance equation. For the second setting, AMD, AMV and KDE were reported as we fitted the samples into a GMM fit then we sampled multiple samples. We only used 3 ensembles of Social-STGCNN to simulate a real-life situation, aka it is not feasible to train it 1000 times and create an ensemble out of it. We notice in <ref type="table" target="#tab_8">Table 6</ref> that the second settings exhibit a very large AMD and KDE, this is an indicator that the GMM fit did not converge because we only have 3 samples. Usually, we use 1000 samples to guarantee the GMM converges and thus the second settings is not feasible to be used as we need that many samples to fit the GMM model well. We notice in both first and second settings that the AMV values are the same. This was expected, as the AMV metric is an indicator of the spread. For the first setting, the AMD value seems reasonable for a deterministic model, as the work of <ref type="bibr" target="#b24">[25]</ref> showed that most of motion predictions problem can be solved using a linear Kalman filter. This also supported by the enormous values of the AMV metric as a deterministic model does not have that much of a spread. We connect this with the results in the main paper on the ExpertTraj where the AMV values was on the same order of magnitude as the deterministic model we trained. In other terms, the ExpertTraj indeed behaves as a deterministic model because of the tight spread. We can notice this in some of the visual cases reported in <ref type="figure" target="#fig_7">Figures 12 and 13</ref>. For further analysis, we plot some samples generated from the ensemble of the deterministic model alongside the spread in <ref type="figure" target="#fig_8">Figure 11</ref>. We notice sometimes the spread of the predictions might be close to the ground truth as in the sample in the top left corner. Also, it can be completely off, as in the other samples. So we think that using an ensemble of a few versions of a deterministic model is a good approach to evaluate its performance using the AMD/AMV metric. Also, with the AMV metric as a target to optimize for, one can train the ensemble using methods that help encourage diversity <ref type="bibr" target="#b21">[22]</ref>.   <ref type="bibr" target="#b26">[27]</ref> as a deterministic model using different random seeds. The first setting reports the AMD/AMV using the mean and variance of the ensemble. The second setting reports the AMD/AMV/KDE using a GMM fit on the mean and variance of the ensemble. The ADE/FDE are the average through the ensembles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Social-Implicit Implementation Details</head><p>Social-Implicit comprises four zones, as discussed before. <ref type="table" target="#tab_9">Table 7</ref> shows more details about the zones. We notice each zone uses a different configuration of the random noise used to generate the samples. The slow zones use noise which has much lower variance than the faster zones. We also show the layer details of the Social-Cell in <ref type="table" target="#tab_10">Table 8</ref>. Both local and global streams share the same design, except that the local stream uses Conv1D and the global stream uses Conv2D. We initialize the noise, global and local weights to zero. The noise weight is being multiplied by the sample generated from the random distribution and then added to the input tensor. The models were trained for 50 epochs with a learning rate = 1, then the learning rate drops to 0.1 after 45 epochs. The batch size was set to 128. We used SGD as an optimizer. We also used an augmentation technique for the trajectories similar to <ref type="bibr" target="#b35">[36]</ref> to fight some imbalance in the datasets. We used random rotation by several degrees, reverse the trajectory, flip the x,y locations, jitter the location by a small value, increase the number of the nodes in the scene by combining it with another scene and changing the speed of the pedestrians. Implementation of the model and augmentation is available in the attached code.    </p><p>3) <ref type="figure" target="#fig_7">Fig. 13</ref>: Visualization of the predicted trajectories by several models on the ETH/UCY datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1)</head><p>2)</p><p>3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4)</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2</head><label></label><figDesc>Mahalanobis distance: 0.55| Max = 20</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig</head><label></label><figDesc>Fig. 4: The Mahalanobis distance is being measured for a test point marked by x. Two Bi-Variate Gaussian distributions are shown, the one on the left has a lower variance than the one on the right. ? stands for the maximum absolute eigenvalue of the distributions covariances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 :</head><label>8</label><figDesc>Visualization of the predicted trajectories on the ETH/UCY datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9 :</head><label>9</label><figDesc>Multi-pedestrian interaction cases on the ETH/UCY datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 :</head><label>10</label><figDesc>Social-Implicit Interactive Demo. This demos shows the changes in the metrics in regards of the generated distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figures 12 and 13</head><label>13</label><figDesc>show cases where our model performs well or where it might be under-performing. Starting from Figures 12, in the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Zone Speed range Noise 1 0</head><label>1</label><figDesc>-0.01 m/s N (0, 0.05 2 ), if eth N (0, 0.175 2 ) 2 0.01-0.1 m/s N (0, 1 2 ) if eth N (1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 :</head><label>12</label><figDesc>Visualization of the predicted trajectories by several models on the ETH/UCY datasets.1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Gaussian distribution GMM distribution Cloud of points (GAN, VAE) Deterministic Ground truth Predictions</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>All Gaussian</cell><cell></cell></row><row><cell></cell><cell></cell><cell>8</cell><cell>2 Gaussian and Uniform 1 Gaussian and 2 Uniform</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>2 Gaussian and Gumbel</cell><cell></cell></row><row><cell></cell><cell>NLL KDE</cell><cell>4 6</cell><cell>1 Gaussian and 2 Gumbel 1 Uniform and 2 Gumbel</cell><cell></cell></row><row><cell></cell><cell></cell><cell>2</cell><cell></cell><cell></cell></row><row><cell>Fig. 2: Different motion prediction</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>models output. The Gaussian and</cell><cell></cell><cell>0</cell><cell>gaussian</cell><cell>KDE Kernel tophat</cell><cell>epanechnikov</cell></row><row><cell>GMM are examples of parametric mod-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>els. The GAN and VAE are examples of</cell><cell cols="5">Fig. 3: Different mixture models NLL</cell></row><row><cell>non-parametric models. The last cate-</cell><cell cols="5">KDE vs the choice of the KDE Ker-</cell></row><row><cell>gory is a deterministic model output. A</cell><cell cols="5">nel. The lower the better. We also no-</cell></row><row><cell>unified metric is needed to evaluate all</cell><cell cols="5">tice that the results vary depending on</cell></row><row><cell>of these models.</cell><cell cols="3">the kernel.</cell><cell></cell></row><row><cell cols="6">right) the mean ADE/FDE will fail because it is deterministic in nature. Another</cell></row><row><cell cols="6">way to evaluate the distribution quality is Kernel Density Estimate (KDE), first</cell></row><row><cell>used in</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>. 4: The Mahalanobis distance is being measured for a test point marked by x. Two Bi-Variate Gaussian distributions are shown, the one on the left has a lower variance than the one on the right. ? stands for the maximum absolute eigenvalue of the distributions covariances.</figDesc><table><row><cell>0.00 0.02 0.04 0.06 0.08 Mean</cell><cell></cell><cell></cell><cell>0.86 0.88 0.90 0.92 0.94 0.96 0.98 1.00 Variance</cell><cell></cell><cell></cell><cell>Mahalanobis Distance</cell><cell>3.00 3.02 3.04 3.06 3.08 3.10 3.12 3.14</cell><cell></cell><cell cols="2">Predicted Ground Truth</cell></row><row><cell>102</cell><cell>103</cell><cell>104</cell><cell>105</cell><cell>102</cell><cell>103 Number of Samples 104</cell><cell>105</cell><cell>102</cell><cell>103</cell><cell>104</cell><cell>105</cell></row><row><cell cols="11">Fig. 5: GMM fit exhibit an error and</cell></row><row><cell cols="11">need a lot of samples to converge into</cell></row><row><cell cols="11">the true mean, something might be a</cell></row><row><cell cols="11">disadvantage to non-parametric mod-</cell></row><row><cell cols="11">els. At the 1000 samples mark, GMM</cell></row><row><cell cols="11">starts to converge to the true mean and</cell></row><row><cell cols="7">variance with stable MD.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>For all metrics, the lower the better. The results are on the SDD dataset.</figDesc><table><row><cell></cell><cell cols="5">ADE FDE AMD AMV KDE (AMD+AMV)/2</cell></row><row><cell>STGAT [11]</cell><cell>0.58 1.11</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Social-Ways [2]</cell><cell>0.62 1.16</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DAG-Net [28]</cell><cell cols="4">0.53 1.04 3.17 0.247 1.76</cell><cell>1.70</cell></row><row><cell cols="5">Social-Implicit (ours) 0.47 0.89 2.83 0.077 3.89</cell><cell>1.45</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Ablation study of Social-Implicit components.</figDesc><table><row><cell cols="7">L triplet L G-distance L G-angle Zones AMD/KDE/AMV AMD/AMV ADE/FDE</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>2.06/2.29/0.110</cell><cell>1.09</cell><cell>0.32/0.66</cell></row><row><cell></cell><cell></cell><cell></cell><cell>?</cell><cell>2.04/1.86/0.104</cell><cell>1.07</cell><cell>0.32/0.64</cell></row><row><cell>?</cell><cell></cell><cell></cell><cell>?</cell><cell>1.96/2.16/0.097</cell><cell>1.03</cell><cell>0.56/1.08</cell></row><row><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell>2.13/2.32/0.092</cell><cell>1.11</cell><cell>0.32/0.62</cell></row><row><cell>?</cell><cell></cell><cell>?</cell><cell>?</cell><cell>1.84/1.78/0.094</cell><cell>0.97</cell><cell>0.78/1.38</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell>2.29/2.76/0.090</cell><cell>1.16</cell><cell>0.35/0.71</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>1.63/1.85/0.174</cell><cell>0.90</cell><cell>0.33/0.67</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: Parameters counts and</cell></row><row><cell>mean inference speed reported, bench-</cell></row><row><cell>marked on the GTX1080Ti.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Number of zones and their speed effect on our model accuracy.</figDesc><table><row><cell>#Zones</cell><cell>ADE/FDE KDE AMD/AMV AVG</cell></row><row><cell>1</cell><cell>0.35/0.71 2.76 2.29/0.090 1.16</cell></row><row><cell>2</cell><cell>0.36/0.73 3.09 2.32/0.088 1.20</cell></row><row><cell>3</cell><cell>0.34/0.70 2.31 2.08/0.085 1.08</cell></row><row><cell cols="2">4@0.6m/s 0.34/0.69 2.85 2.31/0.080 1.19</cell></row><row><cell cols="2">4@1.2m/s 0.33/0.67 1.85 1.63/0.174 0.90</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>KDE AMD AMV KDE ADE FDE eth 1.45 35.7 -27.89 35.7 12.89 1.71 2.97 hotel 0.36 19.6 -44.26 19.5 11.27 1.41 2.56 univ 0.62 170.1 -24.62 169.9 13.30 1.17 2.13 zara1 1.18 28.0 -28.95 28.0 13.86 1.71 3.18 zara2 1.03 96.9 -12.54 96.8 8.36 1.16 2.10 Average 0.93 70.06 -27.65 70.0 11.94 1.43 2.59</figDesc><table><row><cell>Dataset</cell><cell>Ensemble AMD AMV</cell><cell>GMM Fit</cell><cell>General</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Deterministic case experiment. We trained Social-STGCNN</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Social-Zones configurations. The speed range determines if an observed trajectory will be withing the zone or not. The random noise exhibits different variances depending on the zone.Fig. 11: Social-STGCNN deterministic version predictions.</figDesc><table><row><cell>Section</cell><cell>Layer Name</cell><cell>Configuration</cell></row><row><cell></cell><cell>Spatial CNN</cell><cell>Conv1D[P ,P ,3,1]</cell></row><row><cell></cell><cell cols="2">Spatial Activation ReLU</cell></row><row><cell>Local Stream</cell><cell cols="2">Spatial ResCNN Conv1D[P ,P ,1,0]</cell></row><row><cell></cell><cell>Temporal CNN</cell><cell>Conv1D[To,Tp,3,1]</cell></row><row><cell></cell><cell cols="2">Temproal ResCNN Conv1D[To,Tp,1,0]</cell></row><row><cell></cell><cell>Noise Weight</cell><cell>1 Parameter</cell></row><row><cell></cell><cell>Spatial CNN</cell><cell>Conv2D[P ,P ,3,1]</cell></row><row><cell></cell><cell cols="2">Spatial Activation ReLU</cell></row><row><cell>Global Stream</cell><cell cols="2">Spatial ResCNN Conv2D[P ,P ,1,0] Temporal CNN Conv2D[To,Tp,3,1]</cell></row><row><cell></cell><cell cols="2">Temproal ResCNN Conv2D[To,Tp,1,0]</cell></row><row><cell></cell><cell>Global Weight</cell><cell>1 Parameter</cell></row><row><cell></cell><cell>Local Weight</cell><cell>1 Parameter</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>Social-Cell configuration. A Conv1D or Conv2D with [x,x,x,x] = [input features, output features, kernel size, padding size]. The Res = Residual connection being added to the previous layer output. P is the dimension of the observed location. T o and T p is the number of observed and predicted time steps.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social lstm: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="961" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Social ways: Learning multi-modal distributions of pedestrian trajectories with gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Amirian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Hayet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pettr?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Anticipating many futures: Online human motion prediction and generation for human-robot interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>B?tepage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kjellstr?m</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kragic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on robotics and automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4563" to="4570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Multipath: Multiple probabilistic anchor trajectory hypotheses for behavior prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.05449</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multimodal trajectory predictions for autonomous driving using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Djuric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2090" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolutional social pooling for vehicle trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1468" to="1476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Conditional generative adversarial nets for convolutional face generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gauthier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2014</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Diversitygan: Diversity-aware vehicle motion prediction via latent semantic sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Mcgill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Decastro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rosman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="5089" to="5096" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Stgat: Modeling spatial-temporal interactions for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6272" to="6281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2375" to="2384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mart?n-Mart?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.03395</idno>
		<title level="m">Social-bigat: Multimodal trajectory forecasting using bicycle-gan and graph attention networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The continuing evolution of pedestrian walking speed assumptions. Institute of Transportation Engineers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Laplante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Kaeser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ITE Journal</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="336" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Crowds by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chrysanthou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer graphics forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="655" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.09087</idno>
		<title level="m">Implicit maximum likelihood estimation</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Grip: Graph-based interaction-aware trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Chuah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Transportation Systems Conference (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3960" to="3966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning lane graph representations for motion forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="541" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robust deep-learning-based road-prediction for augmented reality navigation systems at night</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Limmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Forster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baudach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sch?le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schweiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Lensch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1888" to="1895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Human motion prediction for human-robot collaboration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Manufacturing Systems</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="287" to="294" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep neural network ensembles against deception: Ensemble diversity, accuracy and robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gursoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Truex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 16th international conference on mobile ad hoc and sensor systems (MASS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="274" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Social nce: Contrastive learning of socially-aware motion representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15118" to="15129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">On the generalized distance in statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Mahalanobis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1936" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Science of India</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">On exposing the challenging long tail in future prediction of traffic actors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Makansi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Cicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12474</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">From goals, waypoints &amp; paths to long term human trajectory forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Social-stgcnn: A social spatiotemporal graph convolutional neural network for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Claudel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14424" to="14432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dag-net: Double attentive graph neural network for trajectory forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bertugli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Calderara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 25th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2551" to="2558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">You&apos;ll never walk alone: Modeling social behavior for multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">How good is my prediction? finding a similarity measure for trajectory prediction evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><forename type="middle">?</forename><surname>Ta?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rehder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">R2p2: A reparameterized pushforward policy for diverse, precise generative path forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="772" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Precog: Prediction conditioned on goals in visual multi-agent settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2821" to="2830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning social etiquette: Human trajectory understanding in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="549" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Human motion trajectory prediction: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rudenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Gavrila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Arras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="895" to="935" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1349" to="1358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Trajectron++: Dynamically-feasible trajectory forecasting with heterogeneous data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="683" to="700" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XVIII 16</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3483" to="3491" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multiple futures prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="15424" to="15434" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deriving cluster analytic distance functions from gaussian mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Tipping</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth International Conference on Artificial Neural Networks ICANN 99</title>
		<imprint>
			<publisher>IET</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="815" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Challenges in networking to support augmented reality and virtual reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Westphal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Motionnet: Joint perception and motion prediction for autonomous driving based on bird&apos;s eye view maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11385" to="11395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Agentformer: Agent-aware transformers for socio-temporal multi-agent forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14023</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Where are you heading? dynamic trajectory prediction with expert goal examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Wildes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7629" to="7638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A Interactive Demo We introduce an interactive demo that shows the change of ADE, FDE, AMD and AMV when the generated distribution changes or shifts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zahran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<ptr target="https://www.abduallahmohamed.com/social-implicit-amdamv-adefde-demo" />
	</analytic>
	<monogr>
		<title level="m">5th Annual Conference on Robot Learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>Motion forecasting with unlikelihood training in continuous space</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">By using this demo, one can see the direct effect of changing the distribution and how the ADE/FDE metrics are inadequate to evaluate the predicted quality. For example, when the shift is huge in one of the x or y directions, the ADE/FDE will stay constant</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
