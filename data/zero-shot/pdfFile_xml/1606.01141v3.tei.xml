<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Valid Optimal Assignment Kernels and Applications to Graph Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><forename type="middle">M</forename><surname>Kriege</surname></persName>
							<email>nils.kriege@tu-dortmund.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<address>
									<settlement>Dortmund</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Louis</forename><surname>Giscard</surname></persName>
							<email>pierre-louis.giscard@york.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of York</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
							<email>richard.wilson@york.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of York</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On Valid Optimal Assignment Kernels and Applications to Graph Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T19:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The success of kernel methods has initiated the design of novel positive semidefinite functions, in particular for structured data. A leading design paradigm for this is the convolution kernel, which decomposes structured objects into their parts and sums over all pairs of parts. Assignment kernels, in contrast, are obtained from an optimal bijection between parts, which can provide a more valid notion of similarity. In general however, optimal assignments yield indefinite functions, which complicates their use in kernel methods. We characterize a class of base kernels used to compare parts that guarantees positive semidefinite optimal assignment kernels. These base kernels give rise to hierarchies from which the optimal assignment kernels are computed in linear time by histogram intersection. We apply these results by developing the Weisfeiler-Lehman optimal assignment kernel for graphs. It provides high classification accuracy on widely-used benchmark data sets improving over the original Weisfeiler-Lehman kernel.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The various existing kernel methods can conveniently be applied to any type of data, for which a kernel is available that adequately measures the similarity between any two data objects. This includes structured data like images <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b10">11]</ref>, 3d shapes <ref type="bibr" target="#b0">[1]</ref>, chemical compounds <ref type="bibr" target="#b7">[8]</ref> and proteins <ref type="bibr" target="#b3">[4]</ref>, which are often represented by graphs. Most kernels for structured data decompose both objects and add up the pairwise similarities between their parts following the seminal concept of convolution kernels proposed by Haussler <ref type="bibr" target="#b11">[12]</ref>. In fact, many graph kernels can be seen as instances of convolution kernels under different decompositions <ref type="bibr" target="#b22">[23]</ref>. A fundamentally different approach with good prospects is to assign the parts of one objects to the parts of the other, such that the total similarity between the assigned parts is maximum possible. Finding such a bijection is known as assignment problem and well-studied in combinatorial optimization <ref type="bibr" target="#b5">[6]</ref>. This approach has been successfully applied to graph comparison, e.g., in general graph matching <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b16">17]</ref> as well as in kernel-based classification <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b0">1]</ref>. In contrast to convolution kernels, assignments establish structural correspondences and thereby alleviate the problem of diagonal dominance at the same time. However, the similarities derived in this way are not necessarily positive semidefinite (p.s.d.) <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref> and hence do not give rise to valid kernels, severely limiting their use in kernel methods.</p><p>Our goal in this paper is to consider a particular class of base kernels which give rise to valid assignment kernels. In the following we use the term valid to mean a kernel which is symmetric and positive semidefinite. We formalize the considered problem: Let [X ] n denote the set of all n-element subsets of a set X and B(X, Y ) the set of all bijections between X, Y in [X ] n for n ? N. We study the optimal assignment kernel K k B on [X ] n defined as</p><formula xml:id="formula_0">K k B (X, Y ) = max B?B(X,Y ) W (B), where W (B) = (x,y)?B k(x, y)<label>(1)</label></formula><p>and k is a base kernel on X . For clarity of presentation we assume n to be fixed. In order to apply the kernel to sets of different cardinality, we may fill up the smaller set by new objects z with k(z, x) = 0 for all x ? X without changing the result.</p><p>Related work. Correspondence problems have been extensively studied in object recognition, where objects are represented by sets of features often called bag of words. Grauman and Darrell proposed the pyramid match kernel that seeks to approximate correspondences between points in R d by employing a space-partitioning tree structure and counting how often points fall into the same bin <ref type="bibr" target="#b10">[11]</ref>. An adaptive partitioning with non-uniformly shaped bins was used to improve the approximation quality in high dimensions <ref type="bibr" target="#b9">[10]</ref>. For non-vectorial data, Fr?hlich et al. <ref type="bibr" target="#b7">[8]</ref> proposed kernels for graphs derived from an optimal assignment between their vertices and applied the approach to molecular graphs. However, it was shown that the resulting similarity measure is not necessarily a valid kernel <ref type="bibr" target="#b21">[22]</ref>. Therefore, Vishwanathan et al. <ref type="bibr" target="#b22">[23]</ref> proposed a theoretically well-founded variation of the kernel, which essentially replaces the max-function in Eq. (1) by a soft-max function. Besides introducing an additional parameter, which must be chosen carefully to avoid numerical difficulties, the approach requires the evaluation of a sum over all possible assignments instead of finding a single optimal one. This leads to an increase in running time from cubic to factorial, which is infeasible in practice. Pachauri et al. <ref type="bibr" target="#b15">[16]</ref> considered the problem of finding optimal assignments between multiple sets. The problem is equivalent to finding a permutation of the elements of every set, such that assigning the i-th elements to each other yields an optimal result. Solving this problem allows the derivation of valid kernels between pairs of sets with a fixed ordering. This approach was referred to as transitive assignment kernel in <ref type="bibr" target="#b17">[18]</ref> and employed for graph classification. However, this does not only lead to non-optimal assignments between individual pairs of graphs, but also suffers from high computational costs. Johansson and Dubhashi <ref type="bibr" target="#b13">[14]</ref> derived kernels from optimal assignments by first sampling a fixed set of so-called landmarks. Each data point is then represented by a feature vector, where each component is the optimal assignment similarity to a landmark. Various general approaches to cope with indefinite kernels have been proposed, in particular, for support vector machines (see <ref type="bibr" target="#b14">[15]</ref> and references therein). Such approaches should principally be used in applications, where similarities cannot be expressed by positive semidefinite kernels.</p><p>Our contribution. We study optimal assignment kernels in more detail and investigate which base kernels lead to valid optimal assignment kernels. We characterize a specific class of kernels we refer to as strong and show that strong kernels are equivalent to kernels obtained from a hierarchical partition of the domain of the kernel. We show that for strong base kernels the optimal assignment (i) yields a valid kernel; and (ii) can be computed in linear time given the associated hierarchy. While the computation reduces to histogram intersection similar to the pyramid match kernel <ref type="bibr" target="#b10">[11]</ref>, our approach is in no way restricted to specific objects like points in R d . We demonstrate the versatility of our results by deriving novel graph kernels based on optimal assignments, which are shown to improve over their convolution-based counterparts. In particular, we propose the Weisfeiler-Lehman optimal assignment kernel, which performs favourable compared to state-of-the-art graph kernels on a wide range of data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>Before continuing with our contribution, we begin by introducing some key notation for kernels and trees which will be used later. A (valid) kernel on a set X is a function k : X ? X ? R such that there is a real Hilbert space H and a mapping ? : X ? H such that k(x, y) = ?(x), ?(y) for all x, y in X , where ?, ? denotes the inner product of H. We call ? a feature map, and H a feature space. Equivalently, a function k : X ? X ? R is a kernel if and only if for every subset</p><formula xml:id="formula_1">{x 1 , . . . , x n } ? X the n ? n matrix defined by [m] i,j = k(x i , x j ) is p.s.d.</formula><p>The Dirac kernel k ? is defined by k ? (x, y) = 1, if x = y and 0 otherwise. We consider simple undirected graphs G = (V, E), where V (G) = V is the set of vertices and E(G) = E the set of edges. An edge {u, v} is for short denoted by uv or vu, where both refer to the same edge. A graph with a unique path between any two vertices is a tree. A rooted tree is a tree T with a distinguished vertex r ? V (T ) called root. The vertex following v on the path to the root r is called parent of v and denoted by p(v), where p(r) = r. The vertices on this path are called ancestors of v and the depth of v is the number of edges on the path. The lowest common ancestor LCA(u, v) of two vertices u and v in a rooted tree is the unique vertex with maximum depth that is an ancestor of both u and v.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Strong kernels and hierarchies</head><p>In this section we introduce a restricted class of kernels that will later turn out to lead to valid optimal assignment kernels when employed as base kernel. We provide two different characterizations of this class, one in terms of an inequality constraint on the kernel values, and the other by means of a hierarchy defined on the domain of the kernel. The latter will provide the basis for our algorithm to compute valid optimal assignment kernels efficiently. We first consider similarity functions fulfilling the requirement that for any two objects there is no third object that is more similar to each of them than the two to each other. We will see later in Section 3.1 that every such function indeed is p.s.d. and hence a valid kernel.</p><formula xml:id="formula_2">Definition 1 (Strong Kernel). A function k : X ? X ? R ?0 is called strong kernel if k(x, y) ? min{k(x, z), k(z, y)} for all x, y, z ? X .</formula><p>Note that a strong kernel requires that every object is most similar to itself, i.e., k(x, x) ? k(x, y) for all x, y ? X . In the following we introduce a restricted class of kernels that is derived from a hierarchy on the set X . As we will see later in Theorem 1 this class of kernels is equivalent to strong kernels according to Definition 1. Such hierarchies can be systematically constructed on sets of arbitrary objects in order to derive strong kernels. We commence by fixing the concept of a hierarchy formally. Let T be a rooted tree such that the leaves of T are the elements of X . Each inner vertex v in T corresponds to a subset of X comprising all leaves of the subtree rooted at v. Therefore the tree T defines a family of nested subsets of X . Let w : V (T ) ? R ?0 be a weight function such that w(v) ? w(p(v)) for all v in T . We refer to the tuple (T, w) as a hierarchy. Definition 2 (Hierarchy-induced Kernel). Let H = (T, w) be a hierarchy on X , then the function defined as k(x, y) = w(LCA(x, y)) for all x, y in X is the kernel on X induced by H.</p><p>We show that Definitions 1 and 2 characterize the same class of kernels. Lemma 1. Every kernel on X that is induced by a hierarchy on X is strong.</p><p>Proof. Assume there is a hierarchy (T, w) that induces a kernel k that is not strong. Then there are x, y, z ? X with k(x, y) &lt; min{k(x, z), k(z, y)} and three vertices a = LCA(x, z), b = LCA(z, y) and c = LCA(x, y) with w(c) &lt; w(a) and w(c) &lt; w(b). The unique path from x to the root contains a and the path from y to the root contains b, both paths contain c. Since weights decrease along paths, the assumption implies that a, b, c are pairwise distinct and c is an ancestor of a and b. Thus, there must be a path from z via a to c and another path from z via b to c. Hence, T is not a tree, contradicting the assumption.</p><p>We show constructively that the converse holds as well. Lemma 2. For every strong kernel k on X there is a hierarchy on X that induces k.</p><p>Proof (Sketch). We incrementally construct a hierarchy on X that induces k by successive insertion of elements from X . In each step the hierarchy induces k restricted to the inserted elements and eventually induces k after insertion of all elements. Initially, we start with a hierarchy containing just one element x ? X with w(x) = k(x, x). The key to all following steps is that there is a unique way to extend the hierarchy: Let X i ? X be the first i elements in the order of insertion and let H i = (T i , w i ) be the hierarchy after the i-th step. A leaf representing the next element z can be grafted onto H i to form a hierarchy H i+1 that induces k restricted to </p><formula xml:id="formula_3">X i+1 = X i ? {z}. Let (a) Hi b 1 b 2 = c b 3 b LCA(x, c) x p z (b) Hi+1 for B = {b1, b2, b3} b p z (c) Hi+1 for |B| = 1</formula><formula xml:id="formula_4">B = {x ? X i : k(x, z) = k max }, where k max = max y?Xi k(y, z).</formula><p>There is a unique vertex b, such that B are the leaves of the subtree rooted at b, cf. <ref type="figure" target="#fig_0">Fig. 1</ref>. We obtain H i+1 by inserting a new vertex p with child z into T i , such that p becomes the parent of b, cf. <ref type="figure" target="#fig_0">Fig. 1</ref></p><formula xml:id="formula_5">(b), (c). We set w i+1 (p) = k max , w i+1 (z) = k(z, z) and w i+1 (x) = w i (x) for all x ? V (T i ). Let k be the kernel induced by H i+1 . Clearly, k (x, y) = k(x, y) for all x, y ? X i . According to the construction k (z, x) = k max = k(z, x) for all x ? B. For all x / ? B we have LCA(z, x) = LCA(c, x) for any c ? B, see Fig. 1(b). For strong kernels k(x, c) ? min{k(x, z), k(z, c)} = k(x, z) and k(x, z) ? min{k(x, c), k(c, z)} = k(x, c), since k(c, z) = k max . Thus k(z, x) = k(c, x) must hold and consequently k (z, x) = k(z, x).</formula><p>Note that a hierarchy inducing a specific strong kernel is not unique: Adjacent inner vertices with the same weight can be merged, and vertices with just one child can be removed without changing the induced kernel. Combining Lemmas 1 and 2 we obtain the following result. Theorem 1. A kernel k on X is strong if and only if it is induced by a hierarchy on X .</p><p>As a consequence of the above theorem the number of values a strong kernel on n objects may take is bounded by the number of vertices in a binary tree with n leaves, i.e., for every strong kernel k on X we have | img(k)| ? 2|X | ? 1. The Dirac kernel is a common example of a strong kernel, in fact, every kernel k : X ? X ? R ?0 with | img(k)| = 2 is strong. The definition of a strong kernel and its relation to hierarchies is reminiscent of related concepts for distances: A metric d on X is an ultrametric if d(x, y) ? max{d(x, z), d(z, y)} for all x, y, z ? X . For every ultrametric d on X there is a rooted tree T with leaves X and edge weights, such that (i) d is the path length between leaves in T , (ii) the path lengths from a leaf to the root are all equal. Indeed, every ultrametric can be embedded into a Hilbert space <ref type="bibr" target="#b12">[13]</ref> and thus the associated inner product is a valid kernel. Moreover, it can be shown that this inner product always is a strong kernel. However, the concept of strong kernels is more general: there are strong kernels k such that the associated kernel metric d k (x, y) = ?(x) ? ?(y) is not an ultrametric. The distinction originates from the self-similarities, which in strong kernels, can be arbitrary provided that they fulfil k(x, x) ? k(x, y) for all x, y in X . This degree of freedom is lost when considering distances. If we require all self-similarities of a strong kernel to be equal, then the associated kernel metric always is an ultrametric. Consequently, strong kernels correspond to a superset of ultrametrics. We explicitly define a feature space for general strong kernels in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Feature maps of strong kernels</head><p>We use the property that every strong kernel is induced by a hierarchy to derive feature vectors for strong kernels. Let (T, w) be a hierarchy on X that induces the strong kernel k. We define the additive weight function ? :</p><formula xml:id="formula_6">V (T ) ? R ?0 as ?(v) = w(v) ? w(p(v))</formula><p>and ?(r) = w(r) for the root r. Note that the property of a hierarchy assures that the difference is non-negative. For v ? V (T ) let P (v) ? V (T ) denote the vertices in T on the path from v to the root r.</p><p>We consider the mapping ? : X ? R t , where t = |V (T )| and the components indexed by v ? V (T ) are</p><formula xml:id="formula_7">[?(x)] v = ?(v), if v ? P (x) 0,</formula><p>otherwise.  </p><formula xml:id="formula_8">r v a b c ?(a) = ? 1, ? 2, ? 1, 0, 0 ?(b) = ? 1, ? 2, 0, ? 2, 0 ?(c) = ? 1, 0, 0, 0, ? 1 (c) Feature vectors</formula><formula xml:id="formula_9">?(x) ?(y) = v?V (T ) [?(x)] v [?(y)] v = v?P (c) ?(v) 2 = w(c) = k(x, y),</formula><p>since according to the definition the only non-zero products contributing to the sum over v ? V (T ) are those in P (x) ? P (y) = P (c). <ref type="figure">Figure 2</ref> shows an example of a strong kernel, an associated hierarchy and the derived feature vectors. As a consequence of Theorem 1 and Proposition 1, strong kernels according to Definition 1 are indeed valid kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Valid kernels from optimal assignments</head><p>We consider the function K k B on [X ] n according to Eq. (1) under the assumption that the base kernel k is strong. Let (T, w) be a hierarchy on X which induces k. For a vertex v ? V (T ) and a set X ? X , we denote by X v the subset of X that is contained in the subtree rooted at v. We define the histogram H k of a set X ? [X ] n w.r.t. the strong base kernel k as H k (X) = x?X ?(x) ? ?(x), where ? is the feature map of the strong base kernel according to Section 3.1 and ? denotes the element-wise product.</p><formula xml:id="formula_10">Equivalently, [H k (X)] v = ?(v) ? |X v | for v ? V (T ). The histogram intersection kernel [20] is defined as K (g, h) = t i=1 min{[g] i ,</formula><p>[h] i }, t ? N, and known to be a valid kernel on R t <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5]</ref>. Theorem 2. Let k be a strong kernel on X and the histograms H k defined as above, then</p><formula xml:id="formula_11">K k B (X, Y ) = K H k (X), H k (Y ) for all X, Y ? [X ] n . Proof.</formula><p>Let (T, w) be a hierarchy inducing the strong base kernel k. We rewrite the weight of an assignment B as sum of weights of vertices in T . Since</p><formula xml:id="formula_12">k(x, y) = w(LCA(x, y)) = v?P (x)?P (y) ?(v), we have W (B) = (x,y)?B k(x, y) = v?V (T ) c v ? ?(v),</formula><p>where c v counts how often v appears simultaneously in P (x) and P (y) in total for all (x, y) ? B. For the histogram intersection kernel we obtain</p><formula xml:id="formula_13">K (H k (X), H k (Y )) = v?V (T ) min{?(v) ? |X v |, ?(v) ? |Y v |} = v?V (T ) min{|X v |, |Y v |} ? ?(v).</formula><p>Since every assignment B ? B(X, Y ) is a bijection, each x ? X and y ? Y appears only once in B and c v ? min{|X v |, |Y v |} follows. It remains to show that the above inequality is tight for an optimal assignment. We construct such an assignment by the following greedy approach: We perform a bottom-up traversal on the hierarchy starting with the leaves. For every vertex v in the hierarchy we arbitrarily pair the objects in X v and Y v that are not yet contained in the assignment. Note that no element in X v has been assigned to an element in Y \ Y v , and no element in Y v to an element from X \ X v . Hence, at every vertex v we have  <ref type="figure" target="#fig_3">Figure 3</ref> illustrates the relation between the optimal assignment kernel employing a strong base kernel and the histogram intersection kernel. Note that a vertex v ? V (T ) with ?(v) = 0 does not contribute to the histogram intersection kernel and can be omitted. In particular, for any two objects x 1 , x 2 ? X with k(x 1 , y) = k(x 2 , y) for all y ? X we have ?(x 1 ) = ?(x 2 ) = 0. There is no need to explicitly represent such leaves in the hierarchy, yet their multiplicity must be considered to determine the number of leaves in the subtree rooted at an inner vertex, cf. <ref type="figure" target="#fig_3">Fig. 2, 3</ref>. Corollary 1. If the base kernel k is strong, then the function K k B is a valid kernel.</p><formula xml:id="formula_14">c v = min{|X v |, |Y v |} vertices from X v assigned to vertices in Y v .</formula><p>Theorem 2 implies not only that optimal assignments give rise to valid kernels for strong base kernels, but also allows to compute them by histogram intersection. Provided that the hierarchy is known, bottom-up computation of histograms and their intersection can both be performed in linear time, while the general Hungarian method would require cubic time to solve the assignment problem <ref type="bibr" target="#b5">[6]</ref>. Corollary 2. Given a hierarchy inducing k, K k B (X, Y ) can be computed in time O(|X| + |Y |).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Graph kernels from optimal assignments</head><p>The concept of optimal assignment kernels is rather general and can be applied to derive kernels on various structures. In this section we apply our results to obtain novel graph kernels, i.e., kernels of the form K : G ? G ? R, where G denotes the set of graphs. We assume that every vertex v is equipped with a categorical label given by ? (v). Labels typically arise from applications, e.g., in a graph representing a chemical compound the labels may indicate atom types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Optimal assignment kernels on vertices and edges</head><p>As a baseline we propose graph kernels on vertices and edges. The vertex optimal assignment kernel (V-OA) is defined as</p><formula xml:id="formula_15">K(G, H) = K k B (V (G), V (H)),</formula><p>where k is the Dirac kernel on vertex labels. Analogously, the edge optimal assignment kernel (E-OA) is given by K(G, H) = K k B (E(G), E(H)), where we define k(uv, st) = 1 if at least one of the mappings (u ? s, v ? t) and (u ? t, v ? s) maps vertices with the same label only; and 0 otherwise. Since these base kernels are Dirac kernels, they are strong and, consequently, V-OA and E-OA are valid kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Weisfeiler-Lehman optimal assignment kernels</head><p>Weisfeiler-Lehman kernels are based on iterative vertex colour refinement and have been shown to provide state-of-the-art prediction performance in experimental evaluations <ref type="bibr" target="#b18">[19]</ref>. These kernels employ the classical 1-dimensional Weisfeiler-Lehman heuristic for graph isomorphism testing and consider subtree patterns encoding the neighbourhood of each vertex up to a given distance. For a parameter h and a graph G with initial labels ? , a sequence (? 0 , . . . , ? h ) of refined labels referred to as colours is computed, where ? 0 = ? and ? i is obtained from ? i?1 by the following procedure:  <ref type="figure">Figure 4</ref>: A graph G with uniform initial colours ?0 and refined colours ?i for i ? {1, . . . , 3} (a), the feature vector of G for the Weisfeiler-Lehman subtree kernel (b) and the associated hierarchy (c). Note that the vertices of G are the leaves of the hierarchy, although not shown explicitly in <ref type="figure">Fig. 4(c)</ref>. Sort the multiset of colours {? i?1 (u) : vu ? E(G)} for every vertex v lexicographically to obtain a unique sequence of colours and add ? i?1 (v) as first element. Assign a new colour ? i (v) to every vertex v by employing a one-to-one mapping from sequences to new colours. <ref type="figure">Figure 4(a)</ref> illustrates the refinement process. The Weisfeiler-Lehman subtree kernel (WL) counts the vertex colours two graphs have in common in the first h refinement steps and can be computed by taking the dot product of feature vectors, where each component counts the occurrences of a colour, see <ref type="figure">Fig. 4(b)</ref>. We propose the Weisfeiler-Lehman optimal assignment kernel (WL-OA), which is defined on the vertices like OA-V, but employs the non-trivial base kernel</p><formula xml:id="formula_16">? 6 ? 5 ? 1 ? 4 ? 1 ? 1 ? 2 ? 1 ? 2 ? 1 (b) Feature vector {a, b} {c, d} {f } {e} (c) Associated hierarchy</formula><formula xml:id="formula_17">k(u, v) = h i=0 k ? (? i (u), ? i (v)).<label>(2)</label></formula><p>This base kernel corresponds to the number of matching colours in the refinement sequence. More intuitively, the base kernel value reflects to what extent the two vertices have a similar neighbourhood. Let V be the set of all vertices of graphs in G, we show that the refinement process defines a hierarchy on V, which induces the base kernel of Eq. (2). Each vertex colouring ? i naturally partitions V into colour classes, i.e., sets of vertices with the same colour. Since the refinement takes the colour ? i (v) of a vertex v into account when computing ? i+1 (v), the implication</p><formula xml:id="formula_18">? i (u) = ? i (v) ? ? i+1 (u) = ? i+1 (v)</formula><p>holds for all u, v ? V. Hence, the colour classes induced by ? i+1 are at least as fine as those induced by ? i . Moreover, the sequence (? i ) 0?i?h gives rise to a family of nested subsets, which can naturally be represented by a hierarchy (T, w), see <ref type="figure">Fig. 4(c)</ref> for an illustration. When assuming ?(v) = 1 for all vertices v ? V (T ), the hierarchy induces the kernel of Eq. (2). We have shown that the base kernel is strong and it follows from Corollary 1 that WL-OA is a valid kernel. Moreover, it can be computed from the feature vectors of the Weisfeiler-Lehman subtree kernel in linear time by histogram intersection, cf. Theorem 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental evaluation</head><p>We report on the experimental evaluation of the proposed graph kernels derived from optimal assignments and compare with state-of-the-art convolution kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Method and Experimental Setup</head><p>We performed classification experiments using the C-SVM implementation LIBSVM <ref type="bibr" target="#b6">[7]</ref>. We report mean prediction accuracies and standard deviations obtained by 10-fold cross-validation repeated 10 times with random fold assignment. Within each fold all necessary parameters were selected by crossvalidation based on the training set. This includes the regularization parameter C, kernel parameters where applicable and whether to normalize the kernel matrix. All kernels were implemented in Java and experiments were conducted using Oracle Java v1.8.0 on an Intel Core i7-3770 CPU at 3.4GHz (Turbo Boost disabled) with 16GB of RAM using a single processor only.</p><p>Kernels. As a baseline we implemented the vertex kernel (V) and edge kernel (E), which are the dot products on vertex and edge label histograms, respectively, where an edge label consist of the labels of its endpoints. V-OA and E-OA are the related optimal assignment kernels as described in Sec. 5.1. For the Weisfeiler-Lehman kernels WL and WL-OA, see Section 5.2, the parameter h was chosen from {0, ..., 7}. In addition we implemented a graphlet kernel (GL) and the shortest-path kernel (SP) <ref type="bibr" target="#b2">[3]</ref>. GL is based on connected subgraphs with three vertices taking labels into account similar to the approach used in <ref type="bibr" target="#b18">[19]</ref>. For SP we used the Dirac kernel to compare path lengths and computed the kernel by explicit feature maps, cf. <ref type="bibr" target="#b18">[19]</ref>. Note that all kernels not identified as optimal assignment kernels by the suffix OA are convolution kernels.</p><p>Data sets. We tested on widely-used graph classification benchmarks from different domains, cf. <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b23">24]</ref>: MUTAG, PTC-MR, NCI1 and NCI109 are graphs derived from small molecules, PROTEINS, D&amp;D and ENZYMES represent macromolecules, and COLLAB and REDDIT are derived from social networks. <ref type="bibr" target="#b0">1</ref> All data sets have two class labels except ENZYMES and COLLAB, which are divided into six and three classes, respectively. The social network graphs are unlabelled and we considered all vertices uniformly labelled. All other graph data sets come with vertex labels. Edge labels, if present, were ignored since they are not supported by all graph kernels under comparison. <ref type="table" target="#tab_0">Table 1</ref> summarizes the classification accuracies. We observe that optimal assignment kernels on most data sets improve over the prediction accuracy obtained by their convolution-based counterpart. The only distinct exception is MUTAG. The extent of improvement on the other data sets varies, but is in particular remarkable for ENZYMES and REDDIT. This indicates that optimal assignment kernels provide a more valid notion of similarity than convolution kernels for these classification tasks. The most successful kernel is WL-OA, which almost consistently improves over WL and performs best on seven of the nine data sets. WL-OA provides the second best accuracy on D&amp;D and ranks in the middle of the field for MUTAG. For these two data set the difference in accuracy between the kernels is small and even the baseline kernels perform notably well. The time to compute the quadratic kernel matrix was less that one minute for all kernels and data sets with exception of SP on D&amp;D (29 min) and REDDIT (2 h) as well as GL on COLLAB (28 min). The running time to compute the optimal assignment kernels by histogram intersection was consistently on par with the running time required for the related convolution kernels and orders of magnitude faster than their computation by the Hungarian method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results and discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and future work</head><p>We have characterized the class of strong kernels leading to valid optimal assignment kernels and derived novel effective kernels for graphs. The reduction to histogram intersection makes efficient computation possible and known speed-up techniques for intersection kernels can directly be applied (see, e.g., <ref type="bibr" target="#b20">[21]</ref> and references therein). We believe that our results may form the basis for the design of new kernels, which can be computed efficiently and adequately measure similarity.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustrative example for the construction of the hierarchy on i + 1 objects (b), (c) from the hierarchy on i objects (a) following the procedure used in the proof of Lemma 2. The inserted leaf z is highlighted in red, its parent p with weight w(p) = kmax in green and b in blue, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :Proposition 1 .</head><label>21</label><figDesc>The matrix of a strong kernel on three objects (a) induced by the hierarchy (b) and the derived feature vectors (c). A vertex u in (b) is annotated by its weights w(u); ?(u). Let k be a strong kernel on X . The function ? defined as above is a feature map of k, i.e., k(x, y) = ?(x) ?(y) for all x, y ? X . Proof. Given arbitrary x, y ? X and let c = LCA(x, y). The dot product yields</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>An assignment instance (a) for X, Y ? [X ] 5 and the derived histograms (b). The set X contains three distinct vertices labelled a and the set Y two distinct vertices labelled b and c. Taking the multiplicities into account the histograms are obtained from the hierarchy of the base kernel k depicted inFig. 2. The optimal assignment yields a value of K k B (X, Y ) = 15, where grey, green, brown, red and orange edges have weight 1, 2, 3, 4 and 5, respectively. The histogram intersection kernel gives K (H k (X), H k (Y )) = min{5, 5} + min{8, 6} + min{3, 1} + min{2, 4} + min{1, 2} = 15.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Graph G with refined colours</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Classification accuracies and standard deviations on graph data sets representing small molecules, macromolecules and social networks. MUTAG PTC-MR NCI1 NCI109 PROTEINS D&amp;D ENZYMES COLLAB REDDIT V 85.4?0.7 57.8?0.9 64.6?0.1 63.6?0.2 71.9?0.4 78.2?0.4 23.4?1.1 56.2?0.0 75.3?0.1 V-OA 82.5?1.1 56.4?1.8 65.6?0.3 65.1?0.4 73.8?0.5 78.8?0.3 35.1?1.1 59.3?0.1 77.8?0.1 E 85.2?0.6 57.3?0.7 66.2?0.1 64.9?0.1 73.5?0.2 78.3?0.5 27.4?0.8 52.0?0.0 75.1?0.1 E-OA 81.0?1.1 56.3?1.7 68.9?0.3 68.7?0.2 74.5?0.6 79.0?0.4 37.4?1.8 68.2?0.3 79.8?0.2 WL 86.0?1.7 61.3?1.4 85.8?0.2 85.9?0.3 75.6?0.4 79.0?0.4 53.7?1.4 79.1?0.1 80.8?0.4 WL-OA 84.5?1.7 63.6?1.5 86.1?0.2 86.3?0.2 76.4?0.4 79.2?0.4 59.9?1.1 80.7?0.1 89.3?0.3 GL 85.2?0.9 54.7?2.0 70.5?0.2 69.3?0.2 72.7?0.6 79.7?0.7 30.6?1.2 64.7?0.1 60.1?0.2 SP 83.0?1.4 58.9?2.2 74.5?0.3 73.0?0.3 75.8?0.5 79.0?0.6 42.6?1.6 58.8?0.2 84.6?0.2</figDesc><table><row><cell>Data Set</cell></row><row><cell>Kernel</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The data sets, further references and statistics are available from http://graphkernels.cs. tu-dortmund.de.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments N. M. Kriege is supported by the German Science Foundation (DFG) within the Collaborative Research Center SFB 876 "Providing Information by Resource-Constrained Data Analysis", project A6 "Resource-efficient Graph Mining". P.-L. Giscard is grateful for the financial support provided by the Royal Commission for the Exhibition of 1851.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An aligned subtree kernel for weighted graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn., ICML 2015</title>
		<meeting>Int. Conf. Mach. Learn., ICML 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="30" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Histogram intersection kernel for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Odone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Verri</surname></persName>
		</author>
		<idno>III-513-16</idno>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Image Proc., ICIP 2003</title>
		<imprint>
			<date type="published" when="2003-09" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Shortest-path kernels on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Data Min., ICDM &apos;05</title>
		<meeting>IEEE Int. Conf. Data Min., ICDM &apos;05<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Protein function prediction via graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sch?nauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="56" />
			<date type="published" when="2005-06" />
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generalized histogram intersection kernel for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boughorbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Tarel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<idno>III-161-4</idno>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Image Proc., ICIP 2005</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Assignment Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Burkard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dell&amp;apos;amico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Martello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>SIAM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Optimal assignment kernels for attributed molecular graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fr?hlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Wegner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sieker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn., ICML &apos;05</title>
		<meeting>Int. Conf. Mach. Learn., ICML &apos;05</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Exact and approximate graph matching using random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maggini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1100" to="1111" />
			<date type="published" when="2005-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Approximate correspondences in high dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS &apos;06</title>
		<editor>B. Sch?lkopf, J. C. Platt, and T. Hoffman</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="505" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The pyramid match kernel: Efficient learning with sets of features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="725" to="760" />
			<date type="published" when="2007-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Convolution kernels on discrete structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Haussler</surname></persName>
		</author>
		<idno>UCSC-CRL-99-10</idno>
		<imprint>
			<date type="published" when="1999" />
			<pubPlace>Santa Cruz, CA, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ultrametric spaces and related hilbert spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Ismagilov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Notes</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="186" to="197" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning with similarity functions on graphs using matchings of geometric embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dubhashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining, KDD &apos;15</title>
		<meeting>ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining, KDD &apos;15</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="467" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning SVM in Krein spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Loosli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Canu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>PP</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Solving the multi-way matching problem by permutation synchronization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pachauri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS &apos;13</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1860" to="1868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Approximate graph edit distance computation by means of bipartite graph matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Riesen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vis. Comp</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="950" to="959" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Transitive assignment kernels for structural classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schiavinato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gasparetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torsello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Workshop Similarity-Based Pattern Recognit., SIMBAD &apos;15</title>
		<editor>A. Feragen, M. Pelillo, and M. Loog</editor>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="146" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Weisfeiler-Lehman graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Van Leeuwen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2539" to="2561" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Color indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comp. Vis</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="32" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient additive kernels via explicit feature maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="480" to="492" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The optimal assignment kernel is not positive definite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Vert</surname></persName>
		</author>
		<idno>abs/0801.4061</idno>
		<imprint>
			<date type="published" when="2008" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Borgwardt. Graph kernels. J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1201" to="1242" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yanardag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining, KDD &apos;15</title>
		<meeting>ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining, KDD &apos;15</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1365" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
