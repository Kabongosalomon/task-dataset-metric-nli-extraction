<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE Tensor Representations for Action Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Cherian</surname></persName>
						</author>
						<title level="a" type="main">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE Tensor Representations for Action Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">, SUBMITTED, DECEMBER 2018, ACCEPTED, DECEMBER 2019 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-CNN</term>
					<term>3D Skeletons</term>
					<term>Action Recognition</term>
					<term>Aggregation</term>
					<term>Kernels</term>
					<term>Higher-order Tensors</term>
					<term>HOSVD</term>
					<term>Power Normalization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Human actions in video sequences are characterized by the complex interplay between spatial features and their temporal dynamics. In this paper, we propose novel tensor representations for compactly capturing such higher-order relationships between visual features for the task of action recognition. We propose two tensor-based feature representations, viz. (i) sequence compatibility kernel (SCK) and (ii) dynamics compatibility kernel (DCK). SCK builds on the spatio-temporal correlations between features, whereas DCK explicitly models the action dynamics of a sequence. We also explore generalization of SCK, coined SCK ?, that operates on subsequences to capture the local-global interplay of correlations, which can incorporate multi-modal inputs e.g., skeleton 3D bodyjoints and per-frame classifier scores obtained from deep learning models trained on videos. We introduce linearization of these kernels that lead to compact and fast descriptors. We provide experiments on (i) 3D skeleton action sequences, (ii) fine-grained video sequences, and (iii) standard non-fine-grained videos. As our final representations are tensors that capture higher-order relationships of features, they relate to co-occurrences for robust fine-grained recognition <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. We use higher-order tensors and so-called Eigenvalue Power Normalization (EPN) which have been long speculated to perform spectral detection of higher-order occurrences <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, thus detecting fine-grained relationships of features rather than merely count features in action sequences. We prove that a tensor of order r, built from Z * dimensional features, coupled with EPN indeed detects if at least one higher-order occurrence is 'projected' into one of its Z * r subspaces of dim. r represented by the tensor, thus forming a Tensor Power Normalization metric endowed with Z * r such 'detectors'. ! We present experiments on seven standard datasets, namely (i) UTKinect-Actions [31], (ii) Florence3D-Actions [32], (iii) MSR-Action3D [33] and (iv) HMDB-51[34] datasets as well as two fine-grained datasets (v) NTU RGB+D [35], (vi) MPII Cooking Activities [25] and (vii) Kinetics <ref type="bibr" target="#b35">[36]</ref>. We use the first three datasets as a source of 3D body joint sequences (as well as Kinetics), NTU for both 3D body joint sequences, and videos with RGB frames and optical flow frames, and HMDB-51 and MPII Cooking Activities for videos with RGB and optical flow frames. We show that our extensions can still achieve state-of-theart accuracy two years after SCK/DCK were proposed <ref type="bibr" target="#b28">[29]</ref>. To summarize:</p><p>i. We design sequence and dynamics compatibility kernels that capture spatio-temporal evolution of 3D skeleton body-joints. ii. We derive linearizations of these kernels by tensors. iii. We extend these kernels to aggregation over multiple subsequences and CNN classifier scores. iv. We conduct a novel theoretical analysis of Tensor Power Normalization which connects it to subspace methods. We are the first to conduct a theoretical analysis of higher-order pooling with Tensor Power Normalization in Section D, and use it for generic/fine-grained action recognition.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Human action recognition is a central problem in computer vision with potential impact in surveillance, human-robot interaction, elderly assistance systems, etc. While there have been significant advancements in this area over the past few years, action recognition in unconstrained settings still remains a challenge. Some papers simplify the problem from using RGB cameras to the use of Microsoft Kinect or the OpenPose library <ref type="bibr" target="#b4">[5]</ref> to localize human body-parts, produce moving 3D skeletons <ref type="bibr" target="#b5">[6]</ref> and use them for recognition. However, skeletons can be noisy due to badly localized body-parts, self-occlusions, and sensor errors. Similarly, a popular strategy of classifying RGB frames into actions followed by average/max-pooling fails as only correlations of some features are informative <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>. Such observations motivate the need for higher-order reasoning on 3D skeletons/frame-wise CNN classifier scores taking action recognition toward fine-grained modeling.</p><p>Recent approaches which work with skeletons can be mainly divided into two perspectives, namely (i) generative models that assume the skeleton points are produced by a latent dynamic model <ref type="bibr" target="#b9">[10]</ref> corrupted by noise and (ii) discriminative approaches that generate compact representations of sequences on which classifiers are trained <ref type="bibr" target="#b10">[11]</ref>. Due to the huge configuration space of 3D actions and the unavailability of sufficient training data, discriminative approaches have been more successful. In this line of research, the main idea is to compactly represent the spatiotemporal evolution of 3D skeletons, and later train classifiers on ? P. <ref type="bibr">Koniusz</ref>  these representations to recognize actions. Fortunately, there is a definitive structure to motions of 3D joints relative to each other due to the connectivity and length constraints of bodyparts. Such constraints have been used with the Lie Algebra <ref type="bibr" target="#b11">[12]</ref>, positive definite matrices <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>, torus manifold <ref type="bibr" target="#b14">[15]</ref>, Hanklet representations <ref type="bibr" target="#b15">[16]</ref>, etc. While modeling actions with explicit manifold assumptions is useful, it is computationally costly. However, action recognition from videos <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref> does not require elaborate skeletal models. A two-stream CNN framework <ref type="bibr" target="#b16">[17]</ref> uses two streams to model RGB frames and optical flow. Tran et al. <ref type="bibr" target="#b17">[18]</ref> use CNNs to learn spatio-temporal filters. Karpathy et al. <ref type="bibr" target="#b18">[19]</ref> apply RGB and optical-flow fusion, whereas approach <ref type="bibr" target="#b19">[20]</ref> combines CNNs with LSTM to model temporal flow. Wang et al. <ref type="bibr" target="#b20">[21]</ref> apply a long-range temporal structure modeling. Tran et al. <ref type="bibr" target="#b21">[22]</ref> study several forms of spatiotemporal convolutions. Recent works on fine-grained activity recognition use CNNs <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref> and the human pose estimation for high-level fine-grained reasoning <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>. Finally, the recent I3D model <ref type="bibr" target="#b27">[28]</ref> 'inflates' 2D CNN filters pretrained on ImageNet to spatio-temporal 3D filters yielding state-of-the-art results.</p><p>In contrast to these approaches, we present a novel representation of actions based on 3D skeleton sequences and the CNN classifier score sequences. We avoid assumptions about the data manifold by capturing higher-order statistics of the body-joints and the classifier score interactions per sequence. To this end, our scheme combines positive definite kernels and higher-order tensors, with the goal of obtaining rich and compact representations that benefit from the non-linearity of radial basis functions (RBF). Such a scheme captures higher-order data statistics <ref type="bibr" target="#b3">[4]</ref>, complex action dynamics <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> and fine-grained relations <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>.</p><p>We present two representations for classification of 3D skeletons. Our first representation, sequence compatibility kernel (SCK), captures the spatio-temporal compatibility of body-joints between two sequences. To this end, we present an RBF kernel arXiv:2012.14371v3 [cs.CV] <ref type="bibr" target="#b27">28</ref> Aug 2021 formulation that jointly captures the spatial and temporal similarity of each body-pose (normalized with respect to the hip position) in a sequence against those in another. We show that tensors generated from third-order outer-products of the linearizations of these kernels are a simple yet powerful representation capturing higher-order statistics of body-parts.</p><p>Our second representation, termed dynamics compatibility kernel (DCK), represents spatio-temporal dynamics of each sequence explicitly. We present a novel RBF kernel formulation that captures the similarity between a pair of body-poses in a given sequence explicitly, and then compare it against such body-pose pairs in other sequences. Such spatio-temporal modeling could be expensive due to the volumetric nature of space and time. However, we show that using an appropriate kernel model can shrink the time-related variable into a small representation of constant size after kernel linearization. With this approach, we can model both spatial and temporal variations in the form of co-occurrences which could otherwise be prohibitive. We show empirically that SCK and DCK are complementary.</p><p>As SCK/DCK work on entire sequences, we formulate an SCK-like kernel over multiple length subsequences as some of subsequences capture the gist of performed actions better than full sequences. To show the versatility of the extended SCK, we apply it to capture spatio-temporal compatibility of frame-wise CNN classifier scores from videos (regular and fine-grained actions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In the first part of our paper, we focus on action recognition from an articulated set of connected body-joints that evolve in time <ref type="bibr" target="#b36">[37]</ref>. A temporal evolution of the human skeleton is very informative for action recognition as shown by Johansson in his seminal experiment involving the moving lights display <ref type="bibr" target="#b37">[38]</ref>. At the simplest level, the human body can be represented as a set of 3D points corresponding to body-joints such as elbow, wrist, knee, ankle, etc. Action dynamics has been modeled using the motion of such 3D points in <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b38">39]</ref>, using joint orientations with respect to a reference axis <ref type="bibr" target="#b39">[40]</ref> and even relative body-joint positions <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref>. In contrast, we represent these 3D body-joints by kernels whose linearization results in higher-order tensors capturing complex statistics. We also note parts-based approaches that use connected body segments <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45]</ref>. For details, see a survey <ref type="bibr" target="#b10">[11]</ref>.</p><p>We also handle the temporal domain differently to other methods. 3D joint locations are modeled as temporal hierarchy of coefficients in <ref type="bibr" target="#b13">[14]</ref>. Pairwise relative positions of joints were modeled in <ref type="bibr" target="#b40">[41]</ref> and combined with a hierarchy of Fourier coefficients to capture temporal evolution of actions. In <ref type="bibr" target="#b41">[42]</ref>, the relative joint positions and their temporal displacements are modeled with respect to the initial frame. In <ref type="bibr" target="#b11">[12]</ref>, the displacements and angles between the body parts are represented as a collection of matrices belonging to SE(3), a special Euclidean group. The temporal domain is handled by the dynamic time warping and Fourier temporal pyramid matching. In contrast, we avoid expensive time warping by modeling the temporal domain with an RBF kernel invariant to local temporal shifts.</p><p>Our scheme also differs from works such as kernel descriptors <ref type="bibr" target="#b45">[46]</ref> that sum gradient orientations over image patches, action recognition via kernelized covariances <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49]</ref>, and a time series kernel <ref type="bibr" target="#b49">[50]</ref> which extracts spatio-temporal autocorrelations. In contrast, our scheme sums over several multiplicative and additive RBF kernels. We capture higher-order statistics by linearizing a polynomial kernel and avoid evaluating costly kernels directly.</p><p>Third-order tensors have been used to form spatio-temporal tensors on videos in <ref type="bibr" target="#b50">[51]</ref>. Non-negative tensor factorization is used for image denoising <ref type="bibr" target="#b51">[52]</ref>, tensors are used for texture rendering <ref type="bibr" target="#b52">[53]</ref> and for face recognition <ref type="bibr">[54]</ref>. A survey of multi-linear algebraic methods for tensor subspace learning is available in <ref type="bibr" target="#b54">[55]</ref>. These methods use a single tensor, whereas we use tensors as descriptors <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b56">57]</ref>. However, we use third-order tensors for action recognition, which poses a set of new challenges.</p><p>For fine-grained action recognition, high-level sophisticated action reasoning <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref> is typically used together with pose estimation systems <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref>. However, these approaches scale poorly to millions of video frames. Human-object interactions in the videos are analyzed in <ref type="bibr" target="#b59">[60]</ref>. Correlations between space-time features are proposed in <ref type="bibr" target="#b60">[61]</ref>.</p><p>Power Normalization approaches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b61">62]</ref> speculate that Eigenvalue Power Normalization prevents so-called burstiness, thus performing spectral detection of higher-order occurrences of features <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, which can be paraphrased as 'do a knife, a hand and a chopping board co-occur together?' rather than 'how many knifes, hands and chopping boards appear in the scene?'</p><p>Moreover, first-order pooling was successfully used for representing action recognition via hallucination <ref type="bibr" target="#b62">[63]</ref>. Papers <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b61">62]</ref> study second-order pooling, power normalizing functions and their taxonomy while fast pooling methods are proposed in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b63">64]</ref>.</p><p>Finally, second-order pooling was successfully used for fewshot action recognition <ref type="bibr" target="#b64">[65]</ref>, few-shot classification <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b66">67]</ref>, fewshot segmentation <ref type="bibr" target="#b67">[68]</ref>, modulating optimization <ref type="bibr" target="#b68">[69]</ref>, style transfer <ref type="bibr" target="#b69">[70,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b72">73]</ref> and action self-supervision <ref type="bibr" target="#b73">[74]</ref>. Noteworthy are also graph convolutional networks <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b76">77]</ref> and embeddings <ref type="bibr" target="#b77">[78]</ref> easily applicable to 3D skeleton action recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>In this section, we review our notations and the necessary background on shift-invariant kernels and their linearizations. <ref type="figure">Figure 1a</ref> illustrates the notion of tensors, their order and modes. Let V ? R d1?d2?d3 denote a third-order tensor. Using the Matlab notation, we refer to the k-th slice of this tensor as V :,:,k , which is a d 1 ? d 2 matrix. For a matrix V ? R d1?d2 and a vector v ? R d3 , the notation V = V ? ? v produces a tensor V ? R d1?d2?d3 whose k-th slice is given by V ? v k , v k being the k-th coefficient of v. <ref type="figure">Figure 1b</ref> illustrates such an outer-product. Symmetric third-order tensors of rank one are formed by the outerproduct of a vector v ? R d in three modes, that is, a rank-one</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Tensor Notations</head><formula xml:id="formula_0">V ? R d?d?d is obtained from v as V = (? ? 3 v (vv T ) ? ? v) which yields V ijk = v i ?v j ?v k , where V ijk represents the ijk-th element of V.</formula><p>Matrices have two modes: the first and second mode correspond to the row and column indexes i and j, respectively. Order r tensors have r modes addressed by V i1...ir where V ? R d1?...?d k ?...?dr and k indicates the mode k. Concatenation of n tensors in mode k is simply stacking them along mode k, denoted as</p><formula xml:id="formula_1">[V i ] ? k i?In ? numpy.concatenate((V 1 , ..., V n ), axis = k ? 1)</formula><p>). I n is an index sequence 1, 2, ..., n. We define the Frobenius norm V F = i,j,k V 2 ijk and the inner-product between X and Y as X , Y = ijk X ijk Y ijk . Also, e z are spanning bases of R Z . Further basics on tensors and tensor algebra can be found in <ref type="bibr" target="#b78">[79]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Kernel Linearization</head><p>Let G ? (u ??) = exp(? u ?? 2 2 /2? 2 ) denote a standard Gaussian RBF kernel centered at? and having a bandwidth ?. Kernel linearization refers to rewriting this G ? as an inner-product of two infinite-dimensional feature maps. To obtain these maps, we use a fast approximation method based on probability product kernels <ref type="bibr" target="#b79">[80]</ref>. Specifically, we employ the inner product of ddimensional isotropic Gaussians given u, u ? R d . Thus, we have:</p><formula xml:id="formula_2">G ? (u??)= 2 ?? 2 d 2 ??R d G ?/ ? 2 (u??) G ?/ ? 2 (???) d?. (1)</formula><p>Eq. (1) is then approximated by replacing the integral with the sum over Z pivots ? 1 , ..., ? Z . Thus, we obtain a feature map ?:</p><formula xml:id="formula_3">?(u; {? i } i?I Z ) = G ?/ ? 2 (u ? ? 1 ), ..., G ?/ ? 2 (u ? ? Z ) T ,<label>(2)</label></formula><p>and</p><formula xml:id="formula_4">G ? (u??) ? ? c?(u), ? c?(?) ,<label>(3)</label></formula><p>where c is a const. Eq. (3) is the linearization of the RBF kernel. Eq. (2) is the feature map. {? i } i?I Z are pivots. As we use 1 dim. signals, we simply cover interval [?1; 1] (or [0; 1]) with Z equally spaced pivots. For clarity, we drop {? i } i?I Z and write ?(u), etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Equivalence between Polynomial Kernels and the Dot-product of Tensors [4]</head><p>For any two Z dim. feature vectors ?,? ? R Z , we have:</p><formula xml:id="formula_5">?,? r = Z i1=1 ... Z ir=1 ? i1?i1 ?...?? ir?ir = ? ? r ?, ? ? r? ,<label>(4)</label></formula><p>where X = (? ? r ?) is defined as X i1...ir = ? i1 ?...?? ir .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PROPOSED APPROACH</head><p>Below, we formulate the problem of action recognition from 3D skeleton sequences, which precedes an exposition of our two kernel formulations for describing actions, followed by their tensor reformulations through kernel linearization. We also introduce Eigenvalue Power Normalization and our improved kernels used  <ref type="figure">Figure 1a</ref> illustrates the notion of tensors, their order and modes. <ref type="figure">Figure 1b</ref> illustrates the matrix-vector order outer-product.</p><p>for action recognition based on skeletons and/or classifier scores obtained from videos passed via CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Statistical Motivation</head><p>Before we outline our higher-order tensor representations, below we motivate the use of higher-order statistics. To compare skeleton sequences/videos, we want to capture distribution of local features/descriptors per sequence e.g., body joints or receptive fields in CNN. The characteristic function</p><formula xml:id="formula_6">? ? (?) = E ??? exp(i? T ?) describes the probability density f ? (?) of a skeleton sequence/video (local features/descriptors ? ? ?).</formula><p>Taylor expansion of the characteristic function per sequence is:</p><formula xml:id="formula_7">E ??? ? r=0 i r r! ?, ? r ? 1 N N n=0 ? r=0 i r r! ? ? r ? n , ? ? r ? (5) = ? r=0 i r r! 1 N N n=0 ? ? r ? n , ? ? r ? = ? r=0 X (r) , i r r! ? ? r ? . Symbol X (r) = 1 N N n=0</formula><p>? ? r ? n defines a tensor descriptor while i is the imaginary number. In principle, with infinite data and infinite moments, one can fully capture f ? (?) which is intractable. In practice, third-order moments work well in what follows while second-order moments are somewhat insufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Problem Formulation</head><p>Suppose we are given a set of 3D human pose skeleton sequences, each pose consisting of J body-keypoints. Further, to simplify our notations, we assume each sequence consists of N skeletons, one per frame <ref type="bibr" target="#b0">1</ref> . We define such a pose sequence ? as:</p><formula xml:id="formula_8">? = x is ? R 3 , i ? I J , s ? I N .<label>(6)</label></formula><p>Further, let each such a sequence ? be associated with one of K action class labels ? I K . Our goal is to use the skeleton sequence ? and generate an action descriptor for this sequence that can be used in a classifier for recognizing the action class. In what follows, we will present two such action descriptors, namely (i) sequence compatibility kernel and (ii) dynamics compatibility kernel, which are formulated using kernel linearization and tensor algebra theories. We present both these kernel formulations next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Sequence Compatibility Kernel</head><p>As alluded to earlier, the main idea of this kernel is to measure the compatibility between two action sequences in terms of the similarity between their skeletons and their temporal order. To this end, we assume each skeleton is centered with respect to <ref type="bibr" target="#b0">1</ref> We assume that all sequences have N frames for simplification of presentation. Our formulations are applicable to sequences of arbitrary lengths e.g., M and N . Thus, we apply in practice G? 3 ( s M ? t N ) in Eq. (7).  <ref type="figure" target="#fig_1">Figure 2c</ref> shows this burden is avoided by linearization -third-order statistics on feature maps ?(xis) and z(s/N ) for joint i are captured in tensor X i and whitened by EPN to obtain Vi which are concatenated over i = 1, ..., J to represent a sequence. The final sequence tensors are vectorized per video by 'vec' and fed to an SVM. . Similarly, we embed the time s/N via function z(?) (also by Eq. <ref type="formula" target="#formula_3">(2)</ref>). Finally, ?r performs the third-order outer-product on concatenated embeddings aggregated next over frames s (note s ). The interpretation: the Gaussians 'soft-divide' the the Cartesian coordinate system along x, y, z direction, resp., and time s/N . Thus, triplets (x, y, z), (x, y, s/N ), (x, z, s/N ) and (y, z, s/N ) assigned into such a 'soft-divided' space capture locally three-way occurrences. They factor out one spatial (or time) variable at a time (note invariance to such a variable).</p><p>one of the body-joints (say, hip). Suppose we are given two such sequences ? A and ? B , each with J joints, and N frames. Further, let x is ? R 3 and y jt ? R 3 correspond to the body-joint coordinates of ? A and ? B , respectively.</p><p>We define our sequence compatibility kernel (SCK) between ? A and ? B as 1 :</p><formula xml:id="formula_9">K S (? A , ? B ) = (7) 1 ? (i,s)?J (j,t)?J G ?1 (i?j) ? 1 G ?2 (x is ?y jt )+? 2 G ?3 ( s ? t N ) r .</formula><p>Symbol ? is a normalization constant and J = I J ? I N . As is clear, this kernel involves three different compatibility subkernels, namely (i) G ?1 , capturing the compatibility between joint-types i and j, (ii) G ?2 , capturing the compatibility between joint locations x and y, and (iii) G ?3 , measuring the temporal alignment of two poses in two sequences. We also introduce weighting factors ? 1 , ? 2 ? 0 that adjust the importance of the body-joint compatibility against the temporal alignment, where ? 1 + ? 2 = 1. Figures 2a and 2b illustrate how this kernel works. It might come as a surprise that we use kernel G ?1 . Note that our skeletons may be noisy and there is a possibility that some keypoints are detected incorrectly (for example, elbows and wrists). Thus, this kernel allows incorporating a degree of uncertainty into the alignment of such joints. To simplify our formulation, in this paper, we will assume that such errors are absent from our skeletons, and thus G ?1 (i ? j) = ?(i ? j). Furthermore, standard deviations ? 2 and ? 3 control the joint-coordinate selectivity and temporal shift-invariance, respectively. That is, for ? 3 ? 0, two sequences will have to match perfectly in the temporal sense. For ? 3 ? ?, the algorithm is invariant to any permutations of the frames. As will be clear in the sequel, parameter r determines the order of statistics of our kernel (we use r = 3). Next, we present linearization of our kernel using the method from Sections 3.2, 3.3, and Eq. <ref type="bibr" target="#b2">3</ref> ). With these approximations and simplification to G ?1 described above, we rewrite our sequence compatibility kernel as:</p><formula xml:id="formula_10">(3), so that kernel G ?2 (x ? y) ? ?(x) T ?(y) (see note 2 ) while G ?3 ( s?t N ) ? z(s/N ) T z(t/N ) (see note</formula><formula xml:id="formula_11">K S (? A , ? B ) ? 1 ? i?I J s?I N t?I N ? ? ? ? 1 ?(x is ), (see note 2 ) ? ? 2 z(s/N ), (see note 3 ) T ? ? ? 1 ?(y it ) ? ? 2 z(t/N ) ? ? r (8) = 1 ? i?I J s?I N t?I N ? ? r ? ? 1 ?(x is ) ? ? 2 z(s/N ) , ? ? r ? ? 1 ?(y it ) ? ? 2 z(t/N ) (9) = i?I J 1 ? ? s?I N ? ? r ? ? 1 ?(x is ) ? ? 2 z(s/N ) , 1 ? ? t?I N ? ? r ? ? 1 ?(y it ) ? ? 2 z(t/N ) .<label>(10)</label></formula><p>Expansion of Eq. (8) into Eq. (9) simply follows the notion of equivalence between the polynomial kernels and tensor outerproducts as detailed in Eq. <ref type="bibr" target="#b3">(4)</ref>. Similarly, the summations in Eq. (9) can be absorbed into the dot-product in Eq. (10) because the inner-product is a linear operation in each of its arguments e.g.,</p><formula xml:id="formula_12">v 1 +v 2 ,v = v 1 ,v + v 2 ,v .</formula><p>The physical meaning of the above equation is detailed in <ref type="figure" target="#fig_2">Figure 3</ref>. While the first-, secondand third-order outer-products are connected to the sample mean, covariance and co-skewness of features, our tensors are not mere counts of features, as explained next. As is clear, (10) expresses K S (? A , ? B ) as a sum of inner-products on third-order tensors (r = 3), as shown in <ref type="figure" target="#fig_1">Figure 2c</ref>. While, using the dot-product as the inner-product is an option, other alternatives for tensors of order r ? 2 can act on their spectrum, leading to better representations. <ref type="bibr" target="#b1">2</ref> In practice, Cartesian coordinates of joints x, y ? R 3 are fed into a kernel. Thus, in place of kernel G? 2 , we use the sum kernel G ? 2 (x?y) = G? 2 (x 1 ? y 1 )+G? 2 (x 2 ?y 2 )+G? 2 (x 3 ?y 3 ) whose approximation is given as:</p><formula xml:id="formula_13">G ? 2 (x? y) ? [?(x 1 ; {? i } i?I Z 2 ); ?(x 2 ; {? i } i?I Z 2 ); ?(x 3 ; {? i } i?I Z 2 )] T [?(y 1 ; {? i } i?I Z 2 ); ?(y 2 ; {? i } i?I Z 2 ); ?(y 3 ; {? i } i?I Z 2 )]</formula><p>but for simplicity we refer to it in our formulations by its generic form</p><formula xml:id="formula_14">G? 2 (x?y) ? ?(x) T ?(y) because we can define ?(x) = [?(x 1 ); ?(x 2 ); ?(x 3 )].</formula><p>3 Feature maps z(?) ? ?(?) from Eq. (2). We simply write z rather than ? to denote these feat. maps as they encode the time/frame number (c.f . the body joints). Note that z(?; <ref type="figure" target="#fig_2">Figure 3</ref>).</p><formula xml:id="formula_15">{? i } i?I Z 3 ) uses Z 3 pivots {? i } i?I Z 3 (see</formula><p>An example is the so-called burstiness <ref type="bibr" target="#b80">[81]</ref>, which is a commonly encountered property that a given feature appears more/less often in a sequence than a statistically independent model predicts. Robust descriptors must be invariant w.r.t. the length of actions e.g., a prolonged hand waving represents the same action as a short hand wave. Eigenvalue Power Normalization (EPN) <ref type="bibr" target="#b3">[4]</ref> suppresses burstiness by acting on higher-order statistics (see <ref type="figure" target="#fig_1">Fig. 2c</ref>). By incorporating EPN, we generalize (10) as:</p><formula xml:id="formula_16">K * S (? A , ? B ) = i?I J G ? ? 1 ? ? s?I N ? ? r ? ? 1 ?(x is ) ? ? 2 z(s/N ) ? ? , G ? ? 1 ? ? t?I N ? ? r ? ? 1 ?(y it ) ? ? 2 z(t/N ) ? ? ,<label>(11)</label></formula><p>where the operator G performs EPN by applying power normalization to the spectrum of the third-order tensor (by taking the higherorder SVD). Note that in general K *</p><formula xml:id="formula_17">S (? A , ? B ) ? K S (? A , ? B ) as G is intended to manipulate the spectrum of X .</formula><p>The final representation for linearized SCK becomes:</p><formula xml:id="formula_18">V i = G(X i ), where X i = 1 ? ? s?I N ? ? r ? ? 1 ?(x is ) ? ? 2 z(s/N ) . (12)</formula><p>We replace the sum over the body-joint indexes in (11) by concatenating V i in (12) along the fourth tensor mode, thus</p><formula xml:id="formula_19">defining V = V i ?4 i?I J . Suppose V A and V B</formula><p>are the corresponding fourth order tensors for ? A and ? B respectively. Then, we obtain:</p><formula xml:id="formula_20">K * S (? A , ? B ) = V A , V B .<label>(13)</label></formula><p>Note that tensors X have the following properties: (i) supersymmetry X i,j,k = X ?(i,j,k) for indexes i, j, k and their permutation given by ?, ??, and (ii) positive semi-definiteness of every slice, that is, X :,:,s ? S d + , for s ? I d . Thus, we use only the uppersimplices of V i which consist of d+r?1 r coefficients (which is the total size of our final representation times the number of bodyjoints) rather than d r , where d is the side-dimension of V i i.e., d = 3Z 2 +Z 3 (see notes 2,3 ), and Z 2 and Z 3 are the numbers of pivots used in the approximation of G ?2 and G ?3 (see notes <ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3</ref> ).</p><p>Next, we pass tensors X via (i) slice-wise EPN (sEPN) operator or (ii) HOSVD-based tensor whitening EPN (tEPN) <ref type="bibr" target="#b3">[4]</ref>. sEPN is faster but tEPN uses the entire tensor spectrum, thus being more accurate. The slice-wise EPN uses the Power-Euclidean dist. for rising matrices, slices of tensor tensor X , to the power of ?. Power norm. and re-stacking slices along the third mode yields:</p><formula xml:id="formula_21">G(X) = [X ? :,:,s ] ?3 s?I d , for 0 &lt; ? ? 1.<label>(14)</label></formula><p>We note that G(X) preserves listed earlier properties of tensors X and it forms our final tensors V for the action sequence.</p><p>The HOSVD-based tensor whitening EPN, proposed in <ref type="bibr" target="#b3">[4]</ref>, is defined by the following operator G:</p><formula xml:id="formula_22">(E; A 1 , ..., A r ) = HOSVD(X ),<label>(15)</label></formula><formula xml:id="formula_23">E = Sgn(E) |E| ? , generally? =?(E)<label>(16)</label></formula><formula xml:id="formula_24">V = ((? ? 1 A 1 ) ...) ? r A r , , thinkV = X 1 2<label>(17)</label></formula><formula xml:id="formula_25">G(X ) = Sgn(V) |V| ? * .<label>(18)</label></formula><p>In the above equations, we distinguish the core tensor E, its powernormalized variant? with factor weights evened out by rising them to the power 0 &lt; ? ? 1, singular vector matrices A 1 , ..., A r and operation ? r which is the so-called tensor-product in mode r.</p><p>As our tensors X are super-symmetric, we note that A 1 = A 2 = ... = A r . However, the kernel which is proposed in Section 4.4 leads to a non-symmetric tensor representation. We refer the reader to paper <ref type="bibr" target="#b3">[4]</ref> for the detailed description of the above steps.</p><p>Eq. (16) has a more general form? =?(E), where? can be any power normalizing function <ref type="bibr" target="#b1">[2]</ref>. In Sec. D, we derive the exact interpretation of Eq. <ref type="bibr" target="#b14">(15)</ref><ref type="bibr" target="#b15">(16)</ref><ref type="bibr" target="#b16">(17)</ref><ref type="bibr" target="#b17">(18)</ref> </p><formula xml:id="formula_26">for? = Sgn(E) (1 ? (1 ? |E|)N ) for which Sgn(E) |E|</formula><p>? is an approximation <ref type="bibr" target="#b1">[2]</ref>. We prove in Sec. D that EPN performs in fact a spectral detection of higherorder occurrences of features, the base of fine-grained systems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. <ref type="figure">Figure 9</ref> illustrates details of such a spectral detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Dynamics Compatibility Kernel</head><p>The SCK kernel that we described above captures the intersequence alignment, whereas the intra-sequence spatio-temporal dynamics is lost. Thus, we propose a novel dynamics compatibility kernel (DCK). In what follows, we use the absolute coordinates of the joints in our kernel and follow notations from the prev. section.</p><p>DCK for two action sequences ? A and ? B is defined as:</p><formula xml:id="formula_27">K D (? A , ? B ) = 1 ? (i,s)?J, (i ,s )?J, i =i,s =s (j,t)?J, (j ,t )?J , j =j,t =t G ? 1 (i?j, i ?j ) G ? 2 ((x is ?x i s )?(y jt ?y j t )) ? ? G ? 3 ( s?t N , s ?t N ) G ? 4 (s?s , t?t ). (19)</formula><p>In contrast to SCK in <ref type="formula" target="#formula_49">(7)</ref>, the DCK kernel uses the intrasequence joint differences, thus capturing the dynamics, which is then compared against dynamics of other sequences.</p><p>Figures 4a-4c depict schematically how DCK captures cooccurrences. As in SCK, the first kernel, G ? 1 , captures the sensor uncertainty in body-keypoint detection, and is assumed to be a delta function in this paper. The second kernel, G ? 2 , models the spatio-temporal co-occurrences of the body-joints. Temporal alignment kernels, expressed as G ? <ref type="bibr" target="#b2">3</ref> (?, ?) = G ? 3 (?)G ? 3 (?), encode temporal start-and end-points from (s, s ) and (t, t ). Finally, G ? 4 limits contributions of dynamics between temporal points if they are distant from each other, i.e. if s s or t t and ? 4 is small. Similarly to SCK, the standard deviations ? 2 and ? 3 control the selectivity over spatio-temporal dynamics of body-joints and their temporal shift-invariance for the start and end points, resp. As discussed for SCK, the practical extensions from footnotes 1,2,3 also apply to DCK e.g., the definition of z, the pivot numbers Z 2 and Z 3 for G ? 2 and G ? 3 kernels.</p><p>Based on the above formulations, Section A shows that the linearization of DCK admits the form:</p><formula xml:id="formula_28">K D (? A , ? B ) ? (20) i?I J , i ?I J : i =i 1 ? ? s?I N , s ?I N : s =s G ? 4 (s?s ) ?(x is ?x i s )?z s N T ? ? z s N , 1 ? ? t?I N , t ?I N : t =t G ? 4 (t?t ) ?(y it ?y i t )?z t N T ? ? z t N .</formula><p>Equation <ref type="formula" target="#formula_3">(20)</ref>   <ref type="figure">Fig. 4</ref>: <ref type="figure">Figure 4a</ref> shows that kernel G ? 2 in DCK captures spatio-temporal dynamics by measuring displacement vectors from any given body-joint to remaining joints spatially-and temporally-wise (i.e. see dashed lines). <ref type="figure">Figure 4b</ref> shows that comparisons performed by G ? 2 for any selected two joints are performed all-against-all temporally-wise which is computationally expensive. <ref type="figure">Figure 4c</ref> shows the encoding steps in the proposed linearization which is fastn. We collect all X ii for joints i ? i , whiten them by EPN to obtain V ii , concatenate, vectorize them per video with 'vec' and fed to an SVM. We introduced color-coded body joints/frame numbers to show how we assemble a single X ii .  <ref type="formula" target="#formula_3">2)</ref>. Similarly, we embed the starting and ending times s/N and s /N via function z(?) (also by Eq. <ref type="formula" target="#formula_3">(2)</ref>). Finally, ? performs the third-order outer-product on concatenated displacement and time embeddings aggregated next over frames s and s (note ss ). The interpretation: the Gaussians 'soft-divide' the Cartesian coordinate system along x, y, z direction, resp., as well as time direction (s/N and s /N ). We project displacements along x, y, z directions of Cartesian coordinates and assign each projection to Gaussians. Thus, triplets ([x; y; z], s, s ) assigned into such a 'softdivided' space capture locally displacements of pairs of joints on the time grid (3-way soft-histogram). For DCK ? in Section 4.6 we use velocity vectors</p><p>x is ?x i s max(1,|s ?s|) (c.f . displacement vectors) with shortand long-term estimates depending on s ?s (3-way soft-histogram of short-and long-term speeds).</p><p>these tensors with a variant of EPN, which involves Higher Order Singular Value Decomposition (HOSVD), into factors stored in the so-called core tensor, and equalize the contributions of these factors to prevent bursts in the spatio-temporal co-occurrence dynamics of actions. For example, consider that a long hand wave versus a short hand wave yield different temporal statistics, that is, the prolonged action results in bursts. However, the final representation described below becomes invariant to bursts.</p><p>The final representation for linearized DCK with a non-linear operator G introduced into Eq. <ref type="bibr" target="#b19">(20)</ref> to prevent burstiness becomes:</p><formula xml:id="formula_29">V ii = G(X ii ), where<label>(21)</label></formula><formula xml:id="formula_30">X ii = 1 ? ? s,s ?I N :s =s G ? 4 (s?s ) ?(x is ?x i s )?z s N T ? ? z s N .</formula><p>The summation over pairs of body-joint indexes in <ref type="formula" target="#formula_3">(20)</ref> is equivalent to the concatenation of V ii from (21) along the fourth mode. Thus, we obtain tensor representations V ii</p><formula xml:id="formula_31">?4 i&gt;i : i,i ?I J for sequence ? A and V ii ?4 i&gt;i : i,i ?I J for sequence ? B .</formula><p>The physical meaning of Eq. <ref type="formula" target="#formula_3">(21)</ref> is detailed in <ref type="figure" target="#fig_4">Figure 5</ref>. The dot-product can be now applied between these representations to compare them. Tensors X in <ref type="formula" target="#formula_3">(21)</ref> are non-symmetric. Thus, for the operator G, we choose the HOSVD-based tensor whitening EPN, that is, tEPN defined in Eq. (15-18).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Sequence Compatibility Kernel 'Plus' (SCK ?)</head><p>Below, we extend the SCK formulation from Section 4.3 to aggregate over multiple subsequences extracted from the input sequence. Intuitively, this process is an equivalent of extracting local descriptors from images to attain so-called shift-invariance to the object location. As it is unlikely that relevant motion patterns stretch throughout a sequence, a specific pattern associated with some action classes may appear in one/few subsequences. Moreover, in what follows next, we will allow the aggregation to run over multiple modalities q ? I Q e.g., we use 3D body-joints and/or frame-wise CNN classification scores from RGB videos and/or optical flow. Thus, we can define our multimodal pose sequence ? as:</p><formula xml:id="formula_32">? = x (q) is ? R Wq , i ? I J , s ? I M , q ? I Q ,<label>(22)</label></formula><p>where W 1 = 3, J is the total number of body-joints, W q for q &gt; 1 equals the size of modality q other than body-joints. Note that if modality q &gt; 1 is global rather than per-joint specified, we can replicate it e.g., x</p><formula xml:id="formula_33">(q) 1s = ... = x (q)</formula><p>Js . SCK ? on a pair of sequences ? A and ? B of length M and N is defined as:</p><formula xml:id="formula_34">K S ? (? A , ? B ) = (23) 1 ? i?I J ? ?P A ? ?P B u?U? u ?U ? s?S? t?S ? q?I Q ? (q) 1 G ? (q) 2 x (q) i,u+s ? y (q) i,u +t + ? 2 G? 3 (f (s, S? )?f (t, S ? ))+ ? 3 G? 4 (f (u, U A ? )?f (u , U B ? ))+ ? 4 G? 5 (f (?, P A )?f (? , P B )) r .</formula><p>Symbols P A and P B denote subsequence lengths, P A = P B = P is a possible assertion to make, so that i.e. P = {8, 10, 12, ..., 20}. Moreover, normalizations f (u, U) and f (?, P) are defined by analogy,</p><formula xml:id="formula_35">? = ? A ?? B = (|I J |?|P A |?|U A ? |?|S ? |)?(|I J |?|P B |?|U B ? |?|S ? |)</formula><p>. For simplicity, we do not model the within-sequence similarity between the body joints in contrast to Eq. <ref type="formula" target="#formula_49">(7)</ref>, thus we skip G ?1 . Kernels G ? (i) 2 capture the compatibility between bodyjoint locations x and y in a subsequence. Kernel G ?3 measures the temporal alignment of two pose snippets in the given two subsequences. Kernel G ?4 measures the temporal alignment of two subsequences in two sequences. Lastly, G ?5 measures the match of two subsequence lengths. Weight factors ? (q) 1 ? 0 adjust the importance of each modality q ? I Q . Weight ? 2 ? 0 is the importance of the temporal alignment of snippets within subsequences. Weight ? 3 ? 0 is the importance of the temporal alignment of subsequences within sequences. Weight ? 4 ? 0 is the importance of the match of two subsequence lengths. We let</p><formula xml:id="formula_36">q ? (q) 1 +? 2 +? 3 +? 4 = 1. Parameters ? (q) 2 in G ? (q) 2 and ? (q) 1</formula><p>are set per modality e.g., for the 3D body-joints we chose G ? (1) 2 to be an RBF kernel, for frame-wise class predictions obtained from CNNs applied on (i) RGB and (ii) optical flow frames we choose G ? (2) 2 and G ? (3) 2 to be linear kernels (with no parameters). As previously, r denotes the order of captured statistics i.e., r = 3.</p><p>Below, we present the process of linearization of our kernel which follows the reasoning from Section 3.2 and Eq. (3). However, we feel it is interesting to show how various kernel components translate to various statistics encoded by the tensor: <ref type="bibr" target="#b1">2</ref> ) and, in order to reflect the choice of par. ?</p><formula xml:id="formula_37">i. G ? (q) 2 (x ? y) ? ? (q) (x) T ? (q) (y) (see note</formula><formula xml:id="formula_38">(q) 2 for index q, we write ? (q) , ii. G ?3 (f (s, S ? )?f (t, S ? )) ? z (f (s, S ? ) T z (f (t, S ? )), iii. G ?4 (f (u, U ? )?f (u , U ? )) ? z (f (u, U ? ) T z (f (u , U ? )), iv. G ?5 (f (?, P A )?f (? , P B )) ? z (f (?, P A ) T z (f (? , P B )).</formula><p>With these approximations at hand, we rewrite our sequence compatibility kernel 'plus' as:</p><formula xml:id="formula_39">K S ? (? A , ? B ) ? 1 ? i?I J ? ?P A ? ?P B u?U? u ?U ? s?S? t?S ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? (1) 1 ?(x (1) i,u+s ) ... ? (Q) 1 ?(x (Q) i,u+s ) ? ? 2 z (f (s, S? )) ? ? 3 z (f (u, U? )) ? ? 4 z (f (?, P A )) ? ? ? ? ? ? ? ? ? ? T ? ? ? ? ? ? ? ? ? ? ? ? (1) 1 ?(y (1) i,u +t ) ... ? (Q) 1 ?(y (Q) i,u +t ) ? ? 2 z (f (t, S ? )) ? ? 3 z (f (u , U ? )) ? ? 4 z (f (? , P B )) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? r = (24) i?I J G ? ? ? ? ? ? ? ? ? ? 1 ? A ? ?P A u?U? s?S? ? ? r ? ? ? ? ? ? ? ? ? ? ? (1) 1 ?(x (1) i,u+s ) ... ? (Q) 1 ?(x (Q) i,u+s ) ? ? 2 z (f (s, S? )) ? ? 3 z (f (u, U? )) ? ? 4 z (f (?, P A )) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,<label>(25)</label></formula><formula xml:id="formula_40">G ? ? ? ? ? ? ? ? ? ? 1 ? B ? ?P B u ?U ? t?S ? ? ? r ? ? ? ? ? ? ? ? ? ? ? (1) 1 ?(y (1) i,u +t ) ... ? (Q) 1 ?(y (Q) i,u +t ) ? ? 2 z (f (t, S ? )) ? ? 3 z (f (u , U ? )) ? ? 4 z (f (? , P B )) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? .</formula><p>In the above equation, we set G(X) = X for Eq. (25) to be equivalent to Eq. (24). However, similarly to considerations in Section 4.3, a commonly encountered adversity in aggregated representations, the burstiness, requires some suppression. To this end, we let operator G in Eq. (25) perform tEPN on the spectrum of the third-order tensor.</p><p>The final representation for linearized SCK ? becomes:</p><formula xml:id="formula_41">V i = G(X i ), where X i = 1 ? A ? ?P A u?U? s?S? ? ? r ? ? ? ? ? ? ? ? ? ? (1) 1 ?(x (1) i,u+s ) ... ? (Q) 1 ?(x (Q) i,u+s ) ? ? 2 z (f (s, S? )) ? ? 3 z (f (u, U? )) ? ? 4 z (f (?, P A )) ? ? ? ? ? ? ? ? ? .<label>(26)</label></formula><p>We can further replace the summation over the body-joint indexes in (25) by concatenating V i in (26) along the fourth tensor mode, thus defining</p><formula xml:id="formula_42">V = V i ?4 i?I J . Suppose V A and V B</formula><p>are the corresponding fourth order tensors for ? A and ? B , then we have:</p><formula xml:id="formula_43">K * S ? (? A , ? B ) = V A , V B .<label>(27)</label></formula><p>Note that in general</p><formula xml:id="formula_44">K * S ? (? A , ? B ) ? K S ? (? A , ? B )</formula><p>as G manipulates the spectrum of X . Finally, for our final representation, we use only the upper-simplices of V i which consist of d+r?1 r coefficients each, rather than d r , where d is the sidedimension of V i i.e., d = 3Z </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Dynamics Compatibility Kernel 'Plus' (DCK ?)</head><p>Below, we apply the aggregation over subsequences to our DCK kernel. We follow the same steps as for SCK ? (Section 4.5) except that our subsequences for DCK ? have a fixed length. For a pair of sequences ? A and ? B of length M and N , we have:</p><formula xml:id="formula_45">K D ? (? A , ? B ) = (28) 1 ? u,u ?U? K D (? A,?,u , ? B,?,u )G ?4 (f (u, U A ? )?f (u , U B ? )),</formula><p>where ? is a length of subsequences. K D (? A,?,u , ? B ,?,u ) is defined in Eq. <ref type="bibr" target="#b18">(19)</ref>. However, we use velocity vectors xis?x i s max(1,|s ?s|) (c.f . displacement vectors in DCK) with short-and long-term estimates depending on s ?s. <ref type="figure" target="#fig_4">Figure 5</ref> provides an interpretation of this kernel. K D (? A,?,u , ? B ,?,u ) is evaluated over subsequences ? A,?,u and ? B,?,u sampled from ? A and ? B according to sets of sampling coordinates S ?,u = {S ? }+u and S ?,u = {S ? }+u of length ? which are shifted by locations u and u according to U ? . Lastly, ? = |U A ? | ? |U B ? |. The remaining symbols follow definitions in Section 4.5. Kernel in Eq. (28) is then linearized in the similar manner to Eq. <ref type="bibr" target="#b18">(19)</ref> which results in linearization similar to Eq. (21) but containing an additional mode corresponding to linearization of kernel G ?4 . We skip this derivation for brevity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>Below, we present experiments on our models on seven popular datasets. For datasets based on 3D skeletons, we use (i) the UTKinect-Action <ref type="bibr" target="#b30">[31]</ref>, (ii) Florence3D-Action <ref type="bibr" target="#b31">[32]</ref>, (iii) MSR-Action3D <ref type="bibr" target="#b32">[33]</ref>, and (iv) Kinetics <ref type="bibr" target="#b35">[36]</ref> (where stated). For datasets based on RGB frames, we use (v) the fine-grained MPII Cooking Activities <ref type="bibr" target="#b24">[25]</ref> and (vi) HMDB-51 <ref type="bibr" target="#b33">[34]</ref> datasets. For experiments on the 3D skeletons fused with RGB frames, we use (vii) large scale NTU-RGBD <ref type="bibr" target="#b34">[35]</ref> dataset. We also evaluate the influence of various hyper-parameters, such as the number of pivots Z used for linearizing the body-joint and temporal kernels, and the impact of Eigenvalue Power Normalization (we vary the factor equalization). We evaluate our older SCK and DCK kernels, and their newer counterparts SCK ? and DCK ?. For skeletons, we feed them directly to our kernel representations while RGB-based datasets are firstly encoded by the two-stream CNN <ref type="bibr" target="#b16">[17]</ref> or the I3D <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>UTKinect-Action <ref type="bibr" target="#b30">[31]</ref> consists of 10 actions performed twice by 10 different subjects, and has 199 action sequences. The dataset provides 3D coordinate annotations of 20 body-joints for every frame. The dataset was captured with a stationary Kinect sensor and contains significant viewpoint and intra-class variations. Florence3D-Action <ref type="bibr" target="#b31">[32]</ref> dataset consists of 9 actions performed 2-3? by 10 different subjects and it has 215 action sequences. 3D coordinate annotations of 15 body-joints captured with a Kinect sensor are provided. Significant intra-class variations are present i.e., the same action articulated with the left/right hand, and actions like drinking/performing a phone call can be seen as fine-grained. MSR-Action3D <ref type="bibr" target="#b32">[33]</ref> dataset is comprised of 20 actions performed 2-3? by 10 different subjects and it has 567 action sequences. 3D coordinates of 20 body-joints captured by a Kinect-like depth sensor are provided. MSR-Action3D has strong inter-class similarity.</p><p>In the above datasets, we use the cross-subject test setting (unless stated otherwise), in which half of the subjects are used for training and the remaining half for testing. Similarly, we divide the training set into two halves for the purpose of training/validation. NTU-RGBD <ref type="bibr" target="#b34">[35]</ref> is by far the largest 3D skeleton-based video action recognition dataset. It has 56880 video sequences across 60 classes, 40 subjects, and 80 views. The videos have on average 70 frames and consist of people performing various actions. Each frame is annotated with 25 human skeletal keypoints (some videos have multiple subjects). Two evaluation protocols are used for this dataset, namely, cross-subject and cross-view evaluation. This dataset can be considered as having many fine-grained classes e.g., make a phone call, playing with phone, punching other person, pushing other person, pat on back of other person, etc. MPII Cooking Activities <ref type="bibr" target="#b24">[25]</ref> dataset consists of high-resolution videos of cooking activities/people cooking various dishes. There are 64 distinct activities spread across 3748 video clips and one background activity (1861 clips). Activities include coarse actions e.g., opening refrigerator, and fine-grained actions e.g., peel, slice, cut apart (see <ref type="figure">Figure 6</ref>). This dataset is challenging due to (i) unbalanced action classes, (ii) significant intra-class differences (each subject cooks according to their own style). We use the mean Average Precision (mAP) over 7-fold cross-validation. HMDB-51 <ref type="bibr" target="#b33">[34]</ref> dataset is a popular video benchmark for human action recognition, consisting of 6766 Internet videos over 51 classes. Each video has about 20-1000 frames. We report the average classification accuracy on standard three-fold splits. Kinetics <ref type="bibr" target="#b35">[36]</ref> contains ?300000 clips from YouTube which cover 400 human action classes, ranging from daily activities, sports scenes, to complex interactions. Each clip is ?10 seconds long.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Setup</head><p>For our experiments, we distinguish four configurations: (i) for UTKinect-Action, Florence3D-Action and MSR-Action3D that provide 3D body-joints, we feed sequences of 3D body-joints to our kernel(s), (ii) for MPII Cooking Activities, HMDB-51 and NTU-RGBD that provide RGB frames, we train a two-stream ResNet-152 model (as in <ref type="bibr" target="#b16">[17]</ref>) taking RGB frames (in the spatial <ref type="figure">Fig. 6</ref>: Fine-grained action instances (MPII Cooking Activities <ref type="bibr" target="#b24">[25]</ref>) from two different action categories: cut-in (left) and slicing (right). stream) and a stack of optical flow frames (in the temporal stream) as input to obtain classification scores per frame per stream which are then passed to our kernel, (iii) for NTU-RGBD which contains both 3D body-joints and RGB frames, we investigate both such inputs separately as well as their combination, and (iv) for Kinetics, we use skeletons and combine ST-GCN with SCK.</p><p>For the sequence compatibility kernel on sequences of 3D body-joints, we first normalized all body-keypoints with respect to the hip joints across frames, as indicated in Section 4.3. We also normalized lengths of all body-parts w.r.t. to a reference skeleton. This setup follows pre-processing of <ref type="bibr" target="#b11">[12]</ref>. For our dynamics compatibility kernel, we use unnormalized body-joints and assume that the displacements of body-joint coordinates across frames capture their temporal evolution implicitly. For the sequence compatibility kernel on classifier scores, we take the scores before they are passed through the logistic function and we apply a rectifier. CNN Training. To extract features with CNN, we train a twostream ResNet-152 model <ref type="bibr" target="#b16">[17]</ref> taking RGB frames (in the spatial stream) and a stack of optical flow frames (in the temporal stream) from a given training split as input. For optical flow, we use the Large Displacement Optical Flow (LDOF) <ref type="bibr" target="#b81">[82]</ref>. We use the classifier predictions from each stream as inputs to our kernels. The two streams of the CNN are trained separately on the respective input modalities against a softmax cross-entropy loss. We simply follow the standard training protocols from <ref type="bibr" target="#b16">[17]</ref>. For fine-tuning, we used a fixed learning rate of 1e?4 and a momentum of 0.9. For the MPII Cooking Activities dataset, we used the sequences from the training set for training the CNNs (1992 sequences) and those from the validation set (615 sequences) to check for overfitting. For HMDB-51, we use three standard splits provided with the dataset. For NTU-RGBD dataset in the cross-subject evaluation, the training and testing sets have 40320 and 16560 samples, respectively. For NTU-RGBD dataset in the cross-view evaluation, the training and testing sets have 37920 and 18960 samples, respectively. We use 70% of the training set for training and 30% for validation. To train SVM, we simply vectorize our tensors and set c = 1e?2.</p><p>To stay competitive w.r.t. the state of the art, we additionally use two newer backbones such as (i) Spatial Temporal Graph Convolutional Network (ST-GCN) <ref type="bibr" target="#b74">[75]</ref> and (ii) Two-Stream Inflated 3D ConvNet (I3D) <ref type="bibr" target="#b27">[28]</ref>. For ST-GCN, we train it on skeletal sequences from NTU and Kinetics <ref type="bibr" target="#b35">[36]</ref> datasets following the standard protocols. For Kinetics, we follow approach <ref type="bibr" target="#b35">[36]</ref> and use skeletons extracted with OpenPose <ref type="bibr" target="#b4">[5]</ref>. Finally, we combine our vectorized tensors from SCK or SCK ? with the output of the last layer of ST-GCN preceding the classifier, and feed such a representation into the cross-entropy loss. As SCK is a shallow approach, we expect it to be highly complementary with ST-  <ref type="figure">Fig. 7</ref>: <ref type="figure">Figure 7a</ref> illustrates the classification accuracy on Florence3d-Action for the sequence compatibility kernel when varying radii ?2 (body-joints subkernel) and ?3 (temporal subkernel). <ref type="figure">Figure 7b</ref> evaluates behavior of SCK w.r.t. the number of pivots Z2 and Z3. <ref type="figure">Figure 7c</ref> demonstrates effectiveness of our slice-wise Eigenvalue Power Normalization in tackling burstiness by varying parameter ?. <ref type="figure">Figure 7d</ref> shows effectiveness of equalizing the factors in non-symmetric tensor representation by HOSVD Eigenvalue Power Normalization by varying ?. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>15</head><p>A B C D E 6, <ref type="bibr">9 1,6,9 6,9,12,15 4,6,7,9,11,14 4,6,7,9,</ref>   <ref type="figure">Fig. 8</ref>: <ref type="figure">Figure 8a</ref> enumerates the body-joints in the Florence3D-Action dataset. The table below lists subsets A-I of the body-joints used to build representations eval. in <ref type="figure">Figure 8b</ref>, which shows the accuracy of our dynamics compatibility kernel w.r.t. these subsets.</p><p>GCN. For I3D network, we train it on subsequences extracted from HMDB51 and MPII. We use RGB and optical flow (LDOF) streams. We extract subsequences of length 48, 64, 80, 96 given strides 1, 2 and 3. Then, subsequences shorter than 64 are lapped. We put together all training subsequences of all lengths and all strides, and we train RGB and LDOF I3D networks separately with a learning rate 1e?4 halved every 10 epochs. IDT Features. On HMDB-51 and MPII Cooking Activities, we also report accuracy when our kernel is combined with dense trajectories <ref type="bibr" target="#b82">[83]</ref> encoded by Fisher Vectors <ref type="bibr" target="#b83">[84]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Sequence compatibility kernel.</head><p>In this section, we first present experiments evaluating the influence of parameters ? 2 and ? 3 of kernels G ?2 and G ?3 which control the degree of selectivity for the 3D body-joints and the temporal shift invariance, respectively. See Section 4.3 for a full definition of these parameters. Recall that kernels G ?2 and G ?3 are approximated via linearizations according to Eq. (1) and <ref type="bibr" target="#b2">(3)</ref>. The quality of these approximations and the size of our final tensor representations depend on the numbers Z 2 and Z 3 of pivots chosen. See Section 3.2, <ref type="figure" target="#fig_2">Figure 3</ref> and notes 2 , 3 for details on pivots.</p><p>In our experiments, the pivots ? are spaced uniformly within interval [?1; 1] and [0; 1] for kernels G ?2 and G ?3 respectively. <ref type="figure">Figures 7a and 7b</ref> present the results of this experiment on the Florence3D-Action dataset. <ref type="figure">Figure 7a</ref> shows that the body-joint compatibility subkernel G ?2 requires a choice of ? 2 , which is not too strict as specific body-joints (e.g., elbow) are expected to repeat across sequences in similar locations due to zero-centering w.r.t. hip. On the one hand, very small ? 2 leads to poor generalization. On the other hand, very large ? 2 allows big displacements of the corresponding body-joints between sequences which results in a poor discriminative power of this kernel. Furthermore, <ref type="figure">Figure  7a</ref> demonstrates that the range of ? 3 for the temporal subkernel for which we obtain very good performance is large. However, as ? 3 becomes very small or very large, extreme temporal selectivity or full temporal invariance, respectively, result in a loss of performance. For instance, ? 3 = 4 results in 91% accuracy only.</p><p>In <ref type="figure">Figure 7b</ref>, we show the performance of our SCK kernel with respect to the number of pivots used for linearization. For the body-joint compatibility subkernel G ?2 , we see that Z 2 = 5 pivots are sufficient to obtain good performance of 92.98% accuracy. We have observed that this is consistent with the results on the validation set. Using more pivots, say Z 2 = 20, deteriorates the results slightly, suggesting overfitting. We make similar observations for the temporal subkernel G ?3 which demonstrates a good performance for as few as Z 3 = 2 pivots. Such a small number of pivots suggests that linearizing 1D variables and generating higher-order co-occurrences, as described in Section 4.3, constitute on a simple, robust, and effective linearization strategy. Furthermore, <ref type="figure">Figure 7c</ref> demonstrates the effectiveness of our slice-wise Eigenvalue Power Normalization described in Eq. <ref type="bibr" target="#b13">(14)</ref>. When ? = 1, the EPN functionality is absent. This results in a drop of performance from 92.98% to 88.7% accuracy. This demonstrates that statistically unpredictable bursts of actions described by body-joints, such as long versus short hand waving, are indeed undesirable. It is clear that in such cases, EPN is very effective, as it deals with correlated bursts, e.g. co-occurring hand wave and associated with it elbow and neck motion. For more details regarding this concept, see <ref type="bibr" target="#b3">[4]</ref>. For our further experiments, we choose ? 2 = 0.6, ? 3 = 0.5, Z 2 = 5, Z 3 = 6, and ? = 0.36, as dictated by cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Dynamics compatibility kernel.</head><p>Below, we evaluate the influence of parameters of the DCK kernel. Our experiments are based on the Florence3D-Action dataset. For ablations, we present results on the test set as results on the validation set match test results closely. As this kernel considers all spatio-temporal co-occurrences of body-joints, we firstly evaluate the impact of the joint subsets we select for generating DCK, as not all body-joints need to be used for capturing actions. <ref type="figure">Figure 8a</ref> enumerates all body-joints that describe every 3D human skeleton on the Florence3D-Action dataset, whereas the   <ref type="bibr" target="#b11">[12]</ref> Second-order DA <ref type="bibr" target="#b85">[86]</ref> 98.9% we use for computations of DCK. In <ref type="figure">Figure 8b</ref>, we plot the performance of our DCK kernel for each subset. The plot shows that using two body-joints associated with the hands from Configuration-A in the DCK kernel construction, we attain 88.32% accuracy which highlights the informativeness of temporal dynamics. Some body-joints may be noisy and thus detrimental to recognition, and should not be selected for experiments e.g., Configuration-D, which includes six body-joints such as the knees, elbows and hands, yields 93.03%, which outperforms more complex configurations.</p><p>As Configuration-E includes eight body-joints such as the feet, knees, elbows and hands, we choose it for our further experiments as it represents a reasonable trade-off between performance and size of representations. This configuration scores 92.77% accuracy. We see that if we utilize all the body-joints according to Configuration-I, performance of 91.65% accuracy is still somewhat lower compared to 93.03% accuracy for Configuration-D highlighting the issue of noisy body-joints.</p><p>In <ref type="figure">Figure 7d</ref>, we show the accuracy on our DCK kernel when HOSVD factors underlying our non-symmetric tensors are equalized by varying the EPN parameter ?. For ? = 1, EPN is disabled, which leads to 90.49% accuracy only. For the optimal value of ? = 0.85, the accuracy rises to 92.77% which indicates the presence of the burstiness effect in temporal representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">SCK and DCK vs. the state of the art.</head><p>Below, we compare the performance of our representations against the state of the art. Along with comparing SCK and DCK, we also explore the complementarity of these representations by combining them via the so-called late fusion, that is, a simple weighted concatenation of vectorized SCK and DCK.</p><p>On the Florence3D-Action dataset, we present our best results in <ref type="table" target="#tab_2">Table 1</ref>. Note that the model parameters for the evaluation was selected by cross-validation. Linearizing a sequence compatibility kernel using these parameters resulted in a tensor representation     <ref type="bibr" target="#b35">[36]</ref> skeletons extracted by OpenPose <ref type="bibr" target="#b4">[5]</ref>.</p><p>Action recognition results on the UTKinect-Action dataset are presented in <ref type="table" target="#tab_3">Table 2</ref>. For our experiments on this dataset, we kept all the parameters the same as those used on the Florence3D dataset. SCK and DCK representations yielded 96.08% and 97.5% accuracy, respectively. Combining SCK and DCK yielded 98.2% accuracy outperforming marginally a more complex approach <ref type="bibr" target="#b11">[12]</ref> based on the Lie group algebra, dynamic time warping and Fourier temporal pyramids.</p><p>In <ref type="table" target="#tab_5">Table 3</ref>, we present our results on the MSR-Action3D dataset. Conforming to the prior literature, we use two evaluation protocols, that is, (i) the protocol described in actionlets <ref type="bibr" target="#b40">[41]</ref>, for which the authors utilize the entire dataset with its 20 classes during the training and evaluation, and (ii) approach of <ref type="bibr" target="#b32">[33]</ref>, for which the authors divide the data into three subsets and report the average in classification accuracy over these subsets. SCK yields the state-of-the-art accuracy of 90.72% and 93.52% for the two evaluation protocols, respectively. Combining SCK with DCK outperforms other approaches listed in the table and yields 91.45% and 93.96% accuracy for the two protocols, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">SCK ? and DCK ? vs. the state of the art.</head><p>Our extended SCK ? is trained with 3Z 2 = 15, Z 3 = Z 4 = 5 and Z 5 = 3 while DCK ? follows the same setting as DCK, except that we introduce quantity Z 6 = 4 which is the number of pivots encoding the subsequence position within the sequence, as dictated by Eq. <ref type="bibr" target="#b27">(28)</ref>. For the Florence3D-Action dataset, <ref type="table" target="#tab_2">Table 1</ref> shows that aggregating over subsequences across various scales results in SCK ? outperforming SCK by ?3.5%, DCK ? outperforming DCK by ?3.4% and the combined kernel SCK ? + DCK ? outperforming SCK+DCK by ?2.2%. <ref type="table" target="#tab_3">Table 2</ref> shows the similar trend for the UTKinect-Action dataset, for which SCK ? outperforms SCK by ?2.4%, DCK ? outperforms DCK by ?0.6% and the combined kernel SCK ? + DCK ? outperforms SCK+DCK by ?1.0%. Note that the results on UTKinect-Action should be considered as already saturated. Furthermore, <ref type="table" target="#tab_5">Table  3</ref> shows that on MSR-Action3D, SCK ? outperforms SCK by ?6.8%, DCK ? outperforms DCK by ?3.7% and the combined kernel SCK ? + DCK ? outperforms SCK+DCK by ?7.5%. Fine-grained Action Recognition. In what follows, we employ NTU-RGBD, a partially fine-grained dataset, and MPII Cooking Activities containing many fine-grained classes.</p><p>Our SCK ? kernel is designed to capture specific subsequences of variable lengths. Kernels G ?2 , ..., G ?5 from Section 4.5 capture higher-order statistics of joint locations in subsequences, the temporal alignment of pose snippets, the global alignment of subsequences, and the match of subsequence lengths. SCK ? uses EPN in Eq. (15-18) which makes it act as a detector of spectral higher-order occurrences. Thus, SCK ? addresses all hallmarks of modern fine-grained recognition systems: it captures higher-order statistics describing visual contents/objects and discarding burstiness <ref type="bibr" target="#b1">[2]</ref> (co-occurrence detection).</p><p>Moreover, our SCK ? kernel captures higher-order occurrences of features representing spatio-temporal evolution of skele-   tons (for 3D body-joints) and/or frame-based classifier scores (semantic information) by feeding them into kernels G ? (1) 2 , ..., G ? (Q) 2 from Eq. (23) for Q modalities. <ref type="table" target="#tab_6">Table 4</ref> (top) shows that, our SCK ? yields some ?3.6% improvement over SCK and reaches 72.82% accuracy on the NTU-RGBD dataset in the cross-subject setting for the 3D bodyjoints as input. We expect that aggregating over subsequences can encode local fine-grained motion details essential for the good performance. Similar observations hold for the cross-view setting.</p><p>Table 4 (middle) shows that our SCK ? attains 90.11% accuracy on the NTU-RGBD dataset in the cross-subject setting on the RGB frames (classifier scores) as input. With the 3D bodyjoints added, results increase to 90.78%. Lastly, adding optical flow as input to our SCK ? yields 91.56%. This is ? 10.0% improvement over competing methods from Table 4 (bottom). <ref type="table" target="#tab_9">Table 6</ref> shows that our SCK ? yields some 1.4% mAP improvement over other state-of-the-art methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b92">93]</ref> on the MPII Cooking Activities dataset. Further improvements are attained by combining SCK ? with the second-order descriptor (sec-ord) <ref type="bibr" target="#b92">[93]</ref> and the IDT representation, which yields 77.4% mAP. This compares favorably with other methods in the table. We also note that SCK ? outperforms the HOK descriptor <ref type="bibr" target="#b29">[30]</ref> which is a variant of SCK with a suboptimal linearization of an fc layer. Finally, applying SCK ? over I3D-based subsequences yields state-of-the-art 80.4% mAP (we comment on the reasons below). Video Classification. <ref type="table" target="#tab_6">Table 4</ref> confirms that the classifier scores extracted from CNNs rather than mere 3D body-joints are a more informative input for SCK ?. Thus, we perform additional evaluations on the HMDB-51 dataset. <ref type="table" target="#tab_10">Table 7</ref> (top) shows that SCK ? and SCK ?+IDT, trained with the two-stream ResNet-152 backbone, score 71.67 and 73.77% accuracy which is on a par with other best methods listed in <ref type="table" target="#tab_10">Table 7</ref> (bottom). Furthermore, applying the I3D backbone on SCK ? yields state-of-the-art 86.11% accuracy. We believe that training I3D on subsequences of various lengths and strides, as detailed in Section 5.2 (bottom), is a more discriminative strategy than average-pooling of frame-wise features in standard two-stream networks. As SCK ? is designed to combine subsequences of various lengths and strides rather than sequences, it captures informative higher-order occurrences of multiple complementary features, and also preserves a degree of individual statistics by factoring out one variable at a time e.g., see the discussion in <ref type="figure" target="#fig_2">Figure 3</ref>. Kinetics-400. <ref type="table" target="#tab_7">Table 5</ref> shows that our SCK and SCK ? are complementary to powerful networks such as ST-GCN <ref type="bibr" target="#b74">[75]</ref>. We work with Kinetics skeletons extracted with <ref type="bibr" target="#b4">[5]</ref> and compare our method to the baseline ST-GCN <ref type="bibr" target="#b74">[75]</ref>. We use the standard training/evaluation protocol (but we use skeletons rather than RGB or optical flow frames). As SCK and SCK ? are shallow representations based on higher-order aggregation, it is unrealistic to expect them to outperform deep networks. However, SCK and SCK ? capture very different statistics compared to deep networks, being highly complementary. <ref type="table" target="#tab_7">Table 5</ref> shows that we attain 1.1% and 2.1% gain over ST-GCN alone by concatenating both representations. Signature Lengths. Section 5.6 indicates the number of pivots for SCK ? on NTU (skeleton-based experiments) to amount to d = 3Z 2 + Z 3 + Z 4 + Z 5 = 15 + 5 + 5 + 3 = 28. The unique number of coefficients in the super-symmetric tensor of order r follows the formula d+r?1 r discussed just below Eq. (11). As we obtain a tensor per joint, and we concatenate unique parts of tensors j = 1, ..., J, we have d+r?1 r ? J coefficients in total in our representation. For SCK ? on NTU with J = 25 body joints, we obtain 4060?25 = 101500 coefficients for SCK ?. For SCK and SCK (r = 2) on NTU, we set d = 3Z 2 +Z 3 = 24+5 = 29 and obtain 112375 and 10875 coefficients, respectively. For Kinetics skeletons with J = 18 body joints, OpenPose returns only two Cartesian coordinates, so we set d = 2Z 2 +Z 3 +Z 4 +Z 5 = 20+ 5+5+3 = 33 which yields 4545?18 = 117810 coefficients.</p><p>For SCK ? (NTU) on (i) RGB frames and (ii) RGB frames+optical flow, we obtain d = Z 2 +Z 3 +Z 4 +Z 5 = 60+5+5+3 = 73 and d = 2Z 2 +Z 3 +Z 4 +Z 5 = 73 (for the latter case, we reduce the size of vector of classifier scores 2? by the PCA). As we do not use any body joints here, we obtain 67525 coefficients. When we concatenate these representations with the skeleton-based one, we obtain 67525+101500 = 169025 coefficients per video.</p><p>On SCK ? given MPII and HMDB-51 datasets, we obtain 171700 and 125580 coefficients after reducing the size of vectors of RGB frame-wise and optical flow classifier scores from 2?64 to 100 and from 2?51 to 90, respectively. Parameters in SCK ?. The main parameters shared between SCK and SCK ? are evaluated in <ref type="figure">Figures 7 and 8</ref>. The parameters for SCK ? that we start with are indicated in Section 4.5 (bottom). To select the best parameters, we cross-validate one parameter at a time while keeping the rest fixed. For NTU, we aggregated over subsequence lengths (using the Matlab notation) of 14 : 1 : 110, 14 : 2 : 110, 14 : 4 : 110 and 14 : 6 : 110, and we obtained 73.10%, 72.82%, 72.41% and 71.65% accuracy, respectively. For subsequence lengths 30 : 2 : 110 and 30 : 2 : 80, we obtained 72.54% and 72.12% accuracy. These evaluations show that SCK ? is not overly sensitive to its parameters. For smaller skeleton-based datasets, we aggregate subsequences in range 6 : 2 : 24, whereas on HMDB-51 we use 6 : 8 : 62, and for MPII we use 48 : 16 : 96. Processing Time. For SCK/DCK, processing a sequence with unoptimized MATLAB code on a single i5 core takes 0.2s and 1.2s, respectively. For SCK ? / DCK ?, processing one sequence takes 0.5s and 3.0s. Training on full MSR-Action3D with the SCK+DCK takes about 13 min, whereas with the SCK ? + DCK ?, it takes about 35 min. In comparison, extracting SE(3) features <ref type="bibr" target="#b11">[12]</ref> takes 5.3s per sequence, processing on the full MSR-Action3D dataset takes ?50 min., whereas with post-processing (time warping and Fourier pyramids) it takes about 72 min. Thus, SCK+DCK is ? 5.4? faster while SCK ? + DCK ? is ? 2? faster. Section C contains the computational complexity analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We have presented two kernel-based tensor representations, namely the sequence compatibility kernel (SCK) and dynamics compatibility kernel (DCK). SCK captures the higher-order correlations between 3D coordinates of the body-joints and their temporal variations. As SCK factors out the temporal variable, expensive Fourier temporal pyramid matching/dynamic time warping are not needed. Further, our DCK kernel captures the action dynamics by modeling the spatio-temporal co-occurrences of the body-joints.</p><p>Additionally, we have presented a highly effective extension of SCK, termed SCK ?, which aggregates over subsequences of multiple lengths, focusing on actions within subsequences. We have demonstrated that SCK ? can aggregate over 3D body-joints and/or frame-wise classifier scores from CNNs to capture higherorder statistics between various features extracted from bodyskeletons, classifier scores, and temporal positions.</p><p>Section D shows that (Tensor) Eigenvalue Power Normalization indeed acts as a spectrum-based metric with Z * r subspacebased detectors of higher-order occurrence of datapoints of dim. Z * , more specifically, detectors that capture asymmetry of projections into 'positive' and 'negative' parts of each subspace. As Z * 3 Z * 2 , third-order tensors capture more dependencies than autocorrelation matrices, improving fine-grained systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REMAINING DETAILS/DERIVATIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Linearizing Dynamics Compatibility Kernel</head><p>In what follows, we derive the linearization of DCK. Let us</p><formula xml:id="formula_46">recall that G ? (u ??) = exp(? u ?? 2 2 /2? 2 ), G ? (?, ?) = G ? (?)G ? (?) and G ? (i ? j) = ?(i ? j)</formula><p>if ? ? 0, therefore ?(0) = 1 and ?(u) = 0 if u = 0. Moreover, ? = J 2 is a normalization constant and J = I J ? I N . We recall that kernel</p><formula xml:id="formula_47">G ? 2 (x?y) ? ?(x) T ?(y) while G ? 3 ( s?t N ) ? z(s/N ) T z(t/N ).</formula><p>Thus, we obtain Eq. (29) which expresses K D (? A , ? B ) as a sum over dot-products on third-order non-symmetric tensors. We introduce operator G into Eq. (29) to amend the dot-product with a distance which handles burstiness. We obtain a modified kernel in Eq. (30) based on which the following notation is introduced: <ref type="bibr" target="#b29">30)</ref> and the summation over the pairs of body-joints in Eq. <ref type="formula" target="#formula_4">(30)</ref> is replaced by the concatenation along the fourth mode to obtain</p><formula xml:id="formula_48">V ii = G(X ii ), where<label>(31)</label></formula><formula xml:id="formula_49">X ii = 1 ? ? s,s ?I N : s =s G ? 4 (s?s ) ?(x is ?x i s )?z s N T ? ? z s N , K D (? A , ? B ) = 1 ? (i,s)?J, (i ,s )?J, i =i,s =s (j,t)?J, (j ,t )?J , j =j,t =t G ? 1 (i?j, i ?j ) G ? 2 (x is ?x i s )? y jt ? y j t G ? 3 ( s ? t N , s ? t N ) ? G ? 4 (s?s , t?t ) = 1 ? i,i ?I J : i =i s,s ?I N : s =s t,t : t =t G ? 2 (x is ?x i s )? y jt ? y j t G ? 3 s ? t N G ? 3 s ? t N ? G ? 4 (s?s ) G ? 4 (t?t ) j=i j =i ? 1 ? i,i ?I J : i =i s,s ?I N : s =s t,t ?I N : t =t ? (x is ?x i s ) T ? (y it ? y i t )?z s N T z t N ?z s N T z t N ? G ? 4 (s?s ) G ? 4 (t?t ) = 1 ? i,i ?I J : i =i s,s ?I N : s =s t,t ?I N : t =t G ? 4 (s?s ) ?(x is ?x i s )?z s N T ? ? z s N , G ? 4 (t?t ) ?(y it ?y i t )?z t N T ? ? z t N = i,i ?I J : i =i 1 ? ? s,s ?I N : s =s G ? 4 (s?s ) ?(x is ?x i s )?z s N T ? ? z s N , 1 ? ? t,t ?I N : t =t G ? 4 (t?t ) ?(y it ?y i t )?z t N T ? ? z t N (29) K * D (? A , ? B ) = i,i ?I J : i =i G 1 ? ? s,s ?I N : s =s G ? 4 (s?s ) ?(x is ?x i s )?z s N T ? ? z s N , G 1 ? ? t,t ?I N : t =t G ? 4 (t?t ) ?(y it ?y i t )?z t N T ? ? z t N<label>(</label></formula><formula xml:id="formula_50">representations V ii ?4 i&gt;i : i,i ?I J and V ii ?4 i&gt;i : i,i ?I J for ? A and ? B . Thus, K * D becomes: K * D (? A , ? B ) = ? 2 V ii ?4 i&gt;i : i,i ?I J , ? 2 V ii ?4 i&gt;i : i,i ?I J<label>(32)</label></formula><p>As Eq. (32) suggests, we avoid repeating the same evaluations in our representations: we stack only unique pairs of body-joints i &gt; i . Moreover, we ensure we run computations temporally only for s &gt; s . In practice, we have to evaluate only JN 2 unique spatiotemporal pairs in Eq. (32) rather than naive J 2 N 2 per sequence. The final representation is of Z 2 ? JZ 3 2 size, where Z 2 and Z 3 are the numbers of pivots for approximation of G ? 2 and G ? 3 .</p><p>We assume that all sequences have N frames for simplification of presentation. Our formulations are equally applicable to sequences of arbitrary lengths e.g., M and N . Thus, we apply in practice G ? <ref type="bibr" target="#b2">3</ref> ( s M ? t N , s M ? t N ) and ? = J 2 M N in Eq. <ref type="bibr" target="#b28">(29)</ref>. Moreover, a displacement between any pair of joints x, y ? R 3 lies within the Cartesian coordinate system, thus x ? y ? R 3 . In practice, in place of generic G ? 2 , we use the sum kernel</p><formula xml:id="formula_51">G ? 2 (x?y) = G ? 2 (x 1 ?y 1 )+G ? 2 (x 2 ?y 2 )+G ? 2 (x 3 ?y 3 ) so the kernel G ? 2 (x?y) ? [?(x 1 ); ?(x 2 ); ?(x 3 )] T [?(y 1 ); ?(y 2 ); ?(y 3 )</formula><p>]. However, for the simplicity of notation, we refer to it in our formulations by its generic form</p><formula xml:id="formula_52">G ? 2 (x ? y) ? ?(x) T ?(y), as we can simply define ?(x) = [?(x 1 ); ?(x 2 ); ?(x 3 )].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Positive Definiteness of SCK and DCK</head><p>SCK/DCK are sums over products of RBF subkernels. According to <ref type="bibr" target="#b94">[95]</ref>, sums, products and linear combinations (for nonnegative weights) of positive definite kernels yield positive definite kernels. Moreover, subkernel G ? 2 ((x is ?x i s )?(y jt ? y j t )) employed by DCK in Eq. (29) (top) can be rewritten as:</p><formula xml:id="formula_53">G ? 2 z isi s ?z jtj t ,<label>(33)</label></formula><p>where z isi s = x is ?x i s and z jtj t = y jt ? y j t .</p><p>The RBF kernel G ? 2 is positive definite (PD) by definition and the mappings from x is and x i s to z isi s and from y jt and y j t to z jtj t , respectively, are unique. Thus, the entire kernel is PD.</p><p>Whitening on SCK results in a positive (semi)definite (PSD) kernel as we employ the Power-Euclidean kernel e.g., if X is PD then X ? stays also PD for 0 &lt; ? ? 1 because X ? = U ? ? V and element-wise rising of eigenvalues to the power of ? gives us daig(?) ? ? 0. Thus, the sum over dot-products of positive (semi)definite matrices raised to the power of ? stays PSD/PD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Computational Complexity</head><p>Non-linearized SCK with ker. SVM have complexity O(JN 2 T ? ) given J body joints, N frames per sequence, T sequences, and 2 &lt; ? &lt; 3 which concerns complexity of kernel SVM. Linearized SCK with linear SVM takes O(JN T Z r * ) for total of Z * pivots and tensor of order r = 3. Note that N 2 T ? N T Z r * . For N = 50 and Z * = 20, this is 3.5? (or 32?) faster than the exact kernel for T = 557 (or T = 5000) used in our experiments.</p><p>Non-linearized DCK+kernel SVM enjoys O(J 2 N 4 T ? ) complexity. Linearized DCK+SVM enjoys O(J 2 N 2 T Z 3 ) for Z pivots per kernel, e.g. Z = Z 2 = Z 3 given G ? 2 and G ? 3 . As N 4 T ? N 2 T Z 3 , the linearization is 11000? faster than the exact kernel, for say Z = 5. Slice-wise EPN applied to SCK has negligible cost O(JT Z ?+1 * ), where 2 &lt; ? &lt; 2.376 concerns complexity of eigenvalue decomposition applied per tensor slice.</p><p>Note that EPN incurs negligible cost (see <ref type="bibr" target="#b95">[96]</ref> for details). EPN applied to DCK utilizes HOSVD and results in complexity O(J 2 T Z 4 ). As HOSVD is performed by truncated SVD on matrices obtained from unfolding V ii ? R Z?Z?Z along a chosen mode, O(Z 4 ) represents the complexity of truncated SVD on matrices V ii ? R <ref type="bibr">Z?Z 2</ref> which have rank less than or equal Z. Linearized SCK ? with linear SVM also takes O(JN T Z r * ) for a total of Z * . However, Z * = 3Z 2 +Z 3 +Z 4 +Z 5 thus Z * = 28. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. What is (Tensor) Eigenvalue Power Normalization?</head><p>Below, we show that EPN in fact retrieves factors which quantify whether there is at least one datapoint ?(x n ) from n ? I N projected into each subspace spanned by r-tuples of eigenvectors from matrices A 1 = A 2 = ... = A r . For brevity, assume order  <ref type="figure">Fig. 9</ref>: The intuitive principle of the EPN. Given a discrete spectrum following a Beta distribution in <ref type="figure">Fig. 9a</ref>, the pushforward measures by MaxExp and Gamma in <ref type="figure">Fig. 9b and 9c</ref> are very similar for large ? (and small ?). Note that both EPN functions in bottom plots whiten the spectrum (map most values to be close to 1) thus removing burstiness. <ref type="figure">Fig. 9d</ref> illustrates the principle of detecting higher-order occurrence(s) in one of Z * r subspaces represented by Eu,v,w (we write E for simplicity). <ref type="figure">Fig. 9d</ref> (top) No EPN: E(?, ?), (middle) MaxExp: 1?(1?E(?, ?)) ? and (bottom) Gamma: E(?, ?) ? . Note how MaxExp/Gamma reach high detection values close to borders. Refer Section A for def. of E(?, ?). r = 3, a super-symmetric case, and a 3-tuple of eigenvectors u, v, and w from A. Note that u ? v, v ? w and u ? w. Moreover, note that if we have Z * unique eigenvectors, we can enumerate Z * r r-tuples and thus Z * r subspaces R r ? R Z * . For brevity, let ||?(x)|| 2 = 1 and ?(x) ? 0. Also, we write ? n instead of ?(x) for n ? I N . Next, let us write our super-symmetric tensor as:</p><formula xml:id="formula_54">X = 1 N n?I N ? ? r ? n ,<label>(34)</label></formula><p>and the 'diagonalization' of X w.r.t. by eigenvec. u, v, and w as:</p><formula xml:id="formula_55">E u,v,w = ((X ? 1 u) ? 1 v) ? 3 w,<label>(35)</label></formula><p>where E u,v,w is a coefficient from the core tensor E for eigenvectors u, v, and w. Now, we combine Eq. 34 and 35 and obtain:</p><formula xml:id="formula_56">E u,v,w = 1 N n?I N ? ? 3 ? n ? 1 u ? 2 v ? 3 w = 1 N n?I N ? n , u ? n , v ? n , w<label>(36)</label></formula><p>We assume ? n is projected into subspace spanned by u, v and w when ? n = ? n , u ? n , v ? n , w is maximized. As our u, v, and w are orthogonal w.r.t. each other and ||? n || 2 = 1, simple Lagrange eq. L = ? r i=1 e T i ? n +?(||? n || 2 2 ?1) yields maximum of ? = (1/ ? r) r at ? n = [(1/ ? r), ..., (1/ ? r)] T . For each n ? I N , we store ? n = ? n /? in vector ?.</p><p>Assume that ? ? {0, 1} N stores N outcomes of drawing from Bernoulli distribution under the i.i.d. assumption for which the probability p of an event (? n = 1) and 1 ? p for (? n = 0) is estimated as an expected value, p = Avg n ? n (even if 0 ? ? ? 1 in reality). Then the probability of at least one projection event (? n = 1) into the subspace spanned by r-tuples in N trials becomes:</p><formula xml:id="formula_57">Eu,v,w = 1?(1?p) N = 1? 1? Eu,v,w ? N ? Eu,v,w ? ? .<label>(37)</label></formula><p>Thus, each of Z * r subspaces spanned by r-tuples acts as a detector of projections into this subspace. The middle part of Eq. (37) (so-called MaxExp pooling) and its connection to the right-hand part of Eq. (37) (so-called Gamma) are detailed in <ref type="bibr" target="#b1">[2]</ref>. In fact, our ? can be negative so extending Eq. (37) to Sgn(E u,v,w ) 1?(1? |Eu,v,w| ? ) N+? makes our model a detector of asymmetry between projections into 'positive' and 'negative' parts of each subspace, and ? compensates for non-binary ?. <ref type="figure">Figure 9</ref> illustrates that MaxExp and Gamma are in fact very similar. <ref type="figure">Figure 9a</ref> shows an initial Beta distribution of spectrum.  <ref type="figure">Figure 9c</ref> illustrates the effect of EPN on eigenvalue E u,v,w (denoted as E for simplicity) representing a single subspace spanned by eigenvectors u, v, w such that u ? v, v ? w and u ? w. As a single projection into the subspace is defined as ? n = ? n , u ? n , v ? n , w /?, we note this is the product of three projections of ? n onto u, v, w, respectively, measured by the cosine (dot-product). Thus, we parametrize such a projection by the spherical coordinates, that is: ? u (?, ?) = cos(?)?sin(?), ? v (?, ?) = sin(?)?sin(?), ? u (?) = cos(?),</p><p>where the azimuthal coordinate ? runs from 0 to 2? and the polar coordinate ? runs from 0 to ?. We rewrite the projection as:</p><p>? u,v,w (?, ?) = ? u (?, ?)?? v (?, ?)?? w (?)/?.</p><p>We note that ? u,v,w (?, ?) and ? n are isomorphic as ||? n || 2 = 1, thus it suffices to note E u,v,w ? ? u,v,w (?, ?) and show the EPN pushforward output of E to understand how EPN behaves around the boundaries of the spanning vectors u, v, w. <ref type="figure">Figure 9d</ref> (top) shows that E by itself has a weak response in the proximity of the spanning vectors u, v, w. However, MaxExp and Gamma in Figures 9d middle and bottom manage to boost projections in the proximity of the spanning vectors in the similar manner to each other, both behaving like spectral detectors. To conclude, let us consider the dot-product between Power Normalized tensors X and Y computed according to Eq. <ref type="bibr" target="#b14">(15)</ref><ref type="bibr" target="#b15">(16)</ref><ref type="bibr" target="#b16">(17)</ref>. Then:</p><formula xml:id="formula_60">V (X ),V(Y) = u?U (X ) v?V (X ) w?W(X ) Eu,v,wuv T ? ?w, u ?U (Y) v ?V (Y) w ?W(Y) E u ,v ,w u v T ? ?w = u?U (X ) v?V (X ) w?W(X ) u ?U (Y) v ?V (Y) w ?W(Y) Eu,v,w? u ,v ,w u, u v, v w, w .<label>(40)</label></formula><p>Eq. <ref type="bibr" target="#b39">(40)</ref> shows that all subspaces of X and Y spanned by r-tuples (3-tuples in this example) are compared against each other for alignment by the cosine distance. When two subspaces [u v w] T and [u v w ] T are aligned, for a strong similarity between these subspaces, a detection of at least one ? n and ? n evidenced b? E u,v,w and? u ,v ,w is also needed. We term Eq. (40) together with Eq. <ref type="bibr" target="#b14">(15)</ref><ref type="bibr" target="#b15">(16)</ref><ref type="bibr" target="#b16">(17)</ref> as Tensor Power Euclidean dot-product which has the associated Tensor Power Euclidean metric ||X ?Y|| T = ||V(X ) ?V(Y)|| F .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 1: Figure 1a illustrates the notion of tensors, their order and modes. Figure 1b illustrates the matrix-vector order outer-product.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Figures 2a and 2bshow how SCK works -kernel G? 2 compares exhaustively e.g. hand-related joint i for every frame in sequence A with every frame in sequence B. Kernel G? 3 compares exhaustively the frame indexes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Order r statistics from Eq.<ref type="bibr" target="#b6">(7)</ref> can be understood by studying the linearization in Eq. (10). For a given joint i at time s/N (normalized frame number), we embed a 3D joint coordinate xis (all centered w.r.t. hip) via function ?(?) into a non-linear Hilbert space representing an RBF kernel according to Eq.(2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>expresses K D (? A , ? B ) as a sum over innerproducts on third-order non-symmetric tensors (c.f. Section 4.3 where the proposed kernel results in an inner-product between super-symmetric tensors). However, we can decompose each of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Third-order statistics from Eq.<ref type="bibr" target="#b18">(19)</ref> can be understood by studying the linearization in Eq.<ref type="bibr" target="#b19">(20)</ref>. For a given pair of joints i ? i at times s/N and s /N (normalized frame numbers), we embed displacement vectors xis ?x i s of 3D joint coordinates xisand x i s via function ?(?) into a non-linear Hilbert space representing an RBF kernel according to Eq. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Moreover, U A ? and U B ? are sets of all positions in sequences ? A and ? B for subsequences of lengths ? and ? , respectively, i.e., if N = 100 and ? = 20 then U A 20 = {1, 3, 5, ..., 79} is an example of a possible choice. Furthermore, S ? and S ? are sets of all sampling positions in subsequences of lengths ? and ? , i.e., if ? = 20 then S 20 = {0, 1, 2, ..., 19} is an example of a possible choice. We define a function f (s, S) = s?S min S max ?? min which performs normalization on s w.r.t. set ?, and S min and S max denote the smallest and largest element of set S, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>2 +</head><label>2</label><figDesc>Z 3 + Z 4 + Z 5 (see notes 2,3 ), and Z (1) 2 , ..., Z (Q) 2 and Z 3 , Z 4 , Z 5 are the numbers of pivots used in the approximation of G ? (1) 2 , ..., G ? (Q) 2 and G ?3 , G ?4 , G ?5 (see notes 2,3 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>The linearized DCK ? takes O(J 2 N 2 T Z 3 Z 6 ) where Z 6 = 4 in our experiments. EPN applied to SCK ? and DCK ? results in complexity O(JT Z 2(r?1) * ) and O(J 2 T Z 4 Z 6 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figures</head><label></label><figDesc>9b and 9c (bottom) show that for sufficiently large parameters ? and ?, both MaxExp and Gamma shift most of the distribution values to be approximately equal 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and L. Wang are with Data61/CSIRO (former NICTA) and the Australian National University, Canberra, Australia, ACT2601.</figDesc><table /><note>E-mail: see http://claret.wikidot.com? A. Cherian is with Mitsubishi Electric Research Labs (MERL), Cambridge, MA, USA. Manuscript submitted Dec-2018. Manuscript accepted by TPAMI on 24-Dec- 2019.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>table underneath</head><label>underneath</label><figDesc>DCK ? SCK ? + DCK ? accuracy 96.50% 96.41% Poses 82.00% [32] Kendal Traj. 93.04% [85] SE(3) 90.88% [12] Kernel+ResNet [86] 95.4%</figDesc><table><row><cell></cell><cell>SCK</cell><cell cols="2">DCK</cell><cell>SCK+DCK</cell></row><row><cell cols="4">accuracy 92.98% 93.03% 92.77%</cell><cell>95.23%</cell></row><row><cell>size</cell><cell>26,565</cell><cell>9,450</cell><cell>16,920</cell><cell>43,485</cell></row><row><cell></cell><cell cols="4">SCK ? 97.45%</cell></row><row><cell>size</cell><cell>60,900</cell><cell>37,800</cell><cell cols="2">98,700</cell></row><row><cell>Bag-of-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>lists the proposed body-joint subsets A-I which</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 1 :</head><label>1</label><figDesc>Evaluations of (top) SCK/DCK, (middle) our improved SCK ? / DCK ?, (bottom) the state of the art on Florence3D-Action.</figDesc><table><row><cell></cell><cell>SCK</cell><cell>DCK</cell><cell>SCK+DCK</cell></row><row><cell cols="3">accuracy 96.08% 97.5%</cell><cell>98.2%</cell></row><row><cell>size</cell><cell>40,480</cell><cell>16,920</cell><cell>57,400</cell></row><row><cell cols="4">SCK ? DCK ? SCK ? + DCK ? accuracy 98.50% 98.12% 99.2%</cell></row><row><cell>size</cell><cell>81,200</cell><cell>67,680</cell><cell>148,880</cell></row><row><cell cols="2">3D joints. hist. 90.92% [31]</cell><cell cols="2">Kendal Traj. 97.39% [85]</cell></row><row><cell cols="2">SE(3) 97.08%</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 2 :</head><label>2</label><figDesc>Evaluations of (top) SCK/DCK, (middle) our improved SCK</figDesc><table /><note>? / DCK ? and (bottom) the state of the art on UTKinect-Action.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>DCK ? SCK ? + DCK ? acc., prot. [41] 97.50% 90.03% 98.10% acc., prot. [33] 98.12% 94.28%</figDesc><table><row><cell></cell><cell>SCK</cell><cell>DCK</cell><cell>SCK+DCK</cell></row><row><cell cols="3">acc., prot. [41] 90.72% 86.30%</cell><cell>91.45%</cell></row><row><cell cols="3">acc., prot. [33] 93.52% 91.71%</cell><cell>93.96%</cell></row><row><cell>size</cell><cell>40,480</cell><cell>16,920</cell><cell>57,400</cell></row><row><cell></cell><cell cols="3">SCK ? 98.62%</cell></row><row><cell>size</cell><cell>81,200</cell><cell>67,680</cell><cell>148,880</cell></row><row><cell cols="2">accuracy, protocol [41]</cell><cell cols="2">accuracy, protocol [33]</cell></row><row><cell cols="2">Actionlets 88.20% [41]</cell><cell cols="2">SE(3) 92.46% [12]</cell></row><row><cell cols="2">SE(3) 89.48% [12]</cell><cell cols="2">Kendal Traj. 94.19% [85]</cell></row><row><cell cols="4">Kin. desc. 91.07% [87] Ker-RP-RBF 96.9% [47]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 3 :</head><label>3</label><figDesc>Results of (top) SCK/DCK, (middle) our improved SCK ? / DCK ? and (bottom) the state of the art on MSR-Action3D.</figDesc><table><row><cell>cross-subject cross-view</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 4 :</head><label>4</label><figDesc>Results on our SCK and the improved SCK ? on (top) skeleton sequences and (middle) two-stream networks. We also indicate results on the baseline two-stream network with standard average pooling (AP) and maximum pooling (MP). We indicate backbones in parentheses. (bottom) The state of the art on NTU-RGBD. of size 26, 565 dimensions 4 , and produced an accuracy of 92.98% accuracy. As for DCK, our model used Configuration-E (described inFigure 8a) resulting in a representation of dimensionality 16, 920, and achieved a performance of 92%. However, somewhat better results were attained by Configuration-D, that is, 92.27% accuracy for size of 9, 450. Combining SCK and DCK in Configuration-E yields 95.23% accuracy, a 4.5% improvement over the state of the art on this dataset, as listed inTable 1, which highlights the complementary nature of SCK and DCK.</figDesc><table><row><cell>top-1</cell><cell cols="3">SCK+ST-GCN SCK ?+ST-GCN ST-GCN 31.2% 31.8% 30.7%</cell></row><row><cell>top-5</cell><cell>53.7%</cell><cell>54.9%</cell><cell>52.8%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 5 :</head><label>5</label><figDesc>SCK and SCK ? combined with ST-GCN vs. ST-GCN [75] alone on Kinetics</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE 6 :</head><label>6</label><figDesc>Results (mAP%) for (top) our HOK<ref type="bibr" target="#b29">[30]</ref> and improved SCK ?. We also indicate results on the baseline two-stream network with standard average pooling (AP). We indicate backbones in parentheses. (bottom) The state of the art on MPII Cooking Activities.</figDesc><table><row><cell>sp1</cell><cell>sp2</cell><cell>sp3 mean acc.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE 7 :</head><label>7</label><figDesc>Evaluations of (top) our improved SCK ?. We also indicate results on baseline two-stream network with standard average pooling (AP) and maximum pooling (MP). We indicate backbones in parentheses. (bottom) The state of the art on HMDB-51.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">This is the length of a vector per sequence after unfolding our tensor represent./removing duplicate coefficients from the symmetries in the tensor.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Improved Bilinear Pooling with CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A deeper look at power normalizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Higherorder occurrence pooling on mid-and low-level features: Visual concept detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Higher-order occurrence pooling for bags-of-words: Visual concept detection</title>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">OpenPose: realtime multi-person 2D pose estimation using Part Affinity Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hidalgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-E</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sheikh</surname></persName>
		</author>
		<idno>CoRR abs/1812.08008</idno>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Real-time human pose recognition in parts from single depth images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kipman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Finocchio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Joint prediction of activity labels and starting times in untrimmed videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mahmud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Roy-Chowdhury</surname></persName>
		</author>
		<idno>2017. 1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Generalized rank pooling for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gould</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Second-order temporal pooling for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gould</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Locally time-invariant models of human activities using trajectories on the grassmannian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">3D skeleton-based human action classification: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Presti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">La</forename><surname>Cascia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Human action recognition by representing 3D skeletons as points in a Lie Group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vemulapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Arrate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">CVPR</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bregman divergences for infinite dimensional covariance matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Human action recognition using a temporal hierarchy of covariance descriptors on 3D joint locations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Hussein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Torki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gowayyed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>El-Saban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Tracking people on a torus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elgammal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cross-view activity recognition using hankelets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">I</forename><surname>Camps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sznaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Two-stream convolutional networks for action recognition in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning spatiotemporal features with 3d convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Large-scale video classification with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Long-term recurrent convolutional networks for visual recognition and description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Temporal segment networks: Towards good practices for deep action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A closer look at spatiotemporal convolutions for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">P-CNN: Pose-based CNN Features for Action Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ch?ron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">3d convolutional neural networks for human action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A database for fine grained activity detection of cooking activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An approach to pose-based action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Puppet flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="437" to="458" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Quo Vadis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Action Recognition? A New Model and the Kinetics Dataset</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Tensor representations via kernel linearization for action recognition from 3D skeletons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Higher-order pooling of cnn features via kernel linearization for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gould</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">View invariant human action recognition using histograms of 3D joints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Recognizing actions from depth cameras as weakly aligned multi-part bag-of-poses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seidenari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Varano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Berretti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Bimbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Action recognition based on a bag of 3D points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Hmdb: a large video database for human motion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Garrote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2556" to="2563" />
		</imprint>
	</monogr>
	<note type="report_type">ICCV</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Ntu rgb+ d: A large scale dataset for 3d human activity analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shahroudy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1010" to="1019" />
		</imprint>
	</monogr>
	<note type="report_type">CVPR</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The kinetics human action video dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hillier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vijayanarasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Back</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Natsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>CoRR abs/1705.06950</idno>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Kinematic of human motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Zatsiorsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Human Kinetics Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Visual perception of biological motion and a model for its analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception and Psychophysics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="211" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Recognition and segmentation of 3-D human action using hmm and multi-class adaboost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="359" to="372" />
		</imprint>
	</monogr>
	<note type="report_type">ECCV</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">View invariance for human action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="101" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Mining actionlet ensemble for action recognition with depth cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Effective 3D action recognition using eigenjoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis. Comun. Image Represent</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="11" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Parameterized modeling and recognition of activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yacoob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="120" to="128" />
		</imprint>
	</monogr>
	<note type="report_type">ICCV</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Joint angles similarities and HOG 2 for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ohn-Bar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Sequence of the most informative joints (SMIJ)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ofli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kurillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bajcsy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis. Comun. Image Represent</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="38" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Object recognition with hierarchical kernel descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Beyond covariance: Feature representation with nonlinear kernel matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Kernelized covariance for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cavazza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zunino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Biagio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vittorio</surname></persName>
		</author>
		<idno>abs/1604.06582</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Beyond covariance: Sice and kernel based visual feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">A time series kernel for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="63" to="64" />
		</imprint>
	</monogr>
	<note type="report_type">BMVC</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Tensor canonical correlation analysis for action classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-Y</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Non-negative tensor factorization with applications to statistics and computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hazan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Tensortextures: multilinear image-based rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Vasilescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="336" to="342" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Multilinear analysis of image ensembles: Tensorfaces</title>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A survey of multilinear subspace learning for tensor data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Plataniotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Venetsanopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1540" to="1551" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Sparse coding for third-order super-symmetric tensor descriptors with application to texture recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A comprehensive study on third order statistical features for image splicing detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Forensics and Watermarking</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="256" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Convolutional pose machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-E</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramakrishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Deepercut: A deeper, stronger, and faster multiperson pose estimation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Interaction part mining: A mid-level approach for fine-grained action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Space-time behavior based correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Power normalizations in fine-grained image, few-shot image and graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Hallucinating idt descriptors and i3d optical flow features for action recognition with cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Q</forename><surname>Huynh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Second-order democratic aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Few-shot action recognition with permutation-invariant attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="525" to="542" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Power normalizing second-order similarity network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WACV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Adaptive subspaces for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Few-shot object detection by second-order pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">On modulating the gradient for meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Face destylization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DICTA</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Identitypreserving face recovery from portraits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WACV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Recovering faces from portraits with auxiliary facial attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WACV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Identity-preserving face recovery from stylized portraits</title>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">6-7</biblScope>
			<biblScope unit="page" from="863" to="883" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Self-supervising action recognition by statistical moment and subspace descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ACM Multimedia</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Spatial temporal graph convolutional networks for skeleton-based action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Fisher-bures adversary graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">UAI</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="465" to="475" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Simple spectral graph convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">REFINE: Random RangE FInder for network embedding</title>
	</analytic>
	<monogr>
		<title level="j">CIKM</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huckle</surname></persName>
		</author>
		<ptr target="www5.in.tum.de/persons/huckle/tensor-kurs1.pdf" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Probability product kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jebara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="819" to="844" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">On the burstiness of visual elements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1169" to="1176" />
		</imprint>
	</monogr>
	<note type="report_type">CVPR</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Large displacement optical flow: Descriptor matching in variational motion estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="500" to="513" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Dense trajectories and motion boundary descriptors for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kl?ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="60" to="79" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Improving the Fisher Kernel for Large-Scale Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Coding kendall&apos;s shape trajectories for 3d action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Tanfous</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Drira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Amor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Cnn-based action recognition and supervised domain adaptation on 3d body skeletons via kernel feature maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMVC</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">The moving pose: An efficient 3D kinematics descriptor for low-latency action recognition and detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Leordeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">A new representation of skeleton sequences for 3d action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Boussaid</surname></persName>
		</author>
		<idno>2017. 10</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">View adaptive recurrent neural networks for high performance human action recognition from skeleton data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
		<idno>2017. 10</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Learning discriminative video representations using adversarial perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Skeleton based action recognition using translation-scale invariant image mapping and multi-scale deep cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<idno>CoRR abs/1704.05645v2</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Deep bilinear learning for rgb-d action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Non-linear temporal subspace representations for activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Learning long-term dependencies for action recognition with a biologically-inspired deep network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<idno>2017. 11</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Kernel methods for pattern analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Tensor representations via kernel linearization for action recognition from 3D skeletons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<idno>CoRR abs/1604.00239</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>extended version</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
