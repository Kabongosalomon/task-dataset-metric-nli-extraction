<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural sentence embedding models for semantic similarity estimation in the biomedical domain</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathrin</forename><surname>Blagec</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asan</forename><surname>Agibetov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Samwald</surname></persName>
						</author>
						<title level="a" type="main">Neural sentence embedding models for semantic similarity estimation in the biomedical domain</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1186/s12859-019-2789-2</idno>
					<note>R E S E A R C H A R T I C L E Open Access</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Background: Neural network based embedding models are receiving significant attention in the field of natural language processing due to their capability to effectively capture semantic information representing words, sentences or even larger text elements in low-dimensional vector space. While current state-of-the-art models for assessing the semantic similarity of textual statements from biomedical publications depend on the availability of laboriously curated ontologies, unsupervised neural embedding models only require large text corpora as input and do not need manual curation. In this study, we investigated the efficacy of current state-of-the-art neural sentence embedding models for semantic similarity estimation of sentences from biomedical literature. We trained different neural embedding models on 1.7 million articles from the PubMed Open Access dataset, and evaluated them based on a biomedical benchmark set containing 100 sentence pairs annotated by human experts and a smaller contradiction subset derived from the original benchmark set.</p><p>Results: Experimental results showed that, with a Pearson correlation of 0.819, our best unsupervised model based on the Paragraph Vector Distributed Memory algorithm outperforms previous state-of-the-art results achieved on the BIOSSES biomedical benchmark set. Moreover, our proposed supervised model that combines different stringbased similarity metrics with a neural embedding model surpasses previous ontology-dependent supervised stateof-the-art approaches in terms of Pearson's r (r = 0.871) on the biomedical benchmark set. In contrast to the promising results for the original benchmark, we found our best models' performance on the smaller contradiction subset to be poor. Conclusions: In this study, we have highlighted the value of neural network-based models for semantic similarity estimation in the biomedical domain by showing that they can keep up with and even surpass previous state-ofthe-art approaches for semantic similarity estimation that depend on the availability of laboriously curated ontologies, when evaluated on a biomedical benchmark set. Capturing contradictions and negations in biomedical sentences, however, emerged as an essential area for further work.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>that are able to accurately capture and quantify their semantic relatedness. Such semantic measures can be broadly divided into two categories: distributional and knowledge-based metrics, depending on whether they use corpora of texts or ontologies as proxies, respectively. While knowledge-based measures have previously been shown to be more effective for semantic similarity estimation in the biomedical field, they are dependent on the availability of domain-specific ontologies, whose creationdespite the emergence of automatic and semi-automatic ontology learningstill remains a tedious, work-intensive and error-prone task <ref type="bibr" target="#b0">[1]</ref> .</p><p>Furthermore, while previous studies suggest that combining different measures in a supervised model perform well in semantic similarity estimation in the general domain, <ref type="bibr">Sogancioglu et al.</ref> have recently demonstrated the insufficiency of these general domain state-of-the-art sentence similarity computation systems when applied to similarity estimation tasks in the biomedical field <ref type="bibr" target="#b8">(Sogancioglu et al. 2017</ref>; Panchenko and Morozova 2012). By merging different knowledge-based (ontology-based) and distributional (corpus-based) semantic similarity measures that are specifically tailored to the biomedical domain in a supervised model, they demonstrated the superiority of these domain-specific approaches compared to general domain state-of-the art systems. Besides string-based measures and ontologies, they also utilized a distributional vector representation methodology, i.e. the Paragraph Vector model <ref type="bibr" target="#b1">[2]</ref>. Boosted by advances in hardware technology that allow fast processing of large amounts of text data, such neural network-based methods for embedding words, sentences or even larger text elements in low-dimensional vector space have recently caught attention for their ability to effectively capture semantic information <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>Numerous neural network architectures for generating these embeddings have been published in recent years <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>. In contrast to current state-of-the-art models for assessing semantic similarity that depend on the availability of labor-intensively curated ontologies, neural embedding models only require large, unstructured text corpora as input. This makes them especially promising tools for further use in text-related applications in the biomedical domain such as question-answering systems.</p><p>In this study, we investigate the usefulness of current state-of-the-art neural sentence embedding models for semantic similarity estimation in the biomedical domain.</p><p>We evaluate and compare these models based on a biomedical benchmark dataset published previously by Sogancioglu et al. <ref type="bibr" target="#b8">[9]</ref>, thereby building on and extending their work. We demonstrate that these models, both when used as standalone methods or when combined with string-based measures, can keep up with and even surpass previous approaches that utilized sophisticated, manually curated ontologies in terms of their capability to effectively capture semantic information. Furthermore, we present preliminary results on the performance of our best neural embedding models on a small contradiction subset derived from the original benchmark dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BIOSSES benchmark set</head><p>For each of the unsupervised approaches (i.e. sent2vec, skip-thoughts, Paragraph Vector, fastText continuous bag-of-words / C-BOW and fastText skip-gram) we evaluated several different models trained with different parameters on the BIOSSES benchmark set by assessing the correlation between estimated similarity scores and scores assigned by human annotators. Furthermore, we calculated simple string-based similarity scores using Jaccard and q-gram distance for later use in our supervised model. Pearson correlation coefficients for the best results obtained with each method are presented in <ref type="table" target="#tab_0">Table 1</ref>. We also calculated Spearman's r but found it to yield similar values, therefore we only report Pearson's r. <ref type="table" target="#tab_1">Table 2</ref> shows results achieved by current state-of-the-art approaches that we used as baselines for comparing the results of our models. For our unsupervised models, the best result (r = 0.819) was attained by a Paragraph Vector Distributed Memory (PV-DM) model with embedding dimension of 100, trained on a filtered version of our PMC Open Access corpus which contained only lines with less than 200 characters. Our best sent2vec mode, which is characterized by significantly lower computational complexity  <ref type="table" target="#tab_0">Tables S1-S4</ref>. For comparison, we also evaluated a publicly available sent2vec model (700 dimension) trained on general domain text (i.e. English Wikipedia content) and found it to yield a substantially lower correlation score (r = 0.44).</p><p>In general, we found that the following post-processing steps empirically proved to enhance the quality of our sentence embeddings across all models (1) Filtering the corpus for excessively long lines and (2) Separation of compound words that are connected by hyphens.</p><p>We furthermore present the results of a supervised models that combine several of the unsupervised models in a hybrid approach, yielding a correlation of r = 0.871 (see <ref type="table" target="#tab_0">Table 1</ref>).</p><p>Distribution of similarity scores for each best model and correlations between different models are shown in Additional file 1: Figures S1 and S2.</p><p>As can be seen from Tables 1 and 2, both our best unsupervised and our best supervised model outperform previous state-of-the art results. It has to be noted that both supervised models are hybrids of string-based similarity measures and corpus-based embedding models, but do not make use of any ontologies as opposed to the model reported by Sogancioglu et al. <ref type="bibr" target="#b8">[9]</ref> that served as a baseline for our analyses ( <ref type="figure" target="#fig_0">Fig. 1</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contradiction subset</head><p>Besides evaluating our models on the BIOSSES benchmark set, we experimented with a small contradiction dataset that was manually created based on a small subset of the original benchmark set and present preliminary results on these experiments. <ref type="table" target="#tab_2">Table 3</ref> shows mean cosine similarities obtained for the negation and antonym subsets and the subset of sentences that were rated as highly similar by the human experts (score of 3.5 or higher). Lower values indicate lower estimated semantic similarity, whereas higher values indicate higher estimated semantic similarities. We would therefore expect the negation and antonym subsets to show lower estimated cosine similarities than the subset of highly similar sentences. Interestingly, for all considered models, average cosine similarities obtained for the negation and antonym subsets were higher than the average cosine similarities obtained for the subset of semantically highly similar sentences. We refrained from testing for statistical significance due to the limited power of such a test given the low sample size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In recent years, neural network-based approaches have gained attraction in the field of natural language processing due to their ability to effectively capture semantic information by representing words, sentences or even larger text elements in low-dimensional vector space when trained on large text corpora. As these models are easy to train, involving minimal manual work and only requiring large amounts of unstructured text data which is abundantly available given the large number of scientific articles published each year, we were interested in how they would perform compared to current state-of-the-art semantic similarity estimation systems that require the availability of elaborate ontologies. We evaluated several different neural network-based embedding models and compared our results to previous state-of-the-art results on the BIOSSES biomedical benchmark set reported by Sogancioglu et al. <ref type="bibr" target="#b8">[9]</ref>. Experimental results showed that our proposed supervised model that combines different string-based similarity metrics with neural embedding models surpasses previous ontology-dependent supervised state-of-the-art approaches. Furthermore, our best unsupervised model based on the Paragraph Vector Distributed Memory algorithm outperforms previous state-of-the-art results achieved by a standalone neural-based embedding model on the BIOSSES biomedical benchmark set.</p><p>We found our results for the string-based measures, i.e. q-gram and Jaccard, to be slightly different from those reported by Sogancioglu et al. This could be explained by variations in sentence pre-processing since we used the stop word list from the Python NLTK library which covers slightly less words (153 vs. 174, respectively) than the RANKS list utilized by Sogancioglu et al. <ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2</ref> .</p><p>The higher correlation for our Paragraph Vector PV-DBOW model as compared to Sogancioglu et al. may be explained by (1) differences in the choice of model hyper-parameters, and (2) differences in the training corpus and corpus pre-processing. We trained our PV-DBOW model using the same vector dimension and nearly identical hyper-parameters as Sogancioglu et al., except for setting the number of minimal word occurrences to five instead of one to accelerate training. Furthermore, we trained on a much larger corpus despite filtering for line lengths since we used the complete PMC dataset instead of only a subset.</p><p>We used the PubMed Central (PMC) Open Access dataset to train our models, applying a simple heuristic to remove excessively long lines from our corpus that did not contain proper sentences, but were caused by table content instead. Furthermore, we experimented with simple post-processing steps, such as separating compound words that are connected by hyphens, which we found to markedly improve embedding quality. More advanced and exhaustive filtering and cleaning of the data set may improve the corpus quality further and consequently lead to even better training results. This is in line with previous findings by Chiu et al. who evaluated and compared embeddings trained on three different biomedical corpora: (1) the OMC Open Access dataset, (2) the PubMed dataset which contains the abstracts of more than 25 million biomedical scientific publications, and (3) a combination of both corpora. They found that using a combination of both corpora worsened the quality of their embeddings, which they speculatively attributed to the amount of non-prose text in the PMC dataset <ref type="bibr" target="#b9">[10]</ref>. For sent2vec and fastText, we experimented with different hyper-parameter settings based on previously published findings on training embeddings in the biomedical domain <ref type="bibr" target="#b9">[10]</ref>. Spending additional time on hyper-parameter tuning might yield even better embeddings.</p><p>The slightly better results achieved with both PV-DM and PV-DBOW model compared to our best sent2vec model have to be interpreted bearing in mind the differences in computational complexity of these two models, which is O(1) for sent2vec and O(n * |V|) for Paragraph Vector, where n is the number of 'paragraphs' (in our case sentences) and |V| is the size of the input vocabulary <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5]</ref>, resulting in a considerable smaller training time for sent2vec models.</p><p>Surprisingly, our best fastText skip-gram and CBOW models yielded strikingly different correlations on the benchmark set. This inconsistency may be explained by the mechanism by which skip-gram and CBOW models are trained (i.e. learning to predict the context using the current word vs. learning to predict the current word using the context, respectively), potentially making skip-gram models more capable of dealing with rare words. Differences between the performance of skipgram and CBOW models in tasks related to semantic similarity have been reported previously, and might be aggravated by the high frequency of rare words commonly found in biomedical texts, such as protein and gene names, or terms to describe metabolic pathways <ref type="bibr" target="#b10">[11]</ref>. For example, considering the sentence 'Oncogenic KRAS mutations are common in cancer.': While the term KRAS (i.e., an oncogene) may be sufficient to estimate the context (i.e., a context most likely related to cancer, biomedical pathways or similar), reversing the task and predicting the term KRAS from the surrounding words, appears much more difficult, considering that there is a wide range of different oncogenes that may fit into the context.</p><p>Two different approaches for assessing the quality of embeddings can be distinguished: (1) Extrinsic evaluation, which refers to evaluation in the context of a specific natural language processing task, and (2) intrinsic evaluation, which attempts to assess overall embedding quality beyond a specific downstream task by applying similarity or distance metrics. We evaluated our sentence embeddings intrinsically based on a publicly available domain-specific benchmark set and used the degree to which estimated semantic similarity corresponds to similarity scores assigned by human experts in terms of Pearson correlation as our evaluation metric. Albeit this procedure is in line with established practices for assessing embedding quality, such intrinsic evaluation tasks have recently been shown to be insufficient for prediction of performance in downstream tasks <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>Further extrinsic evaluation of neural sentence embeddings, for example, as a part of biomedical question-answering systems, is therefore an essential next step in confirming their value for domain-specific downstream tasks.</p><p>We furthermore conducted a preliminary evaluation of the neural models' ability to detect contradictions between sentence pairs on biomedical topics and found that good performance on semantic similarity estimation does not necessarily imply the ability to distinguish contradicting sentence pairs from highly similar sentence pairs. For sentence pairs that are contradicting each other due to the presence of antonyms, these results can be traced to the context-based learning mode of common neural embedding models, where context is treated as "bag of words", and words with similar contexts are close together in vector space. This potential shortcoming is already known from the domain of sentiment analysis. A commonly applied approach to overcome this issue in the field of sentiment analysis is to use supervised training based on sentiment polarity labels (e.g., positive and negative) <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> that can, e.g., be derived from sentiment lexicons.</p><p>For contradictions due to the presence of a negation, a simple heuristic approach for detecting negations may improve performance. Negation detection in sentences with a complicated syntactic structure may, however, require more sophisticated methods <ref type="bibr" target="#b15">[16]</ref>.</p><p>Since our preliminary evaluation of the usefulness of neural embeddings for contradiction detection in biomedical sentences was limited to a small set of sentences pairs, results have to be interpreted with caution. To be able to thoroughly investigate the ability of novel embedding models to detect contradictions in biomedical statements, an extensive benchmark covering common subtypes of contradictions, such as negation, numerical mismatch or antonym-based contradictions, may be of value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>In this study, we have highlighted the value of neural network-based models for semantic similarity estimation in the biomedical domain by showing that they can keep up with and even surpass previous state-of-the-art approaches for semantic similarity estimation that required the availability of labor-intensive manually curated ontologies. However, we identified current standard neural sentence embedding models' ability to detect contradictions in biomedical sentences as an important area for further research. This dataset contains over 1.7 million biomedical articles that have a Creative Common or similar license. Data are available in both plaintext and XML format via the NCBI FTP site <ref type="bibr" target="#b2">3</ref> . Corpus statistics are shown in <ref type="table" target="#tab_3">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus pre-and post-processing</head><p>Preparing and pre-processing of the training corpus are outlined in <ref type="figure" target="#fig_2">Fig. 2</ref> and comprised the following steps: (1) Generating a single text file that contains all articles of the PMC open access dataset, one sentence per line. <ref type="bibr" target="#b1">(2)</ref> Tokenization. The Stanford CoreNLP library was used for sentence boundary detection and tokenization <ref type="bibr" target="#b16">[17]</ref> .</p><p>Initially, we used the resulting, unfiltered corpus for training our embeddings, which, however, resulted in a disproportionately long training time caused by the occurrence of exceptionally long lines. Inspection of the files revealed that they included content beside sentences, such as large numeric tables. We therefore decided to proceed with the analysis using post-processed versions of the original corpus that were filtered to exclude excessively long lines, to accelerate the training time. Furthermore, we post-processed our training corpus to separate compound words that are connected by hyphens, as we empirically found this processing step to improve our results. For the string-based methods, we removed stop words as defined by the NLTK python library 4 and the following punctuation marks: full stop, comma, colon, semicolon, question mark, exclamation mark, slash, dash.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Embedding models fastText</head><p>fastText is a library that allows unsupervised learning numerical word representations using either the skip-gram or continuous bag-of-words (C-BOW) model <ref type="bibr" target="#b17">[18]</ref>. The C-BOW model learns to predict a target word based on a defined number of surrounding context words (i.e. the windows size) <ref type="bibr" target="#b5">[6]</ref>.</p><p>The skip-gram model learns to predict the context (i.e. the neighbouring words) using the current word. In both cases, the amount of words in of the context is defined by the window size parameter. fastText can also be seen as an extension of the word2vec model. While for word2vec, the defining entity is an entire word, fastText additionally allows for representing each word as a composition of character n-grams with the numerical representation of a word being a sum of these n-grams. Furthermore, it allows for capturing word n-grams. These added features make fastText more amenable to represent rare lexical variations of words, as well as phrases.</p><p>We trained both skip-gram and C-BOW word vectors on our corpus using different hyper-parameter settings shown in Additional file 1: <ref type="table" target="#tab_2">Table S3</ref> using a grid search approach. Sentence vectors were then derived by max, min, sum or average pooling across vectors of all words that constitute the respective sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sent2Vec</head><p>Sent2Vec is an unsupervised model for learning general-purpose sentence embeddings. It can be seen as an extension of the C-BOW model that allows to train and infer numerical representations of whole sentences instead of single words. The algorithm is characterized by its low computational complexity, while simultaneously showing good performance on a wide range of evaluation tasks <ref type="bibr" target="#b4">[5]</ref>.</p><p>We trained sent2vec embeddings on the PMC Open Access corpus using a grid search approach for hyper-parameter tuning. We experimented with different values of the following hyper-parameters: dimension, wordNgrams, epoch, minCount, dropoutK and sampling threshold. Values investigated are listed in Additional file 1: <ref type="table" target="#tab_1">Table S2</ref>. Due to limited computational resources, we did not train all our models for 9 epochs. Furthermore, to put results obtained with models trained on a biomedical corpus into context, we also evaluated the performance of a publicly available sent2vec model that was pre-trained on general domain text (i.e. English Wikipedia content) <ref type="bibr" target="#b4">5</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Skip-thoughts</head><p>Skip-thoughts is a RNN (recurrent neural network)-based model for unsupervised learning of a generic, distributed sentence encoder <ref type="bibr" target="#b6">[7]</ref>. Requiring contiguous sentences S i-1 , S i , S i + 1 as input, the model is trained to predict the previous (S i-1 ) and subsequent sentence (S i + 1 ) based on the current sentence (S i ).</p><p>We used a TensorFlow implementation of the skipthoughts model available at GitHub and trained 2400-dimensional skip-thought vectors using a unidirectional mode ('uni-skip') on our post-processed training corpus <ref type="bibr" target="#b5">6</ref> . We also experimented with vocabulary expansion using GoogleNews word2vec vectors 7 . Hyper-parameters of our skip-thoughts model can be found in Additional file 1: <ref type="table" target="#tab_3">Table S4</ref>. Average line length before post-processing (number of characters)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>162</head><p>Longest line length before post-processing (number of characters)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>111,562</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Paragraph vector</head><p>Paragraph Vector is an unsupervised model for representing variable-length texts, such as sentences, paragraphs or larger documents as fixed-size vectors <ref type="bibr" target="#b1">[2]</ref>. The authors proposed two different versions of the model: (1) A Distributed Memory Model (PV-DM), where, given several contiguous words from a paragraph, the model is trained to predict the following word based on the concatenation of the vectors of the previous words with the vector of the given paragraph. Thus, and as opposed to classical bag-of-words models, information on the ordering of words does not get lost in the PV-DM model. (2) A Distributed Bag of Words (PV-DBOW) version, which is trained to predict words randomly sampled from the given paragraph. We used a Python implementation of the Paragraph vector model available at GitHub 8 and trained 100-dimensional vectors on our corpus using both the PV-DM and PV-DBOW versions of the Paragraph Vector model. Due to the large computing time of these models, we trained only one PV-DM and one PV-DBOW model. Hyper-parameters of these models are shown in Additional file 1: <ref type="table" target="#tab_0">Table S1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation of sentence embeddings BIOSSES benchmark set</head><p>To evaluate our sentence embeddings, we used the BIOSSES dataset, a benchmark set for biomedical sentence similarity estimation <ref type="bibr" target="#b8">[9]</ref>. This dataset comprises 100 sentence pairs stemming from the biomedical domain that were selected by the authors from the TAC (Text Analysis Conference) Biomedical Summarization Track Training Dataset.</p><p>Each of the 100 sentence pairs was evaluated by five human experts who judged their semantic similarity using an ordinal scale ranging from 0 (no relation) to 4 (sentences are semantically equivalent). For each sentence pair, individual ratings were then averaged across all experts, resulting in a continuous value score ranging from 0 to 4. <ref type="table" target="#tab_4">Table 5</ref> shows two pairs of example sentences together with their suggested similarity scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contradiction subset</head><p>The original BIOSSES benchmark set was compiled from citing sentences, i.e. sentences that either reference the same or a different research article, to ensure that different degrees of semantic similarity are represented in the pool of selected sentence pairs. Since this compilation method tends to only yield sentence pairs that are either semantically similar to some degree or unrelated, the resulting set is not suitable to evaluate the ability to accurately capture contradictions between sentence pairs. Contradiction refers to a semantic relation where two statements, e.g., two sentences, are opposed to one another. Subtypes of contradiction include (1) contradiction Since we were interested in getting an insight into our models' performance regarding contradiction detection, we manually created two small contradiction subsets using sentences from the original BIOSSES dataset for experimental purposes: (1) A negation subset containing 13 sentence pairs, where sentence 1 is the original sentence, and sentence 2 its negation, (2) an antonym subset containing 7 sentence pairs, where keywords of the original sentences where replaced by one of their antonyms to shift the sentences' meaning to the opposite. For creating the subsets, candidate sentences with a simple syntactic structure were selected manually. Example sentence pairs for both subsets are listed in <ref type="table" target="#tab_6">Tables 6 and 7</ref>. We calculated average cosine similarities obtained for the negation and antonym subsets with cosine similarities obtained for a subset of sentences from the BIOSSES dataset that were rated as highly similar by the human experts (score of 3.5 or higher). We refrained from testing for statistical significance due to the limited power of such a test given the low sample size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Assessing sentence vector similarity and evaluation with benchmark data set</head><p>Evaluation of different embedding models Using the embedding techniques described above, we generated sentence vectors for each of the 100 biomedical sentences pairs included in the BIOSSES dataset. For each of these sentence pairs, we calculated cosine similarity between vectors generated with the respective embedding model. To evaluate the different embedding models' ability to capture useful semantic properties of sentences, we measured the correlation between calculated semantic similarities and the averaged similarity assessments assigned by the five human experts using both Pearson correlation coefficient (r) and Spearman's correlation coefficient (r s ). Since we found the differences between Pearson's and Spearman's r to be negligible, we only report Pearson's r.</p><p>Unsupervised hybrid model Furthermore, we created a simple unsupervised hybrid model by averaging over the estimated cosine similarities obtained with the stringbased and neural network-based models.</p><p>Supervised model In addition to the unsupervised models, we trained a supervised model using linear regression to predict the averaged annotation scores. We used a combination of string-based similarity coefficients together with vector-based similarity metrics obtained with our embedding models as features for training this model.</p><p>A linear regression can be described by the formula</p><formula xml:id="formula_0">y ? X k j?1 b 0 ? b j x j</formula><p>where y denotes the predicted variable, b 0 the intercept term, b j the estimated coefficient and x j the explanatory variable. In our case, y corresponds to the predicted sentence similarity score, which is predicted based on the similarity scores obtained by the string-and our best neural network-based models (i.e., sent2vec, PV-DM, skip-thoughts, fastText). Similarity measures that we used in our analysis are described in detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Similarity measures String-based Jaccard index</head><p>The Jaccard index is a similarity coefficient that measures similarity between sets by comparing which members of the sets are shared and which are distinct. It is computed by dividing the size of the intersection of the sets by the size of the union of the sets. This article discusses the current data on using anti-HER2 therapies to treat CNS metastasis as well as the newer anti-HER2 agents</p><p>Breast cancers with HER2 amplification have a higher risk of CNS metastasis and poorer prognosis.</p><p>The two sentences are not equivalent, but share some details 2</p><p>The up-regulation of miR-146a was also detected in cervical cancer tissues.</p><p>The expression of miR-146a has been found to be up-regulated in cervical cancer.</p><p>The two sentences are completely or mostly equivalent.</p><p>4 <ref type="table">Table 6</ref> Example sentences of contradiction via negation subset Sentence 1 (original sentence) Sentence 2 (negated sentence)</p><p>Rip1 was reported to interact with rip3. Rip1 was reported to not interact with rip3.</p><p>Moreover, other reports have also shown that necroptosis could be induced via modulating rip1 and rip3.</p><p>Moreover, other reports have also shown that necroptosis could not be induced via modulating rip1 or rip3.</p><formula xml:id="formula_1">J A; B ? ? ? A?B j j A?B j j</formula><p>Applied to the BIOSSES benchmark, set A and B comprise the unique words of sentence 1 and sentence 2, respectively.</p><p>Q-gram similarity A q-gram is a contiguous sequence of q items from a given string, where the items can be letters or words for example. Q-gram similarity is defined as the number of q-grams shared by the respective strings and is calculated by dividing the number of q-gram matches of the second string by the number of possible q-grams determined by the first string.</p><p>Vector-based Cosine similarity Cosine similarity is a widely used metric for semantic similarity. It measures the similarity of two vectors, in our case sentence vectors, based on the cosine of the angle between them.  When expressed alone in primary cells however, oncogenic ras induces premature senescence, a putative tumour suppressor mechanism to protect from uncontrolled proliferation.</p><p>When expressed alone in primary cells however, oncogenic ras inhibits premature senescence, a putative tumour suppressor mechanism to protect from uncontrolled proliferation.</p><p>Two recent studies used rnai-mediated tet2 knock-down in vitro to suggest that tet2 depletion led to impaired hematopoietic differentiation and to preferential myeloid commitment.</p><p>Two recent studies used rnai-mediated tet2 knock-down in vitro to suggest that tet2 depletion led to enhanced hematopoietic differentiation and to preferential myeloid commitment.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Scatterplots showing the correlations between given similarities and scores assigned by human annotators</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Training corpus and pre-and post-processing procedures PubMed central open access dataset We used the complete PubMed Central (PMC) open access subset as of November 2017 as our training corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2</head><label>2</label><figDesc>Pre-and post-processing steps for preparing the training corpus and steps for calculating the similarity metrics by negation, (2) antonym-based contradiction and (3) numeric mismatch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Highest correlation coefficients obtained with different methods</figDesc><table><row><cell>Method</cell><cell>r</cell></row><row><cell>String-based methods</cell><cell></cell></row><row><cell>Jaccard</cell><cell>0.751</cell></row><row><cell>Q-gram (q = 3)</cell><cell>0.723</cell></row><row><cell>Unsupervised</cell><cell></cell></row><row><cell>fastText (skip-gram, max pooling)</cell><cell>0.766</cell></row><row><cell>fastText (CBOW, max pooling)</cell><cell>0.253</cell></row><row><cell>Sent2vec</cell><cell>0.798</cell></row><row><cell>Skip-thoughts</cell><cell>0.485</cell></row><row><cell>Paragraph vector (PV-DM)</cell><cell>0.819</cell></row><row><cell>Paragraph vector (PV-DBOW)</cell><cell>0.804</cell></row><row><cell>Unsupervised combination of several methods (mean)</cell><cell></cell></row><row><cell>Jaccard, q-gram, Paragraph vector (PV-DBOW) and sent2vec</cell><cell>0.846</cell></row></table><note>Supervised combination of several methods Supervised linear regression (Combination of Jaccard, Q-gram, sent2vec, Paragraph vector DM, skip-thoughts, fastText) 0.871r Pearson correlation, CBOW Continuous Bag of Words, PV-DM Paragraph Vector Distributed Memory, PV-DBOW Paragraph Vector Distributed Bag of Words</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Baseline values for our analysis, as reported by Sogancioglu et al.<ref type="bibr" target="#b8">[9]</ref> </figDesc><table><row><cell>Method</cell><cell>r</cell></row><row><cell>Jaccard</cell><cell>0.710</cell></row><row><cell>Q-gram</cell><cell>0.754</cell></row><row><cell>Paragraph Vector (PV-DBOW)</cell><cell>0.787</cell></row><row><cell>Supervised linear regression (Combined ontology method,</cell><cell>0.836</cell></row><row><cell>Paragraph vector, Q-gram)</cell><cell></cell></row><row><cell>PV-DBOW Paragraph Vector Distributed Bag of Words</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Average estimated cosine similarities for sentence pairs included in the negation and antonym subset and a reference set of highly similar sentences per model. Lower values indicate lower estimated semantic similarity; higher values indicate higher estimated semantic similarities</figDesc><table><row><cell></cell><cell>Sent2vec</cell><cell>Skip-thoughts</cell><cell>PV-DM</cell><cell>PV-DBOW</cell><cell>fastText CBOW</cell><cell>fastText skip-gram</cell></row><row><cell>Subset of highly similar sentences (n = 11)</cell><cell>0.706</cell><cell>0.899</cell><cell>0.652</cell><cell>0.568</cell><cell>0.938</cell><cell>0.971</cell></row><row><cell>Negation subset (n = 13)</cell><cell>0.967</cell><cell>0.999</cell><cell>0.930</cell><cell>0.936</cell><cell>0.945</cell><cell>0.979</cell></row><row><cell>Antonym subset (n = 7)</cell><cell>0.983</cell><cell>0.999</cell><cell>0.968</cell><cell>0.960</cell><cell>0.976</cell><cell>0.989</cell></row></table><note>PV-DM Paragraph Vector Distributed Memory, PV-DBOW Paragraph Vector Distributed Bag of Words, CBOW Continuous Bag of Words</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Characteristics of the PMC Open Access dataset</figDesc><table><row><cell>File size</cell><cell>45 GB</cell></row><row><cell>Number of articles</cell><cell>&gt; 1,700,000</cell></row><row><cell>Total number of tokens</cell><cell>8,126,457,106</cell></row><row><cell>Number of unique words</cell><cell>31,974,798</cell></row><row><cell>Number of sentences</cell><cell>277,809,416</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5</head><label>5</label><figDesc>Example sentences from the BIOSSES benchmark set</figDesc><table><row><cell>Sentence 1</cell><cell>Sentence 2</cell><cell>Comment</cell><cell>Score</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Endnotes 1 https://www.nltk.org/ 2 https://www.ranks.nl/stopwords 3 http://ftp.ncbi.nlm.nih.gov/pub/pmc 4 https://www.nltk.org/ 5 https://github.com/klb3713/sentence2vec 6 https://github.com/tensorflow/models/tree/master/research/skip_thoughts 7 https://github.com/tmikolov/word2vec 8 https://github.com/klb3713/sentence2vec</figDesc><table><row><cell>cos ? ? ? ?</cell><cell>A ? B A k k B k k</cell></row><row><cell cols="2">Additional file</cell></row></table><note>Additional file 1: Supplementary tables and figures. (DOCX 181 kb) Abbreviations C-BOW: Continuous-bag-of-words; PMC: PubMed Central; PV- DBOW: Paragraph Vector Distributed Bag of Words; PV-DM: Paragraph Vector Distributed Memory</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7</head><label>7</label><figDesc>Example sentences of contradiction via antonyms subset</figDesc><table><row><cell>Sentence 1 (original sentence)</cell><cell>Sentence 2 (negated sentence)</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Blagec et al. BMC Bioinformatics(2019) 20:178</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We want to thank the development teams behind fastText and sent2vec for making these software packages openly available. Furthermore we want to thank Chris Shallue for making his implementation of skip-thoughts available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>A part of the research leading to these results has received funding from the European Community's Horizon 2020 Programme under grant agreement No. 668353 (U-PGx). The funding body was not involved in the design of the study and collection, analysis, and interpretation of data or in writing the manuscript.</p><p>Availability of data and materials Datasets generated and/or analyzed during the current study and Jupyter notebooks are available through Github at https://github.com/kathrinblagec/ neural-sentence-embedding-models-for-biomedical-applications Authors' contributions MS devised the study, KB carried out experiments and conducted data analysis. KB and HX conducted data preparation. MS, KB, HX and AA participated in authoring the manuscript. All authors have read and approved the manuscript.</p><p>Ethics approval and consent to participate Not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent for publication</head><p>Not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare that they have no competing interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Publisher's Note</head><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic similarity in the biomedical domain: an evaluation across knowledge sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Garla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">261</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v32/le14.html" />
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1188" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Word representations: a simple and general method for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1858681.1858721" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th annual meeting of the Association for Computational Linguistics<address><addrLine>Stroudsburg</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="384" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162.</idno>
		<ptr target="https://doi.org/10.3115/v1/D14-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing</title>
		<meeting>the 2014 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pagliardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc 2018 Conf north am chapter Assoc Comput linguist hum Lang Technol</title>
		<meeting>2018 Conf north am chapter Assoc Comput linguist hum Lang Technol</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="528" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1301.3781" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Skipthought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2969442.2969607" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th international conference on neural information processing systems</title>
		<meeting>the 28th international conference on neural information processing systems<address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3294" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2999792.2999959" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th international conference on neural information processing systems</title>
		<meeting>the 26th international conference on neural information processing systems<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3111" to="3120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">BIOSSES: a semantic sentence similarity estimation system for the biomedical domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sogancioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>?zt?rk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>?zg?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinforma Oxf Engl</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="49" to="58" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">How to train good word Embeddings for biomedical NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Crichton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W16-2922.</idno>
		<ptr target="https://doi.org/10.18653/v1/W16-2922" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th workshop on biomedical natural language processing</title>
		<meeting>the 15th workshop on biomedical natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="166" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Applying deep learning techniques on medical corpora from the world wide web: a prototypical system and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Mi?arro-Gim?nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mar?n-Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Samwald</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1502.03682" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Intrinsic evaluation of word vectors fails to predict extrinsic performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<ptr target="http://anthology.aclweb.org/W16-2501" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st workshop on evaluating vector-space representations for NLP</title>
		<meeting>the 1st workshop on evaluating vector-space representations for NLP<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Re-embedding words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P13-2087" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="489" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning Sentiment-Specific Word Embedding via Global Sentiment Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI: Association for the Advancement</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Refining word Embeddings for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L-C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1056</idno>
		<ptr target="https://doi.org/10.18653/v1/D17-1056" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 conference on empirical methods in natural language processing</title>
		<meeting>the 2017 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="534" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural networks for negation scope detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fancellu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Webber</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1047</idno>
		<ptr target="https://doi.org/10.18653/v1/P16-1047" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th annual meeting of the Association for Computational Linguistics<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="495" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P14-5010.</idno>
		<ptr target="https://doi.org/10.3115/v1/P14-5010" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd annual meeting of the Association for Computational Linguistics: system demonstrations: Association for Computational Linguistics</title>
		<meeting>52nd annual meeting of the Association for Computational Linguistics: system demonstrations: Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1607.04606" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
