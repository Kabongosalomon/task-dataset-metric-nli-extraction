<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Embarrassingly Easy but Strong Baseline for Nested Named Entity Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaonan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
							<email>xpqiu@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An Embarrassingly Easy but Strong Baseline for Nested Named Entity Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Named entity recognition (NER) is the task to detect and classify the entity spans in the text. When entity spans overlap between each other, this problem is named as nested NER. Span-based methods have been widely used to tackle the nested NER. Most of these methods will get a score n ? n matrix, where n means the length of sentence, and each entry corresponds to a span. However, previous work ignores spatial relations in the score matrix. In this paper, we propose using Convolutional Neural Network (CNN) to model these spatial relations in the score matrix. Despite being simple, experiments in three commonly used nested NER datasets show that our model surpasses several recently proposed methods with the same pre-trained encoders. Further analysis shows that using CNN can help the model find more nested entities. Besides, we found that different papers used different sentence tokenizations for the three nested NER datasets, which will influence the comparison. Thus, we release a pre-processing script to facilitate future comparison 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named Entity Recognition (NER) is the task to extract entities from raw text. It has been a fundamental task in the Natural Language Processing (NLP) field. Previously, this task is mainly solved by the sequence labeling paradigm through assigning a label to each token <ref type="bibr" target="#b7">(Huang et al., 2015;</ref><ref type="bibr" target="#b16">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b26">Yan et al., 2019)</ref>. However, this method is not directly applicable to the nested NER scenario, since a token may be included in two or more entities. To overcome this issue, the spanbased method which assigns labels to each span was introduced <ref type="bibr" target="#b4">(Eberts and Ulges, 2020;</ref><ref type="bibr" target="#b28">Yu et al., 2020)</ref>. * Corresponding author. <ref type="bibr">1</ref> Code is available at https://github.com/yhcc/ CNN_Nested_NER.  <ref type="figure">Figure 1</ref>: All valid spans of a sentence. We use the start and end tokens to pinpoint a span, for instance, "(2-4)" represents "New York University". Spans in the two orange dotted squares indicates that the center span can have the special relationship (different relations are depicted in different colors) with its surrounding spans. For example, the span "New York" (2-3) is contained by the span "New York University" (2-4). Therefore, the "(2-3)" span is annotated as "d".</p><p>Eberts and Ulges (2020) used a pooling method over token representations to get the span representation, and then conducted classification on this span representation.  transformed the NER task into a Machine Reading Comprehension form, they used the entity type as the query, and asked the model to select the spans that belong to this entity type. <ref type="bibr" target="#b28">Yu et al. (2020)</ref> utilized the Biaffine decoder from dependency parsing <ref type="bibr" target="#b3">(Dozat and Manning, 2017)</ref> to convert the span classification into classifying the start and end token pairs. However, these work did not take advantage of the spatial correlations between adjacent spans. <ref type="figure">Figure 1</ref>, the spans surrounding a span have special relationships with the center span. It should be beneficial if we can leverage these spatial correlations. In this paper, we use the Biaffine decoder <ref type="bibr" target="#b3">(Dozat and Manning, 2017)</ref> to get a 3D feature matrix, where each entry represents one span. After that, we view this feature matrix as an image and utilize Convolutional Neural Network (CNN) to model the local interaction between spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>As depicted in</head><p>We compare this simple method with recently proposed methods <ref type="bibr" target="#b23">(Wan et al., 2022;</ref><ref type="bibr" target="#b30">Zhu and Li, 2022;</ref><ref type="bibr" target="#b29">Yuan et al., 2022)</ref>. To make sure our method is strictly comparable to theirs, we asked the authors for their version of data. Although all of them used the same datasets, we found that the statistics, such as the number of sentences and entities, were not the same. This was caused by the usage of distinct sentence tokenization methods, which will influence the performance as shown in our experiments. To facilitate future comparison, we release a pre-processing script 2 for ACE2004, ACE2005 and Genia datasets.</p><p>Our contributions can be summarized as follows.</p><p>? We find that the adjacent spans have special correlations between each other, and we propose using CNN to model the interaction between them. Despite being very simple, it achieves a considerable performance boost in three widely used nested NER datasets.</p><p>? We release a pre-processing script for the three nested NER datasets to facilitate direct and fair comparison.</p><p>? The way we view the span feature matrix as an image shall shed some light on future exploration of span-based methods for nested NER task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Previously, four kinds of paradigms have been proposed to solve the nested NER task. The first one is the sequence labeling framework <ref type="bibr" target="#b19">(Strakov? et al., 2019)</ref>, since one token can be contained in more than one entities, the Cartesian product of the entity labels are used. However, the Cartesian labels will suffer from the long-tail issue.</p><p>The second one is to use the hypergraph to efficiently represent spans <ref type="bibr" target="#b14">(Lu and Roth, 2015;</ref><ref type="bibr"></ref> Muis and <ref type="bibr" target="#b17">Lu, 2016;</ref><ref type="bibr" target="#b8">Katiyar and Cardie, 2018;</ref><ref type="bibr" target="#b24">Wang and Lu, 2018)</ref>. The shortcoming of this method is the complex decoding. The third one is the sequence-to-sequence (Seq2Seq) framework <ref type="bibr" target="#b20">(Sutskever et al., 2014;</ref><ref type="bibr" target="#b11">Lewis et al., 2020;</ref><ref type="bibr" target="#b18">Raffel et al., 2020)</ref> to generate the entity sequence. The entity sequence can be the entity pointer sequence <ref type="bibr" target="#b27">(Yan et al., 2021;</ref><ref type="bibr" target="#b5">Fei et al., 2021)</ref> or the entity text sequence <ref type="bibr" target="#b15">(Lu et al., 2022)</ref>. Nevertheless, the Seq2Seq method suffers from the time-demanding decoding.</p><p>The fourth one is to conduct span classification. <ref type="bibr" target="#b4">Eberts and Ulges (2020)</ref> proposed to enumerate all possible spans within a sentence, and use a pooling method to get the span representation. While <ref type="bibr" target="#b28">Yu et al. (2020)</ref> proposed to use the start and end tokens of a span to pinpoint the span, and use the Biaffine decoder to get the scores for each span. The span-based methods are friendly to parallelism and the decoding is easy. Therefore, this formulation has been widely adopted <ref type="bibr" target="#b23">(Wan et al., 2022;</ref><ref type="bibr" target="#b30">Zhu and Li, 2022;</ref><ref type="bibr" target="#b29">Yuan et al., 2022)</ref>. However, the relation between neighbor spans was ignored in previous work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Method</head><p>In this section, we first introduce the nested NER task, then describe how to get the feature matrix. After that, we present the CNN module to model the spatial correlation on the feature matrix. A general framework of our proposed method can be viewed in <ref type="figure" target="#fig_1">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Nested NER Task</head><p>Given an input sentence X = [x 1 , x 2 , . . . , x n ] with n tokens, the nested NER task aims to extract all entities in X. Each entity can be expressed as a tuple (s i , e i , t i ). s i , e i are the start, end index of the entity. t i ? {1, . . . , |T |} is its entity type and |T | is the number of entity types. As the task name suggests, the entities may overlap with each other, but different entities are not allowed to have crossing boundaries. For a sentence with n tokens, there are n(n + 1)/2 valid spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Span-based Method for Nested NER</head><p>We follow <ref type="bibr" target="#b28">Yu et al. (2020)</ref> to formulate this task into a span classification task. Namely, for each valid span, the model assigns an entity label to it. The method first uses an encoder to encode the input sentence as follows:</p><formula xml:id="formula_0">H = Encoder(X),</formula><p>where H ? R n?d , and d is the hidden size. Various pre-trained models, such as BERT <ref type="bibr" target="#b1">(Devlin et al., 2019)</ref>, are usually used as the encoder. For the word tokenized into several pieces, we use maxpooling to aggregate from its pieces' hidden states.</p><p>After getting the contextualized embedding of tokens, previous work usually would concatenate it with the static word embedding and the character embedding, and then send this combined embedding into a BiLSTM layer <ref type="bibr" target="#b28">(Yu et al., 2020;</ref><ref type="bibr" target="#b23">Wan et al., 2022;</ref><ref type="bibr" target="#b29">Yuan et al., 2022)</ref>. To make the model less cluttered, we neither use more embeddings, nor the BiLSTM layer.</p><p>Next, we use a multi-head Biaffine decoder <ref type="bibr" target="#b3">(Dozat and Manning, 2017;</ref><ref type="bibr" target="#b21">Vaswani et al., 2017)</ref> to get the score matrix as follows:</p><formula xml:id="formula_1">H s = LeakyReLU(HW s ), H e = LeakyReLU(HW e ), R = MHBiaffine(H s , H e )</formula><p>where W s , W e ? R d?h , h is the hidden size, MHBiaffine(?, ?) is the multi-head Biaffine decoder 3 , and R ? R n?n?r , r is the feature size. Each cell (i, j) in the R can be seen as the feature <ref type="bibr">3</ref> The detailed description is in the Appendix.</p><p>vector v ? R r for the span. And for the lower triangle of R (where i &gt; j), the span contains words from the j-th to the i-th (Therefore, one span will have two entries if it is off-diagonal).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">CNN on Score Matrix</head><p>As shown in <ref type="figure">Figure 1</ref>, the cell has relations with cells around. Therefore, we propose using CNN to model these interactions. We repeat the following CNN block several times in our model:</p><formula xml:id="formula_2">R = Conv2d(R), R = GeLU(LayerNorm(R + R)),</formula><p>where Conv2d, LayerNorm and GeLU are the 2D CNN, layer normalization <ref type="bibr" target="#b0">(Ba et al., 2016)</ref> and GeLU activation function <ref type="bibr" target="#b6">(Hendrycks and Gimpel, 2016)</ref>. The layer normalization is conducted in the feature dimension. A noticeable fact here is that since the number of tokens n in sentences varies, their Rs are of different shapes. To make sure results are the same when R is processed in batch, the 2D CNN has no bias term, and all the paddings in R are filled with 0.</p><p>After passing through several CNN blocks, the R will be further processed by another 2D CNN module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">The Output</head><p>We use a perceptron to get the prediction logits as follows: 4</p><formula xml:id="formula_3">P = Sigmoid(W o (R + R ) + b), where W o ? R |T |?r , b ? R |T | , P ? R n?n?|T | .</formula><p>And then, we use the binary cross entropy to calculate the loss as</p><formula xml:id="formula_4">L BCE = ? 0?i,j&lt;n y ij log(P ij ),</formula><p>unlike previous works that only use the upper triangle part to get the loss <ref type="bibr" target="#b28">(Yu et al., 2020;</ref><ref type="bibr" target="#b30">Zhu and Li, 2022)</ref>, we use both upper and lower triangles to calculate the loss. The reason is that in order to conduct batch computation, we cannot solely compute the upper triangle part. Since the lower triangle part has been computed, we also use them for the output. The tag for the score matrix is symmetric, namely, the tag in the (i, j)-th entry is the same as in the (j, i)-th. When inference, we calculate scores in the upper triangle part as:P ij = (P ij + P ji )/2, where i ? j. Then we only use this upper triangle score to get the final prediction. The decoding process generally follows <ref type="bibr" target="#b28">Yu et al. (2020)</ref>'s method. We first prune out the non-entity spans (none of its scores is above 0.5), then we sort the remained spans based on their maximum entity score. We pick the spans based on this order, if a span's boundary clashes with selected spans, it is ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>To verify the effectiveness of our proposed method, we conduct experiments in three widely used nested NER datasets, ACE 2004 5 <ref type="bibr" target="#b2">(Doddington et al., 2004)</ref>, ACE 2005 6 <ref type="bibr" target="#b22">(Walker and Consortium, 2005)</ref> and Genia <ref type="bibr" target="#b9">(Kim et al., 2003)</ref>.</p><p>Besides, we choose recently published papers as our baselines. To make sure our experiments are strictly comparable to theirs, we asked the authors for their version of data. The data statistics for each 5 https://catalog.ldc.upenn.edu/ LDC2005T09 6 https://catalog.ldc.upenn.edu/ LDC2006T06 paper are listed in the Appendix. For ACE2004 and ACE2005, although all of them used the same document split as suggested <ref type="bibr" target="#b14">(Lu and Roth, 2015)</ref>, they used different sentence tokenizations, resulting in different numbers of sentences and entities. To facilitate future research on nested NER, we release the pre-processing code and fix some tokenization issues to avoid including unannotated text and dropping entities. While for the Genia data, we fixed some annotation conflicts (the same sentence with different entity annotations). We replicate each experiment five times and report its average performance with standard derivation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Main Results</head><p>Results for ACE2004 and ACE2005 are listed in <ref type="table">Table 1</ref>, and for Genia is listed in <ref type="table">Table 2</ref>. When using the same data from previous work, our simple CNN model surpasses the baselines with less or similar number of parameters, which proves that using CNN to model the interaction between neighbor spans can be beneificial to the nested NER task. Besides, in the bottom block, we reproduced some baselines in our newly processed data to facilitate future comparison. Comparing the last block (processed by us) and the upper blocks (data from previous work), different tokenizations can indeed influence the performance. Therefore, we appeal for the same tokenization for future comparison.  <ref type="table">Table 2</ref>: Experiment results for the Genia Dataset. "W2NER", "SG" and "Triaffine" are from , <ref type="bibr" target="#b23">(Wan et al., 2022)</ref> and <ref type="bibr" target="#b29">(Yuan et al., 2022)</ref>, all models use the BioBERT-base   <ref type="table">Table 3</ref>: The precision and recall for flat and nested entities in the test set of three datasets. FEP, FER, NEP and NER are the flat entity precision, flat entity recall, nested entity precision and nested entity recall, respectively. Compared with models without CNN ("w.o. CNN"), the most improved metric is bold. By using CNN, the recall for nested entities improve significantly. The subscript means the standard deviation (e.g 88.8 0.9 means 88.8?0.9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Why CNN Helps</head><p>To study why CNN can boost the performance of the nested NER datasets, we split entities into two kinds. One kind is entities that overlap with other entities, and the other kind is entities that do not. The results of FEP, FER, NEP, and NER 7 are listed 7 The detailed calculation description of the four metrics locate in the Appendix.</p><p>in <ref type="table">Table 3</ref>. Compared with models without CNN, the NEP of models with CNN improved for 2.2, 2.8 and 10.7 for ACE2004, ACE2005 and Genia respectively. Namely, much of the performance improvement can be ascribed to finding more nested entities. This is expected as the CNN can be more effective for exploiting the neighbor entities when they are nested.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose using CNN on the score matrix of span-based NER model. Although this method is very simple, it achieves comparable or better performance than recently proposed methods. Analysis shows exploiting the spatial correlation between neighbor spans through CNN can help model find more nested entities. And experiments show that different tokenizations indeed influence the performance. Therefore, it is necessary to make sure all comparative baselines uses the same tokenization. To facilitate future comparison, we release a new pre-processing script for three nested NER datasets. e ? R n?h k ; h k is the hidden size for each head, and U ? R h k ?r k ?h k , S 2 ? R n?n?r , and R ? R n?n?r .</p><p>We did not use multi-head for W , because it does not occupy too much parameters and using multi-head for W harms the performace slightly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Data</head><p>We list the statistics for each datasets in <ref type="table">Table 4</ref>. As shown in the table, the number of sentences and even the number of entities are different for each paper. Therefore, it is not fair to directly compare results. For the ACE2004 and ACE2005, we release the pre-processing code to get data from the LDC files. We make sure no entities are dropped <ref type="table">Table 4</ref>: The statistics used in each paper. "W2NER" 8 , "SG", "BS" and "Triaffine" are from , <ref type="bibr" target="#b23">(Wan et al., 2022)</ref>, <ref type="bibr" target="#b30">(Zhu and Li, 2022)</ref> and <ref type="bibr" target="#b29">(Yuan et al., 2022)</ref>, respectively. Different papers used different sentence tokenization for ACE2004 and ACE2005, resulting in different numbers of sentences in each split. To facilitate future comparison, we open-sourced a pre-processing script to prepare ACE2004 and ACE2005. Previously, some entities will be dropped because of sentence tokenization, we avoid sentence tokenization within an entity and resulting in more entities. And for Genia, different papers used different train/dev/test splits. Besides, the Genia data has conflicting annotations, we remove these sentences. The data annotated with "Ours" is obtained by our pre-processing code.</p><p>because of the sentence tokenization. Thus, the pre-processed ACE2004 and ACE2005 data from this work in <ref type="table">Table 4</ref> have the most entities. And for Genia, we appeal for the usage of train/dev/test, and we release the data split within the code repo. Moreover, in order to facilitate the document-level NER study, we split the Genia dataset based on documents. Therefore, sentences from train/dev/test splits are from different documents, the document ratio for train/dev/test is 8:1:1. Besides, we found one conflicting document annotation in Genia, we fix this confict. After comparing different versions of Genia, we found the W2NER  and Triaffine <ref type="bibr" target="#b29">(Yuan et al., 2022)</ref> dropped the spans with more than one entity tags (there are 31 such entities). Thus, they have less number of nested entities than us. While SG <ref type="bibr" target="#b23">(Wan et al., 2022)</ref> includes the discontinuous entities, so they have more number of nested entities than us.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Implementation Details</head><p>We used the AadmW optimizer to optimize the model and the transformers package for the pretrained model <ref type="bibr" target="#b25">(Wolf et al., 2020)</ref>. The hyperparameter range in this paper is listed in <ref type="table">Table 5</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FCFigure 2 :</head><label>2</label><figDesc>The proposed method in this paper. Use several blocks of CNN to model the spatial correlations between neighbor spans.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>87.8238 87.4020 87.6118 86.3961 87.2434 86.8245 w.o. CNN[BERT-large] 343.6 86.5448 87.0941 86.8121 84.8826 86.9933 85.9227</figDesc><table><row><cell></cell><cell># Param.</cell><cell></cell><cell>ACE2004</cell><cell></cell><cell></cell><cell>ACE2005</cell></row><row><cell></cell><cell>(Million)</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>Data from Li et al. (2022)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">W2NER (Li et al., 2022)[BERT-large] 355.4 87.33</cell><cell>87.71</cell><cell>87.52</cell><cell>85.03</cell><cell>88.62</cell><cell>86.79</cell></row><row><cell cols="2">Ours[BERT-large] 345.1 Data from Wan et al. (2022)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SG (Wan et al., 2022)[BERT-base]</cell><cell cols="2">112.3 86.70</cell><cell>85.93</cell><cell>86.31</cell><cell>84.37</cell><cell>85.87</cell><cell>85.11</cell></row><row><cell>Ours[BERT-base]</cell><cell cols="7">110.5 86.8561 86.4536 86.6522 84.9449 85.4027 85.1616</cell></row><row><cell>w.o. CNN[BERT-base]</cell><cell cols="7">109.1 85.7946 85.7812 85.7822 82.9121 84.8923 83.8916</cell></row><row><cell>Data from Zhu and Li (2022)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">BS (Zhu and Li, 2022)[RoBERTa-base] 125.6 88.43</cell><cell>87.53</cell><cell>87.98</cell><cell>86.25</cell><cell>88.07</cell><cell>87.15</cell></row><row><cell>Ours[RoBERTa-base]</cell><cell cols="7">125.6 87.7727 88.2836 88.0314 86.5878 87.9446 87.2548</cell></row><row><cell>w.o. CNN[RoBERTa-base]</cell><cell cols="7">125.2 86.7127 87.4042 87.0518 85.4839 87.5459 86.5026</cell></row><row><cell>Data from this work</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>W2NER[BERT-large] ?</cell><cell cols="7">355.4 87.1711 87.7019 87.4311 85.7830 87.8124 86.7721</cell></row><row><cell>Ours[BERT-large]</cell><cell cols="7">345.1 87.9830 87.5022 87.7416 86.2665 87.5631 86.9123</cell></row><row><cell>w.o. CNN[BERT-large]</cell><cell cols="7">343.6 86.6068 86.4836 86.5419 84.9134 87.3926 86.1330</cell></row><row><cell>BS[RoBERTa-base] ?</cell><cell cols="7">125.6 87.3240 86.8416 87.0824 86.5838 87.8459 87.2032</cell></row><row><cell>Ours[RoBERTa-base]</cell><cell cols="7">125.6 87.3341 87.2925 87.3116 86.7029 88.1654 87.4226</cell></row><row><cell>w.o. CNN[RoBERTa-base]</cell><cell cols="7">125.2 86.0936 86.8823 86.4817 85.1767 88.035 86.5638</cell></row></table><note>Table 1: Results for the ACE2004 and ACE2005 datasets. Models in the same block use the same data. The subscript means the standard deviation (e.g 87.73 18 means 87.73?0.18). ? means our reproducation with their publicly available code.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/yhcc/CNN_Nested_ NER/tree/master/preprocess</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We did not use the Softmax because in the very rare case (such as in the ACE2005 and Genia dataset), one span can have more than one entity tag.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">The number of entites is different from that reported in their paper, because we found some duplicated entities in their data.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Multi-head Biaffine Decoder</head><p>The input of Multi-head Biaffine decoder is two matrix H s , H e ? R n?h , and the output is R ? R n?n?r . The formulation of Multi-head Biaffine decoder is as follows</p><p>where H s , H e ? R n?h , h is the hidden size, w i?j ? R c is the span length embedding for length i ? j, W ? R (2h+c)?r , S 1 ? R n?n?r , r is the biaffine feature size, Split(?) equally splits a matrix in the last dimension, thus, H</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D FEP FER NEP NER</head><p>We split entities into two kinds based on whether they overlap with other entities, and the statistics   for each dataset are listed in <ref type="table">Table 6</ref>. When calculating the flat entity precision (FEP), we first get all flat entities in the prediction and calculate their ratio in the gold. For the flat entity recall (FER), we get all flat entities in the gold and calculate their ratio in the prediction. And we get the nested entity precision (NEP) and nested entity recall (NER) similarly.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<idno>abs/1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA; Long and Short Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-02" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The automatic content extraction (ACE) program -tasks, data, and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">R</forename><surname>Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><forename type="middle">A</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><forename type="middle">M</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><forename type="middle">M</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Language Resources and Evaluation</title>
		<meeting>the Fourth International Conference on Language Resources and Evaluation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05-26" />
		</imprint>
	</monogr>
	<note>European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep biaffine attention for neural dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. Open-Review.net</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Span-based joint entity and relation extraction with transformer pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Eberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Ulges</surname></persName>
		</author>
		<idno type="DOI">10.3233/FAIA200321</idno>
	</analytic>
	<monogr>
		<title level="m">-Including 10th Conference on Prestigious Applications of Artificial Intelligence</title>
		<meeting><address><addrLine>Santiago de Compostela, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2020-08-29" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="2006" to="2013" />
		</imprint>
	</monogr>
	<note>ECAI 2020 -24th European Conference on Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Rethinking boundaries: End-to-end recognition of discontinuous mentions with pointer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Hao Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bobo</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yafeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021-02-02" />
			<biblScope unit="page" from="12785" to="12793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Bridging nonlinearities and stochastic regularizers with gaussian error linear units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<idno>abs/1606.08415</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bidirectional LSTM-CRF models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno>abs/1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Nested named entity recognition revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arzoo</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n18-1079</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06-01" />
			<biblScope unit="page" from="861" to="871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">GENIA corpus -a semantically annotated corpus for bio-textmining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Intelligent Systems for Molecular Biology</title>
		<meeting>the Eleventh International Conference on Intelligent Systems for Molecular Biology<address><addrLine>Brisbane, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06-29" />
			<biblScope unit="page" from="180" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonjin</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunkyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chan</forename><surname>Ho So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btz682</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinform</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.703</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07-05" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unified named entity recognition as wordword relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengqiong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Sixth AAAI Conference on Artificial Intelligence, AAAI 2022, Thirty-Fourth Conference on Innovative Applications of Artificial Intelligence, IAAI 2022, The Twelveth Symposium on Educational Advances in Artificial Intelligence, EAAI 2022 Virtual Event</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2022-02-22" />
			<biblScope unit="page" from="10965" to="10973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A unified MRC framework for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingrong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxian</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.519</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07-05" />
			<biblScope unit="page" from="5849" to="5859" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Joint mention extraction and classification with mention hypergraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d15-1102</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09-17" />
			<biblScope unit="page" from="857" to="867" />
		</imprint>
	</monogr>
	<note>The Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unified structure generation for universal information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaojie</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.395</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022-05-22" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5755" to="5772" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p16-1101</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-08-07" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Long Papers. The Association for Computer Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning to recognize discontiguous entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldrian</forename><surname>Obaja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d16-1008</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-01" />
			<biblScope unit="page" from="75" to="84" />
		</imprint>
	</monogr>
	<note>EMNLP</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural architectures for nested NER through linearization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Strakov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1527</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-01" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5326" to="5331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-08" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Linguistic Data</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Consortium</surname></persName>
		</author>
		<title level="m">ACE 2005 Multilingual Training Corpus. LDC corpora. Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Nested named entity recognition with span-level graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncheng</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyu</forename><surname>Ru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-05-22" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="892" to="903" />
		</imprint>
	</monogr>
	<note>ACL 2022</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Neural segmental hypergraphs for overlapping mention recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-1019</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10-31" />
			<biblScope unit="page" from="204" to="214" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teven</forename><forename type="middle">Le</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">TENER: adapting transformer encoder for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bocao</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaonan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<idno>abs/1911.04474</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A unified generative framework for various NER subtasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqi</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qipeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.451</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5808" to="5822" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Named entity recognition as dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juntao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.577</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-07-05" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="6470" to="6476" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fusing heterogeneous factors with triaffine mechanism for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-acl.250</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-05-22" />
			<biblScope unit="page" from="3174" to="3186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Boundary smoothing for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enwei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinpeng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022-05-22" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7096" to="7108" />
		</imprint>
	</monogr>
	<note>ACL 2022. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<title level="m">Sentence Mention #Train #Dev #Test Avg. Len #Ovlp. #Train #Dev #Test Avg. Len ACE2004 W2NER 6</title>
		<imprint>
			<biblScope unit="volume">802</biblScope>
		</imprint>
	</monogr>
	<note>056 2,492 3,020 2.5 SG 6.198 742 809 21.55 12,666 22,195 2,514 3,034 2.51 BS 6,799 829 879 20.43 12,679 22,207 2,511 3,031 2.51 Ours 6,297 742 824 23.52 12,690 22,231 2,514 3,036 2.64</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Triaffine</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="509" to="514" />
		</imprint>
	</monogr>
	<note>506 1.97 Ours 15,038 1,765 1,732 26.47 10,315 46,203 4,714 5,119 2.0</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
