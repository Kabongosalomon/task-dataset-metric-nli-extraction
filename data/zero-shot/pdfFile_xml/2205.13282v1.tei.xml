<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 On the Eigenvalues of Global Covariance Pooling for Fine-grained Visual Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Yue</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Senior Member, IEEE</roleName><forename type="first">Nicu</forename><forename type="middle">Sebe</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Wei</forename><surname>Wang</surname></persName>
						</author>
						<title level="a" type="main">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 On the Eigenvalues of Global Covariance Pooling for Fine-grained Visual Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Global Covariance Pooling</term>
					<term>Fine-grained Classification</term>
					<term>Bilinear Pooling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Fine-Grained Visual Categorization (FGVC) is challenging because the subtle inter-class variations are difficult to be captured. One notable research line uses the Global Covariance Pooling (GCP) layer to learn powerful representations with second-order statistics, which can effectively model inter-class differences. In our previous conference paper, we show that truncating small eigenvalues of the GCP covariance can attain smoother gradient and improve the performance on large-scale benchmarks. However, on fine-grained datasets, truncating the small eigenvalues would make the model fail to converge. This observation contradicts the common assumption that the small eigenvalues merely correspond to the noisy and unimportant information. Consequently, ignoring them should have little influence on the performance. To diagnose this peculiar behavior, we propose two attribution methods whose visualizations demonstrate that the seemingly unimportant small eigenvalues are crucial as they are in charge of extracting the discriminative class-specific features. Inspired by this observation, we propose a network branch dedicated to magnifying the importance of small eigenvalues. Without introducing any additional parameters, this branch simply amplifies the small eigenvalues and achieves state-of-the-art performances of GCP methods on three fine-grained benchmarks. Furthermore, the performance is also competitive against other FGVC approaches on larger datasets. Code is available at https://github.com/KingJamesSong/DifferentiableSVD.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>T HE Fine-Grained Visual Categorization (FGVC) aims to classify the subordinate categories from a given supercategory (e.g., birds <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> or dogs <ref type="bibr" target="#b2">[3]</ref>). Compared with ordinary classification tasks, the FGVC is very challenging due to the subtle inter-class variations but significant intraclass differences. It has a multitude of real-world applications, such as image captioning <ref type="bibr" target="#b3">[4]</ref>, food recommendation <ref type="bibr" target="#b4">[5]</ref>, and image retrieval <ref type="bibr" target="#b5">[6]</ref>. Among the approaches for the FGVC task, the Global Covariance Pooling (GCP) methods, which exploit the second-order feature statistics, have achieved impressive performances on common FGVC benchmarks and have attracted research interests from the computer vision community <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. The GCP method is a spectral meta-layer that computes the sample covariance from convolutional features and conducts the matrix normalization to obtain more powerful representations. In general, a standard GCP meta-layer first uses Singular Value Decomposition (SVD) to factorize the sample covariance into the eigenvalue and eigenvector matrices. Afterwards, the matrix logarithm <ref type="bibr" target="#b12">[13]</ref> or matrix square root <ref type="bibr" target="#b13">[14]</ref> is performed on the eigenvalues for normalization. Finally, the normalized covariance is used as the global representation and fed into the FC layer for exploitation of second-order statistics.</p><p>In our previous conference paper <ref type="bibr" target="#b11">[12]</ref>, we conduct an investigation into the gradient smoothness of the SVD in the GCP layer. The SVD gradient involves the term K ij = 1 ?i??j where ? i and ? j are eigenvalues. Since the covariance size of GCP is very large (i.e., 256?256), it is very likely to have ? Yue Song, Nicu Sebe, and <ref type="bibr">Wei</ref>   many similar and small eigenvalues, i.e., ? i ?? j . This will cause the gradient term moves towards infinity (i.e., K ij ??) and trigger the numerical instability. To avoid this issue, a common practice is to truncate the small eigenvalues <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>, which could attain smoother gradients. We observe that when the small eigenvalues (i.e., last 50 out of 256) of the global covariance are truncated, the performance of GCP method on ImageNet <ref type="bibr" target="#b14">[15]</ref> could get improvements and the training will be more stable. However, as can be seen from <ref type="figure" target="#fig_0">Fig. 1</ref>, on fine-grained recognition datasets truncating the small eigenvalues would make the model fail to converge. This intriguing phenomenon contradicts the common belief on the insignificant eigenvalues: as the eigenvalues decomposed by SVD are exponentially decayed, the majority of the matrix energy has been preserved well by the first few large eigenvalues. Truncating the small ones should not harm the compact representation of the data. For a given matrix P and the truncated one P k that keeps top-k eigenvalues, according arXiv:2205.13282v1 [cs.CV] 26 May 2022 to Eckart-Young-Mirsky theorem <ref type="bibr" target="#b15">[16]</ref>, we have:</p><formula xml:id="formula_0">||P ? P k || F = ? 2 k+1 +, . . . , +? 2 d<label>(1)</label></formula><p>where ? i is the i-th largest eigenvalue, and d denotes the dimensionality. This is also known as the best low-rank approximation property of SVD. The theorem implies that truncating the insignificant eigenvalues still provides a very close approximation of the data (i.e., ||P ? P k || F ?0). In many practical applications such as image processing <ref type="bibr" target="#b16">[17]</ref> and data mining <ref type="bibr" target="#b17">[18]</ref>, the noise of the data is usually hidden in the small eigenvalues. Therefore, truncating the small eigenvalues of large matrices has become a common practice. An intuitive explanation is that the large eigenvalues capture statistics of principal directions along which the feature variances are large. Small eigenvalues, on the other hand, correspond to the features with smaller variance. However, for fine-grained recognition datasets, the interclass feature differences (e.g., color of the bird head) are often very subtle. These features containing the classification clues are more likely to be encoded by the small eigenvalues. Unfortunately, due to the highly non-linear structure of CNNs, this assumption cannot be directly validated.</p><p>We propose two visual explainability methods to diagnose the behavior of eigenvalues and associated eigenvectors. One methodology is to back-propagate the gradients of eigenvalues to the input image, which will highlight the distinct regions crucial to specific eigenvalues. The other technique is to perturb the image such that the final representation only embeds the large or small eigenvalues. The obtained images are in a deep-dreamed style <ref type="bibr" target="#b18">[19]</ref> and characterize the learned feature patterns. Through both quantitative evaluation and visual observation, the two aforementioned methods demonstrate that the small eigenvalues can effectively encode the discriminative and class-specific features. On the contrary, the large eigenvalues usually correspond to the background regions and fail in activating discriminative class-specific features compared with the small ones. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, for the small eigenvalues, the backward-based input responses consistently have salient points falling on the object, and the class-relevant features emerge repeatedly in the perturbationbased visualizations.</p><p>Our explainability methods attribute the decision cues of fine-grained classification to the small eigenvalues. Existing GCP methods usually use matrix square root normalization to reduce the magnitude of large eigenvalues <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b19">[20]</ref>. However, the importance of small eigenvalues is not fully enhanced and remains less exploited. These observations naturally raise the following question: Can we increase the significance of small eigenvalues to make existing GCP models focus more on the semantically meaningful features and therefore to help improving their performance on fine-grained visual recognition?</p><p>To solve this problem, we propose Scaling Eigen Branch (SEB), a general plug-in component for existing GCP models. It computes the exponential inverse of the covariance matrix that amplifies the relative significance of small eigenvalues. Then the covariance exponential inverse is used to generate a dynamic scaling factor and compensate for eigenvalues of the matrix square root. The backward gradient of the scaling factor helps the model to generate better-conditioned covariance matrices. The importance of small eigenvalues is thus magnified. Without introducing any additional parameters, the SEB improves the performances of GCP methods by 1.6% on three popular fine-grained benchmarks, i.e., Caltech University Birds (Birds) <ref type="bibr" target="#b0">[1]</ref>, Stanford Cars (Cars) <ref type="bibr" target="#b20">[21]</ref>, and FGVC Aircrafts (Aircrafts) <ref type="bibr" target="#b21">[22]</ref>. Moreover, the GCP method equipped with our proposed SEB also has very competitive performances against recent transformer-based FGVC approaches on some larger benchmarks including Stanford Dogs (Dogs) <ref type="bibr" target="#b2">[3]</ref> and iNaturalist (iNats) <ref type="bibr" target="#b22">[23]</ref>.</p><p>We summarize our contributions as follows: ? We propose two visual explainability methods to diagnose the behavior of GCP eigenvalues, both of which demonstrate that small eigenvalues encode more class-specific features and make larger contributions to the decisionmaking process of GCP networks. ? We propose Scaling Eigen Branch (SEB), an add-on network branch to amplify the importance of small eigenvalues. Without bringing any extra parameters, the proposed SEB achieves the state-of-the-art performance of GCP methods on three fine-grained benchmarks. On large fine-grained datasets, our method also has comparable performance against other FGVC approaches. This paper and our previous conference paper <ref type="bibr" target="#b11">[12]</ref> are connected but different. In the experiments of <ref type="bibr" target="#b11">[12]</ref>, we identify the peculiar behavior of GCP models on fine-grained recognition datasets, i.e., the model cannot converge without the last few eigenvalues. In this paper, we perform additional substantial work to explain the behavior and propose a plugin network branch to improve the performances of GCP methods on the FGVC task.</p><p>The rest of the paper is organized as follows: Sec. 2 describes the related work in fine-grained classification, global covariance pooling, and visual explainability methods. Sec. 3 presents our proposed methods to attribute the eigenvalues and Sec. 4 introduces our SEB module that amplifies the small eigenvalues. Sec. 5 provides the experimental results and indepth analysis. Finally, Sec. 6 summarizes the conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Fine-grained Visual Categorization</head><p>The task of FGVC aims at distinguishing the subordinate categories of a given object category, e.g., birds <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, cars <ref type="bibr" target="#b20">[21]</ref>, and dogs <ref type="bibr" target="#b2">[3]</ref>. Different from common classification scenarios, the FGVC is more challenging because the subtle inter-class variation needs to be captured. Existing works can be roughly divided into two groups: localization-based methods <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref> and representationbased approaches <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>. The former group exploits the part annotations to localize the semantically-relevant regions and assist the classification, whereas the latter category targets learning more powerful representations with either attentive information or high-order statistics to model the subtle inter-class details. Recently, several vision transformerbased works have been proposed to tackle the challenge of FGVC <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>. In <ref type="bibr" target="#b34">[35]</ref>, the authors design a feature fusion strategy to increase the representation power of the ordinary vision transformer <ref type="bibr" target="#b37">[38]</ref> for the FGVC task. Thus, this work belongs to the representation-based category. The works of <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref> both design dedicated mechanisms to select the discriminative visual tokens or images patches to assist the FGVC, which can be considered as localizationbased methods. The GCP methods that explore the secondorder statistics are a particular kind of approach belonging to the representation-based category, and we will give a more detailed illustration in the following paragraph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Global Covariance Pooling</head><p>In deep neural networks, Global Covariance Pooling (GCP) aims to explore the second-order statistics of convolutional features. DeepO 2 P [13] is the first end-to-end global covariance pooling network. It formulates the theory of matrix back-propagation and demonstrates its effectiveness in visual recognition and segmentation tasks. Another pioneering work is B-CNN <ref type="bibr" target="#b29">[30]</ref> which proposes to aggregate the outer product of global features and perform element-wise power normalization. However, there exist two caveats in the two methods. First, the dimensionality of the covariance feature is too high, which significantly increases the parameters of the fully-connected layer and introduces the risk of overfitting. Secondly, the matrix logarithm normalization over-stretches the small eigenvalues and may not be effective enough. Based on the two pioneering works, the follow-up researches mainly proceed in three directions:</p><p>? i) increase the representation power of global covariance by exploiting the distribution manifold or considering feature interactions in the convolutional layers <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b38">[39]</ref>; ? ii) reduce the dimensionality of the covariance feature <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b39">[40]</ref>; ? iii) seek for more efficient or effective matrix normalization schemes <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b19">[20]</ref>. The second direction is closely related to the robustness of eigendecomposition. As pointed in <ref type="bibr" target="#b40">[41]</ref>, large matrices are more likely to have gradient explosion problems, but this has been solved by <ref type="bibr" target="#b11">[12]</ref>. It is also revealed that preserving the full dimension of covariance usually brings better performances. The second direction is therefore out of the scope of this paper. In this work, we mainly focus on the first and the last directions. To be more specific, we propose a plugin component to improve the effectiveness of the global covariance feature. Also, our proposed component, together with the matrix square root normalization, can be viewed as a special matrix normalization scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Visual Explainability Methods</head><p>Although the CNN has achieved remarkable success in many computer vision tasks, it is often considered a black-box model and suffers from weak interpretability. There have been many attempts to improve CNN's explainability by visualizing the learned feature patterns or by highlighting the activation neurons. Existing visualization approaches can be roughly categorized into two families: backpropagationbased methods <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref> and perturbationbased techniques <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b51">[52]</ref>. The former category designs dedicated back-propagation rules to selectively highlight the input activations, whereas the latter perturbs or occludes the input image to maximally activate or confuse the classification predictions. Our work is closely related to both categories. More specifically, we use both backpropagation-based and perturbation-based techniques to provide the hint of the impact of eigenvalues. To the best of our knowledge, no similar work has been done in interpreting the impact of eigenvalues of GCP networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ATTRIBUTING THE EIGENVALUES</head><p>In this section, we first revisit the procedure of global covariance pooling. Then, we introduce the two proposed visualization techniques in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Global Covariance Pooling Recap</head><p>Consider the reshaped convolutional feature X?R d?N , where d denotes the feature dimensionality (i.e., the number of channels) and N represents the number of features (i.e., the product of spatial dimensions of features), a GCP meta-layer first computes the sample covariance matrix as:</p><formula xml:id="formula_1">P = X?X T ,? = 1 N (I ? 1 N 11 T )<label>(2)</label></formula><p>where? represents the centering matrix, I denotes the identity matrix, and 1 is a column vector whose values are all ones, respectively. The sample covariance matrices are always symmetric positive semi-definite. Such matrices do not have any negative eigenvalues. Then the eigendecomposition is performed via SVD or eigenvalue decomposition (EIG):</p><formula xml:id="formula_2">P = U?U T , ? = {? 1 , . . . , ? d } diag<label>(3)</label></formula><p>where U is the orthogonal eigenvector matrix, and ? is the diagonal matrix in which the eigenvalues are sorted in a non-increasing order i.e., ? i ?? i+1 . Afterwards, the matrix square root is conducted for normalization:</p><formula xml:id="formula_3">Q P 1 2 = UF(?)U T , F(?) = ? 1 2 = {? 1 2 1 , . . . , ? 1 2 d } diag (4)</formula><p>where the normalized covariance matrix Q will be fed to the fully-connected layer. Besides the matrix square root normalization, there exist some other normalization schemes such as matrix logarithm <ref type="bibr" target="#b12">[13]</ref> and rank-1 update <ref type="bibr" target="#b19">[20]</ref>. As the matrix square root is proved to amount to robust covariance estimation under the regularized MLE framework <ref type="bibr" target="#b6">[7]</ref>, this normalization is often preferred over other techniques. Existing state-of-the-art GCP methods are MPN-COV <ref type="bibr" target="#b6">[7]</ref> and iSQRT-COV <ref type="bibr" target="#b7">[8]</ref>. The MPN-COV <ref type="bibr" target="#b6">[7]</ref> applies the above formulations for the covariance matrix computation. However, the standard SVD used in the MPN-COV is known to suffer from the gradient explosion problem as it involves the computation of 1 ?i??j where i =j. When ? i and ? j are very close or equal, the gradient will go to infinity. To avoid using SVD, the iSQRT-COV <ref type="bibr" target="#b7">[8]</ref> proposes using Newton-Schulz iteration to directly derive the approximate matrix square root. Recently, the gradient explosion problem of SVD has been solved by <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b40">[41]</ref> and a faster scheme of computing matrix square root is proposed in <ref type="bibr" target="#b52">[53]</ref>. Throughout the experiments in this paper, we mainly investigate MPN-COV <ref type="bibr" target="#b6">[7]</ref> which is a standard GCP method that conducts explicit eigendecomposition, and we use the techniques of <ref type="bibr" target="#b11">[12]</ref> to compute the gradients.</p><p>We take ResNet-50 models of MPN-COV [7] trained on the fine-grained benchmarks to diagnose the peculiar behavior of the eigenvalues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Backpropagation-based Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Selective Back-propagation of Eigenvalues</head><p>The core idea of our backward method is to manipulate the eigenvalue matrix defined in eq. (3) and project the gradient back to the image. To visualize input activations to different eigenvalues, we could either abandon the small ones or the large ones from the eigenvalue matrix ?:</p><formula xml:id="formula_4">? L = diag{? 1 , . . . , ? t , 0, . . . , 0}, ? S = diag{0, . . . , 0, ? t+1 , . . . , ? d }.<label>(5)</label></formula><p>where t denotes the number of kept eigenvalues (i.e., top 206 out of 256), ? L represents the matrix that only preserves the large eigenvalues, and ? S is the matrix consisting of the small eigenvalues. The covariance matrix is usually of the size 256?256 and has 256 non-negative eigenvalues in total. According to our observation on fine-grained datasets, for most covariance matrices, the last 50 eigenvalues take less than 0.1% energy of the matrix (i.e.,</p><formula xml:id="formula_5">d i=t+1 ?i d i=1 ?i &lt;0.001)</formula><p>. Therefore, we categorize the last 50 eigenvalues as the small eigenvalue ? S and the rest as the large eigenvalue ? L .</p><p>Substituting the eigenvalue matrix ? with ? L or ? S and back-propagating the gradients to the input could localize the salient regions that are crucial to the specific eigenvalues. To project the gradient back to the input, we need to consider the back-propagation rules of the GCP meta-layer and the standard CNN layers. For the sake of conciseness, we omit the back-propagation algorithm of the GCP meta-layer, and the readers are kindly referred to <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b53">[54]</ref> for a detailed review. As for the gradient propagation of CNN, the main difficulty lies in the ReLU non-linearity. The vanilla backward gradient of ReLU <ref type="bibr" target="#b41">[42]</ref> is calculated by:</p><formula xml:id="formula_6">ReLU * (p) = 1, p &gt; 0 0, p ? 0 .<label>(6)</label></formula><p>where p is the pixel-wise gradient back-propagated to ReLU. For the positive gradients, ReLU passes a constant to the next node in the computational graph, which loses the magnitude information and may not generate appealing visualizations.</p><p>To resolve this issue, DeConv <ref type="bibr" target="#b42">[43]</ref> proposes an imputed back-propagation scheme:</p><formula xml:id="formula_7">ReLU * DeConv (p) = p, p &gt; 0 0, p ? 0 .<label>(7)</label></formula><p>where the gradient magnitude is kept and more dynamic gradients are allowed. Compared with the vanilla gradient, DeConv gradient usually yields larger activated regions and more salient points, which could improve the visual appeal. We use both back-propagation rules to generate the input activations and they yield similar results.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Quantitative Evaluation</head><p>Correlation Coefficient. To quantitatively evaluate the importance of eigenvalues, we compute the average correlation coefficients between the input responses to the specific eigenvalues and those to all eigenvalues. The correlation coefficient is defined as:</p><formula xml:id="formula_8">Corr(A, B)= m n (A m,n ??)(B m,n ?B) m n (A m,n ??) 2 m n (B m,n ?B) 2<label>(8)</label></formula><p>where A and B are images to be compared,? andB are the mean intensity of the images, and the correlation coefficient Corr(?, ?), which is normalized into the range of [0, 1], is used to assess their similarity. By measuring the similarity between the visualizations, we could understand what eigenvalues contribute more to the decision-making process. As the large eigenvalues using DeConv back-propagation rule have responses nearly everywhere on the image, the activated regions highly overlap with those using all the eigenvalues. Their correlation will be inevitably large. Mean Absolute Error. Alternatively, we could compute their Mean Absolute Error (MAE) to measure the statistical distance:</p><formula xml:id="formula_9">MAE(A, B) = 1 M ? N m n |A m,n ? B m,n |<label>(9)</label></formula><p>where M and N denote the image width and height, respectively. The joint use of these two metrics can provide a comprehensive assessment on the similarities between the visualizations. <ref type="table" target="#tab_1">Table 1</ref> compares the similarity between the input activations of specific eigenvalues and those of all the eigenvalues. For both metrics, the activated regions of small eigenvalues have a substantially larger similarity with the activated regions of all the eigenvalues. This demonstrates that the small eigenvalues preserve more semantically meaningful information and have greater contributions to the decisions of the GCP networks. Validation Accuracy. Besides the analysis in the lens of visualization similarity, we also evaluate the impact of eigenvalues on the classification accuracy. <ref type="table" target="#tab_2">Table 2</ref> presents the validation accuracy using different subsets of the eigenvalues in the inference stage. Since the last eigenvalues are very small in magnitude, merely using the small ones might poorly reconstruct the covariance representation and cannot output reasonable class predictions. Therefore, we also add the first eigenvalue ? 1 to keep the dominant vector space when testing the performance of small eigenvalues. As can be seen, even using the last 30 eigenvalues has a higher validation accuracy than using the large ones. When the number of used eigenvalues is increased from 30 to 50, we can observe a steady performance improvement.</p><p>This demonstrates that the small eigenvalues have more predictive power and a larger contribution to the decisionmaking process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Perturbation-based Methodology</head><p>Instead of seeking for input responses to eigenvalues, another visualization method is to freeze the classifier weights and perturb the input images such that only specific eigenvalues and the associated eigenvectors are maximally activated. After keeping updating the image values for a certain number of iterations, the perturbed image will highlight the learned feature patterns of specific eigenvalues. For an input image, we first decompose the covariance matrix into two submatrices that embed only the large or small eigenvalues:</p><formula xml:id="formula_10">P L = U? L U T , P S = U? S U T<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Visualization of Large Eigenvalues</head><p>To visualize the feature patterns that correspond to the large eigenvalues, we could iteratively use the following loss function to perturb the image:</p><formula xml:id="formula_11">l 1 = ||M ? P L || 2 F<label>(11)</label></formula><p>where M denotes the covariance matrix generated by the perturbed image, l 1 is the loss to optimize the image, and || ? || F represents the Frobenius norm. The loss can push the perturbed image to generate the covariance composed only by large eigenvalues. Notice that the loss l 1 can be regarded as the Mean Square Error (MSE) loss between P L and M.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Visualization of Small Eigenvalues</head><p>Deriving the perturbation loss for the small eigenvalues is more complex than the large ones. We cannot adopt the ||M ? P S || 2 F loss as in eq. (11). Since the eigenvalues ? S are sparse and exponentially smaller than the large ones, the reconstructed matrix P S contains little energy of the original matrix P (often &lt;0.1%). It is infeasible for a covariance matrix M to have the identical eigenvalues as P S . Instead of pushing them to have the same eigenvalues, we enforce the eigenvalues of M and P S to be highly correlated. To achieve this goal, we introduce the following loss function:</p><formula xml:id="formula_12">l 2 = ?||M ? P L || 2 F + ||M ? P S || 2 F<label>(12)</label></formula><p>where the first term pushes M far from P L , and the second term makes sure that M stays close with P S . The composition of the two losses can guarantee that M maximally activates the eigenvectors of P S and has a highly correlated representation. Formally, we have the proposition as follows: Proof. Relying on Frobenius inner product, the loss l 2 is decomposed by:</p><formula xml:id="formula_13">l 2 = ? ||M ? P L || 2 F + ||M ? P S || 2 F = ? M ? P L , M ? P L + M ? P S , M ? P S =2 M, P L ?||P L || 2 F ?2 M, P S +||P S || 2 F<label>(13)</label></formula><p>Since both ||P S || 2 F and ||P L || 2 F are independent of M, we can use a constant C to represent the sum of these two terms:</p><formula xml:id="formula_14">l 2 = 2 M, P L ? 2 M, P S + C = ?2 M, P S ? P L + C<label>(14)</label></formula><p>For the inner product of a given matrix pair A and B, Von Neumann's trace inequality <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b55">[56]</ref> tells:</p><formula xml:id="formula_15">| A, B | ? ? 1 (A)? 1 (B) + ? ? ? + ? n (A)? n (B)<label>(15)</label></formula><p>where ? i (?) denotes the i-th eigenvalue. Injecting eq. (15) into eq. <ref type="formula" target="#formula_0">(14)</ref>, the loss l 2 can be re-expressed as:</p><formula xml:id="formula_16">l 2 ? ?2 d i=1 ? i (M)? i (P S ? P L ) + C<label>(16)</label></formula><p>Recall that P L is composed by the large eigenvalues ? L ={? 1 , . . . , ? t , 0, . . . , 0} diag and P S only embeds the small eigenvalues ? S ={0, . . . , 0, ? t+1 , . . . , ? d } diag . Eq. 16 can be further formulated as:</p><formula xml:id="formula_17">l 2 ? 2 t i=1 ? i (M)? i ? 2 d i=t+1 ? i (M)? i + C<label>(17)</label></formula><p>Since M is positive semi-definitive, there will not exist any negative eigenvalues ? i (M). Therefore, the minimum of the first term is zero. It happens when the eigenvalues of M have a zero correlation with ? L , i.e., the large eigenvalues of M are zero. The second term actually measures the correlation between the last (d?t) eigenvalues of M and P. When the r.h.s. of eq. (17) attains the minimum, the correlation will reach the maximum and M will maximally activate the eigenvectors associated with the small eigenvalues. The equality is taken when M also has the eigenvector matrix U.</p><p>This proposition shows that after the image is perturbed for certain iterations, i.e., the loss attains the minimum, M will only activate the learned feature patterns of the eigenvectors associated with small eigenvalues. But the eigenvectors that correspond to the large eigenvalues will not be encoded by M. <ref type="figure" target="#fig_1">Fig. 2</ref> right visualizes the learned feature patterns that correspond to the specific eigenvalues. Although mainly mid-level and low-level features are activated in the visualizations, the semantically meaningful patterns can be observed. For the small eigenvalues, the visualizations exhibit distinct class-relevant features. Take the 2 nd row as an example, the bird head, which characterizes the bird species, emerges repeatedly in the visualizations. On the contrary, the large eigenvalues do not activate obviously classrelevant and human-interpretable features. Unfortunately, this visualization technique can only be assessed through visual observation but cannot be evaluated by any reasonable quantitative metrics. We provide more visualization results in Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SCALING EIGEN BRANCH</head><p>The visualization results and quantitative analysis demonstrate that the small eigenvalues and associated eigenvectors are actually crucial to the network decisions as they capture rich semantic information and class-relevant feature patterns. This observation inspires us to propose SEB, a plug-in component dedicated to magnify the importance of small eigenvalues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Amplifying Small Eigenvalues by Scaling</head><p>To magnify the importance of small eigenvalues, one straightforward approach is to increase their numerical values. However, the eigenvalues are sorted according to the varying extent of the feature along the eigenvector directions. Directly increasing the value of small eigenvalues could reverse the significance order and disturb the statistical information of covariance, which might make the model fail to converge. For the covariance matrix, it is important to maintain the significance order of the eigenvalues. Another intuitively possible method is to increase the relative importance of small eigenvalues (i.e., increase ? d ?1 ) but maintain the significance order (i.e. ?i+1 ?i ?1 is always satisfied). This could be easily done by computing the matrix p-th root P 1 p instead of the square root P 1 2 . A small 1 p would punish the magnitude of large eigenvalues and magnify the significance of small ones. However, as pointed out in <ref type="bibr" target="#b6">[7]</ref>, only the matrix square root can amount to robust covariance estimation under the regularized MLE framework and approximately exploits Riemannian geometry under the Power-Euclidean metric <ref type="bibr" target="#b56">[57]</ref>. Besides the theoretical analysis, the matrix square root also achieves the best experimental performances among different power normalization schemes (e.g., P 0.1 and P 0.3 ) <ref type="bibr" target="#b6">[7]</ref>. All of these suggest that computing the covariance square root is indispensable for robust covariance pooling.</p><p>So far, the only practical approach seems to be properly transforming the covariance matrix such that the eigenvalues are amplified but the form of matrix square root still manifests. Since our covariance matrix is symmetric positive semi-definite (SPSD), it is appropriate to consider the geometry of SPSD manifold. In the space of SPSD manifold, the distance between covariance matrices is not measured by the traditional Euclidean metrics (i.e., d(X, Y )=||X?Y || 2 F ). Instead, a non-Euclidean metric should be adopted. One commonly used metric is the Log-Euclidean metric <ref type="bibr" target="#b57">[58]</ref> defined as:</p><formula xml:id="formula_18">d 2 L (X, Y ) = ||log(X) ? log(Y )|| 2 F<label>(18)</label></formula><p>We can easily find that this metric is scale-invariant, i.e., scaling two covariance matrices keeps their distance unchanged. Therefore, it is appropriate to consider scaling the covariance square root by a factor (&gt;1) such that the eigenvalues are amplified and the distance between two scaled covariance matrices does not change in the SPSD manifold. Notice that the scale-invariance property generally applies for the non-Euclidean metrics used in the SPSD manifold (e.g., affine-invariant Riemannian metric <ref type="bibr" target="#b58">[59]</ref> and Stein divergence <ref type="bibr" target="#b59">[60]</ref>). In the following paragraphs, we will illustrate how the covariance matrices get appropriately scaled in our proposed SEB (see also <ref type="figure">Fig. 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Dynamic Scaling Factor</head><p>To scale the covariance square root Q, one may consider multiplying a constant a: a ? Q = U{a? 1 2 1 , . . . , a?</p><formula xml:id="formula_19">1 2 d } diag U T<label>(19)</label></formula><p>where {?} diag means transforming a vector to a diagonal matrix. It is non-trivial to choose a suitable constant a, as each covariance matrix has a different eigenvalue distribution. The scaling factor should accordingly be different and preferably dependent on the eigenvalues. An intuitive choice is using ||Q|| F or ||P|| F as the factor. However, both Q and P have very imbalanced eigenvalue distributions and are likely to be ill-conditioned (i.e., ?1 ? d is too large). In that case, the small eigenvalues will contribute little and the first eigenvalue ? 1 will dominate the scaling factor (i.e., ||P|| F ?? 1 and ||Q|| F ?? 1 2 1 ). To avoid this issue, we propose to first balance the eigenvalue distribution by calculating the exponential inverse of the covariance:</p><formula xml:id="formula_20">S=e ?P =Ue ?? U T =U{e ??1 , . . . , e ?? d } diag U T<label>(20)</label></formula><p>Unfortunately, differentiating this step is not supported by the AutoGrad package of the deep learning frameworks. The gradient has to be manually derived. Given the partial derivatives of the loss l w.r.t S, we have dS=dUe ?? U T +Ude ?? U T +Ue ?? dU T and de ?? =?{e ??1 ,. . .,e ?? d } diag d?. After some arrangements using the chain rule and matrix back-propagation rule <ref type="bibr" target="#b53">[54]</ref>, the partial derivatives of the loss l w.r.t the eigenvalue and eigenvector are calculated as:</p><formula xml:id="formula_21">?l ?U = ?l ?S +( ?l ?S ) T U{e ??1 , . . . , e ?? d } diag , ?l ?? =? {e ??1 , . . . , e ?? d } diag U T ?l ?S U diag<label>(21)</label></formula><p>where (?) diag denotes the operation of setting off-diagonal elements to zero. The covariance exponential inverse S normalizes the eigenvalue distribution on (0, 1] but reverses the order of importance (see also <ref type="figure">Fig. 4</ref>). We then combine S and Q to compute their cross-covariance:</p><formula xml:id="formula_22">QS T = U{? 1 2 1 e ??1 , . . . , ? 1 2 d e ?? d } diag U T<label>(22)</label></formula><p>Eq. <ref type="formula" target="#formula_1">(22)</ref> actually measures the similarity between Q and S. Compared with the ordinary covariance square root Q, it has a more balanced eigenvalue distribution. Thus we use its Frobenius norm ||QS|| F as the scaling factor to compensate for the covariance square root.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Covariance Square Root Compensation</head><p>After generating the scaling factor, we multiply it to the covariance square root plus the ordinary one. This process can be denoted by:</p><formula xml:id="formula_23">A = ||QS T || F ? Q + Q = (||QS T || F + 1) ? Q<label>(23)</label></formula><p>where A is the final representation that will be fed to the fullyconnected layer. The value of the Frobenius norm ||QS T || F takes the following form:</p><formula xml:id="formula_24">||QS T || F = Tr((QS T )(QS T ) H ) = d i=1 ? 1 2 i e ??i 2<label>(24)</label></formula><p>It is easy to find that the numerical value is in the range of (0, ||Q|| F ). We add the ordinary matrix square root to ensure that A can always amplify the eigenvalues of Q (i.e., ||QS T || F +1&gt;1). Note that the norm ||QS T || F is differentiable and the gradient could help to increase the significance of small eigenvalues. Its derivatives w.r.t. Q and S are given by:</p><formula xml:id="formula_25">?||QS T || F ?Q = 1 ||QS T || F QS T S = U{ ? 1 2 1 e ?2?1 ||QS T || F , . . . , ? 1 2 d e ?2? d ||QS T || F } diag U T , ?||QS T || F ?S = 1 ||QS T || F SQ T Q = U{ ? 1 e ??1 ||QS T || F , . . . , ? d e ?? d ||QS T || F } diag U T<label>(25)</label></formula><p>For both matrices, the gradients are healthy as the use of S balances the eigenvalue distribution and reduces the 3: Comparison with the state-of-the-art GCP approaches. For a fair comparison, we report our training results of MPN-COV <ref type="bibr" target="#b6">[7]</ref> and iSQRT-COV <ref type="bibr" target="#b7">[8]</ref> using the same deep learning platform (PYTORCH). Notice that the values reported in these two papers are not based on the commonly used backbones with the first-order pooling layers (see Supplementary Material for details). The values of other methods are taken directly from their papers as they are less related to our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Backbone</head><p>Method Birds <ref type="bibr" target="#b0">[1]</ref> Aircrafts <ref type="bibr" target="#b21">[22]</ref> Cars <ref type="bibr" target="#b20">[21]</ref> VGG-16 <ref type="bibr">[</ref> risk of ill-conditioned derivative matrices. This could help the network to generate the better-conditioned covariance matrix P and the covariance square root Q, which implicitly amplifies the importance of the small eigenvalues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Implementation Details</head><p>The code is implemented in PYTORCH. We run all the experiment on the workstation equipped with a GeForce GTX 1080 Ti GPU and a 6-core Intel Core i7-7800X@3.50GHz CPU. For MPN-COV <ref type="bibr" target="#b6">[7]</ref> and our proposed SEB, the forward eigendecomposition is conducted on the CPU for a faster speed. The other operations are performed on the GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Dataset Specifications</head><p>The Birds dataset includes 11, 788 images belonging to 200 bird species. The Aircrafts dataset contains 10, 000 images of 100 classes of airplanes, and the Cars dataset consists of 16, 185 images from 196 classes. Besides the three commonly used datasets, we also evaluate our method on two large datasets, namely Dogs and iNats. The Dogs dataset is comprised of 20, 580 images of 120 dog categories, and the INats dataset have 675, 170 images from 5, 089 natural finegrained categories that belong to 13 super-categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Perturbation-based Explainability Settings</head><p>The image is resized to 448?448 before being fed into the network. We keep the weights of the model frozen and only update the image pixel values. The learning rate to perturb the image is set to 0.1 and the perturbation lasts for 1, 000 iterations for each image. For the training recipe of different models on fine-grained benchmarks, please refer to Supplementary Material for details. <ref type="table">Table 3</ref> compares the validation accuracy on three benchmarks with different backbones against the standard GCP method (i.e., MPN-COV <ref type="bibr" target="#b6">[7]</ref>), as well as iSQRT-COV <ref type="bibr" target="#b7">[8]</ref> and other covariance pooling methods. We can observe that the standard GCP method equipped with our proposed SEB improves the performance of its original version <ref type="bibr" target="#b6">[7]</ref> by 1.6% on average across different datasets regardless of the backbones. To be more specific, on Birds dataset, the performance is improved by 1.5% across backbones. On Aircrafts dataset, our SEB improves MPN-COV [7] by 1.5% on average. On Cars dataset, the average performance gain brought by SEB is 1.7%. Based on ResNet-152 <ref type="bibr" target="#b62">[63]</ref> and EfficientNet-b5 <ref type="bibr" target="#b63">[64]</ref>, our method achieves the state-of-the-art performance of GCP methods on all datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results Compared with GCP Methods</head><p>The consistent performance gain demonstrates that our proposed SEB could be a powerful add-on for the GCP methods on the fine-grained recognition task. With the VGG backbone, our method is slightly inferior to RUN <ref type="bibr" target="#b19">[20]</ref> and MoNet <ref type="bibr" target="#b32">[33]</ref> on Aircrafts and Birds, respectively. That is mainly because the covariance of VGG architecture is of the size 512?512, which is twice larger than ResNet <ref type="bibr" target="#b62">[63]</ref> and more prone to be ill-conditioned. However, there are two sides to reducing the number of channels. Projecting the channel dimension into 256 could reduce the covariance size but might weaken the representation power and might not necessarily lead to performance improvements. Besides, these methods do not report the experimental results on other backbones and their applicability on other deep architectures cannot be confirmed. It is also worth mentioning that our SEB does not introduce any additional parameters to MPN-COV <ref type="bibr" target="#b6">[7]</ref> and only slightly increases the speed and memory consumption (See Sec. 5.6).</p><p>To sum up, the small eigenvalues play a vital role on the fine-grained classification task as they capture the semantic class-specific features, and amplifying their importance does bring consistent improvements. However, the small eigenvalues seem less important on the large-scale classification dataset (i.e., ImageNet <ref type="bibr" target="#b14">[15]</ref>) in which the inter-class feature differences are no longer subtle and are more likely to be encoded by the large eigenvalues. The small eigenvalues might only capture the data noise and the network predictions would be largely dependent on large eigenvalues. For the detailed analysis, please refer to Supplementary Material which illustrates this point by a series of experiments including the explainability visualizations. Besides the evaluation within the scope of GCP methods, we also compare our method with other state-of-theart FGVC approaches on some larger datasets. <ref type="table" target="#tab_5">Table 4</ref> presents the validation accuracy of our approach and recent transformer-based FGVC methods on the three larger datasets, i.e., Cars <ref type="bibr" target="#b20">[21]</ref>, Dogs <ref type="bibr" target="#b2">[3]</ref>, and INats <ref type="bibr" target="#b22">[23]</ref>. Our method outperforms other baselines by 0.7% on Dogs <ref type="bibr" target="#b2">[3]</ref> and by 0.6% on INats <ref type="bibr" target="#b22">[23]</ref>, while the performance slight falls behind TransFG <ref type="bibr" target="#b36">[37]</ref> by 0.4% on Cars <ref type="bibr" target="#b20">[21]</ref>. This observation indicates that our method can also have very competitive performances against other FGVC approaches on large benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results Compared with Other FGVC Approaches</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results on Other Deep Models</head><p>Under the same training protocol of ResNet, we conduct more experiments on other popular deep architectures, namely Inception <ref type="bibr" target="#b65">[66]</ref> and DenseNet <ref type="bibr" target="#b66">[67]</ref>. <ref type="table" target="#tab_6">Table 5</ref> displays the performances on the fine-grained benchmarks. Similar with the results on VGG and ResNet, our proposed SEB Inception V3 <ref type="bibr" target="#b65">[66]</ref> iSQRT-COV <ref type="bibr" target="#b7">[8]</ref> 83.5 90.0 90.5 MPN-COV <ref type="bibr" target="#b6">[7]</ref> 82.7 89.9 90.6 MPN-COV + Our SEB 84.8 (? 2.1) 90.9 (? 1.0) 92.5 (? 1.9) DenseNet-169 <ref type="bibr" target="#b66">[67]</ref> iSQRT-COV <ref type="bibr" target="#b7">[8]</ref> 86.4 91.1 92.6 MPN-COV <ref type="bibr" target="#b6">[7]</ref> 86.3 90.8 92.9 MPN-COV + Our SEB 87.6 (? 1.3) 92.3 (? 1.5) 94.0 (? 1.1) significantly improves MPN-COV [7] by 1.5% on average. This consistent performance gain demonstrates the general model-agnostic applicability of our SEB for different deep architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Ablation Studies</head><p>Using ResNet-50 as the backbone, we conduct two ablation studies on the impact of using only SEB path and the impact of different scaling factors.  Instead of combining the matrix square root and the compensated one ||QS T || F ?Q+Q, one may consider only passing the amplified covariance square root ||QS T || F ?Q to the fully-connected layer. <ref type="table" target="#tab_7">Table 6</ref> compares the performances of using different paths. Solely using the SEB path ||QS T || F ?Q brings about 1.2% increase on the performances over MPN-COV <ref type="bibr" target="#b6">[7]</ref>. The combination of the two paths can assure that the final representation always amplifies the covariance square root Q, thus outperforming using only SEB by 0.4% on average. To magnify the eigenvalues of Q, one may think about using other scaling factors instead of our used ||QS T || F . We take some possible factors to evaluate the impact, including the fixed constant, ||Q|| F , ||S|| F , and factors learned by an MLP from ? 1 2 and Q. As shown in <ref type="table" target="#tab_8">Table 7</ref>, none of the alternative factors bring obvious improvements and some even have side effects on the performances. We conjecture that this is related to the backward gradient of the scaling factor. Using a constant factor and ||S|| F cannot propagate valid gradients to Q. For the scaling factor ||Q|| F , its derivative w.r.t. Q is Q/||Q|| F , which is prone to be illconditioned. For the learned scaling factor, the value is   <ref type="bibr" target="#b6">[7]</ref> and our SEB on three fine-grained benchmarks. The proposed SEB effectively narrows the eigenvalue range and magnify the small ones. (Bottom) The condition number ?(P) of MPN-COV <ref type="bibr" target="#b6">[7]</ref> and our proposed SEB on the fine-grained benchmarks. Our covariance matrices are consistently better-conditioned than MPN-COV <ref type="bibr" target="#b6">[7]</ref> and the relative importance of small eigenvalues are amplified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">Impact of Scaling Factors.</head><p>unbounded and the gradient can not be constrained in good conditions. By contrast, our ||QS T || F consistently has well-conditioned gradient matrices and outperforms other schemes significantly. <ref type="table" target="#tab_9">Table 8</ref> compares the time and memory consumption of the GCP models for each mini-batch. Compared with the ordinary MPN-COV <ref type="bibr" target="#b6">[7]</ref>, our proposed SEB only brings marginal overhead on the computation complexity and memory cost. The extra memory usage is due to the calculation and storage of the scaling factor in the proposed SEB path.  As can be observed, our proposed SEB consistently brings the performance gain about 2% over MPN-COV <ref type="bibr" target="#b6">[7]</ref> and iSQRT-COV <ref type="bibr" target="#b7">[8]</ref> during the training process. Besides, the original GCP methods show some signs of overfitting, i.e., their validation accuracy seems to slowly decrease as the training goes in the later stage. In contrast, our SEB appears to continuously improve throughout the training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Speed and Memory Comparison</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Validation Accuracy Curves</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Eigenvalue Distribution Comparison</head><p>In Sec. 4.2, we show that the backward gradient of ||QS T || F are healthy and can help the network to generate betterconditioned covariance matrices. To validate the concrete impact, we compare the eigenvalue distributions of our proposed SEB method and the ordinary GCP method MPN-COV <ref type="bibr" target="#b6">[7]</ref>. The comparison is made by visualizing the histogram of the eigenvalues and by evaluating the matrix condition number. The matrix condition number ?(?) is defined as:</p><formula xml:id="formula_26">?(X) = ||X|| 2 ||X ?1 || 2 = ? max (X) ? min (X)<label>(26)</label></formula><p>where X is the matrix to be measured. The condition number computes the ratio between the maximum and minimum eigenvalues. The lower the ratio is, the higher the relative importance of small eigenvalues will be. The histogram displays the overall eigenvalue distribution for all covariance matrices, whereas the condition number measures the conditioning of each individual matrix. The joint use of these two evaluation methods can provide a comprehensive picture of the eigenvalue information. <ref type="figure" target="#fig_7">Fig. 6</ref> top shows the histogram of eigenvalues distribution for the global covariance P. As can be observed, our SEB effectively narrows the eigenvalue range. The large eigenvalues are reduced and the small ones are increased. Interestingly, on all datasets, a large portion of small eigenvalues group together to form a peak around 2 ?18 . We expect that these eigenvalues and associated eigenvectors are the determinant factors that capture the rich semantic information and boost the performances of the GCP methods. The condition number of all the covariance matrices ?(P) are plotted in the bottom of <ref type="figure" target="#fig_7">Fig. 6</ref>. For MPN-COV <ref type="bibr" target="#b6">[7]</ref>, the value varies from 10 8 to 10 15 , whereas the condition number of our SEB is on [10 7 , 10 8 ]. This demonstrates that our covariance matrices are consistently much better-conditioned than MPN-COV <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we propose two explainability methods to diagnose the eigenvalue behaviors of GCP layers. Both quantitative evaluation and visual observation demonstrate that the small eigenvalues capture more class-relevant and semantically meaningful feature patterns. Based on this finding, we further propose a plug-in network branch to magnify the importance of small eigenvalues and the associated eigenvectors. Without bringing extra parameters, the existing GCP method integrated with our proposed component achieves state-of-the-art performances of GCP methods on fine-grained benchmarks. Moreover, on larger datasets, our method also has competitive performances against other FGVC approaches.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A IMPLEMENTATION DETAILS AND EXTRA VISUALIZA-TION RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Training Recipe for Fine-grained Benchmarks</head><p>The ResNet and VGG pre-trained on ImageNet <ref type="bibr" target="#b14">[15]</ref> are finetuned on each fine-grained dataset. The images are first resized to the resolution of 512?512, then centered cropped to 448?448, and finally fed into the network. The 1000-d fully-connected layer of the original network is changed to fit the number of classes. The model is trained using SGD with momentum 0.9. The batch size is set as 8 for Aircrafts <ref type="bibr" target="#b21">[22]</ref> and set as 10 for Birds <ref type="bibr" target="#b0">[1]</ref> and Cars <ref type="bibr" target="#b20">[21]</ref>. We make the inference also on the 448?448 centered crop of the test image. Since the covariance matrix is symmetric, we only pass the upper triangular part to the fully-connected layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.1 ResNet Settings</head><p>For the ResNet architectures, we squeeze the channels of the final convolutional feature from 2048 to 256 for computation efficiency of covariance matrices. The resultant spatial dimension of the covariance is 256 ? 256. The initial learning rate is set as 3?10 ?3 for the convolutional layers. The learning rate of the fully-connected layer is set 5, 10, and 20 times larger than the convolutional layers for Aircrafts <ref type="bibr" target="#b21">[22]</ref>, Cars <ref type="bibr" target="#b20">[21]</ref>, and Birds <ref type="bibr" target="#b0">[1]</ref> respectively. The weight decay of the optimizer is set as 1?10 ?3 for Aircrafts <ref type="bibr" target="#b21">[22]</ref> and as 1?10 ?4 for Birds <ref type="bibr" target="#b0">[1]</ref> and Cars <ref type="bibr" target="#b20">[21]</ref>. For Aircrafts <ref type="bibr" target="#b21">[22]</ref> dataset, the training lasts for 50 epochs with dividing the learning rate by 10 at epoch 20. For Cars <ref type="bibr" target="#b20">[21]</ref> and Birds <ref type="bibr" target="#b0">[1]</ref> datasets, the training lasts for 100 epochs and the learning rate dividing happens at epoch 50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.2 VGG Settings</head><p>For the VGG architecture, the final representation has 512 channels, which is much smaller than ResNet and will lead to the covariance matrix of a acceptable size. Therefore, we do not perform any channel reduction and the resultant covariance matrix is of size 512 ? 512. For Cars <ref type="bibr" target="#b20">[21]</ref> dataset, the initial learning rate is set as 6?10 ?3 for the fullyconnected layer and 1.2?10 ?3 for the other layers. We set the initial learning rate to 3?10 ?3 for Aircrafts <ref type="bibr" target="#b0">[1]</ref> and Birds <ref type="bibr" target="#b0">[1]</ref>. Batch normalization is used to stabilize the training process. The training lasts 150 epochs for all the datasets with periodically learning rate decay by 10 at epoch 50 and epoch 100.</p><p>For the concern of comparison fairness, the same training protocol is applied to MPN-COV <ref type="bibr" target="#b6">[7]</ref> and iSQRT-COV <ref type="bibr" target="#b7">[8]</ref> methods. <ref type="figure">Fig. 7</ref> displays randomly selected backward-based visualizations on the three fine-grained benchmarks. For all the datasets, the small eigenvalues display much more similar input activations with those of all the eigenvalues. This implies that the classification decisions of the GCP networks are more dependent on the small eigenvalues and the associated eigenvectors. <ref type="figure" target="#fig_11">Fig. 8</ref> shows the randomly selected perturbation-based visualization. For Birds datatset, the visualization of small eigenvalues are interpretable, where the head, beak, and feather of the bird species emerge repeatedly in the images. However, the images on Cars and Aircrafts are less explainable. It might be difficult to tell which visualization characterizes more class-relevant feature patterns. We believe this is largely because the subtle differences between cars or airplanes are not easily interpretable by human beings. For example, classes of Cars datasets are typically at the level of Make, Model, and Year. One can not really tell the differences between the classes 'Audi S4 Sedan 2012' and 'Audi S4 Sedan 2007'. Thus the visualized feature patterns can be vague. The fine-grained datasets of natural species, on the other hand, might generate more human-friendly feature patterns. <ref type="figure">Fig. 9</ref> displays the perturbation-based visualizations of the ResNet-50 trained on Dogs <ref type="bibr" target="#b67">[68]</ref> and Flowers <ref type="bibr" target="#b68">[69]</ref> dataset. Similar with the images on Birds, the visualization is interpretable and the feature patterns of small eigenvalues are more class-relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Random Backward-based Visualization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Random Perturbation-based Visualization</head><p>All in all, for the fine-grained datasets we have tested, the visualizations of the small eigenvalues generally have more semantically meaningful and more structured patterns. The large eigenvalues mainly generate not obviously classrelevant and hard-to-interpret features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B EXPERIMENTS ON IMAGENET</head><p>Since some GCP methods (i.e., MPN-COV <ref type="bibr" target="#b6">[7]</ref> and iSQRT-COV <ref type="bibr" target="#b7">[8]</ref>) can work on the generic visual recognition task (e.g., ImageNet), we also apply our proposed SEB on this dataset to evaluate the performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Training Recipe for ImageNet</head><p>We take AlexNet and ResNet-50 as the model architectures and use the same experimental settings in our conference paper <ref type="bibr" target="#b11">[12]</ref>. We set the batch size as 128 for AlexNet and 256 for ResNet. The AlexNet is trained for 30 epochs with an initial learning rate set as 10 ?1.1 . The learning rate decays by 10 every 10 epochs. For training ResNet, we use the same learning rate to train for 60 epochs but decays by 10 at epoch 30 and epoch 45. We use SGD for optimization, with momentum of 0.9 and weight decay of 0.0001 for ResNet and 0.0005 for AlexNet. The network parameters are randomly initialized for both architectures. During training, the images are resized to 256?256 and then cropped to 224?224, with random horizontal flip augmentation. The inference is conducted on the 224?224 centered crop from the validation set. <ref type="table" target="#tab_10">Table 9</ref> shows the validation top-1 and top-5 accuracy on ImageNet. For AlexNet, our proposed SEB significantly improves the performances of MPN-COV <ref type="bibr" target="#b6">[7]</ref> by about 5 %. However, it brings 1 % performance drop on ResNet-50 though the training accuracy still surpass others by a large margin (see <ref type="figure" target="#fig_0">Fig. 10</ref>). This phenomenon implies that the ResNet-50 equipped with our SEB has the risks of over-fitting <ref type="figure">Fig. 7</ref>: Visualization of randomly chosen backward-based attributions on three fine-grained datasets. The small eigenvalues generate the input activations that are more coherent with those using all the eigenvalues. Zoom in for a better view. Zoom in for a better view. <ref type="figure">Fig. 9</ref>: Extra visualizations on Dogs and Flowers datasets. Obviously, small eigenvalues capture more semantically-meaningful and class-relevant feature patterns. and the poorer generalization performances. We observe that the eigenvalue distributions of the GCP methods on ImageNet are quite different from those on fine-grained benchmarks. For ImageNet, both the overall eigenvalue range and the eigenvalue differences are much smaller. Consider the large class complexity and the considerable amount of noise of ImageNet <ref type="bibr" target="#b69">[70]</ref>, <ref type="bibr" target="#b70">[71]</ref>, the small eigenvalues do not necessarily capture the class-specific features and the subtle classification clues. On the contrary, the small eigenvalues are more likely to encode only the data noise. Therefore, amplifying the insignificant eigenvalues might bring side effects on the generalization ability. To validate this guess, we also apply our proposed explainability methods on the ResNet-50 of MPN-COV <ref type="bibr" target="#b6">[7]</ref> trained on ImageNet to evaluate the behavior of eigenvalues, which will be illustrated in the following sections. Despite the analyses from the perspective of visual explainability, we think this problem is worth further research in our future work.  <ref type="figure" target="#fig_0">Fig. 11</ref> shows some examples of input responses to different eigenvalues. Unlike the case of fine-grained benchmarks, the large eigenvalues almost generate the identical input activations with all the eigenvalues, while the visualizations of small eigenvalues are less similar. <ref type="table" target="#tab_1">Table 10</ref> compares the quantitative evaluation results. For the large eigenvalues, the MAE is nearly negligible and the correlation coefficient achieves the maximum. This demonstrate that on ImageNet the decisions of the GCP networks are almost entirely dependent on the large eigenvalues and the associated eigenvectors. <ref type="figure" target="#fig_0">Fig. 12</ref> shows several examples of perturbation-based visualizations on ImageNet. Different from the situation on finegrained benchmarks, the learnt feature patterns of the small eigenvalues are not obviously class-relevant. In contrast, the large eigenvalues show some signs of the class-specific feature patterns.  <ref type="bibr" target="#b41">[42]</ref>. The evaluation is conducted on the subset of randomly selected 2, 000 images from the ImageNet validation set.  Both MPN-COV <ref type="bibr" target="#b6">[7]</ref> and iSQRT-COV <ref type="bibr" target="#b7">[8]</ref> first train ResNet-50 models with each GCP meta-layer on ImageNet from scratch and then use the same model to fine-tune on the fine-grained benchmarks. Although their reported results on fine-grained benchmarks are claimed to be based on the backbone ResNet-50, strictly speaking their backbone is actually ResNet-50 with the GCP meta-layer rather than the ordinary widely used ResNet-50. <ref type="table" target="#tab_1">Table 11</ref> shows their performances on these two backbones. As can be observed, only when the backbone equipped with the GCP meta-layer is trained on ImageNet from scratch, the GCP methods MPN-COV <ref type="bibr" target="#b6">[7]</ref> and iSQRT-COV <ref type="bibr" target="#b7">[8]</ref> can achieve comparable performances on fine-grained benchmarks. This may limit their practical usage as a dedicated backbone with the GCP layer is needed. Our proposed SEB is free of this constraint. It does not pose any backbone requirement and can achieve impressive performances on the commonly used backbones.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Results on AlexNet and ResNet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Backward-based Explainability on ImageNet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Perturbation-based Explainability on ImageNet</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>(Left) Validation accuracy on Aircrafts versus the number of truncated eigenvalues. When the small eigenvalues are truncated, the performance drops drastically. After 30 eigenvalues are truncated, the model cannot converge. (Middle and Right) Validation/training accuracy and loss on Aircrafts versus training epochs when the last 50 eigenvalues are truncated. The model fails to converge on the dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>(Left) Input responses of backward gradients to specific eigenvalues. Small eigenvalues (i.e., last 50 out of 256) highlight the salient class-discriminative regions, and they are coherent with the cases which use all eigenvalues. In contrast, the large eigenvalues (i.e., top 206) correspond to the background region. (Right) Visualization of learned feature patterns that maximally activate the specific eigenvalues: small eigenvalues correspond to the class-specific features (e.g., feather, beak, and head), while the features associated with the large eigenvalues are not obviously class-relevant and human-interpretable. Zoom in for a better view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2</head><label>2</label><figDesc>left displays several examples of input responses to all the eigenvalues, the large eigenvalues, and the small eigenvalues respectively. Obviously, for both rules, the visualizations of small eigenvalues are very similar to those of all eigenvalues. The salient points in their visualizations consistently fall on the objects. By contrast, the large eigenvalues mainly have activated neurons in the background and unimportant regions. More visualizations are provided in Supplementary Material.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Proposition 1 .</head><label>1</label><figDesc>The loss l 2 attains the minimum when the eigenvectors of M are U, and the eigenvalues of M maximally correlate with ? S but have zero correlation with ? L .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 :Fig. 4 :</head><label>34</label><figDesc>Overview of the standard global covariance pooling procedure (i.e., MPN-COV<ref type="bibr" target="#b6">[7]</ref> and iSQRT-COV<ref type="bibr" target="#b7">[8]</ref>) and the proposed SEB component (indicated in pink). Our proposed SEB augments the representation power of matrix square root by magnifying the importance of small eigenvalues. Without introducing any additional parameters, the performances are significantly boosted. Different eigenvalue normalization schemes. Our proposed matrix exponential inverse can effectively narrow the eigenvalue range and amplify the importance of the small ones.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>5. 5 . 1</head><label>51</label><figDesc>Impact of Only SEB Path.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>Validation accuracy curves versus training epochs of ResNet-50 on three fine-grained benchmarks. Our proposed SEB consistently outperforms the original GCP methods by a large margin. The lines are smoothed by a moving average filter for a better view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 :</head><label>6</label><figDesc>(Top) The histogram of eigenvalue distribution of the covariance P of MPN-COV</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5</head><label>5</label><figDesc>displays the validation accuracy curves of our SEB and the GCP methods on three fine-grained benchmarks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Nicu</head><label></label><figDesc>Sebe is Professor with the University of Trento, Italy, leading the research in the areas of multimedia information retrieval and human behavior understanding. He was the General Co-Chair of ACM Multimedia 2013, and the Program Chair of ACM Multimedia 2007 and 2011, ECCV 2016, ICCV 2017 and ICPR 2020. He is a fellow of the International Association for Pattern Recognition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Wei</head><label></label><figDesc>Wang is an Assistant Professor of Computer Science at University of Trento, Italy. Previously, after obtaining his PhD from University of Trento in 2018, he became a Postdoc at EPFL, Switzerland. His research interests include machine learning and its application to computer vision and multimedia analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 8 :</head><label>8</label><figDesc>Randomly selected perturbation-based visualizations. The small eigenvalues mainly activates the class-relevant semantic feature, whereas the large eigenvalues are related to the background and the human-uninterpretable patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 :</head><label>10</label><figDesc>Training and validation top-1 accuracy of our proposed SEB and other GCP methods with AlexNet and ResNet architectures on ImageNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 11 :</head><label>11</label><figDesc>Backward-based visual explanations of different eigenvalues on ImageNet. Different from the situation of fine-grained benchmarks, the large eigenvalues have almost identical input activations with all the eigenvalues. By contrast, the small eigenvalues exhibit less similar input responses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 12 :</head><label>12</label><figDesc>Perturbation-based visualization on ImageNet. Unlike the case of fine-grained benchmarks, the small eigenvalues do not show obviously class-relevant feature patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1 :</head><label>1</label><figDesc>The average correlation coefficient and MAE between the input activation of the specific eigenvalues and the responses of all the eigenvalues. For the correlation coefficient, a higher number indicates the larger similarity, while the lower MAE implies smaller differences.</figDesc><table><row><cell>Gradient</cell><cell>Eigenvalue</cell><cell cols="6">Correlation Coefficient Birds [1] Aircrafts [22] Cars [21] Birds [1] Aircrafts [22] Cars [21] Mean Absolute Error</cell></row><row><cell>Vanilla [42]</cell><cell>Large Small</cell><cell>0.06 0.81</cell><cell>0.23 0.80</cell><cell>0.11 0.81</cell><cell>3.5e-2 1.1e-2</cell><cell>3.3e-2 1.0e-2</cell><cell>3.5e-2 9.5e-3</cell></row><row><cell>DeConv [43]</cell><cell>Large Small</cell><cell>0.61 0.89</cell><cell>0.70 0.91</cell><cell>0.75 0.93</cell><cell>8.6e-2 3.4e-2</cell><cell>6.9e-2 3.1e-2</cell><cell>6.0e-2 2.4e-2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 2 :</head><label>2</label><figDesc>Classification accuracy (%) using only subsets of eigenvalues during the inference stage. Aircrafts [22] Cars [21] ? 1 , . . . , ? 206 (top 206) 65.3 70.1 72.4 ? 1 + ? 207 , . . . , ? 256 (last 50) + ? 217 , . . . , ? 256 (last 40) 79.2 80.7 81.8 ? 1 + ? 227 , . . . , ? 256 (last 30) 77.1 78.5 79.9 ? 1 , . . . , ? 256 (all 256)</figDesc><table><row><cell>Eigenvalue</cell><cell cols="3">Classification Accuracy (%) Birds [1] 81.3 82.1 83.4</cell></row><row><cell cols="2">? 1 84.3</cell><cell>89.9</cell><cell>91.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 4 :</head><label>4</label><figDesc>Comparison with other state-of-the-arts that are achieved by transformer-based methods on larger datasets.</figDesc><table><row><cell>Backbone</cell><cell>Method</cell><cell cols="3">Cars [21] Dogs [3] INats [23]</cell></row><row><cell></cell><cell>ViT2021 [38]</cell><cell>93.5</cell><cell>91.2</cell><cell>68.0</cell></row><row><cell>ViT [38]</cell><cell>TransFG2021 [37]</cell><cell>94.1</cell><cell>92.3</cell><cell>71.7</cell></row><row><cell></cell><cell>AFTrans2021 [65]</cell><cell>95.0</cell><cell>91.6</cell><cell>68.9</cell></row><row><cell></cell><cell>iSQRT-COV [8]</cell><cell>93.3</cell><cell>92.3</cell><cell>71.0</cell></row><row><cell>EfficientNet-b5 [64]</cell><cell>MPN-COV [7]</cell><cell>93.4</cell><cell>92.1</cell><cell>70.8</cell></row><row><cell></cell><cell cols="4">MPN-COV + Our SEB 94.6 (? 1.2) 93.0 (? 0.9) 72.3 (? 1.5)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 5 :</head><label>5</label><figDesc>Performance on other popular deep architectures.</figDesc><table><row><cell>Backbone</cell><cell>Method</cell><cell>Birds [1] Aircrafts [22] Cars [21]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 6 :</head><label>6</label><figDesc>Impact of using only SEB path.</figDesc><table><row><cell>Baselines</cell><cell cols="4">Formulation Birds [1] Aircrafts [22] Cars [21]</cell></row><row><cell>MPN-COV [7]</cell><cell>Q</cell><cell>84.3</cell><cell>89.9</cell><cell>91.7</cell></row><row><cell>SEB</cell><cell>||QS T || F ?Q</cell><cell>85.6</cell><cell>91.1</cell><cell>93.0</cell></row><row><cell cols="3">MPN-COV+SEB ||QS T || F ?Q+Q 86.2</cell><cell>91.4</cell><cell>93.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 7 :</head><label>7</label><figDesc>Impact of different scaling factors.</figDesc><table><row><cell cols="2">Factor</cell><cell cols="3">Birds [1] Aircrafts [22] Cars [21]</cell></row><row><cell cols="2">Constant 100</cell><cell>82.4</cell><cell>88.5</cell><cell>89.3</cell></row><row><cell>ReLU(MLP(?</cell><cell>1 2 )) + 1</cell><cell>82.9</cell><cell>89.1</cell><cell>91.3</cell></row><row><cell cols="2">ReLU(MLP(Q)) + 1</cell><cell>80.5</cell><cell>88.3</cell><cell>90.7</cell></row><row><cell>||S|| F</cell><cell></cell><cell>83.3</cell><cell>90.1</cell><cell>90.6</cell></row><row><cell>||Q|| F</cell><cell></cell><cell>83.8</cell><cell>90.3</cell><cell>92.1</cell></row><row><cell cols="2">||QS T || F</cell><cell>86.2</cell><cell>91.4</cell><cell>93.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE 8 :</head><label>8</label><figDesc>Time and memory consumption of GCP methods with ResNet-50 model on Cars dataset for each mini-batch.</figDesc><table><row><cell cols="3">Methods Computational Time (s) Memory Usage (M)</cell></row><row><cell>iSQRT-COV [8]</cell><cell>0.28</cell><cell>4345</cell></row><row><cell>MPN-COV [7]</cell><cell>0.30</cell><cell>4298</cell></row><row><cell>MPN-COV + Our SEB</cell><cell>0.31</cell><cell>4501</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE 9 :</head><label>9</label><figDesc>Comparison on validation accuracy with other GCP methods on ImageNet. Our SEB 56.68 (? 5.45) 79.94 (? 4.22) 75.79 (? 1.27 ) 92.58 (? 0.67)</figDesc><table><row><cell>Method</cell><cell cols="4">AlexNet [72] top-1 acc (%) top-5 acc (%) top-1 acc (%) top-5 acc (%) ResNet-50 [63]</cell></row><row><cell>iSQRT-COV [8]</cell><cell>52.06</cell><cell>66.36</cell><cell>77.19</cell><cell>93.40</cell></row><row><cell>MPN-COV [7]</cell><cell>51.23</cell><cell>75.72</cell><cell>77.07</cell><cell>93.25</cell></row><row><cell>SVD-Pad? [12]</cell><cell>51.59</cell><cell>76.09</cell><cell>77.33</cell><cell>93.49</cell></row><row><cell>MPN-COV +</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE 10 :</head><label>10</label><figDesc>The average correlation coefficient and the MAE between the input responses of the specific eigenvalues and the responses of all the eigenvalues. Here we use vanilla ReLU back-propagation rule</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE 11 :</head><label>11</label><figDesc>Performances on fine-grained benchmarks when the backbone is GCP ResNet-50. GCP ResNet-50 means that the ResNet-50 equipped with the GCP meta-layer is first trained on ImageNet from scratch. GAP refers to the Global Average Pooling layer used in the ResNet architecture. For MPN-COV<ref type="bibr" target="#b6">[7]</ref> and iSQRT-COV<ref type="bibr" target="#b7">[8]</ref>, the results are slightly different from the values reported in the original papers as different platforms and training protocols are used.</figDesc><table><row><cell>Backbone Architecture Pooling Layer</cell><cell>Method</cell><cell cols="3">Birds [1] Aircrafts [22] Cars [21]</cell></row><row><cell>GCP ResNet-50 2 nd -order GCP</cell><cell>iSQRT-COV [8] MPN-COV [7]</cell><cell>87.3 87.2</cell><cell>89.5 90.5</cell><cell>91.7 92.8</cell></row><row><cell>ResNet-50 [63] 1 st -order GAP</cell><cell>iSQRT-COV [8] MPN-COV [7]</cell><cell>84.7 84.3</cell><cell>89.6 89.9</cell><cell>91.4 91.7</cell></row><row><cell></cell><cell cols="4">MPN-COV + Our SEB 86.2 (? 1.0) 91.4 (? 0.9) 93.6 (? 0.8)</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Caltech-UCSD Birds 200</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<idno>CNS-TR-2010-001</idno>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Building a bird recognition app and large scale dataset with citizen scientists: The fine print in finegrained dataset collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Novel dataset for fine-grained image categorization: Stanford dogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jayadevaprakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop on Fine-Grained Visual Categorization (FGVC)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep compositional captioning: Describing novel object categories without paired training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Food recommendation: Framework, existing solutions, and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMM</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Solving mixed-modal jigsaw puzzle for fine-grained sketch-based image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Is second-order information helpful for large-scale visual recognition?&quot; in ICCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards faster training of global covariance pooling networks by iterative matrix square root normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hierarchical bilinear pooling for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning deep bilinear transformation for fine-grained image representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-J</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Deep cnns meet global covariance pooling: Better representation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">TPAMI</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Why approximate matrix square root outperforms accurate svd in global covariance pooling?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">in ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Matrix backpropagation for deep networks with structured layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vantzos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improved bilinear pooling with cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMVC</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The approximation of one matrix by another of lower rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Eckart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="218" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Svd based image processing applications: state of the art, contributions and research challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Sadek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Computer Science and Applications</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Understanding complex datasets: data mining with matrix decompositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Skillicorn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Inceptionism: Going deeper into neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mordvintsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tyka</surname></persName>
		</author>
		<ptr target="https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Toward faster and simpler matrix normalization via rank-1 update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International IEEE Workshop on 3D Representation and Recognition</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Fine-grained visual classification of aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.5151</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The inaturalist species classification and detection dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">Mac</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Poof: Part-based one-vs.-one features for fine-grained categorization, face verification, and attribute estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hierarchical part matching for fine-grained visual categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Bird species categorization using pose normalized deep convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">BMVC</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Part-stacked cnn for fine-grained visual categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Weakly supervised complementary parts models for fine-grained image classification from the bottom up</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stochastic partial swap: Enhanced model generalization and interpretability for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bilinear cnn models for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roychowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Beijbom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Compact bilinear pooling,&quot; in CVPR</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Low-rank bilinear pooling for finegrained classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Monet: Moments embedding network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Camps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sznaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fine-grained visual classification via progressive multi-granularity training of jigsaw patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Bhunia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Feature fusion vision transformer for fine-grained visual categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">BMVC</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Transformer with peak suppression and knowledge guidance for fine-grained image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Transfg: A transformer architecture for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kortylewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">G2denet: Global gaussian distribution embedding network and its application to visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Kernel pooling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Robust differentiable svd,&quot; TPAMI, 2021</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep inside convolutional networks: Visualising image classification models and saliency maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR Workshop</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Striving for simplicity: The all convolutional net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Grad-cam: Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">There and back again: Revisiting backpropagation saliency methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">why should i trust you?&quot; explaining the predictions of any classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Interpretable explanations of black boxes by meaningful perturbation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Real time image saliency for black box classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dabkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Rise: Randomized input sampling for explanation of black-box models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Petsiuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">BMVC</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Understanding deep networks via extremal perturbations and smooth masks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Classifier-agnostic saliency map extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zolna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Geras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVIU</title>
		<imprint>
			<biblScope unit="volume">196</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fast differentiable matrix square root</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Training deep networks with structured layers by matrix backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vantzos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.07838</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A trace inequality of john von neumann</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mirsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Monatshefte f?r mathematik</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="303" to="306" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A note on von neumann&apos;s trace inequalitv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Grigorieff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematische Nachrichten</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="327" to="328" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Non-euclidean statistics for covariance matrices, with applications to diffusion tensor imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">L</forename><surname>Dryden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koloydenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1102" to="1123" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Geometric means in a novel vector space structure on symmetric positive-definite matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Arsigny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on matrix analysis and applications</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="328" to="347" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A riemannian framework for tensor computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A new metric on the manifold of kernel matrices with application to matrix geometric means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">ICLR</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Grassmann pooling as compact homogeneous bilinear pooling for fine-grained visual classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A free lunch from vit: Adaptive attention multi-scale fusion transformer for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Novel dataset for fine-grained image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jayadevaprakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Workshop on Fine-Grained Visual Categorization, IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Colorado Springs, CO</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Delving deeper into the whorl of flower segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-E</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Webvision database: Visual learning and understanding from web data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">J</forename><surname>H?naff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V D</forename><surname>Oord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07159</idno>
		<title level="m">Are we done with imagenet?</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="84" to="90" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
				<title level="m">he is a Ph.D. student with the Multimedia and Human Understanding Group (MHUG) at the University of</title>
		<meeting><address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint/>
		<respStmt>
			<orgName>Yue Song received the B.Sc. cum laude from KU Leuven, Belgium and the joint M.Sc. summa cum laude from the University of Trento, Italy and KTH Royal Institute of Technology, Sweden. Currently</orgName>
		</respStmt>
	</monogr>
	<note>His research interests are computer vision and numerical methods</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
