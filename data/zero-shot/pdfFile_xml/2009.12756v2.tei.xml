<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Published as a conference paper at ICLR 2021 ANSWERING COMPLEX OPEN-DOMAIN QUESTIONS WITH MULTI-HOP DENSE RETRIEVAL</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Barbara</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><forename type="middle">Lorraine</forename><surname>Li</surname></persName>
							<email>xiangl@cs.umass.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Massachusetts Amherst ? University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
							<email>sviyer@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
							<email>jingfeidu@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
							<email>plewis@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Wang</surname></persName>
							<email>william@cs.ucsb.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Barbara</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
							<email>mehdad@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
							<email>sriedel@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
							<email>dkiela@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
							<email>barlaso@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Facebook</forename><surname>Ai</surname></persName>
						</author>
						<title level="a" type="main">Published as a conference paper at ICLR 2021 ANSWERING COMPLEX OPEN-DOMAIN QUESTIONS WITH MULTI-HOP DENSE RETRIEVAL</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a simple and efficient multi-hop dense retrieval approach for answering complex open-domain questions, which achieves state-of-the-art performance on two multi-hop datasets, HotpotQA and multi-evidence FEVER. Contrary to previous work, our method does not require access to any corpus-specific information, such as inter-document hyperlinks or human-annotated entity markers, and can be applied to any unstructured text corpus. Our system also yields a much better efficiency-accuracy trade-off, matching the best published accuracy on HotpotQA while being 10 times faster at inference time. 1 * Equal Contribution 1 https://github.com/facebookresearch/multihop_dense_retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Open domain question answering is a challenging task where the answer to a given question needs to be extracted from a large pool of documents. The prevailing approach <ref type="bibr" target="#b4">(Chen et al., 2017)</ref> tackles the problem in two stages. Given a question, a retriever first produces a list of k candidate documents, and a reader then extracts the answer from this set. Until recently, retrieval models were dependent on traditional term-based information retrieval (IR) methods, which fail to capture the semantics of the question beyond lexical matching and remain a major performance bottleneck for the task. Recent work on dense retrieval methods instead uses pretrained encoders to cast the question and documents into dense representations in a vector space and relies on fast maximum inner-product search (MIPS) to complete the retrieval. These approaches <ref type="bibr" target="#b14">Guu et al., 2020;</ref><ref type="bibr" target="#b18">Karpukhin et al., 2020)</ref> have demonstrated significant retrieval improvements over traditional IR baselines.</p><p>However, such methods remain limited to simple questions, where the answer to the question is explicit in a single piece of text evidence. In contrast, complex questions typically involve aggregating information from multiple documents, requiring logical reasoning or sequential (multihop) processing in order to infer the answer (see <ref type="figure">Figure 1</ref> for an example). Since the process for answering such questions might be sequential in nature, single-shot approaches to retrieval are insufficient. Instead, iterative methods are needed to recursively retrieve new information at each step, conditioned on the information already at hand. Beyond further expanding the scope of existing textual open-domain QA systems, answering more complex questions usually involves multi-hop reasoning, which poses unique challenges for existing neural-based AI systems. With its practical MIPS ... <ref type="figure">Figure 1</ref>: An overview of the multi-hop dense retrieval approach.</p><p>and research values, multi-hop QA has been extensively studied recently <ref type="bibr" target="#b37">(Talmor &amp; Berant, 2018;</ref><ref type="bibr" target="#b49">Yang et al., 2018;</ref><ref type="bibr" target="#b43">Welbl et al., 2018)</ref> and remains an active research area in NLP <ref type="bibr" target="#b30">(Qi et al., 2019;</ref><ref type="bibr" target="#b28">Nie et al., 2019;</ref><ref type="bibr" target="#b27">Min et al., 2019;</ref><ref type="bibr" target="#b51">Zhao et al., 2020;</ref><ref type="bibr" target="#b0">Asai et al., 2020;</ref><ref type="bibr" target="#b29">Perez et al., 2020)</ref>.</p><p>The main problem in answering multi-hop open-domain questions is that the search space grows exponentially with each retrieval hop. Most recent work tackles this issue by constructing a document graph utilizing either entity linking or existing hyperlink structure in the underlying Wikipedia corpus <ref type="bibr" target="#b28">(Nie et al., 2019;</ref><ref type="bibr" target="#b0">Asai et al., 2020)</ref>. The problem then becomes finding the best path in this graph, where the search space is bounded by the number of hyperlinks in each passage. However, such methods may not generalize to new domains, where entity linking might perform poorly, or where hyperlinks might not be as abundant as in Wikipedia. Moreover, efficiency remains a challenge despite using these data-dependent pruning heuristics, with the best model <ref type="bibr" target="#b0">(Asai et al., 2020)</ref> needing hundreds of calls to large pretrained models to produce a single answer.</p><p>In contrast, we propose to employ dense retrieval to the multi-hop setting with a simple recursive framework. Our method iteratively encodes the question and previously retrieved documents as a query vector and retrieves the next relevant documents using efficient MIPS methods. With highquality, dense representations derived from strong pretrained encoders, our work first demonstrates that the sequence of documents that provide sufficient information to answer the multi-hop question can be accurately discovered from unstructured text, without the help of corpus-specific hyperlinks. When evaluated on two multi-hop benchmarks, HotpotQA <ref type="bibr" target="#b49">(Yang et al., 2018)</ref> and a multi-evidence subset of FEVER <ref type="bibr" target="#b38">(Thorne et al., 2018)</ref>, our approach improves greatly over the traditional linkingbased retrieval methods. More importantly, the better retrieval results also lead to state-of-the-art downstream results on both datasets. On HotpotQA, we demonstrate a vastly improved efficiencyaccuracy trade-off achieved by our system: by limiting the amount of retrieved contexts fed into downstream models, our system can match the best published result while being 10x faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">PROBLEM DEFINITION</head><p>The retrieval task considered in this work can be described as follows (see also <ref type="figure">Figure 1</ref>). Given a multi-hop question q and a large text corpus C, the retrieval module needs to retrieve a sequence of passages P seq : {p 1 , p 2 , ..., p n } that provide sufficient information for answering q. Practically, the retriever returns the k best-scoring sequence candidates, {P 1 seq , P 2 seq , ..., P k seq } (k |C|), with the hope that at least one of them has the desired qualities. k should be small enough for downstream modules to process in a reasonable time while maintaining adequate recall. In general, retrieval also needs to be efficient enough to handle real-world corpora containing millions of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MULTI-HOP DENSE RETRIEVAL</head><p>Model Based on the sequential nature of the multi-hop retrieval problem, our system solves it in an iterative fashion. We model the probability of selecting a certain passage sequence as follows:</p><formula xml:id="formula_0">P (P seq |q) = n t=1 P (p t |q, p 1 , ..., p t?1 ),</formula><p>where for t = 1, we only condition on the original question for retrieval. At each retrieval step, we construct a new query representation based on previous results and the retrieval is implemented as maximum inner product search over the dense representations of the whole corpus:</p><formula xml:id="formula_1">P (p t |q, p 1 , ..., p t?1 ) = exp ( p t , q t ) p?C exp ( p, q t )</formula><p>, where q t = g(q, p 1 , ..., p t?1 ) and p t = h(p t ).</p><p>Here ?, ? is the inner product between the query and passage vectors. h(?) and and g(?) are passage and query encoders that produce the dense representations. In order to reformulate the query representation to account for previous retrieval results at time step t, we simply concatenate the question and the retrieved passages as the inputs to g(?). Note that our formulation for each retrieval step is similar to existing single-hop dense retrieval methods <ref type="bibr" target="#b14">Guu et al., 2020;</ref><ref type="bibr" target="#b18">Karpukhin et al., 2020)</ref> except that we add the query reformulation process conditioned on previous retrieval results. Additionally, instead of using a bi-encoder architecture with separately parameterized encoders for queries and passages, we use a shared RoBERTa-base  encoder for both h(?) and g(?). In ?3.1.3, we show this simple modification yields considerable improvements. Specifically, we apply layer normalization over the start token's representations from RoBERTa to get the final dense query/passage vectors.</p><p>Training and Inference The retriever model is trained as in <ref type="bibr" target="#b18">Karpukhin et al. (2020)</ref>, where each input query (which at each step consists of a question and previously retrieved passages) is paired with a positive passage and m negative passages to approximate the softmax over all passages. The positive passage is the gold annotated evidence at step t. Negative passages are a combination of passages in the current batch which correspond to other questions (in-batch), and hard negatives which are false adversarial passages. In our experiments, we obtain hard negatives from TF-IDF retrieved passages and their linked pages in Wikipedia. We note that using hyperlinked pages as additional negatives is neither necessary nor critical for our approach. In fact we observe only a very small degradation in performance if we remove them from training ( ?3.1.3). In addition to in-batch negatives, we use a memory bank (M) mechanism <ref type="bibr" target="#b47">(Wu et al., 2018)</ref> to further increase the number of negative examples for each question. The memory bank stores a large number of dense passage vectors. As we block the gradient back-propagation in the memory bank, its size (|M| batch size) is less restricted by the GPU memory size. Specifically, after training to convergence with the shared encoder, we freeze a copy of the encoder as the new passage encoder and collect a bank of passage representations across multiple batches to serve as the set of negative passages. This simple extension results in further improvement in retrieval. ( ?3.1.3).</p><p>For inference, we first encode the whole corpus into an index of passage vectors. Given a question, we use beam search to obtain top-k passage sequence candidates, where the candidates to beam search at each step are generated by MIPS using the query encoder at step t, and the beams are scored by the sum of inner products as suggested by the probabilistic formulation discussed above. Such inference relies only on the dense passage index and the query representations, and does not need explicit graph construction using hyperlinks or entity linking. The top-k sequences will then be fed into task-specific downstream modules to produce the desired outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>Datasets Our experiments focus on two datasets: HotpotQA and Multi-evidence FEVER. Hot-potQA <ref type="bibr" target="#b49">(Yang et al., 2018)</ref> includes 113k multi-hop questions. Unlike other multi-hop QA datasets <ref type="bibr" target="#b37">Talmor &amp; Berant, 2018;</ref><ref type="bibr" target="#b43">Welbl et al., 2018)</ref>, where the information sources of the answers are knowledge bases, HotpotQA uses documents in Wikipedia. Thus, its questions are not restricted by the fixed KB schema and can cover more diverse topics. Each question in HotpotQA is also provided with ground truth support passages, which enables us to evaluate the intermediate retrieval performance. Multi-evidence FEVER includes 20k claims from the FEVER <ref type="bibr" target="#b38">(Thorne et al., 2018)</ref> fact verification dataset, where the claims can only be verified using multiple documents. We use this dataset to validate the general applicability of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>All the experiments are conducted on a machine with 8 32GB V100 GPUs. Our code is based on Huggingface Transformers <ref type="bibr" target="#b44">(Wolf et al., 2019)</ref>. Our best retrieval results are predicted using the exact inner product search index (IndexFlatIP) in FAISS <ref type="bibr" target="#b17">(Johnson et al., 2017)</ref>. Both datasets assume 2 hops, so we fix n = 2 for all experiments. Since HotpotQA does not provide the order of the passage sequences, as a heuristic, we consider the passage that includes the answer span as the final passage. 2 In ?3.1.3, we show that the order of the passages is important for effective retriever training. The hyperparameters can be found in Appendix B.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">EXPERIMENTS: RETRIEVAL</head><p>We evaluate our multi-hop dense retriever (MDR) in two different use cases: direct and reranking, where the former outputs the top-k results directly using the retriever scores and the latter applies a task-specific reranking model to the initial results from MDR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">DIRECT</head><p>We first compare MDR with several efficient retrieval methods that can directly find the top-k passage sequences from a large corpus, including TF-IDF, TF-IDF + Linked, DrKIT and Entity Linking. TF-IDF is the standard term-matching baseline, while TF-IDF + Linked is a straightforward extension that also extracts the hyperlinked passages from TF-IDF passages, and then reranks both TF-IDF and hyperlinked passages with BM25 3 scores. DrKIT <ref type="bibr" target="#b11">(Dhingra et al., 2020)</ref> is a recently proposed dense retrieval approach, which builds a entity-level (mentions of entities) dense index for retrieval. It relies on hyperlinks to extract entity mentions and prunes the search space with a binary mask that restricts the next hop to using hyperlinked entities. On FEVER, we additionally consider an entity linking baseline <ref type="bibr" target="#b15">(Hanselowski et al., 2018)</ref> that is commonly used in existing fact verification pipelines. This baseline first uses a constituency parser to extract potential entity mentions in the fact claim and then uses the MediaWiki API to search documents with titles that match the mentions. <ref type="table" target="#tab_0">Table 1</ref> shows the performance of different retrieval methods. On HotpotQA the metric is recall at the top k paragraphs 4 , while on FEVER the metrics are precision, recall and F 1 in order to be consistent with previous results. On both datasets, MDR substantially outperforms all baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">RERANKING</head><p>Reranking documents returned by efficient retrieval methods with a more sophisticated model is a common strategy for improving retrieval quality. For instance, state-of-the-art multi-hop QA systems usually augment traditional IR techniques with large pretrained language models to select a more compact but precise passage set. On HotpotQA, we test the effectiveness of MDR after a simple cross-attention reranking: each of the top k passage sequences from MDR is first prepended with the original question and then fed into a pretrained Transformer encoder, i.e., ELECTRA-large <ref type="bibr" target="#b5">(Clark et al., 2020)</ref>, that predicts relevant scores. We train this reranking model with a binary crossentropy loss, with the target being whether the passage sequence cover both groundtruth passages. We empirically compare our approach with two other existing reranking-based retrieval methods: Semantic Retrieval <ref type="bibr" target="#b28">(Nie et al., 2019)</ref> uses BERT at both passage-level and sentence-level to select context from the initial TF-IDF and hyperlinked passages; Graph Recurrent Retriever <ref type="bibr" target="#b0">(Asai et al., 2020)</ref> learns to recursively select the best passage sequence on top of a hyperlinked passage graph, where each passage node is encoded with BERT. 2 If the answer span is in both, the one that has its title mentioned in the other passage is treated as the second. 3 https://pypi.org/project/rank-bm25 4 As the sequence length is 2 for HotpotQA, we pick the top k/2 sequences predicted by MDR. 5 Whether the final predicted sequence covers both gold passages.  encoding involves cross-attention over a concatenated question-passage pair). After we rerank the top-100 sequences from the dense retriever, our passage recall is better than the state-of-the-art Graph Recurrent Retriever, which uses BERT to process more than 500 passages. We do not compare the reranked results on FEVER, as most FEVER systems directly use BERT encoder to select the top evidence sentences from the retrieved documents, instead of the reranking the documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">ANALYSIS</head><p>To understand the strengths and weaknesses of MDR, we conduct further analysis on HotpotQA dev. This case appears almost solved, confirming recent work demonstrating that dense retrieval is very effective at entity linking <ref type="bibr" target="#b46">(Wu et al., 2019)</ref>.</p><p>For the case of bridge questions, we manually inspect 50 randomly sampled erroneous examples after reranking. We find that in half of these cases, our retrieval model predicts an alternative passage sequence that is also valid (see Appendix A.1 for examples). This gives an estimated top-1 passage sequence accuracy of about 90%. Other remaining errors are due to the dense method's inability to capture the exact n-gram match between the question and passages. This is a known issue <ref type="bibr" target="#b18">Karpukhin et al., 2020)</ref> of dense retrieval methods when dealing with questions that have high lexical overlap with the passages. To this end, a hybrid multi-hop retrieval method with both term and dense index might be used to further improve the performance on bridge questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retriever Ablation Study</head><p>In <ref type="table" target="#tab_3">Table 3</ref>, we examine our model with different variations on HotpotQA to show the effectiveness of each proposed component. We see that further training with a memory bank results in modest gains, while using a shared encoder is crucial for the best performance.</p><p>Respecting the ordering of passages in two hops is essential -training in an order-agnostic manner hardly works at all, and underperforms even the single-hop baseline. Finally, not using hyperlinked paragraphs from TF-IDF passages as additional negatives has only a minor impact on performance.</p><p>Question Decomposition for Retrieval As multi-hop questions have more complex structures than simple questions, recent studies <ref type="bibr" target="#b27">(Min et al., 2019;</ref><ref type="bibr" target="#b29">Perez et al., 2020)</ref> propose to use explicit question decomposition to simplify the problem. <ref type="bibr" target="#b45">Wolfson et al. (2020)</ref> shows that with TF-IDF, using decomposed questions improves the retrieval results. We investigate whether the conclusion still holds with stronger dense retrieval methods. We use the human-annotated question decomposition from the QDMR dataset <ref type="bibr" target="#b45">(Wolfson et al., 2020)</ref> for analysis. For a question like Q:Mick Carter is the landlord of a public house located at what address?, QDMR provides two subquestions, SubQ1: What is the public house that Mick Carter is the landlord of? and SubQ2: What is the address that #1 is located at?. We sample 100 bridge questions and replace #1 in SubQ2 with the correct answer (The Queen Victoria) to SubQ1. Note that this gives advantages to the decomposed method as we ignore any intermediate errors. We estimate the performance of potential decomposed methods with the state-of-the-art single-hop dense retrieval model <ref type="bibr" target="#b18">(Karpukhin et al., 2020)</ref>. As shown in <ref type="table" target="#tab_4">Table 4</ref>, we did not observe any strong improvements from explicit question decomposition, which is contrary to the findings by <ref type="bibr" target="#b45">Wolfson et al. (2020)</ref> when using term-based IR methods. Moreover, as shown in the third row of the table, when the 1st hop of the decomposed retrieval (i.e., SubQ1) is replaced with the original question, no performance degradation is observed. This suggests that strong pretrained encoders can effectively learn to select necessary information from the multi-hop question at each retrieval step. Regarding the performance drop when using explicit compositions, we hypothesize that it is because some information in one decomposed subquestion could be useful for the other retrieval hop. Examples supporting this hypothesis can be found in Appendix A.2. While this could potentially be addressed by a different style of decomposition, our analysis suggests that decomposition approaches might be sub-optimal in the context of dense retrieval with strong pretrained encoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">EXPERIMENTS: HOTPOTQA</head><p>We evaluate how the better retrieval results of MDR improve multi-hop question answering in this section. As our retriever system is agnostic to downstream models, we test two categories of answer prediction architectures: the extractive span prediction models based on pretrained masked language models, such as BERT  and ELECTRA <ref type="bibr" target="#b5">(Clark et al., 2020)</ref>, and the retrieval-augmented generative reader models <ref type="bibr" target="#b22">(Lewis et al., 2020b;</ref><ref type="bibr" target="#b16">Izacard &amp; Grave, 2020)</ref>, which are based on pretrained sequence-to-sequence (seq2seq) models such as BART <ref type="bibr" target="#b21">(Lewis et al., 2020a)</ref> and T5 <ref type="bibr" target="#b31">(Raffel et al., 2019)</ref>. Note that compared to more complicated graph reasoning models <ref type="bibr" target="#b12">(Fang et al., 2019;</ref><ref type="bibr" target="#b51">Zhao et al., 2020)</ref>, these two classes of models do not rely on hyperlinks and can be applied to any text.</p><p>Extractive reader models learn to predict an answer span from the concatenation of the question and passage sequence ([q, p 1 , ..., p n ]). On top of the token representations produced by pretrained models, we add two prediction heads to predict the start and end position of the answer span. <ref type="bibr">6</ref> To predict the supporting sentences, we add another prediction head and predict a binary label at each sentence start. For simplicity, the same encoder is also responsible for reranking the top k passage sequences. The reranking detail has been discussed in ?3.1.2. Our best reader model is based on ELECTRA <ref type="bibr" target="#b5">(Clark et al., 2020)</ref>, which has achieved the best single-model performance on the standard SQuAD <ref type="bibr" target="#b32">(Rajpurkar et al., 2018)</ref> benchmark. Additionally, we also report the performance of BERT-large with whole word masking (BERT-wwm) to fairly compare with <ref type="bibr" target="#b0">Asai et al. (2020)</ref>.</p><p>Generative models, such as RAG <ref type="bibr" target="#b22">(Lewis et al., 2020b)</ref> and FiD <ref type="bibr" target="#b16">(Izacard &amp; Grave, 2020)</ref>, are based on pretrained seq2seq models. These methods finetune pretrained models with the concatenated questions and retrieved documents as inputs, and answer tokens as outputs. This generative paradigm has shown state-of-the-art performance on single-hop open-domain QA tasks. Specifically, FiD first uses the T5 encoder to process each retrieved passage sequence independently and then uses the decoder to perform attention over the representations of all input tokens while generating answers.</p><p>RAG is built on the smaller BART model. Instead of only tuning the seq2seq model, it also jointly train the question encoder of the dense retriever. We modified it to allow multi-hop retrieval.</p><p>More details about these two classes of reader models are described in Appendix B.2. Comparison with Existing Systems <ref type="table" target="#tab_5">Table 5</ref> compares the HotpotQA test performance of our best ELECTRA reader with recently published systems, using the numbers from the official leaderboard, which measure answer and supporting sentence exact match (EM)/F1 and joint EM/F1. Among these methods, only GoldEn Retriever <ref type="bibr" target="#b30">(Qi et al., 2019)</ref> does not exploit hyperlinks. In particular, Graph Recurrent Retriever trains a graph traversal model for chain retrieval; TransformerXH <ref type="bibr" target="#b51">(Zhao et al., 2020)</ref> and HGN <ref type="bibr" target="#b12">(Fang et al., 2019)</ref> explicitly encode the hyperlink graph structure within their answer prediction models. In fact, this particular inductive bias provides a perhaps unreasonably strong advantage in the specific context of HotpotQA, which by construction guarantees groundtruth passage sequences to follow hyperlinks. Despite not using such prior knowledge, our model outperforms all previous systems by large margins, especially on supporting fact prediction, which benefits more directly from better retrieval. Reader Model Variants Results for reader model variants are shown in <ref type="table" target="#tab_6">Table 6</ref>. <ref type="bibr">7</ref> First, we see that the BERT-wwm reader is 1-2% worse than the ELECTRA reader when using enough passages. However, it still outperforms the results in <ref type="bibr" target="#b0">(Asai et al., 2020)</ref> which also uses BERT-wwm for answer prediction. While RAG and FiD have shown strong improvements over extractive models on single-hop datasets such as NaturalQuestions <ref type="bibr" target="#b19">(Kwiatkowski et al., 2019)</ref>, they do not show an advantage in the multi-hop case. Despite having twice as many parameters as ELECTRA, FiD fails to outperform it using the same amount of context (top 50). In contrast, on NaturalQuestions, FiD is 4 points better than a similar extractive reader when using the top 100 passages in both. <ref type="bibr">8</ref> We hypothesize that the improved performance on single-hop questions is due to the ability of larger pretrained models to more effectively memorize single-hop knowledge about real-world entities. 9 Compared to multi-hop questions that involve multiple relations and missing entities, simple questions usually only ask about a certain property of an entity. It is likely that such simple entity-centric information is explicitly mentioned by a single text piece in the pretraining corpus, while the evidence for multihop questions is typically dispersed, making the 7 For the compute-heavy generative models, we feed in as many passages as possible without running into memory issues (Muli-hop RAG takes top 4 passages from hop1, and for each of those, takes another top 4 from hop2. They are not necessarily the same as the top 16 passages sequences.). As extractive models encode each passage sequence separately, we can use arbitrary number of input sequences. However, the performance mostly plateaus as we use over 200 input sequences. <ref type="bibr">8</ref> We implemented NQ extractive readers with both RoBERTa-large and ELECTRA-large, and RoBERTa-large yielded a better answer EM of 47.3, which is much lower than the 51.4 answer EM achieved by FiD. <ref type="bibr">9</ref> As shown by <ref type="bibr" target="#b33">Roberts et al. (2020)</ref>, a large pretrained seq2seq model can be finetuned to directly decode answers with questions as the only inputs. However, we find that this retrieval-free approach performs poorly on multi-hop questions. See Appendix C for the exact numbers.  Inference Efficiency To compare with existing multi-hop QA systems in terms of efficiency, we follow <ref type="bibr" target="#b11">Dhingra et al. (2020)</ref> and measure the inference time with 16 CPU cores and batch size 1. We implement our system with a fast approximate nearest neighbor search method, i.e., <ref type="bibr">HNSW (Malkov &amp; Yashunin, 2018)</ref>, which achieves nearly the same performance as exact search. With an in-memory index, we observe that the retrieval time is negligible compared to the forward pass of large pretrained models. Similarly, for systems that use term-based indices, the BERT calls for passage reranking cause the main efficiency bottleneck. Thus, for systems that do not release the end-to-end code, we estimate the running time based on the number of BERT cross-attention forward passes (the same estimation strategy used by <ref type="bibr" target="#b11">Dhingra et al. (2020)</ref>), and ignore the overhead caused by additional processing such as TF-IDF or linking graph construction. As shown in <ref type="figure" target="#fig_1">Figure 3</ref>, our method is about 10 times faster than current state-ofthe-art systems while achieving a similar level of performance. Compared to two efficient systems (DrKIT and GoldEn), we achieve over 10 points improvement while only using the top-1 retrieval result for answer and supporting sentence prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">EXPERIMENTS: MULTI-EVIDENCE FEVER</head><p>For FEVER claim verification, we reuse the best open-sourced verification system, i.e., KGAT <ref type="bibr" target="#b24">(Liu et al., 2020)</ref>, to show the benefit of our retrieval approach over existing retrieval methods. We report the results in verification label accuracy (LA) and the FEVER score 10 in <ref type="table" target="#tab_7">Table 7</ref>, where the numbers of competitive baselines, <ref type="bibr">GEAR (Zhou et al., 2019)</ref>, graph attention network (GAT) <ref type="bibr" target="#b40">(Veli?kovi? et al., 2017)</ref> and variants of KGAT are from the KGAT <ref type="bibr" target="#b24">(Liu et al., 2020)</ref> paper. All these baselines use entity linking for document retrieval, then rerank the sentences of the retrieved documents, and finally use different graph attention mechanisms over the fully-connected sentence graph to predict verification labels. Since some instances in the multi-evidence subset used by previous studies only needs multiple evidence sentences from the same document, we additionally test on a strict multi-hop subset with instances that need multiple documents. As shown by the results, even without finetuning the downstream modules, simply replacing the retrieval component with MDR leads to significant improvements, especially on the strict multi-evidence subset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head><p>Open-domain QA with Dense Retrieval In contrast to sparse term-index IR methods that are widely used by existing open-domain QA systems <ref type="bibr" target="#b4">(Chen et al., 2017;</ref><ref type="bibr" target="#b42">Wang et al., 2018;</ref><ref type="bibr" target="#b48">Yang et al., 2019)</ref>, recent systems <ref type="bibr" target="#b14">Guu et al., 2020;</ref><ref type="bibr" target="#b18">Karpukhin et al., 2020)</ref> typically uses dense passage retrieval techniques that better capture the semantic matching beyond simple n-gram overlaps. To generate powerful dense question and passage representations, these methods either conduct large-scale pretraining with self-supervised tasks that are close to the underlying question-passage matching in retrieval, or directly use the human-labeled question-passage pairs to finetune pretrained masked language models. On single-hop information-seeking QA datasets such as NaturalQuestions <ref type="bibr" target="#b19">(Kwiatkowski et al., 2019)</ref> or WebQuestions <ref type="bibr" target="#b2">(Berant et al., 2013)</ref>, these dense methods have achieved significant improvements over traditional IR methods. Prior to these methods based on pretrained models, <ref type="bibr" target="#b8">Das et al. (2019)</ref> use RNN encoder to get dense representations of questions and passages. They also consider an iterative retrieval process and reformulate the query representation based on reader model's hidden states. However, their method requires an initial round of TF-IDF/BM25 retrieval and a sophisticated RL-based training paradigm to work well. Finally, like the aforementioned methods, only single-hop datasets are considered in their experiments. More akin to our approach, Feldman &amp; El-Yaniv (2019) use a similar recursive dense retrieval formulation for multi-hop QA. In contrast to their biattenional reformulation component, which is applied on top of the token-level representations of the query and passages, we adopt a more straightforward query reformulation strategy, by simply concatenating the original query and previous retrieval as the inputs to the query encoder. Together with stronger pretrained encoders and more effective training methods (in-batch + memory bank negative sampling vs their binary ranking loss), MDR is able to double the accuracy of their system.</p><p>Query Expansion Techniques in IR As our dense encoder augments the original question with the initial retrieved results to form the updated query representation, our work is also relevant to query expansion techniques <ref type="bibr" target="#b34">(Rocchio, 1971;</ref><ref type="bibr" target="#b41">Voorhees, 1994;</ref><ref type="bibr" target="#b35">Ruthven &amp; Lalmas, 2003)</ref> that are widely used in traditional IR systems. In particular, our system is similar in spirit to pseudo-relevance feedback techniques <ref type="bibr" target="#b7">(Croft &amp; Harper, 1979;</ref><ref type="bibr" target="#b3">Cao et al., 2008;</ref><ref type="bibr" target="#b25">Lv &amp; Zhai, 2010)</ref>, where no additional user interaction is required at the query reformulation stage. Existing studies mainly focus on alleviating the uncertainty of the user query (Collins- <ref type="bibr" target="#b6">Thompson &amp; Callan, 2007)</ref> by adding relevant terms from the first round of retrieval, where the retrieval target remains the same throughout the iterative process. In contrast, the query reformulation in our approach aims to follow the multi-hop reasoning chain and effectively retrieves different targets at each step. Furthermore, instead of explicitly selecting terms to expand the query, we simply concatenate the whole passage and rely on the pretrained encoder to choose useful information from the last retrieved passage.</p><p>Other Multi-hop QA Work Apart from HotpotQA, other multi-hop QA datasets <ref type="bibr" target="#b43">(Welbl et al., 2018;</ref><ref type="bibr" target="#b37">Talmor &amp; Berant, 2018;</ref> are mostly built from knowledge bases (KBs). Compared to questions in HotpotQA, questions in these datasets are rather synthetic and less diverse.</p><p>As multi-hop relations in KBs could be mentioned together in a single text piece, these datasets are not designed for an open-domain setting which necessitates multi-hop retrieval. Existing methods on these datasets either retrieve passages from a small passage pool pruned based on the the specific dataset <ref type="bibr" target="#b11">Dhingra et al., 2020)</ref>, or focus on a non-retrieval setting where a compact documents set is already given <ref type="bibr" target="#b9">(De Cao et al., 2018;</ref><ref type="bibr" target="#b39">Tu et al., 2019;</ref><ref type="bibr" target="#b1">Beltagy et al., 2020)</ref>. Compared to these research, our work aims at building an efficient multi-hop retrieval model that easily scales to large real-world corpora that include millions of open-domain documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this work, we generalized the recently proposed successful dense retrieval methods by extending them to the multi-hop setting. This allowed us to handle complex multi-hop queries with much better accuracy and efficiency than the previous best methods. We demonstrated the versatility of our approach by applying it to two different tasks, using a variety of downstream modules. In addition, the simplicity of the framework and the fact that it does not depend on a corpus-dependent graph structure opens the possibility of applying such multi-hop retrieval methods more easily and broadly cross different domains and settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A QUALITATIVE ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 FALSE BRIDGE QUESTION ERROR CASES</head><p>As mentioned in ?3.1.3, half of the errors of bridge questions are not real errors. In <ref type="table" target="#tab_8">Table 8</ref>, we can see that the model predicts alternative passage sequences that could also be used to answer the questions.   <ref type="table" target="#tab_6">Table 6</ref> demonstrates the answer prediction performance for four different reader models. The extractive models predict answers given the top 250 retrieved passage sequences (pairs of passage from hop1 and hop2).</p><p>Since generative models are generally heavier on the computation side, we can only use fewer passages. Besides the observations alredy discussed in ?3.2.1, we hypothesize the worse performance of multi-hop RAG compared to FiD is partially due to the smaller pretrained model used in RAG, i.e., BART is only half the size of T5-large. Also, as RAG back-propagate the gradients to the query encoder, it needs more memory footprint and can only take in fewer retrieved contexts. Our RAG implementation largely follows the implementation of the original paper and we did not use the PyTorch checkpoint (as used by FiD) to trade computation for memory. We conjecture the multi-hop RAG performance will also improve if we augment the current implementation with memory-saving tricks. However, given the same amount of context and read model size, the multi-hop RAG is still worse than the extractive ELECTRA reader, i.e., with only the top 1 retrieved passage sequence, our ELECTRA reader gets 53.8 EM compared to the 51.2 answer EM achieved by multi-hop RAG when using more context.</p><p>Given the same number of retrieved passage sequences (top 50) as shown in   The extractive reader is trained with four loss functions. With the [CLS] token, we predict a reranking score based on whether the passage sequence match the groundtruth supporting passages. On top of the representation of each token, we predict a answer start score and answer end score. Finally, we prepend each sentence with the [unused0] special token and predict whether the sentence is one of the supporting sentences using the representations of the special token. At training time, we pair each question with 1 groundtruth passage sequence and 5 negative passage sequence which do not contain the answer. At inference time, we feed in the top 250 passage sequences from MDR. We rank the predicted answer for each sequence with a linear combination of the reranking score and the answer span score. The combination weight is selected based on the dev results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2.2 FUSION-IN-DECODER</head><p>The FiD model uses T5-large as the underlying seq2seq model. It is twice as large as the extractive models and has 770M parameters. We reuse the hyperparameters as described in <ref type="bibr" target="#b16">Izacard &amp; Grave (2020)</ref>. The original FiD uses the top 100 passages for NaturalQuestions. In our case, we use the top 50 retrieved passage sequences and concatenate the passages in each sequence before feeding into T5. In order to fit this model into GPU, we make use of PyTorch checkpoint 11 for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2.3 MULTI-HOP RAG</head><p>The RAG model aims to generate answer y given question x and the retrieved documents z. Similarly, the goal of multi-hop RAG can be expressed as: generate answer y given question x and retrieved documents in hop one z 1 and hop two z 2 (Limiting to two hops for HotpotQA). The model has three components:</p><p>? Hop-one retriever p ?1 (z 1 |x) with parameter ? 1 to represent the retrieved top-k passage distribution (top-k truncated distribution) given the input question x.</p><p>? Hop-two retriever p ?2 (z 2 |x, z 1 ) with parameter ? 2 to represent the hop-two retrieved top-k passage distribution given not only the question x but also the retrieved document z 1 from hop-one.</p><p>? A generator p ? (y i |x, z 1 , z 2 , , y 1:i?1 ) to represent the next token distribution given input question x, hop-one retrieved document z 1 , hop-two retrieved document z 2 and previous predicted token y 1:i?1 parametrized by ?</p><p>Multi-Hop RAG Sequence Model As the RAG Sequence model, this model generates the answer sequence given the fixed set of documents from hop-one retriever and hop-two retriever. In order to the get the probability of the generated sequence, we marginalize through the two latent variables corresponding to the two retrieval hops:</p><formula xml:id="formula_2">p sequence (y|x) = z1 p ?1 (z 1 |x) z2 p ?2 (z 2 |x, z 1 ) N i p ? (y i |x, z 1 , z 2 , y 1:i?1 ) z1 z2 p ?1 (z 1 |x)p ?2 (z 2 |x, z 1 ) N i p ? (y i |x, z 1 , z 2 , y 1:i?1 )</formula><p>where z 1 and z 2 are top k document from the respective retrieval modules.</p><p>Multi-Hop RAG Token Model Moreover, the model can make predictions based on different passage extracted at each token.</p><formula xml:id="formula_3">p token (y|x) = N i z1 z2 p ?1 (z 1 |x)p ?2 (z 2 |x, z 1 )p ? (y i |x, z 1 , z 2 , y 1:i?1 )</formula><p>The predicted probability for each token is the following p token (y i |(x, y j )) = z1 z2 p ?1 (z 1 |x)p ?2 (z 2 |x, z 1 )p ? (y i |x, z 1 , z 2 , y 1:i?1 )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C RETRIEVAL-FREE APPROACHES</head><p>Inspired by a recent work <ref type="bibr" target="#b33">(Roberts et al., 2020)</ref> that trains the T5 seq2seq model to directly decode answers from questions (retrieval-free), we conduct similar experiments on HotpotQA using BART <ref type="bibr" target="#b21">(Lewis et al., 2020a)</ref>. As shown in <ref type="figure" target="#fig_2">Figure 4</ref>, the performance gap between retrieval-based methods and retrieval-free methods on multi-hop QA is much larger than the gap in the case of simple single-hop questions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NQ</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D A UNIFIED QA RETRIEVAL SYSTEM</head><p>In practice, when a fixed text corpus is given for open-domain systems, we do not know beforehand whether the incoming questions require single or multiple text evidence. Thus, it is essential to build a unified system that adaptively retrieves for multiple hops. Due to the simplicity of the approach, our method can easily be extended in the unified setup. To the best of our knowledge, only <ref type="bibr" target="#b0">(Asai et al., 2020)</ref> test the same retrieval method on both single and multi-hop questions but with separate trained models. Here we take a further step and explore the possibility of using a single retrieval model for both types of questions.</p><p>To enable adaptive retrieval, we add a binary prediction head on top of the question encoder. Once the retriever finishes the 1-hop retrieval, it encodes concatenation of q and p 1 and predicts whether to stop retrieval using the final hidden state of the first token. We construct this unified setting with NaturalQuestions-Open (Lee et al., 2019) (NQ) as single-hop and HotpotQA as multi-hop. As the two datasets use different corpora, we merge the two 12 for easy comparison. As baselines, we use the retrieval models trained only on the respective dataset. For HotpotQA, the baseline is the best multi-hop retrieval model discussed in the main text. For NQ, we follow the training method in DPR <ref type="bibr" target="#b18">(Karpukhin et al., 2020)</ref>, but with a shared question and passage encoder, which achieves stronger results. As the NQ corpus includes multiple passages of the same document and the HotpotQA corpus only uses the introduction passage, we are not able to compute the strict title-based support passage recall for HotpotQA as in ?3.2. Thus, we only evaluate answer recall. Results are in <ref type="table" target="#tab_0">Table 13</ref>. In contrast to existing studies that train different models for each dataset, we show that a unified dense retrieval model can maintain competitive performance on both, despite the vastly different nature of both datasets. Note that the information-seeking questions in NQ is usually noisier and more ambiguous, while HotpotQA questions are more complicated and contains more lexical overlaps with the evidence passages. Specifically, for NQ, the unified retrieval model achieves very similar performance as the single-dataset DPR model, while the performance on HotpotQA decreases more. We conjecture that this is because the information-seeking questions in NQ cover more diverse patterns, and the added HotpotQA training questions do not cause a dramatic distribution shift from the NQ test data. We leave the development of a more general retrieval system that handles different styles of questions to future work. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>The retrieval performance gap between comparison and bridge questions. Left: recall of groundtruth passage sequences without reranking. Right: Top-1 chain exact match after reranking.Retrieval Error AnalysisHotpotQA contains two question categories: bridge questions in which an intermediate entity is missing and needs to be retrieved before inferring the answer; and comparison questions where two entities are mentioned simultaneously and compared in some way. InFigure 2, we show the retrieval performance of both question types. The case of comparison questions proves easier, since both entities needed for retrieval are present in the question.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Efficiency-performance trade-off comparison with published HotpotQA systems. The curve is plotted with different number of top k (k=1,5,10,20,50,100,200) passage sequences we feed into the reader model. seq/Q denotes the time required for each query.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Performance gap between retrieval-free and retrieval-based methods on different QA datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Retrieval performance in recall at k retrieved passages and precision/recall/F 1 .</figDesc><table><row><cell>Method</cell><cell cols="5">HotpotQA R@2 R@10 R@20 Precision Recall FEVER</cell><cell>F1</cell></row><row><cell>TF-IDF</cell><cell>10.3</cell><cell>29.1</cell><cell>36.8</cell><cell>14.9</cell><cell>28.2</cell><cell>19.5</cell></row><row><cell>TF-IDF + Linked</cell><cell>17.3</cell><cell>50.0</cell><cell>62.7</cell><cell>18.6</cell><cell>35.8</cell><cell>24.5</cell></row><row><cell>DrKIT</cell><cell>38.3</cell><cell>67.2</cell><cell>71.0</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Entity Linking</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>30.6</cell><cell>53.8</cell><cell>39.0</cell></row><row><cell>MDR</cell><cell>65.9</cell><cell>77.5</cell><cell>80.2</cell><cell>45.7</cell><cell>69.1</cell><cell>55.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table /><note>shows the reranking results. Following Asai et al. (2020), we use Answer Recall and Support Passage Exact Match (SP EM) 5 as the evaluation metrics. Even without reranking, MDR is already better than Semantic Retrieval, which requires around 50 BERT encoding (where each</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>HotpotQA reranked retrieval results (input passages for final answer prediction).</figDesc><table><row><cell>Method</cell><cell cols="2">SP EM Ans Recall</cell></row><row><cell>Semantic Retrieval</cell><cell>63.9</cell><cell>77.9</cell></row><row><cell>Graph Rec Retriever</cell><cell>75.7</cell><cell>87.5</cell></row><row><cell>MDR (direct)</cell><cell>65.9</cell><cell>75.4</cell></row><row><cell>MDR (reranking)</cell><cell>81.2</cell><cell>88.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Retriever Model Ablation on HotpotQA retrieval. Single-hop here is equivalent to the DPR method<ref type="bibr" target="#b18">(Karpukhin et al., 2020)</ref>.</figDesc><table><row><cell>Retriever variants</cell><cell cols="3">R@2 R@10 R@20</cell></row><row><cell>Full Retrieval Model</cell><cell>65.9</cell><cell>77.5</cell><cell>80.2</cell></row><row><cell>-w/o linked negatives</cell><cell>64.6</cell><cell>76.8</cell><cell>79.6</cell></row><row><cell>-w/o memory bank</cell><cell>63.7</cell><cell>74.2</cell><cell>77.2</cell></row><row><cell>-w/o shared encoder</cell><cell>59.9</cell><cell>70.6</cell><cell>73.1</cell></row><row><cell>-w/o order</cell><cell>17.6</cell><cell>55.6</cell><cell>62.3</cell></row><row><cell>Single-hop</cell><cell>25.2</cell><cell>45.4</cell><cell>52.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="4">: Comparison with decomposed dense retrieval</cell></row><row><cell cols="4">which uses oracle question decomposition (test on</cell></row><row><cell cols="4">100 bridge questions). See text for details about the</cell></row><row><cell>decomposed settings.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="3">R@2 R@10 R@20</cell></row><row><cell>MDR</cell><cell>54.9</cell><cell>63.7</cell><cell>70.6</cell></row><row><cell>Decomp (SubQ1;SubQ2)</cell><cell>50.0</cell><cell>64.7</cell><cell>67.6</cell></row><row><cell>Decomp (Q;SubQ2)</cell><cell>51.0</cell><cell>64.7</cell><cell>68.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>HotpotQA-fullwiki test results.</figDesc><table><row><cell>Methods</cell><cell>Answer EM F1</cell><cell>Support EM F1</cell><cell>Joint EM</cell><cell>F1</cell></row><row><cell>GoldEn Retriever (Qi et al., 2019)</cell><cell cols="4">37.9 48.6 30.7 64,2 18.9 39.1</cell></row><row><cell>Semantic Retrieval (Nie et al., 2019)</cell><cell cols="4">46.5 58.8 39.9 71.5 26.6 49.2</cell></row><row><cell>Transformer-XH (Zhao et al., 2020)</cell><cell cols="4">51.6 64.1 40.9 71.4 26.1 51.3</cell></row><row><cell>HGN (Fang et al., 2019)</cell><cell cols="4">56.7 69.2 50.0 76.4 35.6 59.9</cell></row><row><cell>DrKIT (Dhingra et al., 2020)</cell><cell cols="4">42.1 51.7 37.1 59.8 24.7 42.9</cell></row><row><cell cols="5">Graph Recurrent Retriever (Asai et al., 2020) 60.0 73.0 49.1 76.4 35.4 61.2</cell></row><row><cell>MDR (ELECTRA Reader)</cell><cell cols="4">62.3 75.3 57.5 80.9 41.8 66.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Reader comparison on HotpotQA dev set.</figDesc><table><row><cell></cell><cell>Model</cell><cell>Top k</cell><cell>EM</cell><cell>F1</cell></row><row><cell></cell><cell>ELECTRA</cell><cell>Top 50</cell><cell cols="2">61.7 74.3</cell></row><row><cell>Extractive</cell><cell>ELECTRA</cell><cell cols="3">Top 250 63.4 76.2</cell></row><row><cell></cell><cell>BERT-wwm</cell><cell cols="3">Top 250 61.5 74.7</cell></row><row><cell>Generative</cell><cell cols="4">Multi-hop RAG Top 4*4 51.2 63.9 FiD Top 50 61.7 73.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Multi-Evidence FEVER Fact Verification Results. Loose-Multi represents the subset that requires multiple evidence sentences. Strict-Multi is a subset of Loose-Multi that require multiple evidence sentences from different documents.</figDesc><table><row><cell>Method</cell><cell cols="4">Loose-Multi (1,960) Strict-Multi (1,059) LA FEVER LA FEVER</cell></row><row><cell>GEAR</cell><cell>66.4</cell><cell>38.0</cell><cell>-</cell><cell>-</cell></row><row><cell>GAT</cell><cell>66.1</cell><cell>38.2</cell><cell>-</cell><cell>-</cell></row><row><cell>KGAT with ESIM rerank</cell><cell>65.9</cell><cell>39.2</cell><cell>51.5</cell><cell>7.7</cell></row><row><cell>KGAT with BERT rerank</cell><cell>65.9</cell><cell>40.1</cell><cell>51.0</cell><cell>6.2</cell></row><row><cell cols="2">Ours + KGAT with BERT rerank 77.9</cell><cell>42.0</cell><cell>72.1</cell><cell>16.2</cell></row><row><cell cols="5">complete reasoning chain nontrivial to memorize. More analysis on RAG can be found in Appendix</cell></row><row><cell>A.3.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Error cases where our model predicts a passage sequence that is also correct. Important clues are marked in blue.</figDesc><table><row><cell>Q: What languages did the son of Sacagawea speak?</cell></row><row><cell>Ground-truth SP Passage Titles: Charbonneau, Oregon; Jean Baptiste Charbonneau</cell></row><row><cell>Predicted:</cell></row><row><cell>1. Museum of Human Beings: Museum of Human Beings, included in the National American</cell></row><row><cell>Indian Heritage Month Booklist, November 2012 and 2013 is a novel written by Colin Sargent,</cell></row><row><cell>which delves into the heart-rending life of Jean-Baptiste Charbonneau, the son of Sacagawea.</cell></row><row><cell>Sacagawea was the Native American guide, who at 16 led the Lewis and Clark expedition.</cell></row><row><cell>2. Jean Baptiste Charbonneau: Jean Baptiste Charbonneau (February 11, 1805 -May 16, 1866)</cell></row><row><cell>was an American Indian explorer, guide, fur trapper trader, military scout during the Mexican-</cell></row><row><cell>American War, "alcalde" (mayor) of Mission San Luis Rey de Francia and a gold prospector</cell></row><row><cell>and hotel operator in Northern California. He spoke French and English, and learned German</cell></row><row><cell>and Spanish during his six years in Europe from 1823 to 1829. He spoke Shoshone, his mother</cell></row><row><cell>tongue, and other western American Indian languages...</cell></row><row><cell>Q: Altnahinch is located in a county that has a population density of how many per square mile?</cell></row><row><cell>Ground-truth SP Passage Titles: Altnahinch Dam; County Antrim</cell></row><row><cell>Predicted:</cell></row><row><cell>1. Altnahinch: Altnahinch is a townland in County Antrim, Northern Ireland.</cell></row><row><cell>2. County Antrim: County Antrim (named after the town of Antrim, from Irish: "Aontroim"</cell></row><row><cell>, meaning "lone ridge" , )) is one of six counties that form Northern Ireland. Adjoined to the</cell></row><row><cell>north-east shore of Lough Neagh, the county covers an area of 3046 km2 and has a population</cell></row><row><cell>of about 618,000. County Antrim has a population density of 203 people per square kilometer /</cell></row><row><cell>526 people per square mile...</cell></row><row><cell>Q: What foundation do scholars give for the likelihood of collaboration on a William Shakespeare</cell></row><row><cell>Play written between 1588 and 1593?</cell></row><row><cell>Ground-truth SP Passage Titles:</cell></row><row><cell>Authorship of Titus Andronicus, William Shakespeare's collaborations</cell></row><row><cell>Predicted:</cell></row><row><cell>1. Titus Andronicus: Titus Andronicus is a tragedy by William Shakespeare, believed to have</cell></row><row><cell>been written between 1588 and 1593, probably in collaboration with George Peele. It is thought</cell></row><row><cell>to be Shakespeare's first tragedy, and is often seen as his attempt to emulate the violent and</cell></row><row><cell>bloody revenge plays of his contemporaries, which were extremely popular with audiences</cell></row><row><cell>throughout the 16th century.</cell></row><row><cell>2. William Shakespeare's collaborations: Like most playwrights of his period, William Shake-</cell></row><row><cell>speare did not always write alone... Some of the following attributions, such as "The Two Noble</cell></row><row><cell>Kinsmen", have well-attested contemporary documentation; others, such as "Titus Andronicus",</cell></row><row><cell>are dependent on linguistic analysis by modern scholars...</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10 :</head><label>10</label><figDesc>Answer EM using top 50 retrieved passage chains</figDesc><table><row><cell>Model</cell><cell>Overall</cell><cell>Comp (20%)</cell><cell>Bridge (80%)</cell></row><row><cell>ELECTRA</cell><cell>61.7</cell><cell>79.0</cell><cell>57.4</cell></row><row><cell>FiD</cell><cell>61.7</cell><cell>75.3</cell><cell>58.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>table 10 ,</head><label>10</label><figDesc>FiD obtains similar performance to ELECTRA, despite that the generative model can generate arbitrary answers for the given input. (We tried constrained decoding for the generative model. However, no significant performance improvements were observed, indicating that the errors from the generative model are not due to the free-form generation task.) Further question type analysis in HotpotQA showed that the main difference comes from the comparison type of question, while for bridge question, FiD performs slightly better than ELECTRA. This finding might indicate that for generation models, numerical comparison is still a bigger issue compared to extractive models.</figDesc><table><row><cell>B MODEL DETAILS</cell></row><row><cell>B.1 BEST MODEL HYPERPARAMETERS</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11</head><label>11</label><figDesc></figDesc><table><row><cell cols="2">: Hyperparameters of Retriever</cell></row><row><cell>learning rate</cell><cell>2e-5</cell></row><row><cell>batch size</cell><cell>150</cell></row><row><cell>maximum passage length</cell><cell>300</cell></row><row><cell>maximum query length at initial hop</cell><cell>70</cell></row><row><cell>maximum query length at 2nd hop</cell><cell>350</cell></row><row><cell>warmup ratio</cell><cell>0.1</cell></row><row><cell>gradient clipping norm</cell><cell>2.0</cell></row><row><cell>traininig epoch</cell><cell>50</cell></row><row><cell>weight decay</cell><cell>0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12</head><label>12</label><figDesc></figDesc><table><row><cell cols="2">: Hyperparameters of Extractive Reader (ELECTRA)</cell></row><row><cell>learning rate</cell><cell>5e-5</cell></row><row><cell>batch size</cell><cell>128</cell></row><row><cell>maximum sequence length</cell><cell>512</cell></row><row><cell>maximum answer length</cell><cell>30</cell></row><row><cell>warmup ratio</cell><cell>0.1</cell></row><row><cell>gradient clipping norm</cell><cell>2.0</cell></row><row><cell>traininig epoch</cell><cell>7</cell></row><row><cell>weight decay</cell><cell>0</cell></row><row><cell># of negative context per question</cell><cell>5</cell></row><row><cell cols="2">weight of SP sentence prediction loss 0.025</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 13 :</head><label>13</label><figDesc>Comparing the unified retrieval model with models specifically trained for each task. We test the retrieval performance with a single merged corpus. For easy comparison, all three models are based on BERT-base encoder which we find achieves stronger performance than RoBERTa-base on NQ. AR@K denotes answer recall at top-K retrieved passage sequences.</figDesc><table><row><cell>Model</cell><cell cols="4">NQ AR@20 AR@100 AR@20 AR@100 HotpotQA</cell></row><row><cell>single-hop only</cell><cell>80.7</cell><cell>87.3</cell><cell>-</cell><cell>-</cell></row><row><cell>multi-hop only</cell><cell>-</cell><cell>-</cell><cell>83.4</cell><cell>89.4</cell></row><row><cell>unified</cell><cell>79.5</cell><cell>86.1</cell><cell>78.1</cell><cell>83.0</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">To account for yes/no questions, we prepend yes and no tokens to the context.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">FEVER scores takes into account both support sentence accuracy and label accuracy, similar as the joint metrics in HotpotQA.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">https://pytorch.org/docs/stable/checkpoint.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">The Wikipedia corpus of NQ is taken from DPR<ref type="bibr" target="#b18">(Karpukhin et al., 2020)</ref>.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 EXAMPLES FROM THE QUESTION DECOMPOSITION ANALYSIS</head> <ref type="table">Table 9</ref><p>: Sampled retrieval errors (marked in red) only made by the decomposed system. These errors could be potentially avoided if the model has access to the full information in the original question or previous hop results. The important clue for correctly retrieving the documents or avoiding errors is marked in blue. Once decomposed, the marked information are not longer available in one of the decomposed retrieval hop.</p><p>Multi-hop Question: What is the birthday of the author of "She Walks These Hills"? </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to retrieve reasoning paths over wikipedia graph for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Longformer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<title level="m">The long-document transformer</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
		<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Selecting good expansion terms for pseudo-relevance feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guihong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 31st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="243" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to answer open-domain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ELECTRA: pre-training text encoders as discriminators rather than generators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Estimation and use of uncertainty in pseudo-relevance feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevyn</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 30th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="303" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Using probabilistic models of document retrieval without relevance information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David J</forename><surname>Harper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of documentation</title>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Multi-step retrieverreader interaction for scalable open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shehzaad</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05733</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Question answering by reasoning across documents with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilker</forename><surname>Aziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.09920</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Differentiable reasoning over a virtual knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidhisha</forename><surname>Balachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Hierarchical graph network for multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03631</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-hop paragraph retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>El-Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2296" to="2309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08909</idno>
		<title level="m">Realm: Retrievalaugmented language model pre-training</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Ukp-athene: Multi-sentence textual entailment for claim verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Hanselowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zile</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniil</forename><surname>Sorokin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Schiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.01479</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Leveraging passage retrieval with generative models for open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.01282</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Billion-scale similarity search with gpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08734</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="466" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6086" to="6096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandara</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>K?ttler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.11401</idno>
		<title level="m">Tim Rockt?schel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roberta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fine-grained fact verification with kernel graph attention network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7342" to="7351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Positional relevance model for pseudo-relevance feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhua</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 33rd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="579" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dmitry A Yashunin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-hop reading comprehension through question decomposition and rescoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6097" to="6109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Revealing the importance of semantic retrieval for machine reading at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2553" to="2566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised question decomposition for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP. Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Answering complex open-domain questions through iterative query generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Mehr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2590" to="2602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10683</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Know what you don&apos;t know: Unanswerable questions for squad</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="784" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">How much knowledge can you pack into the parameters of a language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08910</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Relevance feedback in information retrieval. The Smart retrieval system-experiments in automatic document processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Rocchio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971" />
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A survey on the use of relevance feedback for information access systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Ruthven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge engineering review</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="145" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tania</forename><surname>Bedrax-Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pullnet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09537</idno>
		<title level="m">Open domain question answering with iterative retrieval on knowledge bases and text</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The web as a knowledge-base for answering complex questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="641" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">FEVER: a largescale dataset for fact extraction and verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpit</forename><surname>Mittal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="809" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangtao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.07374</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<title level="m">Graph attention networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Query expansion using lexical-semantic relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;94</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">R 3 : Reinforced ranker-reader for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerry</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5981" to="5988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Constructing datasets for multi-hop reading comprehension across documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="287" to="302" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="page">1910</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Break it down: A question understanding benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Wolfson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mor</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Deutch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="183" to="198" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Zero-shot entity linking with dense entity retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Josifoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03814</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">End-to-end open-domain question answering with bertserini</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aileen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01718</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Variational reasoning for question answering with knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6069" to="6076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Transformer-xh: Multi-evidence reasoning with extra hop attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corby</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Coarse-grain fine-grain coattention network for multi-evidence question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.00603</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Jordan Parise</publisher>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Q: Zach Parise&apos;s father played in which league? Ground-truth SP Passage Titles. Zach Parise Predicted</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">) is an American professional ice hockey left winger who is currently serving as an alternate captain for the Minnesota Wild in the National Hockey League (NHL)</title>
		<editor>J. P. Paris?... 2. J. P. Paris?: Jean-Paul Joseph-Louis Paris?</editor>
		<imprint>
			<date type="published" when="1941-12-11" />
		</imprint>
	</monogr>
	<note>) was a Canadian professional ice hockey coach and player. Parise played in the National Hockey League (NHL). most notably for the Minnesota North Stars and the New York Islanders</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
