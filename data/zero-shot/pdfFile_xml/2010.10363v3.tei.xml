<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bootleg: Chasing the Tail with Self-Supervised Named Entity Disambiguation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurel</forename><surname>Orr</surname></persName>
							<affiliation key="aff0">
								<address>
									<country>Apple</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megan</forename><surname>Leszczynski</surname></persName>
							<affiliation key="aff0">
								<address>
									<country>Apple</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simran</forename><surname>Arora</surname></persName>
							<email>simran@cs.stanford.edu</email>
							<affiliation key="aff0">
								<address>
									<country>Apple</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wu</surname></persName>
							<email>senwu@cs.stanford.edu</email>
							<affiliation key="aff0">
								<address>
									<country>Apple</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neel</forename><surname>Guha</surname></persName>
							<email>nguha@cs.stanford.edu</email>
							<affiliation key="aff0">
								<address>
									<country>Apple</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
							<email>xiaoling@apple.com</email>
							<affiliation key="aff0">
								<address>
									<country>Apple</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
							<affiliation key="aff0">
								<address>
									<country>Apple</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanford</forename><surname>University</surname></persName>
							<affiliation key="aff0">
								<address>
									<country>Apple</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bootleg: Chasing the Tail with Self-Supervised Named Entity Disambiguation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A challenge for named entity disambiguation (NED), the task of mapping textual mentions to entities in a knowledge base, is how to disambiguate entities that appear rarely in the training data, termed tail entities. Humans use subtle reasoning patterns based on knowledge of entity facts, relations, and types to disambiguate unfamiliar entities. Inspired by these patterns, we introduce Bootleg, a self-supervised NED system that is explicitly grounded in reasoning patterns for disambiguation. We define core reasoning patterns for disambiguation, create a learning procedure to encourage the self-supervised model to learn the patterns, and show how to use weak supervision to enhance the signals in the training data. Encoding the reasoning patterns in a simple Transformer architecture, Bootleg meets or exceeds state-of-the-art on three NED benchmarks. We further show that the learned representations from Bootleg successfully transfer to other non-disambiguation tasks that require entity-based knowledge: we set a new state-ofthe-art in the popular TACRED relation extraction task by 1.0 F1 points and demonstrate up to 8% performance lift in highly optimized production search and assistant tasks at a major technology company.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge-aware deep learning models have recently led to significant progress in fields ranging from natural language understanding <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b40">41]</ref> to computer vision <ref type="bibr" target="#b55">[56]</ref>. Incorporating explicit knowledge allows for models to better recall factual information about specific entities <ref type="bibr" target="#b37">[38]</ref>. Despite these successes, a persistent challenge that recent works continue to identify is how to leverage knowledge for low-resource regimes, such as tail examples that appear rarely (if at all) in the training data <ref type="bibr" target="#b15">[16]</ref>.</p><p>In this work, we study knowledge incorporation in the context of named entity disambiguation (NED) to better disambiguate the long tail of entities that occur infrequently during training. <ref type="bibr" target="#b0">1</ref> Humans disambiguate by leveraging subtle reasoning over entity-based knowledge to map strings to entities in a knowledge base. For example, in the sentence "Where is Lincoln in Logan County?", resolving the mention "Lincoln" to "Lincoln, IL" requires reasoning about relations because "Lincoln, IL"-not "Lincoln, NE" or "Abraham Lincoln"-is the capital of Logan County. Previous NED systems disambiguate by memorizing co-occurrences between entities and textual context in a self-supervised manner <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b50">51]</ref>. The self-supervision is critical to building a model that is easy to maintain and does not require expensive hand-curated features. However, these approaches struggle to handle tail entities: a baseline SotA model from <ref type="bibr" target="#b15">[16]</ref> achieves less than 28 F1 points over the tail, compared to 86 F1 points over all entities.</p><p>Despite their rarity in training data, many real-world entities are tail entities: 89% of entities in the Wikidata knowledge base do not have Wikipedia pages to serve as a source of textual training data. However, to achieve 60 F1 points on disambiguation, we find that the prior SotA baseline model should see an entity shows F1 versus number of times an entity was seen in training data for a baseline NED model compared to Bootleg across the head, torso, tail, and unseen.</p><p>on-the-order-of 100 times during training <ref type="figure" target="#fig_0">(Figure 1 (right)</ref>). This presents a scalability challenge as there are 15x more entities in Wikidata than in Wikipedia, the majority of which are tail entities. For the model to observe each of these tail entities 100x, the training data would need to be scaled by 1,500x the size of Wikipedia. Prior approaches struggle with the tail, yet industry applications such as search and voice assistants are known to be tail-heavy <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b19">20]</ref>. Given the requirement for high quality tail disambiguation, major technology companies continue to press on this challenge <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b38">39]</ref>. Instead of scaling the training data until co-occurrences between tail entities and text can be memorized, we define a principled set of reasoning patterns for entity disambiguation across the head and tail. When humans disambiguate entities, they leverage signals from context as well as from entity relations and types. For example, resolving "Lincoln" in the text "How tall is Lincoln?" to "Abraham Lincoln" requires reasoning that people, not locations or car companies, have heights-a type affordance pattern. These core patterns apply to both head and tail examples with high coverage and involve reasoning over entity facts, relations, and types, information which is available for both head and tail in structured data sources. <ref type="bibr" target="#b1">2</ref> Thus, we hypothesize that these patterns assembled from the structured resources can be learned over training data and generalize to the tail.</p><p>In this work, we introduce Bootleg, an open-source, self-supervised NED system designed to succeed on head and tail entities. <ref type="bibr" target="#b2">3</ref> Bootleg encodes the entity, relation, and type signals as embedding inputs to a simple stacked Transformer architecture. The key challenges we face are understanding how to use knowledge for NED, designing a model that learns those patterns, and fully extracting the useful knowledge signals from the training data:</p><p>? Tail Reasoning: Humans use subtle reasoning patterns to disambiguate different entities, especially unfamiliar tail entities. The first challenge is characterizing these reasoning patterns and understanding their coverage over the tail.</p><p>? Poor Tail Generalization: We find that a model trained using standard regularization and a combination of entity, type and relation information performs 10 F1 points worse on disambiguating unseen entities compared to the two models which respectively use only type and only relation information. We find this performance drop is due to the model's over-reliance on discriminative textual and entity features compared to more general type and relation features.</p><p>? Underutilized Data: Self-supervised models improve with more training data <ref type="bibr" target="#b6">[7]</ref>. However, only a <ref type="bibr" target="#b1">2</ref> We find that type affordance patterns apply to over 84% of all examples, including tail examples, while KG relation patterns apply to over 27% of all examples and type consistency applies to over 8% of all examples. In Wikidata, 75% of entities that are not in Wikipedia have type or knowledge graph connectivity signals, and among tail entities, 88% are in non-tail type categories and 90% are in non-tail relation categories. <ref type="bibr" target="#b2">3</ref> Bootleg is open-source at http://hazyresearch.stanford.edu/bootleg limited portion of the standard NED training dataset, Wikipedia, is useful: Wikipedia lacks labels <ref type="bibr" target="#b18">[19]</ref> and we find that an estimated 68% of entities in the dataset are not labeled. <ref type="bibr" target="#b3">4</ref> Bootleg addresses these challenges through three contributions:</p><p>? Reasoning Patterns for Disambiguation: We contribute a principled set of core disambiguation patterns for NED <ref type="figure" target="#fig_0">(Figure 1 (left)</ref>)-entity memorization, type consistency, KG relation, and type affordance-and show that on slices of Wikipedia examples exemplifying each pattern, Bootleg provides a lift over the baseline SotA model on tail examples by 18 F1, 56 F1, 62 F1, and 45 F1 points respectively. Overall, using these patterns, Bootleg meets or exceeds state-of-the-art performance on three NED benchmarks and outperforms the prior SotA by more than 40 F1 points on the tail of Wikipedia.</p><p>? Generalizing Learning to the Tail: Our key insight is that there are distinct entity-, type-, and relation-tails. Over tail entities (based on entity count in the training data), 88% have non-tail types and 90% have non-tail relations. The model should balance these signals differently depending on the particular entity being disambiguated. We thus contribute a new 2D regularization scheme to combine the entity, tail, and relation signals and achieve a lift of 13.6 F1 points on unseen entities compared to the model using standard regularization techniques. We conduct extensive ablation studies to verify the effectiveness of our approach.</p><p>? Weak Labelling of Data: Our insight is that because Wikipedia is highly structured-most sentences on an entity's Wikipedia page refer to that entity via pronouns or alternative names-we can weakly label our training data to label mentions. Through weak labeling, we increase the number of labeled mentions in the training data by 1.7x, and find this provides a 2.6 F1 point lift on unseen entities.</p><p>With these three contributions, Bootleg achieves SotA on three NED benchmarks. We further show that embeddings from Bootleg are useful for downstream applications that require the knowledge of entities. We show the reasoning patterns learned in Bootleg transfer to tasks beyond NED by extracting Bootleg's learned embeddings and using them to set a new SotA by 1.0 F1 points on the TACRED relation extraction task <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b52">53]</ref>, where the prior SotA model also uses entity-based knowledge <ref type="bibr" target="#b37">[38]</ref>. Bootleg representations further provide an 8% performance lift on highly optimized industrial search and assistant tasks at a major technology company. For Bootleg's embeddings to be viable for production, it is critical that these models are space-efficient: the models using only Bootleg relation and type embeddings each achieve 3.3x the performance of the prior SotA baseline over unseen entities using 1% of the space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">NED Overview and Reasoning Patterns</head><p>We now define the task of named entity disambiguation (NED), the four core reasoning patterns, and the structural resources required for learning the patterns.</p><p>Task Definition Given a knowledge base of entities E and an input sentence, the goal of named entity disambiguation is to determine the entities e ? E referenced in each sentence. Specifically, the input is a sequence of N tokens W = {w 1 , . . . , w N } and a set of M non-overlapping spans in the sequence W, termed mentions, to be disambiguated M = {m 1 , . . . , m M }. The output is the most likely entity for each mention.</p><p>The Tail of NED We define the tail, torso, and head of NED as entities occurring less than 11 times, between 11 and 1,000, and more than 1,000 times in training, respectively. Following <ref type="figure" target="#fig_0">Figure 1</ref> (right), the head represents those entities a simple language-based baseline model can easily resolve, as shown by a baseline SotA model from <ref type="bibr" target="#b15">[16]</ref> achieving 86 F1 over all entities. These entities were seen enough times during training to memorize distinguishing contextual cues. The tail represents the entities these models struggle to resolve due to their rarity in training data, as shown by the same baseline model achieving less than 28 F1 on the tail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Four Reasoning Patterns</head><p>When humans disambiguate entities in text, they conceptually leverage signals over entities, relationships, and types. Our empirical analysis reveals a set of desirable reasoning patterns for NED. The patterns operate at different levels of granularity (see <ref type="figure" target="#fig_0">Figure 1</ref> (left))-from patterns which are highly specific to an entity, to patterns which apply to categories of entities-and are defined as follows.</p><p>? Entity Memorization: We define entity memorization as the factual knowledge associated with a specific entity. Disambiguating "Lincoln" in the text "Where is Lincoln, Nebraska?" requires memorizing that "Lincoln, Nebraska", not "Abraham Lincoln" frequently occurs with the text "Nebraska" <ref type="figure" target="#fig_0">(Figure 1  (left)</ref>). This pattern is easily learned by now-standard Transformer-based language models. As this pattern is at the entity-level, it is the least general pattern.</p><p>? Type Consistency: Type consistency is the pattern that certain textual signals in text indicate that the types of entities in a collection are likely similar. For example, when disambiguating "Lincoln" in the text "Is a Lincoln or Ford more expensive?", the keyword "or" indicates that the entities in the pair (or sequence) are likely of the same Wikidata type, "car company". Type consistency is a more general pattern than entity memorization, covering 12% of the tail examples in a sample of Wikipedia. 5</p><p>? KG Relations: We define the knowledge graph (KG) relation pattern as when two candidates have a known KG relationship and textual signals indicate that the relation is discussed in the sentence. For example, when disambiguating "Lincoln" in the sentence "Where is Lincoln in Logan County?", "Lincoln, IL" has the KG relationship "capital of" with Logan County while Lincoln, NE does not. The keyword "in" is associated with the relation "capital of" between two location entities, indicating that "Lincoln, IL" is correct, despite being the less popular candidate entity associated with "Lincoln". As patterns over pairs of entities with KG relations cover 23% of the tail examples, this is a more general reasoning pattern than consistency.</p><p>? Type Affordance: We define type affordance as the textual signals associated with a specific entitytype in natural language. For example, "Manhattan" is likely resolved to the cocktail rather than the burrough in the sentence "He ordered a Manhattan." due to the affordance that drinks, not locations, are "ordered". As affordance signals cover 76% of the tail examples, it is the most general reasoning pattern.</p><p>Required Structural Resources An NED system requires entity, relation, and type knowledge signals to learn these reasoning patterns. Entity knowledge is captured in unstructured text, while relation signals and type signals are readily available in structured knowledge bases such as Wikidata: from a sample of Wikipedia, 27% of all mentions and 23% of tail mentions participate in a relation, and 97% of all mentions and 92% of tail mentions are assigned some type in Wikidata. As these structural resources are readily available for all entities, they are useful for generalizing to the tail. A rare entity with a particular type or relation can leverage textual patterns learned from every other entity with that type or relation. Given the input signals and reasoning patterns, the next key challenge is ensuring that the model combines the discriminative entity and more general relation and type signals that are useful for disambiguation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Encoding the Signals</head><p>We first encode the structural signals-entities, KG relations and types-by mapping each to a set of embeddings.</p><p>? Entity Embedding: Each entity e is represented by a unique embedding u e .</p><p>? Type Embedding: Let T be the set of possible entity types. Given a known mapping from an entity e to its set {t e,1 , . . . , t e,T |t e,i ? T } of T possible types, Bootleg assigns an embedding t e,i to each type. Because an entity can have multiple types, we use an additive attention <ref type="bibr" target="#b2">[3]</ref>, AddAttn, to create a single type embedding t e = AddAttn([t e,1 , . . . , t e,T ]). We further allow the model to leverage coarse named entity recognition types through a mention-type prediction module (see Appendix A for details). This coarse predicted type is concatenated with the assigned type to form t e .</p><p>? Relation Embedding: Let R represent the set of possible relationships any entity can participate in. Similar to types, given a mapping from an entity e to its set {r e,1 , . . . , r e,R |r e,i ? R} of R relationships, Bootleg assigns an embedding r e,i to each relation. Because an entity can participate in multiple relations, we use the additive attention to compute r e = AddAttn([r e,1 , . . . , r e,R ]).</p><p>As in existing work <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b39">40]</ref>, given the input sentence of length N and set of M mentions, Bootleg generates for each mention m i a set ?(m i ) = {e 1 i , . . . , e K i } of K possible entity candidates that could be referred to by m i . For each candidate and its associated types and relations, Bootleg uses a multi-layer perceptron e = MLP([u e , t e , r e ]) to generate a vector representation for each candidate entity, for each mention. We denote this entity matrix as E ? R M ?K?H , where H is the hidden dimension. We use BERT to generate contextual embeddings for each token in the input sentence. We denote this sentence embedding as W ? R N ?H . W and E are passed to Bootleg's model architecture, described next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bootleg Model Architecture</head><p>The design goal of Bootleg is to capture the reasoning patterns by modeling textual signals associated with entities (for entity memorization), co-occurrences between entity types (for type consistency), textual signals associated with relations along with which entities are explicitly linked in the KG (for KG relations), and textual signals associated with types (for type affordance). We design three modules to capture these design goals: a phrase memorization module, a co-occurrence memorization module, and a knowledge graph connection module. The model architecture is shown in <ref type="figure">Figure 2</ref>. We describe each module next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phrase Memorization Module</head><p>We design the phrase memorization module, Phrase2Ent, to encode the dependencies between the input text and the entity, relation, and type embeddings. The purpose of this module is to learn textual cues for the entity memorization and type affordance patterns. It should also learn relation context for the KG relation pattern. It will, for example, allow the person type embedding to encode the association with the keyword "height". The module accepts as input E and W and outputs E p = MHA(E, W), where MHA is the standard multi-headed attention with a feed-forward layer and skip connections <ref type="bibr" target="#b47">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Co-occurrence Memorization Module</head><p>We design the co-occurrence memorization module, Ent2Ent, to encode the dependencies between entities. The purpose of the Ent2Ent module is to learn textual cues for the type consistency pattern. The module accepts E and computes E c = MHA(E) using self-attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge Graph (KG) Connection Module</head><p>We design the KG module, KG2Ent, to collectively resolve entities based on pairwise connectivity features. Let K represent the adjacency matrix of a (possibly weighted) graph where the nodes are entities and an edge between e i and e j signifies that the two entities share some pairwise feature. Given E, KG2Ent computes E k = softmax(K + wI)E + E where I is the identity and w is a learned scalar weight that allows Bootleg to learn to balance the original entity and its connections. This module allows for representation transfer between two related entities, meaning entities with a high-scoring representation will boost the score of related entities. The second computation acts as a skip connection between the input and output. In Bootleg, we allow the user to specify multiple KG2Ent modules: one for each adjacency matrix. The purpose of KG2Ent along with Phrase2Ent is to learn the KG relation pattern.</p><p>End-to-End The computations for one layer of Bootleg includes:</p><formula xml:id="formula_0">E =MHA(E, W) + MHA(E) E k =softmax(K + wI)E + E</formula><p>where E k is passed as the entity matrix to the next layer. After the final layer, Bootleg scores each entity by computing S dis = max(E k v T , E v T ) with S dis ? R M ?K and learned scoring vector v ? R H . Bootleg then outputs the highest scoring candidate for each mention. This scoring treats E k and E as two separate predictions in an ensemble method, allowing the model to use collective reasoning from E k when it achieves the highest scoring representation. If there are multiple KG2Ent modules, we use the average of their outputs as input to the next layer and, for scoring, take the maximum score across all outputs. For training, we use the cross-entropy loss of S to compute the disambiguation loss L dis .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Improving Tail Generalization</head><p>Regularization is the standard technique to encourage models to generalize, as models will naturally fit to discriminative features. However, we demonstrate that standard regularization is not effective when we want to leverage a combination of general and discriminative signals. We then present two techniques, regularization and weak labeling, to encourage Bootleg to incorporate general structural signals and learn general reasoning patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Regularization</head><p>We hypothesize that Bootleg will over-rely on the more discriminative entity features compared to the more general type and relation features to lower training loss. However, tail disambiguation requires Bootleg to leverage the general features. Using standard regularization techniques, we evaluate three models which respectively use only type embeddings, only relation embeddings, and a combination of type, relation, and entity embeddings. Bootleg's performance on unseen entities is 10 F1 points worse on the latter than each of the former two, suggesting that standard regularization is not sufficient when the signals operate at different granularities (details <ref type="table" target="#tab_12">Table 9</ref> in Appendix B).</p><p>We can improve tail performance if Bootleg leverages memorized discriminative features for popular entities and general features for rare entities. We achieve this by designing a new regularization scheme for the entity-specific embedding u, which has two key properties: it is 2-dimensional and more popular entities are regularized less than less popular ones.</p><p>? 2-dimensional : In contrast to 1-dimensional dropout, 2-dimensional regularization involves masking the full embedding. With probability p(e), we set u = 0 before the MLP layer; i.e., e = MLP([0, t e , r e ]).</p><p>Entirely masking the entity embedding in these cases, the model learns to disambiguate using the type and relation patterns, without entity knowledge.</p><p>? Inverse Popularity: We find in ablations (Appendix B) that setting p(e) proportional to the power of the inverse of the entity e's popularity in the training data (i.e., the more popular the less regularized), gives us the best performance and improves by 13.6 F1 on unseen entities over standard regularization. In contrast, fixing p(e) at 80% improves performance by over 11.3 F1 over standard regularization, and regularizing proportional to the power of popularity only improves performance by 3.8 F1 (details in Section 4).</p><p>The regularization scheme encourages Bootleg to use entity-specific knowledge when the entity is seen enough times to memorize entity patterns and encourages the use of generalizable patterns over the rare, highly masked, entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Weakly Supervised Data Labeling</head><p>We use Wikipedia to train Bootleg: we define a self-supervision task in which the internal links in Wikipedia are the gold entity labels for mentions during training. Although this dataset is large and widely used, it is often incomplete with an estimated 68% of named entities being unlabeled. Given the scale and the requirement that Bootleg be self-supervised, it is not feasible to hand-label the data. Our insight is that because Wikipedia is highly structured-most sentences on an entity's Wikipedia page refer to that entity via pronouns or alternative names-we can weakly label our training data <ref type="bibr" target="#b43">[44]</ref> to label mentions. We use two heuristics for weak labeling: the first labels pronouns that match the gender of a person's Wikipedia page as references to that person, and the second labels known alternative names for an entity if the alternative name appears in sentences on the entity's Wikipedia page. Through weak labeling, we increase the number of labeled mentions in the training data by 1.7x across Wikipedia, and find this provides a 2.6 F1 lift on unseen entities (full results in Appendix B <ref type="table" target="#tab_1">Table 11</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We demonstrate that Bootleg (1) nearly matches or exceeds state-of-the-art performance on three standard NED benchmarks and (2) outperforms a BERT-based NED baseline on the tail. As NED is critical for downstream tasks that require the knowledge of entities, we (3) verify Bootleg's learned reasoning patterns can transfer by using them for a downstream task: using Bootleg's learned representations, we achieve a new SotA on the TACRED relation extraction task and improve performance on a production task at a major technology company by 8%. Finally, we (4) demonstrate that Bootleg can be sample-efficient by using only a fraction of its learned entity embeddings without sacrificing performance. We (5) ablate Bootleg to understand the impact of the structural signals and the regularization scheme on improved tail performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>Wikipedia Data We define our knowledge base as the set of entities with mentions in Wikipedia (for a total of 5.3M entities). We allow each mention to have up to K = 30 possible candidates. As Bootleg is a sentence disambiguation system, we train on individual sentences from Wikipedia, where the anchor links and our weak labeling (Section 3.3) serve as mention labels. Our candidate lists ? are mined from Wikipedia anchor links and the "also known as" field in Wikidata. For each person, we further add their first and last name as aliases linking to that person. We use the mention boundaries provided in the Wikipedia data and generate candidates by performing a direct lookup in ?.</p><p>We use Wikidata and YAGO knowledge graphs and Wikipedia to extract structural data about entity types and relations as input for Bootleg. Further details about data are in Appendix B.</p><p>Metrics We report micro-average F1 scores for all metrics over true anchor links in Wikipedia (not weak labels). We measure the torso and tail sets based on the number of times that an entity is the gold entity across Wikipedia anchors and weak labels, as this represents the number of times an entity is seen by Bootleg. For benchmarks, we also report precision and recall using the number of mentions extracted by Bootleg and the number of mentions defined in the data as denominators, respectively. The numerator is the number of correctly disambiguated mentions. For Wikipedia data experiments, we filter mentions such that (a) the gold entity is in the candidate set and (b) they have more than one possible candidate. The former is to decouple candidate generation from model performance for ablations. <ref type="bibr" target="#b5">6</ref> The latter is to not inflate a model's performance, as all models are trivially correct when there is a single candidate.</p><p>Training For our main Bootleg model, we train for two epochs on Wikipedia sentences with a maximum sentence length of 100. For our benchmark model, we train for one epoch and additionally add a title embedding feature, a sentence co-occurrence KG matrix as another KG module, and a Wikipedia page co-occurrence statistical feature. Additional details about the models and training procedure are in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Bootleg Performance</head><p>Benchmark Performance To understand the overall performance of Bootleg, we compare against reported state-of-the-art numbers of two standard sentence benchmarks (KORE50, RSS500) and the standard document benchmark (AIDA CoNLL-YAGO). Benchmark details are in Appendix B.</p><p>For AIDA, we first convert each document into a set of sentences where a sentence is the document title, a BERT SEP token, and the sentence. We find this is sufficient to encode document context into Bootleg. We fine-tune the pretrained Bootleg model on the AIDA training set with learning rate of 0.00007, 2 epochs, batch size of 16, and evaluating every 25 steps. We choose the test score associated with the best validation score. <ref type="bibr" target="#b7">8</ref> In <ref type="table" target="#tab_1">Table 1</ref>, we show that Bootleg achieves up to 5.8 F1 points higher than prior reported numbers on benchmarks.</p><p>Tail Performance To validate that Bootleg improves tail disambiguation, we compare against a baseline model from F?vry et al. <ref type="bibr" target="#b15">[16]</ref>, which we refer to as NED-Base. <ref type="bibr" target="#b8">9</ref> NED-Base learns entity embeddings by maximizing the dot product between the entity candidates and fine-tuned BERT-contextual representations of the mention. NED-Base is successful overall on the validation achieving 85.9 F1 points, which is within 5.4 F1 points of Bootleg <ref type="table" target="#tab_2">(Table 2)</ref>. However, when we examine performance over the torso and tail, we see that Bootleg outperforms NED-Base by 8 and 41.2 F1 points, respectively. Finally, on unseen entities, Bootleg outperforms NED-Base by 50 F1 points. Note that NED-Base only has access to textual data, indicating that text is often sufficient for popular entities, but not for rare entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Downstream Evaluation</head><p>Relation Extraction Using the learned representations from Bootleg, we achieve the new state-of-the-art on TACRED, a standard relation extraction benchmark. TACRED involves identifying the relationship between a specified subject and object in an example sentence as one of 41 relation types (e.g., spouse) or no relation. Relation extraction is a well-suited for evaluating Bootleg because the substrings in the text can refer to many different entities, and the disambiguated entities impact the set of likely relations.</p><p>Given an example, we run inference with the Bootleg model to disambiguate named entities and generate the contextual Bootleg entity embedding matrix, which we feed to a simple Transformer architecture that uses SpanBERT <ref type="bibr" target="#b26">[27]</ref> (details in Appendix C). We achieve a micro-average test F1 score of 80.3, which improves upon the prior state of the art-KnowBERT <ref type="bibr" target="#b37">[38]</ref>, which also uses entity-based knowledge-by 1.0 F1 points and the baseline SpanBERT model by 2.3 F1 points on TACRED-Revisited data ( <ref type="table" target="#tab_3">Table 3</ref>) ([53], Alt et al. <ref type="bibr" target="#b1">[2]</ref>). We find that the Bootleg downstream model corrects errors made by the SpanBERT baseline, for example by leveraging entity, type, and relation information or recognizing that different textual aliases refer to the same entity (see <ref type="table" target="#tab_4">Table 4</ref>).</p><p>generators and fine-tuned a pretrained BERT encoder rather than training a BERT encoder from scratch, as is done in F?vry et al. <ref type="bibr" target="#b15">[16]</ref>. We trained NED-Base on the same weak labelled data as Bootleg for 2 epochs.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gold relation: Cause of Death</head><p>Disambiguates "Marshall" to Thomas Riley Marshall and "heart attack" to myocardial infarction, which have the Wikidata relation "cause of death"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cause of Death</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No Relation</head><p>The International Water Management (obj) Institute or IWMI (subj) study said both . . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gold relation: Alternate Names</head><p>Disambiguates alias "International Water Management Institute" and its acronym, the alias "IWMI", to the same Wikidata entity Alternate Names</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No Relation</head><p>In studying the slices for which the Bootleg downstream model improves upon the baseline SpanBERT model, we rank TACRED examples in three ways: by the proportion of words where Bootleg disambiguates it as an entity, leverages Wikidata relations for the embedding, and leverages Wikidata types for the embedding. For each of these three, we report the gap between the SpanBERT model and Bootleg model's error rates on the examples with above-median proportion (more Bootleg signal) relative to the below-median proportion (less Bootleg signal). We find that the relative gap between the baseline and Bootleg error rates is larger on the slice above (with more Bootleg information) than below the median by 1.10x, 4.67x, and 1.35x respectively: with more Bootleg information, the improvement our SotA model provides over SpanBERT increases (more details in Appendix C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Industry Use Case</head><p>We additionally demonstrate how the learned entity embeddings from Bootleg provide useful information to a system at a large technology company that answers factoid queries such as "How tall is the president of the United States?". We use Bootleg's embeddings in the Overton <ref type="bibr" target="#b44">[45]</ref> system and compare to the same system without Bootleg embeddings as the baseline. We measure the overall test quality (F1) on an in-house entity disambiguation task as well as the quality over the tail slices which include unseen entities. Per company policy, we report relative to the baseline rather than raw F1 score; for example, if the baseline F1 score is 80.0 and the subject F1 is 88.0, the relative quality is 88.0/80.0 = 1.1. <ref type="table" target="#tab_5">Table 5</ref> shows that the use of Bootleg's embeddings consistently results in a positive relative quality, even over Spanish, French, and German, where improvements are most visible over tail entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Memory Usage</head><p>We explore the memory usage of Bootleg during inference and demonstrate that by only using the entity embeddings for the top 5% of entities, ranked by popularity in the training data, Bootleg reduces its  <ref type="figure">Figure 3</ref>: We show the error across all entities, torso entities, tail entities, and unseen entities as we decrease the number embeddings we use during inference, assigning the non-popular entities to a fixed unseen entity embedding. For example, a compression ratio of 80 means only the top 20% of entity embeddings are used, ranked by entity popularity.</p><p>embedding memory consumption by 95%, while sacrificing only 0.8 F1 points over all entities. We find that the 5.3M entity embeddings used in Bootleg consume the most memory, taking 5.2 GB of space while the attention network only consumes 39 MB (1.37B updated model parameters in total, 1.36B from embeddings).</p><p>As Bootleg's representations must be used in a variety of downstream tasks, the representations must be memory-efficient: we thus study the effect of reducing Bootleg's memory footprint by only using the most popular entity embeddings. Specifically, for the top k% of entities ranked by the number of occurrences in training data, we keep the learned entity embedding intact. For the remaining entities, we choose a random entity embedding for an unseen entity to use instead. Instead of storing 5.3M entity embeddings, we thus store ((100 ? k)/100) * 5.3M , which gives a compression ratio of (100 ? k). <ref type="figure">Figure 3</ref> shows performance for k of 100, 50, 20, 10, 5, 1, and 0.1. We see that when just the top 5% of entity embeddings are used, we only sacrifice 0.8 F1 points overall and in fact score 2 F1 points higher over the tail. We hypothesize that the increase in tail performance is due to the fact that the majority of mention candidates all have the same learned embedding, decreasing the amount of conflict among candidates from textual patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablation Study</head><p>Bootleg To better understand the performance gains of Bootleg, we perform an ablation study over a subset of Wikipedia (data details explained in Appendix B). We train Bootleg with: (1) only learned entity embeddings (Ent-only), (2) only type information from type embeddings (Type-only), and (3) only knowledge graph information from relation embeddings and knowledge graph connections (KG-only). All model sizes are reported in Appendix B <ref type="table" target="#tab_1">Table 10</ref>. In <ref type="table" target="#tab_2">Table 2</ref>, we see that just using type or knowledge graph information leads to improvements on the tail of over 25 F1 points and on the unseen entities of over 46 F1 points compared to the Ent-only model. However, neither the Type-only nor KG-only model performs as well on any of the validation sets as the full Bootleg model. An interesting comparison is between Ent-only and NED-Base. NED-Base overall outperforms Ent-only due to the fine-tuning of BERT word embeddings. We attribute the high performance of Ent-only on the tail compared to NED-Base to our Ent2Ent module which allows for memorizing co-occurrence patterns over entities.</p><p>Regularization To understand the impact of our entity regularization function p(e) on overall performance, we perform an ablation study on a sample of Wikipedia (explained in Appendix B). We apply (1) a fixed regularization set to a constant percent of 0, 20, 50 and 80, (2) a regularization function proportional to the power of the inverse popularity, and (3) the inverse of (2). <ref type="table" target="#tab_6">Table 6</ref> shows results over unseen entities (full results and details in Appendix B). We see that the fixed regularization of 80% achieves the highest F1 over the fixed regularizations of (1). The method that regularizes by inverse popularity achieves the highest overall F1. We further see that the scheme where popular entities are more regularized sees a drop of 9.8 F1 points in performance compared to the inverse popularity scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head><p>We have shown that Bootleg excels on benchmark tasks and that Bootleg's learned patterns can transfer to non-NED tasks. We now verify whether the defined entity, type consistency, KG relation, and affordance reasoning patterns are responsible for these results. We evaluate each over a representative slice of the Wikipedia validation set that exemplifies one of the reasoning patterns and present the results from each ablated model ( Pattern Analysis For the slice representing each reasoning pattern, we find that Bootleg provides a lift over the Entity-only and NED-Base models, especially over the tail. We find that Bootleg generally combines the entity, relation, and type signals effectively, performing better than the individual Entity-only, KG-only, and Type-only models, although the KG-only model performs well on the KG relation slice. The lift from Bootleg across slices indicates the model's ability to capture the reasoning required for the slice. We provide additional details in Appendix D.</p><p>Error Analysis We next study the errors made by Bootleg and find four key error buckets.</p><p>? Granularity Bootleg struggles with granularity, predicting an entity that is too general or too specific compared to the gold entity (example in <ref type="table" target="#tab_9">Table 8</ref>). Considering the set of examples where the predicted entity is a Wikidata subclass of the gold entity or vice versa, Bootleg predicts a too general or specific entity in 12% of overall and 7% of tail errors.</p><p>? Numerical Bootleg struggles with entities containing numerical tokens, which may be due to the fact that the BERT model represents some numbers with sub-word tokens and is known to not perform as well for numbers as other language models <ref type="bibr" target="#b48">[49]</ref> (example in <ref type="table" target="#tab_9">Table 8</ref>).</p><p>To evaluate examples requiring reasoning over numbers, we consider the slice of data where the entity title contains a year, as this is the most common numerical feature in a title. This slice covers 14% of overall and 25% of tail errors.</p><p>? Multi-Hop There is room for improvement in multi-hop reasoning. In the example shown  <ref type="table" target="#tab_9">Table 8</ref>). We attribute this decrease in performance to Bootleg's regularization. This mention-to-entity similarity would need to be encoded in Bootleg's entity embedding, but the regularization encourages Bootleg to not use entity-level information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>We discuss related work in terms of both NED and the broader picture of self-supervised models and tail data. Standard, pre-deep-learning approaches to NED have been rule-based <ref type="bibr" target="#b0">[1]</ref> or leverage statistical techniques and manual feature engineering to filter and rank candidates <ref type="bibr" target="#b49">[50]</ref>. For example, link counts and similarity scores between entity titles and mention are two such features <ref type="bibr" target="#b11">[12]</ref>. These systems tend to be hard to maintain over time, with the work of Petasis et al. <ref type="bibr" target="#b36">[37]</ref> building a model to detect when a rule-based NED system needs to be retrained and updated. In recent years, deep learning systems have become the new standard (see <ref type="bibr">Mudgal et al. [32]</ref> for a high-level overview of deep learning approaches to entity disambiguation and entity matching problems). The most recent state-of-the-art models generally rely on deep contextual word embeddings with entity embeddings <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b50">51]</ref>. As we showed in <ref type="table" target="#tab_2">Table 2</ref>, these models perform well over popular entities, but struggle to resolve the tail. Jin et al. <ref type="bibr" target="#b25">[26]</ref> and Hoffart et al. <ref type="bibr" target="#b22">[23]</ref> study disambiguation at the tail, and both rely on phrase-based language models for feature extraction. Unlike our work, they do not fuse type or knowledge graph information for disambiguation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exact Match</head><p>According to the Nielsen Media Research, the episode was watched by 469 million viewers...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nielsen ratings Nielsen Media Research</head><p>Disambiguation with Types Similar to our work, recent approaches have found that type information can be useful for entity disambiguation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b54">55]</ref>. Dredze et al. <ref type="bibr" target="#b13">[14]</ref> use predicted coarse-grained types as entity features into a SVM classifier. Chen et al. <ref type="bibr" target="#b8">[9]</ref> models type information as local context and integrates a BERT contextual embedding into the model from <ref type="bibr" target="#b16">[17]</ref>. Raiman and Raiman <ref type="bibr" target="#b42">[43]</ref> learns its own type systems and performs disambiguation through type prediction alone (essentially capturing the type affordance pattern). Ling et al. <ref type="bibr" target="#b30">[31]</ref> demonstrate that the 112-type FIGER type ontology could improve entity disambiguation, and the LATTE framework <ref type="bibr" target="#b54">[55]</ref> uses multi-task learning to jointly perform type classification and entity disambiguation on biomedical data. Gupta et al. <ref type="bibr" target="#b20">[21]</ref> adds both an entity-level and mention-level type objective using type embeddings embeddings. We build on these works using fine and coarse-grained entity-level type embeddings and a mention-level type prediction task.</p><p>Disambiguation with Knowledge Graphs Several recent works have also incorporated (knowledge) graph information through graph embeddings <ref type="bibr" target="#b34">[35]</ref>, co-occurrences in the Wikipedia hyperlink graph <ref type="bibr" target="#b41">[42]</ref>, and the incorporation of latent relation variables <ref type="bibr" target="#b29">[30]</ref> to aid disambiguation. Cetoli et al. <ref type="bibr" target="#b7">[8]</ref> and Mulang et al. <ref type="bibr" target="#b32">[33]</ref> incorporate Wikidata triples as context into entity disambiguation by encoding triples as textual phrases (e.g., "&lt;subject&gt; &lt;predict&gt; &lt;object&gt;") to use as additional inputs, along with the original text to disambiguate, into a language model. In Bootleg, the Wikidata connections through the KG2Ent module allow for collective resolution and are not just additional features.  <ref type="bibr" target="#b53">[54]</ref> incorporate pretrained entity embeddings and finetune either on a the standard masked sequence-to-sequence prediction task or combined with an entity disambiguation/linking task. <ref type="bibr" target="#b9">10</ref> On the other hand, Broscheit <ref type="bibr" target="#b5">[6]</ref> trains its own entity embeddings. Most works, like Bootleg, see lift from incorporating entity representations in the downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity Knowledge in Downstream Tasks</head><p>Wikipedia Weak Labelling Although uncommon, Broscheit <ref type="bibr" target="#b5">[6]</ref>, De Cao et al. <ref type="bibr" target="#b12">[13]</ref>, Ghaddar and Langlais <ref type="bibr" target="#b18">[19]</ref>, Nothman et al. <ref type="bibr" target="#b33">[34]</ref> all apply some heuristic weak labelling techniques to increase link coverage in Wikipedia for either entity disambiguation or named entity recognition. All methods generally rely on finding known surface forms for entities and labelling those in the text. Bootleg is the first to investigate the lift from incorporating weakly labelled Wikipedia data over the tail.</p><p>Self-Supervision and the Tail The works of Tata et al. <ref type="bibr" target="#b46">[47]</ref>, Chung et al. <ref type="bibr" target="#b10">[11]</ref>, Ilievski et al. <ref type="bibr" target="#b24">[25]</ref>, and Chung et al. <ref type="bibr" target="#b9">[10]</ref> all focus on the importance of the tail during inference and the challenges of capturing it during training. They all highlight the data management challenges of monitoring the tail (and other missed slices of data) and improving generalizability. In particular, Ilievski et al. <ref type="bibr" target="#b24">[25]</ref> studies the tail in NED and encourages the use of separate head and tail subsets of data. From a broader perspective of natural language systems and generalizability, Ettinger et al. <ref type="bibr" target="#b14">[15]</ref> highlights that many NLP systems are brittle in the face of tail linguistic patterns. Bootleg builds off this work, investigating the tail with respect to NED and demonstrating the generalizable reasoning patterns over structural resources can aid tail disambiguation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We present Bootleg, a state-of-the-art NED system that is explicitly grounded in a principled set of reasoning patterns for disambiguation, defined over entities, types, and knowledge graph relations. The contributions of this work include the characterization and evaluation of core reasoning patterns for disambiguation, a new learning procedure to encourage the model to learn the patterns, and a weak supervision technique to increase utilization of the training data. We find that Bootleg improves over the baseline SotA model by over 40 F1 points on the tail of Wikipedia. Using Bootleg's entity embeddings for a downstream relation extraction task improves performance by 1.0 F1 points, and Bootleg's representations lead to an 8% lift on highly optimized production tasks at a major technology company. We hope this work inspires future research on improving tail performance by incorporating outside knowledge in deep models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Extended Model Details</head><p>We now provide additional details about the model introduced in Section 3. We first describe our type prediction module and then describe the added entity positional encoding.</p><p>Type Prediction To allow the model to further infer the correct types for an entity, especially when the entity does not have a preassigned type, we add a coarse mention type prediction task given the mention embedding. Given a mention m and a coarse type embedding matrix T, the task is to assign a coarse type embedding for the mention m; i.e., determine t m . We do so by adding the first and last token of the mention from W to generate a contextualized mention embedding m. We predict the coarse type of the mentiont m by computing</p><formula xml:id="formula_1">S type = softmax(MLP(m)) t m = S type T</formula><p>where S type generates a distribution over coarse types. For each entity candidate of m,t m gets concatenated to the other type embedding t e before the MLP. This is supervised by minimizing the cross entropy between S type and the true coarse type for the gold entity, generating a type prediction loss L type . When performing type prediction, our overall loss is L dis + L type .</p><p>Position Encoding We need Bootleg to be able to reason over absolute and relative positioning of the words in the sentence and the mentions. For example, in the sentence "Where is America in Indiana?", "America" refers to the city in Indiana, not the United States. In the sentence "Where is Indiana in America?", "America" refers to the United States. The relative position of "Indiana", "in", and "America" signals the correct answer. To achieve this signaling, we add the sin positional encoding from Vaswani et al. <ref type="bibr" target="#b47">[48]</ref> to E before it is passed to our neural model. Specifically, for mention m, we concatenate of the positional encoding of the first and last token of m, project the concatenation to dimension H, and add it to each of m's K candidates in E. As we use BERT word embeddings for W , the positional encoding is already added to words in the sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Extended Results</head><p>We now give the details of our experimental setup and training. We then give extended results over the regularization scheme and model ablations. Lastly, we extend our error analysis to validate Bootleg's ability to reason over the four patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Evaluation Data</head><p>Wikipedia Datasets We use two main datasets to evaluate Bootleg.</p><p>? Wikipedia: we use the November 2019 dump of Wikipedia to train Bootleg. We use the set of entities that are linked to in Wikipedia for a total of 3.3M entities. After weak labelling, we have a total of 5.7M sentences.</p><p>? Wikipedia Subset: we use a subset of Wikipedia for our micro ablation experiments over regularization parameters. We generate this subset by taking all sentences where at least one mention is a mention from the KORE50 disambiguation benchmark. Our set of entities is all entities and entity candidates referred to by mentions in this subset of sentences. We have a total of 370,000 entities and 520,000 sentences. For our Wikipedia experiments, we use a 80/10/10 train/test/dev split by Wikipedia pages, meaning all sentences for a single Wikipedia page get placed into one of the splits. For our benchmark model, we use a 96/2/2 train/test/dev split over sentences to allow our model to learn as much as possible from Wikipedia for our benchmark tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmark Datasets</head><p>We use three benchmark NED datasets. Following standard procedure <ref type="bibr" target="#b16">[17]</ref>, we only consider mentions whose linked entities appear in Wikipedia. The datasets are summarized as follows:</p><p>? KORE50: KORE50 <ref type="bibr" target="#b22">[23]</ref> represents difficult-to-disambiguate sentences and contains 144 mentions to disambiguate. Note, as of the Nov 2019 Wikipedia dump, one mention in the 144 does not have a Wikipedia page. Although it is standard to remove mentions that do not link to an entity in Wikipedia, to be comparable to other methods, we measure with 144 mentions, not 143.</p><p>? RSS500: RSS500 <ref type="bibr" target="#b17">[18]</ref> is a dataset of news sentences and contains 520 mentions (4 of the mentions did not have entities in E).</p><p>? AIDA CoNLL-YAGO: AIDA CoNLL-YAGO <ref type="bibr" target="#b21">[22]</ref> is a document-based news dataset containing 4, 485 test mentions, 4, 791 validation set mentions, and 18, 541 training mentions. As Bootleg is a sentence-level NED system, we create sentences from documents following the technique from F?vry et al. <ref type="bibr" target="#b15">[16]</ref> where we concatenate the title of the document to the beginning of each sentence. To improve the quality of annotated mention boundaries in the benchmarks, we follow the technique of Phan et al. <ref type="bibr" target="#b39">[40]</ref> and allow for mention boundary expansion using a standard off-the-shelf NER tagger. <ref type="bibr" target="#b10">11</ref> For candidate generation, as aliases may not exist in ?, we gather possible candidates by looking at n-grams in descending order of length and determine the top 30 by measuring the similarity of the proper nouns in the example sentence to each candidate's Wikipedia page text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structural Resources</head><p>The last source of input data to Bootleg is the structural resources of types and knowledge graph relations. We extract relations from Wikidata knowledge graph triples. For our pairwise KG adjacency matrix used in KG2Ent, we require the subject and object to be in E. For our relation embeddings, we only require the subject be in E as our goal is to extract all relations an entity participates in independent of the other entities in the sentence. We have a total of 1,197 relations.</p><p>We use two different type sources to assign types to entities-Wikidata types and HYENA types <ref type="bibr" target="#b51">[52]</ref>-and use coarse HYENA types for type prediction. The Wikidata types are generated from Wikidata's "instance of", "subclass of", and "occupation" relationships. The "occupation" types are used to improve disambiguation of people, which otherwise only receive "human" types in Wikidata. We filter the set of Wikidata types to be only those occurring 100 or more times in Wikipedia, leaving 27K Wikidata types in total. The HYENA type hierarchy has 505 types derived from the YAGO type hierarchy. We also use the coarsest HYENA type for an entity as the gold type for type prediction. There are 5 coarse HYENA types of person, location, organization, artifact, event, and miscellaneous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Training Details</head><p>Model Parameters We run three separate models of Bootleg: two on our full Wikipedia data (one for the ablation and one for the benchmarks) and one on our micro data. For all models we use 30 candidates for each mention and incorporate the structural resources discussed above. We set T = 3 and R = 50 for the number of types and relations assigned to each entity.</p><p>For the models trained on our full Wikipedia data, we set the hidden dimension to 512, the dimension of u to 256, and the dimension of all other type and relation embeddings to 128. For our models trained on our micro dataset, we set the hidden dimension to 256, the dimension of u to 256, and the dimension of all other type and relation embeddings to 128.</p><p>The final differences to discuss are between the benchmark model and ablation model over all of Wikipedia. To make the best performing model for benchmarks, we add two additional additional features we found improved performance:</p><p>? We use an additional KG2Ent module in addition to an adjacency matrix indicating if two entities are connected in Wikidata. We add a matrix containing the log of the number of times two entities occur in a sentence together in Wikipedia. If they co-occur less than 10 times, the weight is 0. We found this helped the model better learn entity co-occurrences from Wikipedia.</p><p>? We allow our model to use additional entity-based features to be concatenated into our final E matrix. We add two features. The first is the average BERT WordPiece embeddings of the title of an entity. This is similar to improving tail generalization by embedding a word definition in word sense disambiguation <ref type="bibr" target="#b4">[5]</ref>. This allows the model to better capture textual cues indicating the correct entity. We also append a 1-dimensional feature of how many other entities in the sentence appear on the entity's Wikipedia page. This increases the likelihood of an entity that has more connection to other candidates in the sentence. We empirically find that using the page co-occurrences as an entity feature rather than as a KG2Ent module performs similarly and reduces the runtime.</p><p>Further, our benchmark model uses a fixed regularization scheme of 80% which did not hurt benchmark performance and training was marginally faster than the inverse popularity scheme. We did not use these features for ablations as we wanted a clean study of the model components as described in Section 3 with respect to the reasoning patterns.</p><p>Training We initialize all entity embeddings to the same vector to reduce the impact of noise from unseen entities receiving different random embeddings. We use the Adam optimizer <ref type="bibr" target="#b27">[28]</ref> with a learning rate of 0.0001 and a dropout of 0.1 in all feedforward layers, 16 heads in our attention modules, and we freeze the BERT encoder stack. Note for the NED-Base model, we do not freeze the encoder stack to be consistent with F?vry et al. <ref type="bibr" target="#b15">[16]</ref>.</p><p>For the models trained on all of Wikipedia, we use a batch size of 512 and train for 1 epoch for the benchmark model and 2 epochs for the ablation models on 8 NVIDIA V100 GPUs. For our micro data model, we use a batch size of 96 and train for 8 epochs on a NVIDIA P100 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Extended Ablation Results</head><p>Ablation Model Size <ref type="table" target="#tab_1">Table 10</ref> reports the model sizes of each of the five ablation models from <ref type="table" target="#tab_2">Table 2</ref>. As we finetuned the BERT language model in NED-Base (to be consistent with F?vry et al. <ref type="bibr" target="#b15">[16]</ref>) but do not do so in Bootleg, we do not count the BERT parameters in our reported sizes to be comparable.</p><p>Regularization We now present the extended results of our regularization and weak labelling ablations over our representative micro dataset. <ref type="table" target="#tab_12">Table 9</ref> gives full ablations over a variety of regularization techniques. As in <ref type="table" target="#tab_2">Table 2</ref>, we include results from models using only the entity, type, or relation information, in addition to the BERT and Bootleg models.  We report the results of inverse popularity regularization based on three different functions that map the the curve of entity counts in training to the regularization value. For each function, we fix that entities with a frequency 1 receive a regularization value of 0.95 while entities with a frequency of 10,000 receive a value of 0.05 and assign intermediate values to generate a linear, logarithmic, and power curve that applies less regularization for more popular entities. The regularization reported in <ref type="table" target="#tab_6">Table 6</ref> uses a power law function (f (x) = 0.95(x ?0.32 )). We also report in <ref type="table" target="#tab_12">Table 9</ref> a linear function (f (x) = ?0.00009x + 0.9501) and a logarithmic function (f (x) = ?0.097 log(x) + 0.96). Each regularization function is set to a range of 0.05 to 0.95. We leave it as future work to explore other varied regularization functions. <ref type="table" target="#tab_12">Table 9</ref> shows similar trends as reported in Section 4 that Bootleg with all sources of information and the power law inverse regularization performs best over the tail and the unseen entities. We do see that the model trained with a fixed regularization of 0.5 performs marginally better on the torso and over all entities, likely because this involves less regularization over those entity embeddings, allowing it to better leverage the memorized entity patterns, while also leveraging some type and relational information (as shown by its improved performance over a lower fixed regularization). This model, however, performs 4.5 F1 points worse over unseen entities than the best model. <ref type="table" target="#tab_1">Table 11</ref> shows Bootleg's results with the inverse power law regularization with and without weak labelling. For this ablation, we define our set of torso, tail, and unseen entities by counting entity occurrence before weak labelling to have a better understanding as to the lift from adding weak labelling (rather than the drop without it).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weak Labeling</head><p>We see that weak labelling provides a lift of 2.6 F1 points over unseen entities and 0.3 F1 points over tail entities. Surprisingly, without weak labeling, Bootleg performs 0.5 F1 points better on torso entities. We hypothesize this occurs because the noisy weakly labels increase the amount available signals for Bootleg to learn consistency patterns for rarer entities-noisy signals are better than no signals-however, popular entities have enough less-noisy gold labels in the training data, so the noise from weak labels may create conflicting signals that hurt performance.</p><p>To validate this hypothesis, we see that overall, counting both true and weakly labelled mentions, 4% of mentions without weak labeling share the same types as at least one other mention in the sentence while 14% of mentions with weak labelling do. Our model predicts a consistent answer only 4% of the time without weak labeling compared to 13% of the time with weak labeling. Note this is a slightly higher coverage numbers than reported in Section 5 as we are using a weaker form of consistency-two mentions in the sentence share the same type independent of position and ordering-and are including weakly labelled mentions. This indicates consistency is a significantly more useful pattern with weak labelling, and our model predicts more consistent answers with weak labelling than without. Over the torso with weak labelling, we find that 14% of the errors across all mentions (weak labelled and anchor) are when Bootleg uses consistency reasoning, but the correct answer does not follow the consistency pattern. Without weak labelling, only 5% of the errors are due to consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Extended Downstream Details</head><p>We now provide additional details of our SotA TACRED model, which uses Bootleg embeddings.</p><p>Input We use the revisited TACRED dataset <ref type="bibr" target="#b1">[2]</ref>: each example includes text and subject and object positions in the text. The task involves extracting the relation between the subject and object. There are 41 potential relations as well as a "no relation" option. The other features we use as inputs are NER, POS tags, and contextual Bootleg embeddings for entities that Bootleg disambiguates in the sentence.</p><p>Bootleg Model As TACRED does not come with existing mention boundaries, we perform mention extraction by searching over n-grams, from longest to shortest, in the sentence and extract those that are known mentions in Bootleg's candidate maps. We use the same Bootleg model from our ablations with entity, KG, and type information except with the addition of fine-tuned BERT word embeddings. For efficiency, we train on a subset of Wikipedia training data relevant to TACRED. To obtain the relevant subset, we take Wikipedia sentences containing entities extracted during candidate generation from a uniform sample of TACRED data; i.e., entities in the candidate lists of detected mentions from a uniform TACRED sample. The contextualized entity embeddings from Bootleg over all TACRED are fed to the downstream model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Downstream Model</head><p>We first use standard SpanBERT-Large embeddings to encode the input text, concatenate the contextual Bootleg embeddings with the SpanBERT embeddings, and then pass this through four transformer layers. We then calculate the cross-entropy loss and apply a softmax for scoring. We freeze the Bootleg embeddings and fine-tune the SpanBERT embeddings. We use the following hyperparameters: the learning rate is 0.00002, batch size is 8, gradient accummulation is 6, number of epochs is 10, L2 regularization is 0.008, warm-up percentage is 0.1, and maximum sequence length is 128. We train with a NVIDIA Tesla V100 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extended Results</head><p>We study the model performance as a function of the signals provided by Bootleg.</p><p>In <ref type="table" target="#tab_1">Table 12</ref>, we show that on slices with above-median numbers of Bootleg entity, relation, and type signal counts identified in the TACRED example, the relative gap between BERT and Bootleg errors is larger on the slice above, than below, the median by 1.10x, 4.67x, and 1.35x respectively. In <ref type="table" target="#tab_1">Table 13</ref> we show the relative error rates from the Bootleg and baseline SpanBERT models for the slices where Bootleg provides an entity, relation, or type signal for the TACRED example's subject or object. On the slice of these signals are respectively present, the baseline model performs 1.20x, 1.18x, and 1.20x worse than the Bootleg TACRED model. These results indicate that the knowledge representations from Bootleg successfully transfer useful information to the downstream model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Extended Error Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Reasoning Patterns</head><p>Here we provide additional details about the distributions of types and relations in the data.</p><p>Distinct Tails Like entities, types and relations also have tail distributions. For example, types such as "country" and "film" appear 2.7M and 800k times respectively, while types such as "quasiregular polyhedron" and "hospital-acquired infection" appear once each in our Wikipedia training data. Meanwhile, relations such as "occupation" and "educated at" appear 35M and 16M times respectively, while relations such as <ref type="table" target="#tab_1">Table 12</ref>: We rank TACRED examples by the proportion of words that receive Bootleg embedding features where: Bootleg disambiguates an entity, leverages Wikidata relations for the embedding, and leverages Wikidata types for the embedding. We take examples where the proportion is greater than 0. For each of these three slices, we report the gap between the SpanBERT model and Bootleg model's error rates on the examples with above-median proportion (more Bootleg signal) relative to the below-median proportion (less Bootleg signal). With more Bootleg information, we see the improvement our SotA model provides over SpanBERT increases.  "positive diagnostic predictor" and "author of afterword" appear 7 times respectively in the Wikipedia training data. However we find that the entity-, relation-, and type-tails are distinct: 88% of the tail-entities by entity-count have Wikidata types that are non-tail types and 90% of the tail-entities by entity-count have non-tail relations. <ref type="bibr" target="#b11">12</ref> For example, the head Wikidata type "country" contains rare entities "Pala?" and "Belgium-France border". We observe that Bootleg significantly improves tail performance over each of the tails. We rank the Wikidata types and relations by the number of occurrences in the training data and study the lift from Bootleg as a function of the number of times the signal appears during training. Bootleg performs an 9.4 F1 and 20.3 F1 points better than the NED-Base baseline for examples with gold types appearing more and less than the median number of times during training respectively. Bootleg provides a a 7.8 F1 points and 13.7 F1 points better than the baseline for examples with gold relations appearing more and less than the median number of times during training respectively. These results indicate that Bootleg excels on the tails of types and relations as well.</p><p>Next, ranking the Wikidata types and relations by the proportion of comprised rare (tail and unseen) entities, we further find that Bootleg provides the lowest error rates across types and relations, regardless of the proportion of rare entities, while the baseline and Entity-Only models give relatively larger error rates as the proportion of rare entities increases <ref type="figure">(Figure 4</ref>). The trend for types is flat as the proportion of rare entities increases, while the trend for relations is upwards sloping. These results indicate that Bootleg is better able to transfer the patterns learned from one entity to other entities that share its same types and relations. The improvement from Bootleg over the baseline increases as the rare-proportion increases, indicating that Bootleg is able to efficiently transfer knowledge even when the type or relation category contains none or few popular entities.</p><p>Type Affordance For the type affordance pattern, we find that the TF-IDF keywords provide high coverage over the examples containing the gold type: 88% of examples where the gold entity has a particular type contain an affordance keyword for that type. An example of a type with full coverage by the affordance Error Rate BOOTLEG BERT KG-Only Type-Only Entity-Only <ref type="figure">Figure 4</ref>: For all the entities of a particular type or relation, we calculate the percentage of rare entities (tails and toes entities). We show the error rate on the Wikipedia validation set as a function of the rare-proportion of entities of a given (Left) relation or (Right) type appearing in the validation set.</p><p>keywords is "caf?", with keywords such as "coffee", "Starbucks", and "Internet"; in each of the 77 times an entity of the type "cafe" appears in the validation set, an affordance keyword is present. Types with low coverage in the validation set by affordance keywords tend to be the rare types: for the types with coverage less than 50%, such as "dietician" or "chess official", the median number of occurrences in the validation set is 1. This supports the need for knowledge signals with distinct tails, which can be assembled to together address the rare examples.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(Left) shows the four reasoning patterns for disambiguation. The correct entity is bolded. (Right)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>We compare Bootleg to the best published numbers on three NED benchmarks. "-" indicates that the metric was not reported. Bolded numbers indicate the best value for each metric on each benchmark.</figDesc><table><row><cell cols="2">Benchmark Model</cell><cell cols="2">Precision Recall</cell><cell>F1</cell></row><row><cell>KORE50</cell><cell>Hu et al. [24] 7 Bootleg</cell><cell>80.0 86.0</cell><cell>79.8 85.4</cell><cell>79.9 85.7</cell></row><row><cell>RSS500</cell><cell>Phan et al. [40] Bootleg</cell><cell>82.3 82.5</cell><cell>82.3 82.5</cell><cell>82.3 82.5</cell></row><row><cell>AIDA</cell><cell>F?vry et al. [16] Bootleg</cell><cell>-96.9</cell><cell>96.7 96.7</cell><cell>-96.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>(top)  We compare Bootleg to a BERT-based NED baseline (NED-Base) on validation sets of a Wikipedia dataset. We report micro-average F1 scores. All torso, tail, and unseen validation sets are filtered by the number of entity occurrences in the training data and such that the mention has more than one candidate.</figDesc><table><row><cell>Model</cell><cell cols="4">All Entities Torso Entities Tail Entities Unseen Entities</cell></row><row><cell>NED-Base</cell><cell>85.9</cell><cell>79.3</cell><cell>27.8</cell><cell>18.5</cell></row><row><cell>Bootleg</cell><cell>91.3</cell><cell>87.3</cell><cell>69.0</cell><cell>68.5</cell></row><row><cell>Bootleg (Ent-only)</cell><cell>85.8</cell><cell>79.0</cell><cell>37.9</cell><cell>14.9</cell></row><row><cell>Bootleg (Type-only)</cell><cell>88.0</cell><cell>81.6</cell><cell>62.9</cell><cell>61.6</cell></row><row><cell>Bootleg (KG-only)</cell><cell>87.1</cell><cell>79.4</cell><cell>64.0</cell><cell>64.7</cell></row><row><cell># Mentions</cell><cell>4,065,778</cell><cell>1,911,590</cell><cell>162,761</cell><cell>9,626</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Test micro-average F1 score on revised TACRED dataset.</figDesc><table><row><cell>Validation Set</cell><cell>F1</cell></row><row><cell cols="2">Bootleg Model 80.3</cell></row><row><cell>KnowBERT</cell><cell>79.3</cell></row><row><cell>SpanBERT</cell><cell>78.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>The following are examples of how the contextual entity representation from Bootleg, generated from entity, relation, and type signals, can help our downstream model. We provide the TACRED example, signals provided by Bootleg, as well our model and the baseline SpanBERT models' predictions.</figDesc><table><row><cell>TACRED Example</cell><cell>Bootleg Signals</cell><cell>Our</cell><cell>SpanBERT</cell></row><row><cell></cell><cell></cell><cell>Prediction</cell><cell>Prediction</cell></row><row><cell>Vincent Astor, like Marshall (subj),</cell><cell></cell><cell></cell><cell></cell></row><row><cell>died unexpectedly of a heart attack</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(obj) in 1959 . . .</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Relative F1 quality of an Overton[45] model with Bootleg embeddings over one without in four languages.</figDesc><table><row><cell cols="5">Validation Set English Spanish French German</cell></row><row><cell>All Entities</cell><cell>1.08</cell><cell>1.03</cell><cell>1.02</cell><cell>1.00</cell></row><row><cell>Tail Entities</cell><cell>1.08</cell><cell>1.17</cell><cell>1.05</cell><cell>1.03</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>We show the micro F1 score over unseen entities for a Wikipedia sample as we vary the entity regularization scheme p(e). A scalar percent means a fixed regularization. InvPop (inverse poularity scheme) applies less regularization for more popular entities and Pop applies more regularization for more popular entities.</figDesc><table><row><cell>p(e)</cell><cell>0%</cell><cell>20% 50% 80% Pop InvPop</cell></row><row><cell cols="3">Unseen Entities 48.6 52.5 57.7 59.9 52.4 62.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7</head><label>7</label><figDesc></figDesc><table /><note>).? Entity To evaluate whether Bootleg captures factual knowledge about entities in the form of textual entity cues, we consider the slice of 28K overall, 5K tail examples where the gold entity has no relation or type signals available.? Type Consistency To evaluate whether Bootleg captures consistency patterns, we consider the slice of 312K overall, 19K tail examples that contain a list of three or more sequential distinct gold entities, where all items in the list share at least one type.? KG Relation To evaluate whether Bootleg captures KG relation patterns, we consider the slice of 1.1M overall, 37K tail examples for which the gold entities are connected by a known relation in the Wikidata knowledge graph.? Type Affordance To evaluate whether Bootleg captures affordance patterns, we consider a slice where the sentence contains keywords that are afforded by the type of the gold entity. We mine the keywords afforded by a type by taking the 15 keywords that receive the highest TF-IDF scores over training examples with that type. This slice has 3.4M overall, 124K tail examples.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>We report the Overall/Tail F1 scores across each ablation model for a slice of data that exemplifies a reasoning pattern. Each slice is representative but may not cover every example that contains the reasoning pattern.</figDesc><table><row><cell>Model</cell><cell>Entity</cell><cell cols="3">Type Consistency KG Relation Type Affordance</cell></row><row><cell>NED-Base</cell><cell>59/29</cell><cell>84/29</cell><cell>91/30</cell><cell>87/28</cell></row><row><cell>Bootleg</cell><cell>66/47</cell><cell>95/85</cell><cell>98/92</cell><cell>93/73</cell></row><row><cell>Bootleg (Ent-only)</cell><cell>59/31</cell><cell>87/45</cell><cell>90/42</cell><cell>87/39</cell></row><row><cell>Bootleg (Type-only)</cell><cell>53/44</cell><cell>93/80</cell><cell>93/69</cell><cell>90/66</cell></row><row><cell>Bootleg (KG-only)</cell><cell>40/29</cell><cell>92/79</cell><cell>97/93</cell><cell>89/68</cell></row><row><cell>% Coverage</cell><cell>0.7%/3.3%</cell><cell>8%/12%</cell><cell>27%/23%</cell><cell>84%/76%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8</head><label>8</label><figDesc></figDesc><table /><note>, none of the present gold entities-Stillwater Santa Fe Depot, Citizens Bank Building (Stillwater, Oklahoma), Hoke Building (Stillwater, Oklahoma), or Walker Building (Stillwater, Oklahoma)-are directly connected in Wikidata; however, they share connections to the entity "Oklahoma". This indicates that the correct disambiguation is Citizens Bank Building (Stillwater, Oklahoma), not Citizens Bank Building (Burnsville, North Carolina). To evaluate examples requiring 2-hop reasoning, we consider examples where none of the present entities are directly linked in the KG, but a present pair connects to a different entity that is not present in the sentence. We find this occurs in 6% of overall and 7% of tail errors. This type of error represents a fundamental limitation of Bootleg as we do not encode any form of multi-hop reasoning over a KG in Bootleg. Our KG information only encodes single-hop patterns (i.e., direct connections).? Exact Match Bootleg struggles on several examples in which the exact entity title is present in the text. Considering examples where the BERT Baseline is correct but Bootleg is incorrect, in 28% of the examples, the textual mention is an exact match of the entity title. Further, 32% of the examples contain a keyword from the entity title that Bootleg misses (example in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>We identify four key error buckets for Bootleg: granularity, numerical errors, multi-hop reasoning, and missed exact matches. We provide a Wikipedia example, the gold entity, and Bootleg's predicted entity for each example.</figDesc><table><row><cell>Error</cell><cell>Wikipedia Example</cell><cell>Bootleg Prediction</cell><cell>Gold Entity</cell></row><row><cell cols="2">Granularity Posey is the recipient of a Golden</cell><cell>Satellite Awards</cell><cell>Satellite Award for Best</cell></row><row><cell></cell><cell>Globe Award nomination, a Satel-</cell><cell></cell><cell>Actress -Motion Picture</cell></row><row><cell></cell><cell>lite Award nomination and two In-</cell><cell></cell><cell></cell></row><row><cell></cell><cell>dependent Spirit Award nominations.</cell><cell></cell><cell></cell></row><row><cell>Numerical</cell><cell>He competed in the individual road</cell><cell>Cycling at the 1960</cell><cell>Cycling at the 1976 Sum-</cell></row><row><cell></cell><cell>race and team time trial events at the</cell><cell>Summer Olympics -</cell><cell>mer Olympics -1976</cell></row><row><cell></cell><cell>1976 Summer Olympics.</cell><cell>1960 Men's Road Race</cell><cell>Men's Road Race</cell></row><row><cell>Multi-hop</cell><cell>Other nearby historic buildings in-</cell><cell>Citizens Bank Build-</cell><cell>Citizens Bank Building</cell></row><row><cell></cell><cell>clude the Santa Fe Depot, the Cit-</cell><cell>ing (Burnsville, North</cell><cell>(Stillwater, Oklahoma)</cell></row><row><cell></cell><cell>izens Bank Building, the Hoke</cell><cell>Carolina)</cell><cell></cell></row><row><cell></cell><cell>Building, the Walker Building, and</cell><cell></cell><cell></cell></row><row><cell></cell><cell>the Courthouse</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>The works of Broscheit [6], Peters et al. [38], Poerner et al. [41], Zhang et al. [54] all try to add entity knowledge into a deep language model to improve downstream natural language task performance. Peters et al. [38], Poerner et al. [41], Zhang et al.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>(top)  We compare Bootleg to a BERT-based NED baseline (NED-Base) on validation sets of our micro Wikipedia dataset and ablate Bootleg by only training with entity, type, or knowledge graph data. We further ablate (bottom 8 rows) the regularization schemes for the entity embeddings for Bootleg.</figDesc><table><row><cell>Model</cell><cell cols="4">All Entities Torso Entities Tail Entities Unseen Entities</cell></row><row><cell>NED-Base</cell><cell>90.2</cell><cell>91.6</cell><cell>50.5</cell><cell>21.5</cell></row><row><cell>Bootleg (Ent-only)</cell><cell>89.1</cell><cell>89.0</cell><cell>48.3</cell><cell>15.5</cell></row><row><cell>Bootleg (Type-only)</cell><cell>91.6</cell><cell>90.4</cell><cell>65.9</cell><cell>56.8</cell></row><row><cell>Bootleg (KG-only)</cell><cell>91.8</cell><cell>90.8</cell><cell>65.3</cell><cell>58.6</cell></row><row><cell>Bootleg (p(e) = 0%)</cell><cell>92.5</cell><cell>92.3</cell><cell>67.7</cell><cell>48.6</cell></row><row><cell>Bootleg (p(e) = 20%)</cell><cell>92.8</cell><cell>92.5</cell><cell>68.9</cell><cell>52.5</cell></row><row><cell>Bootleg (p(e) = 50%)</cell><cell>92.9</cell><cell>92.7</cell><cell>70.1</cell><cell>57.7</cell></row><row><cell>Bootleg (p(e) = 80%)</cell><cell>92.8</cell><cell>92.2</cell><cell>69.5</cell><cell>59.9</cell></row><row><cell>Bootleg (InvPopLog)</cell><cell>92.7</cell><cell>91.9</cell><cell>69.7</cell><cell>61.1</cell></row><row><cell>Bootleg (InvPopPow)</cell><cell>92.8</cell><cell>92.3</cell><cell>70.5</cell><cell>62.2</cell></row><row><cell>Bootleg (InvPopLin)</cell><cell>92.6</cell><cell>91.8</cell><cell>69.7</cell><cell>61.0</cell></row><row><cell>Bootleg (PopPow)</cell><cell>92.9</cell><cell>92.5</cell><cell>68.9</cell><cell>52.4</cell></row><row><cell># Mentions</cell><cell>96,237</cell><cell>37,077</cell><cell>11,087</cell><cell>2,810</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>We report the model sizes in MB of each of the five ablation models: NED-Base, Bootleg, Bootleg (Ent-Only), Bootleg (KG-Only), and Bootleg (Type-Only).</figDesc><table><row><cell>Model</cell><cell cols="5">NED-Base Bootleg Ent-Only Type-Only KG-Only</cell></row><row><cell cols="2">Embedding Size (MB) 5,186</cell><cell>5,201</cell><cell>5,186</cell><cell>13</cell><cell>1</cell></row><row><cell>Network Size (MB)</cell><cell>4</cell><cell>39</cell><cell>35</cell><cell>38</cell><cell>34</cell></row><row><cell>Total Size (MB)</cell><cell>5,190</cell><cell>5,240</cell><cell>5,221</cell><cell>51</cell><cell>35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 :</head><label>11</label><figDesc>We report Bootleg trained with versus without weak labelling on our micro Wikipedia dataset. The slices defined by gold anchor counts (pre-weak labelling). We use the InvPopPow regularization for both.</figDesc><table><row><cell>Model</cell><cell cols="4">All Entities Torso Entities Tail Entities Unseen Entities</cell></row><row><cell>Bootleg</cell><cell>92.8</cell><cell>92.6</cell><cell>70.5</cell><cell>63.3</cell></row><row><cell>Bootleg (No WL)</cell><cell>93.3</cell><cell>93.1</cell><cell>70.2</cell><cell>60.7</cell></row><row><cell># Mentions</cell><cell>96,237</cell><cell>36,904</cell><cell>11,541</cell><cell>3,146</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 13 :</head><label>13</label><figDesc>We compute the error rate of SpanBERT relative to our Bootleg downstream model for three slices of TACRED data where respectively Bootleg disambiguates the subject and/or object, Bootleg leverages Wikidata relations for the embedding of the subject and object pair, and Bootleg leverages Wikidata types for the embedding of the subject and/or object in the example.</figDesc><table><row><cell cols="3">Subject-Object Signal # Examples BERT/Bootleg Error Rate</cell></row><row><cell>Entity</cell><cell>12621</cell><cell>1.20</cell></row><row><cell>Relation</cell><cell>542</cell><cell>1.18</cell></row><row><cell>Obj Type</cell><cell>12044</cell><cell>1.20</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We computed this statistic by computing the number of proper nouns and the number of pronouns/known aliases for an entity on that entity's page that were not already linked.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Bootleg Architecture for Tail DisambiguationWe now describe our approach to leverage the reasoning patterns based on entity, relation, and type signals. We then present our new regularization scheme to inject inductive bias of when to use general versus discriminative reasoning patterns and our weak labeling technique to extract more signal from the self-supervision training data.<ref type="bibr" target="#b4">5</ref> Coverage numbers are calculated from representative slices of Wikidata that require each reasoning pattern. Additional details in Section 5.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">We drop only 1% of mentions from this filter.<ref type="bibr" target="#b7">8</ref> We use the standard candidate list from Pershina et al.<ref type="bibr" target="#b35">[36]</ref> when comparing to existing systems for fine-tuning and inference for AIDA CoNLL-YAGO.<ref type="bibr" target="#b8">9</ref> As code for the model from F?vry et al.<ref type="bibr" target="#b15">[16]</ref> is not publicly available, we re-implemented the model. We used our candidate</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">Entity disambiguation refers to when the mentions are pre-detected in text. Entity linking includes the mention detection phase. In Bootleg, we focus on the entity disambiguation task.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">We use the spaCy NER tagger from https://spacy.io/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">Similar to tail-entities, tail-types and tail-relations are defined as those appearing 1-10 times in the training data.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements:</head><p>We thank Jared Dunnmon, Dan Fu, Karan Goel, Sarah Hooper, Monica Lam, Fred Sala, Nimit Sohoni, and Silei Xu for their valuable feedback and Pallavi Gudipati for help with experiments. We gratefully acknowledge the support of DARPA under Nos. FA86501827865 (SDH) and FA86501827882 (ASED); NIH under No. U54EB020405 (Mobilize), NSF under Nos. CCF1763315 (Beyond Sparsity), CCF1563078 (Volume to Velocity), and 1937301 (RTML); ONR under No. N000141712266 (Unifying Weak Supervision); the Moore Foundation, NXP, Xilinx, LETI-CEA, Intel, IBM, Microsoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Ericsson, Qualcomm, Analog Devices, the Okawa Foundation, American Family Insurance, Google Cloud, Swiss Re, the HAI-AWS Cloud Credits for Research program, and members of the Stanford DAWN project: Teradata, Facebook, Google, Ant Financial, NEC, VMWare, and Infosys. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of DARPA, NIH, ONR, or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mitre: Description of the alembic system as used in met</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Aberdeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynette</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vilain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TIPSTER TEXT PROGRAM PHASE II: Proceedings of a Workshop</title>
		<meeting><address><addrLine>Vienna, Virginia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="461" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Tacred revisited: A thorough evaluation of the tacred relation extraction task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Alt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Gabryszak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonhard</forename><surname>Hennig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Direct answers for search queries in the long tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Liebling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCHI</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Moving down the long tail of word sense disambiguation with gloss-informed biencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terra</forename><surname>Blevins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.02590</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<idno type="arXiv">arXiv:2003.05473</idno>
		<title level="m">Samuel Broscheit. Investigating entity knowledge in bert with simple neural end-to-end entity linking</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Tom B Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Askell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Named entity disambiguation using deep learning on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Cetoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Akbari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Bragaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>O&amp;apos;harney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sloan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.09164</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Improving entity linking by modeling latent entity type information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinpeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.01447</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Unknown examples &amp; machine learning model generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeounoh</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Upfal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kraska</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.08294</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Automated data slicing for model validation: A big data-ai integration approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeounoh</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neoklis</forename><surname>Polyzotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyun</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">Euijong</forename><surname>Whang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>TKDE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Large-scale named entity disambiguation based on wikipedia data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silviu Cucerzan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="708" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.00904</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">Autoregressive entity retrieval. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Entity disambiguation for knowledge base population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delip</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Finin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="277" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allyson</forename><surname>Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudha</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daum?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.01505</idno>
		<title level="m">Towards linguistically generalizable nlp systems: A workshop and shared task</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Empirical evaluation of pretraining strategies for supervised entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>F?vry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Livio Baldini</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AKBC</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Deep joint entity disambiguation with local neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Octavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hofmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04920</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Real-time rdf extraction from unstructured data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenz</forename><surname>B?hmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Soru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Usbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Winer: A wikipedia annotated corpus for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abbas</forename><surname>Ghaddar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Langlais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="413" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Our latest quality improvements for search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Gomes</surname></persName>
		</author>
		<ptr target="https://blog.google/products/search/our-latest-quality-improvements-search/" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Entity linking via joint encoding of types, descriptions, and context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2681" to="2690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust disambiguation of named entities in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">Amir</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilaria</forename><surname>Bordino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hagen</forename><surname>F?rstenau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilyana</forename><surname>Taneva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Thater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="782" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Kore: keyphrase overlap relatedness for entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Seufert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><surname>Ba Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Entity linking via symmetrical attention-based neural network and entity structural features. Symmetry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengze</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Systematic study of long tail phenomena in entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ilievski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piek</forename><surname>Vossen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Schlobach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="664" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Entity linking at the tail: Sparse signals, unknown entities and phrase models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhe</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emre</forename><surname>Kiciman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricky</forename><surname>Loynd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM &apos;14 Proceedings of the 7th ACM international conference on Web search and data mining</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014-02" />
			<biblScope unit="page" from="453" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.10529</idno>
		<title level="m">SpanBERT: Improving pre-training by representing and predicting spans</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="466" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Improving entity linking by modeling latent relations between mentions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phong</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.10637</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Design challenges for entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="315" to="328" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Rohit Deep, Esteban Arcaute, and Vijay Raghavendra. Deep learning for entity matching: A design space exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sidharth</forename><surname>Mudgal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodoros</forename><surname>Rekatsinas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anhai</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngchoon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Evaluating the impact of knowledge graph contexton entity disambiguation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuldeep</forename><surname>Isaiah Onando Mulang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitali</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Nadgeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lehmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.05190</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Transforming wikipedia into named entity training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><surname>James R Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Australasian Language Technology Association Workshop</title>
		<meeting>the Australasian Language Technology Association Workshop</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="124" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fast and accurate entity linking via graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Parravicini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rhicheek</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><forename type="middle">B</forename><surname>Bartolini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><forename type="middle">D</forename><surname>Santambrogio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Joint International Workshop on Graph Data Management Experiences &amp; Systems (GRADES) and Network Data Analytics (NDA)</title>
		<meeting>the 2nd Joint International Workshop on Graph Data Management Experiences &amp; Systems (GRADES) and Network Data Analytics (NDA)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Personalized page rank for named entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pershina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Using machine learning to maintain rule-based named-entity recognition and classification systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Petasis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frantz</forename><surname>Vichot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Wolinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 39th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="426" to="433" />
		</imprint>
	</monogr>
	<note>Vangelis Karkaletsis, and Constantine D Spyropoulos</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Knowledge enhanced contextual word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidur</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1005</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11" />
			<biblScope unit="page" from="43" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Majid</forename><surname>Yazdani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><forename type="middle">De</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.02252</idno>
		<title level="m">Vassilis Plachouras, Tim Rockt?schel, et al. Kilt: a benchmark for knowledge intensive language tasks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Pair-linking for collective entity disambiguation: Two could be better than all</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><forename type="middle">C</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenliang</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>TKDE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Poerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Waltinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sch?tze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03681</idno>
		<title level="m">Efficient-yet-effective entity embeddings for bert</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Elden: Improved entity linking using densified knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1844" to="1853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deeptype: multilingual entity linking by neural type system evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Raphael Raiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Michel Raiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Snorkel: Rapid training data creation with weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Ehrenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Overton: A data system for monitoring and improving machine-learned products</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallavi</forename><surname>Gudipati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Srisuwananukorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Entity-aware elmo: Learning contextual entity representation for entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Shahbazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiaoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rasha</forename><surname>Ghaeini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasad</forename><surname>Obeidat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tadepalli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.05762</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Itemsuggest: A data management platform for machine learned ranking services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Tata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Panait</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremiah</forename><surname>Suming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Colagrosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<editor>Neurips</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Do nlp models know numbers? probing numeracy in embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.07940</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">A survey on recent advances in named entity recognition from deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.11470</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Pre-training of deep contextualized embeddings of words and entities for named entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikuya</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyuki</forename><surname>Shindo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.00426</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">HYENA: Hierarchical type classification for entity names</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Amir Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandro</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<meeting><address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-12" />
			<biblScope unit="page" from="1361" to="1370" />
		</imprint>
	</monogr>
	<note>Proceedings of COLING 2012: Posters</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Position-aware attention and supervised data improve slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ernie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.07129</idno>
		<title level="m">Enhanced language representation with informative entities</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Latte: Latent type modeling for biomedical entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Busra</forename><surname>Celikkaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parminder</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandan</forename><forename type="middle">K</forename><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Knowledge acquisition for visual question answering via iterative querying</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1154" to="1163" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
