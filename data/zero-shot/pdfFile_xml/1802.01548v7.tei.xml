<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Regularized Evolution for Image Classifier Architecture Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Brain</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Brain</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Brain</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Brain</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Regularized Evolution for Image Classifier Architecture Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The effort devoted to hand-crafting neural network image classifiers has motivated the use of architecture search to discover them automatically. Although evolutionary algorithms have been repeatedly applied to neural network topologies, the image classifiers thus discovered have remained inferior to human-crafted ones. Here, we evolve an image classifier-AmoebaNet-A-that surpasses hand-designs for the first time.</p><p>To do this, we modify the tournament selection evolutionary algorithm by introducing an age property to favor the younger genotypes. Matching size, AmoebaNet-A has comparable accuracy to current state-of-the-art ImageNet models discovered with more complex architecture-search methods. Scaled to larger size, AmoebaNet-A sets a new state-of-theart 83.9% top-1 / 96.6% top-5 ImageNet accuracy. In a controlled comparison against a well known reinforcement learning algorithm, we give evidence that evolution can obtain results faster with the same hardware, especially at the earlier stages of the search. This is relevant when fewer compute resources are available. Evolution is, thus, a simple method to effectively discover high-quality architectures.</p><p>Review papers provide informative surveys of earlier <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b48">49]</ref> and more recent [15] literature on image classifier architecture search, including successful RL studies <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref> and evolutionary studies like those mentioned in 1 After our submission, a recent preprint has further scaled up and retrained AmoebaNet-A to reach 84.3% top-1 / 97.0% top-5 ImageNet accuracy <ref type="bibr" target="#b24">[25]</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Until recently, most state-of-the-art image classifier architectures have been manually designed by human experts <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b44">45]</ref>. To speed up the process, researchers have looked into automated methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b52">53]</ref>. These methods are now collectively known as architecturesearch algorithms. A traditional approach is neuro-evolution of topologies <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b41">42]</ref>. Improved hardware now allows scaling up evolution to produce high-quality image classifiers <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b46">47</ref>]. Yet, the architectures produced by evolutionary algorithms / genetic programming have not reached the accuracy of those directly designed by human experts. Here we evolve image classifiers that surpass hand-designs.</p><p>To do this, we make two additions to the standard evolutionary process. First, we propose a change to the wellestablished tournament selection evolutionary algorithm <ref type="bibr" target="#b18">[19]</ref> that we refer to as aging evolution or regularized evolution. Whereas in tournament selection, the best genotypes (architectures) are kept, we propose to associate each genotype with an age, and bias the tournament selection to choose the younger genotypes. We will show that this change turns out to make a difference. The connection to regularization will be clarified in the Discussion section. Second, we implement the simplest set of mutations that would allow evolving in the NASNet search space <ref type="bibr" target="#b53">[54]</ref>. This search space associates convolutional neural network architectures with small directed graphs in which vertices represent hidden states and labeled edges represent common network operations (such as convolutions or pooling layers). Our mutation rules only alter architectures by randomly reconnecting the origin of edges to different vertices and by randomly relabeling the edges, covering the full search space.</p><p>Searching in the NASNet space allows a controlled comparison between evolution and the original method for which it was designed, reinforcement learning (RL). Thus, this paper presents the first comparative case study of architecturesearch algorithms for the image classification task. Within this case study, we will demonstrate that evolution can attain similar results with a simpler method, as will be shown in the Discussion section. In particular, we will highlight that in all our experiments evolution searched faster than RL and random search, especially at the earlier stages, which is important when experiments cannot be run for long times due to compute resource limitations.</p><p>Despite its simplicity, our approach works well in our benchmark against RL. It also evolved a high-quality model, which we name AmoebaNet-A. This model is competitive with the best image classifiers obtained by any other algorithm today at similar sizes (82.8% top-1 / 96.1% top-5 Im-ageNet accuracy). When scaled up, it sets a new state-ofthe-art accuracy (83.9% top-1 / 96.6% top-5 ImageNet accuracy) <ref type="bibr" target="#b0">1</ref> .</p><p>the Introduction. Other methods have also been applied: cascade-correlation <ref type="bibr" target="#b15">[16]</ref>, boosting <ref type="bibr" target="#b9">[10]</ref>, hill-climbing <ref type="bibr" target="#b13">[14]</ref>, MCTS <ref type="bibr" target="#b33">[34]</ref>, SMBO <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31]</ref>, and random search <ref type="bibr" target="#b3">[4]</ref>, and grid search <ref type="bibr" target="#b49">[50]</ref>. Some methods even forewent the idea of independent architectures <ref type="bibr" target="#b37">[38]</ref>. There is much architecturesearch work beyond image classification too, but that is outside our scope.</p><p>Even though some methods stand out due to their efficiency <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b42">43]</ref>, many approaches use large amounts of resources. Several recent papers reduced the compute cost through progressive-complexity search stages <ref type="bibr" target="#b28">[29]</ref>, hypernets <ref type="bibr" target="#b4">[5]</ref>, accuracy prediction <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b25">26]</ref>, warm-starting and ensembling <ref type="bibr" target="#b16">[17]</ref>, parallelization, reward shaping and early stopping <ref type="bibr" target="#b51">[52]</ref> or Net2Net transformations <ref type="bibr" target="#b5">[6]</ref>. Most of these methods could in principle be applied to evolution too, but this is beyond the scope of this paper.</p><p>A popular approach to evolution has been through generational algorithms, e.g. NEAT <ref type="bibr" target="#b41">[42]</ref>. All models in the population must finish training before the next generation is computed. Generational evolution becomes inefficient in a distributed environment where a different machine is used to train each model: machines that train faster models finish earlier and must wait idle until all machines are ready. Real-time algorithms address this issue, e.g. rtNEAT <ref type="bibr" target="#b40">[41]</ref> and tournament selection <ref type="bibr" target="#b18">[19]</ref>. Unlike the generational algorithms, however, these discard models according to their performance or do not discard them at all, resulting in models that remain alive in the population for a long time-even for the whole experiment. We will present evidence that the finite lifetimes of aging evolution can give better results than direct tournament selection, while retaining its efficiency.</p><p>An existing paper <ref type="bibr" target="#b21">[22]</ref> uses a concept of age but in a very different way than we do. In that paper, age is assigned to genes to divide a constant-size population into groups called age-layers. Each layer contains individuals with genes of similar ages. Only after the genes have survived a certain age-gap, they can make it to the next layer. The goal is to restrict competition (the newly introduced genes cannot be immediately out-competed by highly-selected older ones). Their algorithm requires the introduction of two additional meta-parameters (size of the age-gap and number of agelayers). In contrast, in our algorithm, an age is assigned to the individuals (not the genes) and is only used to track which is the oldest individual in the population. This permits removing such oldest individual at each cycle (keeping a constant population size). Our approach, therefore, is in line with our goal of keeping the method as simple as possible. In particular, our method remains similar to nature (where the young are less likely to die than the very old) and it requires no additional meta-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>This section contains a readable description of the methods. The Methods Details section gives additional information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search Space</head><p>All experiments use the NASNet search space <ref type="bibr" target="#b53">[54]</ref>. This is a space of image classifiers, all of which have the fixed outer structure indicated in <ref type="figure" target="#fig_8">Figure 1</ref> (left): a feed-forward stack of Inception-like modules called cells. Each cell receives a direct input from the previous cell (as depicted) and a skip input from the cell before it <ref type="figure" target="#fig_8">(Figure 1</ref>, middle). The cells in the stack are of two types: the normal cell and the reduction cell. All normal cells are constrained to have the same architecture, as are reduction cells, but the architecture of the normal cells is independent of that of the reduction cells. Other than this, the only difference between them is that every application of the reduction cell is followed by a stride of 2 that reduces the image size, whereas normal cells preserve the image size. As can be seen in the figure, normal cells are arranged in three stacks of N cells. The goal of the architecture-search process is to discover the architectures of the normal and reduction cells.  <ref type="bibr" target="#b53">[54]</ref>. LEFT: the full outer structure (omitting skip inputs for clarity). MIDDLE: detailed view with the skip inputs. RIGHT: cell example. Dotted line demarcates a pairwise combination. <ref type="figure" target="#fig_8">Figure 1</ref> (middle and right), each cell has two input activation tensors and one output. The very first cell takes two copies of the input image. After that, the inputs are the outputs of the previous two cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>As depicted in</head><p>Both normal and reduction cells must conform to the following construction. The two cell input tensors are considered hidden states "0" and "1". More hidden states are then constructed through pairwise combinations. A pairwise combination is depicted in <ref type="figure" target="#fig_8">Figure 1</ref> (right, inside dashed circle). It consists in applying an operation (or op) to an existing hidden state, applying another op to another existing hidden state, and adding the results to produce a new hidden state. Ops belong to a fixed set of common convnet operations such as convolutions and pooling layers. Repeating hidden states or operations within a combination is permitted. In the cell example of <ref type="figure" target="#fig_8">Figure 1</ref> (right), the first pairwise combination applies a 3x3 average pool op to hidden state 0 and a 3x3 max pool op to hidden state 1, in order to produce hidden state 2. The next pairwise combination can now choose from hidden states 0, 1, and 2 to produce hidden state 3 (chose 0 and 1 in <ref type="figure" target="#fig_8">Figure 1</ref>), and so on. After exactly five pairwise combinations, any hidden states that remain unused (hidden states 5 and 6 in <ref type="figure" target="#fig_8">Figure 1</ref>) are concatenated to form the output of the cell (hidden state 7).</p><p>A given architecture is fully specified by the five pairwise combinations that make up the normal cell and the five that make up the reduction cell. Once the architecture is specified, the model still has two free parameters that can be used to alter its size (and its accuracy): the number of normal cells per stack (N) and the number of output filters of the convolution ops (F). N and F are determined manually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evolutionary Algorithm</head><p>The evolutionary method we used is summarized in Algorithm 1. It keeps a population of P trained models throughout the experiment. The population is initialized with models with random architectures ("while |population|" in Algorithm 1). All architectures that conform to the search space described are possible and equally likely. After this, evolution improves the initial population in cycles ("while |history|" in Algorithm 1). At each cycle, it samples S random models from the population, each drawn uniformly at random with replacement. The model with the highest validation fitness within this sample is selected as the parent. A new architecture, called the child, is constructed from the parent by the application of a transformation called a mutation. A mutation causes a simple and random modification of the architecture and is described in detail below. Once the child architecture is constructed, it is then trained, evaluated, and added to the population. This process is called tournament selection <ref type="bibr" target="#b18">[19]</ref>.</p><p>It is common in tournament selection to keep the population size fixed at the initial value P. This is often accomplished with an additional step within each cycle: discarding (or killing) the worst model in the random S-sample. We will refer to this approach as non-aging evolution. In contrast, in this paper we prefer a novel approach: killing the oldest model in the population-that is, removing from the population the model that was trained the earliest ("remove dead from left of pop" in Algorithm 1). This favors the newer models in the population. We will refer to this approach as aging evolution. In the context of architecture search, aging evolution allows us to explore the search space more, instead of zooming in on good models too early, as non-aging evolution would (see Discussion section for details).</p><p>In practice, this algorithm is parallelized by distributing the "while |history|" loop in Algorithm 1 over multiple workers. A full implementation can be found online. <ref type="bibr" target="#b1">2</ref> Intuitively, the mutations can be thought of as providing exploration, while the parent selection provides exploitation. The parameter S controls the aggressiveness of the exploitation: S = 1 reduces to a type of random search and 2 ? S ? P leads to evolution of varying greediness.</p><p>New models are constructed by applying a mutation to existing models, transforming their architectures in random ways. To navigate the NASNet search space described above, we use two main mutations that we call the hidden state mutation and the op mutation. A third mutation, the identity, is also possible. Only one of these mutations is applied in each cycle, choosing between them at random.  The hidden state mutation consists of first making a random choice of whether to modify the normal cell or the reduction cell. Once a cell is chosen, the mutation picks one of the five pairwise combinations uniformly at random. Once the pairwise combination is picked, one of the two elements of the pair is chosen uniformly at random. The chosen element has one hidden state. This hidden state is now replaced with another hidden state from within the cell, subject to the constraint that no loops are formed (to keep the feed-forward nature of the convnet). <ref type="figure" target="#fig_2">Figure 2</ref> (top) shows an example.</p><p>The op mutation behaves like the hidden state mutation as far as choosing one of the two cells, one of the five pairwise combinations, and one of the two elements of the pair.</p><p>Then it differs in that it modifies the op instead of the hidden state. It does this by replacing the existing op with a random choice from a fixed list of ops (see Methods Details). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline Algorithms</head><p>Our main baseline is the application of RL to the same search space. RL was implemented using the algorithm and code in the baseline study <ref type="bibr" target="#b53">[54]</ref>. An LSTM controller outputs the architectures, constructing the pairwise combinations one at a time, and then gets a reward for each architecture by training and evaluating it. More detail can be found in the baseline study. We also compared against random search (RS). In our RS implementation, each model is constructed randomly so that all models in the search space are equally likely, as in the initial population in the evolutionary algorithm. In other words, the models in RS experiments are not constructed by mutating existing models, so as to make new models independent from previous ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Setup</head><p>We ran controlled comparisons at scale, ensuring identical conditions for evolution, RL and random search (RS). In particular, all methods used the same computer code for network construction, training and evaluation. Experiments always searched on the CIFAR-10 dataset <ref type="bibr" target="#b26">[27]</ref>.</p><p>As in the baseline study, we first performed architecture search over small models (i.e. small N and F) until 20k models were evaluated. After that, we used the model augmentation trick <ref type="bibr" target="#b53">[54]</ref>: we took architectures discovered by the search (e.g. the output of an evolutionary experiment) and turn them into a full-size, accurate models. To accomplish this, we enlarged the models by increasing N and F so the resulting model sizes would match the baselines, and we trained the enlarged models for a longer time on the CIFAR-10 or the ImageNet classification datasets <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b26">27]</ref>. For Ima-geNet, a stem was added at the input of the model to reduce the image size, as shown in <ref type="figure">Figure 5</ref> (left). This is the same procedure as in the baseline study. To produce the largest model (see last paragraph of Results section; not included in tables), we increased N and F until we ran out of memory. Actual values of N and F for all models are listed in the Methods Details section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods Details</head><p>This section complements the Methods section with the details necessary to reproduce our experiments. Possible ops: none (identity); 3x3, 5x5 and 7x7 separable (sep.) convolutions (convs.); 3x3 average (avg.) pool; 3x3 max pool; 3x3 dilated (dil.) sep. conv.; 1x7 then 7x1 conv. Evolved with P =100, S=25. CIFAR-10 dataset <ref type="bibr" target="#b26">[27]</ref> with 5k withheld examples for validation. Standard ImageNet dataset <ref type="bibr" target="#b11">[12]</ref>, 1.2M 331x331 images and 1k classes; 50k examples withheld for validation; standard validation set used for testing. During the search phase, each model trained for 25 epochs; N=3/F=24, 1 GPU. Each experiment ran on 450 K40 GPUs for 20k models (approx. 7 days). To optimize evolution, we tried 5 configurations with P/S of: 100/2, 100/50, 20/20, 100/25, 64/16, best was 100/25. The probability of the identity mutation was fixed at the small, arbitrary value of 0.05 and was not tuned. Other mutation probabilities were uniform, as described in the Methods. To optimize RL, started with parameters already tuned in the baseline study and further optimized learning rate in 8 configurations: 0.00003, 0.00006, 0.00012, 0.0002, 0.0004, 0.0008, 0.0016, 0.0032; best was 0.0008. To avoid selection bias, plots do not include optimization runs, as was decided a priori. Best few (20) models were selected from each experiment and augmented to N=6/F=32, as in baseline study; batch 128, SGD with momentum rate 0.9, L2 weight decay 5 ? 10 ?4 , initial lr 0.024 with cosine decay, 600 epochs, Scheduled-DropPath to 0.7 prob; auxiliary softmax with half-weight of main softmax. For <ref type="table" target="#tab_1">Table 1</ref>, we used N/F of 6/32 and 6/36. For ImageNet table, N/F were 6/190 and 6/448 and standard training methods <ref type="bibr" target="#b43">[44]</ref>: distributed sync SGD with 100 P100 GPUs; RMSProp optimizer with 0.9 decay and =0.1, 4 ? 10 ?5 weight decay, 0.1 label smoothing, auxiliary softmax weighted by 0.4; dropout probability 0.5; Scheduled-DropPath to 0.7 probability (as in baseline-note that this trick only contributes 0.3% top-1 ImageNet acc.); 0.001 initial lr, decaying every 2 epochs by 0.97. Largest model used N=6/F=448. F always refers to the number of filters of convolutions in the first stack; after each reduction cell, this number is doubled. Wherever applicable, we used the same conditions as the baseline study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison With RL and RS Baselines</head><p>Currently, reinforcement learning (RL) is the predominant method for architecture search. In fact, today's state-ofthe-art image classifiers have been obtained by architecture search with RL <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b53">54]</ref>. Here we seek to compare our evolutionary approach against their RL algorithm. We performed large-scale side-by-side architecture-search experiments on CIFAR-10. We first optimized the hyperparameters of the two approaches independently (details in Methods Details section). Then we ran 5 repeats of each of the two algorithms-and also of random search (RS). <ref type="figure">Figure 3</ref> shows the model accuracy as the experiments progress, highlighting that evolution yielded more accurate models at the earlier stages, which could become important in a resource-constrained regime where the experiments may have to be stopped early (for example, when 450 GPUs for 7 days is too much). At the later stages, if we allow to run for the full 20k models (as in the baseline study), evolution produced models with similar accuracy. Both evolution and RL compared favorably against RS. It is important to note that the vertical axis of <ref type="figure">Figure 3</ref> does not present the compute cost of the models, only their accuracy. Next, we will consider their compute cost as well.</p><p>As in the baseline study, the architecture-search experiments above were performed over small models, to be able to train them quicker. We then used the model augmentation trick <ref type="bibr" target="#b53">[54]</ref> by which we take an architecture discovered by the search (e.g. the output of an evolutionary experiment) and turn it into a full-size, accurate model, as described in  <ref type="figure">Figure 4</ref> compares the augmented top models from the three sets of experiments. It shows test accuracy and model compute cost. The latter is measured in FLOPs, by which we mean the total count of operations in the forward pass, so lower is better. Evolved architectures had higher accuracy (and similar FLOPs) than those obtained with RS, and lower FLOPs (and similar accuracy) than those obtained with RL. Number of parameters showed similar behavior to FLOPs. Therefore, evolution occupied the ideal relative position in this graph within the scope of our case study. So far we have been comparing evolution with our reproduction of the experiments in the baseline study, but it is also informative to compare directly against the results reported by the baseline study. We select our evolved architecture with highest validation accuracy and call it AmoebaNet-A ( <ref type="figure">Figure 5</ref>). <ref type="table" target="#tab_1">Table 1</ref> compares its test accuracy with the top model of the baseline study, NASNet-A. Such a comparison is not entirely controlled, as we have no way of ensuring the network training code was identical and that the same number of experiments were done to obtain the final model. The table summarizes the results of training AmoebaNet-A at sizes comparable to a NASNet-A version, showing that AmoebaNet-A is slightly more accurate (when matching model size) or considerably smaller (when matching accuracy). We did not train our model at larger sizes on CIFAR-10. Instead, we moved to ImageNet to do further comparisons in the next section. Reduction Cell</p><p>x N</p><p>x N</p><p>x N  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ImageNet Results</head><p>Following the accepted standard, we compare our top model's classification accuracy on the popular ImageNet dataset against other top models from the literature. Again, we use AmoebaNet-A, the model with the highest validation accuracy on CIFAR-10 among our evolution experiments.</p><p>We highlight that the model was evolved on CIFAR-10 and then transferred to ImageNet, so the evolved architecture cannot have overfit the ImageNet dataset. When re-trained on ImageNet, AmoebaNet-A performs comparably to the baseline for the same number of parameters <ref type="table" target="#tab_1">(Table 2, model  with F=190)</ref>. Finally, we focused on AmoebaNet-A exclusively and enlarged it, setting a new state-of-the-art accuracy on Ima-geNet of 83.9%/96.6% top-1/5 accuracy with 469M parameters <ref type="table" target="#tab_2">(Table 2</ref>, model with F=448). Such high parameter counts may be beneficial in training other models too but we have not managed to do this yet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>This section will suggest directions for future work, which we will motivate by speculating about the evolutionary process and by summarizing additional minor results. The details of these minor results have been relegated to the supplements, as they are not necessary to understand or reproduce our main results above.</p><p>Scope of results. Some of our findings may be restricted to the search spaces and datasets we used. A natural direction for future work is to extend the controlled comparison to more search spaces, datasets, and tasks, to verify generality, or to more algorithms. Supplement A presents preliminary results, performing evolutionary and RL searches over three search spaces (SP-I: same as in the Results section; SP-II: like SP-I but with more possible ops; SP-III: like SP-II but with more pairwise combinations) and three datasets (gray-scale CIFAR-10, MNIST, and gray-scale ImageNet), at a small-compute scale (on CPU, F =8, N =1). Evolution reached equal or better accuracy in all cases <ref type="figure" target="#fig_6">(Figure 6, top)</ref>. Algorithm speed. In our comparison study, <ref type="figure">Figure 3</ref> suggested that both RL and evolution are approaching a common accuracy asymptote. That raises the question of which algorithm gets there faster. The plots indicate that evolution reaches half-maximum accuracy in roughly half the time. We abstain, nevertheless, from further quantifying this effect since it depends strongly on how speed is measured (the number of models necessary to reach accuracy a depends on a; the natural choice of a = a max /2 may be too low to be informative; etc.). Algorithm speed may be more important when exploring larger spaces, where reaching the optimum can require more compute than is available. We saw an example of this in the SP-III space, where evolution stood out ( <ref type="figure" target="#fig_6">Figure 6</ref>, bottom-right). Therefore, future work could explore evolving on even larger spaces.</p><p>Model speed. The speed of individual models produced is also relevant. <ref type="figure">Figure 4</ref> demonstrated that evolved models are faster (lower FLOPs). We speculate that asynchronous evolution may be reducing the FLOPs because it is indirectly optimizing for speed even when training for a fixed number of epochs: fast models may do well because they "reproduce" quickly even if they initially lack the higher accuracy of their slower peers. Verifying this speculation could be the subject of future work. As mentioned in the Related Work section, in this work we only considered asynchronous algorithms (as opposed to generational evolutionary methods) to ensure high resource utilization. Future work may explore how asynchronous and generational algorithms compare with regard to model accuracy.</p><p>Benefits of aging evolution. Aging evolution seemed advantageous in additional small-compute-scale experiments, shown in <ref type="figure" target="#fig_7">Figure 7</ref> and presented in more detail in Supplement B. These were carried out on CPU instead of GPU, and used a gray-scale version of CIFAR-10, to reduce compute requirements. In the supplement, we also show that these results tend to hold when varying the dataset or the search space.  Understanding aging evolution and regularization. We can speculate that aging may help navigate the training noise in evolutionary experiments, as follows. Noisy training means that models may sometimes reach high accuracy just by luck. In non-aging evolution (NAE, i.e. standard tournament selection), such lucky models may remain in the population for a long time-even for the whole experiment. One lucky model, therefore, can produce many children, caus-ing the algorithm to focus on it, reducing exploration. Under aging evolution (AE), on the other hand, all models have a short lifespan, so the population is wholly renewed frequently, leading to more diversity and more exploration. In addition, another effect may be in play, which we describe next. In AE, because models die quickly, the only way an architecture can remain in the population for a long time is by being passed down from parent to child through the generations. Each time an architecture is inherited it must be re-trained. If it produces an inaccurate model when retrained, that model is not selected by evolution and the architecture disappears from the population. The only way for an architecture to remain in the population for a long time is to re-train well repeatedly. In other words, AE can only improve a population through the inheritance of architectures that re-train well. (In contrast, NAE can improve a population by accumulating architectures/models that were lucky when they trained the first time). That is, AE is forced to pay attention to architectures rather than models. In other words, the addition of aging involves introducing additional information to the evolutionary process: architectures should retrain well. This additional information prevents overfitting to the training noise, which makes it a form of regularization in the broader mathematical sense 3 . Regardless of the exact mechanism, in Supplement C we perform experiments to verify the plausibility of the conjecture that aging helps navigate noise. There we construct a toy search space where the only difficulty is a noisy evaluation. If our conjecture is true, AE should be better in that toy space too. We found this to be the case. We leave further verification of the conjecture to future work, noting that theoretical results may prove useful here.</p><p>Simplicity of aging evolution. A desirable feature of evolutionary algorithms is their simplicity. By design, the application of a mutation causes a random change. The process of constructing new architectures, therefore, is entirely random. What makes evolution different from random search is that only the good models are selected to be mutated. This selection tends to improve the population over time. In this sense, evolution is simply "random search plus selection". In outline, the process can be described briefly: "keep a population of N models and proceed in cycles: at each cycle, copymutate the best of S random models and kill the oldest in the population". Implementation-wise, we believe the methods of this paper are sufficient for a reader to understand evolution. The sophisticated nature of the RL alternative introduces complexity in its implementation: it requires backpropagation and poses challenges to parallelization <ref type="bibr" target="#b36">[37]</ref>. Even different implementations of the same algorithm have been shown to produce different results <ref type="bibr" target="#b20">[21]</ref>. Finally, evolution is also simple in that it has few meta-parameters, most of which do not need tuning <ref type="bibr" target="#b35">[36]</ref>. In our study, we only adjusted 2 meta-parameters and only through a handful of attempts (see Methods Details section). In contrast, note that the RL baseline requires training an agent/controller which is often itself a neural network with many weights (such as an LSTM), and its optimization has more meta-parameters to adjust: learning rate schedule, greediness, batching, replay buffer, etc. (These meta-parameters are all in addition to the weights and training parameters of the image classifiers being searched, which are present in both approaches.) It is possible that through careful tuning, RL could be made to produce even better models than evolution, but such tuning would likely involve running many experiments, making it more costly. Evolution did not require much tuning, as described. It is also possible that random search would produce equally good models if run for a very long time, which would be very costly.</p><p>Interpreting architecture search. Another important direction for future work is that of analyzing architecturesearch experiments (regardless of the algorithm used) to try to discover new neural network design patterns. Anecdotally, for example, we found that architectures with high output vertex fan-in (number of edges into the output vertex) tend to be favored in all our experiments. In fact, the models in the final evolved populations have a mean fan-in value that is 3 standard deviations above what would be expected from randomly generated models. We verified this pattern by training various models with different fan-in values and the results confirm that accuracy increases with fan-in, as had been found in ResNeXt <ref type="bibr" target="#b47">[48]</ref>. Discovering broader patterns may require designing search spaces specifically for this purpose.</p><p>Additional AmoebaNets. Using variants of the evolutionary process described, we obtained three additional models, which we named AmoebaNet-B, AmoebaNet-C, and AmoebaNet-D. We describe these models and the process that led to them in detail in Supplement D, but we summarize here. AmoebaNet-B was obtained through through platform-aware architecture search over a larger version of the NASNet space. AmoebaNet-C is simply a model that showed promise early on in the above experiments by reaching high accuracy with relatively few parameters; we mention it here for completeness, as it has been referenced in other work <ref type="bibr" target="#b10">[11]</ref>. AmoebaNet-D was obtained by manually extrapolating the evolutionary process and optimizing the resulting architecture for training speed. It is very efficient: AmoebaNet-D won the Stanford DAWNBench competition for lowest training cost on ImageNet <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>This paper used an evolutionary algorithm to discover image classifier architectures. Our contributions are the following:</p><p>? We proposed aging evolution, a variant of tournament selection by which genotypes die according to their age, favoring the young. This improved upon standard tournament selection while still allowing for efficiency at scale through asynchronous population updating. We opensourced the code. <ref type="bibr" target="#b3">4</ref> We also implemented simple muta-tions that permit the application of evolution to the popular NASNet search space. ? We presented the first controlled comparison of algorithms for image classifier architecture search in a case study of evolution, RL and random search. We showed that evolution had somewhat faster search speed and stood out in the regime of scarcer resources / early stopping. Evolution also matched RL in final model quality, employing a simpler method. ? We evolved AmoebaNet-A ( <ref type="figure">Figure 5</ref>), a competitive image classifier. On ImageNet, it is the first evolved model to surpass hand-designs. Matching size, AmoebaNet-A has comparable accuracy to top image-classifiers discovered with other architecture-search methods. At large size, it sets a new state-of-the-art accuracy. We open-sourced code and checkpoint. <ref type="bibr" target="#b4">5</ref> .</p><p>In this supplement, we will extend the comparison between evolution and reinforcement learning (RL) from the Results Section. Evolutionary algorithms and RL have been applied recently to the field of architecture search. Yet, comparison is difficult because studies tend to use novel search spaces, preventing direct attribution of the results to the algorithm. For example, the search space may be small instead of the algorithm being fast. The picture is blurred further by the use of different training techniques that affect model accuracy <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b45">46]</ref>, different definitions of FLOPs that affect model compute cost <ref type="bibr" target="#b5">6</ref> and different hardware platforms that affect algorithm run-time <ref type="bibr" target="#b6">7</ref> . Accounting for all these factors, we will compare the two approaches in a variety of image classification contexts. To achieve statistical confidence, we will present repeated experiments without sampling bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setup</head><p>All evolution and RL experiments used the NASNet search space design <ref type="bibr" target="#b53">[54]</ref>. Within this design, we define three concrete search spaces that differ in the number of pairwise combinations (C) and in the number of ops allowed (see Methods Section). In order of increasing size, we will refer to them as SP-I (e.g. <ref type="figure" target="#fig_8">Figure A-1f)</ref>, SP-II, and SP-III (e.g. <ref type="figure" target="#fig_8">Figure A-1g</ref>). SP-I is the exact variant used in the main text and in the study that we use as our baseline <ref type="bibr" target="#b53">[54]</ref>. SP-II increases the allowed ops from 8 to 19 (identity; 1x1 and 3x3 convs.; 3x3, 5x5 and 7x7 sep. convs.; 2x2 and 3x3 avg. pools; 2x2 min pool.; 2x2 and 3x3 max pools; 3x3, 5x5 and 7x7 dil. sep. convs.; 1x3 then 3x1 conv.; 1x7 then 7x1 conv.; 3x3 dil. conv. with rates 2, 4 and 6). SP-III allows for larger tree structures within the cells (C=15, same 19 ops). The evolutionary algorithm is the same as that in the main text. The RL algorithm is the one used in the baseline study. We chose this baseline because, when we began, it had obtained the most accurate results on CIFAR-10, a popular dataset for image classifier architecture search.</p><p>We ran evolution and RL experiments for comparison purposes at different compute scales, always ensuring both approaches used identical conditions. In particular, evolution and RL used the same code for network construction, training and evaluation. The experiments in this supplement were performed at a smaller compute scale than in the main text, to reduce resource usage: we used gray-scale versions of popular datasets (e.g. "G-Imagenet" instead of ImageNet), we ran on CPU instead of GPU and trained relatively small models (F=8, see Methods Details in main text) for only 4 epochs. Where unstated, the experiments ran on SP-I and G-CIFAR. <ref type="bibr" target="#b5">6</ref> For example, see https://stackoverflow.com/ questions/329174/what-is-flop-s-and-is-ita-good-measure-of-performance. <ref type="bibr" target="#b6">7</ref> A Tesla P100 can be twice as fast as a K40, for example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Findings</head><p>We first optimized the meta-parameters for evolution and for RL by running experiments with each algorithm, repeatedly, under each condition ( <ref type="figure" target="#fig_8">Figure A-1a)</ref>. We then compared the algorithms in 5 different contexts by swapping the dataset or the search space ( <ref type="figure" target="#fig_8">Figure A-1b)</ref>. Evolution was either better than or equal to RL, with statistical significance. The best contexts for evolution and for RL are shown in more detail in <ref type="figure" target="#fig_8">Figures A-1c</ref> and A-1d, respectively. They show the progress of 5 repeats of each algorithm. The initial speed of evolution is noticeable, especially in the largest search space (SP-III). <ref type="figure" target="#fig_8">Figures A-1f</ref> and A-1g illustrate the top architectures from SP-I and SP-III, respectively. Regardless of context, <ref type="figure" target="#fig_8">Figure A-1e</ref> indicates that accuracy under evolution increases significantly faster than RL at the initial stage. This stage was not accelerated by higher RL learning rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outcome</head><p>The main text provides a comparison between algorithms for image classifier architecture search in the context of the SP-I search space on CIFAR-10, at scale. This supplement extends those results, varying the dataset and the search space by running many small experiments, confirming the conclusions of the main text.  , so the cell is replicated three times; i.e. the left two-thirds of the diagram (grayed out) are constrained to mirror the right third. This is in contrast with the vastly larger SP-III search space of (g), where a bigger, unconstrained construct without replication (N=1) is explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplement B: Aging and Non-Aging Evolution Motivation</head><p>In this supplement, we will extend the comparison between aging evolution (AE) and standard tournament selection / non-aging evolution (NAE). As was described in the Methods Section, the evolutionary algorithm used in this paper keeps the population size constant by always removing the oldest model whenever a new one is added; we will refer to this algorithm as AE. A recent paper used a similar method but kept the population size constant by removing the worst model in each tournament <ref type="bibr" target="#b35">[36]</ref>; we will refer to that algorithm as NAE. This supplement will show how these two algorithms compare in a variety of contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setup</head><p>The search spaces and datasets were the same as in Supplement A. We performed experiments in 5 different search spacedataset contexts. In each context, we ran several repeats of evolutionary search using NAE and AE ( <ref type="figure" target="#fig_8">Figure B-1</ref>). Under 4 of the 5 contexts, AE resulted in statistically significant higher accuracy at the end of the runs, on average. The exception was the G-ImageNet search space, where the experiments were extremely short due to the compute demands of training on so much data using only CPUs. Interestingly, in the two contexts where the search space was bigger (SP-II and SP-III), all AE runs did better than all NAE runs.</p><p>Additionally, we performed three experiments comparing AE and NAE at scale, under the same conditions as in the main text. The results, which can be seen in <ref type="figure">Figure B</ref>  <ref type="bibr" target="#b35">[36]</ref>. These accuracy values are not meaningful in absolute terms, as the models need to be augmented to reach their maximum accuracy, as described in the Methods Section).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outcome</head><p>The Discussion Section in the main text suggested that AE tends to perform better than NAE across various parameters for one fixed search space-dataset context. Such robustness is desirable for computationally demanding architecture search experiments, where we cannot always afford many runs to optimize the meta-parameters. This supplement extends those results to show that the conclusion holds across various contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplement C: Aging Evolution in Toy Search Space Motivation</head><p>As indicated in the Discussion Section, we suspect that aging may help navigate the noisy evaluation in an evolution experiment. We leave verification of this suspicion to future work, but for motivation we provide here a sanity check for it. We construct a toy search space in which the only difficulty is a noisy evaluation. Within this toy search space, we will see that aging evolution outperforms non-aging evolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setup</head><p>The toy search space we use here does not involve any neural networks. The goal is to evolve solutions to a very simple, single-optimum, D-dimensional, noisy optimization problem with a signal-to-noise ratio matching that of our neuroevolution experiments.</p><p>The search space used is the set of vertices of a Ddimensional unit cube. A specific vertex is "analogous" to a neural network architecture in a real experiment. A vertex can be represented as a sequence of its coordinates (0s and 1s)-a bit-string. In other words, this bit-string constitutes a simulated architecture. In a real experiment, training and evaluating an architecture yields a noisy accuracy. Likewise, in this toy search space, we assign a noisy simulated accuracy (SA) to each cube vertex. The SA is the fraction of coordinates that are zero, plus a small amount of Gaussian noise (? = 0, ? = 0.01, matching the observed noise for neural networks). Thus, the goal is to get close to the optimum, the origin. The sample complexity used was 10k. This space is helpful because an experiment completes in milliseconds.</p><p>This optimization problem can be seen as a simplification of the evolutionary search for the minimum of a multidimensional integer-valued paraboloid with bounded support, where the mutations treat the values along each coordinate categorically. If we restrict the domain along each direction to the set {0, 1}, we reduce the problem to the unit cube described above. The paraboloid's value at a cube corner is just the number of coordinates that are not zero. We mention this connection because searching for the minimum of a paraboloid seems like a more natural choice for a trivial problem ("trivial" compared to architecture search). The simpler unit cube version, however, was chosen because it permits faster computation.</p><p>We stress that these simulations are not intended to truly mimic architecture search experiments over the space of neural networks. We used them only as a testing ground for techniques that evolve solutions in the presence of noisy evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Findings</head><p>We found that optimized NAE and AE perform similarly in low-dimensional problems, which are easier. As the dimensionality (D) increases, AE becomes relatively better than NAE ( <ref type="figure" target="#fig_8">Figure C-1</ref> For each D, we optimized the metaparameters for NAE and AE independently. To do this, we carried out 100 simulations for each meta-parameter combination and averaged the outcomes. We plot here the optima found, together with ? 2 SEM error bars. The graph shows that in this toy search space, AE is never worse and is significantly better for larger D (note the broad range of the vertical axis).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outcome</head><p>The findings provide circumstantial evidence in favor of our suspicion that aging may help navigate noise (Discussion Section), suggesting that attempting to verify this with more generality may be an interesting direction for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplement D: Additional AmoebaNets Motivation</head><p>In the Discussion Section, we briefly mentioned three additional models, AmoebaNet-B, AmoebaNet-C, and AmoebaNet-D. While all three used the aging evolution algorithm presented the main text, there were some differences in the experimental setups: AmoebaNet-B was obtained through platform-aware architecture search; AmoebaNet-C was selected with a pareto-optimal criterion; and AmoebaNet-D involved multi-stage search, including manual extrapolation of the evolutionary process. Below we describe each of these models and the methods that produced them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setup</head><p>AmoebaNet-B was evolved by running experiments directly on Google TPUv2 hardware, since this was the target platform for its final evaluation. In the main text, the architecture had been discovered on GPU but the largest model was evaluated on TPUs. In contrast, here we perform the full process on TPUs. This architecture-aware approach allows the evolutionary search to optimize even hardware-dependent aspects of the final accuracy, such as optimizations carried out by the compiler. The search setup was as in the main text, except that it used the larger SP-II space of Supplement A and trained larger models (F=32) for longer (50 epochs). The se-lection of the top model was as follows. We picked from the experiment K=100 models. To do this, we binned the models by their number of parameters to cover the range, using B bins. From each bin, we took the top K/B models by validation accuracy. We then augmented all models to N=6 and F=32 and selected the one with the top validation accuracy.</p><p>AmoebaNet-C was discovered in the experiments described in the main text (see Methods and Methods Details sections). Instead of selecting the highest validation accuracy at the end of the experiments (as done in the main text), we picked a promising model while the experiments were still ongoing. This was done entirely for expediency, to be able to study a model while we waited for the search to complete. AmoebaNet-C was promising in that it stood out in a pareto-optimal sense: it was a high-accuracy outlier for its relatively small number of parameters. As opposed to all other architectures, AmoebaNet-C was selected based on CIFAR-10 test accuracy, because it was intended to only be benchmarked on ImageNet. This process was less methodical than the one used in the main text but because the model has been cited in the literature, we include it here for completeness.</p><p>AmoebaNet-D was obtained by manually modifying AmoebaNet-B by extrapolating evolution. To do this, we studied the progress of an experiment and identified which    <ref type="bibr" target="#b53">[54]</ref> and diagrams for the cell architectures discovered by evolution: AmoebaNet-B, AmoebaNet-C, and AmoebaNet-D. The three normal cells are on the top row and the three reduction cells are on the bottom row. The labeled activations or hidden states correspond to the cell inputs ("0" and "1") and the cell output ("7"). mutations were still causing improvements in fitness at the later stages of the process. By inspection, we found these mutations to be: replacing a 3x3 separable (sep.) convolution (conv.) with a 1x7 followed by 7x1 conv. in the normal cell, replacing a 5x5 sep. conv. by a 1x7 followed by 7x1 conv. in the reduction cell, and replacing a 3x3 sep. conv. with 3x3 avg. pool in the reduction cell. Additionally, we reduced the numeric precision from 32-bit to 16-bit floats, and set a learning rate schedule of step-wise decay, reducing by a factor of 0.88 every epoch. We trained for 35 epochs in total. To submit to Stanford DAWNBench (see Outcome section), we used N=2 and F=256.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Findings</head><p>Figure D-1 presents all three model architectures. We refrain from benchmarking these here. Instead, in the Outcome Section below, we will refer the reader to results presented elsewhere.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outcome</head><p>In this supplement we have described additional evolutionary experiments that led to three new models. Such experiments were intended mainly to search for better models. Due to the resource-intensive nature of these methods, we forewent ablations and baselines in this supplement. For a more empirically rigorous approach, please refer to the process that produced AmoebaNet-A in the main text.</p><p>AmoebaNet-B had set a new state of the art on CIFAR-10 (2.13% test error) in a previous preprint of this paper 8 after being trained with cutout, but has since been superseded.</p><p>AmoebaNet-C had set the previous state-of-the-art top-1 accuracy on ImageNet after being trained with advanced data augmentation techniques in <ref type="bibr" target="#b10">[11]</ref>.</p><p>AmoebaNet-D won the Stanford DAWNBench competition for lowest training cost on ImageNet. The goal of this competition category was to minimize the monetary cost of training a model to 93% top-5 accuracy. AmoebaNet-D costs $49.30 to train. This was 16% better than the second-best model, which was ResNet and which trained on the same hardware. The results were published in <ref type="bibr" target="#b8">[9]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>6 Figure 1 :</head><label>61</label><figDesc>NASNet Search Space</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of the two mutation types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 2 (bottom) shows an example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Time-course of 5 identical large-scale experiments for each algorithm (evolution, RL, and RS), showing accuracy before augmentation on CIFAR-10. All experiments were stopped when 20k models were evaluated, as done in the baseline study. Note this plot does not show the compute cost of models, which was higher for the RL ones.the Methods. Final augmented models from 5 identical architecture-search experiments for each algorithm, on CIFAR-10. Each marker corresponds to the top models from one experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>2 Figure 5 :</head><label>25</label><figDesc>AmoebaNet-A architecture. The overall model<ref type="bibr" target="#b53">[54]</ref> (LEFT) and the AmoebaNet-A normal cell (MIDDLE) and reduction cell (RIGHT).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>TOP: Comparison of the final model accuracy in five different contexts, from left to right: G-CIFAR/SP-I, G-CIFAR/SP-II, G-CIFAR/SP-III, MNIST/SP-I and G-ImageNet/SP-I. Each circle marks the top test accuracy at the end of one experiment. BOTTOM: Search progress of the experiments in the case of G-CIFAR/SP-II (LEFT, best for RL) and G-CIFAR/SP-III (RIGHT, best for evolution).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Small-compute-scale comparison between our aging tournament selection variant and the non-aging variant, for different population sizes (P) and sample sizes (S), showing that aging tends to be beneficial (most markers are above the y = x line).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure A- 1 :</head><label>1</label><figDesc>Evolution and RL in different contexts. Plots show repeated evolution (orange) and RL (blue) experiments side-byside. (a) Summary of hyper-parameter optimization experiments on G-CIFAR. We swept the learning rate (lr) for RL (left) and the population size (P) and sample size (S) for evolution (right). We ran 5 experiments (circles) for each scenario. The vertical axis measures the mean validation accuracy (MVA) of the top 100 models in an experiment. Superposed on the raw data are ? 2 SEM error bars. From these results, we selected best meta-parameters to use in the remainder of this figure.(b) We assessed robustness by running the same experiments in 5 different contexts, spanning different datasets and search spaces: G-CIFAR/SP-I, G-CIFAR/SP-II, G-CIFAR/SP-III, MNIST/SP-I and G-ImageNet/SP-I, shown from left to right. These experiments ran to 20k models. The vertical axis measures the mean testing accuracy (MTA) of the top 100 models (selected by validation accuracy). (c) and (d) show a detailed view of the progress of the experiments in the G-CIFAR/SP-II and G-CIFAR/SP-III contexts, respectively. The horizontal axes indicate the number of models (m) produced as the experiment progresses. (e) Resourceconstrained settings may require stopping experiments early. At 5k models, evolution performs better than RL in all 5 contexts. (f) and (g) show a stack of normal cells of the best model found for G-CIFAR in the SP-I and SP-III search spaces, respectively. The "h" labels some of the hidden states. The ops ("avg 3x3", etc.) are listed in full form in the text. Data flows from left to right. See the baseline study for a detailed description of these diagrams. In (f), N=3 (see Methods section)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure B- 1 :</head><label>1</label><figDesc>A comparison of NAE and AE under 5 different contexts, spanning different datasets and search spaces: G-CIFAR/SP-I, G-CIFAR/SP-II, G-CIFAR/SP-III, MNIST/SP-I and G-ImageNet/SP-I, shown from left to right. For each context, we show the final MTA of a few NAE and a few AE experiments (circles) in adjacent columns. We superpose ? 2 SEM error bars, where SEM denotes the standard error of the mean. The first context contains many repeats with identical meta-parameters and their MTA values seem normally distributed (Shapiro-Wilks test). Under this normality assumption, the error bars represent 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>- 2 ,Figure</head><label>2</label><figDesc>provide some verification that observations from smaller CPU experiments in the previous paragraph generalize to the large-compute regime. B-2: A comparison of AE and NAE at scale. These experiments use the same conditions as the main text (including dataset, search space, resources and duration). From top to bottom: an AE experiment with good AE metaparameters from Supplement A, an analogous NAE experiment, and an NAE experiment with the meta-parameters used in a recent study</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure C- 1 :</head><label>1</label><figDesc>Results in the toy search space. The graph summarizes thousands of evolutionary search simulations. The vertical axis measures the simulated accuracy (SA) and the horizontal axis the dimensionality (D) of the problem, a measure of its difficulty.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure D- 1 :</head><label>1</label><figDesc>Architectures of overall model and cells. From left to right: outline of the overall model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>CIFAR-10 testing set results for AmoebaNet-A, compared to top model reported in the baseline study.</figDesc><table><row><cell>Model</cell><cell cols="2"># Params Test Error (%)</cell></row><row><cell>NASNet-A (baseline)</cell><cell>3.3 M</cell><cell>3.41</cell></row><row><cell>AmoebaNet-A (N=6, F=32)</cell><cell>2.6 M</cell><cell>3.40 ? 0.08</cell></row><row><cell>AmoebaNet-A (N=6, F=36)</cell><cell>3.2 M</cell><cell>3.34 ? 0.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>ImageNet classification results for AmoebaNet-A compared to hand-designs (top rows) and other automated methods (middle rows). The evolved AmoebaNet-A architecture (bottom rows) reaches the current state of the art (SOTA) at similar model sizes and sets a new SOTA at a larger size. All evolution-based approaches are marked with a * . We omitted Squeezeand-Excite-Net because it was not benchmarked on the same ImageNet dataset version.</figDesc><table><row><cell>Model</cell><cell cols="3"># Parameters # Multiply-Adds Top-1 / Top-5 Accuracy (%)</cell></row><row><cell>Incep-ResNet V2 [44]</cell><cell>55.8M</cell><cell>13.2B</cell><cell>80.4 / 95.3</cell></row><row><cell>ResNeXt-101 [48]</cell><cell>83.6M</cell><cell>31.5B</cell><cell>80.9 / 95.6</cell></row><row><cell>PolyNet [51]</cell><cell>92.0M</cell><cell>34.7B</cell><cell>81.3 / 95.8</cell></row><row><cell>Dual-Path-Net-131 [7]</cell><cell>79.5M</cell><cell>32.0B</cell><cell>81.5 / 95.8</cell></row><row><cell>GeNet-2 [47]  *</cell><cell>156M</cell><cell>-</cell><cell>72.1 / 90.4</cell></row><row><cell>Block-QNN-B [52]  *</cell><cell>-</cell><cell>-</cell><cell>75.7 / 92.6</cell></row><row><cell>Hierarchical [30]  *</cell><cell>64M</cell><cell>-</cell><cell>79.7 / 94.8</cell></row><row><cell>NASNet-A [54]</cell><cell>88.9M</cell><cell>23.8B</cell><cell>82.7 / 96.2</cell></row><row><cell>PNASNet-5 [29]</cell><cell>86.1M</cell><cell>25.0B</cell><cell>82.9 / 96.2</cell></row><row><cell>AmoebaNet-A (N=6, F=190)  *</cell><cell>86.7M</cell><cell>23.1B</cell><cell>82.8 / 96.1</cell></row><row><cell>AmoebaNet-A (N=6, F=448)  *</cell><cell>469M</cell><cell>104B</cell><cell>83.9 / 96.6</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://colab.research.google.com/github/ google-research/google-research/blob/master/ evolution/regularized_evolution_algorithm/ regularized_evolution.ipynb</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://en.wikipedia.org/wiki/ Regularization_(mathematics)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://colab.research.google.com/github/ google-research/google-research/blob/master/ evolution/regularized_evolution_algorithm/ regularized_evolution.ipynb</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://tfhub.dev/google/imagenet/ amoebanet_a_n18_f448/classification/1</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">Version 1 with same title on arXiv: https://arxiv.org/ pdf/1802.01548v1.pdf</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We wish to thank Megan Kacholia, Vincent Vanhoucke, Xiaoqiang Zheng and especially Jeff Dean for their support and valuable input; Chris Ying for his work helping tune Amoe-baNet models and for his help with specialized hardware, Barret Zoph and Vijay Vasudevan for help with the code and experiments used in their paper <ref type="bibr" target="#b53">[54]</ref>, as well as Jiquan Ngiam, Jacques Pienaar, Arno Eigenwillig, Jianwei Xie, Derek Murray, Gabriel Bender, Golnaz Ghiasi, Saurabh Saxena and Jie Tan for other coding contributions; Jacques Pienaar, Luke Metz, Chris Ying and Andrew Selle for manuscript comments, all the above and Patrick Nguyen, Samy Bengio, Geoffrey Hinton, Risto Miikkulainen, Jeff Clune, Kenneth Stanley, Yifeng Lu, David Dohan, David So, David Ha, Vishy Tirumalashetty, Yoram Singer, and Ruoming Pang for helpful discussions; and the larger Google Brain team.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An evolutionary algorithm that constructs recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Angeline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Pollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Neural Networks</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Designing neural network architectures using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Accelerating neural architecture search using performance prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Random search for hyperparameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Smash: one-shot model architecture search through hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Efficient architecture search by network transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dual path networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multicolumn deep neural networks for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ciregan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Analysis of dawnbench, a time-toaccuracy machine learning performance benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bailis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Re</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01427</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adanet: Adaptive structural learning of artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gonzalvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autoaugment</surname></persName>
		</author>
		<title level="m">Learning augmentation policies from data. arXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Domhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Simple and efficient architecture search for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<title level="m">Neural architecture search: A survey. arXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The cascade-correlation learning architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Fahlman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lebiere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient and robust automated machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eggensperger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Neuroevolution: from architectures to learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Floreano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>D?rr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mattiussi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Evolutionary Intelligence</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A comparative analysis of selection schemes used in genetic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FOGA</title>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning that matters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Alps: the age-layered population structure for reducing the problem of premature convergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Hornby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GECCO</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gpipe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.06965</idno>
		<title level="m">Efficient training of giant neural networks using pipeline parallelism</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Falkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<title level="m">Learning curve prediction with bayesian neural networks. ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, U. of Toronto</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progressive neural architecture search. ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hierarchical representations for efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Towards automatically-tuned neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Automatic Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Francon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Navruzyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Duffy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hodjat</surname></persName>
		</author>
		<title level="m">Evolving deep neural networks. arXiv</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Designing neural networks using genetic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">F</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">U</forename><surname>Hegde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICGA</title>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Negrinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gordon</surname></persName>
		</author>
		<title level="m">Deeparchitect: Automatically designing and training deep architectures. arXiv</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Faster discovery of neural architectures by searching for paths in a large model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR Workshop</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Large-scale evolution of image classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L</forename><surname>Suematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<title level="m">Evolution strategies as a scalable alternative to reinforcement learning. arXiv</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Convolutional neural fabrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Falsepositive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Simonsohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Real-time neuroevolution in the nero video game</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>TEVC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Evolving neural networks through augmenting topologies. Evol. Comput</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A genetic programming approach to designing convolutional neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Suganuma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shirakawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nagao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GECCO</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Regularization of neural networks using dropconnect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Le</forename><surname>Cun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Genetic CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Evolving artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Polynet: A pursuit of structural diversity in very deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Practical network blocks design with q-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
