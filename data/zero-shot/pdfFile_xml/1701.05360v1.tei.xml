<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">3D Face Morphable Models &quot;In-the-Wild&quot;</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Booth</surname></persName>
							<email>james.booth@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Epameinondas</forename><surname>Antonakos</surname></persName>
							<email>e.antonakos@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stylianos</forename><surname>Ploumpis</surname></persName>
							<email>s.ploumpis@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Trigeorgis</surname></persName>
							<email>g.trigeorgis@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Panagakis</surname></persName>
							<email>i.panagakis@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
							<email>s.zafeiriou@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">3D Face Morphable Models &quot;In-the-Wild&quot;</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>3D Morphable Models (3DMMs) are powerful statistical models of 3D facial shape and texture, and among the stateof-the-art methods for reconstructing facial shape from single images. With the advent of new 3D sensors, many 3D facial datasets have been collected containing both neutral as well as expressive faces. However, all datasets are captured under controlled conditions. Thus, even though powerful 3D facial shape models can be learnt from such data, it is difficult to build statistical texture models that are sufficient to reconstruct faces captured in unconstrained conditions ("in-the-wild"). In this paper, we propose the first, to the best of our knowledge, "in-the-wild" 3DMM by combining a powerful statistical model of facial shape, which describes both identity and expression, with an "in-the-wild" texture model. We show that the employment of such an "in-thewild" texture model greatly simplifies the fitting procedure, because there is no need to optimize with regards to the illumination parameters. Furthermore, we propose a new fast algorithm for fitting the 3DMM in arbitrary images. Finally, we have captured the first 3D facial database with relatively unconstrained conditions and report quantitative evaluations with state-of-the-art performance. Complementary qualitative reconstruction results are demonstrated on standard "in-the-wild" facial databases. An open source implementation of our technique is released as part of the Menpo Project [1].</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>During the past few years, we have witnessed significant improvements in various face analysis tasks such as face detection <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b43">43]</ref> and 2D facial landmark localization on static images <ref type="bibr" target="#b41">[41,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b37">37]</ref>. This is primarily attributed to the fact that the community has made a considerable effort to collect and annotate facial images captured under unconstrained conditions <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b32">32]</ref> (commonly referred to as "in-the-wild") and to the discriminative methodologies that can capitalise on the availability of such large amount of data. Nevertheless, discriminative techniques cannot be applied for 3D facial shape estimation "in-the-wild", due to lack of ground-truth data.</p><p>3D facial shape estimation from single images has attracted the attention of many researchers the past twenty years. The two main lines of research are (i) fitting a 3D Morphable Model (3DMM) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> and (ii) applying Shape from Shading (SfS) techniques <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b23">23]</ref>. The 3DMM fitting proposed in the work of Blanz and Vetter <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> was among the first model-based 3D facial recovery approaches. The method requires the construction of a 3DMM which is a statistical model of facial texture and shape in a space where there are explicit correspondences. The first 3DMM was built using 200 faces captured in well-controlled conditions displaying only the neutral expression. That is the reason why the method was only shown to work on real-world, but not "in-the-wild", images. State-of-the-art SfS techniques capitalise on special multi-linear decompositions that find an approximate spherical harmonic decomposition of the illumination. Furthermore, in order to benefit from the large availability of "in-the-wild" images, these methods jointly reconstruct large collections of images. Nevertheless, even thought the results of <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b23">23]</ref> are quite interesting, given that there is no prior of the facial surface, the methods only recover 2.5D representations of the faces and particular smooth approximations of the facial normals.</p><p>3D facial shape recovery from a single image under "inthe-wild" conditions is still an open and challenging problem in computer vision mainly due to the fact that:</p><p>? The general problem of extracting the 3D facial shape from a single image is an ill-posed problem which is notoriously difficult to be solved without the use of any statistical priors for the shape and texture of faces. That is, without prior knowledge regarding the shape of the object at-hand there are inherent ambiguities present in the problem. The pixel intensity at a location in an image is the result of a complex combination of the underlying shape of the object, the surface albedo and normal characteristics, camera parameters and the arrangement of scene lighting and other objects in the scene. Hence, there are potentially infinite solutions to the problem.</p><p>? Learning statistical priors of the 3D facial shape and texture for "in-the-wild" images is currently very difficult by using modern acquisition devices. That is, even though there is a considerable improvement in 3D acquisition devices, they still cannot operate in arbitrary conditions. Hence, all the current 3D facial databases have been captured in controlled conditions.</p><p>With the available 3D facial data, it is feasible to learn a powerful statistical model of the facial shape that generalises well for both identity and expression <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b13">14]</ref>. However, it is not possible to construct a statistical model of the facial texture that generalises well for "in-the-wild" images and is, at the same time, in correspondence with the statistical shape model. That is the reason why current stateof-the-art 3D face reconstruction methodologies rely solely on fitting a statistical 3D facial shape prior on a sparse set of landmarks <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b17">17]</ref>.</p><p>In this paper, we make a number of contributions that enable the use of 3DMMs for "in-the-wild" face reconstruction ( <ref type="figure" target="#fig_0">Fig. 1</ref>). In particular, our contributions are:</p><p>? We propose a methodology for learning a statistical texture model from "in-the-wild" facial images, which is in full correspondence with a statistical shape prior that exhibits both identity and expression variations. Motivated by the success of feature-based (e.g., HOG <ref type="bibr" target="#b16">[16]</ref>, SIFT <ref type="bibr" target="#b26">[26]</ref>) Active Appearance Models (AAMs) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> we further show how to learn featurebased texture models for 3DMMs. We show that the advantage of using the "in-the-wild" feature-based texture model is that the fitting strategy gets simplified since there is not need to optimize with respect to the illumination parameters.</p><p>? By capitalising on the recent advancements in fitting statistical deformable models <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b1">2]</ref>, we propose a novel and fast algorithm for fitting "in-the-wild" 3DMMs. Furthermore, we make the implementation of our algorithm publicly available, which we believe can be of great benefit to the community, given the lack of robust open-source implementations for fitting 3DMMs.</p><p>? Due to lack of ground-truth data, the majority of the 3D face reconstruction papers report only qualitative results. In this paper, in order to provide quantitative evaluations, we collected a new dataset of 3D facial surfaces, using Kinect Fusion <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b29">29]</ref>, which has many "in-the-wild" characteristics, even though it is captured indoors.</p><p>?</p><p>We release an open source implementation of our technique as part of the Menpo Project. <ref type="bibr" target="#b0">[1]</ref> The remainder of the paper is structured as follows. In Section 2 we elaborate on the construction of our "inthe-wild" 3DMM, whilst in Section 3 we outline the proposed optimization for fitting "in-the-wild" images with our model. Section 4 describes our new dataset, the first of its kind, to provide images with a ground-truth 3D facial shape that exhibit many "in-the-wild" characteristics. We outline a series of quantitative and qualitative experiments in Section 5, and end with conclusions in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Model Training</head><p>A 3DMM consists of three parametric models: the shape, camera and texture models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Shape Model</head><p>Let us denote the 3D mesh (shape) of an object with N vertexes as a 3N ? 1 vector  orthonormal basis after keeping the first n s principal components. This model can be used to generate novel 3D shape instances using the function S :</p><formula xml:id="formula_0">s = x T 1 , . . . , x T N T = [x 1 , y 1 , z 1 , . . . , x N , y N , z N ] T (1) where x i = [x i , y i , z i ] T are</formula><formula xml:id="formula_1">R ns ? R 3N as S(p) =s + U s p<label>(2)</label></formula><p>where p = [p 1 , . . . , p ns ] T are the n s shape parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Camera Model</head><p>The purpose of the camera model is to map (project) the object-centered Cartesian coordinates of a 3D mesh instance s into 2D Cartesian coordinates on an image plane. In this work, we employ a pinhole camera model, which utilizes a perspective transformation. However, an orthographic projection model can also be used in the same way.</p><p>Perspective projection. The projection of a 3D point x = [x, y, z] T into its 2D location in the image plane x = [x , y ] T involves two steps. First, the 3D point is rotated and translated using a linear view transformation, under the assumption that the camera is still</p><formula xml:id="formula_2">[v x , v y , v z ] T = R v x + t v (3) where R v ? R 3?3 and t v = [t x , t y , t z ]</formula><p>T are the 3D rotation and translation components, respectively. Then, a nonlinear perspective transformation is applied as</p><formula xml:id="formula_3">x = f v z v x v y + c x c y<label>(4)</label></formula><p>where f is the focal length in pixel units (we assume that the x and y components of the focal length are equal) and</p><p>[c x , c y ] T is the principal point that is set to the image center.</p><p>Quaternions. We parametrize the 3D rotation with quaternions <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b40">40]</ref>. The quaternion uses four parameters q = [q 0 , q 1 , q 2 , q 3 ] T in order to express a 3D rotation as</p><formula xml:id="formula_4">R v = 2 ? ? 1 2 ? q 2 2 ? q 2 3 q 1 q 2 ? q 0 q 3 q 1 q 3 + q 0 q 2 q 1 q 2 + q 0 q 3 1 2 ? q 2 1 ? q 2 3 q 2 q 3 ? q 0 q 1 q 1 q 3 ? q 0 q 2 q 2 q 3 + q 0 q 1 1 2 ? q 2 1 ? q 2 2 ? ?</formula><p>(5) Note that by enforcing a unit norm constraint on the quaternion vector, i.e. q T q = 1, the rotation matrix constraints of orthogonality with unit determinant are withheld. Given the unit norm property, the quaternion can be seen as a three-parameter vector [q 1 , q 2 , q 3 ] T and a scalar</p><formula xml:id="formula_5">q 0 = 1 ? q 2 1 ? q 2 2 ? q 2 3 .</formula><p>Most existing works on 3DMM parametrize the rotation matrix R v using the three Euler angles that define the rotations around the horizontal, vertical and camera axes. Even thought Euler angles are more naturally interpretable, they have strong disadvantages when employed within an optimization procedure, most notably the solution ambiguity and the gimbal lock effect. Parametrization based on quaternions overcomes these disadvantages and further ensures computational efficiency, robustness and simpler differentiation.</p><p>Camera function. The projection operation performed by the camera model of the 3DMM can be expressed with the function P(s, c) : R 3N ? R 2N , which applies the transformations of Eqs. 3 and 4 on the points of provided 3D mesh s with</p><formula xml:id="formula_6">c = [f, q 1 , q 2 , q 3 , t x , t y , t z ] T<label>(6)</label></formula><p>being the vector of camera parameters with length n c = 7. For abbreviation purposes, we represent the camera model of the 3DMM with the function W : R ns,nc ? R 2N as</p><formula xml:id="formula_7">W(p, c) ? P (S(p), c)<label>(7)</label></formula><p>where S(p) is a 3D mesh instance using Eq. 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">"In-the-Wild" Feature-Based Texture Model</head><p>The generation of an "in-the-wild" texture model is a key component of the proposed 3DMM. To this end, we take advantage of the existing large facial "in-the-wild" databases that are annotated in terms of sparse landmarks. Assume that for a set of M "in-the-wild" images {I i } M 1 , we have access to the associated camera and shape parameters {p i , c i }. Let us also define a dense feature extraction function</p><formula xml:id="formula_8">F : R H?W ? R H?W ?C<label>(8)</label></formula><p>where C is the number of channels of the feature-based image. For each image, we first compute its feature-based representation as F i = F(I i ) and then use Eq. 7 to sample it at each vertex location to build back a vectorized texture</p><formula xml:id="formula_9">sample t i = F i (W(p i , c i )) ? R CN . This texture sample Figure 3.</formula><p>Building an ITW texture model will be nonsensical for some regions mainly due to selfocclusions present in the mesh projected in the image space</p><formula xml:id="formula_10">W(p i , c i ).</formula><p>To alleviate these issues, we cast a ray from the camera to each vertex and test for self-intersections with the triangulation of the mesh in order to learn a per-vertex occlusion mask m i ? R N for the projected sample. Let us create the matrix X = [t 1 , . . . , t M ] ? R CN ?M by concatenating the M grossly corrupted feature-based texture vectors with missing entries that are represented by the masks m i . To robustly build a texture model based on this heavily contaminated incomplete data, we need to recover a low-rank matrix L ? R CN ?M representing the clean facial texture and a sparse matrix E ? R CN ?M accounting for gross but sparse non-Gaussian noise such that X = L + E. To simultaneously recover both L and E from incomplete and grossly corrupted observations, the Principal Component Pursuit with missing values <ref type="bibr" target="#b34">[34]</ref> is solved arg min</p><formula xml:id="formula_11">L,E L * + ? E 1 s.t. P ? (X) = P ? (L + E),<label>(9)</label></formula><p>where ? * denotes the nuclear norm, ? 1 is the matrix 1norm and ? &gt; 0 is a regularizer. ? represents the set of locations corresponding to the observed entries of X (i.e., (i, j) ? ? if m i = m j = 1). Then, P ? (X) is defined as the projection of the matrix X on the observed entries ?, namely P ? (X) ij = x ij if (i, j) ? ? and P ? (X) ij = 0 otherwise. The unique solution of the convex optimization problem in Eq. 9 is found by employing an Alternating Direction Method of Multipliers-based algorithm <ref type="bibr" target="#b10">[11]</ref>.</p><p>The final texture model is created by applying PCA on the set of reconstructed feature-based textures acquired from the previous procedure. This results in {t, U t }, wher? t ? R CN is the mean texture vector and U t ? R CN ?nt is the orthonormal basis after keeping the first n t principal components. This model can be used to generate novel 3D feature-based texture instances with the function T : R nt ? R CN as</p><formula xml:id="formula_12">T (?) =t + U t ?<label>(10)</label></formula><p>where ? = [? 1 , . . . , ? nt ] T are the n t texture parameters.</p><p>Finally, an iterative procedure is used in order to refine the texture. That is, we started with the 3D fits provided by using only the 2D landmarks <ref type="bibr" target="#b21">[21]</ref>. Then, a texture model is learned using the above procedure. The texture model was used with the proposed 3DMM fitting algorithm on the same data and texture model was refined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model Fitting</head><p>We propose to fit the 3DMM on an input image using Gauss-Newton iterative optimization. To this end, herein, we first formulate the cost function and then present two optimization procedures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Cost Function</head><p>The overall cost function of the proposed 3DMM formulation consists of a texture-based term, an optional error term based on sparse 2D landmarks and optional regularization terms on the parameters.</p><p>Texture reconstruction cost. The main term of the optimization problem is the one that aims to estimate the shape, texture and camera parameters that minimize the 2 2 norm of the difference between the image feature-based texture that corresponds to the projected 2D locations of the 3D shape instance and the texture instance of the 3DMM. Let us denote by F = F(I) the feature-based representation with C channels of an input image I using Eq. 8. Then, the texture reconstruction cost is expressed as</p><formula xml:id="formula_13">arg min p,c,? F (W(p, c)) ? T (?) 2<label>(11)</label></formula><p>Note that F (W(p, c)) ? R CN denotes the operation of sampling the feature-based input image on the projected 2D locations of the 3D shape instance acquired by the camera model (Eq. 7).</p><p>Regularization. In order to avoid over-fitting effects, we augment the cost function with two optional regularization terms over the shape and texture parameters. Let us denote as ? s ? R ns?ns and ? t ? R nt?nt the diagonal matrices with the eigenvalues in their main diagonal for the shape and texture models, respectively. Based on the PCA nature of the shape and texture models, it is assumed that their parameters follow normal prior distributions, i.e. p ? N (0, ? s ) and ? ? N (0, ? t ). We formulate the regularization terms as the 2 2 of the parameters' vectors weighted with the corresponding inverse eigenvalues, i.e. arg min</p><formula xml:id="formula_14">p,? c s p 2 ? ?1 s + c t ? 2 ? ?1 t<label>(12)</label></formula><p>where c s and c t are constants that weight the contribution of the regularization terms in the cost function.</p><p>2D landmarks cost. In order to rapidly adapt the camera parameters in the cost of Eq. 11, we further expand the optimization problem with the term arg min p,c c l W l (p, c) ? s l 2 <ref type="bibr" target="#b12">(13)</ref> where s l = [x 1 , y 1 , . . . , x L , y L ] T denotes a set of L sparse 2D landmark points (L N ) defined on the image coordinate system and W l (p, c) returns the 2L ? 1 vector of 2D projected locations of these L sparse landmarks. Intuitively, this term aims to drive the optimization procedure using the selected sparse landmarks as anchors for which we have the optimal locations s l . This optional landmarks-based cost is weighted with the constant c l .</p><p>Overall cost function. The overall 3DMM cost function is formulated as the sum of the terms in Eqs. 11, 12, 13, i.e. arg min</p><formula xml:id="formula_15">p,c,? F (W(p, c)) ? T (?) 2 + c l W l (p, c) ? s l 2 + + c s p 2 ? ?1 s + c t ? 2 ? ?1 t<label>(14)</label></formula><p>The landmarks term as well as the regularization terms are optional and aim to facilitate the optimization procedure in order to converge faster and to a better minimum. Note that thanks to the proposed "in-the-wild" feature-based texture model, the cost function does not include any parametric illumination model similar to the ones in the relative literature <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, which greatly simplifies the optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Gauss-Newton Optimization</head><p>Inspired by the extensive literature in Lucas-Kanade 2D image alignment <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b1">2]</ref>, we formulate a Gauss-Newton optimization framework. Specifically, given that the camera projection model is applied on the image part of Eq. 14, the proposed optimization has a "forward" nature.</p><p>Parameters update. The shape, texture and camera parameters are updated in an additive manner, i.e. p ? p + ?p, ? ? ? + ??, c ? c + ?c <ref type="bibr" target="#b14">(15)</ref> where ?p, ?? and ?c are their increments estimated at each fitting iteration. Note that in the case of the quaternion used to parametrize the 3D rotation matrix, the update is performed as the multiplication q ?(?q)q = ?q 0 ?q 1:3 q 0 q 1:3 = = ?q 0 q 0 ? ?q T 1:3 q 1:3 ?q 0 q 1:3 + q 0 ?q 1:3 + ?q 1:3 ? q 1:3 <ref type="bibr" target="#b16">(16)</ref> However, we will still denote it as an addition for simplicity. Finally, we found that it is beneficial to keep the focal length constant in most cases, due to its ambiguity with t z .</p><p>Linearization. By introducing the additive incremental updates on the parameters of Eq. 14, the cost function is </p><p>where J F,p = ?F ?W ?p p=p and J F,c = ?F ?W ?c c=c are the image Jacobians with respect to the shape and camera parameters, respectively. Note that most dense featureextraction functions F(?) are non-differentiable, thus we simply compute the gradient of the multi-channel feature image ?F. Similarly, the linearization on the sparse landmarks projection term gives</p><formula xml:id="formula_17">W l (p + ?p, c + ?c) ? W l (p, c) + J W l ,p ?p + J W l ,c ?c (19) where J W l ,p = ?W l ?p p=p</formula><p>and J W l ,c = ?W l ?c c=c are the camera Jacobians. Please refer to the supplementary material for more details on the computation of these derivatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Simultaneous</head><p>Herein, we aim to simultaneously solve for all parameters' increments. By substituting Eqs. <ref type="bibr" target="#b18">18</ref>   </p><formula xml:id="formula_18">F (W(p, c)) + J F,p ?p + J F,c ?c ? T (? + ??) 2 + + c l W l (p, c) + J W l ,p ?p + J W l ,c ?c ? s l 2 + + c s p + ?p 2 ? ?1 s + c t ? + ?? 2 ? ?1 t<label>(</label></formula><formula xml:id="formula_19">b = ?H ?1 J T F e F + c l J T W l e l + c s ? ?1 s p + c t ? ?1 t ? (21) where H = J F T J F + c l J W l T J W l + c s ? ?1 s + c t ? ?1 t is the Hessian with J F = J T F,p , J T F,c , ?U T t T J W l = J T W l ,p , J T W l ,c , 0 nt?2L T<label>(22)</label></formula><p>and e F = F (W(p, c)) ? T (?)</p><formula xml:id="formula_20">e l = W l (p, c) ? s l<label>(23)</label></formula><p>are the residual terms. The computational complexity of the Simultaneous algorithm per iteration is dominated by the texture reconstruction term as O((n s + n c + n t ) 3 + CN (n s + n c + n t ) 2 ), which in practice is too slow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Project-Out</head><p>We propose to use a Project-Out optimization approach that is much faster than the Simultaneous. The main idea is to optimize on the orthogonal complement of the texture subspace which will eliminate the need to solve for the texture parameters increment at each iteration. By substituting Eqs. 18 and 19 into Eq. 17 and removing the incremental update on the texture parameters as well as the texture parameters regularization term, we end up with the problem arg min ?p,?c,? </p><formula xml:id="formula_21">F (W(p, c)) + J F,p ?p + J F,c ?c ? T (?) 2 + + c l W l (p, c) + J W l ,p ?p + J W l ,c ?c ? s l 2 + + c s p + ?p 2 ? ?1 s<label>(24)</label></formula><formula xml:id="formula_22">+ c s p + ?p 2 ? ?1 s (26) where P = E?U t U t</formula><p>T is the orthogonal complement of the texture subspace that functions as the "project-out" operator with E denoting the CN ? CN unitary matrix. Note that in order to derive Eq. 26, we use the properties P T = P and P T P = P. By differentiating Eq. 26 and equalizing to zero, we get the solution</p><formula xml:id="formula_23">?p = H p ?1 J T F,p Pe F + c l J T W l ,p e l + c s ? ?1 s p ?c = H c ?1 J T F,c Pe F + c l J T W l ,c e l<label>(27)</label></formula><p>where</p><formula xml:id="formula_24">H p = J T F,p PJ F,p + c l J T W l ,p J W l ,p + c s ? ?1 H c = J T F,c PJ F,c + c l J T W l ,c J W l ,c<label>(28)</label></formula><p>are the Hessian matrices and</p><formula xml:id="formula_25">e F = F (W(p, c)) ?t e l = W l (p, c) ? s l<label>(29)</label></formula><p>are the residual terms. The texture parameters can be estimated at the end of the iterative procedure using Eq. 25. Note that the most expensive operation is J T F,p P. However, if we first do J T F,p U t and then multiply this result with U T t , the total cost becomes O(CN n t n s ). The same stands for J T F,c P. Consequently, the cost per iteration is O((n s + n c ) 3 + CN n t (n s + n c ) + CN (n s + n c ) 2 ) which is much faster than the Simultaneous algorithm.</p><p>Residual masking. In practice, we apply a mask on the texture reconstruction residual of the Gauss-Newton optimization, in order to speed-up the 3DMM fitting. This mask is constructed by first acquiring the set of visible vertexes using z-buffering and then randomly selecting K of them. By keeping the number of vertexes small (K ? 5000 N ), we manage to greatly speed-up the fitting process without any accuracy penalty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">KF-ITW Dataset</head><p>For the evaluation of the 3DMM, we have constructed KF-ITW, the first dataset of 3D faces captured under relatively unconstrained conditions. The dataset consists of 17 different subjects recorded under various illumination conditions performing a range of expressions (neutral, happy, surprise). We employed the KinectFusion <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b29">29]</ref> framework to acquire a 3D representation of the subjects with a Kinect v1 sensor.</p><p>The fused mesh for each subject serves as a 3D face ground-truth in which we can evaluate our algorithm and compare it to other methods. A voxel grid of size 608 3 was utilized to get the detailed 3D scans of the faces. In order to accurately reconstruct the entire surface of the faces, a circular motion scanning pattern was carried out. Each subject was instructed to stay still in a fixed pose during the entire scanning process. The frame rate for every subject was constant to 8 frames per second. After getting the 3D scans from the KinectFusion framework we fit our shape model in a non-rigid manner to get a clear mesh with a distinct number of vertexes for the evaluation process. Finally, each mesh was manually annotated with the iBUG 49 sparse landmark set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>To train our model, which we label as ITW, we use a variant of the Basel Face Model (BFM) <ref type="bibr" target="#b31">[31]</ref> that we trained to contain both identities drawn from the original BFM model along with expressions provided by <ref type="bibr" target="#b14">[15]</ref>. We trained the "in-the-wild" texture model on the images of iBUG, LFPW &amp; AFW datasets <ref type="bibr" target="#b32">[32]</ref> as described in Sec. 2.3 using the 3D shape fits provided by <ref type="bibr" target="#b45">[45]</ref>. Additionally, we elect to use the project-out formulation for the throughout our experiments due its superior run-time performance and equivalent fitting performance to the simultaneous one.   <ref type="table" target="#tab_2">Table 1</ref> reports additional measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">3D Shape Recovery</head><p>Herein, we evaluate our "in-the-wild" 3DMM (ITW) in terms of 3D shape estimation accuracy against two popular state-of-the-art alternative 3DMM formulations. The first one is a classic 3DMM with the original Basel laboratory texture model and full lighting equation which we term Classic. The second is the texture-less linear model proposed in <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b18">18]</ref> which we refer to as Linear. For Linear code we use the Surrey Model with related blendshapes along with the implementation given in <ref type="bibr" target="#b18">[18]</ref>.</p><p>We use the ground-truth annotations provided in the KF-ITW dataset to initialize and fit all three techniques to the "in-the-wild" style images in the dataset. The mean mesh of each model under test is landmarked with the same 49point markup used in the dataset, and is registered against the ground truth mesh by performing a Procrustes alignment using the sparse annotations followed by Non-Rigid Iterative Closest Point (N-ICP) to iteratively deform the two surfaces until they are brought into correspondence. This provides a per-model 'ground-truth' for the 3D shape recovery problem for each image under test. Our error metric is the per-vertex dense error between the recovered shape and the model-specific corresponded ground-truth fit, normalized by the inter-ocular distance for the test mesh. <ref type="figure" target="#fig_6">Fig. 4</ref> shows the cumulative error distribution for this experiment for the three models under test. <ref type="table" target="#tab_2">Table 1</ref> reports the corresponding Area Under the Curve (AUC) and failure rates. The Classic model struggles to fit to the "in-the-wild" conditions present in the test set, and performs the worst. The texture-free Linear model does better, but the ITW model is most able to recover the facial shapes due to its ideal feature basis for the "in-the-wild" conditions. <ref type="figure">Figure 6</ref> demonstrates qualitative results on a wide range of fits of "in-the-wild" images drawn from the Helen and  300W datasets <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref> that qualitatively highlight the effectiveness of the proposed technique. We note that in a wide variety of expression, identity, lighting and occlusion conditions our model is able to robustly reconstruct a realistic 3D facial shape that stands up to scrutiny.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Quantitative Normal Recovery</head><p>As a second evaluation, we use our technique to find per-pixel normals and compare against two well established Shape-from-Shading (SfS) techniques: PS-NL <ref type="bibr" target="#b8">[9]</ref> and IMM <ref type="bibr" target="#b23">[23]</ref>. For experimental evaluation we employ images of 100 subjects from the Photoface database <ref type="bibr" target="#b42">[42]</ref>. As a set of four illumination conditions are provided for each subject then we can generate ground-truth facial surface normals using calibrated 4-source Photometric Stereo <ref type="bibr" target="#b27">[27]</ref>. In <ref type="figure" target="#fig_7">Fig. 5</ref> we show the cumulative error distribution in terms of the mean angular error. ITW slightly outperforms IMM even though both IMM and PS-NL use all four available images of each subject.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We have presented a novel formulation of 3DMMs reimagined for use in "in-the-wild" conditions. We capitalise on the annotated "in-the-wild" facial databases to propose a methodology for learning an "in-the-wild" feature-based texture model suitable for 3DMM fitting without having to optimise for illumination parameters. Furthermore, we propose a novel optimisation procedure for 3DMM fitting. We <ref type="figure">Figure 6</ref>. Examples of in the wild fits of our ITW 3DMM taken from 300W <ref type="bibr" target="#b32">[32]</ref>.</p><p>show that we are able to recover shapes with more detail than is possible using purely landmark-driven approaches. Our newly introduced "in-the-wild" KinectFusion dataset allows for the first time a quantitative evaluation of 3D fa-cial reconstruction techniques in the wild, and on these evaluations we demonstrate that our in the wild formulation is state of the art, outperforming classical 3DMM approaches by a considerable margin.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Our "in-the-wild" Morphable Model is capable of recovering accurate 3D facial shape for a wide variety of images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Left: The mean and first four shape and SIFT texture principal components of our "in-the-wild" SIFT texture model. Right: To aid in interpretation we also show the equivalent RGB basis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>F 2 ++ c s p + ?p 2 ? ? 1 s+ c t ? + ?? 2 ? ? 1 t ( 17 )</head><label>2212117</label><figDesc>(W(p + ?p, c + ?c)) ? T (? + ??) 2 + + c l W l (p + ?p, c + ?c) ? s l Note that the texture reconstruction and landmarks constraint terms of this cost function are non-linear due to the camera model operation. We need to linearize them around (p, c) using first order Taylor series expansion at (p + ?p, c + ?c) = (p, c) ? (?p, ?c) = 0. The linearization for the image term givesF (W(p + ?p, c + ?c)) ?F (W(p, c)) + + J F,p ?p + J F,c ?c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>20 )</head><label>20</label><figDesc>Let us concatenate the parameters and their increments as b = [p T , c T , ? T ] T and ?b = [?p T , ?c T , ?? T ] T . By taking the derivative of the final linearized cost function with respect to ?b and equalizing with zero, we get the solution</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2 P</head><label>2</label><figDesc>The solution of Eq. 24 with respect to ? is readily given by? = U t T (F(W(p, c)) + J F,p ?p + J F,c ?c ?t) (25)By plugging Eq. 25 into Eq. 24, we get arg min?p,?c F (W(p, c)) + J F,p ?p + J F,c ?c ?t + + c l W l (p, c) + J W l ,p ?p + J W l ,c ?c ? s l 2 +</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Accuracy results for facial shape estimation on KF-ITW database. The results are presented as Cumulative Error Distributions of the normalized dense vertex error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Results on facial surface normal estimation in the form of Cumulative Error Distribution of mean angular error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>3N is the mean shape vector and U s ? R 3N ?ns is the</figDesc><table><row><cell>the object-centered Cartesian</cell></row><row><cell>coordinates of the i-th vertex. A 3D shape model can be</cell></row><row><cell>constructed by first bringing a set of 3D training meshes</cell></row><row><cell>into dense correspondence so that each is described with</cell></row><row><cell>the same number of vertexes and all samples have a shared</cell></row><row><cell>semantic ordering. The corresponded meshes, {s i }, are</cell></row><row><cell>then brought into a shape space by applying Generalized</cell></row><row><cell>Procrustes Analysis and then Principal Component Anal-</cell></row><row><cell>ysis (PCA) is performed which results in {s, U s }, wher?</cell></row><row><cell>s ? R</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>and 19 in Eq. 17 we get</figDesc><table><row><cell>arg min</cell></row><row><cell>?p,?c,??</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Accuracy results for facial shape estimation on KF-ITW database. The table reports the Area Under the Curve (AUC) and Failure Rate of the Cumulative Error Distributions of Fig. 4.</figDesc><table><row><cell cols="3">Method AUC Failure Rate (%)</cell></row><row><cell>ITW</cell><cell>0.678</cell><cell>1.79</cell></row><row><cell>Linear</cell><cell>0.615</cell><cell>4.02</cell></row><row><cell cols="2">Classic 0.531</cell><cell>13.9</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Menpo: A comprehensive platform for parametric image alignment and visual deformable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alabort-I Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Multimedia, MM &apos;14</title>
		<meeting>the ACM International Conference on Multimedia, MM &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="679" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A unified framework for compositional fitting of active appearance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alabort-I Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Inverse rendering of faces with a 3d morphable model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Aldrian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1080" to="1093" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hog active appearance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alabort-I-Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Image Processing</title>
		<meeting>IEEE International Conference on Image Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="224" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Feature-based lucas-kanade and active appearance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alabort-I-Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2617" to="2632" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Active pictorial structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alabort-I-Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision &amp; Pattern Recognition</title>
		<meeting>IEEE International Conference on Computer Vision &amp; Pattern Recognition<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="5435" to="5444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Incremental face alignment in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Asthana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1859" to="1866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Lucas-kanade 20 years on: A unifying framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="255" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Photometric stereo with general, unknown lighting. IJCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="239" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Localizing parts of faces using a consensus of exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2930" to="2940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Constrained optimization and Lagrange multiplier methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Academic press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A morphable model for the synthesis of 3d faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Blanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual conference on Computer graphics and interactive techniques</title>
		<meeting>the 26th annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<publisher>ACM Press/Addison-Wesley Publishing Co</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Face recognition based on fitting a 3d morphable model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Blanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A 3d morphable model learnt from 10,000 faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roussos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ponniah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dunaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Facewarehouse: A 3d facial expression database for visual computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fitting 3d morphable face models using local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Christmas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>R?tsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Processing (ICIP), 2015 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A multiresolution 3d morphable face model and fitting framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mortazavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">P</forename><surname>Koppen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Christmas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>R?tsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications</title>
		<meeting>the 11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Kinectfusion: real-time 3d reconstruction and interaction using a moving depth camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Molyneaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual ACM symposium on User interface software and technology</title>
		<meeting>the 24th annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="559" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Fddb: A benchmark for face detection in unconstrained settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
		<idno>UM- CS-2010-009</idno>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
			<pubPlace>Amherst</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Large-pose face alignment via cnnbased dense 3d model fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jourabloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">One millisecond face alignment with an ensemble of regression trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1867" to="1874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Internet based morphable model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Kuipers</surname></persName>
		</author>
		<title level="m">Quaternions and rotation sequences</title>
		<imprint>
			<publisher>Princeton university press Princeton</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">66</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Interactive facial feature localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="679" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Object recognition from local scale-invariant features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The proceedings of the seventh IEEE international conference on</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
	<note>Computer vision</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Representation and recognition of the spatial organization of three-dimensional shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Nishihara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Royal Society of London B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">200</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="269" to="294" />
			<date type="published" when="1140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Active appearance models revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="164" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Kinectfusion: Real-time dense surface mapping and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Molyneaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th IEEE international symposium on</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
	<note>Mixed and augmented reality (ISMAR)</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adaptive and constrained algorithms for inverse compositional active appearance model fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Maragos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note>CVPR 2008. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Vetter. A 3d face model for pose and illumination invariant face recognition. In Advanced video and signal based surveillance, 2009. AVSS&apos;09</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paysan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Knothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Amberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Romdhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">300 faces in-the-wild challenge: Database and results. Image and Vision Computing, Special Issue on Facial Landmark Localisation &quot;In-The-Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">300 faces in-the-wild challenge: The first facial landmark localization challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Intl Conf. on Computer Vision (ICCV-W 2013), 300 Faces in-the-Wild Challenge (300-W)</title>
		<meeting>IEEE Intl Conf. on Computer Vision (ICCV-W 2013), 300 Faces in-the-Wild Challenge (300-W)<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Robust principal component analysis with missing data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, CIKM &apos;14</title>
		<meeting>the 23rd ACM International Conference on Conference on Information and Knowledge Management, CIKM &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1149" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Automatic construction of robust spherical harmonic subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="91" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Kernel-pca analysis of surface normals for shape-from-shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1059" to="1066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mnemonic descent method: A recurrent process applied for end-to-end face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision &amp; Pattern Recognition</title>
		<meeting>IEEE International Conference on Computer Vision &amp; Pattern Recognition<address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Optimization problems for fast aam fitting in-the-wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Gauss-newton deformable part models for face alignment in-the-wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1851" to="1858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Iterative estimation of rotation and translation using the quaternion: School of computer science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Supervised descent method and its applications to face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The photoface database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Argyriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Petrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="132" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A survey on face detection in the wild: past, present and future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Face alignment by coarse-to-fine shape searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4998" to="5006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Face alignment across large poses: A 3d solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Face detection, pose estimation, and landmark localization in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2879" to="2886" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
