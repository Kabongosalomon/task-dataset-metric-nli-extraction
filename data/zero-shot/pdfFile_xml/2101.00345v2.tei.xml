<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Fine-Grained Entity Types with Box Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasumasa</forename><surname>Onoe</surname></persName>
							<email>yasumasa@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin ? University of Massachusetts Amherst ? Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Boratko</surname></persName>
							<email>mboratko@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin ? University of Massachusetts Amherst ? Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum ??</surname></persName>
							<email>mccallum@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin ? University of Massachusetts Amherst ? Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
							<email>gdurrett@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin ? University of Massachusetts Amherst ? Google Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Fine-Grained Entity Types with Box Embeddings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>arXiv:2101.00345v2 [cs.CL] 3 Jun 2021</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural entity typing models typically represent fine-grained entity types as vectors in a high-dimensional space, but such spaces are not well-suited to modeling these types' complex interdependencies. We study the ability of box embeddings, which embed concepts as d-dimensional hyperrectangles, to capture hierarchies of types even when these relationships are not defined explicitly in the ontology. Our model represents both types and entity mentions as boxes. Each mention and its context are fed into a BERT-based model to embed that mention in our box space; essentially, this model leverages typological clues present in the surface text to hypothesize a type representation for the mention. Box containment can then be used to derive both the posterior probability of a mention exhibiting a given type and the conditional probability relations between types themselves. We compare our approach with a vector-based typing model and observe state-of-the-art performance on several entity typing benchmarks. In addition to competitive typing performance, our box-based model shows better performance in prediction consistency (predicting a supertype and a subtype together) and confidence (i.e., calibration), demonstrating that the box-based model captures the latent type hierarchies better than the vector-based model does. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The development of named entity recognition and entity typing has been characterized by a growth in the size and complexity of type sets: from 4 <ref type="bibr" target="#b44">(Tjong Kim Sang and De Meulder, 2003)</ref> to 17 <ref type="bibr" target="#b20">(Hovy et al., 2006)</ref> to hundreds <ref type="bibr" target="#b48">(Weischedel and Brunstein, 2005;</ref><ref type="bibr" target="#b28">Ling and Weld, 2012)</ref> or thousands <ref type="bibr" target="#b6">(Choi et al., 2018)</ref>. These types follow some kind of hierarchical structure <ref type="bibr" target="#b48">(Weischedel and Brunstein, 2005;</ref><ref type="bibr" target="#b28">Ling and Weld, 2012;</ref><ref type="bibr" target="#b16">Gillick et al., 2014;</ref>, so effective models for these tasks frequently engage with this hierarchy explicitly. Prior systems incorporate this structure via hierarchical losses <ref type="bibr" target="#b52">Xu and Barbosa, 2018;</ref><ref type="bibr" target="#b5">Chen et al., 2020)</ref> or by embedding types into a high-dimensional Euclidean or hyperbolic space <ref type="bibr" target="#b53">(Yogatama et al., 2015;</ref><ref type="bibr" target="#b30">L?pez and Strube, 2020)</ref>. However, the former approach requires prior knowledge of the type hierarchy, which is unsuitable for a recent class of large type sets where the hierarchy is not explicit <ref type="bibr" target="#b6">(Choi et al., 2018;</ref><ref type="bibr" target="#b35">Onoe and Durrett, 2020a)</ref>. The latter approaches, while leveraging the inductive bias of hyperbolic space to represent trees, lack a probabilistic interpretation of the embedding and do not naturally capture all of the complex type relationships beyond strict containment.</p><p>In this paper, we describe an approach that represents entity types with box embeddings in a highdimensional space . We build an entity typing model that jointly embeds each entity mention and entity types into the same box space to determine the relation between them. Volumes of boxes correspond to probabilities and taking intersections of boxes corresponds to computing joint distributions, which allows us to model mentiontype relations (what types does this mention exhibit?) and type-type relations (what is the type hierarchy?). Concretely, we can compute the conditional probability of a type given the entity mention with straightforward volume calculations, allowing us to construct a probabilistic type classification model.</p><p>Compared to embedding types as points in Euclidean space <ref type="bibr" target="#b40">(Ren et al., 2016a)</ref>, the box space is expressive and suitable for representing entity types due to its geometric properties. Boxes can nest, overlap, or be completely disjoint to capture ? The Hunger Games, the first of 3 best selling books by Suzanne Collins. <ref type="figure">Figure 1</ref>: A mention (Suzanne Collins) and three entity types are embedded into a vector space (left) and a box space (right). The box space can more richly represent hierarchical interactions between types and uncertainty about the properties of the mention. subtype, correlation, or disjunction relations, properties which are not explicitly manifested in Euclidean space. The nature of the box computation also allows these complex relations to be represented in a lower-dimensional space than needed by vector-based models.</p><p>In our experiments, we focus on comparing our box-based model against a vector-based baseline. We evaluate on four entity typing benchmarks: Ultra-fine Entity Typing <ref type="bibr" target="#b6">(Choi et al., 2018)</ref>, OntoNotes <ref type="bibr" target="#b16">(Gillick et al., 2014)</ref>, BBN <ref type="bibr" target="#b48">(Weischedel and Brunstein, 2005)</ref>, and FIGER <ref type="bibr" target="#b28">(Ling and Weld, 2012)</ref>. To understand the behavior of box embeddings, we further analyze the model outputs in terms of consistency (predicting coherent supertypes and subtypes together), robustness (sensitivity against label noise), and calibration (i.e., model confidence). Lastly, we compare entity representations obtained by the box-based and vector-based models. Our box-based model outperforms the vector-based model on two benchmarks, Ultra-fine Entity Typing and OntoNotes, achieving state-ofthe-art-performance. In our other experiments, the box-based model also performs better at predicting supertypes and subtypes consistently and being robust against label noise, indicating that our approach is capable of capturing the latent hierarchical structure in entity types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation</head><p>When predicting class labels like entity types that exhibit a hierarchical structure, we naturally want our model's output layer to be sensitive to this structure. Previous work <ref type="bibr" target="#b40">(Ren et al., 2016a;</ref><ref type="bibr" target="#b42">Shimaoka et al., 2017;</ref><ref type="bibr" target="#b6">Choi et al., 2018;</ref><ref type="bibr" target="#b34">Onoe and Durrett, 2019,</ref> inter alia) has fundamentally treated types as vectors, as shown in the left half of <ref type="figure">Figure 1</ref>. As is standard in multiclass or multi-label classification, the output layer of these models typically involves taking a dot product between a mention embedding and each possible type. A type could be more general and predicted on more examples by having higher norm, 2 but it is hard for these representations to capture that a coarse type like Person will have many mutually orthogonal subtypes.</p><p>By contrast, box embeddings naturally represent these kinds of hierarchies as shown in the right half of <ref type="figure">Figure 1</ref>. A box that is completely contained in another box is a strict subtype of that box: any entity exhibiting the inner type will exhibit the outer one as well. Overlapping boxes like Politician and Author represent types that are not related in the type hierarchy but which are not mutually exclusive. The geometric structure of boxes enables complex interactions with only a moderate number of dimensions <ref type="bibr" target="#b8">(Dasgupta et al., 2020)</ref>.  also define a probability measure over the box space, endowing it with probabilistic semantics. If the boxes are restricted to a unit hypercube, for example, the volumes of type boxes represent priors on types and intersections capture joint probabilities, which can then be used to derive conditional probabilities.</p><p>Critically, box embeddings have previously been trained explicitly to reproduce a given hierarchy such as WordNet. A central question of this work is whether box embeddings can be extended to model the hierarchies and type relationships that are implicit in entity typing data: we do not assume access to explicit knowledge of a hierarchy during training. While some datasets such as OntoNotes have orderly ontologies, recent work on entity typing has often focused on noisy type sets from crowdworkers <ref type="bibr" target="#b6">(Choi et al., 2018)</ref> or derived from Wikipedia <ref type="bibr" target="#b35">(Onoe and Durrett, 2020a)</ref>. We show that box embeddings can learn these structures organically; in fact, they are not restricted to only tree structures, but enable a natural Venndiagram style of representation for concepts, as <ref type="bibr">2</ref> We do not actually observe this in our vector-based model. with Politician and Author in <ref type="figure">Figure 1</ref>. </p><formula xml:id="formula_0">(x) = ?? i (x M,i ? x m,i</formula><p>). If we normalize the volume of the box space to be 1, we can interpret the volume of each box as the marginal probability of a mention exhibiting the given entity type.</p><p>Furthermore, the intersection volume between two boxes, x and y, is defined as Vol(x ? y) = ?? i max (min(x M,i , y M,i ) ? max(x m,i , y m,i ), 0) and can be seen as the joint probability of entity types x and y. Thus, we can obtain the conditional probability P (y | x) = Vol(x?y)</p><p>Vol(x) . Soft boxes Computing conditional probabilities based on hard intersection poses some practical difficulties in the context of machine learning: sparse gradients caused by disjoint or completely contained boxes prevent gradient-based optimization methods from working effectively. To ensure that gradients always flow for disjoint boxes, <ref type="bibr" target="#b26">Li et al. (2019)</ref> relax the hard edges of the boxes using Gaussian convolution. We follow the more recent approach of <ref type="bibr" target="#b8">Dasgupta et al. (2020)</ref>, who further improve training of box embeddings using max and min Gumbel distributions (i.e., Gumbel boxes) to represent the min and max coordinates of a box.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Box-based Multi-label Type Classifier</head><p>Let s denote a sequence of context words and m denote an entity mention span in s. Given the input tuple (m, s), the output of the entity typing model is an arbitrary number of predicted types {t 0 , t 1 , ...} ? T , where t k is an entity type belonging to a type inventory T . Because we do not assume an explicit type hierarchy, we treat entity typing as a multi-label classification problem, or |T | independent binary classification problems for each mention. Section 3.3 will describe how to use a BERTbased model to predict a mention and context box 3 x from (m, s). For now, we assume x is given and we are computing the probability of that mention exhibiting the kth entity type, with type box y k . Each type t k ? T has a dedicated box y k , which is parameterized by a center vector c k y ? R d and an offset vector o k y ? R d . The minimum and maximum corners of a box y k are computed as y k m = ?(c k y ? softplus(o k y )) and y k M = ?(c k y + softplus(o k y )) respectively, so that parameters c ? R d and o ? R d yield a valid box with nonzero volume.</p><p>The conditional probability of the type t k given the mention and context (m, s) is calculated as</p><formula xml:id="formula_1">p ? (t k | m, s) = Vol(z k ) Vol(x) = Vol(x ? y k ) Vol(x) ,</formula><p>where z k is the intersection between x and y k ( <ref type="formula">(2)</ref> and <ref type="formula">(3)</ref> in <ref type="figure" target="#fig_0">Figure 2</ref>). Our final type predictions are based on thresholding these probabilities; i.e., predict the type if p &gt; 0.5.</p><p>As mentioned in Section 3.1, we use the Gumbel box approach of <ref type="bibr" target="#b8">Dasgupta et al. (2020)</ref>, in which the box coordinates are interpreted as the location parameter of a Gumbel max (resp. min) distribution with variance ?. In this approach, the intersection box coordinates become</p><formula xml:id="formula_2">z k m = ? ln (? e xm ? + e y k m ? )? , z k M = ?? ln (? e ? x M ? + e ? y k M ? )? .</formula><p>Following Dasgupta et al. <ref type="formula">(2020)</ref>, we approximate the expected volume of a Gumbel box using a softplus function:</p><formula xml:id="formula_3">Vol(x) ? ?? i softplus (? x M,i ? x m,i ? ? 2? )? ,</formula><p>where i is an index of each coordinate and ? ? 0.5772 is the Euler-Mascheroni constant, 4 and softplus(x) = 1 t log(1 + exp(xt)), with t as an inverse temperature value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Mention and Context Encoder</head><p>We format the context words s and the mention span m as</p><formula xml:id="formula_4">x = [CLS] m [SEP] s [SEP]</formula><p>and chunk into WordPiece tokens <ref type="bibr" target="#b50">(Wu et al., 2016)</ref>. Using pre-trained BERT 5 <ref type="bibr" target="#b10">(Devlin et al., 2019)</ref>, we encode the whole sequence into a single vector by taking the hidden vector at the [CLS] token. A highway layer <ref type="bibr" target="#b43">(Srivastava et al., 2015)</ref> projects down the hidden vector h <ref type="bibr">[CLS]</ref> ? R ? to the R 2d space, where ? is the hidden dimension of the encoder (BERT), and d is the dimension of the box space. This highway layer transforms representations in a vector space to the box space without impeding the gradient flow. We further split the hidden vector h ? R 2d into two vectors: the center point of the box c x ? R d and the offset from the maximum and minimum corners o x ? R d . The minimum and maximum corners of the mention and context box are computed as</p><formula xml:id="formula_5">x m = ?(c x ? SOFTPLUS(o x )) and x M = ?(c x + SOFTPLUS(o x )),</formula><p>where ? is an element-wise sigmoid function, and SOFTPLUS is an element-wise softplus function as defined in Section 3.2 ((1) in <ref type="figure" target="#fig_0">Figure 2</ref>). The output of the softplus is guaranteed to be positive, guaranteeing that the boxes have volume greater than zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Learning</head><p>The goal of training is to find a set of parameters ? that minimizes the sum of binary cross-entropy losses over all types over all examples in our train-ing dataset D:</p><formula xml:id="formula_6">L = ? ?? (m,s,t)?D ?? k t k gold ? log p ? (t k | m, s) + (1 ? t k gold ) ? log(1 ? p ? (t k | m, s)), where t k gold ? {0, 1}</formula><p>is the gold label for the type t k . We optimize this objective using gradient-based optimization algorithms such as Adam <ref type="bibr" target="#b22">(Kingma and Ba, 2015)</ref>. 6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>Our focus here is to shed light on the difference between type hierarchies learned by the box-based model and the vector-based model. To this end, we first evaluate those two models on standard entity typing datasets. Then, we test models' consistency, robustness, and calibration, and evaluate the predicted types as entity representations on a downstream task (coreference resolution). See Appendix A for hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline</head><p>Our chief comparison is between box-based and vector-based modeling of entity types. As our main baseline for all experiments, we use a vector-based version of our entity typing model. We use the same mention and context encoder followed by a highway layer, but this baseline has vector-based type embeddings (i.e., a |T | ? d ? matrix), and type predictions are given by a dot product between the type embeddings and the mention and context representation followed by element-wise logistic regression. This model is identical to that of <ref type="bibr" target="#b36">Onoe and Durrett (2020b)</ref> except for the additional highway layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation and Datasets</head><p>Entity Typing We evaluate our approach on the Ultra-Fine Entity Typing (UFET) dataset <ref type="bibr" target="#b6">(Choi et al., 2018)</ref> with the standard splits (2k for each of train, dev, and test). In addition to the manually annotated training examples, we use the denoised distantly annotated training examples from <ref type="bibr" target="#b34">Onoe and Durrett (2019)</ref>. 7 This dataset contains 10,331 entity types, and each type is marked as one of the three classes: coarse, fine, and ultra-fine. Note that this classification does not provide explicit hierarchies in the types, and all classes are treated equally during training.</p><p>Additionally, we test our box-based model on three other entity typing benchmarks that have relatively simpler entity type inventories with known hierarchies, namely OntoNotes <ref type="bibr" target="#b16">(Gillick et al., 2014)</ref>, BBN <ref type="bibr" target="#b48">(Weischedel and Brunstein, 2005)</ref> , and FIGER <ref type="bibr" target="#b28">(Ling and Weld, 2012)</ref>. See Appendix B for more details on these datasets.</p><p>Consistency A model that captures hierarchical structure should be aware of the relationships between supertypes and subtypes. When a model predicts a subtype, we want it to predict the corresponding supertype together, even when this is not explicitly enforced as a constraint or consistently demonstrated in the data, such as in the UFET dataset. That is, when a model predicts artist, person should also be predicted. To check this ability, we analyze the model predictions on the UFET dev set. We select 30 subtypes from the UFET type inventory and annotate corresponding supertypes for them in cases where these relationships are clear, based on their cooccurrence in the UFET training set and human intuition. Based on the 30 pairs, we compute accuracy of predicting supertypes and subtypes together. <ref type="table">Table 10</ref> in Appendix C lists the 30 pairs.</p><p>Robustness Entity typing datasets with very large ontologies like UFET are noisy; does our box-based model's notion of hierarchy do a better job of handling intrinsic noise in a dataset? To test this in a controlled fashion, we synthetically create noisy labels by randomly dropping the gold labels with probability 1 3 . <ref type="bibr">8</ref> We derive two noisy training sets from the UFET training set: 1) adding noise to the coarse types and 2) adding noise to fine &amp; ultra-fine types. We train on these noised datasets and evaluate on the standard UFET dev set.</p><p>Calibration Desai and Durrett (2020) study calibration of pre-trained Transformers such as BERT and RoBERTa <ref type="bibr" target="#b29">(Liu et al., 2019)</ref> on natural language inference, paraphrase detection, and commonsense reasoning. In a similar manner, we investigate if our box-based entity typing model is calibrated: do the probabilities assigned to types by the model match the empirical likelihoods of those types? Since models may naturally have different scales 8 If this causes the gold type set to be empty, we retain the original gold type(s); however, this case is rare.  <ref type="table">Table 1</ref>: Macro-averaged P/R/F1 on the test set for the ultra-fine entity typing task of <ref type="bibr" target="#b6">Choi et al. (2018).</ref> for their logits depending on how long they are trained, we post-hoc calibrate each of our models using temperature scaling <ref type="bibr" target="#b17">(Guo et al., 2017</ref>) and a shift parameter. We report the total error (e.g., the sum of the errors between the mean confidence and the empirical accuracy) on the UFET dev set and the OntoNotes dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity Representations</head><p>We are interested in the usefulness of the trained entity typing models in a downstream task. Following <ref type="bibr" target="#b36">Onoe and Durrett (2020b)</ref>, we evaluate entity representation given by the box-based and vector-based models on the Coreference Arc Prediction (CAP) task  derived from PreCo <ref type="bibr" target="#b3">(Chen et al., 2018)</ref>. This task is a binary classification problem, requiring to judge if two mention spans (either in one sentence or two sentences) are the same entity or not. As in <ref type="bibr" target="#b36">Onoe and Durrett (2020b)</ref>, we obtain type predictions (a vector of probabilities associated with types) for each span and use it as an entity representation. The final prediction of coreference for a pair of mentions is given by the cosine similarity between the entity type probability vectors with a threshold 0.5. The original data split provides 8k examples for each of the training, dev, and test sets. We report accuracy on the CAP test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Entity Typing</head><p>Here we report entity typing performance on Ultra-Fine Entity Typing (UFET), OntoNotes, FIGER, and BBN. For each dataset, we select the best model from 5 runs with different random seeds based on the development performance.</p><p>UFET <ref type="table">Table 1</ref> shows the macro-precision, recall, and F1 scores on the UFET test set. Our boxbased model outperforms the vector-based model and state-of-the-art systems in terms of macro-  <ref type="table">Table 2</ref>: Macro-averaged P/R/F1 on the dev set for the entity typing task of <ref type="bibr" target="#b6">Choi et al. (2018)</ref> comparing various systems. Our box-based model outperforms models from past work as well as our vector-based baseline.</p><p>F1. 9 Compared to the vector-based model, the boxbased model improves primarily in macro-recall compared to macro-precision. <ref type="bibr" target="#b6">Choi et al. (2018)</ref> is a LSTM-based model using GloVe <ref type="bibr" target="#b37">(Pennington et al., 2014)</ref>. On top of this model, <ref type="bibr" target="#b51">Xiong et al. (2019)</ref> add a graph convolution layer to model type dependencies. <ref type="bibr" target="#b34">Onoe and Durrett (2019)</ref> use ELMo <ref type="bibr" target="#b38">(Peters et al., 2018)</ref> and apply denoising to fix label inconsistency in the distantly annotated data. Note that past work on this dataset has used BERT-base <ref type="bibr" target="#b34">(Onoe and Durrett, 2019)</ref>. Work on other datasets has used ELMo and observed that BERT-based models have surprisingly underperformed <ref type="bibr" target="#b27">(Lin and Ji, 2019)</ref>. Some of the gain from our vector-based model can be attributed to our use of BERT-Large; however, our box model still achieves stronger performance than the corresponding vector-based version which uses the same pretrained model. <ref type="table">Table 2</ref> breaks down the performance into the coarse, fine, and ultra-fine classes. Our box-based model consistently outperforms the vector-based model in macro-recall and F1 across the three classes. The largest gap in macro-recall is in the fine class, leading to the largest gap in macro-F1 within the three classes.</p><p>We also list the numbers from prior work in <ref type="table">Table 2</ref>. HY XLarge <ref type="bibr" target="#b30">(L?pez and Strube, 2020</ref>), a hyperbolic model designed to learn hierarchical structure in entity types, exceeds the performance of the models with similar sizes such as <ref type="bibr" target="#b6">Choi et al. (2018)</ref> and <ref type="bibr" target="#b51">Xiong et al. (2019)</ref> especially in macrorecall. In the ultra-fine class, both our box-based model and HY XLarge achieve higher macro-F1 compared to their vector-based counterparts.</p><p>One possible reason for the higher recall of our model is a stronger ability to model dependencies between types. Instead of failing to predict a highly correlated type, the model may be more likely to predict a complete, coherent set of types.</p><p>Other datasets <ref type="table" target="#tab_4">Table 3</ref> compares macro-F1 and micro-F1 on the OntoNotes, BBN, and FIGER test sets. 10 On OntoNotes, our box-based model achieves better performance than the vector-based model. <ref type="bibr" target="#b54">Zhang et al. (2018)</ref> use document-level information, <ref type="bibr" target="#b5">Chen et al. (2020)</ref> apply a hierarchical ranking loss that assumes prior knowledge of type hierarchies, and <ref type="bibr" target="#b27">Lin and Ji (2019)</ref> propose an ELMo-based model with an attention layer over mention spans and train their model on the augmented data from <ref type="bibr" target="#b6">Choi et al. (2018)</ref>. Among the models trained only on the original OntoNotes training set, the box-based model achieves the highest macro-F1 and micro-F1. The state-of-the-art system on BBN, the system of <ref type="bibr" target="#b5">Chen et al. (2020)</ref> in the "undefined" setting, uses explicit knowledge of the type hierarchy. This is particularly relevant on the BBN dataset, where the training data is noisy and features training points with obviously conflicting labels like person and organization, which appear systematically in the data. To simulate constraints like the ones they use, we use three simple rules to modify our models' prediction: <ref type="formula">(1)</ref>    with state-of-the-art systems. We notice that some of the test examples have inconsistent labels (e.g., /organization/sports team is present, but its supertype /organization is missing), penalizing models that predict the supertype correctly. In addition, FIGER, like BBN, has systematic shifts between training and test distributions. We hypothesize that our model's hyperparameters (tuned on OntoNotes only) are suboptimal.</p><p>The high dev performance shown in <ref type="table" target="#tab_5">Table 4</ref> implies that our model optimized on held-out training examples may not capture these specific shifts as well as other models whose inductive biases are better suited to this unusually mislabeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Consistency</head><p>One factor we can investigate is whether our model is able to predict type relations in a sensible, consistent fashion independent of the ground truth for a particular example. For this evaluation, we investigate our model's predictions on the UFET dev set. We count the number of occurrences for each subtype in 30 supertype/subtype pairs (see <ref type="table">Table 10</ref> in Appendix C). Then, for each subtype, we count how many times its corresponding supertype is also predicted. Although these supertype-subtype relations are not strictly defined in the training data, we believe they should nevertheless be exhibited by models' predictions. Accuracy is given by the ratio between those counts, indicating how often the supertype was correctly picked up. <ref type="table" target="#tab_7">Table 5</ref> lists the total and per-supertype accuracy on the supertype/subtype pairs. We report the number of subtypes grouped by their supertypes to show their frequency (the "Count" column in <ref type="table" target="#tab_7">Table 5</ref>). Our box-based model achieves better accuracy compared to the vector-based model on all supertypes. The gaps are particularly large on place and organization. Note that some of the UFET training examples have inconsistent labels (e.g., a subtype team can be a supertype organization or group), and this ambiguity potentially confuses a model during training. Even in those tricky cases, the box-based model shows reasonable performance. The geometry of the box space itself gives some evidence as to why this consistency would arise (see Section 5.6 for visualization of box edges). <ref type="table" target="#tab_8">Table 6</ref> analyzes models' sensitivity to the label noise. We list the UFET dev performance by models trained on the noised UFET training set. When the coarse types are noised (i.e., omitting some supertypes), the vector-based model loses 4.8 points of macro-F1 while our box-based model only loses 1.5 points. A similar trend can be seen when the fine and ultra-fine types are noised (i.e., omitting some subtypes). In both cases, the vector-based model shows lower recall compared to the same model trained on the clean data, while our boxbased model is more robust. We also note that the vector-based model tends to overfit to the training data quickly. We hypothesize that the use of boxes works as a form of regularization, since moving boxes may be harder than moving points in a space, thus being less impacted by noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Robustness</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Calibration</head><p>Following <ref type="bibr" target="#b32">Nguyen and O'Connor (2015)</ref>, we split model confidence (output probability) for each typing decision of each example into 10 bins (e.g., 0-0.1, 0.1-0.2 etc.). For each bin, we compute mean confidence and empirical accuracy. We show the total calibration error (lower is better) as well as the scaling and shifting constants in   reasonably well calibrated after applying temperature scaling and shifting. However, the box-based model achieves slightly lower total error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Entity Representation for Coreference</head><p>This experiment evaluates if model outputs are immediately useful in a downstream task. For this task, we use the box-based and vector-based entity typing models trained on the UFET training set (i.e., we do not train models on the CAP training set). <ref type="table" target="#tab_11">Table 8</ref> shows the test accuracy on the CAP data. Our box-based model achieves slightly higher accuracy than the vector-based model, indicating that "out-of-the-box" entity representations obtained by the box-based model contains more useful features for the CAP task. 11</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Box Edges</head><p>To analyze how semantically related type boxes are located relative to one another in the box space, we plot the edges of the person and actor boxes along the 109 dimensions one by one. <ref type="figure" target="#fig_1">Figure 3</ref> shows how those two boxes overlap each other in the high-dimensional box space.    . This is a binary classification task.</p><p>in <ref type="figure" target="#fig_1">Figure 3</ref> compares the person box and the actor box learned on the UFET data. We can see that the edges of person contain the edges of actor in many dimensions but not all, meaning that the person box overlaps with the actor box but doesn't contain it perfectly as we might expect. However, we can additionally investigate whether the actor box is effectively contained in the person for parts of the space actually used by the mention boxes. The lower plot in <ref type="figure" target="#fig_1">Figure 3</ref> compares the person box and the minimum bounding box of the intersections between the actor and the mention and context boxes obtained using the UFET dev examples where the actor type is predicted. This minimum bounding box approximates the effective region within the actor box. Now the edges of actor are contained in the edges of person in the most of dimensions, indicating that the person box almost contains this "effective" actor box.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Embeddings Embedding concepts/words into a high-dimensional vector space (Hinton, 1986) has a long history and has been an essential part of neural networks for language <ref type="bibr" target="#b1">(Bengio et al., 2003;</ref><ref type="bibr" target="#b7">Collobert et al., 2011)</ref>. There is similarly a long history of rethinking the semantics of these embedding spaces, such as treating words as regions using sparse count-based vectors <ref type="bibr">(Erk, 2009a,b)</ref> or dense distributed vectors <ref type="bibr" target="#b47">(Vilnis and McCallum, 2015)</ref>. Order embeddings <ref type="bibr" target="#b45">(Vendrov et al., 2016)</ref> or their probabilistic version (POE) <ref type="bibr" target="#b23">(Lai and Hockenmaier, 2017)</ref> are one technique suited for hierarchical modeling. However, OE can only handle binary entailment decisions, and POE cannot model negative correlations between types, a critical limitation in its use as a probabilistic model; these shortcomings directly led to the development of box embeddings. Hyperbolic embeddings (Nickel and Kiela, 2017; <ref type="bibr" target="#b30">L?pez and Strube, 2020)</ref> can also model hierarchical relationships as can hyperbolic entailment cones <ref type="bibr" target="#b15">(Ganea et al., 2018)</ref>; however, these approaches lack a probabilistic interpretation.</p><p>Recent work on knowledge base completion <ref type="bibr" target="#b0">(Abboud et al., 2020)</ref> and reasoning over knowledge graphs <ref type="bibr" target="#b39">(Ren et al., 2020)</ref> embeds relations or queries using box embeddings, but entities are still represented as vectors. In contrast, our model embed both entity mentions and types as boxes.</p><p>Entity typing Entity typing and named entity recognition <ref type="bibr" target="#b44">(Tjong Kim Sang and De Meulder, 2003)</ref> are old problems in NLP. Recent work has focused chiefly on predicted fine-grained entity types <ref type="bibr" target="#b28">(Ling and Weld, 2012;</ref><ref type="bibr" target="#b16">Gillick et al., 2014;</ref><ref type="bibr" target="#b6">Choi et al., 2018)</ref>, as these convey significantly more information for downstream tasks. As a result, there is a challenge of scaling to large type inventories, which has inspired work on type embeddings <ref type="bibr">(Ren et al., 2016a,b)</ref>.</p><p>Entity typing information has been used across a range of NLP tasks, including models for entity linking and coreference <ref type="bibr" target="#b12">(Durrett and Klein, 2014)</ref>. Typing has been shown to be useful for crossdomain entity linking specifically <ref type="bibr" target="#b18">(Gupta et al., 2017;</ref><ref type="bibr" target="#b35">Onoe and Durrett, 2020a)</ref>. It has also recently been applied to coreference resolution <ref type="bibr" target="#b36">(Onoe and Durrett, 2020b;</ref><ref type="bibr" target="#b21">Khosla and Rose, 2020</ref>) and text generation <ref type="bibr" target="#b11">(Dong et al., 2020)</ref>, suggesting that it can be a useful intermediate layer even in pretrained neural models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we investigated a box-based model for fine-grained entity typing. By representing entity types in a box embedding space and projecting entity mentions into the same space, we can naturally capture the hierarchy of and correlations between entity types. Our experiments showed several benefits of box embeddings over the equivalent vector-based model, including typing performance, calibration, and robustness to noise.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Box-based entity typing model. The mention and context (left) are embedded into the box space and probabilities for each type are computed with a soft volume computation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Edges of (a) the person box vs the actor box and (b) the person box vs the minimum bounding box of the intersections between mention &amp; context boxes and the actor box.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>dropping person if organization exists, (2) dropping location if gpe exists, and (3) replacing facility by fac, since both versions of this tag appear in the training set but only fac in the dev and test set. Our box-based model and the vectorbased model perform similarly and both achieve results comparable with recent systems.</figDesc><table><row><cell></cell><cell cols="2">OntoNotes</cell><cell cols="2">BBN</cell><cell cols="2">FIGER</cell></row><row><cell>Model</cell><cell cols="6">Ma-F1 Mi-F1 Ma-F1 Mi-F1 Ma-F1 Mi-F1</cell></row><row><cell>Box</cell><cell>77.3</cell><cell>70.9</cell><cell cols="3">78.7 * 78.0 * 79.4</cell><cell>75.0</cell></row><row><cell>Vector</cell><cell>76.2</cell><cell>68.9</cell><cell cols="3">78.3 * 78.0 * 81.6</cell><cell>77.0</cell></row><row><cell>Zhang et al. (2018)</cell><cell>72.1</cell><cell>66.5</cell><cell>75.7</cell><cell>75.1</cell><cell>78.7</cell><cell>75.5</cell></row><row><cell>Chen et al. (2020) (exclusive)</cell><cell>72.4</cell><cell>67.2</cell><cell>63.2</cell><cell>61.0</cell><cell>82.6</cell><cell>80.8</cell></row><row><cell cols="2">Chen et al. (2020) (undefined) 73.0</cell><cell>68.1</cell><cell>79.7</cell><cell>80.5</cell><cell>80.5</cell><cell>78.1</cell></row><row><cell>Lin and Ji (2019)</cell><cell cols="3">82.9  ? 77.3  ? 79.3</cell><cell>78.1</cell><cell>83.0</cell><cell>79.8</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">On FIGER, our box-based model shows lower</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">performance compared to the vector-based model,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">though both are approaching comparable results</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">10 Note that our hyperparameters are optimized for macro</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">F1 on OntoNotes.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Macro-averaged F1 and Micro-averaged F1 on the test set for the entity typing task of OntoNotes, BBN, FIGER. ?: Not directly comparable since large-scale augmented data is used. *: We fix the predictions using simple rules post-hoc.</figDesc><table><row><cell></cell><cell>BBN</cell><cell>FIGER</cell></row><row><cell cols="3">Model Dev Ma-F1 Dev Ma-F1</cell></row><row><cell>Box</cell><cell>92.4</cell><cell>94.3</cell></row><row><cell>Vector</cell><cell>92.3</cell><cell>94.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: Macro-averaged F1</cell></row><row><cell>on the dev set of BBN and</cell></row><row><cell>FIGER. These dev sets are</cell></row><row><cell>drawn from the same distribu-</cell></row><row><cell>tions as their training sets.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 .</head><label>7</label><figDesc>As the results on UFET and OntoNotes show, both boxbased and vector-based entity typing models can be</figDesc><table><row><cell></cell><cell></cell><cell>Box</cell><cell cols="2">Vector</cell></row><row><cell>Supertype</cell><cell cols="4">Count Acc. Count Acc.</cell></row><row><cell>person</cell><cell cols="4">982 99.7 745 98.6</cell></row><row><cell>location</cell><cell cols="4">470 86.1 450 84.4</cell></row><row><cell>place</cell><cell>49</cell><cell>95.9</cell><cell>29</cell><cell>68.9</cell></row><row><cell cols="5">organization 496 84.6 407 77.8</cell></row><row><cell>Total</cell><cell cols="4">1,997 92.7 1,631 89.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell cols="5">: Consistency: accuracy evaluated on the 30 su-</cell></row><row><cell cols="5">pertype &amp; subtypes pairs. The "Count" column shows</cell></row><row><cell cols="5">the number of subtypes found in the predictions. The</cell></row><row><cell cols="5">accuracy is the frequency of predicting the correspond-</cell></row><row><cell cols="5">ing supertype when the subtype is exhibited.</cell></row><row><cell cols="3">Training Data Model P</cell><cell>R</cell><cell>F1 ? in F1</cell></row><row><cell>Noised Coarse</cell><cell cols="4">Box Vector 51.5 31.0 38.7 51.0 37.9 43.5</cell><cell>-1.5 -4.8</cell></row><row><cell>Noised Fine</cell><cell>Box</cell><cell cols="3">53.0 37.2 43.7</cell><cell>-1.3</cell></row><row><cell cols="5">&amp; Ultra-fine Vector 58.6 30.6 40.2</cell><cell>-3.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Entity typing results of the UFET dev set. Models are trained on the noised UFET training set. The "? in F1" column shows the performance drop from the model trained on the original UFET training set (not noised).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>The upper plot11  Our results are not directly comparable to those of<ref type="bibr" target="#b36">Onoe and Durrett (2020b)</ref>; we train on the training set of UFET dataset, and they train on examples from the train, dev, and test sets.</figDesc><table><row><cell cols="3">Model Scale / Shift Total Error</cell></row><row><cell></cell><cell>UFET</cell><cell></cell></row><row><cell>Box</cell><cell>0.5 / -1.1</cell><cell>0.1119</cell></row><row><cell>Vector</cell><cell>0.2 / -1.1</cell><cell>0.3279</cell></row><row><cell></cell><cell>OntoNotes</cell><cell></cell></row><row><cell>Box</cell><cell>0.9 / -0.3</cell><cell>0.1358</cell></row><row><cell>Vector</cell><cell>0.7 / -0.4</cell><cell>0.1568</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Total calibration error on UFET and OntroNotes. We scale and shift logits post-hoc.</figDesc><table><row><cell>Model</cell><cell>Test Acc.</cell></row><row><cell>Box</cell><cell>78.1</cell></row><row><cell>Vector</cell><cell>77.3</cell></row><row><cell>Random</cell><cell>50.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Accuracy on the CAP test set</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The code is available at https://github.com/ yasumasaonoe/Box4Types.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We could represent mentions as points instead of boxes; however, representing them as boxes enables the size of a mention box to naturally reflect epistemic uncertainty about a mention's types given limited information.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">From<ref type="bibr" target="#b8">Dasgupta et al. (2020)</ref>, the Euler-Mascheroni constant appears due to the interpretation of xm,i, xM,i as the location parameters of Gumbel distributions.5  We use BERT-large uncased (whole word masking) in our experiments.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">With large type sets, most types are highly skewed towards the negative class (&gt;99% negative for many finegrained types). While past work such as<ref type="bibr" target="#b6">Choi et al. (2018)</ref> has used modified training objectives to handle this class imbalance, we did not find any modification to be necessary.7  This consists of 727k training examples derived from the distantly labeled UFET data.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">We omit the test number of<ref type="bibr" target="#b30">L?pez and Strube (2020)</ref>, since they report results broken down into coarse, fine, and ultra-fine types instead of an aggregated F1 value. However, based on the development results, their approach substantially underperforms the past work of<ref type="bibr" target="#b34">Onoe and Durrett (2019)</ref> regardless.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Thanks to the members of the UT TAUR lab, Pengxiang Cheng, and Eunsol Choi for helpful discussion; Tongfei Chen and Ying Lin for providing the details of experiments. This work was also partially supported by NSF Grant IIS-1814522, NSF Grant SHF-1762299, and based on research in part supported by the Air Force Research Laboratory (AFRL), DARPA, for the KAIROS program under agreement number FA8750-19-2-1003, as well as University of Southern California subcontract no. 123875727 under Office of Naval Research prime contract no. N660011924032. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of AFRL, DARPA, or the U.S. Government.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A: Hyperparameter Search</head><p>We use Bayesian hyperparameter tuning and the Hyperband stopping criteria <ref type="bibr" target="#b25">(Li et al., 2017)</ref> implemented in the Weights &amp; Biases software <ref type="bibr" target="#b2">(Biewald, 2020)</ref>. We use Adam <ref type="bibr" target="#b22">(Kingma and Ba, 2015)</ref> for all experiments. We perform hyperparameter search on OntoNotes due to its fast convergence. This finds a lower dimension for the box-based model compared to the vector-based model (109-d ? 2 vs 307-d), resulting fewer parameters in the boxbased model. When we train the box-based model on the UFET dataset, we sample 1,000 negatives (i.e., wrong types) to speed up convergence; this is not effective in the vector-based model, so we do not do this there.</p><p>We use the same hyperparameters for the other three datasets. We train all models using NVIDIA V100 GPU with batch size 128. We implement our models using HuggingFace's Transformers library <ref type="bibr" target="#b49">(Wolf et al., 2020)</ref>. <ref type="table">Table 9</ref> shows hyperparameters of the box-based and vector-based models as well as their ranges to search. For Adam, we use ? 1 = 0.9 and ? 2 = 0.999 for training.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B: Entity Typing Benchmarks</head><p>OntoNotes <ref type="bibr" target="#b16">(Gillick et al., 2014)</ref> has 89 types with a 3-level hierarchy (e.g., /location/geography/mountain). We use the same splits (250k train / 2k dev / 9k test) provided by <ref type="bibr" target="#b42">(Shimaoka et al., 2017)</ref>. FIGER <ref type="bibr" target="#b28">(Ling and Weld, 2012)</ref>, derived from Wikipedia, uses 113 types with a 2-level hierarchy (e.g., /person/musician). We use the same splits (2M train / 10k dev / 563 test) as <ref type="bibr" target="#b42">(Shimaoka et al., 2017)</ref>. BBN <ref type="bibr" target="#b48">(Weischedel and Brunstein, 2005)</ref> is based on the one million word Penn Treebank corpus from Wall Street Journal articles. We use the same splits (84k train / 2k dev / 14k test) as <ref type="bibr" target="#b41">Ren et al. (2016b)</ref>; <ref type="bibr" target="#b5">Chen et al. (2020)</ref>.</p><p>Appendix C: Supertype/subtype pairs  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D: Box Edges</head><p>Similar to <ref type="figure">Figure 3</ref>, we plot the semantically unrelated type boxes food and building in <ref type="figure">Figure 4</ref>. These boxes are largely misaligned as expected, and the minimum bounding box of the intersections between the building and the mention and context boxes is also off from the food box.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix E: Reliability Plot</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">BoxE: A Box Embedding Model for Knowledge Base Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Abboud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?smaililkan</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Salvatori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</title>
		<meeting>Advances in Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?jean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Janvin</surname></persName>
		</author>
		<title level="m">A Neural Probabilistic Language Model</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Experiment Tracking with Weights and Biases. Software available from wandb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Biewald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">PreCo: A large-scale dataset in preschool vocabulary for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Rong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">EntEval: A holistic evaluation benchmark for entity representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zewei</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical Entity Typing via Multi-level Learning to Rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunmo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ultra-Fine Entity Typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural Language Processing (Almost) from Scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><forename type="middle">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving Local Identifiability in Probabilistic Box Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Shib Sankar Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Boratko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorraine</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</title>
		<meeting>Advances in Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Calibration of Pre-trained Transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrey</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Injecting Entity Types into Entity-Guided Text Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<idno>abs/2009.13401</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00197</idno>
		<title level="m">A Joint Model for Entity Analysis: Coreference, Typing, and Linking. Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="477" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Representing words as regions in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Supporting inferences in semantic space: representing words as regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Semantics (IWCS)</title>
		<meeting>the International Conference on Computational Semantics (IWCS)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hyperbolic Entailment Cones for Learning Hierarchical Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Octavian-Eugen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>B?cigneul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Context-Dependent Fine-Grained Entity Type Tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nevena</forename><surname>Lazic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Huynh</surname></persName>
		</author>
		<idno>abs/1412.1820</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On Calibration of Modern Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Entity Linking via Joint Encoding of Types, Descriptions, and Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning distributed representations of concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth annual conference of the cognitive science society</title>
		<meeting>the eighth annual conference of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">OntoNotes: The 90% Solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using Type Information to Improve Entity Coreference Resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sopan</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolyn</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Computational Approaches to Discourse</title>
		<meeting>the First Workshop on Computational Approaches to Discourse</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to Predict Denotational Probabilities For Modeling Entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the</title>
		<meeting>the Conference of the</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">European</forename><surname>Chapter</surname></persName>
		</author>
		<title level="m">the Association for Computational Linguistics (EACL)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hyperband: Bandit-Based Configuration Evaluation for Hyperparameter Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisha</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">G</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giulia</forename><surname>Desalvo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Afshin Rostamizadeh, and Ameet Talwalkar. ICLR</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Smoothing the Geometry of Probabilistic box Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Boratko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An Attentive Fine-Grained Entity Typing Model with Latent Type Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fine-Grained Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>abs/1907.11692</idno>
	</analytic>
	<monogr>
		<title level="j">RoBERTa: A Robustly Optimized BERT Pretraining Approach. ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A Fully Hyperbolic Neural Model for Hierarchical Multi-Class Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Hierarchical Losses and New Resources for Fine-grained Entity Typing and Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Murty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irena</forename><surname>Radovanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Posterior Calibration and Exploratory Analysis for Natural Language Processing Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Connor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Poincar? Embeddings for Learning Hierarchical Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</title>
		<meeting>Advances in Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to Denoise Distantly-Labeled Data for Entity Typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasumasa</forename><surname>Onoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fine-Grained Entity Typing for Domain Independent Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasumasa</forename><surname>Onoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Interpretable Entity Representations through Large-Scale Typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasumasa</forename><surname>Onoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep Contextualized Word Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Query2box: Reasoning over Knowledge Graphs in Vector Space using Box Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hongyu Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">AFET: Automatic Fine-Grained Entity Typing by Hierarchical Partial-Label Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Label Noise Reduction in Entity Typing by Heterogeneous Partial-Label Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><forename type="middle">R</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Neural Architectures for Fine-grained Entity Type Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonse</forename><surname>Shimaoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>the Conference of the European Chapter of the Association for Computational Linguistics (EACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Highway Networks. ArXiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Rupesh Kumar Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<idno>abs/1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien</forename><surname>De Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Order-embeddings of Images and Languagen</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vendrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Sanja Fidler, and Raquel Urtasun</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Murty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mc-Callum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Word Representations via Gaussian Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">BBN pronoun coreference and entity type corpus. Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ada</forename><surname>Brunstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-Art Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teven</forename><forename type="middle">Le</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apurva</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshikiyo</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideto</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/1609.08144</idno>
	</analytic>
	<monogr>
		<title level="m">Google&apos;s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</title>
		<editor>Oriol Vinyals, Gregory S. Corrado, Macduff Hughes, and Jeffrey Dean</editor>
		<meeting><address><addrLine>Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Imposing Label-Relational Inductive Bias for Extremely Fine-Grained Entity Typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deren</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Neural Fine-Grained Entity Type Classification with Hierarchy-Aware Loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denilson</forename><surname>Barbosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Embedding methods for fine grained entity type classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nevena</forename><surname>Lazic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Fine-grained Entity Typing through Increased Discourse Context and Adaptive Classification Thresholds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics (*SEM)</title>
		<meeting>the Seventh Joint Conference on Lexical and Computational Semantics (*SEM)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
