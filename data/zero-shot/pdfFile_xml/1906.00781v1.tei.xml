<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Semantic Annotations for Tabular Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaoyan</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernesto</forename><surname>Jim?nez-Ruiz</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The Alan Turing Institute</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Oslo</orgName>
								<address>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Horrocks</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">The Alan Turing Institute</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Sutton</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The Alan Turing Institute</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">The University of Edinburgh</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Semantic Annotations for Tabular Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The usefulness of tabular data such as web tables critically depends on understanding their semantics. This study focuses on column type prediction for tables without any meta data. Unlike traditional lexical matching-based methods, we propose a deep prediction model that can fully exploit a table's contextual semantics, including table locality features learned by a Hybrid Neural Network (HNN), and inter-column semantics features learned by a knowledge base (KB) lookup and query answering algorithm. It exhibits good performance not only on individual table sets, but also when transferring from one table set to another.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Tabular data such as web tables and legacy databases are a rich and rapidly expanding resource. They often contain high value data, but may be hard to use due to meta data being missing, incomplete or obfuscated. Gaining an understanding of their meaning is thus of critical importance. One prominent solution, which is often referred to as semantic table annotation, is to exploit the semantics of a widely recognized knowledge base (KB) by linking table components, such as columns and cells, to KB components, such as classes (categories), entities (elements) and properties (relations). It can be widely applied in KB population <ref type="bibr" target="#b3">[Ritze et al., 2016]</ref>, search engines <ref type="bibr" target="#b0">[Cafarella et al., 2008;</ref><ref type="bibr" target="#b0">Cafarella et al., 2018]</ref>, automatic data analysis <ref type="bibr" target="#b3">[Thirumuruganathan et al., 2018;</ref><ref type="bibr" target="#b1">Chu et al., 2015]</ref> and so on.</p><p>Semantic table annotation has been extensively studied, especially for web tables <ref type="bibr" target="#b0">[Cafarella et al., 2018]</ref>. Traditional methods are mostly based on lexical matching by name, with annotation modeled as tasks such as matching cells to entities, columns to classes, inter-column relations to properties and so on <ref type="bibr" target="#b3">[Limaye et al., 2010]</ref>. Other methods, including probabilistic graphical models <ref type="bibr" target="#b0">[Bhagavatula et al., 2015]</ref> and iterative algorithms <ref type="bibr" target="#b3">[Ritze et al., 2015]</ref>, have been developed to explore the correlation between different matching tasks for disambiguation. However, most of them rely on table metadata such as column names to jointly model multiple matching tasks, while lexical matching itself fails to capture the contextual semantics of a name.</p><p>Recently some studies have explored the use of deep learning in semantic table annotation. For example <ref type="bibr" target="#b3">[Luo et al., 2018]</ref> learns cell contextual features to predict its corresponding KB entity (cf. Section 4). These works illustrate the benefit of deep learning in modeling contextual semantics of tables, but they still have limitations: (i) some tasks, such as column type annotation, have not been fully investigated; (ii) some contextual semantics, such as inter-column relations, have not been fully explored; and (iii) the transferability (generalization) of the learned model has not been evaluated.</p><p>In this study, we focus on semantic type (i.e., class) prediction for columns that are composed of phrases (i.e., entity mentions). For example, a column composed of "Google", "Amazon" and "Apple Inc." can be annotated by the class Company. To this end, we first develop a Hybrid Neural Network (HNN) to model the contextual semantics of a column. It embeds the phrase within a cell with a bidirectional Recurrent Neural Network and an attention layer (Att-BiRNN), and learns (i) column features (i.e., intra-column cell correlation) and (ii) row features (i.e., intra-row cell correlation) with a Convolutional Neural Network (CNN).</p><p>The arbitrary relative position of columns makes it difficult for the neural network to learn general row features. Thus we extend the row features with property features, which indicate potential relations between columns and provide discriminative predictive information. For example, given a column composed of "Animal Farm", "The Goldfather" and "Brokeback Mountain", together with a column of person names, the potential relation director indicates the first column is more likely to be of type Film, while the relation author suggests Book as probable type. To extract such property features, a novel KB lookup and reasoning algorithm was developed.</p><p>In summary, this study contributes a new column type prediction method combing HNN for feature learning and KB lookup and reasoning for feature extraction. We evaluate our technique using the DBpedia KB and three table sets: T2Dv2 from the general Web, Limaye and Efthymiou from the Wikipedia encyclopedia. As well as testing single table sets, the evaluation specially considers the generalization (transferability) of the prediction model from one table set to another. The evaluation suggests that our method is effective and that its overall accuracy is higher than the state-of-the-art in most cases. We assume a table is composed of cells organized by columns and rows, without any metadata like column names. The input is a table with a target column whose type is to be predicted. The column includes ordered cells, each of which is a sequence of words (text phrase), known as an entity mention. A column composed of entity mentions is also known as an entity column. Other columns in the input table are called surrounding columns. We assume a fixed set of candidate classes that are disjoint with each other are given, denoted as {C 1 , ..., C K }. The problem is assigning a real value score to each candidate class so that the correct class (type) of the target column has the highest score.</p><p>The input of our method is modeled as a fixed structure table called a micro table, denoted as S. It has one target column with a fixed number of cells, denoted as L = (L 1 , ..., L m ), and a fixed number of surrounding columns, denoted as L = (L 1 , ..., L l ). The first cell of the target column L 1 is known as the micro table's main cell.</p><p>In training, we assume n labeled micro tables (samples) are extracted from labeled entity columns by (i) sliding a window from the first row to the last with the step of one cell and (ii) selecting surrounding columns from the left to the right. A function (model) F : S ? y is learned, where y ? R K represents the output vector. In predicting the type of a target column with size M , micro tables are first extracted and predicted by the trained model F. Their output vectors are then averaged as the final score vector to the target column:</p><formula xml:id="formula_0">y = 1 M ?m+1 M ?m+1 i=1 F(S i ).</formula><p>The remainder of this section presents our model F, while some of its training details are presented in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">HNN Architecture</head><p>Our HNN mainly includes an attentive BiRNN for cell embedding, and a customized convolutional (Conv) layer for table locality feature learning, as shown in <ref type="figure">Figure 1</ref>.  <ref type="figure">Figure 1</ref>: A brief view of the HNN architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Micro</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cell Embedding</head><p>We use an RNN with Gated Recurrent Unit (GRU) <ref type="bibr" target="#b0">[Bhagavatula et al., 2015]</ref> to embed the word sequence of each cell (x t , t ? [1, T ]). It uses a reset gate r t to control the contribution of past state (word), and an update gate z t to balance the contributions of past information and new information. The hidden state at position t is computed as</p><formula xml:id="formula_1">h t = (1 ? z t ) h t?1 + z t h t ,<label>(1)</label></formula><p>where denotes the Hadamard product, h t?1 represents the past state,h t is a state computed with new sequence information.h t , z t and r t are updated as</p><formula xml:id="formula_2">? ? ?h t = tanh(W h x t + r t (U h h t?1 ) + b h ), z t = ?(W z x t + U z h t?1 + b z ), r t = ?(W r x t + U r h t?1 + b r ).</formula><p>(2) Assume the cell phrase length is fixed to T by cropping and padding, and each cell phrase is represented as (v 1 , ..., v T ) where v t denotes the vector of the word at position t. In BiRNN, both forward hidden states (</p><formula xml:id="formula_3">? ? h t = ??? GRU(v t ), t ? [1, T ]) and backward hidden states ( ? ? h t = ??? GRU(v t ), t ? [T, 1]) are calculated.</formula><p>The embedding of the word at position t, denoted as e t , is the concatenation of ? ? h t and ? ? h t . The embedding of a cell phrase is composed of the BiRNN embeddings of its words. Inspired by <ref type="bibr" target="#b4">[Yang et al., 2016]</ref>, we assume different words are differently informative towards a prediction task, and an attention layer is thus stacked. Given a phrase with BiRNN word embedding (e t , t ? [1, T ]), the attention layer output is a = t ? t e t , where ? t is the normalized weight of the word at position t and is calculated as</p><formula xml:id="formula_4">? t = exp(u T t uw) t exp(u T t uw) u t = tanh(W w e t + b w )<label>(3)</label></formula><p>The dimension of cell embedding a is denoted as d 0 ; u w represents the informative degree of all the words in training. Given a micro table, the cells of the target column and the cells of its surrounding entity columns are embedded by the above Att-BiRNN; the cells of the surrounding real value columns are transformed into a vector of dimension d 0 by zero padding; the cells of the surrounding date columns are first parsed with integers of year, month and day, and then transformed into a vector of dimension d 0 by concatenating the integers and zero padding.</p><p>One column is embedded into a matrix of size m ? d 0 by stacking vectors of its cells. For convenience, we also use the annotation of a column to denote its embedded matrix (i.e., L for the target column, L i for a surrounding column). One micro table is embedded into a tensor of size m ? (l + 1) ? d 0 by stacking matrices of its columns, denoted as [L, L 1 , ..., L l ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Column Features and Row Features</head><p>One Conv layer is stacked after Att-BiRNN, including (i) Conv filters over the target column for column feature learning, denoted as c 1 , and (ii) Conv filters over the row of the main cell for row feature learning, denoted as c 2 .</p><p>Each filter over the column W c1 i has the size of</p><formula xml:id="formula_5">k 1 ? d, where k 1 ? ? 1 , ? 1 ? {2, ..., m}.</formula><p>Given the matrix of the target column L, the filter computes the column features as</p><formula xml:id="formula_6">f c1,k1 i = g(W c1 i ? L + b c1 ),<label>(4)</label></formula><p>where ? denotes the Conv operation, g denotes an activation function like ReLu and b c1 denotes the biases. Each filter over the row W c2 j has the size of 1 ? k 2 ? d, where k 2 ? ? 2 , ? 2 ? {2, ..., l + 1}. Given the tensor of a micro table, the filter computes the row features as</p><formula xml:id="formula_7">f c2,k2 j = g(W c2 j ? [L 1 , L 1,1 , ..., L l,1 ] + b c2 ),<label>(5)</label></formula><p>where L i,1 denotes the first cell of surrounding column L i , b c2 denotes the biases. It models the correlation between the target column and its surrounding columns.</p><p>Inspired by some successful CNN architectures with one Conv layer (e.g., <ref type="bibr" target="#b3">[Kim, 2014]</ref> for text classification), a max pooling layer is stacked after the Conv layer to extract salient signals and regularize the network. Thus the column filter k 1 ? d finally computes the output as</p><formula xml:id="formula_8">f c1,k1 = [max(f c1,k1 1 ), max(f c1,k1 2 ), ..., max(f c1,k1 ?1 )] (6)</formula><p>where max(?) denotes a vector's maximum value, ? 1 denotes the number of features to be learned for each filter. For the row filter 1 ? k 2 ? d, with the number of features ? 2 , the output, denoted as f c2,k2 is calculated in the same way as (6).</p><p>The max pooling layer concatenates f c1,k1 , k 1 ? ? 1 and f c2,k2 , k 2 ? ? 2 as the output, denoted as f c1,c2 . ? 1 , ? 2 , ? 1 and ? 2 are hyper parameters about the HNN architecture.</p><p>A fully connected (FC) layer is then stacked for modeling the nonlinear relationship. It calculates the output as</p><formula xml:id="formula_9">f hnn = f c1,c2 ? W f c + b f c ,<label>(7)</label></formula><p>where ? denotes matrix multiplication, W f c and b f c denote weights and biases of the FC layer. Finally, a softmax layer is stacked to calculate the output score for each class:</p><formula xml:id="formula_10">y hnn i = exp(f hnn i )/ K j=1 exp(f hnn j ),<label>(8)</label></formula><formula xml:id="formula_11">where i = 1, 2, ..., K.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Property Features</head><p>Property features are used to represent the potential relations between the target column and its surrounding columns. We first introduce some KB background and then present how property features are extracted and incorporated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RDF-based Knowledge Base</head><p>The KB in this study follows Semantic Web standards including RDF (Resource Description Framework), RDF Schema, OWL (Web Ontology Language) and SPARQL <ref type="bibr" target="#b1">[Domingue et al., 2011]</ref>. One KB is composed of a TBox (terminology) and an ABox (assertions). The TBox, often using RDF Schema, contains constructors for the definition of class, class relations (e.g., rdfs:subClassOf for the descendent relation), property, property domain and range, etc. It can also use more expressive languages such as OWL with more powerful constructs such as relation composition. The ABox contains entities, each of which is represented by an URI (Uniform Resource Identifier), and RDF triples s, p, o , where s represents a subject (an entity), p represents a predicate (a property) and o represents an object (either an entity or a data value like date and number). An entity can belong to one or more classes, which is defined by the property rdf:type.</p><p>Such a KB is often called an RDF-based KB. It can be accessed by SPARQL queries. Two examples used in our method are (Q 1 ) getting entities of a given class according to rdf:type, and (Q 2 ) getting triples whose subject entity is given. SPARQL supports semantic reasoning for accessing implicit knowledge <ref type="bibr">[Glimm and Ogbuji, 2013]</ref>; for example, inferring e rdf:type c 2 , given e rdf:type c 1 and c 1 rdfs:subClassOf c 2 . A KB can also be accessed via fuzzy matching, with a lexical index on entity labels (phrases defined by rdfs:label) and sometimes entity anchor text (short descriptions). This is often referred to as KB lookup. Successful systems include Spotlight for DBpedia <ref type="bibr" target="#b3">[Mendes et al., 2011]</ref> and OpenRefine for Wikidata <ref type="bibr">[Ham, 2013]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Candidate Properties</head><p>Given a class c defined by a KB, we denote entities that belong to it as E(c). It means the triple e rdf:type c is true for any entity e in E(c). Given a property p defined by a KB, an entity is defined as a subject entity of p, denoted as e p , if there exists at least one object o such that the triple e p , p, o is entailed by the KB. We denote all the subject entities of the property p as E(p). A property is defined as a frequent property of class c, denoted as</p><formula xml:id="formula_12">p c , if |E(c) ? E(pc)| /|E(c)| ? ?, where ? ? [0, 1]</formula><p>is a threshold and |?| denotes the cardinality of a set. "Frequent" means at least a specified proportion of the entities of a class are associated to that specific property.</p><p>A candidate property represents a potential relationship between two columns. To get candidate properties, we first extract the frequent properties of each candidate (training) class C i ? C, denoted as p i , and then merge these frequent properties: P = ? K i=1 p i . The size of P is denoted as d 1 . The above calculation requires K SPARQL queries of type Q 1 and ? K i=1 E(C i ) SPARQL queries of type Q 2 . Property Vector (P2Vec) Property features of one micro table are represented by a P2Vec denoted as v. Each slot of v represents the degree of existence of one candidate property, and thus the dimension of v is d 1 . The calculation of P2Vec is shown in Algorithm 1. Given a micro table, it first retrieves KB entities that match the main cell (Line 5). As lookup by lexical matching is ambiguous, entity lookup is set to return more than one entity (at most N) to avoid missing the right entity. For each matched entity, it first retrieves its property annotations, namely the triples whose subject is this entity, using a SPARQL query of type Q 2 (Line 6 to 7), and then matches each triple's object with the first cell of each surrounding column (Line 8 to 10).</p><p>In matching, the function cell object match first classifies the object o into types of entity, date, text and number, and then returns true or false with the following processing. An entity is transformed to a phrase with its English label defined by rdfs:label, while a date is transformed to an integer that represents the year. In comparing two texts, it returns true if their string-edit distance (e.g., Jaro Distance <ref type="bibr" target="#b1">[Cohen et al., 2003]</ref>) exceeds the threshold ? and false otherwise, while in comparing two numbers, it returns true if they are equal and false otherwise. Note that we do not return a matching degree score but true or false, so as to leave salient predictive information about inter-column relations with less noise.</p><p>Algorithm 1 needs once entity lookup, at most N SPARQL queries of type Q2, and N ? d 1 ? l matchings with function cell object match.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Ensemble</head><p>P2Vec is integrated with the HNN by two ensemble approaches. Ensemble I first trains a basic multi-class classifier e.g., Multiple Layer Perception (MLP) and predicts the score:</p><formula xml:id="formula_13">y p2vec classifier e.g., MLP ? ????????? ? [L 1 , v] ,<label>(9)</label></formula><p>where the average word vector of the main cell L 1 is concatenated with the P2Vec v as the input. It then calculates the average of the above score and the score by the HNN <ref type="formula" target="#formula_10">(8)</ref>:</p><formula xml:id="formula_14">y = (y hnn + y p2vec )/2.<label>(10)</label></formula><p>Algorithm 1: P2VecExtract (L, L), P , N, ? Ensemble II trains a multiple-class classifier with the concatenation of the P2Vec v and the FC layer output of the HNN <ref type="formula" target="#formula_9">(7)</ref>, and predicts the score:</p><formula xml:id="formula_15">y classifier e.g., MLP ? ????????? ? f hnn , v .<label>(11)</label></formula><p>In decision making, the class with the highest score is adopted as the column type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>In the evaluation 1 conducted in this paper we rely on DBpedia and three web We annotate (i) 411 entity columns of T2Dv2 with 37 concrete and disjoint classes defined by the DBpedia ontology, (ii) 114 entity columns of Limaye with 8 out of the above 37 classes, and (iii) 620 entity columns of Efthymiou with 31 out of the above 37 classes. T2Dv2 is randomly split into T2D-Tr (70%) and T2D-Te (30%). All the results except for <ref type="table" target="#tab_7">Table 3</ref> are based on the following setting: T2D-Tr is used for training, while T2D-Te, Limaye and Efthymiou are used as three testing sets. We report accuracy, i.e., the ratio of correctly labeled columns.</p><p>The reported results are based on the following hyper parameter setting. Regarding the micro table, the number of rows m is set to 5, the number of surrounding columns l is set to 4, and zero-padding is used for tables that do not have enough columns or rows. In training, negative samples are constructed by labeling the entity column with each wrong class; a word2vec model <ref type="bibr" target="#b3">[Mikolov et al., 2013]</ref> trained by the latest dump of Wikipedia articles is adopted. HNN is trained by <ref type="bibr" target="#b3">Adam [Kingma and Ba, 2014]</ref> with the loss function of softmax cross entropy. The hidden size and the attention layer size of RNN are set to 150 and 50, the column Conv filter set ? 1 and the row Conv filter set ? 2 are set to {2, 3, 4} and {2, 3}, the feature number per filter (? 1 and ? 2 ) is set to 32. In computing P2Vec, the DBpedia lookup service 3 and SPARQL endpoint 4 are used, while the hyper parameters ?, N and ? are set to 0.005, 5 and 0.85 respectively.</p><p>In evaluation, we adopt as baselines two typical multi-class classifiers -Logistic Regression (LR) and Multiple Layer Perception (MLP), variants of our HNN (including ColNet ), and two lexical matching based column type annotation methods -DBpedia lookup service plus majority voting by matched entities <ref type="bibr">[Zwicklbauer et al., 2013]</ref> (Lookup-vote) and T2K Match <ref type="bibr" target="#b3">[Ritze et al., 2015]</ref>. LR and MLP are also used as the classifier for ensemble. In the following, we first consider the effectiveness of HNN and P2Vec and then evaluate the overall result, with the transferability between table sets analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Hybrid Neural Network</head><p>In <ref type="table" target="#tab_4">Table 1</ref>, we can see that the HNN variants with both Att-BiRNN and CNN achieve the highest accuracy on all three testing sets. In the following, we separately analyze the impact of Att-BiRNN and CNN. Att-BiRNN. In comparison with word vector averaging, embedding the cell phrase by Att-BiRNN improves the model's accuracy. In <ref type="table" target="#tab_4">Table 1</ref>, Att-BiRNN outperforms word2vec-avg + FC-Softmax by 3.2%, 6.4% and 11.3% on T2D-Te, Limaye and Efthymiou respectively. When a CNN is stacked, embedding by Att-BiRNN is still beneficial. For instance, Att-BiRNN + CNN cr outperforms word2vec-avg + CNN cr by 2.5%, 9.1% and 9.4% on the three testing sets.  18.4% on T2D-Te and Efthymiou respectively. One potential reason is that the noise from surrounding columns overwhelms the learned discriminative patterns due to factors like varying relative position between a target column and a surrounding column (e.g., a column of book names vs a column of writer names) from table to table. This explanation is supported by the results in <ref type="figure" target="#fig_1">Figure 2</ref> using the basic classifiers LR and MLP. As with adding row feature via CNN, concatenating the average word2vec of cells of surrounding columns increases the accuracy on Limaye but reduces the accuracy on T2D-Te and Efthymiou. Although row features do not always improve the accuracy, they are still beneficial in comparison with directly concatenating the average word2vec of cells of surrounding columns, leading to higher improvement on Limaye and lower decreasement on T2D-Te and Efthymiou, as seen in <ref type="figure" target="#fig_1">Figure 2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Property Vector</head><p>The results in <ref type="figure" target="#fig_2">Figure 3</ref> illustrate the effectiveness of P2Vec in column type prediction. On the one hand, appending P2Vec to the main cell (i.e., Main Cell + P2Vec) significantly improves accuracy; e.g., the improvement of MLP is 2.3%, 32.2% and 5.2% on T2D-Te, Limaye and Efthymiou respectively. This is much higher than directly concatenating average word vectors of cells of surrounding columns in the row (i.e., Main Row). The latter actually negatively impacts performance on T2D-Te and Efthymiou, which is consistent with the impact of row features learned by Conv filters in HNN. On the other hand, we find that feeding LR and MLP with P2Vec concatenation even outperforms the HNN that learns row feature. For example, Main Cell + P2Vec with LR in <ref type="figure" target="#fig_2">Figure 3</ref> outperforms Att-BiRNN + CNN r in <ref type="table" target="#tab_4">Table 1</ref> by 6.4%, 3.9% and 15.5% respectively on T2D-Te, Limaye and Efthymiou.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main Cell Main Row Main Cell + P2Vec</head><p>Main In <ref type="figure" target="#fig_3">Figure 4</ref> we analyze the distribution of non-zero elements of P2Vec and its impact on performance improvement by P2Vec. P2Vec shows significant performance improvement on "Book", "Newspaper" and "Monarch", and at the same time has significant Hits# and zero Noise# (except for "Monarch" of Efthymiou). This indicates the positive impact of the correctly matched properties. Meanwhile we find there are no or limited improvements on the other 5 classes although most of them also have significant Hits#. This is due to (i) the high base accuracy without P2Vec (e.g., close to 1 for "Bird" and "University" of Limaye and Efthymiou), and (ii) the negative impact of Noise# (e.g., "Writer" of Efthymiou). <ref type="figure" target="#fig_3">Figure 4</ref> also shows that Limaye has higher Hits# and lower Noise# than Efthymiou. This in some degree explains why P2Vec achieves more significant improvement on Limaye than on Efthymiou (0.081 vs 0.05 for the average accuracy gap of the 8 classes in <ref type="figure" target="#fig_3">Figure 4</ref>; 25.3% vs 4.3% for the improvement by P2Vec in <ref type="figure" target="#fig_2">Figure 3)</ref>. Meanwhile, the low absolute value of Hits# and Noise# means P2Vec is quite sparse -less than 0.3 out of 422 slots are none zero. Sparsity reduces the training time and helps avoid over fitting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ensemble</head><p>As seen in <ref type="table" target="#tab_6">Table 2</ref>, both ensemble approaches are beneficial. Ensemble I achieves higher accuracy than P2Vec and HNN on T2D-Te which comes from the same table set as the training data. Ensemble II always achieves accuracy very close to the highest of P2Vec and HNN on all three testing sets, e.g., 0.650 vs 0.655 on Efthymiou. Ensemble I outperforms Ensemble II on T2D-Te, while Ensemble II outperforms Ensemble I on Limaye and Efthymiou. Thus, we can apply Ensemble I in contexts where training and testing data come from the same source, and apply Ensemble II in contexts that need high robustness. Considering Ensemble I re-trains a classifier with FC layer output of the trained HNN and P2Vec, and is more likely to be over-fitted to the training data, it is unsurprising to see its performance drop on Limaye and Efthymiou as the training data comes from T2Dv2. This also indicates the difficulty of transferring learned table features and models between data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Overall Result and Discussion</head><p>As shown in <ref type="table" target="#tab_7">Table 3</ref>    <ref type="bibr" target="#b1">et al., 2011;</ref><ref type="bibr" target="#b3">Pham et al., 2016;</ref><ref type="bibr" target="#b0">Cafarella et al., 2018]</ref>. State-of-the-art performance is achieved by jointly considering different matching tasks. These methods include variants of probabilistic graphical models <ref type="bibr" target="#b3">[Limaye et al., 2010;</ref><ref type="bibr" target="#b3">Mulwad et al., 2013;</ref><ref type="bibr" target="#b0">Bhagavatula et al., 2015]</ref>, scoring models <ref type="bibr" target="#b1">[Chu et al., 2015]</ref>, T2K Match <ref type="bibr" target="#b3">[Ritze et al., 2015]</ref>, <ref type="table">Table Miner</ref>  <ref type="bibr" target="#b5">[Zhang, 2017]</ref>, etc. Performance also depends on the quality of the lexical index. For example, the lookup service powered by the index of DBpedia Spotlight <ref type="bibr" target="#b3">[Mendes et al., 2011]</ref> can achieve good performance in cell to entity matching and column type annotation (i.e., Lookup-Vote) . However, most of the above methods rely on table meta data for high performance, while lexical matching in principle fail to capture the contextual meaning of cell phrases. Recently, with the development of deep learning, semantic embedding techniques like word2vec <ref type="bibr" target="#b3">[Mikolov et al., 2013]</ref> have been applied and methods that learn table features have been proposed. Both <ref type="bibr">[Efthymiou et al., 2017]</ref> and <ref type="bibr" target="#b3">[Kunihiro et al., 2019]</ref> utilize KB embedding. The former explores the contextual semantics of an entity in the KB for disambiguation in cell to entity matching, while the latter accelerates searching and deals with the missing linkage in column to class matching with Markov Random Field. <ref type="bibr" target="#b3">[Luo et al., 2018]</ref>, <ref type="bibr" target="#b3">[Nishida et al., 2017]</ref> and  all explore table feature learning with neural networks. The former two learn cell features and locality features as our HNN, but deal with totally different problems. <ref type="bibr" target="#b3">[Luo et al., 2018]</ref> matches a cell to an entity in a different language, while <ref type="bibr" target="#b3">[Nishida et al., 2017]</ref> classifies the structure of a table. In ColNet [?] different problem setting with unfixed candidate classes and multiple binary classifiers. ColNet's architecture is a special case of our HNN, namely word2vec + CNN c in <ref type="table" target="#tab_4">Table 1</ref>. Briefly, learning the semantics of tabular data is promising, but still a big challenge <ref type="bibr" target="#b3">[Thirumuruganathan et al., 2018]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Outlook</head><p>In this study we predict the semantic type of entity columns, using a hybrid neural network (HNN) for cell embedding and table feature learning, and a property vector (P2Vec), extracted by KB lookup and query answering, for semantic features that represent potential inter-column relations. We evaluated our method with DBpedia and three web table sets; it is effective in most cases, and the overall performance exceeds the state-of-the-art in the supervised learning setting. We also considered generalisation across data sets, but this proved to be more challenging. In the future we will apply our approach in an AI assistant for data analytics, and further investigate (permutation invariant) table feature learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1</head><label></label><figDesc>Input: (i) A micro table (L, L), (ii) candidate properties P with the size of d1, (iii) a maximum number of matched entities N, (iv) a text matching threshold ?, 2 Result: v: a property vector of the micro table 3 begin 4 v := zeros(d1); % Init. of the property vector 5 E := entity lookup(L1, ?); % Entity lookup by main cell 6 foreach entity e ? E do 7 T := query(e);% Get triples whose subject is e 8 foreach triple (s, p, o) ? T with p ? P do 9 foreach surrounding column Li ? L do 10 if cell object match(Li,1, o, ?) then 11 j := index(p, P ); 12 v[j] := 1; % Set the slot of the property 13 v := v / v ; % Normalization 14 return v</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Accuracy improvement using surrounding columns.Cells of surrounding column are appended to the main cell through vector concatenation (word2vec-avg + LR and word2vec-avg + MLP) and row feature learning (CNN r and Att-BiRNN + CNN r ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Accuracy with and without P2Vec concatenation. Average word2vec is used for cell embedding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Average number of correctly and incorrectly matched properties per row, i.e., correct and incorrect none zero elements per P2Vec (Hits# and Noise#), and the accuracy improvement (gap) of LR by appending P2Vec to the main cell, on 8 classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table Cell Embedding</head><label>Cell</label><figDesc></figDesc><table><row><cell>Word Vector + BiRNN + Attention Layer</cell><cell>Conv filters over the target column</cell><cell>Column Features</cell><cell>Concatenation + Dropout</cell><cell cols="2">FC Layer + Softmax Layer</cell></row><row><cell></cell><cell>Conv filters over the main</cell><cell>Row Features</cell><cell cols="2">Features</cell><cell>Scores</cell></row><row><cell></cell><cell>row</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>FC layer over the main cell</cell><cell>Cell Features</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Accuracy of HNN variants. word2vec-avg represents averaging the word2vec of words of each cell phrase. FC-Softmax denotes a classifier by a FC layer and a Softmax layer. The superscripts c and r of CNN denote Conv filters over the column and row. Te comes from the same table set as the training data). Row Features. Conv filters over the row of the main cell learn row features. Unlike column features, the impact of row features varies from data to data, as seen in Table 1. For example, with Att-BiRNN, adding CNN r improves the accuracy by 14.6% on Limaye but reduces the accuracy by 7.9% and</figDesc><table><row><cell>Column Features. Conv filters over the target column learn</cell></row><row><cell>column features. According to Table 1, they are effective in improving the accuracy. For example, word2vec-avg + CNN c</cell></row><row><cell>outperforms word2vec-avg + FC-Softmax by 2.4%, 6.4% and</cell></row><row><cell>6.4% on T2D-Te, Limaye and Efthymiou respectively. When</cell></row><row><cell>the embedding by Att-BiRNN is used, they are still beneficial. The corresponding improvement of Att-BiRNN + CNN c over</cell></row><row><cell>Att-BiRNN + FC-Softmax is 0.7%, 5.9% and 1.1%. The lim-</cell></row><row><cell>ited improvement on T2D-Te is due to the high base accuracy</cell></row><row><cell>(T2D-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>Accuracy of P2Vec, HNN, and the ensemble approaches.Both LR and MLP are used and the average is reported.the training and testing data comes from the same table set (Local-70%). Its accuracy is 15.7%, 11.5% and 5.0% higher than Lookup-Vote, 2.0%, 6.1% and 6.4% higher than Col-</figDesc><table><row><cell cols="4">Net, on T2D, Limaye and Efthymiou respectively. Although</cell></row><row><cell cols="4">the assumption on training data would constrain applicability,</cell></row><row><cell cols="4">the case that some columns have been annotated (e.g., by vol-</cell></row><row><cell cols="4">unteers) while many more from the same source remain to be</cell></row><row><cell cols="4">annotated is quite common. On the other hand, when trained</cell></row><row><cell cols="4">on one table set (T2D-Tr) and transferred to another (Limaye</cell></row><row><cell cols="4">and Efthymiou), the performance of HNN + P2Vec decreases</cell></row><row><cell cols="4">but is still higher than ColNet. One cost sensitive solution</cell></row><row><cell cols="4">for such a transfer setting is combining T2D-Tr with a small</cell></row><row><cell cols="4">number of labeled columns from the testing set (Local-10%);</cell></row><row><cell cols="4">its performance on Limaye is then 4.5% and 12.3% higher</cell></row><row><cell cols="3">than Lookup-Vote and T2K Match respectively.</cell><cell></cell></row><row><cell>Methods (Training Data)</cell><cell>T2D-Te</cell><cell>Limaye</cell><cell>Efthymiou</cell></row><row><cell>HNN + P2Vec (T2D-Tr) HNN + P2vec (Local-70%)</cell><cell>0.966</cell><cell>0.746 0.968</cell><cell>0.650 0.865</cell></row><row><cell>HNN + P2vec (T2D-Tr + Local-10% )</cell><cell>-</cell><cell>0.907</cell><cell>0.697</cell></row><row><cell>Lookup-Vote</cell><cell>0.835</cell><cell>0.868</cell><cell>0.827</cell></row><row><cell>T2K Match</cell><cell>0.772</cell><cell>0.807</cell><cell>0.612</cell></row><row><cell>ColNet (T2D-Tr) ColNet (Local-70%)</cell><cell>0.947</cell><cell>0.597 0.912</cell><cell>0.619 0.813</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Accuracy of the baselines and our method under different training data settings. Local-?% represents randomly extracting ?% of a table set as training data, with the remainder as testing data.Discussion. In the evaluation we first analyzed the impact of components of HNN. Cell embedding by Att-BiRNN and column features by Conv filters over the target column achieve significant accuracy gains as expected, while row features by Conv filters over the row of the main cell have a positive impact on only one out of three testing sets, which may be caused by varying table structures such as different column permutations. Second, we evaluated P2Vec which is extracted by a KB lookup and query answering algorithm and includes information about potential relations between the target column and surrounding columns. It achieves significant improvement, thus compensating for the above weak row features. Third, we analyzed two ensemble approaches that combine P2Vec and HNN. They lead to better and more robust performance. Finally we compared our method with some state-of-the-art baselines including those using deep learning (i.e., variants of HNN) and those using lexical matching (i.e., Lookup-Vote and T2K Match). Our method significantly outperforms lexical matching when the training data or a part of the training data comes from the same source as the testing data, but transferring the model trained on one table set to another totally different one for testing is still a big challenge.</figDesc><table><row><cell>4 Related Work</cell></row></table><note>Most semantic table annotation works are based on lexi- cal matching between table and KB [Venetis</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Codes: https://github.com/alan-turing-institute/SemAIDA 2 http://webdatacommons.org/webtables/goldstandardV2.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/dbpedia/lookup 4 http://dbpedia.org/sparql</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgments</head><p>We want to thank Chris Williams from University of Edinburgh for his constructive comments. The work is supported by the AIDA project (UK Government's Defence &amp; Security Programme in support of the Alan Turing Institute), the SIR-IUS Centre for Scalable Data Access (Research Council of Norway, project 237889), the Royal Society, EPSRC projects DBOnto, MaSI 3 and ED 3 .</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tabel: entity linking in web tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bhagavatula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Webtables: exploring the power of tables on the web. Proceedings of the VLDB Endowment</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2140" to="2149" />
		</imprint>
	</monogr>
	<note>Ten years of webtables</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Oktie Hassanzadeh, Mariano Rodriguez-Muro, and Vassilis Christophides. Matching web tables with knowledge base entities: from entity lookups to entity embeddings</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIG-MOD</title>
		<meeting>ACM SIG-MOD</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="260" to="277" />
		</imprint>
	</monogr>
	<note>Birte Glimm and Chimezie Ogbuji. Sparql. 1 entailment regimes. W3C Recommendation. Ham, 2013] Kelli Ham. Openrefine (version 2.5)</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">open-source tool for cleaning and transforming data</title>
		<ptr target="http://openrefine.org.free" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Medical Library Association: JMLA</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">233</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Understanding the semantic structures of tables with a hybrid deep neural network architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Kim ; Yoon Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ba ; Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kunihiro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<idno>arXiv:1803.01384</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Web Intelligence, Mining and Semantics</title>
		<editor>Alon Halevy, Jayant Madhavan, Marius Pa?ca, Warren Shen, Fei Wu, Gengxin Miao, and Chung Wu</editor>
		<meeting>the 5th International Conference on Web Intelligence, Mining and Semantics<address><addrLine>Nan Tang</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="528" to="538" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Towards self driving data curation. Venetis et al., 2011] Petros Venetis. Recovering semantics of tables on the web. Proceedings of the VLDB Endowment</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Xiaodong He, Alex Smola, and Eduard Hovy. Hierarchical attention networks for document classification</title>
	</analytic>
	<monogr>
		<title level="m">NAACL-HTL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Effective and efficient semantic table interpretation using tableminer+</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">; Ziqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic Web</title>
		<editor>Zwicklbauer et al., 2013] Stefan Zwicklbauer, Christoph Einsiedler, Michael Granitzer, and Christin Seifert</editor>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="205" to="208" />
		</imprint>
	</monogr>
	<note>ISWC</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
