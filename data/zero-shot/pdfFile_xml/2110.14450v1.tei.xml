<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rot-Pro: Modeling Transitivity by Projection in Knowledge Graph Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengwei</forename><surname>Song</surname></persName>
							<email>songtengwei@buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<postCode>100191</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Luo</surname></persName>
							<email>luojie@buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<postCode>100191</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Huang</surname></persName>
							<email>huangleiai@buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<postCode>100191</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Rot-Pro: Modeling Transitivity by Projection in Knowledge Graph Embedding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T19:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge graph embedding models learn the representations of entities and relations in the knowledge graphs for predicting missing links (relations) between entities. Their effectiveness are deeply affected by the ability of modeling and inferring different relation patterns such as symmetry, asymmetry, inversion, composition and transitivity. Although existing models are already able to model many of these relations patterns, transitivity, a very common relation pattern, is still not been fully supported. In this paper, we first theoretically show that the transitive relations can be modeled with projections. We then propose the Rot-Pro model which combines the projection and relational rotation together. We prove that Rot-Pro can infer all the above relation patterns. Experimental results show that the proposed Rot-Pro model effectively learns the transitivity pattern and achieves the state-of-the-art results on the link prediction task in the datasets containing transitive relations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graph embedding (KGE) aims to learn low-dimensional dense vectors to express the entities and relations in the knowledge graphs (KG). It is widely used in recommendation system, question answering, dialogue systems <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b6">7]</ref>. The general intuition of KGE is to model and infer relations between entities in knowledge graphs, which has complex patterns such as symmetry, asymmetry, inversion, composition, and transitivity as shown in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>Many studies dedicate to find a method, which is able to model various relation patterns <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b19">20]</ref>. TransE models relations as translations, aims to model the inversion and composition patterns; DisMult can model symmetric relations by capturing interactions between head and tail entities and relations. One representative model proposed recently is RotatE <ref type="bibr" target="#b19">[20]</ref>, which is proved to be able to model symmetry, asymmetry, inversion and composition patterns by modeling relation as a rotation in the complex plane. However, none of them can model all the five relation patterns, especially the transitivity pattern. This paper focus on modeling the transitivity pattern. We theoretically show that the transitive relations can be modeled with idempotent transformations, i.e. projections <ref type="bibr" target="#b24">[25]</ref>. Any projection matrix is similar to a diagonal matrix with elements in the diagonal being 0 or 1. We design the projection by constraining the similarity matrix to be a rotation matrix, which has less parameters to be learn. In order to model not only transitivity but also other relation patterns shown in <ref type="table" target="#tab_0">Table 1</ref>, we propose the Rot-Pro model which combines the projection and relational rotation together. We theoretically prove that Rot-Pro can infer the symmetry, asymmetry, inversion, composition, and transitivity if (r = r 1 ? ? ? ? ? r n ) ? (h, r 1 , u 1 ) ? (u 1 , r 2 , u 2 ) . . . ? (u n?1 , r n , t), then (h, r, t) Transitivity if (a, r, b) and (b, r, c) , then(a, r, c) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>There are mainly two types of knowledge graph embedding models, either using translation transformation or linear transformation between head and tail entities.</p><p>Trans-series models. Trans-series models, which is well-known in KGE area, are essentially translation transformation based models. TransE <ref type="bibr" target="#b2">[3]</ref> proposed a pure translation distance-based score function, which assumes the added embedding of head entity h and relation r should be close to the embedding of tail entity t. This simple approach is effective in capturing composition, asymmetric and inversion relations, but is hard to handle the 1-to-N, N-to-1 and N-N relations.</p><p>To overcome these issues, many variants and extensions of TransE have been proposed. TransH <ref type="bibr" target="#b25">[26]</ref> projects entities and relations into a relation-specific hyperplanes and enables different projections of an entity in different relations. TransR <ref type="bibr" target="#b27">[28]</ref> introduces relation-specific spaces, which builds entity and relation embeddings in different spaces separately. TransD <ref type="bibr" target="#b8">[9]</ref> simplifies TransR by constructs dynamic mapping matrices. For the purpose of model optimization, some models relax the requirement for translational distance. TransA <ref type="bibr" target="#b9">[10]</ref> replaces Euclidean distance by Mahalanobis distance to enable more adaptive metric learning, and a recent model TransMS <ref type="bibr" target="#b17">[18]</ref> transmits multidirectional semantics by complex relations.</p><p>The variants of TransE improve the capability of the models to handle 1-to-N, N-to-1 and N-N relations as well as effectively modeling symmetric and asymmetric relations, but they are no longer able to model composition and inversion relations as they do linear transformation on head and tail entities separately before modeling the relation as translation. BoxE <ref type="bibr" target="#b0">[1]</ref>, a recent trans-series model, embeds entities as points, and relations as a set of boxes, for yielding a model that could express multiple relation patterns including composition and inversion, but it cannot express transitivity.</p><p>Bilinear models. Models of bilinear series model relations as linear transformation matrix M r from head to tail entity. The type of relation patterns that a linear transformation based model can infer depends on the property of M r . RESCAL <ref type="bibr" target="#b13">[14]</ref> proposes the transformation of relation as a matrix that models the pairwise interactions between entities and relation. The score of a fact is defined by a bilinear function: f r = h T M r t. DistMult <ref type="bibr" target="#b1">[2]</ref> simplifies RESCAL by restricting M r to diagonal matrices. Therefore, it cannot handle other types of relations except symmetry. HolE [12] combines the expressive power of RESCAL with the simplicity of DistMult which introduces circular correlations. HolE can express multiple types of relations, since cyclic correlation operations are not commutative.</p><p>Recently, some KGE models begin to model relation patterns explicitly. Dihedral <ref type="bibr" target="#b26">[27]</ref> models relations in KGs with the representation of dihedral group that has properties to support the relation as symmetry. To expand Euclidean space, ComplEx <ref type="bibr" target="#b20">[21]</ref> firstly introduces complex vector space which can capture both symmetric and asymmetric relations. RotatE <ref type="bibr" target="#b19">[20]</ref> also models in complex space and can capture additional inversion and composition patterns by introducing rotational Hadmard product. QuatE <ref type="bibr" target="#b28">[29]</ref> extends RotatE, using a quaternion inner product and gains more expressive semantic learning capability. ATTH <ref type="bibr" target="#b3">[4]</ref> proposes a low-dimensional hyperbolic knowledge graph embedding method, which capture logical patterns such as symmetry and asymmetrical.</p><p>However, none of existing models is capable of modeling transitivity relation pattern. We are the first to show that the transitivity can be modeled with projections, and we prove that the proposed model is able to infer all the five relation patterns shown in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>3 Rot-Pro: Modeling Relation Patterns by Projection and Rotation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminary</head><p>RotatE is a representative approach that models a relation as an element-wise rotation from the embedding e h of head entity to the embedding e t of tail entity in complex vector space. This can be denoted as e t (k) ? rot(e h (k), ? r (k)), where ? r is the embedding of relation r and rot(e h (k), ? r (k)) is the rotation function that rotates the kth element of e h with a phase of the kth element of ? r . For each embedding e, let Re(e(k)) and Im(e(k)) be the real number and imaginary number of its kth dimension, the rotation transformation in the kth dimension is defined by an orthogonal matrix whose determinant is 1, as follows:</p><formula xml:id="formula_0">Re(e t (k)) Im(e t (k)) ? Re(rot(e h (k), ? r (k))) Im(rot(e h (k), ? r (k))) = cos ? r (k) ? sin ? r (k) sin ? r (k) cos ? r (k)</formula><p>Re(e h (k)) Im(e h (k)) .</p><p>It has been proved that RotatE can infer symmetry, asymmetry, inversion, and composition relation patterns <ref type="bibr" target="#b19">[20]</ref>. However, it cannot infer the transitivity pattern, and we will explain in what follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Representation of transitive relation</head><p>Relation r is a transitive relation, if for any instances (e 1 , r, e 2 ) and (e 2 , r, e 3 ) of relation r, (e 1 , r, e 3 ) is also an instance of r. For convenience of illustration, we define the transitive chain of a transitive relation as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1.</head><p>A transitive chain of r is defined as a chain of instances (e 1 , r, e 2 ), . . . , (e m?1 , r, e m ) of r, where e 1 , . . . , e m are different entities.</p><p>For the transitive closure of a transitive chain, every two entities in the chain should be connected by the transitive relation r. Hence, it can be represented as a fully connected directed graph with m(m?1) 2 edges. It can be proved that a transitive relation can be represented as the union of transitive closures of all transitive chains. Thus, the representation of transitive relations can be reduced to the representation of transitive chains.</p><p>An example of a transitive chain and its transitive closure are shown in <ref type="figure" target="#fig_0">Figure 1</ref>(a), where (e 1 , r, e 2 ), (e 2 , r, e 3 ), (e 3 , r, e 4 ) form a transitive chain, (e 1 , r, e 3 ) and (e 2 , r, e 4 ) are instances derived by transitivity via one-hop, and (e 1 , r, e 4 ) is the only instance derived via two-hops.</p><p>Due to the speciality of transitivity, current models are unable to effectively model such transformation in vector space. For instance, in TransE <ref type="figure" target="#fig_0">(Figure 1(b)</ref>), where a relation is regarded as a translation between the head and tail entities, it requires the translation to be a zero vector to model transitivity, which forces the embeddings of entities in a transitive chain to be the same. Thus, it cannot model transitivity. In RotatE <ref type="figure" target="#fig_0">(Figure 1(c)</ref>), it requires the relational rotation phase ? r (k) in each dimension to be 2n? (n = 0, 1, . . .) to model transitivity, which also forces the embeddings of entities to be the same in a transitive chain.</p><p>Our solution. Based on the observation on transitive closures of transitive chains, in each transitive chain (e 1 , r, e 2 ), . . . , (e m?1 , r, e m ), for each entity e j , (e j , r, e j+l ) can be derived by transitivity via l ? 1-hops (2 l m ? j). If we model each relation r as a kind of transformation T r , then it requires T r (e h ) = e t for each relation instance (h, r, t). Therefore, the transformation of a transitive relation must satisfies that T l r (e j ) = T r (e j ) (1 j m, 1 l m ? j), i.e. the result of transforming an entity embedding multiple times is equivalent to that of transforming it once. This inspires us to model the transitivity pattern in terms of the idempotent transformation (projection <ref type="bibr" target="#b24">[25]</ref>) which has the same property. For each relation r, let S r (k) be an invertible matrix on the kth dimension, a general orthogonal projection is defined by the idempotent matrix:</p><formula xml:id="formula_2">M r (k) = S r (k) ?1 a r (k) 0 0 b r (k) S r (k), (a r (k), b r (k) ? {0, 1}).<label>(2)</label></formula><p>Without loss of generality, we simply set S r (k) = cos ? p (k) ? sin ? p (k) sin ? p (k) cos ? p (k) to be a rotation matrix, which rotates the original axis by a phase ? p (k). The orthogonal projection p r (k) defined by M r (k) is performed in the new axis after rotation:</p><formula xml:id="formula_3">p r (k)(x + yi) = [1 i]M r (k) x y .<label>(3)</label></formula><p>In the rest of paper, we will omit the dimensional indices (k) in M r (k) and p r (k) for simplicity. In this way, for entities e 1 , . . . , e m in a transitive chain, we have p l r (e j (k)) = p r (e j (k)) (1 j m, 1 l m ? j). This implies that p r (e 1 (k)) = ? ? ? = p r (e m (k)), which does not force the entity embeddings e 1 , . . . , e m to be the same. The embeddings e 1 , . . . , e m can be different to each other and have the same projected vector under p r .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Rot-Pro model</head><p>Model formulation. In order to model not only transitivity but also other relation patterns shown in <ref type="table" target="#tab_0">Table 1</ref>, we combine the above projection based representation for transitivity and the relational rotation based representation for symmetry, asymmetry, inversion, and composition together. We propose Rot-Pro to model relations as relational rotations on the projected entity embeddings on complex space C d . For each triple (h, r, t), the Rot-Pro model requires that rot(p r (e h (k)), ? r (k)) = p r (e t (k)).</p><p>(4) We demonstrate in the following theorem that Rot-Pro enables the modeling and inferring of all the five types of relation patterns introduced above. Theorem 1. Rot-Pro can infer the symmetry, asymmetry, inversion, composition, and transitivity patterns.</p><p>Proof. (1) Let a r = 1 and b r = 1, M becomes an identity matrix and p becomes an identity transformation, and our model is reduced to the RotatE model. Thus, Rot-Pro can also infer the symmetry, asymmetry, inversion and composition patterns as RotatE does <ref type="bibr" target="#b19">[20]</ref>. (2) Here we will construct the solutions in Rot-Pro model for transitive relations. Let a r = 1 and b r = 0, p r is a projection to the real axis x as shown in <ref type="figure">Figure 2</ref> 2 . As discussed in previous section, to model the transitivity of relation r, the projected entity embeddings in a transitive chain must satisfy that rot(p(rot(p(e j (k)), ? r (k))), ? r (k)) = rot(p r (e j (k)), ? r (k)) = p r (e j+2 (k)) = p r (e j+1 (k)). Therefore, the phase of relational rotation ? r (k) can only be 2n? (n = 0, 1, 2, . . .) and p r (e j (k)) = p r (e 1 (k)) for any 1 &lt; j m.</p><p>According to <ref type="bibr">Equation 4</ref>, the following equation is expected to hold.</p><formula xml:id="formula_4">M r Re(e j (k)) Im(e j (k)) = cos ? r (k) ? sin ? r (k) sin ? r (k) cos ? r (k) M r Re(e 1 (k)) Im(e 1 (k)) = M r Re(e 1 (k)) Im(e 1 (k))<label>(5)</label></formula><p>The above equation holds iff</p><formula xml:id="formula_5">cos ? p (k)Re(e j (k)) ? sin ? p (k)Im(e j (k)) = cos ? p (k)Re(e 1 (k)) ? sin ? p (k)Im(e 1 (k)). (6)</formula><p>This equation holds if for any e j in the transitive chain,</p><formula xml:id="formula_6">cos ? p (i)Re(e j (k)) ? sin ? p (k)Im(e j (k)) = c k ,</formula><p>where c k = cos ? p (k)Re(e 1 (k)) ? sin ? p (k)Im(e 1 (k)) is a constant. That is, all these entity embeddings e j (k) = x + yi in the transitive chain are located in the line defined by Equation <ref type="formula" target="#formula_7">(7)</ref> on the complex plane as shown in <ref type="figure">Figure 2</ref>.</p><formula xml:id="formula_7">cos ? p (k)x ? sin ? p (k)y = c k .<label>(7)</label></formula><p>Here, different value of c k can represent different transitive chain. In summary, we construct the solutions for representing transitivity in Rot-Pro model, i.e. a r (k) = 1, b r (k) = 0, ? r (k) = 2n?, and for any entity embedding e j , it satisfies that cos ? p (i)Re(e j (k)) ? sin ? p (k)Im(e j (k)) = c k , where c k is a constant.</p><p>Score function. For each triple (h, r, t), the distance function of the Rot-Pro model is defined as following:</p><formula xml:id="formula_8">d r (e h , e t ) = rot(p r (e h ), ? r ) ? p r (e t ) .<label>(8)</label></formula><p>The score function f r (e h , e t ) = ?d r (e h , e t ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Optimization objective</head><p>In the training process, we adopt the self-adversarial negative sampling, which has been proved as an effective optimization approach to KGE <ref type="bibr" target="#b19">[20]</ref>. The negative sampling loss L s with self-adversarial training is defined as:</p><formula xml:id="formula_9">L s = ? log ?(? ? d r (h, t)) ? n j=1 p(h j , r, t j ) log ?(d r (h j , t j ) ? ?)<label>(9)</label></formula><p>where ? is a fixed margin, ? is the sigmoid function, (h j , r, t j ) is the jth negative instance and p(h j , r, t j ) is the distribution for negative sampling <ref type="bibr" target="#b19">[20]</ref>.</p><p>In addition, to ensure the learned matrix to be a projection, the values of a and b in Equation 2 should be restricted to 0 or 1. To enforce such constraint, we proposed a projection penalty loss as follows:</p><formula xml:id="formula_10">L p = |R| j=1 (||(a j ? 1.0) a j q j || 2 + ||(b j ? 1.0) b j q j || 2 ).<label>(10)</label></formula><p>Here |R| is the number of relations, is the Hadamard product, and</p><formula xml:id="formula_11">q j = {q j (k)} d k=1 , where q j (k) = 1 if [(x j (k) ? 1.0) (x j (k) ? 0.0)] &lt; ? m , otherwise q j (k) = ? &gt; 1.</formula><p>Here ? m and ? are hyper-parameters. We define q j to impose more penalty to values which are far from 0 or 1 than that of values which are close to 0 or 1.</p><p>Let ? be a hyper-parameter, the total loss is defined as the weighted average of the above two losses.</p><formula xml:id="formula_12">L = L s + ? ? L p .<label>(11)</label></formula><p>4 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We evaluate the Rot-Pro model on four well-known benchmarks. In general, FB15k-237 and WN18RR are two widely-used benchmarks and YAGO3-10 and Countries are two benchmarks with abundant relation patterns including transitivity.</p><p>? </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation protocol</head><p>We evaluate the KGE models on three common evaluation metrics: mean rank (MR), mean reciprocal rank (MRR), and top-k Hit Ratio (Hit@k). For each valid triples (h, r, t) in the test set, we replace either h or t with every other entities in the dataset to create corrupted triples in the link prediction task. Following previous work <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b15">16]</ref>, all the models are evaluated in a filtered setting, i.e, corrupt triples that appear in training, validation, or test sets are removed during ranking. The valid triple and filtered corrupted triples are ranked in ascending order based on their prediction scores. Lower MR, higher MRR or higher Hit@k indicate better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiment setup</head><p>With the hyper-parameters introduced, we train Rot-Pro using a grid search of hyper-parameters: fixed margin ? in Equation 9 ? {0.1, 4.0, 6.0, 9.0, 16.0, 20.0}, weights tuning hyper-parameters for loss, ? ? {0.0001, 0.0005, 0.0008}, value of ? m in Equation 10 ? {1e ?6 , 5e ?6 , 1e ?5 }, value  of ? in Equation 10 ? {1.3, 1.5, 2.0}. Both the real and imaginary parts of the entity embeddings are uniformly initialized, and the phases of the relational rotations are initialized between {(??, ?), (? ? 2 , ? 2 )}. In some settings, the phases of the relational rotations are also normalized to between {(??, ?), (? ? 2 , ? 2 )} during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Main results</head><p>We compare Rot-Pro with several state-of-the-art models, including TransE <ref type="bibr" target="#b2">[3]</ref>, DistMult <ref type="bibr" target="#b1">[2]</ref>, Com-plEx <ref type="bibr" target="#b20">[21]</ref>, ConvE <ref type="bibr" target="#b22">[23]</ref>, as well as RotatE <ref type="bibr" target="#b19">[20]</ref> and BoxE <ref type="bibr" target="#b0">[1]</ref>, to empirically show the importance of being able to model and infer more relation patterns for the task of predicting missing links. <ref type="table" target="#tab_3">Table 3</ref> summarizes our results on FB15k-237 and WN18RR, where results of baseline models are taken from Sun et al <ref type="bibr" target="#b19">[20]</ref> and Ralph et al <ref type="bibr" target="#b0">[1]</ref>. We can see that Rot-Pro outperforms the baseline models on most evaluation metrics. Compared to RotatE, the improvement of Rot-Pro is limited since there is no sufficient transitive relation defined on these two datasets, but the results are still comparable with other baseline models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Validation of learned representation of transitive relations</head><p>We conduct further analysis on the the Rot-Pro model to verify that the model can actually learn the representations of transitive relations and have the theoretical property as expected. To do this, we first investigate the distributions of relational rotation phases in all dimensions of entity embeddings obtained by training on YAGO3-10. According to our theoretical analysis, we expect the model could learn to represent transitivity, i.e. for any non-trivial projection (i.e. a = 1, b = 0 or a = 0, b = 1), the corresponding phase of relational rotation should be 2n?. The experimental results are shown in <ref type="figure" target="#fig_2">Figure 3</ref>  experiments reveal that by turning the initialization range of the relational rotation phases, the problem of learning unexpected relational rotation phase ? could be mitigated. By changing the initialization range of relational rotation phases from (??, ?) to (? ? 2 , ? 2 ), the number of relational rotation phases ? becomes significantly less. When we further restrict the relational rotation phases to (? ? 2 , ? 2 ) during training, almost all relational rotation phases become 0 or 2?.</p><p>The results above are also reflected in the quantitative test. To fully understand the impact of changing initialization range on the performance of the Rot-Pro model on modelling transitive relations, we construct three sub-test sets S1, S2, S3 of YAGO3-10 for evaluation, which consist of a single transitive relation isLocatedIn. Test set S1 contains instances of isLocatedIn in the original test set. Test set S2 is obtained by applying the transitivity once on instances of isLocatedIn in the YAGO3-10 dataset. Test set S3 is constructed similarly to S2, except by applying the transitivity at least twice.</p><p>We take the RotatE model as baseline, and compare it with three variant of Rot-Pro models with different settings: the first one with relational rotation phase initialized in (??, ?), the second one with relational rotation phase initialized in (? ? 2 , ? 2 ), the third one with relational rotation phase restricted in (? ? 2 , ? 2 ) during training. The experimental result is shown in <ref type="figure" target="#fig_3">Figure 4</ref>(a). It shows that tuning of initialization range also largely improves the performance of the Rot-Pro model, which  coincides with the improvement of learning correct representations of transitive relations. All the variant of Rot-Pro models outperform RotatE significantly, especially when the relational rotation phase is restricted to (? ? 2 , ? 2 ) during training. We also visualize one dimension of embeddings of three entities connected by a transitive relation isLocatedIn in YAGO3-10. <ref type="figure" target="#fig_3">Figure 4</ref>(c) shows the visualization of entity embeddings of the Rot-Pro model trained with initialization range (??, ?), which contains a miss placed entity embedding. While <ref type="figure" target="#fig_3">Figure 4(d)</ref> is the visualization of embeddings of entities of the Rot-Pro model trained by restricting the relational rotation phase to (? ? 2 , ? 2 ) during training, where all entity embeddings in the transitive chain are placed correctly as expected. We can see that these vectors are basically fit in a line and can almost be projected to the same vector in the rotated axis.</p><formula xml:id="formula_13">1 3 ? ? 2 2 ? 2 , ( 4 ) 1 , ( 3 ) 4 ( 3 ) ? ( 1 , ?) ( 4 ) ? ( 2 , ?) 4 = ( 1 , ?) (a)</formula><p>Explanation. The Rot-Pro model with no additional restrictions on the relational rotation phase may learn a phase ? which does not exactly meet our expectation. A possible representations of four entities in a transitive chain with relational rotation phase ? is illustrated in <ref type="figure" target="#fig_4">Figure 5(a)</ref>, in which four out of the six instances of transitive relation are correctly represented, while the other two instances (e 1 , r, e 3 ) and (e 2 , r, e 4 ) are not. Obviously, this is not an optimal solution for the model, and the reason is likely to be that the model falls into a local optimum during the learning process. To demonstrate this, we plot the variation of loss for three triples in a transitive chain with the relational rotation phase range over (0, 2?). The result is shown in <ref type="figure" target="#fig_4">Figure 5</ref>(b). We can find that there is indeed a local optimum at ?, and the global optimum is at 0 and 2?, which is consistent with our conjecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Limitation</head><p>According to the experimental results, Rot-Pro is sensitive to the range of relational rotation phases, and hence prone to fall into the local optimum solution. Though it can learn the idempotency of transitivity correctly by enforcing addition constraints on training, however, such constraints have negative impact on the learning of other relation patterns, such as symmetry. We can find in <ref type="figure" target="#fig_5">Figure 6</ref>(a) that for a symmetric relation, the relational rotation phases learned by a Rot-Pro without phase constraint are either 0, ? or 2?, which indicates that it has similar capability of modeling and inferring symmetry relation pattern as RotatE. By narrowing of the range of relational rotation phases, the histogram on the symmetry relation is gradually disrupted as shown in <ref type="figure" target="#fig_5">Figure 6</ref>(b) and 6(c). Therefore, a trade-off should be made between the better modeling and inferring of transitivity and the other relation patterns. Such limitation might be further optimized through learning each relation pattern separately and integrate through mechanisms such as attention, which we will study in future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we theoretically showed that the transitive relations can be modeled with projections that is an idempotent transformation. We also theoretically proved that the proposed Rot-Pro model is able to infer the symmetry, asymmetry, inversion, composition, and transitivity patterns. Our experimental results empirically showed that the Rot-Pro model can effectively learn the transitivity pattern. Our model also has the potential to be improved by extending the complex space to higher dimension space, such as quaternion space <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b21">22]</ref>. While the proof of expressiveness in many previous works is focused on the expressiveness of each relation pattern separately, it is worthwhile to further investigate whether a model can handle all common relation patterns simultaneously, considering that a single relation may exhibit multiple relation patterns and different relation patterns may have complex interactions in knowledge graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proof of a property of transitive relation</head><p>In section 3.2 of the submitted paper, we use the conclusion that "the transitive relation can be represented as the union of transitive closures of of all transitive chains." Here, we prove it in the following lemma. Proof. For any given transitive relation r, it can be represented as a directed graph G r which satisfies that for any vertex e and e , if there is a path from e to e , then there is an edge connecting e to e directly. We can see that if there is a path e, e 1 , . . . , e m , e from e to e whose length is larger than 1 (i.e. m 1), then the edge connecting e and e directly can be derived through transitivity, i.e. the transitive chain (e, r, e 1 ), . . . , (e m , r, e ) implies that (e, r, e ). By removing any edge (e, r, e ) that e and e is connected by a path longer than 1, we can obtain a new graph G r .</p><p>For any instance (e, r, e ), if it is an edge in G r , then (e, r, e ) is a transitive chain itself and hence it is in the transitive closure of itself; otherwise, (e, r, e ) is an edge removed from G r and hence there is a path from e to e in G r whose length is larger than 1, then (e, r, e ) can be derived through transitivity based on the path, i.e. (e, r, e ) is in the transitive closure of the path (transitive chain). Hence any instance of a transitive relation is in a transitive closure of a transitive chain. Thus, a transitive relation can be represented as the union of transitive closures of all transitive chains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Statistics and split of datasets.</head><p>The datasets we used for experiments are open-sourced, which can be obtained in the source code 3 of RotatE <ref type="bibr" target="#b19">[20]</ref>. <ref type="table" target="#tab_6">Table 5</ref> shows the statistic of these datasets, where the number of training triples in the S1, S2, and S3 datasets of Counties are separated by '/'. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Hyper-parameter settings</head><p>We list the best hyper-parameter setting of Rot-Pro on the above datasets in <ref type="table" target="#tab_7">Table 6</ref>. The setting of dimension d and batch size b is the same as RotatE <ref type="bibr" target="#b19">[20]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Transitivity performance comparison with BoxE</head><p>The fully expressive of BoxE refers to that it is able to express inference patterns, which includes symmetry, anti-symmetry, inversion, composition, hierarchy, intersection, and mutual exclusion. However, it does not model and infer the transitivity pattern. Therefore, we further conducted experiments on the three sub-test sets S1, S2, S3 we sampled from YAGO3-10 as described in the paper to verify this. The experimental results are listed as below. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of transitive chain and the limitation of TransE and RotatE on representing transitivity pattern.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>4 Figure 2 :</head><label>42</label><figDesc>The representation of transitivity pattern in complex plane.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>(a). It can be observed that the Rot-Pro model does learn the relational rotation phases 0 and 2? as expected. However, it also learns the unexpected relational rotation phase ?. Further Distributions of relational rotation phases. The x-axis is the relational rotation phases. The y-axis is the number of dimensions of relation embeddings that have non-trivial projection before rotation with a specific phase, i.e. the embedding of parameter a and b are 1, 0 or 0, 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>-(-, )-Init Rot-Pro-(-/2, /2)-Init Rot-Pro-(-/2, /2)-Train (b) Result on transitive test sets (c) Rot-Pro-(??, ?)-Init (d) Rot-Pro-(? ? 2 , ? 2 )-Train (a) shows the Hit@10 results of the RotatE and Rot-Pro models on three test sets for transitivity. (b) and (c) show the representation of four entities in a transitive chain in two variants of Rot-Pro models with different constraints of relational rotation phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Example illustration (b) Variation of loss (a) is an example of miss-placed four entities on a transitive chain, which consist of three triples: T 1 : (Florida_State_University, isLocatedIn, United_States), T 2 : (United_States, isLocatedIn, North_America), T 3 : (North_America, isLocatedIn, Americas). (b) is the variation of loss for these triples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>The distribution of relational rotation phases of three Rot-Pro variants over all dimensions of a specific symmetric relation isMarriedTo. The meaning of x and y axes is the same asFigure 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Lemma 1 .</head><label>1</label><figDesc>A transitive relation can be represented as the union of transitive closures of all transitive chains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Common relation patterns. Relation pattern Definition Symmetry if (h, r, t), then (t, r, h) Asymmetry if (h, r, t), then?(t, r, h) Inversion if r = p ?1 and (h, r, t), then (t, p, h) Composition</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>The supported relation patterns of several models<ref type="bibr" target="#b19">[20]</ref>. Experimental results show that the Rot-Pro model can effectively learn the transitivity pattern. The Rot-Pro model achieves the state-of-the-art results on the link prediction task in the Countries dataset containing transitive relations and outperforms other models in the YAGO3-10 and FB15k-237 dataset.</figDesc><table><row><cell>Symmetry Asymmetry Inversion Composition Transitivity</cell></row><row><cell>TransE</cell></row><row><cell>DistMult</cell></row><row><cell>ComplEx</cell></row><row><cell>RotatE</cell></row><row><cell>Rot-Pro</cell></row><row><cell>patterns.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>WN18RR<ref type="bibr" target="#b22">[23]</ref> is a subset of WN18<ref type="bibr" target="#b2">[3]</ref> from WordNet<ref type="bibr" target="#b14">[15]</ref>. WordNet is a dataset that characterizes associations between English words. Compared with WN18, WN18RR retains most of the symmetric, asymmetric and compositional relations, while removing the inversion relations. It contains 40,943 entities, 11 relations, and 86,835 training triples. ? YAGO3-10: YAGO<ref type="bibr" target="#b18">[19]</ref> is a dataset which integrates vocabulary definitions of WordNet with classification system of Wikipedia. YAGO3-10 [13] is a subset of YAGO, which contains 123,182 entities, 37 relations and 1,079,040 training triples. According to the ontology of YAGO3, it contains almost all common relation patterns.</figDesc><table /><note>FB15k-237: Freebase [11] contains information including people, media, geographical and locations. FB15k is a subset of Freebase and FB15k-237 [24] is a modified version of FB15k, which excludes inverse relations to resolve a flaw with FB15k [23]. It contains 14,541 entities, 237 relations, and 272,115 training triples.? WN18RR:? Countries: Countries [8] is a relatively small-scale dataset, which contains 2 relations and 272 entities (244 countries, 5 regions and 23 sub-regions). The two relations of Countries are locatedIn and neighborOf, which are transitive and symmetric relations respectively. The Countries dataset has 3 tasks, each requiring inferring a composition pattern with increasing length and difficulty.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Link prediction results on FB15k-237 and WN18RR.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">FB15k-237</cell><cell></cell><cell></cell><cell></cell><cell>WN18RR</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="9">MR MRR Hit@1 Hit@3 Hit@10 MR MRR Hit@1 Hit@3 Hit@10</cell></row><row><cell>TransE [3]</cell><cell>357 .294</cell><cell>-</cell><cell>-</cell><cell>.465</cell><cell cols="2">3384 .226</cell><cell>-</cell><cell>-</cell><cell>.501</cell></row><row><cell>DistMult [2]</cell><cell>254 .241</cell><cell>.155</cell><cell>.263</cell><cell>.419</cell><cell>5110</cell><cell>.43</cell><cell>.39</cell><cell>.44</cell><cell>.49</cell></row><row><cell cols="2">ComplEx [21] 339 .247</cell><cell>.158</cell><cell>.275</cell><cell>.428</cell><cell>5261</cell><cell>.44</cell><cell>.41</cell><cell>.46</cell><cell>.51</cell></row><row><cell>ConvE [23]</cell><cell>244 .325</cell><cell>.237</cell><cell>.356</cell><cell>.501</cell><cell>4187</cell><cell>.43</cell><cell>.40</cell><cell>.44</cell><cell>.52</cell></row><row><cell>RotatE [20]</cell><cell>177 .338</cell><cell>.241</cell><cell>.375</cell><cell>.533</cell><cell cols="2">3340 .476</cell><cell>.428</cell><cell>.492</cell><cell>.571</cell></row><row><cell>BoxE [1]</cell><cell>163 .337</cell><cell>.238</cell><cell>.347</cell><cell>.538</cell><cell cols="2">3207 .451</cell><cell>.400</cell><cell>.472</cell><cell>.541</cell></row><row><cell>Rot-Pro</cell><cell>201 .344</cell><cell>.246</cell><cell>.383</cell><cell>.540</cell><cell cols="2">2815 .457</cell><cell>.397</cell><cell>.482</cell><cell>.577</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Link prediction results on YAGO3-10 and Countries.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">YAGO3-10</cell><cell></cell><cell cols="3">Countries (AUC-PR)</cell></row><row><cell></cell><cell>MR</cell><cell>MRR</cell><cell>Hit@1</cell><cell>Hit@3</cell><cell>Hit@10</cell><cell>S1</cell><cell>S2</cell><cell>S3</cell></row><row><cell>DistMult [2]</cell><cell>5926</cell><cell>.34</cell><cell>.24</cell><cell>.38</cell><cell>.54</cell><cell>1.00</cell><cell>0.72</cell><cell>0.52</cell></row><row><cell>ComplEx [21]</cell><cell>6351</cell><cell>.36</cell><cell>.26</cell><cell>.40</cell><cell>.55</cell><cell>0.97</cell><cell>0.57</cell><cell>0.43</cell></row><row><cell>ConvE [23]</cell><cell>1671</cell><cell>.44</cell><cell>.35</cell><cell>.49</cell><cell>.62</cell><cell>1.00</cell><cell>0.99</cell><cell>0.86</cell></row><row><cell>RotatE [20]</cell><cell>1767</cell><cell>.495</cell><cell>.402</cell><cell>.550</cell><cell>.670</cell><cell>1.00</cell><cell>1.00</cell><cell>0.95</cell></row><row><cell>BoxE [1]</cell><cell>1022</cell><cell>.560</cell><cell>.484</cell><cell>.608</cell><cell>.691</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Rot-Pro</cell><cell cols="2">1797542</cell><cell>.443</cell><cell>.596</cell><cell>.699</cell><cell>1.00</cell><cell>1.00</cell><cell>0.998</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc>summarizes our results on YAGO3-10 and Countries, which contain transitive relations. Hence the improvement of Rot-Pro over RotatE and other linear transformation models is much more significant. Specifically, Rot-Pro obtains better AUC-PR result than existing state-of-the-art approaches, which indicates that Rot-Pro could effectively infer relation patterns such as transitivity, symmetry and composition. As a translation transformation model, BoxE outperforms Rot-Pro on YAGO3-10 on most evaluation metrics, which indicates it is also a strong KGE model for inferring multiple relation patterns. However, the performance of BoxE on specific transitivity test sets is still not comparable with Rot-Pro, where additional experiments can be found in the appendix.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Statistics of datasetsOur model is implemented in Python 3.6 using Pytorch 1.1.0. Experiments are performed on a workstation with Intel Xeon Gold 5118 2.30GHz CPU and NVIDIA Tesla V100 16GB GPU.</figDesc><table><row><cell>Triples</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Hyper-parameter settings dimension d batch size b fixed margin ? ?</figDesc><table><row><cell>m</cell><cell>?</cell><cell>?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Link prediction result of BoxE and Rot-Pro on S1, S2, S3 test sets.</figDesc><table><row><cell></cell><cell>S1</cell><cell></cell><cell>S2</cell><cell></cell><cell>S3</cell><cell></cell></row><row><cell></cell><cell cols="6">BoxE Rot-Pro BoxE Rot-Pro BoxE Rot-Pro</cell></row><row><cell>MR</cell><cell>.343</cell><cell>.337</cell><cell>.290</cell><cell>.328</cell><cell>.381</cell><cell>.447</cell></row><row><cell>Hit@1</cell><cell>.255</cell><cell>.247</cell><cell>.262</cell><cell>.235</cell><cell>.349</cell><cell>.337</cell></row><row><cell>Hit@3</cell><cell>.385</cell><cell>.376</cell><cell>.291</cell><cell>.366</cell><cell>.385</cell><cell>.517</cell></row><row><cell cols="2">Hit@10 .504</cell><cell>.512</cell><cell>.342</cell><cell>.522</cell><cell>.439</cell><cell>.626</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We can also set a = 0 and b = 1, then p is a projection to the imaginary axis y .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/DeepGraphLearning/KnowledgeGraphEmbedding/tree/master/data</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments and Disclosure of Funding</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">BoxE: A box embedding model for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Abboud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?smaililkan</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Salvatori</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Lowdimensional hyperbolic knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Chami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adva</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da-Cheng</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="6901" to="6914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Question answering over knowledgebase with attention-based lstm networks and knowledge embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 16th International Conference on Cognitive Informatics and Cognitive Computing (ICCI*CC)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="243" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A novel embedding model for knowledge base completion based on convolutional neural network</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</title>
		<editor>Dat Quoc Nguyen Dai Quoc Nguyen, Tu Dinh Nguyen and Dinh Phung</editor>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="327" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">WDAqua-core1: a question answering service for RDF knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Kamal Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Diefenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion of the The Web Conference 2018 on The Web Conference (WWW)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1087" to="1091" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On approximate reasoning capabilities of low-rank vector spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theo</forename><surname>Trouillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Syposium on Knowledge Representation and Reasoning (KRR): Integrating Symbolic and Neural Approaches</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding via dynamic mapping matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu Kang Liu Guoliang Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="687" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">TransA: An adaptive approach for knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI Conference on Artificial Intelligence</title>
		<meeting>AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paritosh</forename><forename type="middle">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Holographic embeddings of knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI conference on artificial intelligence</title>
		<meeting>AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1955" to="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">YAGO3: A knowledge base from multilingual wikipedias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mahdisoltani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIDR 2015</title>
		<meeting>CIDR 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Volker Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="39" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning attention-based embeddings for relation prediction in knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Nathani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jatin</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charu</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Kaul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4710" to="4723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generating natural answers by incorporating copying and retrieving mechanisms in sequence-to-sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">TransMS: knowledge graph embedding for complex relations by multidirectional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="1935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Yago: A core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on World Wide Web</title>
		<meeting>the 16th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">RotatE: Knowledge graph embedding by relational rotation in complex space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 33rd Int. Conf. Mach. Learn</title>
		<meeting>33rd Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2071" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Orthogonal relation transforms with graph context modeling for knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangtao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="2713" to="2722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Convolutional 2D knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd AAAI Conference on Artificial Intelligence</title>
		<meeting>the 32nd AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Observed versus latent features for knowledge base and text inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality</title>
		<meeting>the 3rd Workshop on Continuous Vector Space Models and their Compositionality</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Linear Algebra: An Introduction to Abstract Mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Valenza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Undergraduate Texts in Mathematics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Relation embedding with dihedral group in knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th AAAI Conference on Artificial Intelligence</title>
		<editor>Maosong Sun Yang Liu Yankai Lin, Zhiyuan Liu and Xuan Zhu</editor>
		<meeting>the 29th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2181" to="2187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Quaternion knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2731" to="2741" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
