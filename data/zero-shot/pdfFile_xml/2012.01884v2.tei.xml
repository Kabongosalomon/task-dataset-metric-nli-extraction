<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Temporal Pyramid Network for Pedestrian Trajectory Prediction with Multi-Supervision</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongqin</forename><surname>Liang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Electronics and Information Engineering</orgName>
								<orgName type="institution">Shenzhen University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Guangdong Key Laboratory of Intelligent Information Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanman</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Electronics and Information Engineering</orgName>
								<orgName type="institution">Shenzhen University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Guangdong Key Laboratory of Intelligent Information Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Electronics and Information Engineering</orgName>
								<orgName type="institution">Shenzhen University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Guangdong Key Laboratory of Intelligent Information Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiantao</forename><surname>Zhou</surname></persName>
							<email>jtzhou@um.edu.mo</email>
							<affiliation key="aff0">
								<orgName type="department">College of Electronics and Information Engineering</orgName>
								<orgName type="institution">Shenzhen University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Guangdong Key Laboratory of Intelligent Information Processing</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Macau</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">State Key Laboratory of Internet of Things for Smart City</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Zou</surname></persName>
							<email>wzou@szu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Electronics and Information Engineering</orgName>
								<orgName type="institution">Shenzhen University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Guangdong Key Laboratory of Intelligent Information Processing</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Temporal Pyramid Network for Pedestrian Trajectory Prediction with Multi-Supervision</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Predicting human motion behavior in a crowd is important for many applications, ranging from the natural navigation of autonomous vehicles to intelligent security systems of video surveillance. All the previous works model and predict the trajectory with a single resolution, which is rather inefficient and difficult to simultaneously exploit the long-range information (e.g., the destination of the trajectory), and the shortrange information (e.g., the walking direction and speed at a certain time) of the motion behavior. In this paper, we propose a temporal pyramid network for pedestrian trajectory prediction through a squeeze modulation and a dilation modulation. Our hierarchical framework builds a feature pyramid with increasingly richer temporal information from top to bottom, which can better capture the motion behavior at various tempos. Furthermore, we propose a coarse-to-fine fusion strategy with multi-supervision. By progressively merging the top coarse features of global context to the bottom fine features of rich local context, our method can fully exploit both the long-range and short-range information of the trajectory. Experimental results on several benchmarks demonstrate the superiority of our method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Modeling the behaviors of pedestrians is an essential step for many applications, including self-driving platforms for safe decision making <ref type="bibr" target="#b14">(Liang et al. 2019)</ref>, socially-aware robots for natural navigation <ref type="bibr" target="#b19">(Monfort, Liu, and Ziebart 2015)</ref> and surveillance systems to identify suspicious activities <ref type="bibr" target="#b1">(Bastani, Marcenaro, and Regazzoni 2016)</ref>. Trajectory prediction as one of the most important future behavior modeling tasks, aims to predict possible future trajectories according to historical paths in the last few seconds <ref type="bibr" target="#b0">(Alahi et al. 2016;</ref><ref type="bibr" target="#b4">Gupta et al. 2018;</ref><ref type="bibr" target="#b18">Mohamed et al. 2020;</ref><ref type="bibr" target="#b26">Xu, Yang, and Du 2020)</ref>. Despite its importance, predicting the trajectory is very challenging due to the inherent properties of pedestrians. First, human motions are highly multimodal, which means that there could be several socially-acceptable and distinct future behaviors under the same trajectory history. Second, human motions are highly affected by the people around them, Jointly modeling the complex social behaviors is rather challenging in reality. <ref type="bibr">*</ref> The corresponding author.</p><p>Traditional pedestrian trajectory prediction algorithms heavily rely on the handcrafted rules to describe human motions <ref type="bibr" target="#b6">(Helbing and Molnar 1995;</ref><ref type="bibr" target="#b20">Pellegrini et al. 2009</ref>), which are difficult to generalize in complex new scenes. Recently, the data-driven based algorithms have received significant attention in the community. Among them, RNN and its variant LSTM have been widely adopted. Social-LSTM <ref type="bibr" target="#b0">(Alahi et al. 2016</ref>) as one of the earliest works on pedestrian trajectory prediction, encoded the motion information using a recurrent network. CIDNN <ref type="bibr" target="#b25">(Xu, Piao, and Gao 2018)</ref> considered different importance of persons to a target pedestrian in a crowd interaction module. The recent works PIF <ref type="bibr" target="#b14">(Liang et al. 2019</ref>) and SR-LSTM ) enhanced the performance of Social-LSTM by taking the scene context as side information. Though the RNN architecture endowed above methods to learn and predict trajectories in a datadriven manner, they failed to capture the multimodal nature of human.</p><p>In order to produce multiple socially-acceptable trajectories, some researchers suggested constructing the recurrent models with generative settings, which led to learning the distribution of the future trajectory rather than directly generating a deterministic path <ref type="bibr" target="#b4">(Gupta et al. 2018;</ref><ref type="bibr" target="#b23">van der Heiden et al. 2019;</ref><ref type="bibr" target="#b13">Li, Ma, and Tomizuka 2019;</ref><ref type="bibr" target="#b29">Zhao et al. 2019)</ref>. Social-GAN <ref type="bibr" target="#b4">(Gupta et al. 2018</ref>) is the pioneering trajectory prediction work incorporating the LSTM model with the generative adversarial networks (GANs) <ref type="bibr">(Goodfellow et al. 2014)</ref>, permitting to produce multiple plausible trajectories. SoPhie ) improved social-GAN through a scene feature extraction component. Some researchers proposed to use graph to model the social interactions <ref type="bibr" target="#b24">Vemula, Muelling, and Oh 2018;</ref><ref type="bibr" target="#b11">Kosaraju et al. 2019;</ref><ref type="bibr" target="#b7">Huang et al. 2019a;</ref><ref type="bibr" target="#b9">Ivanovic and Pavone 2019;</ref><ref type="bibr" target="#b22">Shi et al. 2020;</ref><ref type="bibr" target="#b18">Mohamed et al. 2020)</ref>. For example, the most recent work Social-STGCNN <ref type="bibr" target="#b18">(Mohamed et al. 2020</ref>) modeled trajectories using the spatio-temporal graph convolution neural network, and achieved promising performance.</p><p>Though trajectory prediction has been studied from many aspects, all the existing methods encoded and decoded the trajectory with a single resolution (i.e., a fixed length of time steps). This makes them fail to fully exploit the temporal relations of the motion behavior. We argue that simultaneously modeling the global context (e.g., where the pedestrian plans <ref type="figure">Figure 1</ref>: The framework of our proposed TPNMS. The network consists of a generator and a discriminator. The input of the generator is the historical trajectories of pedestrians, and the output is the corresponding predicted future trajectories. The pyramidal source is first constructed through the temporal squeeze modulation and the temporal dilation modulation. Then, an encoder-decoder network is adopted for hierarchical feature learning. Features are finally fed into a fusion network (presented in <ref type="figure" target="#fig_1">Fig. 3</ref>) to generate the future trajectories with multi-supervision.</p><p>to go) and the local context (e.g., the direction and speed at a certain time) with a single resolution is inefficient or rather difficult, if possible.</p><p>To alleviate the above limitation, in this work, we propose a novel Temporal Pyramid Network with Multi-Supervision (TPNMS) for pedestrian trajectory prediction. As shown in <ref type="figure">Fig. 1</ref>, our framework consists of a generator G and a discriminator D, which are trained in opposition to each other. First, we devise a pyramid feature extractor composed of a squeeze module and a dilation module for multi-scale feature generation from a fixed length input trajectory. The pyramidal features are then fed into an RNN based Encoder-Decoder to generate hierarchical representations of the motion. To ensure effective representations of all pyramid levels, we further propose a coarse-to-fine fusion strategy with multi-supervision through progressively combining higher pyramid levels with lower ones. Finally, similar to Social-GAN, our network is trained in an adversarial manner to produce multiple socially-acceptable motion trajectories, conforming to the multimodal behavior of pedestrians.</p><p>It should be noted that most of the previous pyramid representation methods were designed in spatial domain and only for detection or recognition tasks. To the best of our knowledge, this is the first attempt that models trajectories in a scene as temporal pyramids. As will be shown later, our method outperforms previous approaches by a big margin on several datasets. The main contributions of our work are:</p><p>? A novel temporal pyramid network is proposed to capture the motion behaviors of pedestrians at various tempos. With our hierarchical design, both short-range and long-range motion behaviors can be effectively exploited.</p><p>? By progressively combining the global context with the local one, we further propose a coarse-to-fine trajectory modeling in a multi-supervised fashion. ? Our hierarchical design can be regarded as auxiliary modules, and easily extended to other sequence prediction frameworks, thus bringing performance improvements.</p><p>2 Proposed Temporal Pyramid Network with Multi-Supervision (TPNMS)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem Formulation</head><p>Given a set of N pedestrians in a scene with observed positions over a fixed duration, the trajectory prediction algorithm aims to jointly reason and forecast the future trajectories of all pedestrians. Let (x t i , y t i ) be the position of the i-th pedestrian at the time step t, where i ? {1, ..., N }. Denote X</p><formula xml:id="formula_0">(t1:t2) i = [(x t1 i , y t1 i ), ..., (x t2 i , y t2 i )]</formula><p>as the observed historical trajectory of the i-th pedestrian from the time step t 1 to t 2 . Similarly, we define Y (t1:t2) i as the future trajectory of the i-th pedestrian from the time t 1 to t 2 . The trajectory prediction algorithm takes as input the previous trajectories with t o time steps of all pedestrians in a scene, denoted by</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X = {X</head><p>(1:to) 1 , ..., X</p><p>(1:to) N },</p><p>(1) and aims to predict their trajectories in the next t p time steps simultaneously. We use Y to represent the true future trajectories, i.e.,</p><formula xml:id="formula_1">Y = {Y (to+1:to+tp) 1 , ..., Y (to+1:to+tp) N }.</formula><p>(2) For the sake of brevity, we hereafter will drop the superscript when there is no ambiguity, i.e., X i X . We further use X and Y to represent a generic historical trajectory and the corresponding future trajectory, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TPN for Trajectory Prediction</head><p>Feature pyramids play a significantly important role in the field of computer vision for recognizing objects at vastly different scales <ref type="bibr" target="#b5">(He et al. 2015)</ref>. For example, the popular hand-engineered feature extractors such as SIFT <ref type="bibr" target="#b16">(Lowe 2004</ref>) were designed to compute features in a multi-scale space. Lin et. al. <ref type="bibr" target="#b15">(Lin et al. 2017</ref>) accommodated the idea of pyramid representation to deep convolutional neural networks, achieving quite promising performance in the detection task. Most of the previous approaches were designed in spatial domain. More recently, some works proposed to extract hierarchical features in temporal domain, and demonstrated its effectiveness in action recognition ) and scene classification <ref type="bibr" target="#b8">(Huang et al. 2019b)</ref>. Motivated by the great success of the pyramid representation, we propose a temporal pyramid network (TPN) tailored for pedestrian trajectory prediction. Compared with the existing algorithms which model the trajectory with a single resolution, our temporal pyramid architecture is effective in exploiting the motion behaviors at various tempos, and the hierarchical generation process could greatly facilitate the joint modeling of both global and local contexts. Besides, benefiting from the LSTM network, all levels of pyramids share the same parameters. This allows our method to operate on a single-branch backbone regardless of how many levels are adopted, then avoid to increase model complexity.</p><p>For better illustration, we decompose our TPN into the following two components: 1) pyramidal source construction, and 2) hierarchical feature representation.</p><p>Pyramidal source construction For each trajectory of the input X , we propose to generate a set of L hierarchical features with multi-resolution, and then construct a feature pyramid, having increasingly richer temporal information from top to bottom. With the aid of the pyramid framework, our method can fully exploit the short-range behavior and the long-range behavior in a hierarchical way. As depicted in <ref type="figure">Fig. 1</ref>, this process can be summarized as two procedures, i.e., 1) the temporal squeeze modulation, and 2) the temporal dilation modulation. Temporal squeeze modulation: Assume that there are to-tally L scales of the temporal pyramid network for each trajectory. Denote the feature of the k-th scale as X k i , which is identical to X i . The goal of the temporal squeeze modulation is to reduce the impact of the local context, and generate a set of features with increasingly stronger global context from X . To this end, we propose to gradually produce the top k ? 1 scales through uniformly sampling from the scale below with an interval factor 2. In this work, we refer to the above process as the temporal squeeze modulation. <ref type="figure" target="#fig_0">Fig. 2(a)</ref> illustrates the procedure of the temporal squeeze modulation. For the -scale ( &lt; k), the feature can be represented as</p><formula xml:id="formula_2">X i = [(x 1 i ,? 1 i ), ..., (x m i ,? m i )],<label>(3)</label></formula><p>where m = t o /2 k? , and</p><formula xml:id="formula_3">x j i = x 1+2 k? (j?1) i ,? j i = y 1+2 k? (j?1) i .<label>(4)</label></formula><p>We can see that the detailed short-range information of the motion is gradually weakened by the temporal squeeze modulation, which encourages the higher scales to capture more long-range motion behaviors of pedestrians. Temporal dilation modulation: Note that the observed trajectories are usually of short duration, then the number of scales generated by the temporal squeeze modulation cannot fully capture the motion behaviors. To handle this issue, we further introduce a complementary procedure called temporal dilation modulation, which is similar to the dilated convolution operator widely used in various vision tasks. The temporal dilation modulation could generate more dense trajectories for hierarchical feature representation, then exploit richer short-range information of the motion. We propose to conduct the temporal dilation modulation through trajectory interpolation. It should be noted that pedestrians usually walk/run at varying speeds, accelerations and in different directions over time. In order to generate smooth dense trajectories, in this work, we adopt the cubic spline algorithm for the trajectory interpolation. For simplicity, we rewrite the observed trajectory of the i-th pedestrian as a series of time-position pairs</p><formula xml:id="formula_4">T X i = (1, (x 1 i , y 1 i )), ..., (t o , (x to i , y to i )) .<label>(5)</label></formula><p>We adopt the cubic spline algorithm to seek for a piecewise-</p><formula xml:id="formula_5">cubic function f (t): R ? R 2 f (t) = ? ? ? ? ? f 1 (t), 1 ? t &lt; 2 . . . f to?1 (t), t o ? 1 ? t ? t o ,<label>(6)</label></formula><p>where</p><formula xml:id="formula_6">f k (t) = a k + b k (t ? k) + c k (t ? k) 2 + d k (t ? k) 3 (7)</formula><p>represents the curve between the time steps k and k + 1, and a k , b k , c k , d k ? R 2 are parameters of the cubic spline. According to the cubic spline algorithm, given the trajectory X i , there exists a unique set of parameters {a k , b k , c k , d k } k=1,??? ,to?1 such that the resulting trajectory curve passes through all the positions in X i with continuous velocity and acceleration at each position. Upon having f (t), the feature X i at the -scale ( &gt; k) can be calculated by interpolating positions of the in-between and unobserved time steps as shown in <ref type="figure" target="#fig_0">Fig. 2(b)</ref>. Mathematically, we have</p><formula xml:id="formula_7">X i = [f (1), f (1 + 1 c ), f (1 + 2 c ), ..., f (2), ..., f (to ? 1 c ), f (to)],<label>(8)</label></formula><p>where c = 2 ?k . The interpolated dense trajectories offer more local information for the lower scales, permitting to capture more short-range motion behaviors of pedestrians. With above two modulations, we finally construct the pyramidal source as shown in <ref type="figure">Fig. 1</ref>.</p><p>Hierarchical feature representation For simplicity, we use a similar network architecture proposed in <ref type="bibr" target="#b4">(Gupta et al. 2018)</ref> as the backbone to extract hierarchical features from the constructed pyramid. As shown in <ref type="figure">Fig. 1</ref>, the backbone network consists of two components, i.e., the encoder and the decoder. At the encoder side, we embed the position of each pedestrian as</p><formula xml:id="formula_8">e t i = M LP (x t i , y t i ; ? me ),<label>(9)</label></formula><p>where t ? t o and ? me represents the parameters of MLP. The embedded feature e t i is then fed into an LSTM block, which produces the hidden state at the time step t h t i = LST M (h t?1 i , e t i ; ? le ).</p><p>(10) Note that the parameters of LSTM (? le ) are shared among all the pedestrians and the scales of the pyramid.</p><p>In order to generate multiple socially-acceptable trajectories, our model is designed under the framework of GANs. According to GANs, at the decoder side, we concatenate a noise vector z sampled from the standard normal distribution to the hidden state h to i . Further, we use the pooling module proposed by <ref type="bibr" target="#b4">(Gupta et al. 2018)</ref> to encode the influence caused by pedestrians around. We write h to i := [(h to i , P i ); z].</p><p>(11) Then for each z, we recurrently decode the hierarchical features of the trajectory as follow? e t?1</p><formula xml:id="formula_9">i = M LP (x t?1 i ,? t?1 i ; ? md ) h t i = LST M (h t?1 i ,? t?1 i ; ? ld ) (x t i ,? t i ) = M LP (h t i ; ? md ) ,<label>(12)</label></formula><p>where t ? t o + 1, (x to i ,? to i ) = (x to i , y to i ), and ? md , ? ld , ? md are parameters to be learned. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coarse-to-fine Fusion with Multi-supervision</head><p>To merge and exploit the information of hierarchical features generated by the above TPN, we further propose a coarse-tofine fusion strategy with multi-supervision.</p><p>Coarse-to-fine fusion As shown in <ref type="figure">Fig. 1</ref>, the coarse-tofine fusion organizes features in a top-down pathway, where the top coarse features with long-range context are progressively merged to the bottom fine features with rich localrange context. Denote the extracted feature of the -scale asX i , which is updated by merging the information of the above scale. We writ?</p><formula xml:id="formula_10">X i := 1 2 (X i ?X ?1 i,? ),<label>(13)</label></formula><p>whereX ?1 i,? means upsamplingX ?1 i by a factor of 2, and ? serves as the element-wise addition. This process is iterated until the finest resolution feature is merged. With the coarse-to-fine fusion strategy, the long-range and localrange motion information is collaborated, and then can complete to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-supervision</head><p>To ensure effective representation of each pyramid level, all the scales are supervised during training, where the corresponding loss function is formulated as</p><formula xml:id="formula_11">L s = 1 N L N i=1 L =1 ? X i ? Y i 2 2 .<label>(14)</label></formula><p>Here Y i is the ground-truth pyramidal source of the future trajectory, which can be constructed from Y i in the same way detailed in Section 2. The hyper-parameter ? is inversely proportional to the feature length ofX i , which we empirically set</p><formula xml:id="formula_12">? = t p m .<label>(15)</label></formula><p>Here m represents the length ofX i . The final predicted trajectory is produced by a fusion layer as shown in <ref type="figure" target="#fig_1">Fig. 3</ref>, where a de-pyramid layer is first adopted to down-sample or up-sample the hierarchical features {X i } L =1 to a fixed length t p . The results are then concatenated as a tensor of size L ? 2 ? t p , which is further processed through three convolutional layers to fuse information across the whole pyramid. The fusion layer finally generates the predicted trajectory? i . We supervise the final output using the loss Adversarial training The architecture of the discriminator is shown in <ref type="figure">Fig. 1, which consists</ref>  </p><formula xml:id="formula_13">L f = 1 N N i=1 ? i ? Y i 2 2 .<label>(16)</label></formula><formula xml:id="formula_14">L avd = E X,Y ?P data (X,Y ) [log D(X, Y )] + E X?P data (X),z?Pz(z) [log(1 ? D(X, G(z, X))].<label>(17)</label></formula><p>Finally, training the network is cast into a two-player minmax game with the following objective function</p><formula xml:id="formula_15">min G max D L avd + L s + L f .<label>(18)</label></formula><p>Above problem can be solved by alternatively updating the generator G and the discriminator D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>We implement our model TPNMS using the PyTorch framework with an NVIDIA TITAN Xp GPU. All the source code and models will be publicly available upon the acceptance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>The number of pyramid scales is empirically set as 5, and the dimensions of the hidden state for the encoder and the decoder are 32. Each input coordinate (x, y) is embedded as a 16-dimensional vector. The length of the noise vector z is 8. We adopt Adam algorithm <ref type="bibr" target="#b10">(Kingma and Ba 2014)</ref> to optimize the loss function (18) and train our network with the following hyper-parameter settings: batch size is 64; learning rates for the Generator and Discriminator are set to be 1e-4 and 2e-4, respectively; betas are 0.9 and 0.999; weight decay is 1e-4 and the number of epochs is 400.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets and Metrics</head><p>Datasets: We evaluate our method on two public datasets, i.e., ETH <ref type="bibr" target="#b20">(Pellegrini et al. 2009</ref>) and UCY <ref type="bibr" target="#b12">(Lerner, Chrysanthou, and Lischinski 2007)</ref>. These datasets consist of 5 unique scenes: ETH, HOTEL, UNIV, ZARA1 and ZARA2 with 4 different scenes. There are totally 1536 pedestrians with thousands of trajectories containing challenging behaviors such as walking together, crossing each other, forming groups and dispersing. Metrics: For the sake of fairness, we use the widely adopted leave-one-out approach evaluation methodology. The number of observed time steps is 8 (3.2 seconds) of each person and the upcoming trajectory of 12 time steps (4.8 seconds) is used to predict. Following prior works, we use two error metrics to evaluate the performance of different pedestrian trajectory prediction models.</p><p>1. Average Displacement Error (ADE): The average Euclidean distance between the ground-truth trajectory and the predicted one,</p><formula xml:id="formula_16">ADE = N i=1 to+tp t=to+1 Y (t) i ?? (t) i 2 N ? t p .<label>(19)</label></formula><p>2. Final Displacement Error (FDE): The Euclidean distance between the ground-truth destination and the predicted one,</p><formula xml:id="formula_17">FDE = N i=1 Y (to+tp) i ?? (to+tp) i 2 N .<label>(20)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines</head><p>We compare our method TPNMS with following approaches: an approach that models the social behavior of pedestrians using a graph. Similar to previous works, we generate 20 samples based on the predicted distribution. <ref type="table">Table 1</ref> summarizes the results of different algorithms, where we report the average results for each method in the last two columns. We can see that all the algorithms perform much better than the linear model. Based on the results, we further draw the following conclusions:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantitative Analysis</head><p>? Overall, our method TPNMS outperforms all the previous approaches in terms of the average ADE and FDE.</p><p>? Compared with the baseline approach S-GAN <ref type="bibr" target="#b4">(Gupta et al. 2018)</ref>, TPNMS achieves significant performance gains. For example, S-GAN has an average error of 0.58 on ADE, and 1.18 on FDE, while TPNMS has much lower ADE (0.38) and FDE (0.73), corresponding to 34% and 38% relative improvements, respectively. This demonstrates that our proposed temporal pyramid network with multi-supervision indeed helps for pedestrian trajectory prediction.</p><p>? For the previous state-of-the-art method Social-STGCNN <ref type="bibr" target="#b18">(Mohamed et al. 2020)</ref>, TPNMS still achieves noticeable performance gains. For instance, TPNMS decreases the error of about 14% on ADE and about 3% on FDE compared with Social-STGCNN.</p><p>? Even without using any side information, TPNMS outperforms those methods utilizing the scene context, such as PIF <ref type="bibr" target="#b14">(Liang et al. 2019)</ref>, Sophie  and Social-BiGAT . This implies that the performance of TPNMS could potentially be improved by considering the scene context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qualitative Analysis</head><p>In this subsection, we provide some examples to show how our TPNMS successfully captures complex motion behaviors of pedestrians. We qualitatively compare the prediction results between Social-GAN and TPNMS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results in different interaction scenarios</head><p>We visualize examples from 4 scenarios in <ref type="figure" target="#fig_3">Figure 4</ref>. Walking in parallel When people are walking side by side, they usually have tight connection to each other, and their relative positions tend to be preserved and motion behaviors tend to change consistently. In the <ref type="figure" target="#fig_3">Fig. 4(a)</ref>, two target pedestrians A and B are walking in parallel. It can be noticed that S-GAN incorrectly predicts that these two pedestrians will walk across each other, and have a high possibility of collision. Compared with S-GAN, the predictions by our TPNMS show that these two pedestrians will keep walking in parallel, which is close to the ground-truth trajectories marked by green lines. This demonstrates the superiority of modeling motion behavior at various tempos.</p><p>Meeting from opposite directions People avoiding each other when moving in opposite direction is common in reality. <ref type="figure" target="#fig_3">Fig. 4(b)</ref> presents a scenario where two groups are meeting from opposite directions. We can see that the local behaviors of persons A, B and C are adjusted slightly to avoid collision. Compared with S-GAN, the trajectory of the person A predicted by TPNMS is more accurate after meeting. Further, TPNMS successfully predicts that persons B and C will keep walking in parallel, while the forecasts of S-GAN deviate from their true behaviors.</p><p>Following people When a person is following someone, he or she might want to draw attention to the person ahead, and maintain a safe distance between them. <ref type="figure" target="#fig_3">Fig. 4(c)</ref> shows a situation where the person A is walking behind the person B. We can see that S-GAN tends to decrease the speed of person A even when the distance between others is sufficiently large, while our proposed models TPNMS can more accurately forecast the speed at each time step, and still preserve a safe distance to avoid collision.</p><p>Walking with complex social interactions The complex interactions drive people using various ways to avoid collisions. As shown in <ref type="figure" target="#fig_3">Fig. 4(d)</ref>, many trajectories generated by S-GAN have large deviations from the ground-truth ones, e.g., the persons A, F, H and I. Besides, we can see that S-GAN fails to adjust the behaviors of persons A, B and C, and then causes a collision at the end of the predicted trajectories. As for TPNMS, the predicted trajectories match better with the ground-truth one. For instance, persons I and J are maintained walking in parallel. Furthermore, we observe that the speed of person A is clearly slowed down by TPNMS, to avoid collision with persons B and C. For the trajectories of persons F and H, TPNMS achieves much better prediction accuracy than S-GAN. This demonstrates that our method can effectively capture the motion behaviors of pedestrians in scenarios of complex social interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results of diverse predictions</head><p>Our model is capable of producing multiple plausible and diverse trajectories conforming to the multimodal behavior of pedestrians. In <ref type="figure" target="#fig_4">Fig. 5</ref>, we show some examples of diverse predictions by sampling the noise vector z from the standard normal distribution. We can see from <ref type="figure" target="#fig_4">Fig. 5(b)</ref> and <ref type="figure" target="#fig_4">Fig. 5</ref>(c) that our model generates two socially acceptable and distinct trajectories with different z, including changing the direction and speed. For instance, the top image of <ref type="figure" target="#fig_4">Fig. 5(b)</ref> shows that the person is walking toward the car, where the direction is different from the true trajectory but the predicted path is still acceptable. Similar phenomenon can also be observed from the bottom image of <ref type="figure" target="#fig_4">Fig. 5(b)</ref>. Besides, images presented in <ref type="figure" target="#fig_4">Fig. 5(c)</ref> show that z can also affect the speed of pedestrians. In <ref type="figure" target="#fig_4">Fig.  5(d)</ref>, we draw the density of the predicted trajectory by 20 randomly generated samples. The purple area constructs a plausible area that each pedestrian may pass. The position of darker color indicates a higher probability that the person will pass through. Furthermore, in <ref type="figure" target="#fig_4">Fig. 5(d)</ref>, we also plot the best predicted trajectory from 20 samples for each scenario, and we can see that it closely matches the true trajectory shown in <ref type="figure" target="#fig_4">Fig. 5(a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Experiments</head><p>In <ref type="table" target="#tab_2">Table 2</ref>, we systematically evaluate our method through a series of ablation experiments, where we consider the following variants of our method: S-GAN-P: the method without the temporal pyramid mod-   ule and the multi-supervision module. With this setting, our method degrades to S-GAN-P; TPN: the method only considers the temporal pyramid module without the multi-supervision; TPNMS: the method considers both the temporal pyramid module and the multi-supervision.</p><p>Comparing TPN with S-GAN-P, we can see that TPN significantly reduces the ADE from 0.61 to 0.41, and the FDE from 1.21 to 0.79, which indicates that our temporal pyramid architecture can more effectively model the global context and local context of trajectories. Further, we observe that TPNSM can further improve the prediction accuracy in terms of ADE/FDE metrics, which demonstrates the importance of multi-supervision to ensure effective hierarchical representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we have proposed a novel pyramid architecture for pedestrian trajectory prediction, which outperforms state-of-the-art methods on several benchmark datasets. First, we have devised a temporal pyramid network through squeeze and dilation modulations, which encodes and decodes the trajectory at multiple resolutions. This enables our method to capture both short-range and long-range motion behaviors of pedestrians. By resorting to a coarse-to-fine fusion strategy and the multi-supervision, our method can progressively merge high-scale global context with low-scale local context, finally resulting in an accurate trajectory prediction. Finally, with a GAN based framework, our method can generate multiple socially-acceptable trajectories conditioned on the same trajectory history, obeying the multimodal property of pedestrians. Both quantitative and qual-itative experimental results demonstrate the promising performance of our method under various situations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of the proposed (a) temporal squeeze modulation, and (b) temporal dilation modulation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>The framework of the fusion network, where the convolutional layers have the 1 ? 1 kernel size, and the number of channels are 8, 4 and 1, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>(</head><label></label><figDesc>Alahi et al. 2016): a linear regressor that predicts the next coordinates based on previous points. S-LSTM (Alahi et al. 2016): a method based on LSTM and social pooling. S-GAN and S-GAN-P (Gupta et al. 2018): a model that employs GAN to generate multimodal pedestrian trajectories and the latter with a global pooling module. PIF (Liang et al. 2019): a multi-task method using both visual features and interaction information. SoPhie (Sadeghian et al. 2019): an improved GAN based model considering the physical constraints. SR-LSTM (Zhang et al. 2019): a state refinement method for LSTM based pedestrian trajectory prediction. Social-BiGAT (Kosaraju et al. 2019) and STGAT (Huang et al. 2019a): methods based on GAN and graph attention. Social-STGCNN (Mohamed et al. 2020):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Examples of predicted trajectories by different methods. (a) walk in parallel; (b) meet from opposite directions; (c) follow people and (d) walk with complex social interactions. Blue line represents the historical trajectory; green line denotes the true future trajectory; yellow line shows the predicted future trajectory, and dots are the locations at different time steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Examples of diverse predictions. The historical trajectory and predicted trajectory are marked in blue and yellow, respectively. (a) The ground-truth future trajectory (green). (b, c) two examples of diverse predictions. (d) The density of the prediction, where the purple area is the visualization result of the predicted 20 pedestrian trajectories after mean filtering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The average ADE/FDE performance of variants.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social LSTM: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recogn</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recogn</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="961" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Online Nonparametric Bayesian Activity Mining and Analysis From Surveillance Video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bastani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marcenaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Regazzoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2089" to="2102" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Social GAN: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recogn</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recogn</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spatial pyramid pooling in deep convolutional networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1904" to="1916" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Social force model for pedestrian dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phy. rev. E</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">4282</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">STGAT: Modeling Spatial-Temporal Interactions for Human Trajectory Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6272" to="6281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Attentive temporal pyramid network for dynamic scene classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf. Art. Intel</title>
		<meeting>AAAI Conf. Art. Intel</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8497" to="8504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2375" to="2384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mart?n-Mart?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.03395</idno>
		<title level="m">Social-BiGAT: Multimodal Trajectory Forecasting using Bicycle-GAN and Graph Attention Networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Crowds by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chrysanthou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer graphics forum</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="655" to="664" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Conditional Generative Neural System for Probabilistic Trajectory Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tomizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Intel. Robots and Sys</title>
		<meeting>IEEE Int. Conf. Intel. Robots and Sys</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Peeking into the future: Predicting future person activities and locations in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recogn</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recogn</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5725" to="5734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recogn</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recogn</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distinctive image features from scaleinvariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. of Comp. Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Trafficpredict: Trajectory prediction for heterogeneous traffic-agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf. Art. Intel</title>
		<meeting>AAAI Conf. Art. Intel</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6120" to="6127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Claudel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recogn</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recogn</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14424" to="14432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Intent Prediction and Trajectory Forecasting via Predictive Inverse Linear-Quadratic Regulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Ziebart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf. Art. Intel</title>
		<meeting>AAAI Conf. Art. Intel</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3672" to="3678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">You&apos;ll never walk alone: Modeling social behavior for multitarget tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recogn</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recogn</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1349" to="1358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multimodal Interaction-Aware Trajectory Prediction in Crowded Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shibasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf. Art. Intel</title>
		<meeting>AAAI Conf. Art. Intel</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11982" to="11989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Der Heiden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Nagaraja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gavves</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.06673</idno>
		<title level="m">SafeCritic: Collision-Aware Trajectory Prediction</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Social attention: Modeling attention in human crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vemula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muelling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE int. Conf. Robot. and Auto</title>
		<meeting>IEEE int. Conf. Robot. and Auto</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Encoding crowd interaction with deep neural network for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Piao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recogn</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recogn</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5275" to="5284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">CF-LSTM: Cascaded Feature-Based Long Short-Term Networks for Predicting Pedestrian Trajectory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf. Art. Intel</title>
		<meeting>AAAI Conf. Art. Intel</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12541" to="12548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Temporal pyramid network for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recogn</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recogn</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sr-lstm: State refinement for lstm towards pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recogn</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recogn</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12085" to="12094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-agent tensor fusion for contextual trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recogn</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recogn</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12126" to="12134" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
