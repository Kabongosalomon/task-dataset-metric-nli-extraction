<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Few-Shot Document-Level Relation Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Popovic</surname></persName>
							<email>popovic@kit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Karlsruhe Institute of Technology (KIT)</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>F?rber</surname></persName>
							<email>michael.faerber@kit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Karlsruhe Institute of Technology (KIT)</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Few-Shot Document-Level Relation Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present FREDo, a few-shot document-level relation extraction (FSDLRE) benchmark. As opposed to existing benchmarks which are built on sentence-level relation extraction corpora, we argue that document-level corpora provide more realism, particularly regarding none-ofthe-above (NOTA) distributions. Therefore, we propose a set of FSDLRE tasks and construct a benchmark based on two existing supervised learning data sets, DocRED and sciERC. We adapt the state-of-the-art sentence-level method MNAV to the document-level and develop it further for improved domain adaptation. We find FSDLRE to be a challenging setting with interesting new characteristics such as the ability to sample NOTA instances from the support set. The data, code, and trained models are available online 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of relation extraction is to detect and classify relations between entities in a text according to a predefined schema. The schema, defining which relation types are relevant is highly dependent on the specific application and domain. Supervised learning methods for relation extraction <ref type="bibr" target="#b11">(Soares et al., 2019;</ref><ref type="bibr" target="#b25">Zhou et al., 2021;</ref><ref type="bibr" target="#b23">Zhang et al., 2021;</ref><ref type="bibr" target="#b19">Xu et al., 2021;</ref><ref type="bibr" target="#b18">Xiao et al., 2022)</ref>, which have advanced rapidly since the introduction of pretrained language models such as BERT <ref type="bibr" target="#b0">(Devlin et al., 2019)</ref>, need large corpora of annotated relation instances to learn a schema. Since annotating data sets for relation extraction manually is expensive and time consuming, few-shot learning for relation extraction represents a promising solution for relation extraction at scale.</p><p>While the general N -way K-shot few-shot learning framework is relatively well defined and appears easy to apply to relation extraction, constructing realistic benchmark tasks has proven to be challenging. One of the core difficulties of establishing a realistic benchmark task for few-shot relation extraction is correctly modelling the most frequent situation a relation extraction system will encounter, none-of-the-above (NOTA) detection. NOTA refers to the case in which a candidate pair of entities does not hold any of the relations defined in the schema, a situation which is far more common than its reverse (for the document-level data set DocRED <ref type="bibr" target="#b20">(Yao et al., 2019)</ref>, 96.84% of candidate entity pairs are NOTA cases). While initial benchmarks <ref type="bibr" target="#b4">(Han et al., 2018)</ref> ignored this scenario altogether, researchers working on few-shot relation extraction have pushed for more realistic NOTA modeling in tasks and developed methods that can better detect NOTA instances <ref type="bibr" target="#b1">(Gao et al., 2019;</ref><ref type="bibr" target="#b9">Sabo et al., 2021)</ref>.</p><p>Parallel to the outlined efforts towards realistic few-shot relation extraction benchmarks, research into supervised relation extraction has moved from sentence-level tasks, relation extraction within single sentences, to document-level relation extraction. The push towards document-level relation extraction is motivated by (1) extracting more complex, cross-sentence relations and (2) information extraction at scale. The latter is driven by an inherent challenge when increasing the scope from single sentences to multiple sentences: The number of entities involved increases and with that comes a quadratic increase in candidate entity pairs. While sentence-level approaches typically evaluate each candidate entity pair individually, this strategy is infeasible at the document-level (DocRED contains an average of 393.5 candidate entity pairs per document, compared to only 2 for many sentence leveltasks). In addition to the increased computation requirements, this results in a drastic increase in the amount of NOTA examples in a given query, demanding new methods of handling the imbalances that come with this change of distribution <ref type="bibr" target="#b3">(Han and Wang, 2020;</ref><ref type="bibr" target="#b25">Zhou et al., 2021)</ref>.</p><p>All current few-shot relation extraction bench-marks are based on sentence-level tasks. We argue that moving few-shot relation extraction from the sentence-level to the document-level: (1) brings with it as an inherent characteristic the more realistic NOTA distribution which prior work has looked to emulate and (2) will make the resulting methods more suitable for large scale information extraction.</p><p>In this work, we therefore define a new set of few-shot learning tasks for document-level relation extraction and design a strategy for creating realistic benchmarks from annotated document corpora. Applying the above to the data sets DocRED <ref type="bibr" target="#b20">(Yao et al., 2019)</ref> and sciERC <ref type="bibr" target="#b8">(Luan et al., 2018)</ref>, we construct a few-shot document-level relation extraction (FSDLRE) benchmark, FREDo, consisting of two main tasks, an in-domain and a crossdomain task requiring domain adaptation. Finally, building on the state-of-the-art few-shot relation extraction approach MNAV <ref type="bibr" target="#b9">(Sabo et al., 2021)</ref> and document-level relation extraction concepts <ref type="bibr" target="#b25">(Zhou et al., 2021)</ref>, we develop two approaches for tackling the above tasks.</p><p>We begin by outlining key related work in section 2. In section 3 we give a description of the proposed tasks. Next, in section 4 we explain the construction of the benchmark, FREDo, followed by an overview of the proposed methods (section 5), an analysis and discussion of the observed results (section 6), and the conclusion (section 7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>To the best of our knowledge, all current few-shot relation extraction benchmarks <ref type="bibr" target="#b4">(Han et al., 2018;</ref><ref type="bibr" target="#b1">Gao et al., 2019;</ref><ref type="bibr" target="#b9">Sabo et al., 2021)</ref> focus on extracting relations from single sentences. FewRel <ref type="bibr" target="#b4">(Han et al., 2018)</ref> introduces a relation extraction benchmark in the N -way K-shot setting <ref type="bibr" target="#b13">(Vinyals et al., 2016;</ref><ref type="bibr" target="#b10">Snell et al., 2017)</ref> in which a relation instance is to be assigned to one of N classes given only K examples for each of the classes. In this setting human performance was quickly surpassed <ref type="bibr" target="#b11">(Soares et al., 2019)</ref>, leading <ref type="bibr" target="#b1">Gao et al. (Gao et al., 2019)</ref> to create FewRel 2.0 in an effort to increase the difficulty by adding a domain adaptation task, as well as a NOTA detection task. <ref type="bibr" target="#b9">Sabo et al. (Sabo et al., 2021)</ref> argue that the way FewRel 2.0 models NOTA cases is not realistic due to the way NOTA instances are sampled, develop a framework for creating more realistic benchmarks and propose building such a benchmark using the sentence-level data set TACRED <ref type="bibr" target="#b24">(Zhang et al., 2017)</ref>. <ref type="bibr" target="#b12">Tran et al. (Tran et al., 2021)</ref> forego labeled training data altogether and focus on the one-shot and weakly-supervised classification setting without NOTA cases.</p><p>While multiple relation extraction data sets based on annotated documents, rather than single sentences, are available in the form of CDR <ref type="bibr" target="#b6">(Li et al., 2016)</ref>, sciERC <ref type="bibr" target="#b8">(Luan et al., 2018)</ref>, SciREX <ref type="bibr" target="#b5">(Jain et al., 2020)</ref>, DialogRE <ref type="bibr" target="#b22">(Yu et al., 2020)</ref>, and GDA <ref type="bibr" target="#b17">(Wu et al., 2019)</ref>, the introduction of the large scale data set DocRED <ref type="bibr" target="#b20">(Yao et al., 2019)</ref> seems to have significantly increased research interest into supervised relation extraction at the document-level more recently <ref type="bibr" target="#b25">(Zhou et al., 2021;</ref><ref type="bibr" target="#b23">Zhang et al., 2021;</ref><ref type="bibr" target="#b19">Xu et al., 2021;</ref><ref type="bibr" target="#b18">Xiao et al., 2022)</ref>.</p><p>Since documents contain considerably more entities than individual sentences and the amount of candidate entity pairs increases quadratically with the amount of entities, applying sentencelevel methods to document-level tasks is not feasible. Document-level relation extraction approaches therefore use a different architecture <ref type="bibr" target="#b15">(Wang et al., 2019)</ref> than sentence-level approaches. Another challenge is the large imbalance in the amount of positive and negative examples of relations encountered during training. Some researchers approach the problem by resampling training examples to counteract the imbalance <ref type="bibr" target="#b3">(Han and Wang, 2020)</ref>, while others use more specialized solutions, such as modified loss functions <ref type="bibr" target="#b25">(Zhou et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Description</head><p>In document-level relation extraction the task is to return a set S containing all valid triples of the format (e h , r i , e t ) for a document D. Here, e h and e t are the head-and tail-entity of a relation instance, respectively, and r i ? R is a relation type, with R being the set of relation types for which instances are to be extracted. The positions of any entity mentions, as well as any co-reference clusters are provided as part of the input 2 . In both supervised learning and few-shot learning the documents used at test time are sampled from a different corpus than those used at training time. The added complexity in few-shot learning is caused (1) by a change in the set of relation types R between training and test time, and (2) by a much smaller amount of annotated examples given for each relation type.  <ref type="figure">Figure 1</ref>: Illustration of an episode in the Few-Shot Document-Level Relation Extraction setting. Given a support document with annotated relation instances, the task is to return all instances of the same relation types for the query document. During testing a different corpus of documents, as well as a different set of relation types are used than during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Document-Level Few-Shot Relation Extraction</head><p>In <ref type="figure">figure 1</ref> we give an illustration of the proposed task setting. We define as few-shot document-level relation extraction (FSDLRE) the following: Given a set of support documents {D S,1 , ..., D S,k }, the corresponding sets {T S,1 , ..., T S,k } containing all valid triples for each support document, and a query document D Q , the task is to return the set T Q , containing all valid triples in the query document. The sets {T S,1 , ..., T S,k } and T Q consist of triples for the relation types R episode . R episode is a subset of either R train or R test , two disjoint sets of relation types used for training or testing, respectively. The annotations of the support documents are complete, meaning that any candidate entity pair for which no relation type has been assigned can be considered NOTA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">In-Domain vs. Cross-Domain</head><p>For in-domain FSDLRE training and test documents are taken from the same domain. For crossdomain FSDLRE the test documents are taken from a different domain. Consequently, text style, text content, entity types, and relation types will all differ from those seen in the training documents. While this increases the difficulty of the challenge, this also resembles a more realistic application of few-shot relation extraction methods: A key motivation for few-shot learning is to develop methods which can be applied to new data without the need for large-scale manual annotation. Restricting the applicability of a method to a specific domain and annotation procedure does not fit this idea.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Differences to Existing Benchmarks</head><p>The tasks described above differ from existing fewshot relation extracting benchmarks in multiple ways.</p><p>(1) Operating at document-level means the data now includes instances of relations expressed across multiple sentences and that models need to be able to evaluate candidate entity pairs more efficiently.</p><p>(2) Like for FS-TACRED <ref type="bibr" target="#b9">(Sabo et al., 2021)</ref>, the amount of candidate entity pairs for which no relation is to be extracted is significantly larger than in other benchmarks (96.4% compared to 15%/50% for FewRel 2.0 <ref type="bibr" target="#b1">(Gao et al., 2019)</ref>) and the distribution from which NOTA instances are sampled, is more realistic than in FewRel 2.0, where NOTA instances are always instances of other, valid relation types.</p><p>(3) By requiring support annotations to be complete we have access to a support NOTA distribution, which is not the case for any existing benchmarks. (4) Our tasks do not follow the fixed N -way K-shot format that related work has followed. Instead, N and K are variable between documents and therefore between individual episodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">FREDo: Few-Shot Document-Level Relation Extraction Benchmark</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Selected Data Sets</head><p>In order to construct a benchmark based on the tasks described in section 3 we require fully annotated data sets from two separate domains. For the training set and the in-domain test set we use Doc-RED <ref type="bibr" target="#b20">(Yao et al., 2019)</ref>   We begin by building 3 separate corpora of documents, 1 for training and development and 1 for testing each task (in-/cross-domain). Since the annotated test corpus for DocRED is not publicly available we use the documents in the development corpus as the test corpus for our in-domain task (meta-test). The DocRED training corpus is therefore used as the basis for both our training, and development set (meta-train). For the cross-domain task we require only a test set. This is because the training and development set for this task are identical to that of the in-domain task. We therefore use all documents in sciERC as our cross-domain test set (meta-test).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Assigning Relation Types</head><p>For preprocessing, we begin by comparing the relation types annotated in sciERC to those in the DocRED corpus 3 . We find 2 relation types (P279, P361) which are annotated in both DocRED and sciERC. We remove these from the DocRED corpus in order to prevent data leakage between train and test sets. <ref type="bibr">3</ref> The mapping can be found in appendix A.</p><p>For DocRED, we split the remaining 94 relation types into 4 disjoint sets, a training set (62) R train , development set (16) R dev , and in-domain test set (16) R test . For the cross-domain test set we use all 7 relation types in the sciERC corpus. An overview of the relation types assigned to each set can be found in appendix A and B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Test Episode Sampling</head><p>In few-shot learning, each training/testing step consisting of support documents and query documents is called an episode. Since evaluating every possible combination of support and query documents would result in too many episodes (approx. 1 million episodes for the in-domain and 250k episodes for the cross-domain test set) we need to sample a smaller amount of episodes from our corpora. We chose our sampling procedure with the goal of producing a representative measurement of the macro F 1 score.</p><p>For few-shot learning tasks the episode sampling process can be split into 2 steps, the first step being the sampling of the support examples and the second step being the sampling of the query examples. Unlike the sentence-level scenario where each example contains exactly one relation instance, each document we sample contains multiple instances of different relation types. In order to balance the amount of times each relation type is seen as a support example during testing we use the following procedures for the first sampling step: We begin by selecting from the set R test the relation type r s which is currently least represented in the testing corpus. If there are multiple such relation types we randomly choose one. For this relation type we sample support documents which contain at least one instance of r s each. Since the selected support documents may contain instances of other relation types in R test we add all of the relation types contained in the support document 4 to the episodes annotation schema. Following Sabo et al. <ref type="bibr">(</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Choosing Test Set Sizes</head><p>In order to choose a sufficiently large amount of test episodes for a representative F 1 score we evaluate a trained model for 50k episodes, logging the macro f 1 score at intervals of 100 episodes. We repeat this for 5 different random seeds. Using the variance between the 5 measurements as a guide, we choose a number of episodes which we deem to satisfy a good balance between low variance and manageable test set size. For robustness we sample episodes with 3 different random seeds for the final test sets. The resulting test set sizes are: 15k episodes for the in-domain tasks and 3k episodes for the cross-domain tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Characteristics of Resulting Tasks</head><p>Existing few-shot benchmarks typically set 2 tasks, a single-shot and a K-shot (3/5/10-shot) challenge, in order to determine the way performance may scale when adding annotated training data. Due to the nature of our tasks, N and K are variable from episode to episode, depending on the specific support documents and relation types. We measure the scalability of approaches by defining a 1-Doc and 3-Doc challenge. Therefore, the proposed benchmark, FREDo, consists of 2 main tasks with a 1-Doc and a 3-Doc subtask each:</p><p>? The in-domain tasks for which an approach which has been trained on documents sampled from DocRED is evaluated on 15k episodes generated using documents from DocRED. <ref type="bibr">5</ref> Note that we exclude the previously sampled support documents.</p><p>? The cross-domain tasks for which an approach which has been trained on documents sampled from DocRED is evaluated on 3k episodes generated using documents from sciERC.</p><p>In order to better characterize our tasks in relation to the common N -way K-shot format we measure the distribution of N and K across our test sets. All the average values for K and N are shown in table 2. We find that the mean values of N are (2.18/3.47) for the in-domain tasks (1-/3-doc) and (4.26/6.08) for the cross-domain task. For K we calculate both the mean values across all episodes (micro), as well as the mean across the different relation types (macro).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Models</head><p>A common approach to relation extraction in general is to compute the similarity between embeddings produced by a fine-tuned language model such as BERT <ref type="bibr" target="#b0">(Devlin et al., 2019)</ref>. In order to produce a relation embedding for a given pair of entities, most approaches concatenate embeddings corresponding to each entity. One way to generate an entity embedding from the output of a language model is to average the embeddings of all tokens belonging to an entity. Another way is the use of so called entity markers, introduced by Soares et al. <ref type="bibr" target="#b11">(Soares et al., 2019)</ref>, which are tokens placed at the beginning and end of an entity mention within the input text. The embeddings of the tokens placed at the start of each entity mention are then used as the entity embeddings. In few-shot learning, a common way to use embedding similarity are prototypical networks <ref type="bibr" target="#b10">(Snell et al., 2017)</ref>. Here, the embeddings of all K support examples are averaged into a so-called prototype. Given a query embedding, the similarity to the N class-prototypes is then used for classification.</p><p>In order to assess the difficulty of our challenges we measure the performance of 3 approaches. We set an initial baseline using the pretrained language model BERT BASE <ref type="bibr" target="#b0">(Devlin et al., 2019</ref>) without fine-tuning. Next, we adapt the state-of-the-art sentence-level few-shot relation extraction method MNAV <ref type="bibr" target="#b9">(Sabo et al., 2021)</ref> to the document-level (DL-MNAV). Finally, we make 2 modifications to DL-MNAV (SIE and SBN) to improve crossdomain performance. In <ref type="figure" target="#fig_0">figure 2</ref>  sion boundaries with respect to support and query instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Baseline</head><p>We set an initial baseline using the pretrained language model BERT BASE <ref type="bibr" target="#b0">(Devlin et al., 2019)</ref> without fine-tuning in the following way: We encode each document using the language model and then average the output tokens of each entity mention. Following <ref type="bibr" target="#b3">Han and Wang (Han and Wang, 2020)</ref>, we then average the mention representations for each entity. The resulting entity mentions are then concatenated for each candidate pair of entities to form relation embeddings. The similarity between a relation embedding in a query document to a relation embedding in a support document is calculated via their dot product. The relation type of the support embedding producing the highest dot product is output as the predicted relation type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Adapting MNAV to Document-Level (DL-MNAV)</head><p>The current state-of-the-art few-shot sentence-level relation extraction method MNAV <ref type="bibr" target="#b9">(Sabo et al., 2021)</ref> uses a combination of entity embeddings based on entity markers and prototypical networks. Furthermore, it introduces the idea of learning M prototypes to represent the NOTA class. In order to use MNAV at the document-level one key architectural change is required: Instead of only marking two entities, a head-and a tail-entity, with two different tokens we mark all spans with the same entity marker tokens. Furthermore, following other document-level approaches <ref type="bibr" target="#b3">(Han and Wang, 2020;</ref><ref type="bibr" target="#b25">Zhou et al., 2021)</ref> we apply a pooling step 6 to create representations for entities which are mentioned more than once in a document. One of the challenges in realistic relation extraction is the large imbalance in the amount of positive and negative examples of relations encountered during training. In document-level relation extraction this challenge is even more central to the task than in sentence-level relation extraction. Preliminary experiments showed that simply using cross-entropy loss, as is done for MNAV, yields sub-par results. To tackle this 7 , we adopt the adaptive thresholding loss function used by <ref type="bibr" target="#b25">Zhou et al. (Zhou et al., 2021)</ref> which is an adaptation of categorical cross entropy loss designed specifically for classifiers which treat NOTA as a relation type during classification, as is the case for MNAV.</p><p>Finally, we modify the initialization procedure of the NOTA vectors. While <ref type="bibr" target="#b9">Sabo et al. (2021)</ref> initialize the vectors using an averaged value of relation representations, we sample NOTA representations from the support documents during the first training step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Support Instance Evaluation (SIE)</head><p>MNAV being based on prototypical networks <ref type="bibr" target="#b10">(Snell et al., 2017)</ref> means that the embeddings of all support instances of a relation type are averaged into a single prototype. While this has proven to be an effective strategy, we argue that it may not be ideal during inference in a cross-domain setting where the change in data distribution may break the assumption that the mean of support instances provides a good prototype. In SIE we therefore use all individual support instances during inference, instead of their average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">Support Based NOTA Vectors (SBN)</head><p>In treating NOTA as a relation type and learning a persistent set of vectors during training, MNAV works on the assumption that the NOTA distribution during testing will match that seen during training. While this assumption is warranted and seems to work well for in-domain few-shot learning, we argue that this may not be the case for crossdomain settings. For this reason, we additionally add NOTA instances from the support documents to our set of NOTA vectors during training and inference. 8 Instead of randomly sampling NOTA vectors from the support documents we sample the most similar k = 5 NOTA instances measured via their dot product for each relation prototype 9 . During inference in a new domain, we use only the NOTA vectors sampled from the support document and ignore the learned vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Sampling Training &amp; Development Episodes</head><p>We compare 2 different ways of sampling episodes during training. First we sample training and development episodes in the same way as for the test sets. In order to get sufficient coverage to calculate representative macro F 1 scores on the development set, we sample 4k episodes. As an alternative we modify the query sampling by ensuring that for each episode at least one of the query documents contains an instance of the relation type r s . This way we increase the amount of non-NOTA examples the model sees during training. Another effect is that we need fewer development episodes (we use 500) to calculate macro F 1 scores.   <ref type="bibr" target="#b16">(Wolf et al., 2020)</ref> and trained using mixed precision. We follow Zhou et al. <ref type="bibr" target="#b25">(Zhou et al., 2021)</ref> in using AdamW <ref type="bibr" target="#b7">(Loshchilov and Hutter, 2019)</ref> as optimizer (learning rates ? [1e?5, 3e?5, 5e?5, 1e?4], of which 1e?5 generally performs best) and training using linear warmup (1k/2k steps) <ref type="bibr">(Goyal et al., 2017)</ref> followed by a linear learning rate decay. We use gradient clipping of 1.0. We train each model for 50k episodes and perform early stopping based on the macro F 1 score on the development set which we measure every 1k/2k steps (when random sampling/ensuring positive examples). Each 1-doc training episode consists of 1 support document and 3 query documents, 3-doc training episodes contain 3 support documents and 1 query document. During training we limit the size of R episode to 1. We run each model 5 times using different random seeds and select the learning rate with the highest mean macro F 1 score on the development set for testing. For test scores we report the mean and standard deviation of macro F 1 scores for models trained using 5 different random seeds. For this model we report the macro F 1 score on the test set.</p><p>Results are shown in tables 3, 4, and 5. All models were trained on either NVIDIA V100 or NVIDIA 3090 GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Comparing Sampling Strategies</head><p>In table 3 we compare the test macro F 1 scores of the best models (chosen according to development set) trained using the 2 sampling strategies described in section 5.2 on the 1-Doc challenge using the model DL-MNAV. We find that ensuring positive query documents during training and development helps increase the F 1 scores. Due to the better performance, as well as the reduced computation time needed for validation (thanks to the smaller development set), we use the latter strategy   in all following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Baseline Results</head><p>As expected for a baseline which is not fine-tuned to the task at hand, the resulting macro F 1 scores are very low. We argue, however, that the baseline is nevertheless relevant for 2 reasons. For the indomain challenge, the baseline proves that the tasks are not trivially solvable by using a pre-trained language model out of the box. For the cross-domain challenge, our baseline lets us see whether models overfit on the training domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">In-Domain Setting</head><p>Test scores for the in-domain challenge are shown in table 4. We observe large improvements in F 1 scores over the baseline, especially for DL-MNAV which reaches 7.05% in the 1-Doc and 8.42% in the 3-Doc task. SIE does not seem to affect the accuracy of the model in the 1-Doc task; in the 3-Doc task, however, the F 1 score drops by 1.65 percentage points. SBN, on the other hand causes the F 1 scores to drop by more than 5%. This performance drop following the removal of learned NOTA vectors clearly illustrates their effectiveness for in-domain tasks.</p><p>In table 6 we compare the best F 1 scores of different few-shot relation extraction benchmarks. Overall, compared to scores for benchmarks such as FewRel <ref type="bibr" target="#b4">(Han et al., 2018)</ref> FewRel 2.0 <ref type="bibr" target="#b1">(Gao et al., 2019)</ref>, the F 1 scores are considerably lower, illustrating the difficulty of such a realistic challenge. When compared to the more realistic sentence-level benchmark FS-TACRED <ref type="bibr" target="#b9">(Sabo et al., 2021)</ref>   which Sabo et al. report F 1 10 scores of 12.39% (1-shot) and 30.04% (5-shot) MNAV, these results are in-line with our expectations for an even more realistic (and thereby evidently more difficult) challenge. Notably, the scaling behavior seen in FS-TACRED between the 1-shot and the 5-shot setting is not as pronounced for FREDo. We hypothesize that this is due the fact that the change in K is not as large (see table 2), meaning that (1) our 1-Doc setting does not correlate perfectly to the 1-shot setting, and (2) due to the way that additional support documents are sampled, the 3-Doc setting does not guarantee additional support examples for infrequently occuring relation types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Cross-Domain Setting</head><p>Test scores for the cross-domain challenge are shown in table 5. For DL-MNAV we see a significant drop in F 1 scores over the baseline, il-lustrating the problem with learned NOTA vectors in a cross-domain setting. SIE brings the scores back to the baseline level, illustrating that the distribution of support examples is no longer well represented by their mean values. Switching to SBN (DL-MNAV SIE+SBN ), we find that our model exceeds the baseline scores, suggesting that the NOTA distribution on sciERC seems to be sufficiently different to cause an overfitting effect for learned NOTA vectors. While SBN improves the results over the naive baseline, even the improved F 1 scores are extremely low. This is, however, unsurprising given the increase in difficulty over the previous setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Scalability of DL-MNAV</head><p>Although our methods show improvements over the proposed baseline in both tasks the results are currently severely lacking, especially compared to the state-of-the-art supervised learning approaches on both data sets (65.92% F 1 for DocRED <ref type="bibr" target="#b19">(Xu et al., 2021)</ref> and 52.0% F 1 for sciERC <ref type="bibr">(Ye et al., 2022)</ref>). This performance gap raises the question of whether our models will achieve similar performance if given enough support documents. In order to assess the scalability of DL-MNAV when given amounts of annotated data resembling the supervised setting, we initialize a trained model with the full DocRED training corpus as support documents (96 classes, 3053 documents) and evaluate the performance on the full development set (96 classes, 998 documents). We measure an increase in recall to 45.75% combined with a drop in precision to 5.75%, resulting in a F 1 score of 8.86%.</p><p>While a direct comparison of this score with the few-shot settings assessed in FREDo is not appropriate, due to the nature of how the task is posed (different relation types are examined), the score can be compared to results obtained from supervised learning. Here we see clearly that, when trained in a few-shot setting, DL-MNAV does not scale well to the supervised setting. We hypothesize that a key factor inhibiting the scalability is that the learned NOTA vectors are independent from the support documents in DL-MNAV. As a result the NOTA representations of the model are unaffected by added support documents. We do not experiment with SIE or SIE+SBN, as the amount of support instances would result in prohibitively large model sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Limitations</head><p>Regarding the limitations of the proposed benchmark, FREDo, we believe that while it represents a good basis for model development, it will be beneficial to add other cross-domain data sets from a greater variety of domains in the future. With the current, low F 1 scores seen in our tests, overestimating the performance of approaches does not seem to be too critical a danger. We are, however, hopeful that new methods might achieve significantly better results. At that point we suggest a reassessment of how representative this benchmark is of cross-domain performance in general. For the time being, however, we are confident that our tasks represent a valuable contribution to advancing the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In order to encourage the development of few-shot relation extraction approaches which are useful in real world scenarios, we propose FREDo, a few-shot document-level relation extraction benchmark. By moving to the document-level, the settings become more realistic, a problem which existing benchmarks are struggling with. For both in-domain and cross-domain tasks we present an approach which performs better than a simple baseline. Our experiments confirm that, even though some existing benchmarks imply that impressive, even superhuman performance can already be achieved in few-shot relation extraction, realistic tasks are very difficult using current approaches and that significant advances are required for fewshot relation extraction approaches to be usable in a real word scenario. In providing a benchmark that reveals this performance gap, we look to pave the way towards new methods with a potentially high impact on domain-specific and cross-domain relation extraction at scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Overlap of DocRED and sciERC</head><p>In table 7 we show the mapping of sciERC relation types onto Wikidata <ref type="bibr" target="#b14">(Vrande?i? and Kr?tzsch, 2014)</ref> properties and whether these relation types are contained in DocRED.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Relation Types in in-domain dataset</head><p>In tables 8-11, we list the relation types in the different datasets based on DocRED.</p><p>sciERC ID Wikidata ID DocRED hyponym-of P279 part-of P361 used-for P366 compare P2210 evaluate-for P5133 feature-of -conjunction -- <ref type="table">Table 7</ref>: Overlap of relation types in sciERC and Doc-RED</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>we show a comparison of how the different models handle deci-Embedding space illustration of the different models used for evaluation at inference time. Shown in (a) are all data points available from support documents, as well as the query instance. Class prototypes in (b) are computed as mean of support relation instances. Learned NOTA vectors, shown in red, are not based on support NOTA instances but learned during training and do not change based on the support document. Dotted lines indicate distances affecting the classification of the query instance, shown in white. Background colors illustrate approximate classification boundaries. For the baseline model (5.1.1), decision boundaries are the same as in (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>A comparison of DocRED<ref type="bibr" target="#b20">(Yao et al., 2019)</ref> and sciERC<ref type="bibr" target="#b8">(Luan et al., 2018)</ref>, the datasets selected for the FREDo benchmark.</figDesc><table><row><cell>cross-domain test set we use sciERC (Luan et al.,</cell></row><row><cell>2018) due to its domain (abstracts of scientific pub-</cell></row><row><cell>lications), which differs from DocRED (Wikipedia</cell></row><row><cell>abstracts), and the fact that it contains annotations</cell></row><row><cell>for 7 relation types. In table 1 we show a compari-</cell></row><row><cell>son of the selected datasets. Additional document-</cell></row><row><cell>level relation extraction data sets, SciREX (Jain</cell></row><row><cell>et al., 2020), DialogRE (Yu et al., 2020), GDA (Wu</cell></row><row><cell>et al., 2019), CDR (Li et al., 2016), were consid-</cell></row><row><cell>ered but ultimately not used for the cross-domain</cell></row><row><cell>set, due to the amount of relation types annotated</cell></row><row><cell>(too few), missing coreference links, or differing</cell></row><row><cell>relation format (SciREX annotations are based on</cell></row><row><cell>N -ary relations, while the other datasets annotate</cell></row><row><cell>only binary relations).</cell></row><row><cell>4.2 Training and Test Data</cell></row><row><cell>4.2.1 Document Corpora</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Average values for N and K across test episodes. K (micro) denotes the average across all episodes, K (macro) denotes the weighted average of mean K for each relation type. et al., 2021), we randomly sample query documents from the test corpus 5 to realistically represent the NOTA distribution of the entire corpus.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Results for different query sampling strategies on the in-domain task</figDesc><table><row><cell>6 Analysis of Results</cell></row><row><cell>6.1 Experimental Setup</cell></row><row><cell>All our models are based on BERT BASE (De-</cell></row><row><cell>vlin et al., 2019) implemented using Hugging-</cell></row><row><cell>face's Transformers</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>? 0.22 21.08 ? 2.71 7.05 ? 0.18 7.71 ? 0.69 22.80 ? 3.82 8.42 ? 0.64 DL-MNAV SIE 5.57 ? 0.04 23.12 ? 1.69 7.06 ? 0.15 5.16 ? 0.19 33.61 ? 2.68 6.77 ? 0.21 DL-MNAV SIE+SBN 1.02 ? 0.05 22.94 ? 1.87 1.71 ? 0.04 1.75 ? 0.16 23.41 ? 0.76 2.79 ? 0.24</figDesc><table><row><cell></cell><cell></cell><cell>1-Doc</cell><cell></cell><cell></cell><cell>3-Doc</cell><cell></cell></row><row><cell>Model</cell><cell>Precision [%]</cell><cell>Recall [%]</cell><cell>F 1 [%]</cell><cell>Precision [%]</cell><cell>Recall [%]</cell><cell>F 1 [%]</cell></row><row><cell>Baseline</cell><cell>0.36</cell><cell>9.69</cell><cell>0.60</cell><cell>0.60</cell><cell>10.75</cell><cell>0.89</cell></row><row><cell>DL-MNAV</cell><cell>6.26</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Results for FREDo in-domain task. Reported results are macro averages across relation types. MNAV SIE+SBN 2.26 ? 0.11 4.37 ? 0.13 2.85 ? 0.12 3.47 ? 0.14 4.24 ? 0.21 3.72 ? 0.14</figDesc><table><row><cell></cell><cell></cell><cell>1-Doc</cell><cell></cell><cell></cell><cell>3-Doc</cell><cell></cell></row><row><cell>Model</cell><cell cols="2">Precision [%] Recall [%]</cell><cell>F 1 [%]</cell><cell cols="2">Precision [%] Recall [%]</cell><cell>F 1 [%]</cell></row><row><cell>Baseline</cell><cell>1.34</cell><cell>3.04</cell><cell>1.76</cell><cell>1.84</cell><cell>2.47</cell><cell>1.98</cell></row><row><cell>DL-MNAV</cell><cell cols="6">2.30 ? 0.45 0.58 ? 0.12 0.84 ? 0.16 3.02 ? 2.38 0.29 ? 0.13 0.48 ? 0.21</cell></row><row><cell>DL-MNAV SIE</cell><cell cols="6">1.77 ? 0.60 2.08 ? 0.34 1.77 ? 0.60 2.51 ? 0.66 2.52 ? 0.31 2.51 ? 0.66</cell></row><row><cell>DL-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Results for FREDo cross-domain task. Reported results are macro averages across relation types.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>: A comparison highlighting the levels of dif-</cell></row><row><cell>ficulty of different few-shot relation extraction bench-</cell></row><row><cell>marks. For all sentence-level benchmarks, we report</cell></row><row><cell>the highest F 1 scores (at the time of writing) in the 5-</cell></row><row><cell>way 1-shot setting. For FREDo we report the 1-Doc</cell></row><row><cell>setting. For FewRel and FewRel 2.0, we report the high-</cell></row><row><cell>est scores found at the respective CodaLab competition</cell></row><row><cell>websites.</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/nicpopovic/FREDo</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The setting in which no such annotations are given is typically referred to as joint entity and relation extraction and is out of scope of this paper.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The first, if there are multiple support documents.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">For the pooling step we use mean pooling as, during preliminary experiments, it performed better than the logsumexp pooling used byZhou et al..  7  We also examined the option of resampling the training samples such that the amount of negative examples in each training step roughly matches the amount of positive examples<ref type="bibr" target="#b3">(Han and Wang, 2020)</ref>, but found this to be less effective.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">The sampled NOTA representations do not persist across episodes.9  Since, with SIE, we do not use prototypes at inference time, we then perform this sampling step for each relation instance rather than for prototypes and increase k to 20.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was partially supported by the German Federal Ministry of Education and Research (BMBF) as part of the project IIDI (01IS21026D) and the Smart Data Innovation Lab as part of the Smart Data Innovation Challenges (01IS19030A). The authors acknowledge support by the state of Baden-W?rttemberg through bwHPC.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">FewRel 2.0: Towards more challenging few-shot relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1649</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6251" to="6256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<title level="m">Yangqing Jia, and Kaiming He. 2017. Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Novel Document-Level Relation Extraction Method Based on BERT and Entity Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2020.2996642</idno>
	</analytic>
	<monogr>
		<title level="m">Conference Name: IEEE Access</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="96912" to="96919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-1514</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10-31" />
			<biblScope unit="page" from="4803" to="4809" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Scirex: A challenge dataset for document-level information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarthak</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madeleine</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BioCreative V CDR task corpus: a resource for chemical disease relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueping</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Sciaky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Hsuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><forename type="middle">Peter</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolyn</forename><forename type="middle">J</forename><surname>Mattingly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">C</forename><surname>Wiegers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1093/database/baw068</idno>
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<biblScope unit="page">68</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Decoupled Weight Decay Regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations 2019</title>
		<meeting>the International Conference on Learning Representations 2019</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1360</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3219" to="3232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Revisiting Few-shot Relation Classification: Evaluation Data and Classification Schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofer</forename><surname>Sabo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanai</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00392</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="691" to="706" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Prototypical Networks for Few-shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Matching the Blanks: Distributional Similarity for Relation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Livio Baldini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kwiatkowski</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1279</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2895" to="2905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">One-shot to Weakly-Supervised Relation Classification using Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phong</forename><surname>Thy Thy Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ananiadou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>Automated Knowledge Base Construction</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Matching Networks for One Shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Wikidata: a free collaborative knowledgebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Vrande?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Kr?tzsch</surname></persName>
		</author>
		<idno type="DOI">10.1145/2629489</idno>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dakuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saloni</forename><surname>Potdar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1132</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1371" to="1377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-Art Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teven</forename><forename type="middle">Le</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">RENET: A Deep Learning Approach for Extracting Gene-Disease Associations from Literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruibang</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hing-Fung</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tak-Wah</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lam</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-17083-7_17</idno>
	</analytic>
	<monogr>
		<title level="m">Research in Computational Molecular Biology</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="272" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">SAIS: Supervising and Augmenting Intermediate Steps for Document-Level Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zecheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Entity Structure Within and Throughout: Modeling Mention Dependencies for Document-Level Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhendong</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021-02-02" />
			<biblScope unit="page" from="14149" to="14157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DocRED: A Large-Scale Document-Level Relation Extraction Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1074</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="764" to="777" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">2022. Pack Together: Entity and Relation Extraction with Levitated Marker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2022</title>
		<meeting>ACL 2022</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dialogue-based relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Document-level Relation Extraction as Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shumin</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosha</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huajun</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2021/551</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21</title>
		<meeting>the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3999" to="4006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Position-aware Attention and Supervised Data Improve Slot Filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1004</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
