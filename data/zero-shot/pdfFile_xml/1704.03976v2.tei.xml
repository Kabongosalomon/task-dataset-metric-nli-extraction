<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin-Ichi</forename><surname>Maeda</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Ishii</surname></persName>
						</author>
						<title level="a" type="main">Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the conditional label distribution given input. Virtual adversarial loss is defined as the robustness of the conditional label distribution around each input data point against local perturbation. Unlike adversarial training, our method defines the adversarial direction without label information and is hence applicable to semi-supervised learning. Because the directions in which we smooth the model are only "virtually" adversarial, we call our method virtual adversarial training (VAT). The computational cost of VAT is relatively low. For neural networks, the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward-and back-propagations. In our experiments, we applied VAT to supervised and semi-supervised learning tasks on multiple benchmark datasets. With a simple enhancement of the algorithm based on the entropy minimization principle, our VAT achieves state-of-the-art performance for semi-supervised learning tasks on SVHN and CIFAR-10. !</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>I N practical regression and classification problems, one must face two problems on opposite ends; underfitting and overfitting. On one end, poor design of model and optimization process can result in large error for both training and testing dataset (underfitting). On the other end, the size of the sample that can be used to tune the parameters of model is always finite, and the evaluation of the objective function in practice will always be a mere empirical approximation of the true expectation of the target value over the sample space. Therefore, even with successful optimization and low error rate on the training dataset (training error), the true expected error (test error) can be large <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b46">[47]</ref> (overfitting). The subject of our study is the latter. Regularization is a process of introducing additional information in order to manage this inevitable gap between the training error and the test error. In this study, we introduce a novel regularization method applicable to semisupervised learning that identifies the direction in which the classifier's behavior is most sensitive.</p><p>Regularization is often carried out by augmenting the loss function with a so-called regularization term, which prevents the model from overfitting to the loss function evaluated on a finite set of sample points. From Bayesian standpoint, regularization term can be interpreted as a prior distribution that reflects our educated a priori knowledge or belief regarding the model <ref type="bibr" target="#b6">[7]</ref>. A popular a priori belief based on widely observed facts is that the outputs of most naturally occurring systems are smooth with respect to spatial and/or temporal inputs <ref type="bibr" target="#b45">[46]</ref>. What often underlie this belief are the laws of physics governing the system of interest, which in many cases are described by smooth models based on differential equations <ref type="bibr" target="#b3">[4]</ref>. When we are constructing the probability model, this belief prompts us to prefer conditional output distribution p(y|x) (or just output distribution for short) that are smooth with respect to conditional input x.</p><p>In fact, smoothing the output distribution often works to our advantage in actual practice. For example, label propagation <ref type="bibr" target="#b48">[49]</ref> is an algorithm that improves the performance of classifier by assigning class labels to unlabeled training samples based on the belief that close input data points tend to have similar class labels. Also, it is known that, for neural networks (NNs), one can improve the generalization performance by applying random perturbations to each input in order to generate artificial input points and encouraging the model to assign similar outputs to the set of artificial inputs derived from the same point <ref type="bibr" target="#b5">[6]</ref>. Several studies have also confirmed that this philosophy of making the predictor robust against random and local perturbation is effective in semi-supervised learning. For selected examples, see <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b44">[45]</ref>.</p><p>However, <ref type="bibr" target="#b40">[41]</ref> and <ref type="bibr" target="#b13">[14]</ref> found a weakness in naive application of this philosophy. They found that standard isotropic smoothing via random noise and random data augmentation often leaves the predictor particularly vulnerable to a small perturbation in a specific direction, that is, the adversarial direction, which is the direction in the input space in which the label probability p(y = k|x) of the model is most sensitive. <ref type="bibr" target="#b40">[41]</ref> and <ref type="bibr" target="#b13">[14]</ref> experimentally verified that the predictors trained with the standard regularization technique such as L 1 and L 2 regularization are likely to make mistakes when the signal is perturbed in the adversarial direction, even when the norm of the perturbation is so small that it cannot be perceived by human eyes.</p><p>Inspired by this finding, Goodfellow et al. <ref type="bibr" target="#b13">[14]</ref> developed adversarial training that trains the model to assign to each in-put data a label that is similar to the labels to be assigned to its neighbors in the adversarial direction. This attempt succeeded in improving generalization performance and made the model robust against adversarial perturbation. Goodfellow et al. <ref type="bibr">'</ref>s work suggests that the locally isotropic output distribution cannot be achieved by making the model robust against isotropic noise. In retrospect, this observation is in fact quite intuitive. If the distribution around a given input is anisotropic and the goal is to resolve this anisotropy, it does not make much sense to exert equal smoothing "pressure" into all directions.</p><p>Our proposed regularization technique is a method that trains the output distribution to be isotropically smooth around each input data point by selectively smoothing the model in its most anisotropic direction. In order to quantify this idea, we introduce a notion of virtual adversarial direction, which is a direction of the perturbation that can most greatly alter the output distribution in the sense of distributional divergence. Virtual adversarial direction is our very interpretation of the 'most' anisotropic direction. In contrast, adversarial direction introduced by Goodfellow et al. <ref type="bibr" target="#b13">[14]</ref> at an input data point is a direction of the perturbation that can most reduce the model's probability of correct classification, or the direction that can most greatly "deviate" the prediction of the model from the correct label. Unlike adversarial direction, virtual adversarial direction can be defined on unlabeled data point, because it is the direction that can most greatly deviate the current inferred output distribution from the status quo. In other words, even in the absence of label information, virtual adversarial direction can be defined on an unlabeled data point as if there is a "virtual" label; hence the name "virtual" adversarial direction.</p><p>With the definition of virtual adversarial direction, we can quantify the local anisotropy of the model at each input point without using the supervisory signal. We define the local distributional smoothness (LDS) to be the divergencebased distributional robustness of the model against virtual adversarial direction. We propose a novel training method that uses an efficient approximation in order to maximize the likelihood of the model while promoting the model's LDS on each training input data point. For brevity, we call this method virtual adversarial training (VAT).</p><p>The following list summarizes the advantages of this new method:</p><p>? applicability to semi-supervised learning tasks ? applicability to any parametric models for which we can evaluate the gradient with respect to input and parameter ? small number of hyperparameters ? parametrization invariant regularization The second advantage is worth emphasizing. At first glance, our algorithm may appear as if it needs to solve an internal optimization problem in order to determine the virtual adversarial direction. For models such as NNs for which we can evaluate the gradient of the output with respect to the input, however, virtual adversarial perturbation admits an approximation that can be computed efficiently with the power method <ref type="bibr" target="#b10">[11]</ref>. This property enables us to implement VAT for NNs with no more than three times the computational cost of the standard, regularization-free training. This approximation step is an important part of the VAT algorithm that makes it readily applicable for various settings and model architectures.</p><p>Finally, the fourth advantage is not to be overlooked, because this is the most essential point at which our VAT is fundamentally different from popular regularization methods like L p regularization. For linear models, L p regularization has an effect of mitigating the oversensitivity of the output with respect to input, and one can control the strength of its effect via the hyperparameters. When the model in concern is highly nonlinear, as in the case of neural networks, however, the user has little control over the effect of L p regularization. Manipulation of the parameters in the first layer would have different effect on the final output depending on the choice of the parameters in the middle layers, and the same argument applies to the effect of regularization. In the language of Bayesian statistics with which we interpret the regularization term as prior distribution, this is to say that the nature of the prior distributions favored by the L p regularization depends on the current parameter-setting and is hence ambiguous and difficult to assess. Parameterization invariant regularization, on the other hand, does not suffer from such a problem. In more precise terms, by parametrization invariant regularization we mean the regularization based on an objective function L(?) with the property that the corresponding optimal distribution p(X; ? * ) is invariant under the one-</p><formula xml:id="formula_0">to-one transformation ? = T (?), ? = T ?1 (?). That is, p(X; ? * ) = p(X; ? * ) where ? * = arg min ? L(T ?1 (?); D).</formula><p>VAT is a parameterization invariant regularization, because it directly regularizes the output distribution by its local sensitivity of the output with respect to input, which is, by definition, independent from the way to parametrize the model.</p><p>When we applied VAT to the supervised and semisupervised learning for the permutation invariant task on the MNIST dataset, our method outperformed all contemporary methods other than some cutting-edge methods that use sophisticated network architecture. We also applied our method to semi-supervised learning on CIFAR-10 and Street View House Numbers (SVHN) datasets, and confirmed that our method achieves superior or comparable performance in comparison to those of state-of-the-art methods.</p><p>This article also extends our earlier work <ref type="bibr" target="#b29">[30]</ref> in five aspects:</p><p>? clarification of the objective function ? comparison between VAT and random perturbation training (RPT) 1 ? additional set of extensive experiments ? evaluation of the virtual adversarial examples ? enhancement of the algorithm with entropy minimization</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head><p>Many classic regularization methods for NNs regularize the models by applying random perturbations to input and hidden layers <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b38">[39]</ref>. An early work by <ref type="bibr" target="#b0">1</ref>. a downgraded version of VAT introduced in this paper that smooths the label distribution at each point with same force in all directions. Please see the detail definition of RPT in Section 3.4.</p><p>Bishop <ref type="bibr" target="#b5">[6]</ref> showed that adding Gaussian perturbation to inputs during the training process is equivalent to adding an extra regularization term to the objective function. For small perturbations, the regularization term induced by such perturbation behaves similarly to a class of Tikhonov regularizers <ref type="bibr" target="#b42">[43]</ref>. The application of random perturbations to inputs has an effect of smoothing the input-output relation of the NNs. Another way to smooth the input-output relation is to impose constraints on the derivatives. For example, constraints may be imposed on the Frobenius norm of the Jacobian matrix of the output with respect to the input. This approach was taken by Gu and Rigazio <ref type="bibr" target="#b15">[16]</ref> in their deep contractive network. Instead of computing the computationally expensive full Jacobian, however, they approximated the Jacobian by the sum of the Frobenius norms of the layer-wise Jacobians computed for all adjacent pairs of hidden layers. Possibly because of their layer-wise approximation, however, deep contractive network was not successful in significantly decreasing the test error.</p><p>Dropout <ref type="bibr" target="#b38">[39]</ref> is another popular method for regularizing NNs with random noise. Dropout is a method that assigns random masks on inputs/hidden layers in the network during its training. From a Bayesian perspective, dropout is a method to introduce prior distribution for the parameters <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b28">[29]</ref>. In this interpretation, dropout is a method that regularizes the model via Bayesian model ensembles, and is complementary to our approach, which directly augments the function with a regularization term.</p><p>Adversarial training was originally proposed by <ref type="bibr" target="#b40">[41]</ref>. They discovered that some architectures of NNs, including state-of-the-art NN models, are particularly vulnerable to a perturbation applied to an input in the direction to which the models' label assignment to the input is most sensitive (adversarial), even when the perturbation is so small that human eyes cannot discern the difference. They also showed that training the models to be robust against adversarial perturbation is effective in reducing the test error. However, the definition of adversarial perturbation in <ref type="bibr" target="#b40">[41]</ref> required a computationally expensive inner loop in order to evaluate the adversarial direction. To overcome this problem, Goodfellow et al. <ref type="bibr" target="#b13">[14]</ref> proposed another definition of adversarial perturbation that admits a form of approximation that is free of the expensive inner loop (see the next section for details).</p><p>Bachman et al. <ref type="bibr" target="#b4">[5]</ref> studied the effect of random perturbation in the setting of semi-supervised learning. Pseudo Ensemble Agreement introduced in <ref type="bibr" target="#b4">[5]</ref> trains the model in a way that the the output from each layer in the NN does not vary too much by the introduction of random perturbations. On the other hand, ladder networks <ref type="bibr" target="#b32">[33]</ref> achieved high performance for semi-supervised learning tasks by making an effort so that one can reconstruct the original signal of the lower layer from the signal of the uppermost layer and the noise-perturbed outputs from the hidden layers.</p><p>Our method is similar in philosophy to <ref type="bibr" target="#b4">[5]</ref>, and we use the virtual adversarial perturbation for their noise process. As we show later, in our experiments, this choice of perturbation was able to improve the generalization performance. Random image augmentation is a variant of random perturbation that simply augments the dataset with images perturbed by regular deformation. For more theoretical overview of related methods of noise regularizations, Jacobian regularizations and their extensions like PEA <ref type="bibr" target="#b4">[5]</ref>, ladder networks <ref type="bibr" target="#b32">[33]</ref> and VAT, we refer the readers to <ref type="bibr" target="#b1">[2]</ref>.</p><p>Several works <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b34">[35]</ref> succeeded in using the random image augmentation to improve generalization performance for semi-supervised tasks of image classification. These methods can also be interpreted as types of techniques that smooth the model around input data points and extrapolate the labels of unlabeled examples. In the area of nonparametric studies, this type of method is referred to as label propagation <ref type="bibr" target="#b48">[49]</ref>.</p><p>Another family of methods for the semi-supervised learning of NNs that are worth mentioning is the family based on sophisticated generative models. The methods belonging to this family are different from those that we introduced above because they do not require an explicit definition of smoothness. Kingma et al. <ref type="bibr" target="#b21">[22]</ref> applied a variational-autoencoder-based generative model to semisupervised learning. This work was followed by several variants <ref type="bibr" target="#b26">[27]</ref>. Generative adversarial networks (GANs) proposed by <ref type="bibr" target="#b12">[13]</ref> are a recently popular high-performance framework that can also be applied to semi-supervised learning <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>. In practice, these methods often require careful tuning of many hyperparameters in the generative model, and are usually not easy to implement without high expertise in its optimization process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>We begin this section with a set of notations. Let x ? R I and y ? Q respectively denote an input vector and an output label, where I is the input dimension and Q is the space of all labels. Additionally, we denote the output distribution parameterized by ? as p(y|x, ?). We use? to denote the vector of the model parameters at a specific iteration step of the training process. We use D l = {x (n) l , y (n) l |n = 1, . . . , N l } to denote a labeled dataset, and D ul = {x (m) ul |m = 1, . . . , N ul } to denote an unlabeled dataset. We train the model p(y|x, ?) using D l and D ul .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Adversarial Training</head><p>Our method is closely related to the adversarial training proposed by Goodfellow et al. <ref type="bibr" target="#b13">[14]</ref>. We therefore formulate adversarial training before introducing our method. The loss function of adversarial training in <ref type="bibr" target="#b13">[14]</ref> can be written as</p><formula xml:id="formula_1">L adv (x l , ?) := D [q(y|x l ), p(y|x l + r adv , ?)]</formula><p>(1) where r adv := arg max</p><formula xml:id="formula_2">r; r ? D [q(y|x l ), p(y|x l + r, ?)] ,<label>(2)</label></formula><p>where D[p, p ] is a non-negative function that measures the divergence between two distributions p and p . For example, D can be the cross entropy D[p, p ] = ? i p i log p i , where p and p are vectors whose i-th coordinate represents the probability for the i-th class. The function q(y|x l ) is the true distribution of the output label, which is unknown. The goal with this loss function is to approximate the true distribution q(y|x l ) by a parametric model p(y|x l , ?) that is robust against adversarial attack to x. In <ref type="bibr" target="#b13">[14]</ref>, the function q(y|x l ) was approximated by one hot vector h(y; y l ), whose entries are all zero except for the index corresponding to the true label (output) y l . Likewise, for regression tasks, we can use the normal distribution centered at y l with constant variance, or the delta function with the atom at y = y l . Generally, we cannot obtain a closed form for the exact adversarial perturbation r adv . However, we can approximate r adv with a linear approximation of D with respect to r in Eq. <ref type="bibr" target="#b1">(2)</ref>. When the norm is L 2 , adversarial perturbation can be approximated by</p><formula xml:id="formula_3">r adv ? g g 2 , where g = ? x l D [h(y; y l ), p(y|x l , ?)] .<label>(3)</label></formula><p>When the norm is L ? , adversarial perturbation can be approximated by</p><formula xml:id="formula_4">r adv ? sign(g),<label>(4)</label></formula><p>where g is the same function that appeared in Eq. <ref type="formula" target="#formula_3">(3)</ref>. <ref type="bibr" target="#b13">[14]</ref> originally used (4) for their adversarial training. Note that, for NNs, the gradient ? x l D [h(y; y l ), p(y|x l , ?)] can be efficiently computed by backpropagation. By optimizing the loss function of the adversarial training in Eq.(1) based on the adversarial perturbation defined by Eq.(3) (or (4)), <ref type="bibr" target="#b13">[14]</ref> and <ref type="bibr" target="#b29">[30]</ref> were able to train a model with better generalization performance than the model trained with random perturbations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Virtual Adversarial Training</head><p>Adversarial training is a successful method that works for many supervised problems. However, full label information is not available at all times. Let x * represent either x l or x ul . Our objective function is now given by</p><formula xml:id="formula_5">D [q(y|x * ), p(y|x * + r qadv , ?)]</formula><p>where r qadv := arg max</p><formula xml:id="formula_6">r; r ? D [q(y|x * ), p(y|x * + r, ?)] ,</formula><p>Indeed, we have no direct information about q(y|x ul ). We therefore take the strategy to replace q(y|x) with its current approximation, p(y|x, ?). This approximation is not necessarily naive, because p(y|x, ?) shall be close to q(y|x) when the number of labeled training samples is large. This is also the motivation behind our inclusion of the term "virtual" in our work. Literally, we use "virtual" labels that are probabilistically generated from p(y|x, ?) in place of labels that are unknown to the user, and compute adversarial direction based on the virtual labels. Therefore, in this study, we use the current estimate p(y|x,?) in place of q(y|x). With this compromise, we arrive at our rendition of Eq.(2) given by</p><formula xml:id="formula_7">LDS(x * , ?) := D p(y|x * ,?), p(y|x * + r vadv , ?)<label>(5)</label></formula><formula xml:id="formula_8">r vadv := arg max r; r 2? D p(y|x * ,?), p(y|x * + r) ,<label>(6)</label></formula><p>which defines our virtual adversarial perturbation. The loss LDS(x, ?) can be considered as a negative measure of the local smoothness of the current model at each input data point x, and its reduction would make the model smooth at each data point. The regularization term we propose in this study is the average of LDS(x * , ?) over all input data points:</p><formula xml:id="formula_9">R vadv (D l , D ul , ?) := 1 N l + N ul x * ?D l ,D ul LDS(x * , ?). (7)</formula><p>The full objective function is thus given by</p><formula xml:id="formula_10">(D l , ?) + ?R vadv (D l , D ul , ?),<label>(8)</label></formula><p>where (D l , ?) is the negative log-likelihood for the labeled dataset. VAT is a training method with the regularizer R vadv . One notable advantage of VAT is that there are just two scalar-valued hyperparameters: (1) the norm constraint &gt; 0 for the adversarial direction and (2) the regularization coefficient ? &gt; 0 that controls the relative balance between the negative log-likelihood and the regularizer R vadv . In fact, for all our experiments, our VAT achieved superior performance by tuning only the hyperparameter , while fixing ? = 1. Theoretically, these two hyperparameters play similar roles, as discussed later in Section 4.2. One advantage of VAT is the number of hyperparameters. For many generative model-based supervised and semi-supervised learning methods aimed at learning p(y, x), a bottleneck of training is the difficulty of the optimization of hyperparameters for the generative model (i.e. p(x) or p(x|y)). Also, as opposed to adversarial training <ref type="bibr" target="#b13">[14]</ref>, the definition of virtual adversarial perturbation only requires input x and does not require label y. This is the property that allows us to apply VAT to semi-supervised learning. <ref type="figure">Fig. 1</ref> shows how VAT works on semi-supervised learning on a two-dimensional synthetic dataset. We used an NN classifier with one hidden layer with 50 hidden units. At the beginning of the training, the classifier predicted different labels for input data points in the same cluster, and LDS on the boundaries were very high (see panel <ref type="bibr" target="#b1">(2)</ref> in <ref type="figure">Fig. 1</ref>). The algorithm exerts high pressure for the model to be smooth around the points with large LDS values. As the training progressed, the model evolved so that the label prediction on the points with large LDS values are strongly influenced by the labeled inputs in the vicinity. This encouraged the model to predict the same label for the set of points that belong to the same cluster, which is what we often desire in semi-supervised learning. As we can see in <ref type="figure">Fig. 1</ref>, VAT on semi-supervised learning can be given a similar interpretation as label propagation <ref type="bibr" target="#b48">[49]</ref>, which is another branch of method for semi-supervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fast Approximation Method for r vadv and the Derivative of the Objective Function</head><p>Once virtual adversarial perturbation r vadv is computed, the evaluation of LDS(x * , ?) simply becomes the computation of the divergence D between the output distributions p(y|x * ,?) and p(y|x * + r vadv , ?). However, the evaluation of r vadv cannot be performed with the linear approximation as in the original adversarial training (Eq.(3)) because the gradient of D[p(y|x * ,?), p(y|x * + r,?)] with respect to r is always 0 at r = 0. In the following, we propose an efficient computation of r vadv , for which there is no evident closed form.</p><p>For simplicity, we denote D[p(y|x * ,?), p(y|x * + r, ?)] by D(r, x * , ?). We assume that p(y|x * , ?) is twice differentiable with respect to ? and x almost everywhere. Because D(r, x * ,?) takes the minimal value at r = 0, the differentiability assumption dictates that its first derivative <ref type="figure">Fig. 1</ref>: Demonstration of how our VAT works on semi-supervised learning. We generated 8 labeled data points (y = 1 and y = 0 are green and purple, respectively), and 1,000 unlabeled data points in 2-D space. The panels in the first row (I) show the prediction p(y = 1|x, ?) on the unlabeled input points at different stages of the algorithm. We used a continuous colormap to designate the predicted values of p(y = 1|x, ?), with Green, gray, and purple respectively corresponding to the values 1.0, 0.5, and 0.0. The panels in the second row (II) are heat maps of the regularization term LDS(x,?) on the input points. The values of LDS on blue-colored points are relatively high in comparison to the gray-colored points. We used KL divergence for the choice of D in Eq. <ref type="bibr" target="#b4">(5)</ref>. Note that, at the onset of training, all the data points have similar influence on the classifier. After 10 updates, the model boundary was still appearing over the inputs. As the training progressed, VAT pushed the boundary away from the labeled input data points.</p><p>? r D(r, x,?)| r=0 is zero. Therefore, the second-order Taylor approximation of D is</p><formula xml:id="formula_11">D(r, x,?) ? 1 2 r T H(x,?)r,<label>(9)</label></formula><p>where H(x,?) is the Hessian matrix given by H(x,?) := ?? r D(r, x,?)| r=0 . Under this approximation, r vadv emerges as the first dominant eigenvector u(x,?) of H(x,?) with magnitude :</p><formula xml:id="formula_12">r vadv ? arg max r {r T H(x,?)r; r 2 ? } = u(x,?),<label>(10)</label></formula><p>wherev denotes the unit vector whose direction is the same as its argument vector v; that is,v ? v v 2 . Hereafter, we denote H(x,?) by H for simplicity.</p><p>Next, we need to address the O(I 3 ) runtime required for the computation of the eigenvectors of the Hessian H. We resolve this issue with the approximation via the power iteration method <ref type="bibr" target="#b10">[11]</ref> and the finite difference method. Let d be a randomly sampled unit vector. Provided that d is not perpendicular to the dominant eigenvector u, the iterative calculation of</p><formula xml:id="formula_13">d ? Hd<label>(11)</label></formula><p>makes d converge to u. To reduce the computational time, we perform this operation without the direct computation of H. Note that Hd can be approximated using the finite difference method:</p><formula xml:id="formula_14">Hd ? ? r D(r, x,?)| r=?d ? ? r D(r, x,?)| r=0 ? = ? r D(r, x,?)| r=?d ? ,<label>(12)</label></formula><p>with ? = 0. In the computation above, we use the fact that ? r D(r, x,?)| r=0 = 0 again. To summarize, we can approximate r vadv with the repeated application of the following update:</p><formula xml:id="formula_15">d ? ? r D(r, x,?)| r=?d .<label>(13)</label></formula><p>The computation of ? r D can be performed in a straightforward manner. For NNs, this can be performed with one set of backpropagation. The approximation introduced here can be improved monotonically by increasing the number of the power iterations K. Thus, for NNs, the computation of r vadv can be performed with K sets of backpropagations. Surprisingly, only one power iteration was sufficient for high performance on various benchmark datasets. This approximation of r vadv with K = 1 results in an approximation that is similar in form to Eq. <ref type="formula" target="#formula_3">(3)</ref>:</p><formula xml:id="formula_16">r vadv ? g g 2 (14) where g = ? r D p(y|x,?), p(y|x + r,?) r=?d .<label>(15)</label></formula><p>We further discuss the effects of the number of the power iterations in Section 4. After computing r vadv , the derivative of R vadv can be easily computed with one set of forwardand back-propagation on NNs. Meanwhile, the derivative of r vadv with respect to ? is not only convoluted and computationally costly, but also introduces another source of variance to the gradient and negatively affect the performance of the algorithm. Our VAT therefore ignores the dependency of r vadv on ?. In total, the derivative of the full objective function including the log-likelihood term (8) can be computed with K +2 sets of backpropagation. Algorithm 1 summarizes the procedure for mini-batch SGD with the approximation of ? ? R vadv carried out with one power iteration. VAT is an algorithm that updates the model by the weighted sum of the gradient of the likelihood and the gradient ? ? R vadv computed with Algorithm 1.</p><formula xml:id="formula_17">Algorithm 1 Mini-batch SGD for ? ? R vadv (?)| ?=? , with a one-time power iteration method. 1) Choose M samples of x (i) (i = 1, . . . , M ) from dataset D at random. 2) Generate a random unit vector d (i) ? R I using an iid Gaussian distribution. 3) Calculate r vadv via taking the gradient of D with respect to r on r = ?d (i) on each input data point x (i) : g (i) ? ? r D p(y|x (i) ,?), p(y|x (i) + r,?) r=?d (i) , r (i) vadv ? g (i) / g (i) 2 4) Return ? ? 1 M M i=1 D p(y|x (i) ,?), p(y|x (i) + r (i) vadv , ?) ?=?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Virtual Adversarial Training vs. Random Perturbation Training</head><p>The regularization function we use for VAT can be generally written as</p><formula xml:id="formula_18">R (K) (?, D l , D ul ) := 1 N l + N ul x?D l ,D ul E r K D p(y|x,?), p(y|x + r K , ?) ,<label>(16)</label></formula><p>where r K is obtained by applying the power iteration Ktimes on a sample from the uniform distribution on the sphere U (r| ) with radius . In practice, for the computation of (16) we use an empirical expectation about the random perturbation r K . For the implementation of VAT, we use this regularizer with K ? 1. Meanwhile, We refer to the training with R (0) as Random Perturbation Training (RPT). RPT is a downgraded version of VAT that does not perform the power iteration. By definition, RPT only smooths the function isotropically around each input data point. As we discuss further in Section 4, RPT falls behind VAT in its sheer ability to reduce the generalization error. There could be two reasons for the superiority of VAT.</p><p>First, the learning process of VAT is inherently more stable than that of RPT. At each step of the algorithm, the power iteration generates a vector that has a large projection to the virtual adversarial direction with high probability. Note that, as K ? ?, under the sufficient regularity of the model, the gradient of D in the expression (16) approaches the deterministic vector 1/2 2 ? ? ? 1 (x, ?), where ? 1 is the dominant eigenvalue of H(x, ?).</p><p>Thus, the direction to which VAT smooths the model is more deterministic than the direction to which RPT smooths the model, which is uniformly distributed over the sphere of radius ; the stability of the learning of RPT always suffers from the variance of <ref type="bibr" target="#b15">(16)</ref>.</p><p>Second, the regularization function of RPT has an essentially effect on the model. For each observed input point, VAT trains the model to assign similar label distribution only to the set of proximal points aligned in the virtual adversarial direction. In contrast, RPT encourages the model to assign the same label distribution to all input points in the isotropic neighborhood of each observed input. From spectral perspective, the difference between VAT and RPT is that VAT penalizes the spectral norm (largest singular value) of the Hessian matrix H (9), while RPT penalizes the sum of the eigenvalues <ref type="bibr" target="#b1">[2]</ref>. Therefore, so long that the true output distribution is isotropically smooth around the input data point, VAT tends to be more effective in improving the generalization performance.</p><p>In Section 4.5, we investigate the variance of the gradients in more detail and compare RPT and VAT from this perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We conducted a set of numerical experiments to assess the following aspects of VAT:</p><p>? the sheer efficacy of VAT in comparison to RPT and to a collection of recent competitive algorithms for supervised and semi-supervised learning, ? the effect of hyperparameters (the perturbation size , the regularization coefficient ?, and the number of the power iterations K) on the performance of VAT, ? VAT's effect on the robustness of the trained NNs against virtual adversarial perturbations, and ? the mechanism behind the advantage of using virtual adversarial perturbation as opposed to random perturbation. We would like to remind the readers that, by the term VAT here, we mean the algorithm that uses the approximation step we introduced in Section 3.3 and Algorithm 1. In the following, we describe the experimental settings and outcomes of the experiments. For the performance evaluation of our method, we used standard benchmarks like MNIST, CIFAR-10 and SVHN. For the methods to compare, we used the methods that were state-of-the-art at the time of this research. For more details on the dataset and model architectures, please see the appendix sections. For all our experiments, we used fully connected NNs or convolutional neural networks (CNNs) as the architectures of the classifiers, and used Theano <ref type="bibr" target="#b41">[42]</ref> and TensorFlow <ref type="bibr" target="#b0">[1]</ref> to train the models 2 . We use p(y|x, ?) to denote the label distribution of 2. TensorFlow implementation for the experiments is available at https://github.com/takerum/vat tf. Chainer <ref type="bibr" target="#b43">[44]</ref> implementation is also available at https://github.com/takerum/vat chainer. the classifier, where ? represents the vector of the parameters of the NN. For the activation function, we used ReLU <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b30">[31]</ref>. We also used Batch Normalization <ref type="bibr" target="#b18">[19]</ref>. For the divergence D in Eq. (1), we chose the KL divergence</p><formula xml:id="formula_19">D [p(y|x), p(y|x + r)] := y?Q p(y|x) log p(y|x) p(y|x + r)</formula><p>, <ref type="bibr" target="#b16">(17)</ref> where Q is the domain of y. For classification problems, Q is the set of all possible labels. We set ? in Eq.(12) to be 1e-6 in all of our experiments. For each set of experiments, we repeated the same procedure multiple times with different random seeds for the weight initialization and for the selection of labeled samples (for semi-supervised learning). The values reported on the tables are the means and the standard deviations of the results. Please see the appendix sections for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Testing the Efficacy of VAT on Benchmark Tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Supervised Learning on MNIST and CIFAR-10</head><p>We first applied our algorithm to supervised learning on MNIST dataset. We used NNs with four hidden layers, whose numbers of units were (1200, 600, 300, 150). We provide more details of the experiments in Appendix A.</p><p>For each regularization method, we used the set of hyperparameters that achieved the best performance on the validation dataset of size 10, 000, which was selected from the pool of training samples of size 60, 000. Test datasets were produced so that they have no intersection with the training dataset. We fed the test dataset into the trained NNs and recorded their test errors. <ref type="figure" target="#fig_0">Fig. 2</ref> shows the transition of R vadv and the learning curves for the baseline NN trained without VAT (denoted by 'wo/ VAT') and the NN trained with VAT (denoted by 'w/ VAT'). As the training progressed, R vadv of the NN trained with VAT exceeded that of the baseline; that is, the model trained with VAT grew smoother than the baseline in terms of LDS.  <ref type="table" target="#tab_0">Table 1</ref> summarizes the performance of our regularization method (VAT) and the other regularization methods for supervised learning on MNIST. VAT performed better than all the contemporary methods except ladder networks, which is a highly advanced method based on special network structure.</p><p>We also tested VAT with K &gt; 1 in order to study the dependence of the number of the power iterations K on the performance of VAT. As we will discuss in Section 4.3, however, we were not able to achieve substantial improvement by increasing the value of K.</p><p>We also applied our algorithm to supervised learning on CIFAR-10 <ref type="bibr" target="#b22">[23]</ref>. For the baseline for this set of experiments, we used a 'Conv-Large' with dropout ( <ref type="table">Table 7</ref>, Appendix D). <ref type="table" target="#tab_1">Table 2</ref> summarizes the test performance of supervised learning methods implemented with CNN on CIFAR10. We also compared the performance of VAT to advanced architectures like ResNet <ref type="bibr" target="#b16">[17]</ref> and DenseNet <ref type="bibr" target="#b17">[18]</ref> in order to confirm that the baseline model of our algorithm is "mediocre enough" so that we can rightly attribute the effectiveness of our algorithm to its way of the regularization itself, not to the network structure we used in the experiments. For CIFAR-10, our VAT achieved satisfactory performance relative to the standards.  Recall that our definition of LDS(x, ?) at any point x does not require the supervisory signal for x. In particular, this means that we can apply VAT to semi-supervised learning tasks. We emphasize that this is a property not shared by adversarial training. We applied VAT to semi-supervised image classification tasks on three datasets: MNIST, SVHN <ref type="bibr" target="#b31">[32]</ref>, and CIFAR-10 <ref type="bibr" target="#b22">[23]</ref>. We provide the details of the experimental settings in Appendix D.</p><p>For MNIST, we used the same architecture of NN as in the previous section. We also used batch normalization in our implementation. We used a mini-batch of size 64 for the calculation of the negative log-likelihood term, and a minibatch of size 256 for the calculation of R vadv in Eq. <ref type="bibr" target="#b7">(8)</ref>. As mentioned in Section 3.2, we used both labeled and unlabeled sets for the calculation of R vadv . <ref type="table" target="#tab_2">Table 3</ref> summarizes the results for the permutation invariant MNIST task. All the methods listed in the table belong to the family of semisupervised learning methods. For the MNIST dataset, VAT outperformed all the contemporary methods other than the methods based on generative models, such as <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b35">[36]</ref>, which are state-of-the-art methods. For the experiments on SVHN and CIFAR-10, we used two types of CNNs (Conv-Small and Conv-Large) used in recent state-of-the-art semi-supervised learning methods ( <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>). 'Conv-Small CNN' has practically the same structure as the CNN used in <ref type="bibr" target="#b35">[36]</ref>, and 'Conv-Large CNN' has practically the same structure as the CNN used in <ref type="bibr" target="#b23">[24]</ref>. We provide more details of the architectures in <ref type="table">Table 7</ref> of Appendix D.</p><p>Also, in SVHN and CIFAR-10 experiments, we adopted conditional entropy of p(y|x, ?) as an additional cost:</p><formula xml:id="formula_20">R cent = H(Y |X) = ? 1 N l + N ul x?D l ,D ul y p(y|x, ?) log p(y|x, ?).<label>(18)</label></formula><p>This cost was introduced by <ref type="bibr" target="#b14">[15]</ref>, and similar idea has been used in <ref type="bibr" target="#b34">[35]</ref>. The conditional entropy minimization has an effect of exaggerating the prediction of the model p(y|x, ?) on each data point. For semi-supervised image classification tasks, this additional cost is especially helpful.</p><p>In what follows, 'VAT+EntMin' indicates the training with R vadv + R cent . <ref type="table" target="#tab_3">Table 4</ref> summarizes the results of semi-supervised learning tasks on SVHN and CIFAR-10. Our method achieved the test error rate of 14.82(%) with VAT, which outperformed the state-of-the-art methods for semi-supervised learning on CIFAR-10. 'VAT+EntMin' outperformed the state-of-the-art methods for semi-supervised learning on both SVHN and CIFAR-10.  <ref type="table" target="#tab_4">Table 5</ref> shows the performance of VAT and contemporary semi-supervised learning methods implemented with moderate image data augmentation (translation and horizontal flip). All methods other than VAT were implemented with the strong standing assumption on the unlabeled training samples that the label of the image does not change by the deformation. On CIFAR-10, VAT still outperformed the listed methods with this handicap. 'VAT+EntMin' with moderate data augmentation also outperformed the current state-of-the-art methods for semi-supervised learning on both SVHN and CIFAR-10. This result tells us that the effect of VAT does not overlap so much with that of the data augmentation methods, so that they can be used in combination to boost the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Effects of Perturbation Size and Regularization Coefficient ?</head><p>Generally, there is a high computational cost for optimizing the hyperparameters of large NNs on a large dataset. One advantage of VAT is that the algorithm involves only two hyperparameters: ? and . Even better, our experiments suggest that, in an appropriate setting, VAT can be made effective with the optimization of alone. In all our experiments in Section 4.1, VAT achieved competitive results while fixing ? = 1.</p><p>This result is not too counter-intuitive. For small , the hyperparameter ? plays a similar role as . To see this, consider the Taylor expansion of Eq.(5) for small , given </p><formula xml:id="formula_21">? } ? max r { 1 2 r T H(x, ?)r; r 2 ? } = 1 2 2 ? 1 (x, ?),<label>(19)</label></formula><p>where H(x, ?) and ? 1 (x, ?) are respectively the Hessian matrix of D in Eq.(9) and its dominant eigenvalue. Substituting this into the objective function (Eq. <ref type="formula" target="#formula_10">(8)</ref>), we obtain</p><formula xml:id="formula_22">(?, D l ) + ?R vadv (?, D l , D ul , ) = (?, D l ) + ? 1 N l + N ul x * ?D l ,D ul max r {D(r, x * , ?), r 2 ? } ? (?, D l ) + 1 2 ? 2 1 N l + N ul x * ?D l ,D ul ? 1 (x * , ?).<label>(20)</label></formula><p>Thus, at least for small , the strength of the regularization in VAT is proportional to the product of the two hyperparameters, ? and 2 ; that is, in the region of small , the hyperparameter search for only either or ? suffices. However, when we consider a relatively large value of , the hyperparameters ? and cannot be brought together.</p><p>In such a case, we shall strive to search for the best pair of hyperparameters that attains optimal performance. In our experiments on MNIST, tuning of alone sufficed for achieving satisfactory performance. We therefore recommend on empirical basis that the user prioritizes the parameter search for over the search for ?. <ref type="figure" target="#fig_3">Fig. 3</ref> shows the effects of and ? on the validation performance of supervised learning on MNIST. In <ref type="figure" target="#fig_3">Fig. 3a</ref>, we show the effect of with fixed ? = 1, and in <ref type="figure" target="#fig_3">Fig. 3b</ref> we show the effects of ? with different fixed values of in the range {1.0, 2.0, 3.0}. During the parameter search for supervised learning on MNIST, the algorithm performed optimally when ? = 1. Based on this result, we fixed ? = 1 while searching for optimal in all benchmark experiments, including both supervised learning on MNIST and CIFAR-10, as well as unsupervised learning on MNIST, CIFAR-10, and SVHN. As we showed in Section 4.1, this simple tuning   of was sufficient for good performance of VAT, and it even achieved state-of-the-art performance for several tasks. <ref type="figure" target="#fig_4">Fig. 4</ref> shows the R vadv values of the models trained with different K (the number of the power iterations) for supervised learning on MNIST and semi-supervised learning on CIFAR-10. We can observe a significant increase in the value of R vadv over the transition from K = 0 (random perturbations) to K = 1 (virtual adversarial perturbations). We can also observe that the value saturates at K = 1. The fact that one power iteration sufficed for good performance tells that the ratio ? 1 /? 2 for our experimental settings was very large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Effect of the Number of the Power Iterations K</head><p>In fact, we could not achieve notable improvement in performance by increasing the value of K. <ref type="table" target="#tab_5">Table 6</ref> shows the test accuracies for the semi-supervised learning task on CIFAR10 with different values of K. We however shall note that there is no guarantee that the spectrum of Hessian is always skew. Depending on the dataset and the model, K = 1 might not be sufficient. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Visualization of Virtual Adversarial Examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Virtual Adversarial Examples Produced by the Model</head><p>Trained with Different Choices of One might be interested in the actual visual appearance of the virtual adversarial examples with an appropriate size of that improves the regularization performance. In <ref type="figure">Fig. 5</ref>, we aligned (I) the transition of the performance of VAT on SVHN and CIFAR-10 with respect to along (II) the actual virtual adversarial examples that the models trained with corresponding generated at the end of its training. For small (designated as (1) in the <ref type="figure">figure)</ref>, it is difficult for human eyes to distinguish the virtual adversarial examples from the clean images. The size of that achieved the best validation performance is designated by <ref type="bibr" target="#b1">(2)</ref>. Especially for CIFAR-10, the virtual adversarial examples with of size <ref type="formula" target="#formula_2">(2)</ref> are on the verge of total corruption. For a larger value of (designated by (3) in the figure), we can clearly observe the effect of over-regularization. In fact, the virtual adversarial examples generated by the models trained with this range of are very far from the clean image, and we observe that the algorithm implemented with this large an did the unnecessary work of smoothing the output distribution over the set of images that are "unnatural."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Robustness against Virtual Adversarial Examples after Training</head><p>We studied the nature of the robustness that can be attained by VAT. We trained CNNs on CIFAR-10 with and without VAT and prepared a set of pairs of virtual adversarial examples generated from the same picture, each consisting of (1) the virtual adversarial example generated by the model trained with VAT (w/ VAT) and (2) the virtual adversarial example generated by the model trained without VAT (wo/ VAT). We studied the rates of misidentification by the classifiers (w/VAT and wo/VAT) on these pairs of adversarial examples. <ref type="figure" target="#fig_7">Fig. 6</ref> shows the rates at which the two models (w/VAT and wo/VAT) misidentified the images corrupted by virtual adversarial perturbations of different magnitudes. the examples on which we wish the classifier to make no mistakes. We can clearly observe that the rate of misidentification made by the VAT-trained model for this range of is much lower than that of the model trained without VAT. Also note in the bottom panel that the model trained with VAT correctly identifies both the adversarial examples generated by itself and the adversarial examples generated by the model trained without VAT for this range of . Simultaneously, note that the model trained with VAT alters its decision on the images when the perturbation is too large. In contrast, the model trained without VAT is assigning the original labels to the over-perturbed images at much higher rate than the VAT-trained model, which is completely unnecessary, and is possibly even harmful in practice. Thus, we observe that the VAT-trained model behaves much more 'naturally' than the model trained without VAT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Experimental Assessment of the Difference between VAT and RPT</head><p>As we showed in the previous section, VAT outperforms RPT in many aspects. There are two possible reasons for the difference in performance. First, as mentioned in Section 3.4, the power iteration in VAT promotes a faster learning process by decreasing the variance of the derivative of the objective function. Second, smoothing the function in the direction in which the model is most sensitive seems to be much more effective in improving the generalization performance than smoothing the output distribution isotropically around the input. We discuss the extent to which these claims might be true. Let D M be the mini-batch of size M randomly extracted from D, and letR (K) (?; D M , r K ) be the approximation of R (K) (?, D) computed with the mini-batch D M and random perturbations r K generated by K-times power iterations. To quantify the magnitude of the variance of the stochastic gradient, we define the normalized standard deviation (SD) norm for the gradient ? ?R (K) (?; D M , r K ) of the regularization termR (K) (?; D M , r K ), which is given as the square root of the trace of its variance normalized by the L 2 norm of its expectation:</p><formula xml:id="formula_23">normalized SD norm ? trace Var D M ,r K ? ?R (K) (?; D M , r K ) E D M ,r K ? ?R (K) (?; D M , r K ) 2 ,<label>(21)</label></formula><p>where Var D M ,r K [?] and E D M ,r K [?] respectively represent the variance and expectation with respect to the randomly selected mini-batch D M and perturbation r K . <ref type="figure">Fig. 7</ref> shows the transition of the normalized SD norm during the VAT process of NNs for the supervised learning task on MNIST ( <ref type="figure">Fig. 7a</ref>) and the semi-supervised learning task on CIFAR-10 ( <ref type="figure">Fig. 7b</ref>) with K = 0 and K = 1 (i.e., RPT and VAT). We set M to be 100 and 128 on MNIST and CIFAR-10 respectively. From the figure, we can observe that the normalized SD norm for K = 1 is lower than that for K = 0 in most of the early stages of the training for both MNIST and CIFAR-10.</p><p>Meanwhile, for the instances on which the normalized SD norm of the gradient of RPT falls below that of VAT, the difference is subtle.</p><p>(1) ?=0.1</p><p>(2) ?=3.0 For MNIST, the normalized SD norm of RPT becomes as large as 3 times that of VAT. To understand how much the normalized SD norm affects the performance, we compared (1) VAT with ? = 1 against (2) RPT implemented with optimal ? and an additional procedure of sampling 9 = 3 2 random perturbations and using the average of the 9 gradients for each update. Note that the normalized SD norm of the gradient does not depend on ?. With this setting, the normalized SD norm of RPT is not greater than that of VAT at the beginning of the training <ref type="figure">(Fig. 8)</ref>.</p><p>Remarkably, even with optimal ? and increased S, the performance of RPT still falls behind that of VAT with ? = 1. Even with similar SD norm, the model trained with VAT is more robust against virtual adversarial perturbation than the model trained with RPT. This, in particular, means that we cannot explain the superiority of VAT over RPT by the reduction in the variance alone. All these results suggest that the superior performance of VAT owes much to the unique nature of its objective function. Intuition tells us that the "max" component in the objective function as opposed to "expectation" is working in favor of the performance. At any phase in the training, the model might lack isotropic smoothness around some sample input points; it is natural that, to fix this, we must endeavor to smooth the model in the direction in which the model is most sensitive; that is, we need to take the maximum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>The results of our experiments on the three benchmark datasets, MNIST, SVHN, and CIFAR-10 indicate that VAT is an effective method for both supervised and semisupervised learning. For the MNIST dataset, VAT outperformed recent popular methods other than ladder networks,   which are the current state-of-the-art method that uses special network structure. VAT also greatly outperformed the current state-of-the-art semi-supervised learning methods for SVHN and CIFAR-10.</p><p>The simplicity of our method is also worth reemphasizing. With our approximation of R vadv , VAT can avoid the internal optimization when choosing the adversarial direction and can be implemented with small computational cost. Additionally, VAT has only two hyperparameters ( and ?) and works sufficiently well on the benchmark dataset with the optimization of alone. To add even more, VAT is applicable to wide variety of models regardless of its architecture. Also, unlike generative model-based methods, VAT does not require the training of additional models other than the discriminative model (output distribution) itself. At the same time, in our comparative studies, we reconfirmed the effectiveness of generative model-based semi-supervised learning methods on several experimental settings <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>. Essentially, most generative model-based methods promote generalization performance by making the model robust against perturbations in the region of high p(x) values, the region over which we are likely to receive new input data points in the future. In principle, this is complementary to our method, which aims to isotropically smooth the output distribution p(y|x) over each observed input point without any explicit assumption on the input distribution p(x). Combination of these two ideas is a future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A SUPERVISED CLASSIFICATION FOR THE MNIST DATASET</head><p>The MNIST dataset consists of 28 ? 28 pixel images of handwritten digits and their corresponding labels. The input dimension is therefore 28 ? 28 = 784, and each label is one of the numerals from 0 to 9. The following list summarizes the ranges our hyper parameter search: All experiments were conducted with ? = 1 except when checking the effects of ? in Section 4.2. Training was conducted using mini-batch SGD based on ADAM <ref type="bibr" target="#b20">[21]</ref>. We chose the mini-batch size of 100 and used the default values of <ref type="bibr" target="#b20">[21]</ref> for the tunable parameters of ADAM. We trained the NNs with 60,000 parameter updates. For the base learning rate in validation, we selected the initial value of 0.002, and adopted the schedule of exponential decay with rate 0.9 per 600 updates. We repeated the experiments 10 times with different random seeds for the weight initialization and reported the mean and standard deviation of the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B SUPERVISED CLASSIFICATION FOR CIFAR-10 DATASET</head><p>The CIFAR-10 dataset consists of 32 ? 32 ? 3 pixel RGB images of categorized objects (cars, trucks, planes, animals, and humans). The number of training examples and test examples in the dataset are 50,000 and 10,000, respectively. We used 10,000 out of 50,000 training examples for validation and we applied ZCA whitening prior to the experiment. We also augmented the training dataset by applying random 2 ? 2 translation and random horizontal flip. We trained the Conv-Large model (See Table7) over 300 epochs with batch size 100. For training, we used ADAM with essentially the same learning rate schedule as the one used in <ref type="bibr" target="#b35">[36]</ref>. In particular, we set the initial learning rate of ADAM to be 0.003 and linearly decayed the rate over the last half of training. We repeated the experiments 3 times with different random seeds for the weight initialization and reported the mean and standard deviation of the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX C SEMI-SUPERVISED CLASSIFICATION FOR THE MNIST DATASET</head><p>For semi-supervised learning of MNIST, we used the same network as the network used for supervised learning; however, we added zero-mean Gaussian random noise with 0.5 standard deviation to the hidden variables during the training. This modification stabilized the training on semi-supervised learning with VAT. We experimented with two sizes of labeled training samples, N l ? {100, 1000}, and observed the effect of N l on the test error. We used the validation set of fixed size(1,000), and used all the training samples, excluding the validation set and labeled training samples, to train the NNs; that is, when N l = 100, the unlabeled training set N ul had the size of 60, 000 ? 100 ? 1, 000 = 58, 900.</p><p>We searched for the best hyperparameter from [0.05, 10.0]. All experiments were conducted with ? = 1 and K = 1. For the optimization method, we again used ADAM-based mini-batch SGD with the same hyperparameter values that we used in supervised setting. We note that the likelihood term can be computed from labeled data only.</p><p>We used two separate mini-batches at each step: one mini-batch of size 64 from labeled samples to compute the likelihood term, and another mini-batch of size 256 from both labeled and unlabeled samples to compute the regularization term. We trained the NNs over 100,000 parameter updates, and started to decay the learning rate of ADAM linearly after we 50,000-th update. We repeated the experiments 3 times with different random seeds for the weight initialization and for the selection of labeled samples. We reported the mean and standard deviation of the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX D SEMI-SUPERVISED CLASSIFICATION FOR THE SVHN AND CIFAR-10 DATASETS</head><p>The SVHN dataset consists of 32 ? 32 ? 3 pixel RGB images of house numbers and their corresponding labels (0-9). The number of training samples and test samples within the dataset are 73,257 and 26,032, respectively. We reserved a sample dataset of size 1,000 for validation. From the remainder, we selected sample dataset of size 1,000 as a labeled dataset in semisupervised training. Likewise in the supervised learning, we conducted ZCA preprocessing prior to the semi-supervised learning of CIFAR-10. We also augmented the training datasets with a random 2 ? 2 translation. For CIFAR-10 exclusively, we also applied random horizontal flip as well. For the labeled dataset, we used 4,000 samples randomly selected from the training dataset, from which we selected 1,000 samples for validation. We repeated the experiment three times with different choices of labeled and unlabeled datasets on both SVHN and CIFAR-10.</p><p>For each benchmark dataset, we decided on the value of the hyperparameter based on the validation set. We also used a mini-batch of size 32 for the calculation of the negative log-likelihood term and used a mini-batch of size 128 for the calculation of R vadv in Eq. <ref type="bibr" target="#b7">(8)</ref>. We trained each model with 48,000 updates. This corresponds to 84 epochs for SVHN 7: CNN models used in our experiments on CIFAR-10 and SVHN, based on <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b37">[38]</ref>. All the convolutional layers and fully connected layers are followed by batch normalization <ref type="bibr" target="#b18">[19]</ref> except the fully connected layer on CIFAR-10. The slopes of all lReLU <ref type="bibr" target="#b27">[28]</ref> functions in the networks are set to 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conv-Small on SVHN Conv-Small on CIFAR-10</head><p>Conv and 123 epochs for CIFAR-10. We used ADAM for the training. We set the initial learning rate of ADAM to 0.001 and linearly decayed the rate over the last 16,000 updates. The performance of CNN-Small and CNN-Large that we reported in Section 4.1.2 are all based on the trainings with data augmentation and the choices of that we described above.</p><p>On SVHN, we tested the performance of the algorithm with and without data augmentation, and used the same setting that we used in the validation experiments for both Conv-Small and Conv-Large. For CIFAR-10, however, the models did not seem to converge with 48,000 updates; so we reported the results with 200,000 updates. We repeated the experiments 3 times with different random seeds for the weight initialization and for the selection of labeled samples. We reported the mean and standard deviation of the results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Transition of the (a) classification error and (b) R vadv for supervised learning on MNIST. We set = 2.0 for the evaluation of R vadv for both the baseline and VAT. This is the value of with which the VAT-trained model achieved the best performance on the validation dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>?</head><label></label><figDesc>Validation error rate (%) (a) Effect of (? = 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>?</head><label></label><figDesc>Validation error rate (%) (b) Effect of ?.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Effect of and ? on the validation performance for supervised task on MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Effect of the number of the power iterations on R vadv for (a) supervised task on MNIST and (b) semi-supervised task on CIFAR-10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>The figure (A) in the middle panel shows the rates of misidentification made on the virtual adversarial examples generated by the model trained with VAT. The figure (B) shows the rates on the virtual adversarial examples generated by the model trained without VAT. The example pictures shown beneath the figures (A) and (B) are the adversarial examples generated from the set of images that were correctly identified by both the model trained with VAT and the model trained without VAT when fed without perturbation. As expected, the error rates increased monotonically with the intensity of corruption for both models. Overall, we recognize that the adversarial examples generated by both models are almost identical to the original image for human eyes when ? 10 ?1 . The adversarial examples around ? 10 0 are almost identifiable, but are so corrupted that any further corruption would make the image unidentifiable by human eyes. The virtual adversarial examples with this range of are therefore</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>10 Fig. 5 :</head><label>105</label><figDesc>Performance of VAT with different values of . The effect of on the performance of semi-supervised learning(I), together with the set of typical virtual adversarial examples generated by the model trained with VAT with the corresponding value of (II).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 :</head><label>6</label><figDesc>Robustness of the VAT-trained model against perturbed images. The upper panel shows the procedure for the evaluation of robustness. In step 1, we prepared two classifiers -one trained with VAT (M v ) and another trained without VAT (M 0 ) -and generated a virtual adversarial example from each classifier (Ex v and Ex 0 ). In step 2, we classified Ex v and Ex 0 by these two models, thereby yielding the total of four classification results. The middle panel (graph A and B) plots the rate of misidentification in these four classification tasks against the size of the perturbation ( ) used to generate the virtual adversarial examples (VAEs) in step 1. The left half of the bottom panel aligned with the graph (A) shows a set of Ex v generated with different values of , together with the classification results of M v and M 0 on the images. All Ex v listed here are images generated from a set of clean examples that were correctly identified by M v and M 0 . The right half of the bottom panel aligned with graph (B) shows the set of Ex 0 generated from the same clean images as Ex v with different values of . The label 'Yes' indicates that the model changed the label assignment when the perturbation was applied to the image (e.g. the model was deceived by the perturbation) The label 'No' indicates that the model maintained the label assignment on the perturbed image. Note that the model M v dominates the model M 0 in terms of classification performance on the images that appear almost indistinguishable from the clean image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 :Fig. 8 :</head><label>78</label><figDesc>Transition of the normalized SD norm of R (0) and R<ref type="bibr" target="#b0">(1)</ref> during VAT training of NNs for supervised learning on MNIST and semi-supervised learning on CIFAR-10.Test error rate(%) Update (a) Test error rate Learning curves of VAT implemented with ? = 1 and S = 1 and RPT implemented with optimal ?(= 7) and S = 9. The hyperparameter was set to 2.0 for both VAT and RPT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>?</head><label></label><figDesc>RPT: = [1.0, 50.0], ? adversarial training (with L ? norm constraint): = [0.05, 0.1], ? adversarial training (with L 2 norm constraint): = [0.05, 5.0], and ? VAT: = [0.05, 5.0].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 :</head><label>1</label><figDesc>Test performance of supervised learning methods on MNIST with 60,000 labeled examples in the permutation invariant setting. The top part cites the results provided by the original paper. The bottom part shows the performance achieved by our implementation.</figDesc><table><row><cell>Method</cell><cell>Test error rate(%)</cell></row><row><cell>SVM (Gaussian kernel)</cell><cell>1.40</cell></row><row><cell>Dropout [39]</cell><cell>1.05</cell></row><row><cell>Adversarial, L? norm constraint [14]</cell><cell>0.78</cell></row><row><cell>Ladder networks [33]</cell><cell>0.57 (?0.02)</cell></row><row><cell>Baseline (MLE)</cell><cell>1.11 (?0.06)</cell></row><row><cell>RPT</cell><cell>0.84 (?0.03)</cell></row><row><cell>Adversarial, L? norm constraint</cell><cell>0.79 (?0.03)</cell></row><row><cell>Adversarial, L 2 norm constraint</cell><cell>0.71 (?0.03)</cell></row><row><cell>VAT</cell><cell>0.64 (?0.05)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 2 :</head><label>2</label><figDesc>Test performance of supervised learning methods implemented with CNN on CIFAR-10 with 50,000 labeled examples. The top part cites the results provided by the original paper. The bottom part shows the performance achieved by our implementation.</figDesc><table><row><cell>Method</cell><cell>Test error rate(%)</cell></row><row><cell>Network in Network [26]</cell><cell>8.81</cell></row><row><cell>All-CNN [38]</cell><cell>7.25</cell></row><row><cell>Deeply Supervised Net [25]</cell><cell>7.97</cell></row><row><cell>Highway Network [40]</cell><cell>7.72</cell></row><row><cell>ResNet (1001 layers) [17]</cell><cell>4.62 (?0.20)</cell></row><row><cell>DenseNet (190 layers) [18]</cell><cell>3.46</cell></row><row><cell>Baseline (only with dropout)</cell><cell>6.67 (?0.07)</cell></row><row><cell>RPT</cell><cell>6.30 (?0.04)</cell></row><row><cell>VAT</cell><cell>5.81 (?0.02)</cell></row><row><cell cols="2">4.1.2 Semi-Supervised Learning on MNIST, SVHN, and</cell></row><row><cell>CIFAR-10</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 3 :</head><label>3</label><figDesc>Test performance of semi-supervised learning methods on MNIST with the permutation invariant setting. The value N l stands for the number of labeled examples in the training set. The top part cites the results provided by the original paper. The bottom part shows the performance</figDesc><table><row><cell cols="3">achieved by our implementation. (PEA = Pseudo Ensembles</cell></row><row><cell cols="3">Agreement, DGM = Deep Generative Models, FM=feature</cell></row><row><cell>matching)</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="2">Test error rate(%) N l = 100 N l = 1000</cell></row><row><cell>TSVM [8]</cell><cell>16.81</cell><cell>5.38</cell></row><row><cell>PEA [5]</cell><cell>5.21</cell><cell>2.87</cell></row><row><cell>DGM (M1+M2) [22]</cell><cell cols="2">3.33 (?0.14) 2.40 (?0.02)</cell></row><row><cell>CatGAN [37]</cell><cell cols="2">1.91 (?0.1) 1.73 (?0.18)</cell></row><row><cell>Skip DGM [27]</cell><cell>1.32 (?0.07)</cell><cell></cell></row><row><cell cols="3">Ladder networks [33] 1.06 (?0.37) 0.84 (?0.08)</cell></row><row><cell>Auxiliary DGM [27]</cell><cell>0.96 (?0.02)</cell><cell></cell></row><row><cell>GAN with FM [36]</cell><cell>0.93 (?0.07)</cell><cell></cell></row><row><cell>RPT</cell><cell cols="2">6.81 (?1.30) 1.58 (?0.54)</cell></row><row><cell>VAT</cell><cell cols="2">1.36 (?0.03) 1.27 (?0.11)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 4 :</head><label>4</label><figDesc>Test performance of semi-supervised learning methods on SVHN and CIFAR-10 without image data augmentation. The value N l stands for the number of labeled examples in the training set. The top part cites the results provided by the original paper. The middle and bottom parts show the performance achieved by our implementation. The asterisk(*) stands for the results on the permutation invariant setting. (DGM=Deep Generative Models,</figDesc><table><row><cell>FM=feature matching)</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Test error rate(%)</cell></row><row><cell>Method</cell><cell>SVHN</cell><cell>CIFAR-10</cell></row><row><cell></cell><cell>N l = 1000</cell><cell>N l = 4000</cell></row><row><cell>SWWAE [48]</cell><cell>23.56</cell><cell></cell></row><row><cell>*Skip DGM [27]</cell><cell>16.61 (?0.24)</cell><cell></cell></row><row><cell>*Auxiliary DGM [27]</cell><cell>22.86</cell><cell></cell></row><row><cell>Ladder networks, ? model [33]</cell><cell></cell><cell>20.40 (?0.47)</cell></row><row><cell>CatGAN [37]</cell><cell></cell><cell>19.58 (?0.58)</cell></row><row><cell>GAN with FM [36]</cell><cell cols="2">8.11 (?1.3) 18.63 (?2.32)</cell></row><row><cell>model [24]</cell><cell cols="2">5.43 (?0.25) 16.55 (?0.29)</cell></row><row><cell>(on Conv-Small used in [36])</cell><cell></cell><cell></cell></row><row><cell>RPT</cell><cell cols="2">8.41 (?0.24) 18.56 (?0.29)</cell></row><row><cell>VAT</cell><cell cols="2">6.83 (?0.24) 14.87 (?0.13)</cell></row><row><cell>(on Conv-Large used in [24])</cell><cell></cell><cell></cell></row><row><cell>VAT</cell><cell cols="2">5.77 (?0.32) 14.18 (?0.38)</cell></row><row><cell>VAT+EntMin</cell><cell>4.</cell><cell></cell></row></table><note>28 (?0.10) 13.15 (?0.21)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 5 :</head><label>5</label><figDesc>Test performance of semi-supervised learning methods on SVHN and CIFAR-10 with image data augmentation. The value N l stands for the number of labeled examples in the training set. The performance of all methods other than Sajjadi et al.<ref type="bibr" target="#b34">[35]</ref> are based on experiments with the moderate data augmentation of translation and flipping (see Appendix D for more detail). Sajjadi et al.<ref type="bibr" target="#b34">[35]</ref> used extensive image augmentation, which included rotations, stretching, and shearing operations. The top part cites the results provided by the original paper. The bottom part shows the performance achieved by our implementation.</figDesc><table><row><cell></cell><cell cols="2">Test error rate(%)</cell></row><row><cell>Method</cell><cell>SVHN</cell><cell>CIFAR-10</cell></row><row><cell></cell><cell>N l = 1000</cell><cell>N l = 4000</cell></row><row><cell>model [24].</cell><cell cols="2">4.82 (?0.17) 12.36 (?0.31)</cell></row><row><cell>Temporal ensembling [24]</cell><cell cols="2">4.42 (?0.16) 12.16 (?0.24)</cell></row><row><cell>Sajjadi et al. [35]</cell><cell></cell><cell>11.29 (?0.24)</cell></row><row><cell>(On Conv-Large used in [24])</cell><cell></cell><cell></cell></row><row><cell>VAT</cell><cell cols="2">5.42 (?0.22) 11.36 (?0.34)</cell></row><row><cell>VAT+EntMin</cell><cell cols="2">3.86 (?0.11) 10.55 (?0.05)</cell></row><row><cell>by</cell><cell></cell><cell></cell></row><row><cell>max</cell><cell></cell><cell></cell></row></table><note>r {D(r, x, ?); r 2</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 6 :</head><label>6</label><figDesc>The test accuracies of VAT for the semi-supervised learning task on CIFAR10 with different values of K (the number of the power iterations).</figDesc><table><row><cell></cell><cell>Test error rate(%)</cell></row><row><cell></cell><cell>CIFAR-10</cell></row><row><cell></cell><cell>N l = 4000</cell></row><row><cell>(On Conv-Large)</cell><cell></cell></row><row><cell>VAT, K = 1</cell><cell>14.18 (?0.38)</cell></row><row><cell>VAT, K = 2</cell><cell>14.19 (?0.16)</cell></row><row><cell>VAT, K = 4</cell><cell>14.25 (?0.18)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This study was supported by the New Energy and Industrial Technology Development Organization (NEDO), Japan.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<title level="m">Large-scale machine learning on heterogeneous distributed systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Understanding regularization by virtual adversarial training, ladder networks and others</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mudassar</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jyri</forename><surname>Kivinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapani</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Information theory and an extension of the maximum likelihood principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirotugu</forename><surname>Akaike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Selected Papers of Hirotugu Akaike</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="199" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Vladimir Igorevich Arnol&apos;d. Mathematical methods of classical mechanics</title>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">60</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning with pseudo-ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ouais</forename><surname>Alsharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Training with noise is equivalent to Tikhonov regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="116" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Large scale transductive SVMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Sinz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1687" to="1712" />
			<date type="published" when="2006-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dropout as a Bayesian approximation: Representing model uncertainty in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Eigenvalue computation in the 20th century</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Golub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Henk A Van Der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vorst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="65" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<ptr target="http://www.deeplearningbook.org" />
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards deep neural network architectures robust to adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Rigazio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">What is the best multi-stage architecture for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deeply-supervised nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Yu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Network in network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Auxiliary deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Maal?e</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casper</forename><forename type="middle">Kaae</forename><surname>S?nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>S?ren Kaae S?nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Awni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shin-Ichi Maeda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.7003</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">A Bayesian encourages dropout. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distributional smoothing with virtual adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Shin-Ichi Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Nakae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted Boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on deep learning and unsupervised feature learning on NIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with ladder networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Honkala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapani</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Regularization using jittered training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seho</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Marks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNN. IEEE</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehran</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Improved techniques for training GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unsupervised and semi-supervised learning with categorical generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Striving for simplicity: The all convolutional net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Rupesh Kumar Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Highway networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Theano: A Python framework for fast computation of mathematical expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theano</forename><surname>Development Team</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.02688</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Solutions of ill-posed problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Andrej</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tikhonov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vasiliy Y Arsenin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<pubPlace>Winston</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Chainer: a next-generation open source framework for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiya</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenta</forename><surname>Oono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shohei</forename><surname>Hido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Clayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on machine learning systems (LearningSys) on NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dropout training as adaptive regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Wager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy S</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Spline models for observational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Wahba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<pubPlace>Siam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Algebraic geometry and statistical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumio</forename><surname>Watanabe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Stacked what-where auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning from labeled and unlabeled data with label propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
