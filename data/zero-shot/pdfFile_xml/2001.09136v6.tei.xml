<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NO ROUTING NEEDED BETWEEN CAPSULES</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Byerly</surname></persName>
							<email>abyerly@fsmail.bradley.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Kalganova</surname></persName>
							<email>tatiana.kalganova@brunel.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Dear</surname></persName>
							<email>ian.dear@brunel.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electronic and Electrical Engineering</orgName>
								<orgName type="department" key="dep2">Department of Computer Science and Information Systems</orgName>
								<orgName type="institution">Brunel University London Uxbridge</orgName>
								<address>
									<postCode>UB8 3PH</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Bradley University Peoria</orgName>
								<address>
									<postCode>61615</postCode>
									<region>Il</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Electronic and Electrical Engineering</orgName>
								<orgName type="institution">Brunel University London Uxbridge</orgName>
								<address>
									<postCode>UB8 3PH</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Electronic and Electrical Engineering</orgName>
								<orgName type="institution">Brunel University London Uxbridge</orgName>
								<address>
									<postCode>UB8 3PH</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">NO ROUTING NEEDED BETWEEN CAPSULES</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Capsules</term>
					<term>Convolutional Neural Network (CNN)</term>
					<term>Homogeneous Vector Capsules (HVCs)</term>
					<term>MNIST</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most capsule network designs rely on traditional matrix multiplication between capsule layers and computationally expensive routing mechanisms to deal with the capsule dimensional entanglement that the matrix multiplication introduces. By using Homogeneous Vector Capsules (HVCs), which use element-wise multiplication rather than matrix multiplication, the dimensions of the capsules remain unentangled. In this work, we study HVCs as applied to the highly structured MNIST dataset in order to produce a direct comparison to the capsule research direction of Geoffrey Hinton, et al. In our study, we show that a simple convolutional neural network using HVCs performs as well as the prior best performing capsule network on MNIST using 5.5? fewer parameters, 4? fewer training epochs, no reconstruction sub-network, and requiring no routing mechanism. The addition of multiple classification branches to the network establishes a new state of the art for the MNIST dataset with an accuracy of 99.87% for an ensemble of these models, as well as establishing a new state of the art for a single model (99.83% accurate).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Related Work</head><p>Capsules (vector-valued neurons) have become a more active area of research since <ref type="bibr" target="#b0">[1]</ref>, which demonstrated near state of the art performance on MNIST <ref type="bibr" target="#b1">[2]</ref> classification (at 99.75%) by using capsules and a routing algorithm to determine which capsules in a previous layer feed capsules in the subsequent layer. MNIST is a classic image classification dataset of hand-written digits consisting of 60,000 training images and 10,000 validation images. Studying MNIST, due to the more highly structured content as compared to many other image datasets, allows for the use of more informed data augmentation techniques and, when using capsules, the ability to investigate the capsules' interpretability. In <ref type="bibr" target="#b2">[3]</ref>, the authors extended their work by conducting experiments with an alternate routing algorithm. Research in capsules has since focused mostly on various computationally expensive routing algorithms <ref type="bibr">([4]</ref> <ref type="bibr" target="#b4">[5]</ref>). In <ref type="bibr" target="#b5">[6]</ref>, we proposed a capsule design that used element-wise multiplication between capsules in subsequent layers and relied on backpropagation to do the work that prior capsule designs were relying on routing mechanisms for. We referred to this capsule design as homogeneous vector capsules (HVCs). In this work, we directly extend the work of <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b0">[1]</ref> on capsules applied to MNIST by applying HVCs to MNIST. By using this capsule design, we avoid the the computationally expensive arXiv:2001.09136v6 [cs.CV] 17 Jun 2021</p><p>No Routing Needed Between Capsules routing mechanisms of prior capsule work and we surpass the performance of <ref type="bibr" target="#b0">[1]</ref> on MNIST, all while requiring 5.5? fewer parameters, 4? fewer epochs of training, and using no reconstruction sub-network.</p><p>Many of the best performing convolutional neural networks (CNNs) of the past several years have explored multiple paths from input to classification <ref type="bibr" target="#b7">[8]</ref> <ref type="bibr" target="#b8">[9]</ref>[10] <ref type="bibr" target="#b10">[11]</ref> <ref type="bibr" target="#b11">[12]</ref> <ref type="bibr" target="#b12">[13]</ref>. The idea behind multiple path designs is to enable one or more of the following to contribute to the final classification: (a) different levels of abstraction, (b) different effective receptive fields, and (c) valuable information learned early to flow more easily to the classification stage.</p><p>In <ref type="bibr" target="#b9">[10]</ref> (and subsequent extensions <ref type="bibr" target="#b13">[14]</ref>[15] <ref type="bibr" target="#b15">[16]</ref> <ref type="bibr" target="#b16">[17]</ref>) the authors added extra paths through the network with residual blocks which are meta-layers that contained one or more convolutional operations as well as a "skip connection" that allowed information learned earlier in the network to skip over the convolutional operations. Similarly, in <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b8">[9]</ref>, the authors presented a network architecture that made heavy use of inception blocks, which are meta-layers that branch from a previous layer into anywhere from 3 to 6 branches of varying layers of convolutions. Then the branches were merged back together by concatenating the filters of those branches. Let n be the average number of branches of different length (in terms of successive convolutions) and m be the number of successive inception blocks. Then n ? m effective receptive fields and levels of abstraction are present at the output of the final inception block. Additionally, the designs presented in both of these papers included two output stems (one branching out before going through additional inception blocks and the other after all inception blocks) each producing classification predictions. These classifications were combined via static weighting to produce the final prediction. In contrast to the aforementioned work, in this work, we present a network design that produces 3 output stems, each coming after a different number of convolutions, and thus representing different effective receptive fields and levels of abstraction. We conduct experiments that include statically weighted combinations as in <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b8">[9]</ref>. We then go further and investigate learning the branch weights simultaneously with all of the other network parameters via backpropagation. Again, in contrast to the aforementioned work, in these experiments, each of the separate classifications were performed with capsules rather than simple fully connected layers.</p><p>Our analysis of the existing literature shows that of the many branching methods explored, those that produced multiple final classifications merged those classifications via static weighting, which presupposes the relative importance of each output. In this work we include and compare the results of both statically weighting the classification branches and learning the weights of the classification branches via backpropagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Our Contribution</head><p>Our contribution is as follows:</p><p>1. We present a novel method for branching a CNN that allows for multiple effective receptive fields and levels of abstraction where each branch makes it's own classification prediction. These classifications are then merged together, each contributing a "vote". We present the results of experiments that include and compare both statically weighting the votes and learning the weights of the votes via backpropagation simultaneously with the rest of the network parameters. 2. We do classification without any fully connected layers, but rather with HVCs. HVCs are simpler, less computationally expensive, and our network design requires 5.5? fewer parameters and 4? fewer training epochs compared to the previously best performing capsule network, all while using no reconstruction sub-network and no computationally expensive routing mechanism. 3. This design, in combination with a domain-specific set of randomly applied augmentation techniques, establishes a new state of the art for the MNIST dataset with an accuracy of 99.87% for an ensemble of these models, as well as establishing a new state of the art for a single model (99.83% accurate).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Network Design</head><p>The starting point for the network design was a conventional convolutional neural network following many widely used practices. These include stacked 3 ? 3 convolutions, each of which with ReLU <ref type="bibr" target="#b17">[18]</ref> activation preceded by batch normalization <ref type="bibr" target="#b18">[19]</ref>. We also followed the common practice of increasing the number of filters in each subsequent convolutional operation relative to the previous one. Specifically, our first convolution uses 32 filters and each subsequent convolution uses 16 more filters than the previous one. Additionally, the final operation before classification was to softmax the logits and to use categorical cross entropy for calculating loss.</p><p>One common design element found in many convolutional neural networks which we intentionally avoided was the use of any pooling operations. We agree with Geoffrey Hinton's assessment <ref type="bibr" target="#b19">[20]</ref> of pooling (a method of down-sampling) as an operation to be avoided due to the information it "throws away". With the MNIST data being only 28 ? 28, we have no need to down-sample. In choosing not to down-sample, we face the potential dilemma of how to reduce the dimensionality as we descend deeper into the network. This dilemma is solved by choosing not to zero-pad the convolution operations and thus each convolution operation by its nature reduces the dimensionality by 2 in both the horizontal and vertical dimensions. We deem choosing not to zero-pad as preferable in its own right in that zero padding effectively adds information not present in the original sample.</p><p>Rather than having a single monolithic design such that each operation in our network feeds into the next operation and only the next operation, we chose to create multiple branches. After the first two sets of three convolutions, in addition to feeding to the subsequent convolution, we also branched off the output to be forwarded on to an additional operation (detailed next). Thus, after all convolutions have been performed, we have three branches in our network.</p><p>1) The first of which has been through three 3 ? 3 convolutions and consists of 64 filters each having an effective receptive field of 7 of the original image pixels.</p><p>2) The second of which has been through six 3 ? 3 convolutions and consists of 112 filters each having an effective receptive field of 11 of the original image pixels.</p><p>3) The third of which has been through nine 3 ? 3 convolutions and consists of 160 filters each having an effective receptive field of 15 of the original image pixels.</p><p>For each branch, rather than flattening the outputs of the convolutions into scalar neurons, we instead transformed each filter into a vector to form the first capsule in a pair of homogeneous vector capsules. This operation is represented by "Caps 1(a)", "Caps 2(a)" and "Caps 3(a)" in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>We then performed element-wise multiplication of each of those capsules with a set of weight vectors (one for each class) of the same length. This results in ntimesm weight vectors where n is the number of capsules transformed from filter maps and m is the number of classes. We summed, per class (m), each of the n vectors to form the second capsule in each pair of homogeneous vector capsules. After this that we applied batch normalization and then ReLU activation. The process elucidated in this paragraph is represented by "Caps 1(b)", "Caps 2(b)" and "Caps 3(b)" in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>After the pairs of capsules for each breach, the second capsule vector in each pair is reduced to a single value per class by summing the components of the vector. These values can be thought of as the branch-level logits.</p><p>Before classifying, the three branch-level sets of logits need to be reconciled with the fact that each image only belongs to one class. This is accomplished by stacking each class's branch-level logits into vectors of length 3. Then, each vector is reduced by summation to a single value to form the final set of logits to be classified from. <ref type="figure" target="#fig_0">Figure 1</ref> shows the high-level view of the entire network. In <ref type="bibr" target="#b5">[6]</ref>, we experimented with a variety of methods for constructing the first layer of capsules out of the preceding filter maps. In this work, we limited our experiments to 2 of these methods (see <ref type="figure" target="#fig_1">Figure 2</ref>). The first method constructs each capsule from each distinct feature map (a method that, for brevity, we will refer to as XY-Derived Capsules in this work), whereas the second method constructs each capsule from each distinct x and y coordinate of the combination of all of the feature maps (a method that, for brevity, we will refer to as Z-Derived Capsules in this work).</p><p>(a) In this example, the 4 filter maps have been converted into four 9-dimensional capsules, each made from an entire feature map. The first 2 of 4 such capsules are highlighted in red and blue respectively. For the sake of brevity, we will refer to this throughout the remainder of this work as using XY-Derived Capsules.</p><p>(b) In this example, the 4 filter maps have been converted into a single 4dimensional capsule for each distinct x and y coordinate of the feature maps. The first 2 of 9 such capsules are highlighted in red and blue respectively. For the sake of brevity, we will refer to this throughout the remainder of this work as using Z-Derived Capsules. We used no weight decay regularization <ref type="bibr" target="#b20">[21]</ref>, a staple regularization method that improves generalization by penalizing the emergence of large weight values. Nor did we use any form of dropout regularization <ref type="bibr" target="#b21">[22]</ref>[23] which are regularization methods designed to stop the co-adaptation of weights. We also did not use a reconstruction sub-network as in <ref type="bibr" target="#b0">[1]</ref>. These decisions were made in order to investigate the generalization properties of our novel network design elements in the absence of other techniques associated with good generalization. In addition, we intentionally left out any form of "routing" algorithm as in <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b2">[3]</ref>, preferring to rely on traditional trainable weights and backpropagation.</p><p>3 Experimental Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Merge Strategies</head><p>In <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b8">[9]</ref>, the authors chose to give static, predetermined weights to both output branches and then added them together. In our case, for both capsules configurations from <ref type="figure" target="#fig_1">Figure 2</ref>, we conducted three separate experiments of 32 trials each in order to investigate the effects of predetermined equal weighting of the branch outputs compared to learning the branch weights via backpropagation:</p><p>1) Not learnable. For this experiment, we merged the three branches together with equal weighting in order to investigate the effect of disallowing any one branch to have more impact than any other. 2) Learnable with randomly initialized branch weights. (Abbreviated as Random Init. subsequently.) For this experiment, we allowed randomly initialized weights to be learned via backpropagation. 3) Learnable with branch weights initialized to one. (Abbreviated as Ones Init. subsequently.) For this experiment, we also allowed the weights to be learned via backpropagation. The difference with the Random Init. experiment being that we initialized the weights to 1. We conducted this experiment in addition to the Random Init. experiment in order to understand the difference between starting with random weights and starting with equal weights that are subsequently allowed to diverge during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Augmentation</head><p>Most (but not all <ref type="bibr" target="#b23">[24]</ref>[25]) of the state of the art MNIST results achieved over the past decade have used data augmentation <ref type="bibr" target="#b25">[26]</ref>[23] <ref type="bibr" target="#b12">[13]</ref>. In addition to the network design, a major part of our work involved applying an effective data augmentation strategy that included transformations informed specifically by the domain of the data. For example, we wanted to be sure we did not rotate our images into being more like a different class (e.g. rotating an image of the digit 2 by 180 degrees to create something that would more closely resemble a malformed 5). Nor did we want to translate the image content off of the canvas and perhaps cut off the left side of an 8 and thus create a 3. Choosing data augmentation techniques specific to the domain of interest is not without precedent (see for example <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b0">[1]</ref>, both of which used data augmentation techniques specific to MNIST).</p><p>By modern standards, in terms of dataset size, MNIST has a relatively low number of training images. As such, judicious use of appropriate data augmentation techniques is important for achieving a high level of generalizability in a given model. In terms of structure, hand-written digits show a wide variety in their rotation relative to some shared true "north", position within the canvas, width relative to their height, and the connectedness of the strokes used to create them. Throughout training for all trials, every training image in every epoch was subjected to a series of four operations in order to simulate a greater variety of the values for these properties.</p><p>1) Rotation. First, we randomly rotated each training image by up to 30 degrees in either direction. Whether to actually apply this rotation was chosen by drawing from a Bernoulli distribution with probability p of 0.5 (a fair coin toss). 2) Translation. Second, we randomly translated each training image within the available margin present in that image. In <ref type="bibr" target="#b0">[1]</ref>, the authors limited their augmentation to shifting the training images randomly by up to 2 pixels in either or both directions. The limit of only 2 pixels for the translation ensured that the translation is label-preserving. As the MNIST training data has varying margins of non-digit space in the available 28 ? 28 pixel canvas, using more than 2 pixels randomly, would be to risk cutting off part of the digit and effectively changing the class of the image. For example, a 7 that was shifted too far left could become more appropriately classed as a 1, or an 8 or 9 shifted far enough down could be more appropriately classed as a zero. The highly structured nature of the MNIST training data allows for an algorithmic analysis of each image that will provide the translation range available for that specific image that will be guaranteed to be label-preserving. <ref type="figure" target="#fig_2">Figure 3</ref> shows an example of an MNIST training image that has an asymmetric translation range that, as long as any translations are performed such that the digit part of the image is not moved by more pixels than are present in the margin, will be label preserving. In other words, the specific training example shown in <ref type="figure" target="#fig_2">Figure 3</ref> could be shifted by up to 8 pixels to the left or 4 to the right and up to 5 up or 3 down, and after doing so, all of the pixels belonging to the actual digit will still be in the resulting translated image. The amount within this margin to actually translate a training image was chosen randomly. Whether to translate up or down and whether to translate left or right were drawn independently from a Bernoulli distribution with probability p of 0.5 (a fair coin toss). 3) Width. Third, we randomly adjusted each training image's width. MNIST images are normalized to be within a 20 ? 20 central patch of the 28 ? 28 canvas. This normalization is ratio-preserving, so all images are 20 pixels in the height dimension but vary in the number of pixels in the width dimension. This variance not only occurs across digits, but intra-class as well, as different peoples' handwriting can be thinner or wider than average. In order to train on a wider variety of these widths, we randomly compressed each image's width and then added equal zero padding on either side, leaving the digit's center where it was prior. This was inspired by a similar approach adopted in <ref type="bibr" target="#b12">[13]</ref>. In our work, we compressed the width of each sample randomly within a range of 0-25%. 4) Random Erasure. Fourth, we randomly erased (setting to 0) a 4 ? 4 grid of pixels chosen from the central 20 ? 20 grid of pixels in each training image. The X and Y coordinates of the patch were drawn independently from a random uniform distribution. This was inspired by the random erasing data augmentation method in <ref type="bibr" target="#b26">[27]</ref>. The intention behind this method was to expose the model to a greater variety of (simulated) connectedness within the strokes that make up the digits. An alternative interpretation would be to see this as a kind of feature-space dropout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>We followed the training methodology from <ref type="bibr" target="#b5">[6]</ref> and trained with the Adam optimizer <ref type="bibr" target="#b27">[28]</ref> using all of the default/recommended parameter values, including the base learning rate of 0.001. Also, as in both <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b0">[1]</ref>, we exponentially decayed the base learning rate. For our experiments, which trained for 300 epochs, we applied an exponential decay to the learning rate at a rate of 0.98 per epoch.</p><p>Test accuracy was measured using the exponential moving average of prior weights with a decay rate of 0.999. <ref type="bibr" target="#b28">[29]</ref> 4 Experimental Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Individual Models</head><p>For both of the capsule construction methods (see <ref type="figure" target="#fig_1">Figure 2</ref>) and each of the three merge strategies (see subsection 3.1) we ran 32 trials. Each trial had weights randomly initialized prior to training and, due to the stochastic nature of the data augmentation, a different set of training images. As a result, training progressed to different points in the loss surface resulting in a range of values for the top accuracies that were achieved on the test set. See <ref type="table" target="#tab_0">Table 1</ref>. In all cases, using the Z-Derived Capsules was superior to using the XY-Derived Capsules. For Z-Derived Capsules, no merge strategy produced statistically significantly superior test accuracy. For XY-Derived Capsules, the only statistically significant test accuracy result was that the Ones Init. strategy produced inferior accuracy. It should be noted that, though no strategy produced statistically significantly superior test accuracies, when branches were allowed to learn their weights, the weights learned were statistically significant. (Bold indicates a surpassing of the previous state of the art for individual models on MNIST.) (SD abbreviates Standard Deviation)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ensembles</head><p>Ensembling multiple models together and predicting based on the majority vote among the ensembled models routinely outperforms the individual models' performances. Ensembling can refer to either completely different model architectures with different weights or the same model architecture after being trained multiple times and finding different sets of weights that correspond to different locations in the loss surface. The previous state of the art of 99.82% was achieved using an ensemble of 30 different randomly generated model architectures <ref type="bibr" target="#b29">[30]</ref>. Our ensembling method used the same architecture but with different weights. We calculated the majority vote of the predictions for all possible combinations of the weights produced by the 32 trials. See <ref type="table" target="#tab_1">Table 2</ref>. Shown here are the number of ensembles that were generated that either matched the previous state of the art of 99.82% or exceeded it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Branch Weights</head><p>What follows are visualizations of the final branch weights (after 300 epochs of training) for each of the branches in all 32 trials of the experiment wherein the branch weights were initialized to one for both HVC configurations.</p><p>In <ref type="figure" target="#fig_3">Figure 4</ref>, we see that for all trials, the ratio between the all three learned branch weights is consistent, demonstrating that the amount of contribution from each branch plays a significant role. In <ref type="figure" target="#fig_4">Figure 5</ref>, we see a similar, though less pronounced consistency between the first branch's weight and the other two branches, however, branches two and three show no significant difference. Strikingly, when using XY-Derived Capsules we see that branch three (the one having gone through all nine convolutions) has learned to be a more significant contributor. When using Z-Derived Capsules, branch one (the one having gone through only three convolutions) has learned to be a more significant contributor, but only slightly. Indeed, in the latter configuration, the contributions from all three branches is much more equal.</p><p>The experiments with randomly initialized branch weights showed the same relative weight of the branches for the magnitude of the weights learned. However, when the initial random branch weight was a negative number, it learned the negative value of that magnitude, and backpropagation took care of flipping the signs of weights as needed further up the network.  Because the models using Z-Derived Capsules are clearly superior to XY-Derived Capsules, unless otherwise stated, all analyses throughout the remainder of this work will restrict attention to these 96 trials, and thus, when the text reads "all 96 trials", it should be understood that this refers to all 96 trials using Z-Derived Capsules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Troublesome Digits</head><p>Across all 96 trials there was total agreement on 9,912 out of the 10,000 test samples. There were only 14 digits that were misclassified more often than not across all 96 trials. This shows that although the accuracies of the models in the three experiments were quite similar, the different merge strategies of the three experiments did have a significant effect on classification. Across all 96 trials, only 5 samples were misclassified in all models. Those samples, as numbered by the order they appear in the MNIST test dataset (starting from 0) are 1901, 2130, 2597, 3422, and 6576. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">MNIST State of the Art</head><p>In <ref type="table" target="#tab_2">Table 3</ref> we present a comparison of previous state of the art MNIST results for both single model evaluations and ensembles along with the results achieved in our experiments. How long a model takes to train is an important factor to consider when evaluating a neural network. Indeed, it is an enabling factor during initial experimentation as faster training leads to a greater exploration of the design space. In <ref type="table" target="#tab_3">Table 4</ref> we present a comparison of the number of epochs of training used in experiments for the results achieved in the networks shown in <ref type="table" target="#tab_2">Table 3</ref>. Across all 96 trials, the design achieved peak accuracy in an average of 168 epochs, with a minimum peak achieved in 38 epochs and a maximum peak achieved at epoch 296. Since, all trials were allowed to run for up to 300 epochs, that is the number reported in <ref type="table" target="#tab_3">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Interpreting Capsules' Dimensions</head><p>By adding a reconstruction sub-network to the overall network, it can be trained not just to classify the input digits, but also to reconstruct them. Then, by following the method in <ref type="bibr" target="#b0">[1]</ref>, we can examine the effects of perturbing individual dimensions of the second set of capsules in a pair of HVCs. The experiments using Z-Derived Capsules had capsules with 64, 112, and 160 dimensions. When perturbing only one of that many dimensions the changes to the resulting constructed images are very subtle. So we ran another experiment with no branches, reconstruction, and using multiple 8-dimensional capsules for each distinct x and y coordinate of the feature maps. By perturbing one of only eight  <ref type="bibr" target="#b25">[26]</ref> 15,000 Multi-Column Deep Neural Networks for Image Classification <ref type="bibr" target="#b12">[13]</ref> 800 Regularization of Neural Networks using DropConnect <ref type="bibr" target="#b22">[23]</ref> 1,200 RMDL:Random Multimodel Deep Learning for Classification <ref type="bibr" target="#b29">[30]</ref> 120 The method proposed in this work 300</p><p>Neither <ref type="bibr" target="#b23">[24]</ref> nor <ref type="bibr" target="#b24">[25]</ref> report on how many epochs their designs were trained for.</p><p>dimensions the effects are more visible and allows us to interpret the meaning of values in the digits' capsules (see <ref type="table">Table 5</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Ablation Experiments</head><p>In each of the following set of experiments, we compared the first 10 trials of the 32 trials for the Ones Init. merge strategy with 10 trials each of the additional experiments.</p><p>In <ref type="bibr" target="#b0">[1]</ref>, the authors used a custom loss function they called margin loss combined with the mean squared error of the difference between the input images and the result of reconstructing them. In our work and with our design, we chose to rely solely on categorical cross-entropy and not to use a reconstruction loss, as reconstruction adds a considerable number of parameters to the model (2.1M). We ran two additional experiments to understand the effect of our choice of loss strategy (which used categorical cross-entropy and no reconstruction). The first used margin loss and reconstruction, and the second used categorical cross-entropy and reconstruction. There was no statistically significant difference among the three loss methods (see <ref type="table" target="#tab_5">Table 6</ref>). In order to understand the relative importance of using HVCs vs. a fully connected layer and 3 branches vs. a single branch, we ran a series of experiments that ablated these components of the architecture. <ref type="table" target="#tab_6">Table 7</ref> shows that HVCs are statistically significantly superior to a fully connected layer for both 1 and 3 branches, and shows that 3 branches are superior to 1 branch for both HVCs and a fully connected layer. In <ref type="bibr" target="#b0">[1]</ref>, the authors used translation, by a maximum of 2-pixels, as the only data augmentation method. In our work, we devised a method for translating by up to the full margin available in any given direction. We compared the effect of using only 2-pixel translation, only maximum margin translation, and our full suite of data augmentation methods.</p><p>Using the full suite of data augmentation methods was shown to be statistically superior to either of the other two methods. Much to our surprise, we found that the 2-pixel translation method just barely crossed the threshold of being statistically significantly superior to the full margin translation method (see <ref type="table" target="#tab_7">Table 8</ref>).</p><p>The result we obtained by when using 2-pixel translation as the only data augmentation strategy allows for a direct comparison to the work of <ref type="bibr" target="#b0">[1]</ref>. We obtained the same level of accuracy as they did, but using 5.5? fewer parameters, 4? fewer training epochs, no reconstruction sub-network, and requiring no routing mechanism. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Additional Datasets</head><p>In order to better understand the effect of the Z-Derived HVCs and additional branches, we ran additional sets of paired experiments for several additional datasets wherein the first set of experiments in a pair used the network design as described in this work and the second set of experiments excluded the Z-Derived HVCs and additional branches. These second sets of experiments thus use a very small and typical convolutional neural network with 9 3?3 convolutions and a final fully connected layer.</p><p>For MNIST and Fashion-MNIST we used the data augmentation strategy discussed in subsection 3.2. For CIFAR-10 and CIFAR-100, this data augmentation strategy is inappropriate, so we used a very typical strategy of randomly flipping the images horizontally and applying random adjustments to brightness, contrast, hue, and saturation.</p><p>For all four datasets, the model that included Z-Derived HVCs and 3 branches achieved the higher mean accuracy with statistical significance (see <ref type="table" target="#tab_8">Table 9</ref>).</p><p>The fact that the accuracies for Fashion-MNIST <ref type="bibr" target="#b30">[31]</ref>, CIFAR-10, and CIFAR-100 <ref type="bibr" target="#b31">[32]</ref> were not competitive with current state of the art for those datasets is not especially surprising for several reasons. First, our network was designed for optimal accuracy on classification of Arabic numerals which are highly structured and significantly simpler than the types of data in the other three datasets. Second, due to the significantly simpler nature of MNIST, we used a small number of parameters for our network (1.5M). For comparison, models competitive with state of the art for CIFAR-10 and CIFAR-100 use 10s and even 100s of millions of parameters. Finally, models competitive with state of the art for CIFAR-10 and CIFAR-100 use additional training data beyond the canonical set for each, and we used no additional training data.  <ref type="table" target="#tab_6">Table 7</ref> and are repeated here to facilitate ease of comparison. We conducted 10 trials of each unique type of experiment in order to establish statistical significance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we proposed using a simple convolutional neural network and established design principles as a basis for a network architecture. We then presented a design that branched out of the series of stacked convolutions at different points to capture different levels of abstraction and effective receptive fields, and from these branches, rather than flattening to individual scalar neurons, used Homogeneous Vector Capsules instead.</p><p>We also investigated three different methods of merging the output of the branches back into a single set of logits. Each of the three merge strategies generated models that could be ensembled to create new state of the art results.</p><p>Beyond the network architecture, we proposed a robust and domain specific data augmentation strategy aimed at simulating a wider variety of renderings of the digits.</p><p>In doing this work, we established new MNIST state of the art accuracies for both a single model and an ensemble. In addition to the network design and augmentation strategy, the ability to use an adaptive gradient descent method <ref type="bibr" target="#b5">[6]</ref> allowed us to achieve this on consumer hardware (2x NVIDIA GeForce GTX 1080 Tis in an otherwise unremarkable workstation) and was an enabling factor in both initial explorations and the training of all 322 trials of experiments referenced in this work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The proposed network from input to classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Illustrating the construction of capsules from 4 3?3 filter maps. These are the processes denoted by "Caps 1(a)", "Caps 2(a)", and "Caps 3(a)" inFigure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Example MNIST digit w/annotated margins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Final branch weights (after 300 epochs) for all 32 trials of the experiment using XY-Derived Capsules and for which the branch weights were initialized to one.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Final branch weights (after 300 epochs) for all 32 trials of the experiment using Z-Derived Capsules and for which the branch weights were initialized to one.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>The Most Troublesome Digits</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>5: Dimensional Perturbations Rightward tilt Top curl and height of lower loop Length of lower stroke Angle of the top part of one stroke Sharpness of the angle of the lower two curves Width of entire digit "Hook" in the initial part of the stroke Width of lower loop Lean angle Each row shows the reconstruction when one of the 8 dimensions in a digit's capsule is perturbed by intervals of 0.1 in the range [-0.5, 0.5].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">Test Accuracy of the Individual Models</cell><cell></cell><cell></cell><cell></cell></row><row><cell>HVC Configuration</cell><cell>Experiment</cell><cell>Min</cell><cell>Max</cell><cell>Mean</cell><cell>SD</cell></row><row><cell></cell><cell cols="5">Not Learnable 99.71% 99.79% 0.997500 0.0002190</cell></row><row><cell>Using XY-Derived Capsules</cell><cell>Random Init.</cell><cell cols="4">99.72% 99.78% 0.997512 0.0001499</cell></row><row><cell></cell><cell>Ones Init.</cell><cell cols="4">99.70% 99.77% 0.997397 0.0001885</cell></row><row><cell></cell><cell cols="5">Not Learnable 99.74% 99.81% 0.997731 0.0001825</cell></row><row><cell>Using Z-Derived Capsules</cell><cell>Random Init.</cell><cell cols="4">99.73% 99.80% 0.997684 0.0002023</cell></row><row><cell></cell><cell>Ones Init.</cell><cell cols="4">99.72% 99.83% 0.997747 0.0002509</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="3">Test Accuracy of the Ensembles</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">99.87% 99.86%</cell><cell>99.85%</cell><cell>99.84%</cell><cell>99.83%</cell><cell>99.82%</cell></row><row><cell>Using XY-Derived Capsules</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Not Learnable</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>4</cell><cell>1,183</cell></row><row><cell>Random Init.</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>21</cell><cell>2,069</cell></row><row><cell>Ones Init.</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>19</cell><cell>1,292</cell></row><row><cell>Using Z-Derived Capsules</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Not Learnable</cell><cell>184</cell><cell>4,029</cell><cell>89,384</cell><cell>1,587,152</cell><cell>17,746,467</cell><cell>121,731,146</cell></row><row><cell>Random Init.</cell><cell>0</cell><cell>1,226</cell><cell cols="3">533,318 17,319,668 148,600,238</cell><cell>554,104,195</cell></row><row><cell>Ones Init.</cell><cell>64</cell><cell cols="5">9,920 1,113,217 34,635,994 426,947,909 1,279,126,811</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Current and Previous MNIST State of the Art Results</figDesc><table><row><cell>Paper</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell>Epochs of Training</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Comparison of Loss Methods</figDesc><table><row><cell>Loss Method</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table><row><cell>Comparison of Network Structures</cell><cell></cell><cell></cell></row><row><cell>Network Structure</cell><cell>Mean Accuracy</cell><cell>SD</cell></row><row><cell>Using HVCs and 3 branches</cell><cell cols="2">99.7741% 0.000186455</cell></row><row><cell>Using HVCs and 1 branch</cell><cell cols="2">99.7140% 0.000185472</cell></row><row><cell>Using a fully connected layer and 3 branches</cell><cell cols="2">99.7550% 0.000111803</cell></row><row><cell>Using a fully connected layer and 1 branch</cell><cell cols="2">99.6870% 0.000141774</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Comparison of Data Augmentation Strategies</figDesc><table><row><cell>Data Augmentation Strategy</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 :</head><label>9</label><figDesc>Effects of Z-Derived HVCs and Branching on Additional Datasets Branches 64.15% 63.8260% 0.0026743 6.859 ? 10 ?6 A Fully Connected Layer and 1 Branch 62.96% 62.3760% 0.0035046 MNIST results come from the same experiments detailed in</figDesc><table><row><cell>Dataset</cell><cell>Network Architecture</cell><cell>Max</cell><cell>Mean</cell><cell>SD</cell><cell>p-value</cell></row><row><cell>MNIST</cell><cell>Z-Derived HVCs and 3 Branches A Fully Connected Layer and 1 Branch</cell><cell cols="4">99.81% 99.7741% 0.0001864 1.824 ? 10 ?7 99.71% 99.6870% 0.0001417</cell></row><row><cell>Fashion-MNIST</cell><cell>Z-Derived HVCs and 3 Branches A Fully Connected Layer and 1 Branch</cell><cell cols="4">93.89% 93.6850% 0.0016391 5.243 ? 10 ?6 93.36% 93.0410% 0.0014616</cell></row><row><cell>CIFAR-10</cell><cell>Z-Derived HVCs and 3 Branches A Fully Connected Layer and 1 Branch</cell><cell cols="3">89.23% 88.9290% 0.0015514 89.06% 88.7500% 0.0017515</cell><cell>0.020898</cell></row><row><cell>CIFAR-100</cell><cell>Z-Derived HVCs and 3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Digits Disagreed Upon</head><p>What follows is the complete set of 88 digits that were predicted correctly by at least one model and incorrectly by at least one model. These in combination with the digits from <ref type="figure">Figure 6</ref> represent the complete set of digits that were not predicted correctly by all 96 trials. Each image is captioned first by the class label in the test data set associated with the image, then the number of trials that predicted it correctly, and last the index of the digit in the test data. For example, the first image presented below has a class label of 3, 95 trials predicted that correctly, and it exists at index 87 in the MNIST test data. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dynamic Routing Between Capsules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Frosst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Conference on Neural Information Processing Systems</title>
		<meeting>the 31st Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">MNIST handwritten digit database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist" />
	</analytic>
	<monogr>
		<title level="m">ATT Labs</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Matrix Capsules with EM Routing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Frosst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Learning Representations (ICLR 2018)</title>
		<meeting>the 6th International Conference on Learning Representations (ICLR 2018)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Building Deep Equivariant Capsule Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sai Raam Venkataraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R. Raghunatha</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Path Capsule Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Amer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom?s</forename><surname>Maul</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11063-020-10273-0</idno>
		<idno>DOI: 10.1007/ s11063-020-10273-0</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="545" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Homogeneous Vector Capsules Enable Adaptive Gradient Descent in Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Byerly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Kalganova</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2021.3066842</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="48519" to="48530" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Transforming auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Geoffrey E Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida D</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-21735-7_6</idno>
	</analytic>
	<monogr>
		<title level="m">Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Going Deeper with Convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015)</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rethinking the Inception Architecture for Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015)</title>
		<imprint>
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015)</title>
		<imprint>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BBN: Bilateral-Branch Network With Cumulative Learning for Long-Tailed Visual Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR42600.2020.00974</idno>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 2020</title>
		<imprint>
			<biblScope unit="page" from="9716" to="9725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">CSPNet: A New Backbone that can Enhance Learning Capability of CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPRW50498.2020.00203</idno>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). 2020</title>
		<imprint>
			<biblScope unit="page" from="1571" to="1580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-Column Deep Neural Networks for Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">C</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ueli</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2012)</title>
		<imprint>
			<biblScope unit="page" from="3642" to="3649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Highway Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Rupesh Kumar Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>cs.LG</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Aggregated Residual Transformations for Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.634</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5987" to="5995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<publisher>CVPRW</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1175" to="1183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">ResNeSt: Split-Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<idno>ArXiv abs/2004.08955</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep Sparse Rectifier Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the 14th International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<publisher>AISTATS</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">What&apos;s wrong with convolutional nets? MIT Tech TV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="https://techtv.mit.edu/collections/bcs/videos/30698-what-s-wrong-with-convolutional-nets" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning translation invariant recognition in a massively parallel networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<idno>978-3-540- 47144-8</idno>
	</analytic>
	<monogr>
		<title level="m">PARLE Parallel Architectures and Languages Europe</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0580v1</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>cs.NE</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Regularization of Neural Networks using DropConnect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning</title>
		<meeting>the 30th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seyyed Hossein Hasanpour</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.06037</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>cs.CV</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Batch-Normalized Maxout Network in Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Ren</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong-Sheng</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02583</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>cs.CV</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">APAC: Augmented PAttern Classification with Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikuro</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Nishimura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kensuke</forename><surname>Yokoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.03229</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>cs.CV</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Random Erasing Data Augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04896</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs.CV</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Learning Representations</title>
		<meeting>the 6th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Averaging Weights Leads to Wider Optima and Better Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Conference on Uncertainty in Artificial Intelligence (UAI 2018)</title>
		<meeting>the 34th Conference on Uncertainty in Artificial Intelligence (UAI 2018)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">RMDL: Random Multimodel Deep Learning for Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamran</forename><surname>Kowsari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Information System and Data Mining (ICISDM 2018)</title>
		<meeting>the 2nd International Conference on Information System and Data Mining (ICISDM 2018)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs.LG</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">The code used for all experiments and summary level data is publicly available on</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<ptr target="https://github.com/AdamByerly/BMCNNwHFCs" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep</note>
	<note>Learning Multiple Layers of Features from Tiny Images</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
