<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Centrality and Consistency: Two-Stage Clean Samples Identification for Learning with Instance-Dependent Noisy Labels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganlong</forename><surname>Zhao</surname></persName>
							<email>zhaogl@connect.hku.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<postCode>510006</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Cardiff University</orgName>
								<address>
									<settlement>Cardiff</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Deepwise AI Lab</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Centrality and Consistency: Two-Stage Clean Samples Identification for Learning with Instance-Dependent Noisy Labels</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T17:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Instance-Dependent Noise</term>
					<term>Noisy Label</term>
					<term>Image Classifica- tion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2[0000?0002?1612?3641] , Guanbin Li 1?[0000?0002?4805?0926] , Yipeng Qin 3[0000?0002?1551?9126] , Feng Liu 4[0000?0002?4811?7828] , and Yizhou Yu 2 * [0000?0002?0470?5548]</p><p>Abstract. Deep models trained with noisy labels are prone to overfitting and struggle in generalization. Most existing solutions are based on an ideal assumption that the label noise is class-conditional, i.e. instances of the same class share the same noise model, and are independent of features. While in practice, the real-world noise patterns are usually more fine-grained as instance-dependent ones, which poses a big challenge, especially in the presence of inter-class imbalance. In this paper, we propose a two-stage clean samples identification method to address the aforementioned challenge. First, we employ a class-level feature clustering procedure for the early identification of clean samples that are near the class-wise prediction centers. Notably, we address the class imbalance problem by aggregating rare classes according to their prediction entropy. Second, for the remaining clean samples that are close to the ground truth class boundary (usually mixed with the samples with instance-dependent noises), we propose a novel consistency-based classification method that identifies them using the consistency of two classifier heads: the higher the consistency, the larger the probability that a sample is clean. Extensive experiments on several challenging benchmarks demonstrate the superior performance of our method against the stateof-the-art. Code is available at https://github.com/uitrbn/TSCSI_IDN.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep learning has shown transformative power in various real-world applications but is notoriously data-hungry <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b44">45]</ref>. There are some other alternatives which try to reduce the cost of human labor for data annotation, such as  crawling web images and using machine-generated labels. However, such data are usually noisy, which impedes the generalization of deep learning models due to over-fitting. Addressing the aforementioned issue, Learning with Noisy Labels (LNL) was proposed as a new topic and has attracted increasing attention in both academia and industry. Existing LNL methods mostly focus on the learning with classconditional noise (CCN), which aims to recover a noise transition matrix that contains class-dependent probabilities of a clean label flipping into a noisy label. However, CCN is too ideal for real-world LNL as it ignores the dependence of noise on the content of individual images, a.k.a. instance-dependent noise (IDN).</p><p>Unlike random noise or CCN that can be countered by collecting more (noisy) data <ref type="bibr" target="#b3">[4]</ref>, IDN has some important characteristic that makes it difficult to be tackled. First, classifiers can easily over-fit to the IDN because the noisy labels are dependent on sample features. As <ref type="figure" target="#fig_1">Fig. 1</ref> shows, mislabeled IDN samples (samples with the same shape but with different colors) share similar image features to their mislabeled classes, and thus tend to be distributed near the boundary between their ground truth class and the mislabeled class. As a result, the classifier can easily be confused and over-fits to IDN samples, leading to specious decision boundaries (red lines in <ref type="figure" target="#fig_1">Fig. 1</ref>). In addition, the challenge of IDN can be further amplified in the presence of inter-class imbalance and differences. Consider Clothing1M <ref type="bibr" target="#b37">[38]</ref>, an IDN dataset verified by <ref type="bibr" target="#b2">[3]</ref>, in which the noise is highly imbalanced and asymmetric. In Clothing1M, the IDN samples are unevenly distributed as the samples from similar classes (e.g. sweater and knitwear) can be extremely ambiguous, while those from other classes (e.g. shawl and underwear) are easily distinguishable. Such unevenly distributed IDN samples can be further amplified by the class imbalance problem, as there is no guarantee of a balanced dataset due to the absence of ground truth labels.</p><formula xml:id="formula_0">Shawl(92%), Knitwear(3%), Windbreaker(1%), ?? Sweater(11%), Knitwear(62%), T-Shirt(14%), ?? Vest(46%), Dress(27%), T-Shirt(9%), ?? ? ? ? ? ? ? ? ? ? Fig. 2:</formula><p>The transition matrix of Clothing1M copied from <ref type="bibr" target="#b37">[38]</ref>. The distribution of noisy labels are highly imbalanced. Some classes are almost clean (e.g. Shawl) while some classes has more mislabeled samples than correct labels (e.g. Sweater).</p><p>In this paper, we follow DivideMix <ref type="bibr" target="#b16">[17]</ref> that formulates LNL as a semisupervised learning problem and propose a novel two-stage method to identify clean versus noisy samples in the presence of IDN and the class imbalance problem. In the first stage, we employ a class-level feature-based clustering procedure to identify easily distinguishable clean samples according to their cosine similarity to the corresponding class-wise prediction centers. Specifically, we collect the normalized features of samples belonging to different classes respectively and calculate their class-wise centers located on a unit sphere. Then, we apply Gaussian Mixture Model (GMM) to binarily classify the samples according to their cosine similarity to their corresponding class centers and identify the ones closer to class centers as clean samples. Notably, we propose to augment the GMM classification by aggregating rare classes based on their prediction entropy, thereby alleviating the impact of the class imbalance problem. In the second stage, we propose a consistency-based classification method to identify the hard clean samples that are mixed with IDN samples around the ground truth class boundaries. Our key insight is that such clean samples can be identified by the prediction consistency of two classifiers. Compared to IDN samples, clean samples should produce more consistent predictions. Specifically, we incorporate two regularizers into the training: one applied to the feature extractor to encourage it to facilitate consistent outputs of the two classifiers; one applied to the two classifiers to enforce them generating inconsistent predictions. After training, we use another GMM to binarily classify the samples with smaller GMM means as clean samples. After identifying all clean samples, we feed them into the semi-supervised training as labeled samples, thereby implementing our learning with instance-dependent noisy labels. In summary, our contributions could be summarized as:</p><p>-We propose a method that delving into the instance-dependent noise, and design a class-level feature clustering procedure focusing on the imbalanced and IDN samples detection.</p><p>-We further propose to identify the hard clean samples around the ground truth class boundaries by measuring the prediction consistency between two in-dependently trained classifiers, and further improves the accuracy of clean versus noisy classification. -Our method achieves state-of-the-art performance in some challenging benchmarks, and is proved to be effective in different kinds of synthetic IDN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A large proportion of previous LNL methods focus on the class-conditional noise.</p><p>With the class-conditional noise assumption, some methods try to correct the loss function with the noise transition matrix <ref type="bibr" target="#b26">[27]</ref>, which can be estimated through exploiting a noisy dataset <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b46">47]</ref> or using a clean set of data <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b43">44]</ref>. Such loss correction methods based on noise transition matrix is infeasible for instancedependent noise, since the matrix is dataset dependent and the number of parameters grows proportionally with the size of training dataset. Some methods seek to correct the loss by reweighting the noisy samples or selecting the clean data <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b14">15]</ref>. A common solution is to treat the samples with smaller loss as clean data <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b12">13]</ref>. However, as pointed out by <ref type="bibr" target="#b2">[3]</ref>, instancedependent noise can be more easily over-fitted, and the memorization effect, which indicates that CNN-based models always tend to learn the general simple pattern before over-fitting to the noisy labels, becomes less significant when the model is trained with instance-dependent noise.</p><p>Some other methods combat the noisy label with other techniques. For example, Kim et al . <ref type="bibr" target="#b13">[14]</ref> combine positive learning with negative learning, which uses the complementary labels of noisy data for model training. Some methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b24">25]</ref> formulate LNL as a semi-supervised learning problem. DivideMix <ref type="bibr" target="#b16">[17]</ref> divides the dataset into clean and noisy sets, which serve as labeled and unlabeled data for semi-supervised learning. Some methods investigate the influence of augmentation strategy <ref type="bibr" target="#b25">[26]</ref> or enforce the prediction consistency between different augmentations <ref type="bibr" target="#b21">[22]</ref>. C2D <ref type="bibr" target="#b42">[43]</ref> utilizes self-supervised learning to facilitate the learning with noisy labels.</p><p>Chen et al . <ref type="bibr" target="#b4">[5]</ref> pointed out that for diagonally-dominant class-conditional noise, one can always obtain an approximately optimal classifier by training with a sufficient number of noisy samples. And it raise the significance of learning with IDN. There has been some works for this topic. CORES 2 <ref type="bibr" target="#b4">[5]</ref> try to progressively sieve out corrupted samples and avoid specifying noise rate. CAL <ref type="bibr" target="#b45">[46]</ref> propose a second-order approach with the assistance of additional second-order statistics. Besides, some research work also propose methods for IDN generation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b35">36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>The classification of noisy versus clean samples by the model outputs and their labels is a prevalent choice in the learning with noisy labels (LNL). Previous studies use the cross-entropy of noisy samples <ref type="bibr" target="#b16">[17]</ref> or confidence thresholds <ref type="bibr" target="#b39">[40]</ref> for noisy versus clean division. However, as Chen et al . <ref type="bibr" target="#b2">[3]</ref> point out, samples with instance-dependent noise (IDN) can be more easily over-fitted by neural networks, resulting in less reliable model outputs that confuse the classification of clean versus noisy samples. Such confusion is further amplified when the noisy dataset is imbalanced. For example, the differences between clean and noisy samples might be neglected for rare classes that contribute little to the overall prediction accuracy. Therefore, we propose a two-stage method which can effectively address IDN in the presence of class imbalance. In the first stage, we leverage a class-level feature-based clustering process to identify easily distinguishable clean samples that are close to their corresponding class centers in the feature space. Specifically, in this stage, we address the class imbalance by aggregating rare classes identified by their prediction entropy. In the second stage, we address the remaining clean samples, which are close to the ground truth class boundaries and are thus mixed with IDN samples. Our key insight is that such clean samples can be identified by the consistent predictions of two classifiers. Specifically, we propose a mini-max strategy for this consistency-based clean versus noisy classification: we simultaneously regularize the two classifiers to generate inconsistent predictions but enforce the feature extractor to facilitate the two classifiers to generate consistent predictions. After training, we identify the clean samples as the ones that lead to more consistent predictions between the two classifiers. After identifying all clean samples, we follow DivideMix <ref type="bibr" target="#b16">[17]</ref> and implement the learning with instance-dependent noisy labels as a semi-supervised learning problem that takes the clean samples as labeled samples, and the rest (noisy) samples as unlabeled samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Feature-based Clustering</head><p>As common practice, we divide a CNN-based classifier into two parts: a feature extractor F that takes images as input and extracts their features, and the following classifier G that outputs classification probabilities based on the image features extracted by F . Given a noisy dataset</p><formula xml:id="formula_1">{x i ,? i } N i=1 , where x i is an image sample and? i is its (noisy) label, we denotef i = fi ?fi? as the normalized feature of x i extracted by F , i.e. f i = F (x i ),? i = G(f i )</formula><p>as the predicted label of x i , and calculate the class-wise feature centers O c according to? i as:</p><formula xml:id="formula_2">O c = Nc i=1f i ? Nc i=1f i ? ,<label>(1)</label></formula><p>where c ? {1, 2, 3, ..., C} denotes the C classes, N c is the number of samples x i whose noisy label? i = c. Then, we can obtain the cosine similarity between each sample x i and its corresponding feature center O? i as:</p><formula xml:id="formula_3">S i =f i ? O? i .<label>(2)</label></formula><p>Finally, we apply class-wise Gaussian Mixture Model (GMM) to the similarities S i of samples for each class and performs binary classification. As the cosine similarity of noisy samples tend to be smaller, the component of GMM with a larger mean, i.e. larger similarity, is denoted as the clean set. Thus all the noisy samples is classified as clean or noisy as the preliminary result of first stage.</p><p>Entropy-based Aggregation of Rare Classes However, the performance of the proposed feature-based clustering can be unstable when the sizes of some classes are small and not sufficient for binary classification, which often happens in real-world datasets that have large numbers of classes. Addressing this issue, we propose to aggregate rare classes that struggle with the proposed binary classification. Specifically, we set a class aggregate threshold ? agg and calculate the average prediction entropy of the samples for each class c as:</p><formula xml:id="formula_4">Ent(c) = ? 1 N c Nc i=1 B j=1 p j i log p j i ,<label>(3)</label></formula><p>where N c is the number of samples for class c, B = 2 indicates the binary classification of clean versus noisy samples, p j i represents the output probability that a sample x i belongs to class j, i.e., clean and noisy probability. Samples of class c that satisfy Ent c &gt; ? agg are aggregated and treated as a single class to facilitate our feature-based clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Consistency-based Classification</head><p>As <ref type="figure" target="#fig_1">Fig 1 shows</ref>, challenging clean samples are usually near the ground truth class boundaries in the feature space, which can be identified by the consistency between two independently trained classifiers G 1 and G 2 that have different  <ref type="figure">Fig. 4</ref>: The procedure of the consistency-based classification. At the beginning, two classifiers has different prediction due to different initialization. Then the prediction consistency between two classifiers is minimized to identify the ambiguous noisy samples near the decision boundary. At the third steps, feature extractor is trained to maximize the consistency and the semi-supervised loss further revises both feature extractor and classifiers.</p><p>decision boundaries. Therefore, by replacing the classifier G with G 1 and G 2 in our network, we can get two corresponding predictions p 1 x and p 2 x of the same sample x. Then, we define and calculate the consistency between G 1 and G 2 on x as:</p><formula xml:id="formula_5">D(p 1 , p 2 ) = C i=1 |p 1 i ? p 2 i |,<label>(4)</label></formula><p>where x is omitted for simplicity and C is the number of classes, i.e. the dimension of p 1 x and p 2 x . We measure the discrepancy with L1 norm following <ref type="bibr" target="#b29">[30]</ref>. Consistency Minimization Regularization Although being independently trained, G 1 and G 2 share the same training dataset and the same loss function, leading to a non-negligible risk that the corresponding two predictions are identical or very similar. To minimize such a risk, we propose to incorporate a regularization loss on G 1 and G 2 that aims to minimize their consistency:</p><formula xml:id="formula_6">L min = ?? min N i=1 D * (p 1 xi , p 2 xi ),<label>(5)</label></formula><p>where N is the number of samples and ? min controls the strength,</p><formula xml:id="formula_7">D * (p 1 x , p 2 x ) = w Cx C i=1 |p 1 i ? p 2 i |,<label>(6)</label></formula><p>where x is omitted on the right side for simplicity and w Cx is the frequency of samples x's noisy category C x . w Cx is used to counter the class imbalance problem that often happens in real-world datasets. As the GMM model in the first stage does not guarantee the inter-class balance in the clean set, w Cx explicitly increases the weight of classes with more samples in consistency minimization and thus more samples are filtered out. Consistency Maximization Regularization Solely using the minimization regularization might impair the model performance because the consistency of samples with correct labels are also minimized, and ideally two classifiers should output the same prediction for each sample. Therefore, we propose to add a consistency maximization loss on the feature extractor F to constrain the network:</p><formula xml:id="formula_8">L max = ? max N i=1 D * (p 1 xi , p 2 xi ),<label>(7)</label></formula><p>where ? max controls the strength. Furthermore, the maximization of L max forces the feature extractor to separate the ambiguous features and thus complements semi-supervised training. As shown in the third step of <ref type="figure">Fig. 4</ref>, the feature extractor maximizes the consistency by pushing the samples with small consistency towards clean labeled data, and semi-supervised learning tries to gather the the feature of similar samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Training Procedure</head><p>Based on the discussions in Sec. 3.2 and Sec. 3.3, we propose to train our model by repeating the following four steps for each epoch.</p><p>Initialization Before training, we following <ref type="bibr" target="#b16">[17]</ref> and warm up our model including the two classifiers for several epochs with all noisy labels, where steps 1 and 2 belong to our feature-based clustering (Stage 1), and steps 3 and 4 belong to our consistency-based classification (Stage 2).</p><p>Step-1 We first extract the features of noisy data and calculate the class-wise feature centers according to Eq. 1. Then, we calculate the cosine similarities between features and the center of noisy labels of each sample using Eq. 2.</p><p>Step-2 We perform a binary (noisy vs. clean) classification to samples by applying class-wise Gaussian Mixture Model (GMM) according to the cosine similarities obtained in Step-1. We label the GMM component with a larger mean as "clean". Then, we select the samples with clean probabilities higher than a threshold ? as our primary clean set S 1 clean and the rest samples as the noisy set S 1 noisy .</p><p>Step-3 We first fix the feature extractor and train the two classifiers to minimize their consistency according to Eq. 5 for N max iterations using S 1 clean . Then, we evaluate the consistency of all samples in S 1 clean . Similar to Step-2, we apply a GMM model to the consistencies and select the samples with small mean as clean set S 2 clean . The rest samples are merged with S 1 noisy as S 2 noisy .</p><p>Step-4 With S 2 clean and S 2 noisy obtained as above, we optimize our model with a supervised loss on S 2 clean and a semi-supervised loss on S 2 noisy :</p><formula xml:id="formula_9">L = L X + ? U L U<label>(8)</label></formula><p>where S 2 clean and S 2 noisy are used as labeled set X and unlabeled set U respectively, and ? U balances the trade-off between L X and L U . In addition, we add <ref type="table">Table 1</ref>: Comparison of test accuracies (%) using different methods on CIFAR10 and CIFAR100 with part-dependent label noise. Results of other methods are copied from CAL <ref type="bibr" target="#b45">[46]</ref>. Our method outperforms all previous methods in all settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Inst. CIFAR10 </p><formula xml:id="formula_10">Inst. CIFAR100 ? = 0.2 ? = 0.4 ? = 0.6 ? = 0.2 ? = 0.4 ? = 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>In this section, we will validate the effectiveness of our method on several benchmark datasets with different kinds of IDNs (i.e. synthetic and real-world ones) and different numbers of classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>Synthetic IDN Datasets. Following previous studies on learning with IDN <ref type="bibr" target="#b45">[46]</ref>, our synthetic IDN datasets are created by adding two kinds of synthetic noise to CIFAR-10 and CIFAR-100 datasets <ref type="bibr" target="#b15">[16]</ref>, where CIFAR-10 contains 50,000 training images and 10,000 testing images from 10 different classes, CIFAR-100 contains 50,000 training images and 10,000 testing images from 100 classes. Specifically, we use two kinds of synthetic IDN in our experiment:</p><p>-Part-dependent label noise <ref type="bibr" target="#b35">[36]</ref>, which draws insights from human cognition that humans perceive instances by decomposing them into parts and estimates the IDN transition matrix of an instance as a combination of the transition matrices of different parts of the instance. -Classification-based label noise <ref type="bibr" target="#b2">[3]</ref>, which adds noise by i) collecting the predictions of each sample in every epoch during the training of a CNN classifier; ii) averaging the predictions and locate the class label with largest prediction probability other than the ground truth one for each instance as its noisy label; iii) flipping the labels of the samples whose largest probabilities falls in the top r% of all samples, where r is a user-defined hyper-parameter. 72.46 PTD-R-V <ref type="bibr" target="#b35">[36]</ref> 71.67 DivideMix <ref type="bibr" target="#b16">[17]</ref> 74.76 CORES 2 <ref type="bibr" target="#b5">[6]</ref> 73.24 CAL <ref type="bibr" target="#b45">[46]</ref> 74.17 Ours 75.40</p><p>Real-world IDN Datasets. Following <ref type="bibr" target="#b16">[17]</ref>, we use Clothing1M <ref type="bibr" target="#b37">[38]</ref> and Webvision 1.0 <ref type="bibr" target="#b17">[18]</ref> to evaluate our method:</p><p>-Clothing1M is a large scale dataset containing more than 1 million images of 14 kinds of clothes. As aforementioned, Clothing1M is highly imbalanced with its noise validated as IDN according to <ref type="bibr" target="#b2">[3]</ref>. In our experiments, we use its noisy training set which contains 1 million images and report the performance on test set. -Webvision is a large scale dataset which contains 2.4 million images from 1000 classes that are crawled from the web as ImageNet ILSVRC12 did. Following previous works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17]</ref>, we compare baseline methods on the first 50 classes of the Google image subset, and report the top-1 and top-5 performance on both Webvision validation set and ImageNet ILSVRC12.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We follow DivideMix <ref type="bibr" target="#b16">[17]</ref> and use MixMatch <ref type="bibr" target="#b0">[1]</ref> for semi-supervised learning. For experiments on CIFAR-10 and CIFAR-100, we use ResNet-34 <ref type="bibr" target="#b10">[11]</ref> as the feature extractor following <ref type="bibr" target="#b45">[46]</ref>. We use similar hyperparameters to <ref type="bibr" target="#b16">[17]</ref> across all 3 settings of CIFAR-10 and CIFAR-100 respectively. We train our model using a SGD optimizer with a momentum of 0.9 and a weight decay parameter of 0.0005. The learning rate is set as 0.02 in the first 150 epochs and reduced to 0.002 in the following 150 epochs. The warm up period is set as 10 epochs for CIFAR-10 and 15 epochs for CIFAR-100 respectively. For Clothing1M, we follow previous studies and use ImageNet pretrained ResNet-50 as the backbone. We train the model for 80 epochs. We set the learning rate as 0.002 in the beginning and reduce it to 0.0002 after 40 epochs of training. For Webvision 1.0, we follow <ref type="bibr" target="#b16">[17]</ref> and use the Inception-Resnet v2 <ref type="bibr" target="#b31">[32]</ref> as the backbone. We train the model for 120 epochs. We set the learning rate as 0.01 in the first 50 epoch and 0.001 for the rest of the training. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Results</head><p>CIFAR-10 and CIFAR-100 As aforementioned, we evaluate our method on two kinds of IDN as follows:</p><p>-Part-dependent label noise. To facilitate a fair comparison, we borrow the noise used in CAL <ref type="bibr" target="#b45">[46]</ref> and follow CAL to test the performance of our method against 6 different settings, whose noise ratios vary between 0.2 and 0.6. As <ref type="table">Table 1</ref> shows, our method outperforms previous methods in five in six settings, especially when the noise ratio and class number increase. For example, the improvement of CIFAR-100 with ? = 0.6 is over 10%. -Classification-based label noise. Following <ref type="bibr" target="#b2">[3]</ref>, we test our method against four different noise ratios, 10%, 20%, 30% and 40%. To facilitate a fair comparison, we borrow the same noise from SEAL <ref type="bibr" target="#b2">[3]</ref>. Note that compared to the aforementioned part-dependent label noise, the classification-based label noise used in this experiment is more challenging as it is generated by a CNN-based model. As <ref type="table" target="#tab_3">Table 3</ref> shows, our method still outperforms previous methods in all four different settings. Similar as above, the improvement of our method becomes higher as the noise ratio increases, which demonstrates the effectiveness of our method under different kinds of IDNs.</p><p>Clothing1M As aforementioned, Clothing1M contains over 1 million images from 14 classes collected from Internet, which makes it ideal to evaluate how different LNL methods perform against large-scale image datasets. As <ref type="table" target="#tab_2">Table 2</ref> shows, our method outperforms all previous methods and achieves the stateof-the-art performance. Compared to DivideMix <ref type="bibr" target="#b16">[17]</ref>, we further improve the accuracy by 0.64%.  Webvision and ImageNet ILSVRC12 As <ref type="table" target="#tab_4">Table 4</ref> shows, our method achieves better performance on both top-1 and top-5 accuracy on ILSVRC12 and Webvision. The higher improvement on ILSVRC12 suggests that our method is more robust to the domain difference and can generalize better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Study</head><p>We conduct an ablation study on the two stages of our method. Specifically, we provide the performance of our method on both CIFAR-100, a synthetic IDN dataset with noise ratio ? = 0.6 and Clothing1M, a highly-imbalanced dataset with real-world IDN. We also compare our method to standard CE baseline (i.e. neither stages are applied). As <ref type="table" target="#tab_5">Table 5</ref> shows, our method benefits from each stage in terms of the performance on both datasets, and achieves the best results when both stages are employed.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Performance against Class Imbalance</head><p>We select the highly-imbalanced Clothing1M to test the performance of our method against class imbalance. Specifically, we are concerned on the distribution (proportion of class-wise sample number w.r.t the whole dataset) changes of all 14 classes within our selected clean samples before and after our consistencybased classification. Since Clothing1M does not contain the ground truth labels for its noisy training set, we mix some samples from its validation set that contains both clean and noisy labels with the original noisy training set, and report the distributions of the validation samples. As <ref type="figure" target="#fig_3">Fig. 5</ref> shows, the percentages of most of the rare classes increase after our consistency-based classification, while the percentages of the rich classes decrease. In addition, we observed biggest changes occur in the rarest and richest classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">AUC of Noisy vs. Clean Classification</head><p>Given the prediction probabilities of stage 1 and stage 2, we calculate the area under curve (AUC) of our noisy vs. clean classification on CIFAR-10 with a noise ratio of 0.6. As <ref type="figure" target="#fig_4">Fig. 6</ref> shows, compared to the performance of random selection, both stages of our method can improve the AUC of classification, and the second stage further improve the AUC over the first stage. In addition, it can be observed that the accuracy of noisy vs. clean is improved as the training progresses. The performance decrease occurred around 150 epoch is due to a 0.1-fold decrease of the learning rate. Beside, we provide the probability distribution function of similarity and consistency in <ref type="figure" target="#fig_5">Fig. 7</ref>. Both metrics are effective in distinguishing clean and noisy samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose a two-stage method to address the problem of learning with instance-dependent noisy labels in the presence of inter-class imbalance problem. In the first stage, we identify "easy" clean samples that are close to the class-wise prediction centers using a class-level feature clustering procedure. We also address the class imbalance problem by augmenting the clustering with an entropy-based rare class aggregation technique. In the second stage, we further identify the remaining "difficult" clean samples that are close to the ground truth class boundary based on the consistency of two classifier heads. We conducted extensive experiments on several challenging benchmarks to demonstrate the effectiveness of the proposed method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>:</head><label></label><figDesc>Decision boundary of IDN : Ground truth class boundary : Samples with different ground truth : Samples with different IDN labels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>Example of IDN. The different shapes of the markers represent different ground truth classes. The different colors of the markers represent the noisy (IDN) labels. Different from random noise, IDN samples tend to be distributed near the ground truth class boundary, thus confusing the classifier and leading to over-fitted decision boundaries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>The overview of our proposed method. (a) The first stage. The noisy samples and labels are sent to the feature extractor for calculating the normalized features. The features are clustered with the prediction of samples. Noisy samples are divide to clean set and noisy set according to the cosine similarity between the feature and the center of its labels. (b) The model is train to minimize/maximize the prediction between two classifier heads and samples with smaller consistency are identified as noisy labels. (c) The clean/noisy set serve as labeled/unlabeled data for semi-supervised training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>The distributions of different classes in the validation set of Cloth-ing1M before and after the consistency-based classification (Stage 2). After our consistency-based classification, the distribution becomes more balanced. of noisy/clean classification(CIFAR-10, =0.6) After Stage 1 After Stage 2 Random Selection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 :</head><label>6</label><figDesc>The AUC of noisy vs. clean classification of our method. The second stage steadily improve the AUC of classification. The performance drop at 150 epoch is due to a learning rate change.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 :</head><label>7</label><figDesc>The probability distribution function of clean/noisy samples respectively for CIFAR-10 (?=0.6). The range of statistics is normalized to 0 to 1. (a) The similarity distribution of stage 1. (b) The (inverse) consistency distribution of stage 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Standard) 85.45?0.57 76.23?1.54 59.75?1.30 57.79?1.25 41.15?0.83 25.68?1.55 Forward T [27] 87.22?1.60 79.37?2.72 66.56?4.90 58.19?1.37 42.80?1.01 27.91?3.35 LDMI [39] 88.57?0.60 82.82?1.49 69.94?1.31 57.90?1.21 42.70?0.92 26.96?2.08 Lq [42] 85.81?0.83 74.66?1.12 60.76?3.08 57.03?0.27 39.81?1.18 24.87?2.46 Co-teaching [7] 88.87?0.24 73.00?1.24 62.51?1.98 43.30?0.39 23.21?0.57 12.58?0.51 Co-teaching+ [41] 89.80?0.28 73.78?1.39 59.22?6.34 41.71?0.78 24.45?0.71 12.58?0.51 JoCoR [34] 88.78?0.15 71.64?3.09 63.46?1.58 43.66?1.32 23.95?0.44 13.16?0.91 Reweight-R [37] 90.04?0.46 84.11?2.47 72.18?2.47 58.00?0.36 43.83?8.42 36.07?9.73 Peer Loss [20] 89.12?0.76 83.26?0.42 74.53?1.22 61.16?0.64 47.23?1.23 31.71?2.06 CORES 2 [6] 91.14?0.46 83.67?1.29 77.68?2.24 66.47?0.45 58.99?1.49 38.55?3.25 DivideMix[17] 93.33?0.14 95.07?0.11 85.50?0.71 79.04?0.21 76.08?0.35 46.72?1.32 CAL[46] 92.01?0.75 84.96?1.25 79.82?2.56 69.11?0.46 63.17?1.40 43.58?3.30 Ours 93.68?0.12 94.97?0.09 94.95?0.11 79.61?0.19 76.58?0.25 59.40?0.46</figDesc><table><row><cell>6</cell></row><row><cell>CE (</cell></row></table><note>additional consistency maximization regularization (Eq. 7) to the feature extrac- tor during training.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Classification accuracies on the (clean) test set of Clothing1M. Results of other method are copied from CAL<ref type="bibr" target="#b45">[46]</ref>. Our method achieves state-of-the-art performance.</figDesc><table><row><cell>Method</cell><cell>Accuracy</cell></row><row><cell cols="2">CE (standard) 68.94</cell></row><row><cell cols="2">Forward T [27] 70.83</cell></row><row><cell cols="2">Co-teaching [7] 69.21</cell></row><row><cell>JoCoR [34]</cell><cell>70.30</cell></row><row><cell>LDMI [39]</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Classification accuracies (%) on CIFAR-10 with classification-based label noise of different noise ratios. Our method outperforms all previous ones in all settings.</figDesc><table><row><cell>Method</cell><cell>10% 20% 30% 40%</cell></row><row><cell>CE</cell><cell>91.25 86.34 80.87 75.68 ?0.27 ?0.11 ?0.05 ?0.29</cell></row><row><cell>Forward[27]</cell><cell>91.06 86.35 78.87 71.12 ?0.02 ?0.11 ?2.66 ?0.47</cell></row><row><cell>Co-teaching[7]</cell><cell>91.22 87.28 84.33 78.72 ?0.25 ?0.20 ?0.17 ?0.47</cell></row><row><cell>GCE[42]</cell><cell>90.97 86.44 81.54 76.71 ?0.21 ?0.23 ?0.15 ?0.39</cell></row><row><cell>DAC[33]</cell><cell>90.94 86.16 80.88 74.80 ?0.09 ?0.13 ?0.46 ?0.32</cell></row><row><cell>DMI[39]</cell><cell>91.26 86.57 81.98 77.81 ?0.06 ?0.16 ?0.57 ?0.85</cell></row><row><cell>SEAL[3]</cell><cell>91.32 87.79 85.30 82.98 ?0.14 ?0.09 ?0.01 ?0.05</cell></row><row><cell>Ours</cell><cell>91.39 88.36 86.92 84.18 ?0.08 ?0.11 ?0.68 ?0.40</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Classification accuracies (%) on (mini) Webvision and ILSVRC12. Numbers denote top-1 (top-5) accuracy (%) on the WebVision and the ImageNet ILSVRC12 validation sets.</figDesc><table><row><cell>Method</cell><cell>WebVision ILSVRC12</cell></row><row><cell></cell><cell>top1 top5 top1 top5</cell></row><row><cell cols="2">F-correction [28] 61.12 82.68 57.36 82.36</cell></row><row><cell cols="2">Decoupling [24] 62.54 84.74 58.26 82.26</cell></row><row><cell>D2L [23]</cell><cell>62.68 84.00 57.80 81.36</cell></row><row><cell cols="2">MentorNet [13] 63.00 81.40 57.80 79.92</cell></row><row><cell cols="2">Co-teaching [8] 63.58 85.20 61.48 84.70</cell></row><row><cell cols="2">Iterative-CV [2] 65.24 85.34 61.60 84.98</cell></row><row><cell>DivideMix[17]</cell><cell>77.32 91.64 75.20 90.84</cell></row><row><cell>NGC[17]</cell><cell>79.16 91.84 74.44 91.04</cell></row><row><cell>Ours</cell><cell>79.36 93.64 76.08 93.86</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Ablation study on our Feature Clustering (Stage 1) and Consistency Classification (Stage 2). The models with neither stages are trained with crossentropy loss (i.e. CE baseline).</figDesc><table><row><cell>Dataset</cell><cell>Feature Clustering</cell><cell>Consistency Classification</cell><cell>Accuracy</cell></row><row><cell>CIFAR-100 (?=0.6)</cell><cell>?</cell><cell>?</cell><cell>25.68 53.60 51.41</cell></row><row><cell></cell><cell>?</cell><cell>?</cell><cell>59.40</cell></row><row><cell></cell><cell></cell><cell></cell><cell>68.94</cell></row><row><cell>Clothing1M</cell><cell>?</cell><cell></cell><cell>73.32</cell></row><row><cell></cell><cell></cell><cell>?</cell><cell>74.26</cell></row><row><cell></cell><cell>?</cell><cell>?</cell><cell>75.40</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported in part by the Guangdong Basic and Applied Ba- </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02249</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Understanding and utilizing deep neural networks trained with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1062" to="1070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.05458</idno>
		<title level="m">Beyond class-conditional assumption: A primary attempt to combat instance-dependent label noise</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.04193</idno>
		<title level="m">Robustness of accuracy metric and its inspirations in learning with noisy labels</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning with instancedependent label noise: A sample sieve approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02347</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning with instancedependent label noise: A sample sieve approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Coteaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8527" to="8537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8536" to="8546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Using trusted data to train deep networks on labels corrupted by severe noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05300</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Joint negative and positive learning for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9442" to="9451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Robust learning from untrusted sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Konstantinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3488" to="3498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dividemix: Learning with noisy labels as semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HJgExaVtwr" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<title level="m">Webvision database: Visual learning and understanding from web data</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Classification with noisy labels by importance reweighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="461" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Peer loss functions: Learning from noisy labels without knowing noise rates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning. ICML &apos;20</title>
		<meeting>the 37th International Conference on Machine Learning. ICML &apos;20</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12814</idno>
		<title level="m">Co-matching: Combating noisy labels by augmentation anchoring</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dimensionality-driven learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wijewickrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3355" to="3364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Decoupling &quot;when to update&quot; from &quot;how to update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Malach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="960" to="970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Mummadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P N</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beggel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01842</idno>
		<title level="m">Self: Learning to filter noisy labels with self-ensembling</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Augmentation strategies for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hollerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8022" to="8031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishna Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1944" to="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishna Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1944" to="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Maximum classifier discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3723" to="3732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning with bad training data via iterative trimmed loss minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sanghavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5739" to="5748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-first AAAI conference on artificial intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thulasidasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chennupati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mohd-Yusof</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10964</idno>
		<title level="m">Combating label noise in deep learning using abstention</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Combating noisy labels by agreement: A joint training method with co-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13726" to="13735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Extended t: Learning with mixed closed-set and open-set noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.00932</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Part-dependent label noise: Towards instance-dependent label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7597" to="7610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Are anchor points really indispensable in label-noise learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6838" to="6849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">L dmi: A novel information-theoretic loss function for training deep nets robust to label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6222" to="6233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Jo-src: A contrastive approach for combating noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="5192" to="5201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">How does disagreement help generalization against label corruption?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04215</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8778" to="8788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Contrast to divide: Self-supervised pre-training for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zheltonozhskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Litany</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.13646</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Meta label correction for noisy label learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 35th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Generalized radiograph representation learning via cross-supervision between images and free-text radiology reports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="32" to="40" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A second-order approach to learning with instancedependent label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10113" to="10123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.05291</idno>
		<title level="m">Clusterability as an alternative to anchor points when learning with noisy labels</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
