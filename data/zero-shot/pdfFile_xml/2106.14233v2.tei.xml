<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">KGREFINER: KNOWLEDGE GRAPH REFINEMENT FOR IMPROVING ACCURACY OF TRANSLATIONAL LINK PREDICTION METHODS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Javad</forename><surname>Saeedizade</surname></persName>
							<email>m_saeedizade@iust.ac.ir</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Engineering Data Mining Lab</orgName>
								<orgName type="institution">Iran University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Najmeh</forename><surname>Torabian</surname></persName>
							<email>najmeh.torabian@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Engineering Data Mining Lab</orgName>
								<orgName type="institution">Iran University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behrouz</forename><surname>Minaei-Bidgoli</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Engineering Data Mining Lab</orgName>
								<orgName type="institution">Iran University of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">KGREFINER: KNOWLEDGE GRAPH REFINEMENT FOR IMPROVING ACCURACY OF TRANSLATIONAL LINK PREDICTION METHODS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Link Prediction is the task of predicting missing relations between entities of the knowledge graph. Recent work in link prediction has attempted to provide a model for increasing link prediction accuracy by using more layers in neural network architecture. In this paper, we propose a novel method of refining the knowledge graph so that link prediction operation can be performed more accurately using relatively fast translational models. Translational link prediction models, such as TransE, TransH, TransD, have less complexity than deep learning approaches. Our method uses the hierarchy of relationships and entities in the knowledge graph to add the entity information as auxiliary nodes to the graph and connect them to the nodes which contain this information in their hierarchy. Our experiments show that our method can significantly increase the performance of translational link prediction methods in H@10, MR, MRR.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Knowledge graphs represent a set of interconnected descriptions of entities, including objects, events, or concepts. These graphs are structures by which knowledge is stored in triples. These triples include the three parts head, relation, and tail. The relation determines the type of relationship between head and tail. These graphs are becoming a popular approach to display and model different information in the world. Additionally, knowledge graphs have several applications, for example, question answering systems <ref type="bibr" target="#b3">(Bordes et al., 2014a;</ref><ref type="bibr">b)</ref>, recommendation systems <ref type="bibr" target="#b17">(Zhang et al., 2016)</ref>, search engines <ref type="bibr" target="#b16">(Xiong et al., 2017)</ref>, relationship extraction <ref type="bibr" target="#b10">(Mintz et al., 2009</ref>), etc.</p><p>Despite many efforts to build knowledge graphs, they are not complete yet. For example, in the Freebase <ref type="bibr" target="#b0">(Bollacker et al., 2008)</ref>, over 70% of people do not have their place of birth in the graph. This incompleteness of knowledge graphs has motivated researchers to add information to the graph and complete it.</p><p>One of the developing fields in completing the knowledge graph is knowledge graph embedding (KGE). The task of KGE is to embed entities and relationships in a small continuous vector space. One application of these embedding is to predict missing links in the knowledge graph.</p><p>Translational link prediction models use the sum of the head and relation vectors to predict the tail. These models started with TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref>, and after that, TransH <ref type="bibr" target="#b15">(Wang et al., 2014)</ref>, TransR <ref type="bibr" target="#b8">(Lin et al., 2015)</ref>, TransD <ref type="bibr" target="#b7">(Ji et al., 2015)</ref>, RotatE <ref type="bibr" target="#b14">(Sun et al., 2019)</ref>, etc., tried to improve it in the following years. The advantages of translational methods over deep learning techniques are that they are robust, and their score function is considerably faster. Therefore, in this work, we tried to improve these translational methods.</p><p>There is a lot of information in knowledge graphs. The hierarchy of entities and relationships is part of it. Paris, for example, its hierarchy is "entity ? physical entity ? object ? location ? region ? area ? center ? seat ? capital ? national capital". This hierarchy is not given enough attention in link prediction methods, and we intend to use this information in this paper. SACN <ref type="bibr" target="#b13">(Shang et al., 2019)</ref> added some nodes and relationships to the graph to use the graph structure information but did not justify adding these nodes and edges, so it is not generalizable for other graphs. In addition, SACN added this information only to FB15K237 and did not provide a method for WN18RR. In this paper, we added a much smaller number of relationships and fewer nodes to the graph training section by interpreting them. HRS <ref type="bibr" target="#b19">(Zhang et al., 2018)</ref> used relation clusters and sub-relations to use this information. Nevertheless, like SACN, this can not be generalized well.</p><p>The <ref type="bibr" target="#b11">(Moon et al., 2017)</ref> considered that if two entities are embedded closely in the embedding space, they are similar and assigned entities' classes based on closeness. Still, we assumed that if two entities use the same relation in the graph or have common elements in their hierarchies, they are related.</p><p>When link prediction models learned the relation between Paris and France, previous link prediction methods did not notice that Paris is a city and France is a country. To use this information, we added auxiliary nodes to the graph that included the classes of entities and connected them to related entities. For example, we added an extra node for countries to the knowledge graph and connected it to all the knowledge graph countries. Our contributions are as follows:</p><p>? We presented a method for refining the knowledge graph, which is independent of the structure of the link prediction model and adds triples to the knowledge graph. These triples increase the accuracy of link prediction with the same time and space complexity of translational models.</p><p>? We evaluated our proposed method on two FB15K237 and WN18RR datasets with successful translational models. The results showed that accuracy in link prediction was significantly increased on H@10, MRR, and MR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Knowledge graph embedding is an active and developing field to embed the entities and relations of the knowledge graph. These embeddings are used in link prediction, question answering systems, relation extraction, etc. Knowledge graph embedding starts with TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref>, which is the first translational link prediction method. It interprets relation as a transition from head entity to tail in the graph. Some drawbacks of the TransE model are its inability to model N-1, 1-N, and N-N relationships. In the following years, some other translational approaches, such as TransH <ref type="bibr" target="#b15">(Wang et al., 2014)</ref>, TransD <ref type="bibr" target="#b7">(Ji et al., 2015)</ref>, and TransR <ref type="bibr" target="#b8">(Lin et al., 2015)</ref>, were inspired by the initial idea of TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref> and tried to improve it. These translational models have much more speed against deep learning models such as ConvE <ref type="bibr" target="#b5">(Dettmers et al., 2018)</ref>, <ref type="bibr">ConvKB (Nguyen et al., 2018)</ref>, SACN <ref type="bibr" target="#b13">(Shang et al., 2019)</ref>, and HAKE <ref type="bibr" target="#b18">(Zhang et al., 2020)</ref>, but their accuracy is slightly lower than these models. Therefore, we proposed a method to increase the accuracy of these translational models. Knowledge graph refinement is a field of correcting or improving the knowledge graph. BioKG <ref type="bibr" target="#b20">(Zhao et al., 2020)</ref>, which worked on medical graphs, has tried to provide a method for removing the wrong information in these graphs. Other works in the refinement of the knowledge graphs try to add information. SACN <ref type="bibr" target="#b13">(Shang et al., 2019)</ref> has also added attributes to the knowledge graph, like our work. SACN proposed FB15k237 Attr; this method for constructing this dataset has three major issues. First, it only worked for FB15k237, but our proposed method can be applied on WN18RR as well. Second, it has brought the number of FB15k237 relations from 237 to 484; therefore, it has more time complexity than ours. However, we only proposed two new relations for FB15k237 and only one relation for WN18RR. Third, these new relations and entities are not interpretable in SACN; It does not provide a reason for adding these attributes. So it can not be generalized on other graphs. HRS <ref type="bibr" target="#b19">(Zhang et al., 2018)</ref> tried to use sub-relation and relation-cluster to make better predictions. It used the hierarchy of relations as a sub-relationship, and it created a relation cluster to use these as two additional parts of the transition in the translational models. Because links in Wordnet do not have information about entities, HRS sub-relation and relation-cluster on Wordnet are meaningless.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BACKGROUND</head><p>Suppose E as the collection of all entities of knowledge graph and R set of all its relationships. The (e s , r, e o ) is called a triple. The e s ? E is the head, and e o ? E is the tail of a triple. Finally, r ? E represents the relation between e s and e o .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">LINK PREDICTION</head><p>Link prediction is the task of predicting the missing link of a knowledge graph by inferring from existing facts on it. The score function of link prediction methods is ?(e o , r, e s ), which evaluates triple's accuracy. Our goal in teaching a model that has the highest estimation for the missing triplets of the graph and the lowest prediction for false triples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">TRANSLATIONAL LINK PREDICTION MODELS</head><p>Translational link prediction methods consider the relation as a transition from head to tail. For example (Paris, Capital of, France), the relation "Capital of" is a transition from Paris to France. TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref> is the first translational link prediction model. In TransE, embeddings for correct triples are learned as e s + r ? e o . It means that the sum of the head's embedding and relation's embedding must be close to the tail; primarily, the distance measure is the L2 norm. Here are some translational link predictions: </p><formula xml:id="formula_0">h ? = w ? r hw r , t ? = w ? r tw r ?(e o , r, e s ) = ?||h ? + r ? t ? || 2 2</formula><p>TransD <ref type="bibr" target="#b7">(Ji et al., 2015)</ref> : It creates a dynamic matrix for all entity-relation pairs and maps the head and tail into M1 and M2, respectively. The transition from head to tail is as follow:</p><formula xml:id="formula_1">M 1 r = w r w ? h + I , M 2 r = w r w ? t + I h ? = M 1 r h , t ? = M 2 r t ?(e o , r, e s ) = ?||h ? + r ? t ? || 2 2</formula><p>TransR <ref type="bibr" target="#b8">(Lin et al., 2015)</ref> : It considers that entities may have multiple aspects, and various relations focus on different aspects of entities. It projects entities into relation space by projection matrix M.</p><formula xml:id="formula_2">h ? = M r h , h ? = M r t ?(e o , r, e s ) = ?||h ? + r ? t ? || 2 2</formula><p>RotatE <ref type="bibr" target="#b14">(Sun et al., 2019)</ref> : RotatE deals with relation as a rotation to complex space. This rotation brings the source entity to the target entity in the complex space. The relation applies to the head entity by Hadamard product. Then it uses the L1 norm to measure the distance from the tail entity in the score function.</p><p>?(e o , r, e s ) = ?||h ? r ? t ? || 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">KNOWLEDGE GRAPH REFINEMENT</head><p>The knowledge graph refinement follows two main objectives: (A) adding information to the knowledge graph, which is a subcategory of the knowledge graph completion. (B) Detecting incorrect information and remove those triplets from the knowledge graph to increase the correctness of the knowledge graph. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">KGREFINER</head><p>In this work, we propose a method to add information to the graph, which refines the knowledge graph and increases link prediction accuracy. In FB15k237, we do this refinement by using relation hierarchies, and in WN18RR, we use hierarchies of entities. We add this information to the graph as a new node; these nodes are auxiliary nodes. We introduce several new relations to connect these new nodes to graph nodes, and we add these triples to the graph. Translational link prediction methods such as TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref>, TransH <ref type="bibr" target="#b15">(Wang et al., 2014)</ref>, TransD <ref type="bibr" target="#b7">(Ji et al., 2015)</ref>, etc., create transition property in their embeddings. For example, in TransE, embeddings are made as follow:</p><formula xml:id="formula_3">e s + r ? e o<label>(1)</label></formula><p>This means in embedding space; the tail entity should be close to the sum of head and relation. For example, let's consider these triples:</p><formula xml:id="formula_4">P aris + capitalof ? F rance (2) T ehran + capitalof ? Iran<label>(3)</label></formula><p>Link prediction model is not aware of both tails entities are country. If we add new node as "country" to the graph and connect it to all graph's countries with a new relation "RelatedTo" then these triples are added to graph:</p><formula xml:id="formula_5">F rance + RelatedT o ? country (4) Iran + RelatedT o ? country<label>(5)</label></formula><p>Equations 4 and 5, which are similar, bring closer the embeddings of France and Iran, which are semantically identical. <ref type="figure" target="#fig_1">Figure 1</ref> gives an illustration of what changes KGrefiner brings for the embedding space. This closeness in evaluating Equation 2 causes the model to search between countries when asked where France's capital is.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">REFINEMENT OF FB15K237</head><p>In FB15k237, graph relations contain information about entities. For example, the "entity ? physical entity ? object ? location ? region ? area ? center ? seat ? capital ? national capital" is a relationship between countries and cities, and nodes on one side of relationships can be considered similar. Higher levels usually have more general information about objects in the hierarchy, and lower levels have more specific, so we extracted the last three levels of hierarchies from each relation in this graph to use this information. Then, for each sub-relation, we counted the number of repetitions in the graph training section. We removed those components with less than 100 repetitions in the graph to reduce the number of these sub-relations, and the number 100 is arbitrary. Finally, 285 sub-relations remained, which we added to the set of entities in this graph (as new nodes). We call these auxiliary nodes relation-nodes. We defined two new relations, "RelatedTo" and "HasAttribute", to connect these relation-nodes to the graph. For each triple, if the entity is the triple's head, we linked it with relation-node by "RelatedTo", and if it is the tail of the triple, we use "HasAttribute" to establish these connections. For example, to refine relation between Paris and France, (Paris,"entity ? physical?entity ? object ? location ? region ? area ? center ? seat ? capital ? national?capital",France), "capital" has repetition over 100, so the following triples were added to the graph:</p><formula xml:id="formula_6">F rance + HasAttribute ? capital P aris + RelatedT o ? capital 4.2 REFINEMENT OF WN18RR</formula><p>To refine this graph, we use the hierarchy of entities. In Freebase, we used relationships, but relationships do not give us information about entities in Wordnet. France, for example, has a hierarchy of "existence ? place ? region ? region ? administrative region ? country ? France". This hierarchy gives us good information about France. Except for the last level, we extract the other last three levels of entities. Among these levels, we hold those with more than an arbitrary number of 50 repetitions among entities to reduce these levels. As a result, 207 levels remained. We add these levels as new nodes to the graph training section and connect them to the entities with these levels in their hierarchy with a new type of connection. In this graph, we define a new relation and name it "HasAttribute". For example, France and Iran have a "country" in their hierarchical structure. Then, the following triples were added to the training section of the graph:</p><p>F rance + HasAttribute ? country Iran + HasAttribute ? country 5 EXPREMENT</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">DATASETS</head><p>We evaluated our work on popular benchmarks: FB15K237 and WN18RR; these datasets are respectively refined from real knowledge graphs: WordNet <ref type="bibr" target="#b9">(Miller, 1995)</ref> and Freebase <ref type="bibr" target="#b0">(Bollacker et al., 2008)</ref>. In addition, we built two other datasets with KGRefiner: FB15K237-Refined and WN18RR-Refined, respectively, from FB15K237 and WN18RR. The details of the datasets are shown in <ref type="table">Table  1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">BASELINES</head><p>To demonstrate the effectiveness of our models, we compare results with the original translational models TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref>, TransH <ref type="bibr" target="#b15">(Wang et al., 2014)</ref>, TransD <ref type="bibr" target="#b7">(Ji et al., 2015)</ref>, and the last translational model, RotatE <ref type="bibr" target="#b14">(Sun et al., 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">EXPERIMENTAL SETTINGS</head><p>We used implementation of baselines by OpenKE <ref type="bibr" target="#b6">(Han et al., 2018)</ref>. We used an embedding dimension of 200 for all models. Also, we removed self adversarial negative sampling from TransE and RotatE to have a fair comparison. We tried {200, 500, 1000, 2000} epochs, and we picked the best epoch according to MRR on the validation set. Other hyperparameters of the models are those mentioned in OpenKE. Hyperparameters for FB15K237 and FB15K237-Refined and also WN18RR and WN18RR-Refined are the same.    <ref type="bibr" target="#b19">(Zhang et al., 2018)</ref>, for RotatE we used <ref type="bibr" target="#b6">(Han et al., 2018)</ref> to produce scores. For other results, we used <ref type="bibr" target="#b6">(Han et al., 2018)</ref> to produce them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Training Time for single epoch TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref> [?]</p><p>2.8 s TransH <ref type="bibr" target="#b15">(Wang et al., 2014)</ref> [?] 5.2 s TransD <ref type="bibr" target="#b7">(Ji et al., 2015)</ref> [?] 5.2 s RotatE <ref type="bibr" target="#b14">(Sun et al., 2019)</ref>   [?]: These models are implemented by OpenKE <ref type="bibr" target="#b6">(Han et al., 2018)</ref> and [ ] are produced by their original implementations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">SPEED OF MODELS</head><p>The training time of translational models is much less than deep learning approaches such as ConvE, SACN, ConvKB, etc. The complexity in scoring function and neural network layers in their architecture reduces training speed in deep learning methods. <ref type="table" target="#tab_4">Table 4</ref> compares the time that each model needs to be trained for one epoch on FB15k237. We ran models on Nvidia K80. For fair comparison embedding dimension for all models is 200. These models usually need 1000 epochs, so the runtime difference between TransE and RotatE is around 35000s for FB15k237.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we propose KGRefiner, a novel knowledge graph refinement method that alleviates the limitations of translational models by capturing additional information in knowledge graph hierarchies. We used hierarchy components as new nodes, and by connecting these nodes to proper entities in the knowledge graph, we have a more informative graph. Our experimental results show that our KGRefiner outperforms other state-of-the-art translational models on two benchmark datasets WN18RR and FB15k237. Furthermore, it is the first augmentation method that works with both Wordnet and Freebase, while old methods only perform only on one dataset. In future works, we will expand our work on datasets that can be formulated on the triple structure. For example, recommender system datasets can be formed on graph schema, and KGRefiner can be applied.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>TransE:</head><label></label><figDesc>For factual triple (e s ,r,e o ), adding embeddings of head and relation should be closed to the tail embedding, and on the other hand, for corrupted ones (e s ,r,e o ), e s + r should have a distance with e o . The score function of TransE is as follow: ?(e o , r, e s ) = ?||h + r ? t|| 2 2 TransH (Wang et al., 2014): To improve modelling of N-1, 1-N and N-N, TransH defined a hyperplane for each relations, and translation property should be established on that hyperplane.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Simple illustration of changes in embedding space. The right side graph shows the effect of adding auxiliary nodes to the graph, which translational models bring all countries together and cities together in vector space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc>and 3 compares the experimental results of our KGRefiner plus translational models and with previously published results. Results in bold font are the best results in the group, and the underlined results denote the best results in the column. KGRefiner with TransH obtains the highest H@10 and MRR on FB15k237, and also KGRefiner with RotatE reached the best MR and H@10 in WN18RR.</figDesc><table><row><cell>Dataset</cell><cell cols="5">FB15k237 FB15k237-Refined WN18RR WN18RR-Refined</cell></row><row><cell>Entities</cell><cell>14541</cell><cell>14826</cell><cell></cell><cell>40943</cell><cell>41150</cell></row><row><cell>Relations</cell><cell>237</cell><cell>239</cell><cell></cell><cell>11</cell><cell>12</cell></row><row><cell>Train Edges</cell><cell>272115</cell><cell>550998</cell><cell></cell><cell>86835</cell><cell>230135</cell></row><row><cell>Val. Edges</cell><cell>17535</cell><cell>17535</cell><cell></cell><cell>3034</cell><cell>3034</cell></row><row><cell>Test Edges</cell><cell>20466</cell><cell>20466</cell><cell></cell><cell>31134</cell><cell>31134</cell></row><row><cell cols="6">Table 1: Statistics of the experimental datasets. The refined version represents that graph has some</cell></row><row><cell>auxiliary nodes.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Baseline</cell><cell></cell><cell cols="3">H@10 MR MRR</cell></row><row><cell></cell><cell>TransE</cell><cell></cell><cell>45.6</cell><cell cols="2">347 29.4</cell></row><row><cell></cell><cell cols="2">TransE + KGRefiner</cell><cell>47</cell><cell cols="2">203 29.1</cell></row><row><cell></cell><cell>TransD</cell><cell></cell><cell>45.3</cell><cell cols="2">256 28.6</cell></row><row><cell></cell><cell cols="2">TransD + KGRefiner</cell><cell>43.7</cell><cell>227</cell><cell>24</cell></row><row><cell></cell><cell>RotatE</cell><cell></cell><cell>47.4</cell><cell cols="2">185 29.7</cell></row><row><cell></cell><cell cols="2">RotatE + KGRefiner</cell><cell>43.9</cell><cell cols="2">226 27.9</cell></row><row><cell></cell><cell>TransH</cell><cell></cell><cell>36.6</cell><cell cols="2">311 21.1</cell></row><row><cell></cell><cell cols="2">TransH + KGRefiner</cell><cell>48.9</cell><cell cols="2">221 30.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Link prediction results on FB15K237 and its refined version.</figDesc><table><row><cell>Results of TransE is taken</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Link prediction results on WN18RR and its refined version. Results of TransE is taken from (Nguyen et al., 2018), TransH and TransD from</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison between translational technique and deep learning methods in training time.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<idno type="DOI">http:/doi.acm.org/10.1145/1376616.1376746</idno>
		<ptr target="http://doi.acm.org/10.1145/1376616.1376746" />
		<title level="m">ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;08</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Question answering with subgraph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1067</idno>
		<ptr target="http://aclweb.org/anthology/D14-1067" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="615" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Open question answering with weakly supervised embedding models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="165" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolutional 2d knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minervini</forename><surname>Pasquale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stenetorp</forename><surname>Pontus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1707.01476" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 32th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018-02" />
			<biblScope unit="page" from="1811" to="1818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Openke: An open toolkit for knowledge embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shulin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lv</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding via dynamic mapping matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd annual meeting of the association for computational linguistics and the 7th international joint conference on natural language processing</title>
		<meeting>the 53rd annual meeting of the association for computational linguistics and the 7th international joint conference on natural language processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="687" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-ninth AAAI conference on artificial intelligence</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Wordnet: A lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">http:/doi.acm.org/10.1145/219717.219748</idno>
		<ptr target="http://doi.acm.org/10.1145/219717.219748" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual Meeting of the ACL</title>
		<meeting>the 47th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning entity type embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changsung</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagiza F</forename><surname>Samatova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on conference on information and knowledge management</title>
		<meeting>the 2017 ACM on conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2215" to="2218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A novel embedding model for knowledge base completion based on convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><forename type="middle">Dinh</forename><surname>Dai Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2053</idno>
		<ptr target="http://aclweb.org/anthology/N18-2053" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of North American Chapter of the Association for Computational Linguistics</title>
		<meeting>North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="327" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">End-to-end structureaware convolutional networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinbo</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3060" to="3067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rotate: Knowledge graph embedding by relational rotation in complex space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HkgEQnRqYQ" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2893873.2894046" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI&apos;14</title>
		<meeting>the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI&apos;14</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1112" to="1119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Explicit semantic ranking for academic search via knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th international conference on world wide web</title>
		<meeting>the 26th international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1271" to="1279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Collaborative knowledge base embedding for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><forename type="middle">Jing</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">http:/doi.acm.org/10.1145/2939672.2939673</idno>
		<ptr target="http://doi.acm.org/10.1145/2939672.2939673" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Knowledge Discovery and Data Mining, KDD &apos;16</title>
		<meeting>the 22nd International Conference on Knowledge Discovery and Data Mining, KDD &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning hierarchy-aware knowledge graph embeddings for link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanqiu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3065" to="3072" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding with hierarchical relation structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzhen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3198" to="3207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Biomedical knowledge graph refinement with embedding and logic rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sendong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.01031</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
