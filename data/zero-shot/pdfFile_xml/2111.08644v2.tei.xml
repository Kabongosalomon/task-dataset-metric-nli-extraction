<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andra</forename><surname>Acsintoae</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Florescu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariana-Iuliana</forename><surname>Georgescu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">MBZ University of Artificial Intelligence</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">SecurifAI</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tudor</forename><surname>Mare</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">SecurifAI</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Sumedrea</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><forename type="middle">Tudor</forename><surname>Ionescu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">SecurifAI</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahbaz</forename><surname>Khan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">MBZ University of Artificial Intelligence</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Link?ping University</orgName>
								<address>
									<settlement>Sweden</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<region>US</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T07:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Detecting abnormal events in video is commonly framed as a one-class classification task, where training videos contain only normal events, while test videos encompass both normal and abnormal events. In this scenario, anomaly detection is an open-set problem. However, some studies assimilate anomaly detection to action recognition. This is a closed-set scenario that fails to test the capability of systems at detecting new anomaly types. To this end, we propose UBnormal, a new supervised open-set benchmark composed of multiple virtual scenes for video anomaly detection. Unlike existing data sets, we introduce abnormal events annotated at the pixel level at training time, for the first time enabling the use of fully-supervised learning methods for abnormal event detection. To preserve the typical open-set formulation, we make sure to include disjoint sets of anomaly types in our training and test collections of videos. To our knowledge, UBnormal is the first video anomaly detection benchmark to allow a fair headto-head comparison between one-class open-set models and supervised closed-set models, as shown in our experiments. Moreover, we provide empirical evidence showing that UBnormal can enhance the performance of a state-of-theart anomaly detection framework on two prominent data sets, Avenue and ShanghaiTech. Our benchmark is freely available at https://github.com/lilygeorgescu/ UBnormal.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In spite of the growing interest in video anomaly detection <ref type="bibr">[11, 12, 17-19, 22-24, 27, 32, 34, 39-41, 43, 46, 52, 54, 60, 61, 64, 66]</ref>, which generated significant advances leading to impressive performance levels <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b66">67]</ref>, the task remains very challenging. The difficulty of the task stems from two interdependent aspects: (i) the reliance on context of anomalies, and (ii) the lack of abnormal training data. The former issue can be explained through a simple comparative example considering a truck * equal contribution corresponding author driven on a street, which is normal, versus a truck driven in a pedestrian area, which is abnormal. The reliance on context essentially generates an unbounded set of possible anomaly types. Coupled with the difficulty of collecting sufficient data for certain anomaly types (it is not ethical to fight or hurt people just to obtain video examples), the reliance on context makes it nearly impossible to gather abnormal training data.</p><p>In the recent literature, we identified two distinct formulations to deal with the difficulty of the video anomaly detection task. On the one hand, we have the mainstream formulation, adopted in works such as <ref type="bibr">[2, 9-11, 14, 20, 23, 25, 27, 29, 30, 33, 35, 37, 38, 41, 43, 44, 47, 48, 50, 51, 56, 61, 62, 68-70]</ref>, treating anomaly detection as a one-class classification (or outlier detection) task. In this formulation, training videos contain only normal events, while test videos encompass both normal and abnormal events. Under this scenario, methods learn a model of normality from familiar events, labeling unfamiliar events as abnormal at inference time. While framing anomaly detection as an outlier detection task preserves the open-set characteristic of anomaly types, the models proposed under this formulation usually obtain lower performance rates, as they lack knowledge of abnormal examples. On the other hand, we have the alternative formulation, considered in works such as <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b70">71]</ref>, treating anomaly detection as a weakly-supervised action recognition task, where training videos contain both normal and abnormal events, but the annotation is provided at the video level. This formulation corresponds to a closed-set evaluation scenario where training and test anomalies belong to the same action categories, failing to test the capability of systems at detecting unseen anomaly types.</p><p>To this end, we propose a novel formulation that frames video anomaly detection as a supervised open-set classification problem. In our formulation, both normal and abnormal events are available at training time, but the anomalies that occur at inference time belong to a distinct set of anomaly types (categories). The main advantages of posing anomaly detection as a supervised open-set problem are: (i) enabling the use of fully-supervised models due to the availability of anomalies at training time, (ii) enabling the eval- uation of models under unexpected anomaly types due to the use of disjoint sets of anomaly categories at training and test time, and (iii) enabling the fair comparison between one-class open-set methods and weakly-supervised closedset methods. As for the one-class problem formulation, an issue with the supervised open-set formulation lies in the difficulty of collecting abnormal data from the real world. To alleviate this issue, we propose UBnormal, a new benchmark comprising multiple virtual scenes for video anomaly detection. Our scenes are generated in Cinema4D using virtual animated characters and objects that are placed in realworld backgrounds, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. To the best of our knowledge, this is the first data set for supervised open-set anomaly detection in video.</p><p>Although UBnormal enables both the development and training of models in ideal conditions (with full supervision), and the evaluation of models in adverse conditions (on unknown anomaly types), its simulated scenes belong to a different data distribution than natural scenes. Therefore, it might be unclear what is the behavior of fullysupervised models on real-world scenes. To this end, we propose to overcome the distribution gap using CycleGAN <ref type="bibr" target="#b71">[72]</ref>, translating simulated objects from UBnormal to realworld benchmarks such as Avenue <ref type="bibr" target="#b32">[33]</ref> and ShanghaiTech <ref type="bibr" target="#b34">[35]</ref>. We then employ a state-of-the-art multi-task learning framework <ref type="bibr" target="#b16">[17]</ref> for anomaly detection, introducing a new proxy task to discriminate between normal and abnormal samples from our data set. Our results show that UBnormal can enhance the performance of the state-of-the-art multitask learning framework on both data sets. Interestingly, we provide empirical evidence indicating that performance gains can be achieved even without trying to close the distribution gap with CycleGAN. This shows that UBnormal can directly improve the performance of state-of-the-art models in the real-world.</p><p>In summary, our contribution is threefold: </p><formula xml:id="formula_0">? We</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Video Anomaly Detection Methods</head><p>A large body of recent works <ref type="bibr">[2-4, 7, 9-11, 14, 17, 18, 20, 21, 23, 25, 27, 27-30, 32, 33, 35-38, 41, 43-45, 47, 48, 50, 51, 55, 56, 59-70]</ref> treats anomaly detection in video as a oneclass classification (outlier detection) task, training models without having access to abnormal samples. These works can be divided into three categories corresponding to the level at which the algorithm is applied: frame, patch or object. For instance, Yu et al. <ref type="bibr" target="#b64">[65]</ref> proposed a frame-level framework which employs the adversarial learning of past and future events to detect anomalies, instead of requiring complementary information such as optical flow or explicit abnormal samples during training. Ramachandra et al. <ref type="bibr" target="#b44">[45]</ref> proposed a patch-level framework to localize anomalies in video by using a Siamese network to learn a metric from pairs of video patches. The learned metric is used to measure the perceptual distance between video patches from a test video and video patches from the normal training videos. Georgescu et al. <ref type="bibr" target="#b16">[17]</ref> employed self-supervised multi-task learning at the object level to detect anomalies in video. The framework uses a total of four proxy tasks, three based on self-supervision and one based on knowledge distillation. The final anomaly score for each object detected in a frame is computed by averaging the anomaly scores predicted for each proxy task.</p><p>Another body of works <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b70">71]</ref> treats anomaly detection as a weakly-supervised action recognition task. In this line of work, an algorithm is trained on both normal and abnormal videos, but the abnormal videos are annotated at the video level. The anomalies occurring at test time belong to the same action categories as the training anomalies, leading to an easier closed-set problem. Sul- tani et al. <ref type="bibr" target="#b52">[53]</ref> proposed an algorithm based on multiple instance learning, building a deep anomaly ranking model that predicts high anomaly scores for abnormal video segments.</p><p>To increase the anomaly detection performance, Feng et al. <ref type="bibr" target="#b14">[15]</ref> proposed a multiple instance self-training framework consisting of a multiple instance pseudo-label generator and a self-guided attention encoder in order to focus on the anomalous regions in each frame. We notice that weaklysupervised anomaly detection frameworks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b70">71]</ref> are often evaluated on the ShanghaiTech or UCSD Ped data sets, but there are no official splits for weakly-supervised training on these data sets. Due to the unavailability of official splits, researchers tend to use their own data splits, leading to unfair comparisons between methods. To this end, we emphasize that the comparison between weaklysupervised and outlier detection (one-class) frameworks is unfair. This is because the former methods gain knowledge from the abnormal training data which is not available for the latter methods. If the anomaly types in training and test would be disjoint, the comparison could become more fair. The existing video anomaly detection methods either use normal training data only <ref type="bibr">[2-4, 7, 9-11, 14, 17, 18, 20, 21, 23, 25, 27, 27-30, 32, 33, 35-38, 41, 43-45, 47, 48, 50, 51, 55, 56, 59-70]</ref>, or abnormal training data with video-level annotations <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b70">71]</ref>. To our knowledge, there is no off-the-shelf method that can be applied on UBnormal and take full advantage of its supervised open-set nature. To this end, we introduce minimal changes to the considered baselines to leverage the availability of abnormal training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Video Anomaly Detection Data Sets</head><p>To date, there are quite a few data sets available for anomaly detection in video. We report several statistics about the most utilized data sets in <ref type="table">Table 1</ref>. While there are several data sets that preserve the open-set characteristic of anomaly detection <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b42">43]</ref>, to the best of our knowledge, there is only one data set for closed-set anomaly detection, namely UCF-Crime <ref type="bibr" target="#b52">[53]</ref>.</p><p>The open-set benchmarks can be separated into two categories according to the number of scenes. The CUHK Avenue <ref type="bibr" target="#b32">[33]</ref>, Street Scene <ref type="bibr" target="#b42">[43]</ref>, Subway Entrance <ref type="bibr" target="#b0">[1]</ref>, Subway Exit <ref type="bibr" target="#b0">[1]</ref> and UCSD Ped <ref type="bibr" target="#b36">[37]</ref> data sets form the category of single-scene benchmarks <ref type="bibr" target="#b45">[46]</ref>, enabling the successful use of frame-level methods that learn very specific normality models (adapted to a particular scene). In contrast, ShanghaiTech <ref type="bibr" target="#b34">[35]</ref> and UMN <ref type="bibr" target="#b37">[38]</ref> belong to the category of multiple-scene benchmarks, which tests the capability of methods to build more generic normality models, that perform well on several scenes. Street Scene <ref type="bibr" target="#b42">[43]</ref> is the largest single-scene data set, containing 203,257 frames. Despite being the largest data set for the single-scene scenario, it is not representative of real-world models that are expected to run across multiple scenes (as long as the normal behavior is similar across scenes). With 317,398 frames, the largest multiple-scene data set for open-set anomaly detection is ShanghaiTech <ref type="bibr" target="#b34">[35]</ref>. Despite being the largest in its scenario, it has a small number of anomalies (158) belonging to only 11 anomaly types.</p><p>Most of the existing data sets contain anomalies related to human-interaction <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref> or vehicles in pedestrian areas, but the anomalies are usually staged and lack variety. For example, in UCSD Ped2 <ref type="bibr" target="#b36">[37]</ref>, each anomalous event is related to bicycles, skateboards or cars in a pedestrian area. Similarly, Subway <ref type="bibr" target="#b0">[1]</ref> contains only anomalies related to people, such as people walking in the wrong direction or people jumping over the turnstiles. The size of Subway is quite large, with 144,250 frames for the Entrance video and 64,901 frames for the Exit video, but the number of anomaly types is very small, with only 5 anomaly types for Entrance and 3 anomaly types for Exit, respectively.</p><p>The closed-set UCF-Crime benchmark introduced by Sultani et al. <ref type="bibr" target="#b52">[53]</ref> contains 13M frames from videos re-trieved from YouTube and LiveLeak, using text queries. The data set contains 13 anomaly categories that can be found in both training and test videos. UCF-Crime does not follow the open-set paradigm for anomaly detection in video, where the actions from the training set are different for those in the test set. Moreover, the data set does not contain pixel-level anomaly annotations.</p><p>To the best of our knowledge, we are the first to propose a benchmark for supervised open-set anomaly detection. We consider several factors that justify the need for a novel anomaly detection benchmark. First and foremost, unlike existing data sets, our benchmark contains anomalies with pixel-level annotations in the training set. The anomaly types from the training set are different from the anomaly types seen in the test set, conforming to the openset constraint. Second, none of the existing data sets have a validation set, a mandatory requirement for many machine learning algorithms relying on hyperparameter tuning. This leaves two options, either tune the model on the test data, inherently overfitting the model to the test set, or refrain from hyperparameter tuning, likely leading to suboptimal results. In contrast to existing benchmarks, we are the first to provide a validation set. It contains anomalies belonging to a different set of action categories than the set of action categories available at test time. This ensures the possibility to perform model tuning without overfitting to the test set. Third, some of the existing data sets, e.g. UCSD Ped <ref type="bibr" target="#b36">[37]</ref> and UMN <ref type="bibr" target="#b37">[38]</ref>, are already saturated (the performance surpasses 99% in terms of the frame-level AUC), while the performance on other benchmarks, e.g. Avenue <ref type="bibr" target="#b32">[33]</ref> and Subway <ref type="bibr" target="#b0">[1]</ref>, surpasses 90% in terms of the frame-level AUC. For example, the results reported in <ref type="bibr" target="#b17">[18]</ref> on Avenue (a micro AUC of 92.3%) and UCSD Ped2 (a micro AUC of 98.7%) are significantly higher compared to the results obtained by the same method on the UBnormal data set (a micro AUC of 59.3%). In general, our experiments show that UBnormal is significantly more challenging, likely due to the higher variation of anomaly types and scenes. Considering all these aspects, we believe that UBnormal will likely contribute towards the development of future anomaly detection models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Open-Set Action Recognition</head><p>With respect to the definition of open-set video recognition of Geng et al. <ref type="bibr" target="#b15">[16]</ref>, in our setting, the normal classes are known known classes (KKC) and the abnormal classes used at test time are unknown unknown classes (UUC). We consider the abnormal actions used at training time as known unknown classes (KUC). However, KUC samples will not appear at test time. To this end, our setting can be considered as supervised open-set, which is distinct from the classical open-set setting. Moreover, we underline that the anomaly detection task is distinct from action recognition, i.e. abnormal actions need to be detected and localized in long videos. One video may contain multiple normal and abnormal events happening at the same time. Hence, a pure action recognition approach is not likely to provide optimal results in anomaly detection. Hence, we consider works on open-set action recognition <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8]</ref> as very distantly related.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">UBnormal Benchmark</head><p>Scenes. The UBnormal benchmark is generated using the Cinema4D software, which allows us to create scenes using 2D background images and 3D animations. We select a total of 29 natural images that represent street scenes, train stations, office rooms, among others. In the selected background images, we make sure to eliminate people, cars or other objects that should belong to the foreground. From each natural image, we create a virtual 3D scene and generate (on average) 19 videos per scene. For each scene, we generate both normal and abnormal videos. The proportion of normal versus abnormal videos in the entire UBnormal data set is close to 1 : 1. Action categories. We consider the following events as normal, for all our video scenes: walking, talking on the phone, walking while texting, standing, sitting, yelling and talking with others. In addition, we introduce a total of 22 abnormal event types, as follows: running, falling, fighting, sleeping, crawling, having a seizure, laying down, dancing, stealing, rotating 360 degrees, shuffling, walking injured, walking drunk, stumbling walk, people and car accident, car crash, running injured, fire, smoke, jaywalking, driving outside lane and jumping. We organize the anomalous event types such that those included in the test set are different from those found in the training and validation sets. Hence, the test set includes the following anomalies: running, having a seizure, laying down, shuffling, walking drunk, people and car accident, car crash, jumping, fire, smoke, jaywalking and driving outside lane. The following anomalies are included in the training set: falling, dancing, walking injured, running injured, crawling and stumbling walk. The rest of the anomalies are added to the validation set. Variety. In order to increase the variety of our data set, we include multiple object categories, such as people, cars, skateboards, bicycles and motorcycles. Unlike other data sets (CUHK Avenue <ref type="bibr" target="#b32">[33]</ref>, ShanghaiTech <ref type="bibr" target="#b34">[35]</ref>, UCSD Ped <ref type="bibr" target="#b36">[37]</ref>), these objects can perform both normal and abnormal actions, thus being present in both normal and abnormal videos. Hence, simply labeling an object as abnormal because it belongs to an unseen category is no longer possible. To further increase the diversity of the data set, we include foggy scenes, night scenes, and fire and smoke as abnormal events. In existing data sets, a single person or a small group of people perform most of the abnormal actions. We can take the person with blue pants that is running or throwing a backpack or some papers in CUHK Avenue <ref type="bibr" target="#b32">[33]</ref> as example, or the group of guys that are running and fight-ing in various scenes from ShanghaiTech <ref type="bibr" target="#b34">[35]</ref>. Different from such data sets, the anomalous events in the UBnormal data set are performed by various characters. We employ 19 different characters to animate the videos. We also change the colors of their clothes or their hair color, increasing the diversity of the animated characters included in our benchmark. We provide several figures showcasing the variety of scenes, characters and actions of UBnormal in the supplementary. Data generation and annotation. The anomalies in the UBnormal data set are annotated at the pixel level. For each synthetic object (normal or abnormal) in the data set, we provide the segmentation mask and the object label (person, car, bicycle, motorcycle or skateboard). In the process of simulating the events and generating the benchmark, we involved a team of six people for a period of three months. We generate all videos at 30 FPS with the minimum height of a frame set to 720 pixels. It takes about 15 seconds to render one frame with the Cinema4D software, taking a total of 987 hours (41.1 days) to render the entire data set. After generating the videos, four of our team members checked each generated video for incorrect occlusions, gravity-related issues or other visual inconsistencies, ensuring the high quality of the generated data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methods</head><p>One-class open-set model. As the first baseline for the UBnormal data set, we employ the state-of-the-art backgroundagnostic framework introduced in <ref type="bibr" target="#b17">[18]</ref>. This is an objectlevel method which treats anomaly detection as a one-class classification task. The framework is composed of three auto-encoders and three classifiers. To increase the performance of the anomaly detection method, Georgescu et al. <ref type="bibr" target="#b17">[18]</ref> proposed an adversarial learning scheme for the auto-encoders. To overcome the lack of abnormal samples during training, they created a scene-agnostic set of pseudoanomalies. The pseudo-abnormal samples are used in the adversarial training process as adversarial examples and, in the training of the binary classifiers, as abnormal samples.</p><p>In our first experiment, we employ the framework <ref type="bibr" target="#b17">[18]</ref> without any modification as a baseline for our benchmark. Then, we add the abnormal samples from our training data set to the pool of pseudo-abnormal samples. Supervised closed-set model. As another baseline, we consider the supervised closed-set model proposed by Sultani et al. <ref type="bibr" target="#b52">[53]</ref>. In this framework <ref type="bibr" target="#b52">[53]</ref>, the normal and abnormal videos are represented as bags, and the video segments are instances in multiple instance learning. Sultani et al. <ref type="bibr" target="#b52">[53]</ref> represented each video using features extracted by a pretrained C3D <ref type="bibr" target="#b57">[58]</ref> model. Using the video feature representation, they trained a feed-forward neural network such that the maximum score of the instances from the anomalous bag is higher than the maximum score of the instances from the normal bag. They also incorporated sparsity and smoothness constraints in the loss function to further boost the performance of the framework. Action recognition framework. The third baseline for our benchmark is an action recognition model. We choose the state-of-the-art model proposed by Bertasius et al. <ref type="bibr" target="#b5">[6]</ref>. The TimeSformer <ref type="bibr" target="#b5">[6]</ref> architecture adjusts the standard transformer architecture to the video domain, by learning spatiotemporal features from sequences of frame patches. TimeSformer <ref type="bibr" target="#b5">[6]</ref> uses divided attention, i.e. the spatial and temporal attention maps are learned separately. We train the TimeSformer model to distinguish between normal and abnormal actions. The model predicts the probability of a sequence of frames of being abnormal. Self-supervised multi-task model. We employ the stateof-the-art multi-task learning framework of Georgescu et al. <ref type="bibr" target="#b16">[17]</ref> to show that UBnormal can be used to boost performance on two prominent anomaly detection data sets, namely CUHK Avenue <ref type="bibr" target="#b32">[33]</ref> and ShanghaiTech <ref type="bibr" target="#b34">[35]</ref>. We hereby state that the main goal for conducting experiments with the state-of-the-art method of Georgescu et al. <ref type="bibr" target="#b16">[17]</ref> is to determine if data from the UBnormal data set can help to increase performance on two real-world data sets, regardless of how our data is integrated into the training sets of the respective real-world benchmarks. While we expect higher performance gains after performing domain adaption with CycleGAN (as detailed below), we emphasize that these gains would not be possible without the examples coming from our data set.</p><p>The object-level method of Georgescu et al. <ref type="bibr" target="#b16">[17]</ref> is based on learning a single 3D convolutional neural network (CNN) on four proxy tasks, namely the arrow of time, motion irregularity, middle box prediction and model distillation. Further, we integrate the fifth proxy task (T 5 ) to discriminate between normal and abnormal objects from the UBnormal data set. Here, we consider two options: (i) train the model directly on UBnormal examples, and (ii) pass the objects seen only at training time through CycleGAN <ref type="bibr" target="#b71">[72]</ref>, before training on the fifth proxy task. During inference, we expect the normal samples from the test set to be classified as normal, and the abnormal samples to be classified as abnormal. For each object, we create an object-centric temporal sequence by cropping the object bounding box from the frames {i ? t, ..., i ? 1, i, i + 1, ..., i + t}, following <ref type="bibr" target="#b16">[17]</ref>. The normal object-centric sequences are labeled with class 1, while the abnormal sequences are labeled with class 2.</p><p>Let f be the shared 3D CNN and h T5 be our abnormality head. Let X (T5) be a normal or abnormal object-centric sequence of size (2 ? t + 1) ? 64 ? 64 ? 3. We employ the cross-entropy loss to train the abnormality head:</p><formula xml:id="formula_1">L T5 X (T5) , Y (T5) = ? 2 k=1 Y (T5) k log ? (T5) k ,<label>(1)</label></formula><p>where? (T5) = softmax h T5 f (X (T5) and Y (T5) is the one-hot encoding of the ground-truth label for X (T5) .</p><p>After integrating the fifth proxy task, the shared 3D CNN is trained with the following joint loss:</p><formula xml:id="formula_2">L total = L T1 + L T2 + L T3 + ? ? L T4 + L T5 .<label>(2)</label></formula><p>Further details about L T1 , L T2 , L T3 and L T4 are provided in <ref type="bibr" target="#b16">[17]</ref>. At inference time, the anomaly score for each object is computed using the following equation:</p><formula xml:id="formula_3">score(X) = 1 5 ? (T1) 2 +? (T2) 2 + avg Y (T3) ?? (T3) + avg Y (T4) YOLO ?? (T4) YOLO +? (T5) 2 .<label>(3)</label></formula><p>The notations?</p><formula xml:id="formula_4">(T1) 2 ,? (T2) 2 , Y (T3) ,? (T3) , Y (T4) YOLO and? (T4) YOLO</formula><p>are defined in <ref type="bibr" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Setup and Implementation Details</head><p>Data sets. Aside from reporting results on UBnormal, we evaluate how helpful the data from UBnormal is for other real-world anomaly detection benchmarks. To this end, we consider the popular CHUK Avenue <ref type="bibr" target="#b32">[33]</ref> and Shang-haiTech <ref type="bibr" target="#b34">[35]</ref> data sets. We provide more details about these benchmarks in <ref type="table">Table 1</ref>. Evaluation measures. As evaluation metrics, we consider the widely-used area under the curve (AUC), computed with respect to the ground-truth frame-level annotations, as well as the region-based detection criterion (RBDC) and trackbased detection criterion (TBDC) introduced by Ramachandra et al. <ref type="bibr" target="#b42">[43]</ref>. For the frame-level AUC, we consider both micro and macro versions, following <ref type="bibr" target="#b17">[18]</ref>.</p><p>Learning and parameter tuning. In order to train the oneclass open-set model and the supervised closed-set framework on UBnormal, we use the official code provided by Georgescu et al. <ref type="bibr" target="#b17">[18]</ref> and Sultani et al. <ref type="bibr" target="#b52">[53]</ref>, respectively. We train the models following the instructions given by the authors, without changing any of the hyperparameters.</p><p>To train the TimeSformer model on UBnormal, we rely on the official implementation released by Bertasius et al. <ref type="bibr" target="#b5">[6]</ref>. We use the default version of TimeSformer, which processes 8 frames, each having a spatial resolution of 224 ? 224 pixels. In order to adapt the TimeSformer model to abnormal event detection, we change the last fully-connected layer to distinguish between two classes, normal versus abnormal. We start from the pre-trained TimeSformer and fine-tune it for 20 epochs on the UBnormal benchmark, with the learning rate set to 5 ? 10 ?4 . We perform experiments with the default video sample rate (1/32), as well as two additional sample rates (1/8 and 1/4) that seemed more suitable for UBnormal, at least from our perspective.</p><p>For the experiments on Avenue and ShanghaiTech, we use the official code and the hyperparameters reported by Georgescu et al. <ref type="bibr" target="#b16">[17]</ref> to train the self-supervised multi-task model. To adapt UBnormal examples to Avenue and Shang-haiTech, respectively, we train CycleGAN <ref type="bibr" target="#b71">[72]</ref> using the official code with the default hyperparameters. We apply CycleGAN at the object level. In order to extract the object bounding boxes from the UBnormal training set, we rely on the ground-truth segmentation masks. To detect the objects in Avenue and ShanghaiTech, we apply the pre-trained YOLOv3 <ref type="bibr" target="#b48">[49]</ref> object detector, following <ref type="bibr" target="#b16">[17]</ref>. We train the CycleGAN model only on the training data from UBnormal and Avenue or ShanghaiTech, respectively. We optimize the CycleGAN model for 10 epochs on each of the two data set pairs. In <ref type="figure" target="#fig_1">Figure 2</ref>, we present a few samples of the translated objects, before and after applying CycleGAN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Anomaly Detection Results</head><p>UBnormal. In <ref type="table">Table 2</ref>, we report the results obtained by the baselines <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b52">53]</ref> on the validation and test sets of our benchmark. The method of Georgescu et al. <ref type="bibr" target="#b17">[18]</ref> obtains a performance of 58.5% in terms of the micro-averaged frame-level AUC on the validation set, while scoring 59.3% on the test set. When we add the abnormal samples from our training data set to the pool of pseudo-abnormal samples, we observe performance gains for all four metrics. The framework of Georgescu et al. <ref type="bibr" target="#b17">[18]</ref> is the only baseline method that performs anomaly localization, thus obtaining significantly higher RBDC and TBDC scores than the other two approaches. Nonetheless, we report the RBDC and TBDC scores for all three baselines for completeness, but we acknowledge that two of the methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b52">53]</ref> are only suitable for anomaly detection. Hence, in <ref type="figure" target="#fig_3">Figure 3</ref>   <ref type="table">Table 2</ref>. Micro-averaged frame-level AUC, macro-averaged frame-level AUC, RBDC and TBDC scores (in %) of the proposed baselines <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b52">53]</ref> on the UBnormal data set. Although only one method <ref type="bibr" target="#b17">[18]</ref> can perform anomaly localization, we report RBDC and TBDC scores for all baselines, for completeness. Best results are highlighted in bold. When employing the pre-trained network of Sultani et al. <ref type="bibr" target="#b52">[53]</ref>, we obtain a micro-averaged frame-level AUC of 49.5% on the test set. Further fine-tuning the network on the UBnormal data set increases the micro-averaged frame-level AUC to 50.3% on the test set. The TimeSformer model <ref type="bibr" target="#b5">[6]</ref> attains the highest microaveraged frame-level AUC on both validation and test sets. Using the default video sample rate of 1/32, we obtain a micro-averaged frame-level AUC of 68.5% on the test set. As we thought that the video sample rate of 1/32 was too high for anomaly detection, we also tried smaller sample rates (1/8, 1/4), without prevail. Indeed, the empirical results show that the video sample rate of 1/32 is optimal for TimeSformer.</p><p>In summary, we find that the TimeSformer model <ref type="bibr" target="#b5">[6]</ref> is the method of choice for anomaly detection on UBnormal, while the framework of Georgescu et al. <ref type="bibr" target="#b17">[18]</ref> remains the best choice when it comes to anomaly localization. Avenue. We report the results obtained on the CUHK Avenue <ref type="bibr" target="#b32">[33]</ref> data set in <ref type="table">Tables 3 and 4</ref>. We compare the approach based on UBnormal samples with the following state-of-the-art methods <ref type="bibr">[3, 4, 7, 11-13, 18, 19, 21, 23, 24, 26-28, 30-32, 34, 36, 39, 41, 43, 44, 53-56, 59-61, 63, 65]</ref>. Without closing the distribution gap between UBnormal and CUHK Avenue <ref type="bibr" target="#b32">[33]</ref> via CycleGAN, we still manage to obtain an improvement of 0.4% in terms of the micro-averaged AUC and 0.5% in terms of the macro-averaged AUC compared to the results reported by Georgescu et al. <ref type="bibr" target="#b16">[17]</ref> at the object level. Upon passing the objects through CycleGAN, we obtain the state-of-the-art results of 93.0% and 93.2% in terms of  micro-averaged and macro-averaged frame-level AUC, surpassing the original method <ref type="bibr" target="#b16">[17]</ref> by at least 1.3% for all four metrics.</p><p>In <ref type="figure" target="#fig_4">Figure 4</ref>, we present the frame-level anomaly scores and some examples of anomaly localization for test video 03 from Avenue. We observe that the approach based on five tasks can precisely localize and detect the two anomalies. ShanghaiTech. In <ref type="table">Tables 3 and 4</ref>, we also report the results obtained on the ShanghaiTech <ref type="bibr" target="#b34">[35]</ref> data set, comparing the approach based on UBnormal samples with other state-of-the-art methods <ref type="bibr">[3, 4, 7, 11-13, 18, 19, 21, 27, 28, 30, 32, 34, 36, 41, 43, 44,</ref>   <ref type="bibr" target="#b20">[21]</ref> 87.4 * 90.4 78.7 * 84.9 Ionescu et al. <ref type="bibr" target="#b22">[23]</ref> 88.9 ---Lee et al. <ref type="bibr" target="#b26">[27]</ref> 90.0 -76.2 -Nguyen et al. <ref type="bibr" target="#b38">[39]</ref> 86.9 ---Vu et al. <ref type="bibr" target="#b58">[59]</ref> 71.5 ---Wu et al. <ref type="bibr" target="#b60">[61]</ref> 86.6 ---2020</p><p>Dong et al. <ref type="bibr" target="#b10">[11]</ref> 84.9 -73.7 -Doshi et al. <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> 86.4 -71.6 -Ji et al. <ref type="bibr" target="#b23">[24]</ref> 78.3 ---Lu et al. <ref type="bibr" target="#b33">[34]</ref> 85.8 -77.9 -Park et al. <ref type="bibr" target="#b40">[41]</ref> 88.5 -70.5 -Ramachandra et al. <ref type="bibr" target="#b42">[43]</ref> 72.0 ---Ramachandra et al. <ref type="bibr" target="#b43">[44]</ref> 87.  <ref type="table">Table 3</ref>. Micro-averaged and macro-averaged frame-level AUC scores (in %) of the state-of-the-art methods <ref type="bibr">[3, 4, 7, 11-13, 18, 19, 21, 23, 24, 26-28, 30-32, 34, 36, 39, 41, 43, 44, 53-56, 59-61, 63, 65]</ref> versus an approach based on the framework proposed in <ref type="bibr" target="#b16">[17]</ref>, enhanced by us with the fifth proxy task (T5) to discriminate between normal and abnormal objects from the UBnormal data set. Results are reported on Avenue and ShanghaiTech. Best results are highlighted in bold. Legend: * -results taken from <ref type="bibr" target="#b17">[18]</ref>. <ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref><ref type="bibr" target="#b55">[56]</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b64">65]</ref>. The results obtained before applying the Cycle-GAN model surpass the original object-level method of Georgescu et al. <ref type="bibr" target="#b16">[17]</ref> by at least 0.2% for all four metrics. After processing the UBnormal objects with CycleGAN, we obtain the state-of-theart results of 83.7% and 90.5% in terms of the micro-averaged and macro-averaged frame-level AUC measures. We also surpass the object-level baseline by 4.35% and 2.25% in terms of RBDC and TBDC, respectively. Regardless of how UBnormal data is integrated into the model (with or without domain adaptation), it is the data itself that has the merit of increasing performance.  <ref type="table">Table 4</ref>. RBDC and TBDC scores (in %) of the state-of-the-art methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref> versus an approach based on the framework proposed in <ref type="bibr" target="#b16">[17]</ref>, enhanced by us with the fifth proxy task (T5) to discriminate between normal and abnormal objects from the UBnormal data set. Results are reported on Avenue and Shang-haiTech. Best results are highlighted in bold. Legend: * -results taken from <ref type="bibr" target="#b17">[18]</ref>.</p><p>In <ref type="figure" target="#fig_5">Figure 5</ref>, we present the frame-level anomaly scores and an example of anomaly localization for video 06 0153 from Shang-haiTech. We observe that the approach based on five tasks can accurately localize and detect the anomaly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work, we introduced UBnormal, a novel benchmark for video anomaly detection. To the best of our knowledge, this is the first and only benchmark for supervised open-set anomaly detection. Perhaps the only limitation of UBnormal is that it is composed of virtual characters and simulated actions. However, we showed several important benefits that justify the importance of UBnormal: (i) it enables the fair and head-to-head comparison of open-set and closed-set models, and (ii) it can alleviate the lack of training anomalies in real-world data sets, bringing significant improvements over the current state-of-the-art models.</p><p>The results reported on UBnormal with three state-of-the-art models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b52">53]</ref> indicate that our benchmark is very challenging. Nonetheless, we consider that the chosen baselines are strong competitors for future works trying to further improve performance on our benchmark.</p><p>In future work, we aim to test the benefit of augmenting other video anomaly detection data sets. Perhaps one of the options that seem more appealing is UCF-Crime <ref type="bibr" target="#b52">[53]</ref>. However, given that the abnormal classes in UCF-Crime are available at both training and test time, i.e. the task is closed, we believe that adding UBnormal data will likely not bring very high performance gains. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Supplementary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Visualizations</head><p>In <ref type="figure" target="#fig_6">Figure 6</ref>, we present the 29 scenes of our data set. We have 22 outdoor scenes and 7 indoor scenes. There are various illumination conditions, corresponding to different weather conditions (e.g. sunny, cloudy, foggy) and different day times (e.g. day, sunset, night). The last image (at the bottom right) illustrates one of the existing scenes with the fog effect.</p><p>We present the animated characters from the UBnormal data set in <ref type="figure" target="#fig_7">Figure 7</ref>. There are 19 unique characters, but in order to increase the variety of the data set, we augment the characters by changing the color of their hair and clothes.</p><p>In <ref type="figure">Figure 8</ref>, we show the 5 object categories (excluding people) from UBnormal. We variate the colors of objects to increase diversity, as for the animated characters.</p><p>In <ref type="figure">Figure 9</ref>, we illustrate an example for each abnormal action category from the UBnormal benchmark. There are 20 anomaly types related to objects (e.g. people, cars) and two non-object anomaly types (fire, smoke). The figure shows the diversity of our anomalies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Statistics</head><p>In <ref type="table" target="#tab_6">Table 5</ref>, we report several statistics about the UBnormal data set. The number of videos in the data set is 543, with 268 videos for training, 64 for validation and the remaining 211 for testing. There are a total of 660 anomalies divided into 195, 76 and 389 for training, validation and test, respectively. The total number of abnormal frames is 89,015, with the largest fraction of 49,850 frames belonging to the test set. There are 142,107 abnormal regions in the data set, which accounts for an average of 1.60 abnormal regions per abnormal frame. The average number of objects per frame is 4.44. The overall length of our data set is 132 minutes.   <ref type="figure">Figure 8</ref>. Various objects animating the scenes in the UBnormal benchmark. There are 5 object categories besides people. To increase variation, we apply different colors to the objects. Best viewed in color. <ref type="figure">Figure 9</ref>. The abnormal action categories from UBnormal. The abnormal objects are emphasized through a red contour. To improve readability, we apply a magnifying effect to smaller objects. Best viewed in color.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Normal and abnormal examples from various scenes included in our data set. Objects performing a variety of abnormal actions (e.g.: fighting, crawling, dancing, sleeping, running) are emphasized through a red contour. Notice that the abnormal actions included in the test set belong to distinct categories from the abnormal actions used for training and validation, leading to a supervised open-set setting. More examples are provided in the supplementary. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Normal and abnormal objects from UBnormal (above) and the corresponding CycleGAN translations to ShanghaiTech and Avenue (below), respectively. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>, we present the frame-level anomaly scores and a set of anomaly localization examples provided by the framework of Georgescu et al.<ref type="bibr" target="#b17">[18]</ref> for a test video from UBnormal. The illustrated anomalies represent people running. More qualitative results are shown in the annotated videos uploaded at https://github.com/lilygeorgescu/ UBnormal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Frame-level scores and anomaly localization examples for a test video from the UBnormal data set. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Frame-level scores and anomaly localization examples for test video 03 from the Avenue data set. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Frame-level scores and anomaly localization examples for test video 06 0153 from ShanghaiTech. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>The 29 backgrounds used to generate the virtual scenes in UBnormal. One of the scenes is repeated (in the bottom-right corner) to show the fog effect. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Various characters animating the scenes in the UBnormal benchmark. There are 19 unique characters that serve as seeds for generating people with different hair color and clothes. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Georgescu et al. [18] 58.5 94.4 18.580 48.213 59.3 84.9 21.907 53.438 Georgescu et al. [18] + UBnormal anomalies 68.2 95.3 28.654 58.097 61.3 85.6 25.430 56.272 Sultani et al. [53] (pre-trained) 61.1 89.4 0.001 0.012 49.5 77.4 0.001 0.001 Sultani et al. [53] (fine-tuned) 51.8 88.0 0.001 0.001 50.3 76.8 0.002 0.001 Bertasius et al. [6] (1/32 sample rate, fine-tuned) 86.1 89.2 0.008 0.021 68.5 80.3 0.041 0.053 Bertasius et al. [6] (1/8 sample rate, fine-tuned) 83.4 90.6 0.009 0.023 64.1 75.4 0.040 0.050 Bertasius et al. [6] (1/4 sample rate, fine-tuned) 78.5 89.2 0.006 0.018 61.9 75.4 0.040 0.057</figDesc><table><row><cell></cell><cell cols="2">Validation</cell><cell></cell><cell>Test</cell></row><row><cell>Method</cell><cell>AUC</cell><cell>RBDC TBDC</cell><cell>AUC</cell><cell>RBDC TBDC</cell></row><row><cell></cell><cell>Micro Macro</cell><cell></cell><cell>Micro Macro</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>MethodAvenueShanghaiTech RBDC TBDC RBDC TBDC Liu et al. [30] 19.59 * 56.01 * 17.03 * 54.23 * Ionescu et al. [21] 15.77 * 27.01 * 20.65 * 44.54 * Ramachandra et al. [43] 35.80 80.90 --Ramachandra et al. [44] 41.20 78.60 --Georgescu et al. [18] 65.05 66.95 41.34 78.79 [17] 57.00 58.30 42.80 83.90 [17] + T5 (ours) 58.69 59.84 44.30 84.56 [17] + T5 + CycleGAN (ours) 61.10 61.38 47.15 86.15</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Detailed statistics for the UBnormal data set. Our videos are generated at 30 FPS.</figDesc><table><row><cell></cell><cell cols="3">Training Validation Test</cell><cell>Total</cell></row><row><cell>#anomalies</cell><cell>195</cell><cell>76</cell><cell>389</cell><cell>660</cell></row><row><cell>#abnormal frames</cell><cell>25,227</cell><cell cols="3">13,938 49,850 89,015</cell></row><row><cell>#normal frames</cell><cell>90,860</cell><cell cols="3">14,237 42,790 147,887</cell></row><row><cell>#abnormal minutes</cell><cell>14.02</cell><cell cols="2">7.74 27.69</cell><cell>49.45</cell></row><row><cell>#normal minutes</cell><cell>50.48</cell><cell cols="2">7.91 23.77</cell><cell>82.16</cell></row><row><cell>#videos</cell><cell>268</cell><cell>64</cell><cell>211</cell><cell>543</cell></row><row><cell>#abnormal regions</cell><cell>38,048</cell><cell cols="3">21,321 82,738 142,107</cell></row><row><cell>#unique objects</cell><cell>1,443</cell><cell cols="2">351 1,114</cell><cell>2,908</cell></row><row><cell>avg. objects / frame</cell><cell>4.58</cell><cell>4.53</cell><cell>4.24</cell><cell>4.44</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The research leading to these results has received funding from the EEA Grants 2014-2021, under Project contract no. EEA-RO-NO-2018-0496. This article has also benefited from the support of the Romanian Young Academy, which is funded by Stiftung Mercator and the Alexander von Humboldt Foundation for the period 2020-2022.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust Real-Time Unusual Event Detection Using Multiple Fixed-Location Monitors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilan</forename><surname>Shimshoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daviv</forename><surname>Reinitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Video parsing for abnormality detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borislav</forename><surname>Antic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="2415" to="2422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning memory-guided normality for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><surname>Astrid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Zaigham</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae-Yeong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung-Ik</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Synthetic Temporal Anomaly Guided End-to-End Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><surname>Astrid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Zaigham</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung-Ik</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCVW</title>
		<meeting>ICCVW</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="207" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evidential deep learning for open set action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Kong</surname></persName>
		</author>
		<idno>2021. 4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<biblScope unit="page" from="13349" to="13358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Is Space-Time Attention All You Need for Video Understanding?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gedas</forename><surname>Bertasius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Torresani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Video anomaly detection with spatio-temporal dissociation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shifu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haigang</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adversarial Reciprocal Points Learning for Open Set Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peixi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangqian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="issue">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Video anomaly detection and localization using hierarchical feature representation and Gaussian process regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yie-Tarng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Hsien</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sparse reconstruction cost for abnormal event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dual Discriminator Generative Adversarial Network for Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiushan</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="88170" to="88176" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Any-Shot Sequential Anomaly Detection in Surveillance Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keval</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasin</forename><surname>Yilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPRW</title>
		<meeting>CVPRW</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="934" to="935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Continual Learning for Anomaly Detection in Surveillance Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keval</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasin</forename><surname>Yilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPRW</title>
		<meeting>CVPRW</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="254" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Online Detection of Abnormal Events Using Incremental Coding Length</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jayanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonny</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MIST: Multiple Instance Self-Training Framework for Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Chang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fa-Ting</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Shi</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recent advances in open set recognition: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanxing</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheng-Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songcan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3614" to="3631" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Anomaly Detection in Video via Self-Supervised and Multi-Task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariana-Iuliana</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Barbalau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tudor</forename><surname>Radu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="12742" to="12752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Background-Agnostic Framework with Adversarial Training for Abnormal Event Detection in Video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariana</forename><forename type="middle">Iuliana</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Moussa Reda Mansour, Svetha Venkatesh, and Anton Van Den Hengel. Memorizing Normality to Detect Anomaly: Memory-Augmented Deep Autoencoder for Unsupervised Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingqiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vuong</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Budhaditya</forename><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1705" to="1714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning temporal regularity in video sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmudul</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghyun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Roy-Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Object-Centric Auto-Encoders and Dummy Anomalies for Abnormal Event Detection in Video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Radu Tudor Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariana-Iuliana</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="7842" to="7851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unmasking the abnormal events in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sorina</forename><surname>Radu Tudor Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Smeureanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Alexe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2895" to="2903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Detecting abnormal events in video using Narrowed Normality Clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sorina</forename><surname>Radu Tudor Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Smeureanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alexe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WACV</title>
		<meeting>WACV</meeting>
		<imprint>
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">TAM-Net: Temporal Enhanced Appearance-to-Motion Generative Network for Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangli</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bairong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuesheng</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNN</title>
		<meeting>IJCNN</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Observe locally, infer globally: A space-time MRF for detecting abnormal activities with incremental updates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaechul</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">STAN: Spatio-temporal adversarial networks for abnormal event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Man</forename><surname>Hak Gu Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1323" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">BMAN: Bidirectional Multi-Scale Aggregation Networks for Abnormal Event Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Man</forename><surname>Hak Gu Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Decoupled appearance and motion learning for efficient anomaly detection in surveillance video. Computer Vision and Image Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Leroux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Simoens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">210</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Anomaly detection and localization in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Future Frame Prediction for Anomaly Detection -A New Baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongze</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="6536" to="6545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Classifier Two-Sample Test for Video Anomaly Detections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusha</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barnaba?s</forename><surname>P?czos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Hybrid Video Anomaly Detection Framework via Memory-Augmented Flow Reconstruction and Flow-Guided Frame Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongwei</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjiang</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiqing</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="13588" to="13597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Abnormal Event Detection at 150 FPS in MATLAB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2720" to="2727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Few-Shot Scene-Adaptive Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiwei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="125" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A Revisit of Sparse Coding Based Anomaly Detection in Stacked RNN Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="341" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Temporal Cues From Socially Unacceptable Trajectories for Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neelu</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arya</forename><surname>Farkhondeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamal</forename><surname>Nasrollahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Escalera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">B</forename><surname>Moeslund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCVW</title>
		<meeting>ICCVW</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2150" to="2158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Anomaly Detection in Crowded Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Xin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Viral Bhalodia, and Nuno Vasconcelos</title>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
	<note>Proceedings of CVPR</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Abnormal crowd behavior detection using social force model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramin</forename><surname>Mehran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="935" to="942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Anomaly detection in video sequence with appearance-motion correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Trong-Nguyen Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Self-trained Deep Ordinal Regression for End-to-End Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guansong</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12173" to="12182" />
		</imprint>
	</monogr>
	<note>Anton van den Hengel, and Xiao Bai</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning Memory-guided Normality for Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongyoun</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bumsub</forename><surname>Ham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="14372" to="14381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dance With Self-Attention: A New Look of Conditional Random Fields on Anomaly Detection in Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Didik</forename><surname>Purwanto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yie-Tarng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Hsien</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Street Scene: A new dataset and evaluation protocol for video anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharathkumar</forename><surname>Ramachandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WACV</title>
		<meeting>WACV</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2569" to="2578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning a distance function with a Siamese network to localize anomalies in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharathkumar</forename><surname>Ramachandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranga</forename><surname>Vatsavai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WACV</title>
		<meeting>WACV</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2598" to="2607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Perceptual metric learning for video anomaly detection. Machine Vision and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharathkumar</forename><surname>Ramachandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranga Raju</forename><surname>Vatsavai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A Survey of Single-Scene Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharathkumar</forename><surname>Ramachandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranga Raju</forename><surname>Vatsavai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Plug-and-Play CNN for Crowd Motion Analysis: An Application in Abnormal Event Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdyar</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moin</forename><surname>Nabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enver</forename><surname>Sangineto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WACV</title>
		<meeting>WACV</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Abnormal Event Detection in Videos using Generative Adversarial Nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdyar</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moin</forename><surname>Nabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enver</forename><surname>Sangineto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucio</forename><surname>Marcenaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Regazzoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICIP</title>
		<meeting>ICIP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.02767</idno>
		<title level="m">YOLOv3: An incremental improvement</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Unsupervised Behavior-Specific Dictionary Learning for Abnormal Event Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Huamin Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Soren Ingvor Olsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">B</forename><surname>Escalera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moeslund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deep-Cascade: Cascading 3D Deep Neural Networks for Fast Anomaly Detection and Localization in Crowded Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmood</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Klette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Deep Appearance Features for Abnormal Behavior Detection in Video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sorina</forename><surname>Smeureanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tudor</forename><surname>Radu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alexe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICIAP</title>
		<meeting>ICIAP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">10485</biblScope>
			<biblScope unit="page" from="779" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Real-World Anomaly Detection in Surveillance Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waqas</forename><surname>Sultani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="6479" to="6488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Scene-Aware Context Reasoning for Unsupervised Abnormal Event Detection in Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Che</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunde</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACMMM</title>
		<meeting>ACMMM</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="184" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">X-MAN: Explaining Multiple Sources of Anomalies in Video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Szymanowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPRW</title>
		<meeting>CVPRW</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3224" to="3232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Integrating prediction and reconstruction for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="123" to="130" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Weakly-Supervised Video Anomaly Detection With Robust Temporal Feature Magnitude Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guansong</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajvinder</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><forename type="middle">W</forename><surname>Verjans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Learning Spatiotemporal Features with 3D Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Du</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lubomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paluri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4489" to="4497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Robust Anomaly Detection in Videos Using Multilevel Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trung</forename><surname>Tu Dinh Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5216" to="5223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Cluster Attention Contrast for Video Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexian</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACMMM</title>
		<meeting>ACMMM</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2463" to="2471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2609" to="2622" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Detecting Anomalous Events in Videos by Learning Deep Representations of Appearance and Motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Bidirectional retrospective generation adversarial network for anomaly detection in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="107842" to="107857" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Cloze Test Helps: Effective Video Anomaly Detection via Learning to Complete Video Events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiping</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">En</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanfu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACMMM</title>
		<meeting>ACMMM</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="583" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Abnormal event detection and localization via adversarial event prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongmin</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Younkwan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kin</forename><forename type="middle">Choong</forename><surname>Yow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moongu</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Witold</forename><surname>Pedrycz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Old is Gold: Redefining the Adversarially Learned One-Class Classifier Training Paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Ha</forename><surname>Muhammad Zaigham Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung-Ik</forename><surname>Astrid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">CLAWS: Clustering Assisted Weakly Supervised Learning with Normalcy Suppression for Anomalous Event Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arif</forename><surname>Muhammad Zaigham Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung-Ik</forename><surname>Astrid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Video Anomaly Detection and Localization using Motion-field Shape Description and Homogeneity Testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiulong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weishan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Video anomaly detection based on locality sensitive hashing filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huchuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shun</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Online Detection of Unusual Events in Videos via Dynamic Sparse Coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="3313" to="3320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Graph Convolutional Label Noise Cleaner: Train a Plug-And-Play Action Classifier for Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Xing</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycleconsistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
