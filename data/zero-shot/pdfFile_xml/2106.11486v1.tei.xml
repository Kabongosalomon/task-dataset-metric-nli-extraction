<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Embedding Adaptation via Early-Stage Feature Reconstruction for Few-Shot Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><forename type="middle">Hoon</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sae-Young</forename><surname>Chung</surname></persName>
						</author>
						<title level="a" type="main">Unsupervised Embedding Adaptation via Early-Stage Feature Reconstruction for Few-Shot Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose unsupervised embedding adaptation for the downstream few-shot classification task. Based on findings that deep neural networks learn to generalize before memorizing, we develop Early-Stage Feature Reconstruction (ESFR) -a novel adaptation scheme with feature reconstruction and dimensionality-driven early stopping that finds generalizable features. Incorporating ESFR consistently improves the performance of baseline methods on all standard settings, including the recently proposed transductive method. ESFR used in conjunction with the transductive method further achieves state-of-the-art performance on mini-ImageNet, tiered-ImageNet, and CUB; especially with 1.2%?2.0% improvements in accuracy over the previous best performing method on 1-shot setting. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep learning has achieved impressive results on visual recognition tasks. However, it still has difficulty generalizing to novel classes with few examples; while humans can learn to recognize from few experiences. Few-shot classification <ref type="bibr" target="#b33">(Miller et al., 2000;</ref><ref type="bibr" target="#b50">Vinyals et al., 2016;</ref><ref type="bibr" target="#b38">Ravi &amp; Larochelle, 2017)</ref> is designed to bridge the gap between the two and has recently attracted substantial attention.</p><p>Several works <ref type="bibr" target="#b18">Hou et al., 2019;</ref><ref type="bibr" target="#b37">Qiao et al., 2019;</ref><ref type="bibr" target="#b21">Hu et al., 2020;</ref><ref type="bibr" target="#b10">Dhillon et al., 2020;</ref><ref type="bibr" target="#b56">Ziko et al., 2020;</ref><ref type="bibr" target="#b6">Boudiaf et al., 2020)</ref> have shown the effectiveness of transductive methods in few-shot classification, showing a significant improvement over inductive methods. While test samples are inaccessible in an inductive few-shot classification setting, one can utilize all the unlabeled test samples together to make an inference in a transductive 1 School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea. Correspondence to: Dong Hoon Lee &lt;donghoonlee@kaist.ac.kr&gt;.</p><p>Proceedings of the 38 th International Conference on Machine Learning, PMLR 139, 2021. Copyright 2021 by the author(s). <ref type="bibr">1</ref> Code is available at https://github.com/movinghoon/ESFR setting. The co-existence of labeled-and unlabeled-data in this setting motivates the use of transductive inference or semi-supervised learning. A popular transductive approach is pseudo-label-based methods that progressively update the labels or inference models by predicted test samples. For instance, <ref type="bibr" target="#b30">Liu et al. (2019)</ref>; <ref type="bibr" target="#b24">Kim et al. (2019)</ref> use a neighbor graph for label propagation, <ref type="bibr" target="#b18">Hou et al. (2019)</ref>; <ref type="bibr" target="#b29">Liu et al. (2020)</ref> use predicted labels on test samples to update the class prototypes, and <ref type="bibr" target="#b4">Antoniou &amp; Storkey (2019)</ref>; <ref type="bibr" target="#b21">Hu et al. (2020)</ref> use prediction to produce an intrinsic loss or synthetic gradient. Another line of works utilizes regularization terms on unlabeled test samples. To list a few, <ref type="bibr" target="#b10">Dhillon et al. (2020)</ref>; <ref type="bibr" target="#b6">Boudiaf et al. (2020)</ref> use entropy minimization of the prediction on unlabeled data, <ref type="bibr" target="#b56">Ziko et al. (2020)</ref> uses the Laplacian regularization term for graph clustering. These methods are mostly originated from semi-supervised learning studies; approaches in semi-supervised learning are still motivating few-shot classification research.</p><p>On the other hand, semi-supervised learning research has recently benefited from unsupervised learning. Rapidly advancing self-supervised learning methods <ref type="bibr" target="#b7">(Caron et al., 2020;</ref><ref type="bibr" target="#b16">Grill et al., 2020;</ref><ref type="bibr" target="#b8">Chen et al., 2020)</ref> have shown strong performance on semi-supervised image classification tasks. A popular approach is to use a self-supervision loss for representation learning to acquire more general features. Learned representations are then used with fine-tuning <ref type="bibr" target="#b7">(Caron et al., 2020;</ref><ref type="bibr" target="#b16">Grill et al., 2020;</ref><ref type="bibr" target="#b8">Chen et al., 2020)</ref> or other semisupervised learning methods <ref type="bibr" target="#b55">(Zhai et al., 2019;</ref><ref type="bibr" target="#b23">Kim et al., 2021)</ref> for downstream tasks. These studies achieved stateof-the-art performance on semi-supervised learning tasks, especially in settings with extremely few labels.</p><p>The success of unsupervised learning on semi-supervised tasks suggests the potential benefit of finding shared features or patterns without labels in relevant research areas. In fewshot classification, several works <ref type="bibr" target="#b46">Su et al., 2020)</ref> use additional self-supervision loss during the training of base datasets to learn more general features. However, the use of unsupervised learning on unlabeled data that appears in test-time is less studied. In this work, we study unsupervised learning for adaptation to satisfy the thirst.</p><p>arXiv:2106.11486v1 [cs.CV] 22 Jun 2021</p><p>Our contributions are summarized as follows:</p><p>? We find that early generalized features during unsupervised training are valuable for recognizing novel classes of few-shot classification. Based on recent studies of deep neural network's training dynamics, we explain the finding with experiments. (Section 3.1)</p><p>? Based on the finding, we construct a novel embedding adaptation scheme with (1) feature reconstruction training and (2) dimensionality-driven early stopping. Our method provides task-adapted embeddings composed of desirable-shared features, which are more likely to be task-relevant and valuable for the few-shot classification. Our method is used as a plug-and-play module for few-shot methods. (Section 3.3)</p><p>? We test our method, ESFR, used in conjunction with baseline methods in the standard few-shot classification benchmarks. ESFR consistently improves the performance of baselines; adding ESFR to the transductive method achieves the state-of-the-art performance on mini-ImageNet, tiered-ImageNet, and CUB. Particularly in the scarce-label setting of 1-shot, our method outperforms the previous state-of-the-art with accuracies of 1.2%?2.0%. (Section 5.3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Problem Setting</head><p>In a few-shot classification task, a small labeled support</p><formula xml:id="formula_0">set S = {(x i s , y i s )} |S| i=1 and unlabeled query set Q = {(x i q , )} |Q| i=1</formula><p>are given. 2 Both support samples and query samples are from the same novel classes that are never seen during training. The goal of few-shot classification is to classify query (test) samples by few examples in the support set. In the usual setting, the support set has K = 1 or 5 examples per N = 5 novel classes, and we call this an N -way K-shot problem.</p><p>We address a transductive few-shot classification task where all query samples are accessible. Since learning from few samples without prior is extremely hard, we use a pretrained embedding network f that is trained on the base dataset as in <ref type="bibr" target="#b41">Rusu et al. (2019)</ref>; <ref type="bibr" target="#b51">Wang et al. (2019)</ref>; <ref type="bibr" target="#b21">Hu et al. (2020)</ref>; <ref type="bibr" target="#b56">Ziko et al. (2020)</ref>. We denote</p><formula xml:id="formula_1">S f = {(f (x i s ), y i s )} |S| i=1 and Q f = {(f (x i q ), ?)} |Q| i=1</formula><p>as the support set and the query set in the embedding domain, respectively. Our interest is in task-adapted embeddings (representations) that are useful in the given few-shot task. We construct the embeddings with a module g ? on top of f by training on the union of the support set and query set.</p><p>2 (x, y) denotes an image and its label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Local Intrinsic Dimensionality (LID)</head><p>We briefly explain LID that our method uses as early stopping criterion. LID is a statistical version of an expansionbased Intrinsic Dimension (ID) that provides an estimated subspace dimension of local regions. Recently, substantial redundant dimensions of modern deep neural networks lead to the wide use of ID and LID to track and analyze training <ref type="bibr" target="#b2">(Amsaleg et al., 2017;</ref><ref type="bibr" target="#b31">Ma et al., 2018a;</ref><ref type="bibr" target="#b3">Ansuini et al., 2019;</ref><ref type="bibr" target="#b15">Gong et al., 2019)</ref>. The formal definition of LID is given as <ref type="bibr" target="#b1">(Amsaleg et al., 2015;</ref><ref type="bibr">Houle, 2017a;</ref>:</p><p>Definition 1 (Local Intrinsic Dimensionality). Given a data point x, let r &gt; 0 be a continuous random distance variable from x. For the cumulative density function F x (r), the LID of x at distance r is defined as:</p><formula xml:id="formula_2">LID(r; F x ) def = lim ?0 + ln F x ((1 + )r) ? ln F x (r) ln(1 + ) ,<label>(1)</label></formula><p>whenever the limit exists. The LID at x is then defined as the limit of distance r ? 0 + :</p><formula xml:id="formula_3">LID(x) def = lim r?0 + LID(r; F x ).</formula><p>(2)</p><p>Since the density function of the distance variable is usually unknown, the exact value of LID is hard to acquire. We use the maximum likelihood estimation by <ref type="bibr" target="#b1">Amsaleg et al. (2015)</ref> to calculate the LID estimates as follows:</p><formula xml:id="formula_4">LID(x) = ? 1 m m i=1 ln r i (x) r m (x) ?1 ,<label>(3)</label></formula><p>where r i (x) indicates the distance 3 between x and its i-th nearest neighbor. The number of the nearest neighbor m should be chosen appropriately to make estimation local but stabilized. <ref type="bibr">4</ref> We refer to <ref type="bibr" target="#b1">Amsaleg et al. (2015)</ref>; <ref type="bibr">Houle (2017a;</ref> for more details about LID and its estimation methods. <ref type="figure">Figure 1</ref> illustrates the usage and overview of our method. As a plug-and-play module, our method provides taskadapted embeddings to other few-shot classification methods. Our method is mainly composed of feature reconstruction training and LID-based early stopping. We will explain feature reconstruction training (Section 3.1); LIDbased early stopping (Section 3.2); the overall method (Section 3.3), in the following.  <ref type="figure">Figure 1</ref>. Overview of our method. 1-(a) shows the case without embedding adaptation, and 1-(b) shows the case with embedding adaptation. Our scheme mainly consists of feature reconstruction training and dimensionality-driven early stopping, and provides new embeddings of generalizable features for the downstream few-shot task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Feature Reconstruction</head><p>Our main idea is based on the findings that deep neural networks learn to generalize before memorizing to abstract task-useful features. We design feature-level reconstruction training, which is unsupervised learning and builds on prior knowledge given by embeddings. As mentioned before, unsupervised learning for few-shot adaptation tends to have less attention; and we find that naively applied unsupervised learning for few-shot adaptation often fails. 5 Moreover, the behavior of unsupervised learning with a pre-trained embedding network is often ambiguous. For instance, contrastive learning heavily relies on augmentations, while augmentations affect embeddings differently depending on how the embedding network is pre-trained. Instead, we find that our feature reconstruction training can be used to adapt embeddings for few-shot classification.</p><p>We explain our feature reconstruction training. For a fewshot classification task with embedding support set S f and query set Q f ; we train a reconstruction module g ? using the following feature level reconstruction loss:</p><formula xml:id="formula_5">L(?) = 1 |S f ? Q f | z?S f ?Q f d cos (z, g ? (z)),<label>(4)</label></formula><p>where d cos denotes the cosine distance. Both z and g ? (z) are preprocessed 6 embeddings, but their expressions are omitted for notational simplicity. We note that for a newly given fewshot classification task, the weight ? of the reconstruction module is randomly re-initialized.</p><p>We investigate the behavior of reconstruction modules during feature reconstruction training w.r.t. the downstream  <ref type="figure">Figure 2</ref>. Few-shot classification accuracy with A0, A1, and B1 during feature reconstruction training. We use ResNet-18 backbone, mini-ImageNet dataset, and nearest neighbor classifier. For g ? 1 , we use a 4-layer neural network with 256-128-256-512 units. Other settings are described in the experiment section. (left) shows the accuracy on 1-shot and (right) shows the accuracy on 5-shot setting.</p><p>few-shot task. We train two types of reconstruction modules, g ?1 with compressed (bottleneck) hidden layer as in conventional auto-encoders, and g ?2 ; without compression. We evaluate few-shot classification accuracy with three embeddings A0, A1, B1; where A0 is the middle compressed hidden layer output of g ?1 ; A1 and B1 are the reconstructed output of g ?1 and g ?2 , respectively. <ref type="figure">Figure 2</ref> shows an interesting behavior that few-shot classification accuracies, with embeddings of reconstruction modules, initially increase then decrease. Moreover, the peak accuracy of B1 exceeds the baseline accuracy of the original embedding, on both 1-and 5-shot settings. We believe that recent studies of Deep Neural Networks (DNNs) explain such behavior. Several works <ref type="bibr" target="#b5">(Arpit et al., 2017;</ref><ref type="bibr" target="#b26">Lampinen &amp; Ganguli, 2019;</ref><ref type="bibr">Stephenson et al., 2021)</ref> observe a property that DNNs learn to generalize before memorizing. To be more specific, <ref type="bibr" target="#b5">Arpit et al. (2017)</ref> reports that DNNs learn patterns first before memorization, with experiments on the mixture of well-structured real data and noisy data. Further research <ref type="bibr" target="#b26">Lampinen &amp; Ganguli (2019)</ref>; <ref type="bibr">Stephenson et al. (2021)</ref> provide analytical explanations on the property that learning speeds between generalization of patterns and memorization of noise are different. <ref type="bibr">7</ref> We argue that the behavior, shown in <ref type="figure">Figure 2</ref>, is a result of the DNNs' property. By the property, reconstruction modules learn shared features faster since they form certain patterns or correlations among data, while non-shared features are learned later since they are less generalizable. Generalizable shared features are more likely to be task-relevant in classification; the difference in learning speeds between shared features and non-shared features explains the initial increase of accuracies.</p><p>Our main idea is to use the behavior shown in <ref type="figure">Figure 2</ref> for embedding adaptation. The behavior provides an opportunity to achieve improved few-shot classification performance by acquiring new embeddings of generalized features. To do this, we find that non-compressed and non-encoded embedding (B1) performs the best. Throughout the rest of our work, we use the reconstructed output g ? that is noncompressed as task-adapted embeddings.  <ref type="figure">Figure 3</ref>. The figure shows the accuracy and the LID curve during feature reconstruction training, with (Acc:dropout, LID:dropout) and without (Acc, LID) dropout perturbation. We use the same setting as in <ref type="figure">Figure 2</ref>. The vertical lines indicate the maximum accuracy (blue) and the minimum LID (red) points; for 1-shot, they are overlapped. (left) shows the results in the 1-shot and (right) shows the results in the 5-shot setting.</p><p>We propose to perturb the training to further discard the nonshared features. Perturbation with noise does not form generalizable patterns or correlations; thus, perturbation tends to make training harder for less generalizable non-shared features while shared features are still learnable by pattern learning. While additive perturbation is hard to design, due to the unknown distribution of z, we find that multiplicative perturbation by dropout <ref type="bibr" target="#b44">(Srivastava et al., 2014)</ref> is well suited for our purpose. Our feature reconstruction training 7 Generalization is faster than memorization. with input dropout uses the following loss function 8 : <ref type="formula">(5)</ref> where ? is a multiplicative noise implemented with dropout. <ref type="figure">Figure 3</ref> shows the effect of dropout on the training curve; we can observe that the dropout perturbation results in higher peak accuracies.</p><formula xml:id="formula_6">L FR (?) = 1 |S f ? Q f | z?S f ?Q f E ? [d cos (z, g ? (z ??))],</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Dimensionality Driven Early Stopping</head><p>Utilization of early retained generalizable features seems a promising idea for the downstream few-shot classification. However, determining the optimal early stopping time is not straightforward. Here, we suggest using Local Intrinsic Dimensionality (LID) as an early stopping criterion. Recent work by <ref type="bibr" target="#b32">Ma et al. (2018b)</ref> used LID to monitor the internal generalization and memorization during training. They argued that LID tends to decrease while DNNs learn to generalize, due to summarizing effect; LID tends to increase while memorizing, as DNNs try to encode detailed information individually. We observe the tendency in our reconstruction training, and we find that LID can be used as an early stopping criterion.</p><p>For a given few-shot classification task with embedding support set S f and query set Q f , we use estimated LID, with reconstruction module g ? , given as:</p><formula xml:id="formula_7">LID(?) = z?S f ?Q f LID(g L?2 ? (z)) = ? z?S f ?Q f 1 m m i=1 ln r i (g L?2 ? (z)) r m (g L?2 ? (z)) ?1 ,<label>(6)</label></formula><p>where g L?2 ? is the hidden representation of the second-tolast layer of g ? ; r i (g L?2 ? (z)) denotes the Eucidean distance between g L?2 ? (z) and its i-th nearest neighbor in</p><formula xml:id="formula_8">{g L?2 ? (z )|z ? S f ? Q f }. Our LID(?)</formula><p>is a proxy for the hidden layer subspace dimensionality of the reconstruction module.</p><p>In <ref type="figure">Figure 3</ref>, we empirically investigate the relationship between the LID and accuracy during reconstruction training. The result shows that the change of LID can be used to find the early stopping time of the best possible new embeddings; when the LID becomes the lowest or starts to increase. To be more specific, in 1-shot settings, we observe that the LID behaves exactly the opposite of the accuracy curve, for both with and without dropout. For 5-shot settings, the LID behaves almost the opposite of the accuracy curve; however, it has a small misalignment, especially for the case Algorithm 1 ESFR Input: embedding support set S f , embedding query set Q f , and few-shot classifier Alg :</p><formula xml:id="formula_9">S f , Q f ? Y Q Initialize: ? i=1:Ne for i = 1 to N e do prev lid = LID(? i 0 ) Initialize: optimizer for j = 0 to MAX ITERATION do ? i j+1 ? ? i j ? ? ? i j L(? i j ) from equation 5 or 7 lid = LID(? i j+1 ) if lid &gt; prev lid then ? i * = ? i j+1 break end if prev lid = lid end for end for S ESFR = {(z , y)|z = 1 Ne Ne i=1 g ? i * (z), (z, y) ? S f } Q ESFR = {z |z = 1 Ne Ne i=1 g ? i * (z), z ? Q f } Output: Y Q = Alg(S ESFR , Q ESFR )</formula><p>with dropout. This seems reasonable since the classifier can further filter out non-shared features by multiple examples of novel classes in 5-shot settings; hence acquiring more shared features at the cost of learning non-shared ones can be advantageous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Proposed Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ESFR:</head><p>We describe our unsupervised adaptation scheme for few-shot classification: Early-Stage Feature Reconstruction (ESFR). Given a few-shot classification task and embedding network, we run feature reconstruction training by L FR (5) with initialized ?. At every training iteration, we measure the LID of g ? with task samples by <ref type="formula" target="#formula_7">(6)</ref> and we early stop the training when the LID starts to increase. Task-adapted embeddings of g ? (z) are used for the classification of the given few-shot task. A wide range of metric-based and finetuning few-shot methods can be used with our embeddings for such classification. To reduce the variance by random initial weights of ?, we train N e reconstruction modules, separately, with different initial weights, and take the center of each sample's reconstructed embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ESFR-Semi:</head><p>We further investigate the semi-supervised version of our scheme, ESFR-Semi, by adding the support classification loss to the reconstruction loss (5):</p><formula xml:id="formula_10">C j (z, ?, W, b) = softmax j [W g ? (z) + b] L CE (?, W, b) = ? 1 |S f | (zi,yi)?S f log C yi (z i , ?, W, b) L Semi (?, W, b) = L FR (?) + ?L CE (?, W, b)<label>(7)</label></formula><p>where L CE is the cross-entropy loss given by an affine classifier on new embeddings, and ? is a trade-off parameter. Additional weights W and b are jointly trained with ?. The trade-off parameter ? is tuned using few-shot classification tasks from validation datasets as in <ref type="bibr" target="#b56">Ziko et al. (2020)</ref>. Note that the only ESFR-Semi requires (while ESFR does not) few-shot classification task experiences to determine a certain parameter.</p><p>The overall methods are described in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Work</head><p>Few-Shot Classification (FSC): Few-shot learning or few-shot classification methods have broad categories: optimization-based methods <ref type="bibr" target="#b38">(Ravi &amp; Larochelle, 2017;</ref><ref type="bibr" target="#b11">Finn et al., 2017;</ref><ref type="bibr" target="#b41">Rusu et al., 2019)</ref>, distance-based approaches <ref type="bibr" target="#b50">(Vinyals et al., 2016;</ref><ref type="bibr" target="#b42">Snell et al., 2017;</ref><ref type="bibr" target="#b35">Oreshkin et al., 2018)</ref>, fine-tunings <ref type="bibr" target="#b49">Tian et al., 2020;</ref><ref type="bibr" target="#b10">Dhillon et al., 2020)</ref>, etc. A large portion of these methods is based on meta-learning <ref type="bibr" target="#b48">(Thrun &amp; Pratt, 2012)</ref>. In meta-learning, training is done in a series of few-shot classification tasks (a.k.a. episodic training) to train the model in a way that reflects test-time scenarios. Several recent studies <ref type="bibr" target="#b49">Tian et al., 2020;</ref><ref type="bibr" target="#b10">Dhillon et al., 2020;</ref><ref type="bibr" target="#b56">Ziko et al., 2020;</ref><ref type="bibr" target="#b6">Boudiaf et al., 2020)</ref> have questioned the necessity of meta-learning on few-shot classification, reporting competitive performance on few-shot benchmarks without neither episodic training nor few-shot task experiences. These methods solve the few-shot task by fine-tuning 9 a pretrained embedding network trained on the base dataset with standard cross-entropy loss. Our method lies in this line of research that doesn't require meta-learning. It seems possible to merge our method with meta-learning; we leave it as future work. Unsupervised adaptation for FSC: We mentioned in the introduction that transductive methods, based on semi-supervised learning techniques, have been widely studied in few-shot classification. In contrast, unsupervised adaptation for few-shot classification is an open field. To the best of our knowledge, we are the first to propose deep unsupervised adaptation for few-shot classification. The closest related works are <ref type="bibr" target="#b40">Rodr?guez et al. (2020)</ref> and <ref type="bibr" target="#b28">Lichtenstein et al. (2020)</ref>. Embedding Propagation proposed by <ref type="bibr" target="#b40">Rodr?guez et al. (2020)</ref> iteratively updates embeddings by a linear combination with the nearest neighbors' embeddings and improves few-shot classification performance. <ref type="bibr" target="#b28">Lichtenstein et al. (2020)</ref> uses the principal component analysis to acquire major components from given task embeddings; this classical approach shows impressive performance gain. However, these works are limited to an affine transformation of embeddings and do not benefit from deep learning; while our method finds non-linear patterns and correlations by the benefit of deep unsupervised learning. Though unsupervised adaptation in few-shot classification had less attention, our experimental results show that it can outperform conventional transductive baselines, especially when extremely few labeled samples are available in the 1-shot setting. Training behavior of DNNs: Our method is based on the property of Deep Neural Networks' (DNNs) training behavior that DNNs learn to generalize before memorizing.</p><p>The property is reported and studied in recent works <ref type="bibr" target="#b5">(Arpit et al., 2017;</ref><ref type="bibr" target="#b26">Lampinen &amp; Ganguli, 2019;</ref><ref type="bibr">Stephenson et al., 2021)</ref>, as mentioned in Section 3.1. Similar to our work, several methods of training DNNs with noisy labels are based on different training behaviors between generalization and memorization. After the report of the property by <ref type="bibr" target="#b5">Arpit et al. (2017)</ref>, several works <ref type="bibr" target="#b17">(Hendrycks et al., 2019;</ref><ref type="bibr" target="#b36">Oymak et al., 2019;</ref><ref type="bibr" target="#b43">Song et al., 2020)</ref> suggest using early stopping to discard noisy information before memorization, <ref type="bibr" target="#b22">Jiang et al. (2018)</ref>; <ref type="bibr" target="#b54">Yu et al. (2019)</ref>; <ref type="bibr" target="#b47">Sugiyama (2018)</ref> propose to gather the clean samples that exhibit high confident prediction in the early pattern learning for further training. <ref type="bibr" target="#b32">Ma et al. (2018b)</ref> offer to use LID to detect and correct noisy label memorization, which strongly motivates our methodology. However, these works are limited to the domain of learning from noisy labels and supervised learning. In our work, we find the behavior also appears in unsupervised adaptation for few-shot classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Settings</head><p>Datasets: We evaluate our method on three standard datasets of few-shot classification: (1) mini-ImageNet <ref type="bibr" target="#b50">(Vinyals et al., 2016)</ref> dataset as in <ref type="bibr" target="#b38">Ravi &amp; Larochelle (2017)</ref>, (2) tiered-ImageNet dataset as in <ref type="bibr" target="#b39">Ren et al. (2018)</ref>, and (3) Caltech-UCSD Birds 200 (CUB) <ref type="bibr">(Welinder et al., 2010)</ref> as in <ref type="bibr" target="#b9">Chen et al. (2019)</ref>. Each dataset is divided into train/val/test splits according to references. All the images are resized to 84 ? 84.</p><p>Baseline Methods: We investigate three baseline few-shot classification methods (classifiers) used in conjunction with our method.</p><p>? Linear: Train an affine classifier on labeled support set with embeddings and use the trained classifier to classify the query samples.</p><p>? Nearest Neighbor (NN): Compute the class prototype by the centroid of support sample embeddings in each class and classify the query sample to the class of the nearest prototype. 10</p><p>? BD-CSPN: BD-CSPN <ref type="bibr" target="#b29">(Liu et al., 2020)</ref> is chosen as a baseline transductive method. It can be used with pre- <ref type="bibr">10</ref> We use Euclidean as a distance metric.</p><p>trained embeddings and achieves state-of-the-art performance on 5-shot <ref type="table">(Table 2)</ref>. To briefly summarize, BD-CSPN consists of two components: (1) shifting-term for removing the cross-class bias between the support set and query set, (2) Prototype Rectification (PR) that updates class prototypes by accounting pseudo-labeled query samples. Our particular interest is in PR since it is a baseline approach of transductive methods; a similar scheme was suggested in <ref type="bibr" target="#b39">Ren et al. (2018)</ref>; <ref type="bibr" target="#b18">Hou et al. (2019)</ref>.</p><p>Evaluation Protocol: We evaluate our method on standard 5-way 1-and 5-shot settings with 15 query samples per class. We sampled 2,000 tasks for each experimental result. Our method uses the same fixed hyper-parameters for all experiments and settings. For the semi-supervised version of our method, with trade-off parameter ?, we tune ? by selecting the best among ? ? [0, 0.1, 0.2, 0.4, 0.8, 1.6] from 600 sampled few-shot tasks of validation dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Implementation Details</head><p>Embedding Network: We follow the embedding network training procedure from <ref type="bibr" target="#b56">Ziko et al. (2020)</ref>, using backbone architectures: ResNet-18, WRN-28-10. We use from input to the average-pooled last residual block output as an embedding network. Embedding networks are trained for 90 epochs, using stochastic gradient descent to minimize the standard cross-entropy on labeled base datasets. Label smoothing with parameter 0.1 is used for more general features. Random cropping, color jittering, and random horizontal flipping are applied for data augmentation. <ref type="bibr">11</ref> The initial learning rate is 0.1 and shrank by 1 10 at 45 and 66 epochs. Mini-batch sizes of 256 and 128 are used for ResNet-18 and WRN-28-10 training, respectively. The best performing embedding network on the 5-way 1-shot task of validation split dataset is chosen; while using the nearest neighbor classifier and l2-normalized embeddings for classification.</p><p>Reconstruction Training: For the reconstruction module, we use 4-layer fully connected deep neural network with ReLU activation. Each layer has the size of units equal to the embedding dimension, and weight initialization follows the TensorFlow <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref> default setting (Gloro-tUniform). As an optimizer, we use Adam <ref type="bibr" target="#b25">(Kingma &amp; Ba, 2015)</ref> with a default learning rate of 1e-3. For dropout (Srivastava et al., 2014), we use the maximum possible rate of 0.5. Finally, we take the ensemble of N e = 5 reconstruction modules.</p><p>Preprocessing: <ref type="bibr" target="#b51">Wang et al. (2019)</ref> reports the importance of preprocessing in few-shot classification. We apply centering and l2-normalization to embedding network's output for reconstruction training and baseline methods. For centering, <ref type="table">Table 1</ref>. Improvement by incorporating our method into baseline methods with ResNet-18/WRN-28-10 backbone on mini-ImageNet and tiered-ImageNet. ? indicates the use of shifting-term <ref type="formula" target="#formula_11">(8)</ref>  we subtract the center of task sample embeddings from each embedding as in <ref type="bibr" target="#b28">Lichtenstein et al. (2020)</ref> since it performs better on all baseline methods. For BD-CSPN <ref type="bibr" target="#b29">(Liu et al., 2020)</ref>, the aforementioned shifting-term defined as:</p><formula xml:id="formula_11">= 1 |S| xs?S f (x s ) ? 1 |Q| xq?Q f (x q )<label>(8)</label></formula><p>is added for query sample before centering as in <ref type="bibr" target="#b56">Ziko et al. (2020)</ref>; <ref type="bibr" target="#b29">Liu et al. (2020)</ref>. For reconstruction training, when computing the reconstruction loss, output embeddings of the reconstruction module and the pre-trained embedding network follows the same preprocessing. For few-shot classification with new embeddings, we apply only l2-normalization since it performs the best. <ref type="bibr">12</ref> We refer to Appendix A for more details on preprocessing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Improvement by ESFR:</head><p>We validate the improvement of our method when used in conjunction with commonly used few-shot classification methods. We evaluate our method in the most common 5-way 1-and 5-shot settings on standard mini-ImageNet, tiered-ImageNet datasets with ResNet-18, WRN-28-10 backbone networks. The results are listed in <ref type="table">Table 1</ref>.</p><p>In <ref type="table">Table 1</ref>-(i, ii), we investigate our method with linear and NN classifiers. Each is a widely used baseline method in unsupervised representation learning and few-shot classification. Our method provides noticeable improvements in all settings; +5.9%?8.9% for 1-shot and +1.5%?3.1% for 5-shot settings. This roughly indicates that our embedding adaptation provides well-clustered new embeddings; hence samples can be classified by simple affine classifiers.</p><p>In <ref type="table">Table 1</ref>-(iii, iv), we compare our method with the semisupervised learning approach, Prototype-Rectification (PR) <ref type="bibr">12</ref> Note that applying only l2-normalization for baseline methods worsen the performance. <ref type="bibr" target="#b29">(Liu et al., 2020)</ref>. For a fair comparison, we use the same preprocessing with shifting-term (8) and cosine similaritybased nearest neighbor (CSPN) classifier as in BD-CSPN ? (which includes PR); the result is described as CSPN ? + ESFR. We can observe that ESFR further improves accuracies on 1-shot by +0.8%?2.1% compared to BD-CSPN ? while showing comparable improvements on 5-shot. This result implies that, though unsupervised adaptation has received less attention in few-shot classification, welldesigned unsupervised learning can provide comparable improvements to conventional transductive methods.</p><p>Performance can be further improved by incorporating our method into BD-CSPN, a transductive method. The result is described in <ref type="table">Table 1</ref> <ref type="bibr">-(iv)</ref>. For the 5-shot setting, there was no additional gain by combining our method; however, for the 1-shot setting, improvements of +2.9%?4.1% indicates that ESFR can offer a complementary improvement to PR.</p><p>In the last row of Table 1-(iv), we also investigate ESFRsemi that uses the semi-supervised loss L Semi (7) for embedding adaptation. As mentioned in Section 5.2, we chose the trade-off parameter ? that best performs with validation tasks. For the 1-shot setting, we find that ? = 0 performs the best that does not use label information during adaptation. For the 5-shot setting, ESFR-semi gives an additional +0.3%?0.8% gain over BD-CSPN.</p><p>Comparison with prior work: We compare our method with prior few-shot classification methods 13 on mini-ImageNet, tiered-ImageNet, and CUB datasets in <ref type="table">Table 2</ref>. We use BD-CSPN + ESFR and BD-CSPN + ESFR-Semi as our methods.</p><p>For the 1-shot setting, our method achieves new state-of-theart performance on all datasets and backbone networks. To be specific, our method outperforms the previous state-of- <ref type="table">Table 2</ref>. Comparison with state-of-the-art methods of 5-way 1-and 5-shot accuracy (in %) on mini-ImageNet, tiered-ImageNet and CUB. The best results are reported in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>mini-ImageNet tiered-ImageNet CUB Method</head><p>Backbone 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot MAML <ref type="bibr" target="#b11">(Finn et al., 2017)</ref> ResNet  the-art LaplacianShot  by +1.2%?2.0%. We note that our implementation is based on Laplacian-Shot; BD-CSPN + ESFR shares many aspects including the baseline method BD-CSPN and embedding network pre-training.</p><p>For the 5-shot setting, our method shows comparable performance to the state-of-the-art. Note that in <ref type="table">Table 1</ref>, CSPN + ESFR, which does not benefit from transductive inference, shows subequal performance with BD-CSPN + ESFR. For BD-CSPN + ESFR-Semi, our method provides further improvements of +0.3%?0.8%.</p><p>Ablation study: We conduct an ablation analysis on the effects of different components of the proposed method. We use a NN classifier with ResNet-18 backbone network for these experiments; our experimental results are on mini-ImageNet, tiered-ImageNet, and CUB with 5-way 1-and 5-shot tasks. <ref type="table" target="#tab_3">Table 3</ref> shows the influences of the embedding ensemble and dropout perturbation.</p><p>In Section 3.3, we proposed the embedding ensemble to reduce the variance by random initialization. The empirical result in <ref type="table" target="#tab_3">Table 3</ref>-(iii) shows that the ensemble consistently provides improvements in all settings. In Section 3.1, we expected the effectiveness of dropout perturbation since noise perturbations tend to make memorization harder. The result in <ref type="table" target="#tab_3">Table 3</ref>-(ii) shows consistent improvements by dropout; supports our expectation. Finally, we observe that the complete version with both the embedding ensemble and dropout perturbation outperforms the other configurations.</p><p>Comparison with prior embedding adaptation: We compare our method with prior embedding adaptation methods that are based on affine transformations: 1) Embedding Propagation (EP) from <ref type="bibr" target="#b40">Rodr?guez et al. (2020)</ref>, 2) Principal Component Analysis (PCA)-and Independent Component Analysis (ICA) 14 -based methods from <ref type="bibr" target="#b28">Lichtenstein et al. (2020)</ref>. For a fair comparison, we experiment with the same nearest neighbor classifier and pre-trained embeddings. We use the released official code of each method. <ref type="table" target="#tab_4">Table 4</ref> describes the results of 1-and 5-shot settings on mini-ImageNet with WRN backbone. Our method outperforms both <ref type="bibr" target="#b40">Rodr?guez et al. (2020)</ref> and <ref type="bibr" target="#b28">Lichtenstein et al. (2020)</ref> on all settings. Extracting shared or correlated features reminds us of the concept of PCA; however, compared to PCA, our method advantage from discovering non-linear patterns and correlates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We propose the novel unsupervised embedding adaptation scheme based on the finding that deep neural networks learn to generalize before memorizing. Our method, ESFR, provides task-adapted embeddings of generalizable features by feature reconstruction training and LID-based early stopping. Experimental results show that well-designed unsupervised adaptation can consistently improve baseline methods; outperform conventional transductive methods; be further improved by joint usage with a transductive method. ESFR used in conjunction with the transductive method achieves new state-of-the-art performance on the 1-shot setting. We hope that our work will become a starting point for future unsupervised learning studies on few-shot classification.  <ref type="bibr" target="#b6">(Boudiaf et al., 2020)</ref> of 5-way 1-and 5-shot accuracies (in %) on mini-ImageNet, tiered-ImageNet and CUB. The performance of TIM-GD is from the paper <ref type="bibr" target="#b6">(Boudiaf et al., 2020)</ref>. We use preprocessing with shifting-term to acquire new embeddings for TIM-GD + ESFR since it performs better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison to TIM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>mini-ImageNet tiered-ImageNet CUB Method</head><p>Backbone 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot TIM-GD <ref type="bibr" target="#b6">(Boudiaf et al., 2020)</ref>  We separately compare the performance of our method with TIM <ref type="bibr" target="#b6">(Boudiaf et al., 2020)</ref> since we believe TIM uses a strong prior that query samples per class are balanced in the standard few-shot classification benchmarks (e.g., 15-query samples per class); while our method combined with the baseline methods (NN, Linear, BD-CSPN <ref type="bibr" target="#b29">(Liu et al., 2020)</ref>) does not utilize any query statistics. We find that TIM's proposed regularization term with conditional entropy and label-marginal entropy forces balancing among the predicted number of query samples per class. To be specific, the conditional entropy minimization term encourages the classification model to output confident prediction and the label-marginal entropy maximization term encourages marginal predicted label distribution to be uniform. When both conditional and label-marginal entropy terms are used simultaneously, the predicted labels close to one-hot from uniform class distribution, resulting in the same number of predicted samples for each class. This seems helpful in the balanced query class distribution setting where all query samples per class are the same, but its possible use case will be limited. We find that query class imbalance setting can easily ruin TIM's performance in Section D.</p><p>To investigate our method when using query statistics, we experiment with TIM-GD + ESFR. <ref type="table" target="#tab_5">Table 5</ref> shows the results on standard mini-ImageNet, tiered-ImageNet, and CUB with 5-way 1-and 5-shot settings. For 1-shot settings, our method improves the performance of TIM by 1.5%?2.5% across all datasets and backbones. As mentioned before (in Section 5.3), this indicates that our method can offer a complementary improvement to semi-supervised learning techniques such as TIM for 1-shot. For 5-shot settings, our method decreases the performance by 0.4%?1.0%. The decrease in 5-shot performance encourages further research about the simultaneous use of pseudo-label information and unsupervised information, which we leave as future work. We further investigate the effect of the dropout noise level. In the main text, we argued that multiplicative noise by dropout seems well suited for our method. Experiments in <ref type="table" target="#tab_7">Table 6</ref> with various drop-rate show that the dropout can be used in our method without careful tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation: noise level of dropout</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Few-shot classification with imbalance query class distribution</head><p>To verify our method's robustness on various query settings, we experiment with the setting when the numbers of query samples per class are imbalanced. We set the number of query samples per class as <ref type="bibr">(11,</ref><ref type="bibr">13,</ref><ref type="bibr">15,</ref><ref type="bibr">17,</ref><ref type="bibr">19</ref>) and <ref type="bibr">(7,</ref><ref type="bibr">11,</ref><ref type="bibr">15,</ref><ref type="bibr">19,</ref><ref type="bibr">23)</ref>. <ref type="table" target="#tab_8">Table 7</ref> shows that our method consistently improves the performance of few-shot classification regardless of the query imbalance setting. To be more specific, the improvement by our method in different query settings varies within &lt; 1.5%; thus, our method is robust to different query settings. In contrast, TIM <ref type="bibr" target="#b6">(Boudiaf et al., 2020)</ref> that uses the strong prior about  <ref type="bibr">(15,</ref><ref type="bibr">15,</ref><ref type="bibr">15,</ref><ref type="bibr">15,</ref><ref type="bibr">15)</ref>. For the imbalance case, we set the number of query samples per class as <ref type="bibr">(11,</ref><ref type="bibr">13,</ref><ref type="bibr">15,</ref><ref type="bibr">17,</ref><ref type="bibr">19</ref>) and <ref type="bibr">(7,</ref><ref type="bibr">11,</ref><ref type="bibr">15,</ref><ref type="bibr">19,</ref><ref type="bibr">23)</ref>. The ? describes 95% confidence interval. For these results, we use our implementation version of TIM-GD <ref type="bibr" target="#b6">(Boudiaf et al., 2020)</ref>, which matches the original paper's performance. For BD-CSPN <ref type="bibr" target="#b29">(Liu et al., 2020)</ref> with an imbalance number of query samples, we do not use shift-term since it worsens the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>mini-ImageNet</head><p>Method Backbone <ref type="bibr">(15, 15, 15, 15, 15) (11, 13, 15, 17, 19) (7, 11, 15, 19, 23)</ref>  query statistics, suffers from the change in query setting. The performance of TIM on the 5-shot when the number of query samples per class is <ref type="bibr">(7,</ref><ref type="bibr">11,</ref><ref type="bibr">15,</ref><ref type="bibr">19,</ref><ref type="bibr">23)</ref> shows ?6.2%??4.2% performance decrease compare to the baseline (NN).</p><p>E. Naively applied unsupervised learning methods We experiment if naively applied unsupervised (or self-supervised) learning can improve few-shot classification in the standard settings. For a fair comparison, we use the pre-trained embeddings of ResNet-18 on mini-ImageNet. We test with pretext task-based self-supervised methods of rotation <ref type="bibr" target="#b13">(Gidaris et al., 2018)</ref> and jigsaw <ref type="bibr" target="#b34">(Noroozi &amp; Favaro, 2016)</ref>. For both methods, we use grid search to find the best performing settings; shown in <ref type="table" target="#tab_10">Table 8</ref>. An additional module is inserted between the embedding network and classifier and we use hidden dimensions from ?. For jigsaw tasks, we use 35-permutations from ?. For both methods, the same setting with the bold font on <ref type="table" target="#tab_10">Table 8</ref> performs the best.  <ref type="formula">(2)</ref> new embeddings are given via oracle early stopping at the best performing training iteration (for ? 1). The result with converged embeddings shows that the naively applied self-supervised learning fails to improve few-shot classification performance. Note that our method achieves 70.94 on the same setting. Our method outperforms both the rotation-and jigsaw-based 15 unsupervised learning methods that even contain oracle early-stopping. We use pre-trained Conv4-64 backbones following the settings of <ref type="bibr" target="#b51">Wang et al. (2019)</ref>. We applied the same preprocessing strategy as in the main text. For the reconstruction module, we find that the bottleneck structure (Section 3.1) is helpful for Conv4-64; while reconstructed embeddings still outperform the encoded ones. Thus, we use 800-400-800-1600 as hidden dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Experiments with Conv4</head><p>Table-F shows experimental results with Conv4-64. As in the experimental results with ResNet and WideResNet, our method consistently improves the performance of the baseline methods: NN and BD-CSPN. ESFR also offers a complementary improvement to BD-CSPN <ref type="bibr" target="#b29">(Liu et al., 2020)</ref> in 1-shot settings. Compare to prior state-of-the-art methods with Conv4-64, our method with BD-CSPN has slightly lower performance. 16</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Early Stopping New Task-adapted Embeddings ? ? Shared Features Learning Non-shared Features Learning Few-Shot Classification Task update update Support Set Query Set ? Original Embeddings LID</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Feature</cell><cell></cell><cell></cell><cell>Dimensionality-</cell></row><row><cell></cell><cell></cell><cell>Reconstruction</cell><cell></cell><cell></cell><cell>driven</cell></row><row><cell></cell><cell></cell><cell>Training</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>1</cell><cell>?</cell><cell>*</cell></row><row><cell>Embedding</cell><cell>Embedding</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Network</cell><cell>Network Embedding</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell></cell><cell>Adaptation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Classifier</cell><cell>Classifier</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Prediction</cell><cell>Prediction</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(a)</cell><cell>(b)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>during preprocessing.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">ResNet-18</cell><cell></cell><cell></cell><cell cols="2">WRN-28-10</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">mini-ImageNet</cell><cell cols="2">tiered-ImageNet</cell><cell cols="2">mini-ImageNet</cell><cell cols="2">tiered-ImageNet</cell></row><row><cell></cell><cell>Method</cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>(i)</cell><cell>Linear + ESFR</cell><cell>62.45 70.38+7.93</cell><cell>79.32 81.6+2.28</cell><cell>68.49 76.98+8.49</cell><cell>83.77 86.09+2.32</cell><cell>64.53 73.33+8.8</cell><cell>80.81 83.65+2.84</cell><cell>69.78 78.57+8.79</cell><cell>84.91 87.37+2.46</cell></row><row><cell>(ii)</cell><cell>NN + ESFR</cell><cell>64.04 70.94+6.9</cell><cell>79.71 81.61+1.9</cell><cell>71.60 77.44+5.84</cell><cell>84.62 85.84+1.22</cell><cell>66.73 74.01+7.28</cell><cell>81.85 83.58+1.73</cell><cell>72.97 79.13+6.16</cell><cell>85.74 87.08+1.34</cell></row><row><cell>(iii)</cell><cell>CSPN ? + ESFR</cell><cell>64.54 71.71+7.17</cell><cell>80.49 82.22+1.73</cell><cell>71.89 78.17+6.28</cell><cell>85.09 86.38+1.29</cell><cell>67.52 74.83+7.31</cell><cell>82.36 84.17+1.81</cell><cell>73.00 79.65+6.65</cell><cell>86.28 87.57+1.29</cell></row><row><cell></cell><cell>BD-CSPN ?</cell><cell>70.00</cell><cell>82.36</cell><cell>77.28</cell><cell>86.55</cell><cell>72.74</cell><cell>84.14</cell><cell>78.89</cell><cell>87.72</cell></row><row><cell>(iv)</cell><cell>+ ESFR</cell><cell>73.98+3.98</cell><cell>82.32-0.04</cell><cell>80.13+2.85</cell><cell>86.34-0.21</cell><cell>76.84+4.10</cell><cell>84.36+0.22</cell><cell>81.77+2.88</cell><cell>87.61-0.11</cell></row><row><cell></cell><cell>+ ESFR-Semi</cell><cell></cell><cell>82.89+0.53</cell><cell></cell><cell>86.83+0.28</cell><cell></cell><cell>84.97+0.83</cell><cell></cell><cell>88.10+0.38</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Ablation study evaluating the effects of embedding ensemble and dropout perturbation.</figDesc><table><row><cell></cell><cell cols="4">mini-ImageNet tiered-ImageNet</cell><cell cols="2">CUB</cell></row><row><cell>Method</cell><cell cols="4">1-shot 5-shot 1-shot 5-shot</cell><cell cols="2">1-shot 5-shot</cell></row><row><cell>NN with ResNet-18</cell><cell>64.04</cell><cell>79.71</cell><cell>71.60</cell><cell>84.62</cell><cell>71.43</cell><cell>86.44</cell></row><row><cell>(i) w/o Dropout and Ensemble</cell><cell>66.87</cell><cell>80.59</cell><cell>73.39</cell><cell>84.60</cell><cell>75.46</cell><cell>87.02</cell></row><row><cell>(ii) w/o Ensemble</cell><cell>69.66</cell><cell>81.10</cell><cell>76.31</cell><cell>85.33</cell><cell>78.32</cell><cell>87.63</cell></row><row><cell>(iii) w/o Dropout</cell><cell>68.90</cell><cell>81.53</cell><cell>75.39</cell><cell>85.31</cell><cell>77.32</cell><cell>87.66</cell></row><row><cell>NN + ESFR</cell><cell>70.94</cell><cell>81.61</cell><cell>77.44</cell><cell>85.84</cell><cell>79.44</cell><cell>88.02</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Comparison with prior embedding adaptation methods ? 0.44 81.85 ? 0.31 NN + PCA 69.63 ? 0.50 82.28 ? 0.32 NN + EP 70.58 ? 0.47 82.73 ? 0.30 NN + ICA 72.19 ? 0.54 83.12 ? 0.32 NN + ESFR (Ours) 74.01 ? 0.51 83.58 ? 0.31</figDesc><table><row><cell></cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>NN</cell><cell>66.73</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Table describes the performance comparison with TIM</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 .</head><label>6</label><figDesc>The table shows the influence of drop-rate applied to our method. We experimented with ResNet-18 backbone on mini-ImageNet and tiered-ImageNet.</figDesc><table><row><cell></cell><cell cols="4">mini-ImageNet tiered-ImageNet</cell></row><row><cell cols="2">rate 1shot</cell><cell>5shot</cell><cell>1shot</cell><cell>5shot</cell></row><row><cell>0.</cell><cell>68.90</cell><cell>81.53</cell><cell>75.39</cell><cell>85.31</cell></row><row><cell>0.1</cell><cell>69.41</cell><cell>81.59</cell><cell>75.90</cell><cell>85.50</cell></row><row><cell>0.2</cell><cell>69.90</cell><cell>81.70</cell><cell>76.39</cell><cell>85.63</cell></row><row><cell>0.3</cell><cell>70.39</cell><cell>81.71</cell><cell>76.78</cell><cell>85.71</cell></row><row><cell>0.4</cell><cell>70.63</cell><cell>81.71</cell><cell>77.23</cell><cell>85.77</cell></row><row><cell>0.5</cell><cell>70.94</cell><cell>81.61</cell><cell>77.44</cell><cell>85.84</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 .</head><label>7</label><figDesc>This table shows few-shot classification performance when the numbers of query samples per class are imbalanced. For standard settings, the number of query samples per class is equally 15, given as</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>67?0.33 85.01?0.19 68.93?0.30 79.05?0.17 66.04?0.28 75.60?0.16 NN ResNet-18 64.04?0.44 79.71?0.32 63.73?0.46 80.01?0.33 63.25?0.47 79.88?0.33 +ESFR ResNet-18 70.94?0.50 81.61?0.33 70.32?0.52 81.35?0.33 69.74?0.53 81.12?0.34 BD-CSPN ResNet-18 70.00?0.51 82.36?0.32 68.99?0.51 81.49?0.34 68.26?0.52 81.12?0.34 +ESFR ResNet-18 73.98?0.55 82.32?0.33 72.39?0.56 81.51?0.34 71.74?0.57 81.17?0.35 99?0.33 88.62?0.20 74.21?0.29 81.93?0.18 70.95?0.28 78.36?0.17 NN ResNet-18 71.60?0.49 84.62?0.36 71.10?0.49 84.59?0.35 70.51?0.49 84.52?0.35 +ESFR ResNet-18 77.44?0.52 85.84?0.35 76.77?0.53 85.64?0.35 76.21?0.54 85.42?0.36 BD-CSPN ResNet-18 77.28?0.52 86.55?0.34 76.38?0.52 85.89?0.35 75.63?0.53 85.65?0.36 +ESFR ResNet-18 80.13?0.56 86.34?0.36 78.72?0.57 85.76?0.36 78.12?0.57 85.50?0.37 TIM WRN 82.18?0.32 89.87?0.19 76.11?0.28 83.18?0.17 72.72?0.27 79.55?0.16 NN WRN 72.97?0.49 85.74?0.34 72.17?0.48 85.79?0.34 71.57?0.49 85.70?0.34 +ESFR WRN 79.13?0.52 87.08?0.34 78.30?0.53 86.90?0.34 77.67?0.53 86.69?0.34 BD-CSPN WRN 78.89?0.52 87.72?0.32 77.71?0.52 87.11?0.34 77.05?0.53 86.86?0.35 +ESFR WRN 81.77?0.55 87.61?0.34 80.50?0.55 87.04?0.35 79.67?0.56 86.72?0.35</figDesc><table><row><cell></cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell cols="7">TIM-GD ResNet-18 73.TIM WRN 77.60?0.31 87.31?0.17 72.03?0.28 80.91?0.16 68.86?0.26 77.28?0.15</cell></row><row><cell>NN</cell><cell>WRN</cell><cell cols="5">66.73?0.44 81.85?0.31 66.64?0.46 82.07?0.31 66.30?0.47 81.98?0.32</cell></row><row><cell>+ESFR</cell><cell>WRN</cell><cell cols="5">74.01?0.51 83.58?0.31 73.34?0.51 83.27?0.32 72.89?0.52 83.03?0.33</cell></row><row><cell>BD-CSPN</cell><cell>WRN</cell><cell cols="5">72.74?0.49 84.14?0.30 71.67?0.51 83.34?0.32 71.19?0.51 83.02?0.33</cell></row><row><cell>+ESFR</cell><cell>WRN</cell><cell cols="5">76.84?0.54 84.36?0.32 75.26?0.55 83.48?0.33 74.66?0.55 83.09?0.34</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">tiered-ImageNet</cell><cell></cell></row><row><cell>Method</cell><cell>Backbone</cell><cell cols="2">(15, 15, 15, 15, 15) 1-shot 5-shot</cell><cell cols="2">(11, 13, 15, 17, 19) 1-shot 5-shot</cell><cell>(7, 11, 15, 19, 23) 1-shot 5-shot</cell></row><row><cell>TIM-GD</cell><cell cols="2">ResNet-18 79.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 .</head><label>8</label><figDesc>Experiment settings</figDesc><table><row><cell></cell><cell>Candidates</cell></row><row><cell>Learning rate</cell><cell>1e-3, 1e-4</cell></row><row><cell>Classifier</cell><cell>Linear, Cosine</cell></row><row><cell>Additional module</cell><cell>2-layer FCN, None</cell></row><row><cell>update weights</cell><cell>None, All,</cell></row><row><cell>of embedding networks</cell><cell>only-the-last-residual-block</cell></row><row><cell>New embeddings</cell><cell>Backbone output, Additional module output</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table -</head><label>-</label><figDesc></figDesc><table /><note>9 shows the results with (1) new embeddings are provided when training becomes converged and</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 .</head><label>9</label><figDesc>Naively applied unsupervised learning results</figDesc><table><row><cell>Method</cell><cell cols="2">mini-ImageNet 1-shot accuracy</cell></row><row><cell>NN</cell><cell>64.04</cell><cell></cell></row><row><cell>+ESFR</cell><cell cols="2">70.94 +6.90</cell></row><row><cell></cell><cell cols="2">(1) Converged (2) Oracle early stopping</cell></row><row><cell>Jigsaw</cell><cell>33.1</cell><cell>67.22 +3.18</cell></row><row><cell>Rotation</cell><cell>32.2</cell><cell>66.70 +2.66</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 .</head><label>10</label><figDesc>The table shows the experimental results of our method with Conv4-64 backbone on mini-ImageNet and tiered-ImageNet. +3.51 69.18 +0.68 60.16 +5.22 72.37 +0.84</figDesc><table><row><cell></cell><cell cols="2">mini-ImageNet</cell><cell cols="2">tiered-ImageNet</cell></row><row><cell>Method</cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>NN</cell><cell>50.72</cell><cell>67.17</cell><cell>52.18</cell><cell>69.60</cell></row><row><cell>+ ESFR</cell><cell cols="4">54.63 +3.91 68.32 +1.15 57.56 +5.38 71.46 +1.86</cell></row><row><cell>BD-CSPN</cell><cell>52.73</cell><cell>68.5</cell><cell>54.94</cell><cell>71.53</cell></row><row><cell>+ ESFR</cell><cell>56.24</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We use Euclidean distance.4  We set m = 20 throughout experiments as in<ref type="bibr" target="#b31">Ma et al. (2018a)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We test self-supervised learning models of rotation<ref type="bibr" target="#b13">(Gidaris et al., 2018)</ref> and jigsaw<ref type="bibr" target="#b34">(Noroozi &amp; Favaro, 2016)</ref> in Appendix E.6  Details are described in the experiment section.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">? indicates the element-wise product.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">Including the only change of class prototypes or last layer parameters.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">Data augmentations are used only for embedding network pre-training.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">We separately compared the work by<ref type="bibr" target="#b6">(Boudiaf et al., 2020)</ref> in Appendix B; since they use strong prior that the number of query samples per class is equal.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14"><ref type="bibr" target="#b28">Lichtenstein et al. (2020)</ref> explained their method as Independent Component Analysis (ICA), but it seems the difference between their PCA-and ICA-based methods is only in the whitening; for ICA, they whiten by the projection of 1 T z = 0.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">We improved the performance with the jigsaw task after the rebuttal period. Originally performance with rotation task performs better.16  <ref type="bibr" target="#b21">Hu et al. (2020)</ref> shows 58.0% and 70.7% accuracies on mini-ImageNet in 1-and 5-shot settings, respectively.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Unsupervised Embedding Adaptation via Early-Stage Feature</head><p>Reconstruction for Few-Shot Classification <ref type="bibr">A. Preprocessing</ref> In this section, we describe the preprocessing including equations in our paper. Assume we are given the embedding support set S f and embedding query set Q f . We apply centering and l2-normalization to the embedding samples for reconstruction training as described in (10). Preprocessed embeddings z ? Z preprocess are used as an input to the reconstruction module g ? . The same preprocessing (centering and l2-normalization) is applied at the output of reconstruction module to compute the reconstruction loss L FR as in <ref type="formula">(13)</ref>.</p><p>As new embeddings for few-shot classification, we apply only l2-normalization since it performs the best. The new embedding sets S ESFR and Q ESFR for the few-shot classification task are as follows:</p><p>For BD-CSPN <ref type="bibr" target="#b29">(Liu et al., 2020)</ref> and our method used with BD-CSPN, additional shifting-term is added for query samples before preprocessing. In this case, we define S preprocess and Q preprocess as follows:</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Estimating local intrinsic dimensionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Amsaleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Furon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Girard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kawarabayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The vulnerability of learning to adversarial perturbation increases with intrinsic dimensionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Amsaleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radovanovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Information Forensics and Security WIFS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ansuini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Macke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zoccolan</surname></persName>
		</author>
		<title level="m">trinsic dimension of data representations in deep neural networks. In NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to learn by selfcritique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Information maximization for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Boudiaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">M</forename><surname>Ziko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Piantanida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joulin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Big self-supervised models are strong semisupervised learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Model-agnostic metalearning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generating classification weights with GNN denoising autoencoders for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Boosting few-shot visual learning with selfsupervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On the intrinsic dimensionality of image representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Boddeti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent: A new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Azar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Using pre-training can improve model robustness and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cross attention network for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Local intrinsic dimensionality I: an extremevalue-theoretic foundation for similarity applications</title>
	</analytic>
	<monogr>
		<title level="m">Unsupervised Embedding Adaptation via Early-Stage Feature Reconstruction Houle</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>SISAP</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Local intrinsic dimensionality II: multivariate analysis and distributional support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SISAP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Empirical bayes transductive meta-learning with synthetic gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Damianou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mentornet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Combining contrastive self-supervision and consistency for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-D</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Selfmatch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06480</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Edge-labeling graph neural network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An analytic theory of generalization dynamics and transfer learning in deep linear networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Finding task-relevant features for few-shot learning by category traversal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">TAFSSL: task-adaptive feature sub-space learning for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lichtenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sattigeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Karlinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Prototype rectification for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to propagate labels: Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Characterizing adversarial subspaces using local intrinsic dimensionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N R</forename><surname>Wijewickrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schoenebeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Dimensionalitydriven learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N R</forename><surname>Wijewickrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning from one example through shared densities on transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>Matsakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Viola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oymak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fabian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Soltanolkotabi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05392</idno>
		<title level="m">Generalization guarantees for neural networks via harnessing the low-rank structure of the jacobian</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Transductive episodic-wise adaptive metric for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Metalearning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Embedding propagation: Smoother manifold for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laradji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Drouin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-G</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.08059</idno>
		<title level="m">How does early stopping help generalization against label noise? arXiv preprint</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">56</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On the geometry of generalization and memorization in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stephenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">When does selfsupervision improve few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning to learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Rethinking few-shot image classification: a good embedding is all you need?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.11539</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simpleshot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.04623</idno>
		<title level="m">Revisiting nearest-neighbor classification for few-shot learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Few-shot learning via embedding adaptation with set-to-set functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sha</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">How does disagreement help generalization against label corruption</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">S4l: Selfsupervised semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Laplacian regularized few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">M</forename><surname>Ziko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
