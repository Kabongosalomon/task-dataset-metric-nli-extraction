<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Balanced Meta-Softmax for Long-Tailed Visual Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ren</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunjun</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunan</forename><surname>Sheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SenseTime Research</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SenseTime Research</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
							<email>yishuai@sensetime.comcunjun.yu@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">Multimedia Laboratory</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Balanced Meta-Softmax for Long-Tailed Visual Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep classifiers have achieved great success in visual recognition. However, realworld data is long-tailed by nature, leading to the mismatch between training and testing distributions. In this paper, we show that the Softmax function, though used in most classification tasks, gives a biased gradient estimation under the long-tailed setup. This paper presents Balanced Softmax, an elegant unbiased extension of Softmax, to accommodate the label distribution shift between training and testing. Theoretically, we derive the generalization bound for multiclass Softmax regression and show our loss minimizes the bound. In addition, we introduce Balanced Meta-Softmax, applying a complementary Meta Sampler to estimate the optimal class sample rate and further improve long-tailed learning. In our experiments, we demonstrate that Balanced Meta-Softmax outperforms state-of-the-art long-tailed classification solutions on both visual recognition and instance segmentation tasks. ? We propose Balanced Meta-Softmax (BALMS) for long-tailed visual recognition. We first show that the Softmax function is intrinsically biased under the long-tailed scenario. We derive a Balanced Softmax function from the probabilistic perspective that explicitly models the test-time label distribution shift. Theoretically, we found that optimizing for the Balanced Softmax cross-entropy loss is equivalent to minimizing the generalization error bound. Balanced Softmax generally improves longtailed classification performance on datasets with moderate imbalance ratios, e.g., CIFAR-10-LT [21] with a maximum imbalance factor of 200. However, for datasets with an extremely large imbalance factor, e.g., LVIS [9]  with an imbalance factor of 26,148, the optimization process becomes difficult. Complementary to the loss function, we introduce the Meta Sampler, which learns to re-sample for achieving high validation accuracy by meta-learning. The combination of Balanced Softmax and Meta Sampler could efficiently address long-tailed classification tasks with high imbalance factors.</p><p>We evaluate BALMS on both long-tailed image classification and instance segmentation on five commonly used datasets: CIFAR-10-LT [21], CIFAR-100-LT [21], ImageNet-LT [26], Places-LT [39] and LVIS <ref type="bibr" target="#b8">[9]</ref>. On all datasets, BALMS outperforms state-of-the-art methods. In particular, BALMS outperforms all SOTA methods on LVIS, with an extremely high imbalanced factor, by a large margin.</p><p>We summarize our contributions as follows: 1) we theoretically analyze the incapability of Softmax function in long-tailed tasks; 2) we introduce Balanced Softmax function that explicitly considers the label distribution shift during optimization; 3) we present Meta Sampler, a meta-learning based re-sampling strategy for long-tailed learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Data Re-Balancing. Pioneer works focus on re-balancing during training. Specifically, re-sampling strategies [22, 5, 10, 12, 31, 2, 1] try to restore the true distributions from the imbalanced training data. Re-weighting, i.e., cost-sensitive learning <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b27">28]</ref>, assigns a cost weight to the loss of each class. However, it is argued that over-sampling inherently overfits the tail classes and under-sampling under-represents head classes' rich variations. Meanwhile, re-weighting tends to cause unstable training especially when the class imbalance is severe because there would be abnormally large gradients when the weights are very large. Loss Function Engineering. Tan et al. [35] point out that randomly dropping some scores of tail classes in the Softmax function can effectively help, by balancing the positive gradients and negative gradients flowing through the score outputs. Cao et al. [4] show that the generalization error bound could be minimized by increasing the margins of tail classes. Hayat et al. [11] modify the loss function based on Bayesian uncertainty. Li et al. [23] propose two novel loss functions to balance the gradient flow. Khan et al. [19] jointly learn the model parameters and the class-dependent loss function parameters. Ye et al.</p><p>[37] force a large margin for minority classes to prevent feature deviation. We progress this line of works by introducing probabilistic insights that also bring empirical improvements. We show in this paper that an ideal loss function should be unbiased under the long-tailed scenarios.</p><p>Meta-Learning. Many approaches <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32]</ref> have been proposed to tackle the long-tailed issue with meta-learning. Many of them <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b29">30]</ref> focus on optimizing the weight-per-sample as a learnable parameter, which appears as a hyper-parameter in the sample-based re-weight approach. This group of methods requires a clean and unbiased dataset as a meta set, i.e., development set, which is usually a fixed subset of the training images and use bi-level optimization to estimate the weight parameter.</p><p>Decoupled Training. Kang et al. <ref type="bibr" target="#b17">[18]</ref> point out that decoupled training, a simple yet effective solution, could significantly improve the generalization issue on long-tailed datasets. The classifier is the only under-performed component when training in imbalanced datasets. However, in our experiments, we found this technique is not adequate for datasets with extremely high imbalance factors, e.g., LVIS [9]. Interestingly in our experiments, we observed that decoupled training is complementary to our proposed BALMS, and combining them results in additional improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Balanced Meta-Softmax</head><p>The major challenge for long-tailed visual recognition is the mismatch between the imbalanced training data distribution and the balanced metrics, e.g., mean Average Precision (mAP), that encourage</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Most real-world data comes with a long-tailed nature: a few high-frequency classes (or head classes) contributes to most of the observations, while a large number of low-frequency classes (or tail classes) are under-represented in data. Taking an instance segmentation dataset, LVIS <ref type="bibr" target="#b8">[9]</ref>, for example, the number of instances in banana class can be thousands of times more than that of a bait class. In practice, the number of samples per class generally decreases from head to tail classes exponentially. Under the power law, the tails can be undesirably heavy. A model that minimizes empirical risk on long-tailed training datasets often underperforms on a class-balanced test dataset. As datasets are scaling up nowadays, the long-tailed nature poses critical difficulties to many vision tasks, e.g., visual recognition and instance segmentation.</p><p>An intuitive solution to long-tailed task is to re-balance the data distribution. Most state-of-the-art (SOTA) methods use the class-balanced sampling or loss re-weighting to "simulate" a balanced training set <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b35">36]</ref>. However, they may under-represent the head class or have gradient issues during optimization. Cao et al. <ref type="bibr" target="#b3">[4]</ref> introduced Label-Distribution-Aware Margin Loss (LDAM), from the perspective of the generalization error bound. Given fewer training samples, a tail class should have a higher generalization error bound during optimization. Nevertheless, LDAM is derived from the hinge loss, under a binary classification setup and is not suitable for multi-class classification. minimizing error on a balanced test set. Let X = {x i , y i }, i ? {1, ? ? ? , n} be the balanced test set, where x i denotes a data point and y i denotes its label. Let k be the number of classes, n j be the number of samples in class j, where k j=1 n j = n. Similarly, we denote the long-tailed training set asX = {x i ,? i }, i ? {1, . . . , n}. Normally, we have ?i, p(? i ) = p(y i ). Specifically, for a tail class j, p(? j ) p(y j ), which makes the generalization under long-tailed scenarios extremely challenging.</p><p>We introduce Balanced Meta-Softmax (BALMS) for long-tailed visual recognition. It has two components: 1) a Balanced Softmax function that accommodates the label distribution shift between training and testing; 2) a Meta Sampler that learns to re-sample training set by meta-learning. We denote a feature extractor function as f and a linear classifier's weight as ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Balanced Softmax</head><p>Label Distribution Shift. We begin by revisiting the multi-class Softmax regression, where we are generally interested in estimating the conditional probability p(y|x), which can be modeled as a multinomial distribution ?:</p><formula xml:id="formula_0">? = ? 1{y=1} 1 ? 1{y=2} 2 ? ? ? ? 1{y=k} k ; ? j = e ?j k i=1 e ?i ; k j=1 ? j = 1<label>(1)</label></formula><p>where 1(?) is the indicator function and Softmax function maps a model's class-j output ? j = ? T j f (x) to the conditional probability ? j .</p><p>From the Bayesian inference's perspective, ? j can also be interpreted as:</p><formula xml:id="formula_1">? j = p(y = j|x) = p(x|y = j)p(y = j) p(x)<label>(2)</label></formula><p>where p(y = j) is in particular interest under the class-imbalanced setting. Assuming that all instances in the training dataset and the test dataset are generated from the same process p(x|y = j), there could still be a discrepancy between training and testing given different label distribution p(y = j) and evidence p(x). With a slight abuse of the notation, we re-define ? to be the conditional distribution on the balanced test set and define? to be the conditional probability on the imbalanced training set. As a result, standard Softmax provides a biased estimation for ?.</p><p>Balanced Softmax. To eliminate the discrepancy between the posterior distributions of training and testing, we introduce Balanced Softmax. We use the same model outputs ? to parameterize two conditional probabilities: ? for testing and? for training. Theorem 1. Assume ? to be the desired conditional probability of the balanced dataset, with the form ? j = p(y = j|x) = p(x|y=j) p(x) 1 k , and? to be the desired conditional probability of the imbalanced training set, with the form? j =p(y = j|x) = p(x|y=j) p(x) nj k i=1 ni . If ? is expressed by the standard Softmax function of model output ?, then? can be expressed a?</p><formula xml:id="formula_2">? j = n j e ?j k i=1 n i e ?i .<label>(3)</label></formula><p>We use the exponential family parameterization to prove Theorem 1. The proof can be found in the supplementary materials. Theorem 1 essentially shows that applying the following Balanced Softmax function can naturally accommodate the label distribution shifts between the training and test sets. We define the Balanced Softmax function a?</p><formula xml:id="formula_3">l(?) = ? log(? y ) = ? log n y e ?y k i=1 n i e ?i .<label>(4)</label></formula><p>We further investigate the improvement brought by the Balanced Softmax in the following sections.</p><p>Many vision tasks, e.g., instance segmentation, might use multiple binary logistic regressions instead of a multi-class Softmax regression. By virtue of Bayes' theorem, a similar strategy can be applied to the multiple binary logistic regressions. The detailed derivation is left in the supplementary materials.</p><p>Generalization Error Bound. Generalization error bound gives the upper bound of a model's test error, given its training error. With dramatically fewer training samples, the tail classes have much higher generalization bounds than the head classes, which make good classification performance on tail classes unlikely. In this section, we show that optimizing Eqn. 4 is equivalent to minimizing the generalization upper bound.</p><p>Margin theory provides a bound based on the margins <ref type="bibr" target="#b16">[17]</ref>. Margin bounds usually negatively correlate to the magnitude of the margin, i.e., a larger margin leads to lower generalization error. Consequently, given a constraint on the sum of margins of all classes, there would be a trade-off between minority classes and majority classes <ref type="bibr" target="#b3">[4]</ref>.</p><p>Locating such an optimal margin for multi-class classification is non-trivial. The bound investigated in <ref type="bibr" target="#b3">[4]</ref> was established for binary classification using hinge loss. Here, we try to develop the margin bound for the multi-class Softmax regression. Given the previously defined ? and?, we derivel(?) by minimizing the margin bound. Margin bound commonly bounds the 0-1 error:</p><formula xml:id="formula_4">err 0,1 = Pr ? T y f (x) &lt; max i =y ? T i f (x) .<label>(5)</label></formula><p>However, directly using the 0-1 error as the loss function is not ideal for optimization. Instead, negative log likelihood (NLL) is generally considered more suitable. With continuous relaxation of Eqn. 5, we have</p><formula xml:id="formula_5">err(t) = Pr[t &lt; log(1 + i =y e ? T i f (x)?? T y f (x) )] = Pr [l y (?) &gt; t] ,<label>(6)</label></formula><p>where t ? 0 is any threshold, and l y (?) is the standard negative log-likelihood with Softmax, i.e., the cross-entropy loss. This new error is still a counter, but describes how likely the test loss will be larger than a given threshold. Naturally, we define our margin for class j to be</p><formula xml:id="formula_6">? j = t ? max (x,y)?Sj l j (?).<label>(7)</label></formula><p>where S j is the set of all class j samples. If we force a large margin ? j during training, i.e., force the training loss to be much lower than t, then err(t) will be reduced. The Theorem 2 in <ref type="bibr" target="#b16">[17]</ref> can then be directly generalized as Theorem 2. Let t ? 0 be any threshold, for all ? j &gt; 0, with probability at least 1 ? ?, we have</p><formula xml:id="formula_7">err bal (t) 1 k k j=1 1 ? j C n j + log n ? n j ; ? * j = ?n ?1/4 j k i=1 n ?1/4 i ,<label>(8)</label></formula><p>where err bal (t) is the error on the balanced test set, is used to hide constant terms and C is some measure on complexity. With a constraint on k j=1 ? j = ?, Cauchy-Schwarz inequality gives us the optimal ? * j .</p><p>The optimal ? * suggests that we need larger ? for the classes with fewer samples. In other words, to achieve the optimal generalization ability, we need to focus on minimizing the training loss of the tail classes. To enforce the optimal margin, for each class j, the desired training lossl * j (?) i?</p><formula xml:id="formula_8">l * j (?) = l j (?) + ? * j , where l j (?) = ? log(? j ),<label>(9)</label></formula><formula xml:id="formula_9">Corollary 2.1.l * j (?) = l j (?) + ? * j = l j (?) + ?n ?1/4 j k i=1 n ?1/4 i can be approximated byl j (?) when: l j (?) = ? log(? j );? j = e ?j ?log ? * j k i=1 e ?i?log ? * i = n 1 4 j e ?j k i=1 n 1 4 i e ?i<label>(10)</label></formula><p>We provide a sketch of proof to the corollary in supplementary materials. Notice that compared to Eqn. 4, we have an additional constant 1/4. We empirically find that setting 1/4 to 1 leads to the optimal results, which may suggest that Eqn. 8 is not necessarily tight. To this point, the label distribution shift and generalization bound of multi-class Softmax regression lead us to the same loss form: Eqn. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Meta Sampler</head><p>Re-sampling. Although Balanced Softmax accommodates the label distribution shift, the optimization process is still challenging when given large datasets with extremely imbalanced data distribution. For example, in LVIS, the bait class may appear only once when the banana class appears thousands of times, making the bait class difficult to contribute to the model training due to low sample rate. Re-sampling is usually adopted to alleviate this issue, by increasing the number of minority class samples in each training batch. Recent works <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b2">3]</ref> show that the global minimum of the Softmax regression is independent of the mini-batch sampling process. Our visualization in the supplementary material confirms this finding. As a result, a suitable re-sampling strategy could simplify the optimization landscape of Balanced Softmax under extremely imbalanced data distribution.</p><p>Over-balance. Class-balanced sampler (CBS) is a common re-sampling strategy. CBS balances the number of samples for each class in a mini-batch. It effectively helps to re-train the linear classifier in the decoupled training setup <ref type="bibr" target="#b17">[18]</ref>. However, in our experiments, we find that naively combining CBS with Balanced Softmax may worsen the performance.</p><p>We first theoretically analyze the cause of the performance drop. When the linear classifier's weight ? j for class j converges, i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B s=1</head><p>?L (s) ??j = 0, we should have:</p><formula xml:id="formula_10">B s=1 ?L (s) ?? j = B/k s=1 f (x (s) y=j )(1 ?? (s) j ) ? k i =j B/k s=1 f (x (s) y=i )? (s) j = 0,<label>(11)</label></formula><p>where B is the batch size and k is the number of classes. Samples per class have been ensured to be B/k by CBS. We notice that? j , the output of Balanced Softmax, casts a varying, minority-favored effect to the importance of each class.</p><p>We use an extreme case to demonstrate the effect. When the classification loss converges to 0, the conditional probability of the correct class? y is expected to be close to 1. For any positive sample</p><formula xml:id="formula_11">x + and negative sample x ? of class j, we have? j (x + ) ? ? j (x + ) and? j (x ? ) ? nj ni ? j (x ? ), when ? y ? 1.</formula><p>Eqn. 11 can be rewritten as</p><formula xml:id="formula_12">1 n 2 j E (x + ,y=j)?Dtrain [f (x + )(1 ? ? j )] ? k i =j 1 n 2 i E (x ? ,y=i)?Dtrain [f (x ? )? j ] ? 0<label>(12)</label></formula><p>where D train is the training set. The formal derivation of Eqn. 12 is in the supplementary materials. Compared to the inverse loss weight, i.e., 1/n j for class j, combining Balanced Softmax with CBS leads to the over-balance problem, i.e., 1/n 2 j for class j, which deviates from the optimal distribution. Although re-sampling does not affect the global minimum, an over-balanced, tail class dominated optimization process may lead to local minimums that favor the minority classes. Moreover, Balanced Softmax's effect in the optimization process is dependent on the model's output, which makes hand-crafting a re-sampling strategy infeasible.</p><p>Meta Sampler. To cope with CBS's over-balance issue, we introduce Meta Sampler, a learnable version of CBS based on meta-learning, which explicitly learns the optimal sample rate. We first define the empirical loss by sampling from dataset D as L D (?) = E (x,y)?D [l(?)] for standard Softmax, andL D (?) = E (x,y)?D [l(?)] for Balanced Softmax, wherel(?) is defined previously in Eqn. 4.</p><p>To estimate the optimal sample rates for different classes, we adopt a bi-level meta-learning strategy: we update the parameter ? of sample distribution ? ? in the inner loop and update the classifier parameters ? in the outer loop,</p><formula xml:id="formula_13">? * ? = arg min ? L Dmeta (? * (? ? )) s.t. ? * (? ? ) = arg min ?L D q(x,y;? ? ) (?),<label>(13)</label></formula><p>where ? j ? = p(y = j; ?) is the sample rate for class j, D q(x,y;? ? ) is the training set with class sample distribution ? ? , and D meta is a meta set we introduce to supervise the inner loop optimization. We create the meta set by class-balanced sampling from the training set D train . Empirically, we found it sufficient for inner loop optimization. An intuition to this bi-level optimization strategy is that: we want to learn best sample distribution parameter ? such that the network, parameterized by ?, outputs best performance on meta dataset D meta when trained by samples from ? ? .</p><p>We first compute the per-instance sample rate ? i = ?</p><formula xml:id="formula_14">c(i) ? / n i=1 ? c(i) ? ,</formula><p>where c(i) denotes the label class for instance i and n is total number of training samples, and sample a training batch B ? from a parameterized multi-nomial distribution ?. Then we optimize the model in a meta-learning setup by 1. sample a mini-batch B ? given distribution ? ? and perform one step gradient descent to get a surrogate model parameterized by? by? ? ? ? ? ?LB ? (?).</p><p>2. compute the L Dmeta (?) of the surrogate model on the meta dataset D meta and optimize the sample distribution parameter by ? ? ? ? ? ? L Dmeta (?) with the standard cross-entropy loss with Softmax.</p><p>3. update the model parameter ? ? ? ? ? ?LB ? (?) with Balanced Softmax.</p><p>However, sampling from a discrete distribution is not differentiable by nature. To allow end-to-end training for the sampling process, when forming the mini-batch B ? , we apply the Gumbel-Softmax reparameterization trick <ref type="bibr" target="#b15">[16]</ref>. A detailed explanation can be found in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Exprimental Setup</head><p>Datasets. We perform experiments on long-tailed image classification datasets, including CIFAR-10-LT <ref type="bibr" target="#b20">[21]</ref>, CIFAR-100-LT <ref type="bibr" target="#b20">[21]</ref>, ImageNet-LT <ref type="bibr" target="#b25">[26]</ref> and Places-LT <ref type="bibr" target="#b38">[39]</ref> and one long-tailed instance segmentation dataset, LVIS <ref type="bibr" target="#b8">[9]</ref>. We define the imbalance factor of a dataset as the number of training instances in the largest class divided by that of the smallest. Details of datasets are in <ref type="table">Table 1</ref>.</p><p>Dataset #Classes Imbalance Factor CIFAR-10-LT <ref type="bibr" target="#b20">[21]</ref> 10 10-200 CIFAR-100-LT <ref type="bibr" target="#b20">[21]</ref> 100 10-200 ImageNet-LT <ref type="bibr" target="#b25">[26]</ref> 1,000 256 Places-LT <ref type="bibr" target="#b38">[39]</ref> 365 996 LVIS <ref type="bibr" target="#b8">[9]</ref> 1,230 26,148 <ref type="table">Table 1</ref>: Details of long-tailed datatsets. For both CIFAR-10 and CIFAR-100, we report results with different imbalance factors.</p><p>Evaluation Setup. For classification tasks, after training on the long-tailed dataset, we evaluate the models on the corresponding balanced test/validation dataset and report top-1 accuracy. We also report accuracy on three splits of the set of classes: Many-shot (more than 100 images), Medium-shot (20 ? 100 images), and Few-shot (less than 20 images). Notice that results on small datasets, i.e., CIFAR-LT 10/100, tend to show large variances, we report the mean and standard error under 3 repetitive experiments. We show details of long-tailed dataset generation in supplementary materials. For LVIS, we use official training and testing splits. Average Precision (AP) in COCO style <ref type="bibr" target="#b23">[24]</ref> for both bounding box and instance mask are reported. Our implementation details can be found in the supplementary materials. x-axis is the class labels with decreasing training samples and y-axis is the marginal likelihood p(y) on the test set. We use end-to-end training for the experiment. Balanced Softmax is more stable under a high imbalance factor compared to the Softmax baseline and the SOTA method, Equalization Loss (EQL).  <ref type="bibr" target="#b17">[18]</ref> 76 </p><formula xml:id="formula_15">.6 ? 0.2 82.0 ? 0.2 91.0 ? 0.0 44.5 ? 0.1 50.0 ? 0.2 63.3 ? 0.1 LWS [18] 78.1 ? 0.0 83.7 ? 0.0 91.1 ? 0.0 45.3 ? 0.1 50.5 ? 0.1 63.4 ? 0.1 BALMS 81.5 ? 0.0 84.9 ? 0.1 91.3 ? 0.1 45.5 ? 0.1 50.8 ? 0.0 63.0 ? 0.1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Long-Tailed Image Classification</head><p>We present the results for long-tailed image classification in <ref type="table" target="#tab_1">Table 2</ref> and <ref type="table" target="#tab_3">Table 3</ref>. On all datasets, BALMS achieves SOTA performance compared with all end-to-end training and decoupled training methods. In particular, we notice that BALMS demonstrates a clear advantage under two cases: 1) When the imbalance factor is high. For example, on CIFAR-10 with an imbalance factor of 200, BALMS is higher than the SOTA method, LWS <ref type="bibr" target="#b17">[18]</ref>, by 3.4%. 2) When the dataset is large. BALMS achieves comparable performance with cRT on ImageNet-LT, which is a relatively small dataset, but it significantly outperforms cRT on a larger dataset, Places-LT.</p><p>In addition, we study the robustness of the proposed Balanced Softmax compared to standard Softmax and SOTA loss function for long-tailed problems, EQL <ref type="bibr" target="#b34">[35]</ref>. We visualize the marginal likelihood p(y), i.e., the sum of scores on each class, on the test set with different losses given different imbalance factors in <ref type="figure" target="#fig_0">Fig. 1</ref>   <ref type="table">Table 4</ref>: Results for LVIS dataset. AP m denotes Average Precision of masks. AP b denotes Average Precision of bounding box. AP f , AP c and AP r denote Average Precision of masks on frequent classes, common classes and rare classes. ?: the multiple binary logistic regression variant of Balanced Softmax, more details in the supplementary material. BALMS significantly outperforms SOTA models given high imbalance factor in LVIS. All compared methods are reproduced with higher AP than reported in the original papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Long-Tailed Instance Segmentation</head><p>LVIS dataset is one of the most challenging datasets in the vision community. As suggested in Tabel 1, the dataset has a much higher imbalance factor compared to the rest (26148 vs. less than 1000) and contains many very few-shot classes. Compared to the image classification datasets, which are relatively small and have lower imbalance factors, the LVIS dataset gives a more reliable evaluation of the performance of long-tailed learning methods.</p><p>Since one image might contain multiple instances from several categories, we hereby use Meta Reweighter, a re-weighting version of Meta Sampler, instead of Meta Sampler. As shown in <ref type="table">Table 4</ref>, BALMS achieves the best results among all the approaches and outperform others by a large margin, especially in rare classes, where BALMS achieves an average precision of 19.6 while the best of the rest is 14.6. The results suggest that with the Balanced Softmax function and learnable Meta Reweighter, BALMS is able to give more balanced gradients and tackles the extremely imbalanced long-tailed tasks.</p><p>In particular, LVIS is composed of images of complex daily scenes with natural long-tailed categories.</p><p>To this end, we believe BALMS is applicable to real-world long-tailed visual recognition challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Component Analysis</head><p>We conduct an extensive component analysis on CIFAR-10/100-LT dataset to further understand the effect of each proposed component of BALMS. The results are presented in <ref type="table" target="#tab_5">Table 5</ref>.    <ref type="formula" target="#formula_0">(10)</ref>, we observe that Balanced Softmax gives a clear improvement to the overall performance, under both end-to-end training and decoupled training setup. It successfully accommodates the distribution shift between training and testing. In particular, we observe that Balanced Softmax <ref type="bibr">1 4</ref> , which we derive in Eqn. 10, cannot yield ideal results, compared to our proposed Balanced Softmax in Eqn. 4.</p><p>Meta-Sampler. From (6), <ref type="bibr" target="#b6">(7)</ref>, <ref type="formula" target="#formula_8">(9)</ref> and <ref type="formula" target="#formula_0">(10)</ref>, we observe that Meta-Sampler generally improves the performance, when compared with no Meta-Sampler, and variants of Meta-Sampler. We notice that the performance gain is larger with a higher imbalance factor, which is consistent with our observation in LVIS experiments. In (9) and (10), Meta-Sampler generally outperforms the Meta-Reweighter and suggests the discrete sampling process gives a more efficient optimization process. Comparing <ref type="bibr" target="#b6">(7)</ref> and <ref type="formula" target="#formula_0">(10)</ref>, we can see Meta-Sampler addresses the over-balancing issue discussed in Section 3.2.</p><p>Decoupled Training. Comparing (2) with (4) and (3) with (6), decoupled training scheme and Balanced Softmax are two orthogonal components and we can benefit from both at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have introduced BALMS for long-tail visual recognition tasks. BALMS tackles the distribution shift between training and testing, combining meta-learning with generalization error bound theory: it optimizes a Balanced Softmax function which theoretically minimizes the generalization error bound; it improves the optimization in large long-tailed datasets by learning an effective Meta Sampler. BALMS generally outperforms SOTA methods on 4 image classification datasets and 1 instance segmentation dataset by a large margin, especially when the imbalance factor is high.</p><p>However, Meta Sampler is computationally expensive in practice and the optimization on large datasets is slow. In addition, the Balanced Softmax function only approximately guarantees a generalization error bound. Future work may extend the current framework to a wider range of tasks, e.g., machine translation, and correspondingly design tighter bounds and computationally efficient meta-learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>This work is supported in part by the General Research Fund through the Research Grants Council of Hong Kong under grants (Nos. CUHK14208417, CUHK14207319), in part by the Hong Kong Innovation and Technology Support Program (No. ITS/312/18FX).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>Due to the Zipfian distribution of categories in real life, algorithms, and models with exceptional performance on research benchmarks may not remain powerful in the real world. BALMS, as a light-weight method, only adds minimal computational cost during training and is compatible with most of the existing works for visual recognition. As a result, BALMS could be beneficial to bridge the gap between research benchmarks and industrial applications for visual recognition.</p><p>However, there can be some potential negative effects. As BALMS empowers deep classifiers with stronger recognition capability on long-tailed distribution, the application of such a classification algorithm can be further extended to more real-life scenarios. We should be cautious about the misuse of the method proposed. Depending on the scenario, it might cause negative effects on democratic privacy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A Proofs and Derivations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Proof to Theorem 1</head><p>The exponential family parameterization of the multinomial distribution gives us the standard Softmax function as the canonical response function</p><formula xml:id="formula_16">? j = e ?j k i=1 e ?i<label>(14)</label></formula><p>and also the canonical link function</p><formula xml:id="formula_17">? j = log( ? j ? k )<label>(15)</label></formula><p>We begin by adding a term ? log(? j /? j ) to both sides of Eqn. 15,</p><formula xml:id="formula_18">? j ? log ? ? ? j = log( ? j ? k ) ? log( ? ? ? j ) = log(? j ? k )<label>(16)</label></formula><p>Subsequently,</p><formula xml:id="formula_19">? k e ?j ?log ? ? ? j =? j (17) ? k k i=1 e ?i?log ? ? ? i = k i=1? i = 1 (18) ? k = 1/ k i=1 e ?i?log ? ? ? i<label>(19)</label></formula><p>Substitute Eqn. 19 back to Eqn. 17, we hav?</p><formula xml:id="formula_20">? j = ? k e ?j ?log ? ? ? j = e ?j ?log ? ? ? j k i=1 e ?i?log ? ? ? i<label>(20)</label></formula><p>Recall that</p><formula xml:id="formula_21">? j = p(y = j|x) = p(x|y = j) p(x) 1 k ;? j =p(y = j|x) = p(x|y = j) p(x) n j n (21) then log ? ? ? j = log n kn j + logp (x) p(x)<label>(22)</label></formula><p>Finally, bring Eqn. 22 back to Eqn. 20</p><formula xml:id="formula_22">? j = e ?j ?log n kn j ?logp (x) p(x) k i=1 e ?i?log n kn i ?logp (x) p(x) = n j e ?j k i=1 n i e ?i<label>(23)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Derivation for the Multiple Binary Logistic Regression variant</head><p>Definition. Multiple Binary Logisitic Regression uses k binary logistic regression to do multi-class classification. Same as Softmax regression, the predicted label is the class with the maximum model output, y pred = arg max j (? j ).</p><p>The only difference is that ? j is expressed by a logistic function of ? j ? j = e ?j 1 + e ?j <ref type="bibr" target="#b24">(25)</ref> and the loss function sums up binary classification loss on all classes</p><formula xml:id="formula_24">l(?) = k j=1 ? log? j (26) where? j = ? j , if y = j 1 ? ? j , otherwise<label>(27)</label></formula><p>Setup. By the virtue of Bayes' theorem, ? j and 1 ? ? j can be decomposed as</p><formula xml:id="formula_25">? j = p(x|y = j)p(y = j) p(x) ; 1 ? ? j = p(x|y = j)p(y = j) p(x)<label>(28)</label></formula><p>and for? and 1 ??,</p><formula xml:id="formula_26">? j = p(x|y = j)p(y = j) p(x) ; 1 ?? j = p(x|y = j)p(y = j) p(x)<label>(29)</label></formula><p>Derivation. Again, we introduce the exponential family parameterization and have the following link function for ? j</p><formula xml:id="formula_27">? j = log ? j 1 ? ? j<label>(30)</label></formula><p>Bring the decomposition Eqn. 28 and Eqn.29 into the link function above </p><formula xml:id="formula_28">? j = log(? j 1 ?? j ? ? ? ? j ? 1 ?? j 1 ? ? j )<label>(31)</label></formula><p>Simplify the above equation</p><formula xml:id="formula_30">? j = log(? j 1 ?? j ? p(y = j) p(y = j) ?p (y = j) p(y = j) )<label>(33)</label></formula><p>Substitute the n j in to the equation above</p><formula xml:id="formula_31">? j = log(? j 1 ?? j ? n/k n j ? n ? n j n ? n/k )<label>(34)</label></formula><p>Then</p><formula xml:id="formula_32">? j ? log( n/k n j ? n ? n j n ? n/k ) = log(? j 1 ?? j )<label>(35)</label></formula><p>Finally, we have? </p><p>Remark. A careful implementation should be made for instance segmentation tasks. As discussed in <ref type="bibr" target="#b34">[35]</ref>, suppressing background samples' gradient leads to a large number of false positives. Therefore, we restrict our loss to foreground samples, while applying the standard Sigmoid function to background samples, and ignore the constant n/k n?n/k to avoid penalizing the background class. Please refer to our code for the above-mentioned implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Proof to Theorem 2</head><p>Setup. Firstly, we define f as, f (x) := ?l(?) + t (37) where l(?) and t is previously defined in the main paper.</p><p>Let err j (t) be the 0-1 loss on example from class j err j (t) = Pr</p><formula xml:id="formula_34">(x,y)?Sj [f (x) &lt; 0] = Pr (x,y)?Sj [l(?) &gt; t]<label>(38)</label></formula><p>and err ?,j (t) be the 0-1 margin loss on example from class j err ?,j (t) = Pr</p><formula xml:id="formula_35">(x,y)?Sj [f (x) &lt; ? j ] = Pr (x,y)?Sj [l(?) + ? j &gt; t]<label>(39)</label></formula><p>Let? rr ?,j (t) denote the empirical variant of err ?,j (t).</p><p>Proof. For any ? &gt; 0 and with probability at least 1 ? ?, for all ? j &gt; 0, and f ? F, Theorem 2 in <ref type="bibr" target="#b16">[17]</ref> directly gives us</p><formula xml:id="formula_36">err j (t) ?? rr ?,j (t) + 4 ? jR j (F) + log(log 2 4B ?j ) n j + log(1/?) 2n j (40)</formula><p>where sup (x,y)?S |l(?) ? t| ? B andR j (F) denotes the empirical Rademacher complexity of function family F. By applying <ref type="bibr" target="#b3">[4]</ref>'s analysis on the empirical Rademacher complexity and union bound over all classes, we have the generalization error bound for the loss on a balanced test set</p><formula xml:id="formula_37">err bal (t) ? 1 k k j=1 ? rr ?,j (t) + 4 ? j C(F) n j + j (? j ) (41) where j (? j ) log(log 2 4B ?j ) n j + log(1/?) 2n j (42)</formula><p>is a low-order term of n j . To minimize the generalization error bound Eqn. 40, we essentially need to minimize k j=1 4 ? j C(F) n j (43)</p><p>By constraining the sum of ? as k j=1 ? j = ?, we can directly apply Cauchy-Schwarz inequality to solve the optimal ? ? *</p><formula xml:id="formula_38">j = ?n ?1/4 j k i=1 n ?1/4 i .</formula><p>(44)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Proof to Corollary 2.1</head><p>Preliminary. Notice thatl * j (?) = l j (?) + ? * j can not be achieved for all class j, since ? log? * j = ? log ? j + ? * j and ? * j &gt; 0 implie?</p><formula xml:id="formula_39">? * j &lt; ? j ; k j=1? * j &lt; k j=1 ? j = 1 (45)</formula><p>The equation above contradicts the definition that the sum of? * should be exactly equal to 1. To solve the contradiction, we introduce a term ? base &gt; 0, such that </p><formula xml:id="formula_40">? log? * j = ? log ? j ? ? base + ? * j ; k j=1? * j = 1<label>(</label></formula><formula xml:id="formula_41">[l(?) + ? j &gt; t + ? base ] = Pr (x,y)?Sj [(l(?) ? ? base ) + ? j &gt; t] (48) err bal (t + ? base ) = Pr (x,y)?S bal [l(?) &gt; t + ? base ] = Pr (x,y)?S bal [(l(?) ? ? base ) &gt; t]<label>(49)</label></formula><p>As ? * is not a function of t, the value of ? * will not be affected by the tweak. Thus, instead of looking forl * j (?) = l j (?) + ? * j that minimizes the generalization bound for err bal (t), we are in fact looking forl * j (?) = (l j (?) ? ? base ) + ? * j that minimizes generalization bound for err bal (t + ? base )</p><p>Proof. In this section, we show thatl j in the corollary is an approximation ofl * j .</p><formula xml:id="formula_42">l j (?) ? (l j (?) ? ? base ) = log ? j ? log? j + ? base (50) = log e ?j k i=1 e ?i ? log e ?j ?log ? * j k i=1 e ?i?log ? * i + ? base (51) = log e ?j k i=1 e ?i ? log e ?j k i=1 e ?i?log ? * i +log ? * j + ? base (52) = log k i=1 e ?i?log ? * i +log ? * j ? log k i=1 e ?i + ? base (53) = ( k i=1 e ?i?log ? * i +log ? * j ? k i=1 e ?i )/? + ? base (Mean-Value Theorem) (54) = (? * j k i=1 1 ? * i e ?i ? k i=1 e ?i )/? + ? base (55) ? ( ? * j ? ( k i=1 e 1 2 ?i ) 2 ? k i=1</formula><p>e ?i )/? + ? base (Cauchy-Schwarz Inequality)</p><formula xml:id="formula_43">(56) = (? * j ? ? k i=1 e ?i ? k i=1 e ?i )/? + ? base (1 ? ? ? k) (57) ? ? * j (let ? = 1, ? base = 1) (58)<label>(59)</label></formula><p>where ? = d dx log(x ) for some x in between k i=1 e ?i?log ? * i +log ? * j and k i=1 e ?i , ? is close to 1 when the model converges. Although the approximation holds under some constraints, we show that it approximately minimizes the generalization bound derived in the last section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Derivation for Eqn.12</head><p>Gradient for positive samples:</p><formula xml:id="formula_44">?l (s) y=j (?) ?? j = ? ? log? (s) j ?? j (60) = ? ? log e ? T j f (x (s) )+log n j n i=1 e ? T i f (x (s) )+log n i ?? j (61) = ? ?? T j f (x (s) ) + log n j ?? j + ? log n i=1 e ? T i f (x (s) )+log ni ?? j (62) = ?f (x (s) ) + f (x (s) ) e ? T j f (x (s) )+log nj n i=1 e ? T i f (x (s) )+log ni (63) = ?f (x (s) ) + f (x (s) )? (s) j (64) = f (x (s) )(? (s) j ? 1)<label>(65)</label></formula><p>Gradient for negative samples:</p><formula xml:id="formula_45">?l (s) y =j (?) ?? j = ? ? log? (s) y ?? j (66) = ? ? log e ? T y f (x (s) )+log ny n i=1 e ? T i f (x (s) )+log n i ?? j (67) = ? ?? T y f (x (s) ) + log n y ?? j + ? log n i=1 e ? T i f (x (s) )+log ni ?? j (68) = f (x (s) ) e ? T j f (x (s) )+log nj n i=1 e ? T i f (x (s) )+log ni (69) = f (x (s) )? (s) j<label>(70)</label></formula><p>Overall gradients on the training dataset:</p><formula xml:id="formula_46">n s=1 l (s) (?) = nj s=1 l (s) y=j (?) + k i =j ni s=1 l (s) y=i (?) (71) = nj s=1 f (x (s) )(? (s) j ? 1) + k i =j ni s=1 f (x (s) )? (s) j<label>(72)</label></formula><p>With Class-Balanced Sampling (CBS), number of samples in each class is equalized and therefore changed from n i and n j to</p><formula xml:id="formula_47">B/k B s=1 l (s) (?) = B/k s=1 f (x (s) )(? (s) j ? 1) + k i =j B/k s=1 f (x (s) )? (s) j<label>(73)</label></formula><p>Set the overall gradient of a training batch to be zero gives</p><formula xml:id="formula_48">B/k s=1 f (x (s) )(1 ?? (s) j ) ? k i =j B/k s=1 f (x (s) )? (s) j = 0<label>(74)</label></formula><p>We can also rewrite the equation using empirical expectation</p><formula xml:id="formula_49">1 n j E (x + ,y=j)?Dtrain [f (x + )(1 ?? j )] ? k i =j 1 n i E (x ? ,y=i)?Dtrain [f (x ? )? j ] = 0 (75)</formula><p>Then we make the following approximation when the training loss is close to 0, i.e.,? </p><formula xml:id="formula_50">(87) = lim ? y =j ?1 n j ? 1 n y ? 1 + 0 1 + 0 (88) = n j /n y<label>(89)</label></formula><p>Therefore, when? y ? 1, Eqn.75 can be expanded as</p><formula xml:id="formula_51">1 n j E (x + ,y=j)?Dtrain [f (x + )(1 ? ? j )] ? k i =j 1 n i E (x ? ,y=i)?Dtrain [f (x ? )? j n j n i ] ? 0<label>(90)</label></formula><p>That is</p><formula xml:id="formula_52">1 n 2 j E (x + ,y=j)?Dtrain [f (x + )(1 ? ? j )] ? k i =j 1 n 2 i E (x ? ,y=i)?Dtrain [f (x ? )? j ] ? 0<label>(91)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Software</head><p>We implement our proposed algorithm with PyTorch-1.3.0 <ref type="bibr" target="#b28">[29]</ref> for all experiments. Second-order derivatives are computed with Higher <ref type="bibr" target="#b7">[8]</ref> library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Training details</head><p>Decoupled Training. Through the paper, we refer to decoupled training as training the last linear classifier on a fixed feature extractor obtained from instance-balanced training.</p><p>Meta Sampler/Reweighter. We apply Meta Sampler/Reweighter only when decoupled training to save computational costs. We start them at the beginning of the decoupled training with no deferment.</p><p>CIFAR-10-LT and CIFAR-100-LT. All experiments use ResNet-32 as backbone like <ref type="bibr" target="#b5">[6]</ref>. We use Nesterov SGD with momentum 0.9 and weight-decay 0.0005 for training. We use a total mini-batch size of 512 images on a single GPU. The learning rate increased from 0.05 to 0.1 in the first 800 iterations. Cosine scheduler <ref type="bibr" target="#b26">[27]</ref> is applied afterward, with a minimum learning rate of 0. Our augmentation follows <ref type="bibr" target="#b34">[35]</ref>. In testing, the image size is 32x32. In end-to-end training, the model is trained for 13K iterations. In decoupled training experiments, we fix the Softmax model, i.e., the instance-balanced baseline model obtained from the previous end-to-end training, as the feature extractor. And the classifier is trained for 2K iterations. For Meta Sampler and Meta Reweighter, we use Adam <ref type="bibr" target="#b19">[20]</ref> with betas (0.9, 0.99) and weight decay 0. The learning rate is set to 0.01 with no warm-up strategy or scheduler applied. The meta-set is formed by randomly sampling 512 images from the training set with replacement, using Class-Balanced Sampling.</p><p>ImageNet-LT and Places-LT. We follow the setup in <ref type="bibr" target="#b17">[18]</ref> for decoupled classifier retraining. We first train a base model without any bells and whistles following Kang et al. <ref type="bibr" target="#b17">[18]</ref> for these two datasets. For ImageNet-LT, the model is trained for 90 epochs from scratch. For Places-LT, we choose ResNet-152 as the backbone network pre-trained on the full ImageNet-2012 dataset and train it on Places-LT following Kang et al <ref type="bibr" target="#b17">[18]</ref>. For both datasets, we use SGD optimizer with momentum 0.9, batch size 512, cosine learning rate schedule <ref type="bibr" target="#b26">[27]</ref> decaying from 0.2 to 0 and image resolution 224 ? 224.</p><p>After obtaining the base model, we retrain the last linear classifier. For Meta Sampler, we use Adam <ref type="bibr" target="#b19">[20]</ref> with betas (0.9, 0.99) and weight decay 0. The learning rate is set to 0.01 with no warm-up strategy and is kept unchanged during the training process. The meta-set is formed by randomly sampling 512 images from the training set with replacement, using Class-Balanced Sampling. For ImageNet-LT, we use SGD optimizer with momentum 0.9, batch size 512, cosine learning rate schedule decaying from 0.2 to 0 for 10 epochs. For Places-LT, we use SGD optimizer with momentum 0.9, batch size 128, cosine learning rate schedule decaying from 0.01 to 0 for 10 epochs.</p><p>For the training process, we resize the image to 224 ? 224. During testing, we first resize the image to 256 ? 256 and do center-crop to obtain an image of 224 ? 224.</p><p>LVIS. We use the off-the-shelf model Mask R-CNN with the backbone network ResNet-50 for LVIS. The backbone network is pre-trained on ImageNet. We follow the setup (including Repeat Factor Sampling) from the original dataset paper <ref type="bibr" target="#b8">[9]</ref> for two baseline models (Softmax and Sigmoid). We use an SGD optimizer with 0.9 momentum, 0.01 initial learning rate, and 0.0001 weight decay. The model is trained for 90k iterations with 8 images per mini-batch. The learning rate is dropped by a factor of 10 at both 60k iterations and 80k iterations.</p><p>Methods other than baselines are trained under the decoupled training scheme, with the abovementioned models as the base model. Slightly different from the decoupled training for classification tasks <ref type="bibr" target="#b17">[18]</ref>, we fine-tune the bounding box classifier (one fully connected layer) instead of retraining it from scratch. This significantly saves the training time. We use an SGD optimizer with 0.9 momentum, 0.02 initial learning rate, and 0.0001 weight decay. The model is trained for 22k iterations with 8 images per mini-batch. The learning rate is dropped by a factor of 10 at both 11k iterations and 18k iterations.</p><p>For our method with a Meta Reweighter, we use Adam optimizer with 0.001 for the Meta Reweighter and train the Meta Reweighter together with the model. The learning rate is kept unchanged during the training process.</p><p>We apply scale jitter and random flip at training time (sampling image scale for the shorter side from 640, 672, 704, 736, 768, 800). For testing, images are resized to a shorter image edge of 800 pixels; no test-time augmentation is used.</p><p>C.4 Meta-learned sample rates with Softmax and Balanced Softmax <ref type="figure" target="#fig_6">Figure 3</ref> demonstrates that compared with standard Softmax function, Meta Sampler learns a more balanced sample rates with our proposed Balanced Softmax. The sample rates for all the classes are initialized with 0.5 and are constrained in the range of (0,1).</p><p>The blue bar represents the learned sample rates with standard Softmax. The sample rates of tail classes approach 1 while the sample rates of head classes approach 0. Such an extreme divergence in sample rates could potentially pose challenges to the meta-learning optimization process. A very low optimal learning rate may also not be numerically stable.</p><p>With Balanced Softmax, we can see that Meta Sampler produces a more balanced distribution of sample rates. After convergence, the sample rates for Softmax has a variance of 0.13. Balanced Softmax significantly reduces the variance to 0.03.      <ref type="bibr" target="#b31">[32]</ref>. ? indicates results reported in <ref type="bibr" target="#b3">[4]</ref>. ? indicates results reported in <ref type="bibr" target="#b34">[35]</ref>.</p><p>the number of samples in the y-th class is n y ? y , where n y is the original number of training samples in the class and ? ? (0, 1). By varying ?, we generate three training sets with the imbalance factors of 200, 100, and 10. The test set is kept unchanged and balance.</p><p>ImageNet-LT. We use the long-tailed version of ImageNet from Liu et al. <ref type="bibr" target="#b25">[26]</ref>. It is created by firstly sampling the class sizes from a Pareto distribution with the power value ? = 6, followed by sampling the corresponding number of images for each class. The ImageNet-LT dataset has 115,846 training images in 1,000 classes, and its imbalance factor is 256 as shown in <ref type="table" target="#tab_8">Table 6</ref>. The original ImageNet <ref type="bibr" target="#b6">[7]</ref> validation set is used as the test set, which contains 50 images for each class.</p><p>Places-LT. In a similar spirit to the long-tailed ImageNet, a long-tailed version of the Places-365 dataset is generated using the same strategy as above. It contains 62,500 training images from 365 classes with an imbalance factor 996. In the test set, there are 100 test images for each class.</p><p>LVIS. We use official training and validation split from LVIS <ref type="bibr" target="#b8">[9]</ref>. No modification is made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix E Comparisons with Reported SOTA Results on CIFAR-LT</head><p>We used our reproduced results on CIFAR-LT in the empirical analysis section in the paper since prior works chose different baselines and cannot be fairly compared with. <ref type="table" target="#tab_9">Table 7</ref> compares our method with more results originally reported in corresponding papers.</p><p>Appendix F More Visualizations and Analysis F.1 Visualization and analysis on the feature space of Balanced Softmax</p><p>Recent work <ref type="bibr" target="#b17">[18]</ref> shows that instance-balanced training results in the best feature space in practice.</p><p>In this section, we use t-SNE to visualize the feature space created by Balanced Softmax. The result is shown in <ref type="figure" target="#fig_7">Fig. 4</ref>. The following pattern can be observed: CBS and Balanced Softmax tend to have a more concentrated center area compared to the Softmax baseline. This indicates that the Softmax baseline's features are more suitable for the classification task than Balanced Softmax and CBS's. Further empirical analysis in <ref type="table" target="#tab_11">Table 8</ref>    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Visualization of re-sampling's effect towards training</head><p>We use a two-dimensional, three-way classification example to demonstrate re-sampling's effect on training a one-layer linear classifier either with standard Softamx or with Balanced Softmax. The result, shown in <ref type="figure">Figure 5</ref>, confirms that the linear classifier's solution is unaffected by re-sampling. Meanwhile, different re-sampling strategies have different effects on the optimization process, where CBS causes the over-balance problem to Balanced Softmax's optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Iterations Softmax Softmax + CBS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Balanced Softmax</head><p>Balanced Softmax + CBS 1000 5000 25000 125000 <ref type="figure">Figure 5</ref>: Visualization of decision boundaries over iterations with different training setups. We create an imbalanced, two-dimensional, dummy dataset of three classes: red, yellow and blue. The red point represents 10000 red samples, the yellow point represents 100 yellow samples and the blue point represents 1 blue sample. Background shading shows the decision surface. Both Softmax and Softmax+CBS converge to symmetric decision boundaries, and Softmax+CBS converges faster than Softmax. Note that symmetric decision boundaries do not optimize for the generalization error bound on an imbalanced dataset <ref type="bibr" target="#b3">[4]</ref>. Both Balanced Softmax and Balanced Softmax+CBS converge to a better solution: they successfully push the decision boundary from the minority class toward the majority class. Compared to Balanced Softmax, Balanced Softmax+CBS shows the over-balance problem: its optimization is dominated by the minority class.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Experiment on CIFAR-100-LT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Balanced Softmax. Comparing (1), (2) with (3), and (5), (8) with</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>? j = log(? j 1</head><label>1</label><figDesc>?? j ? p(x|y = j)p(y = j)/p(x) p(x|y = j)p(y = j)/p(x) ? p(x|y = j)p(y = j)/p(x) p(x|y = j)p(y = j)/p(x) )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>? 1 lim ?y?1 n y e ?y n y e ?y + k i =y n i e ?i = 1 j</head><label>1</label><figDesc>/? j = lim ?y=j ?1n y e ?y n y e ?y + k i =y n i e ?i ?1?j /? j = lim ? y =j ?1n j e ?j n y e ?y + k i =y n i e ?i ?1 n j e ?j e ?j ? e ?y + k i =y e ?i n y e ?y + k i =y n i e ?i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Learned sample rates with Meta-Sampler when training with Softmax and Balanced Softmax. The experiment is on CIFAR-100-LT with imbalanced factor 200. The X-axis denotes classes with a decreasing number of training samples. Y-axis denotes sample rates for different classes. Balanced Softmax gives a smoother distribution compared to Softmax.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>t-SNE visualization of the feature space created by different methods. The experiment is on CIFAR-10-LT with imbalanced factor 200. The 10 colors represent the 10 classes. Compared to Softmax, Softmax+CBS and Balanced Softmax have a more concentrated center area, making them less suitable for classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Top 1 accuracy for CIFAR-10/100-LT. Softmax: the standard cross-entropy loss with Softmax. CBW: class-balanced weighting. CBS: class-balanced sampling. LDAM Loss: LDAM loss without DRW. Results of Focal Loss, Class Balanced Loss, LDAM Loss and Equalization Loss are reproduced with optimal hyper-parameters reported in their original papers. BALMS generally outperforms SOTA methods, especially when the imbalance factor is high. Note that for all compared methods, we reproduce higher accuracy than reported in original papers. Comparison with their originally reported results is provided in the supplmentary materials.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>. Balanced Softmax clearly gives a more balanced likelihood under different imbalance factors. Moreover, we show Meta Sampler's effect on p(y) inFig. 2. Compared to CBS, Meta Sampler significantly relieves the over-balance issue.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell></cell><cell></cell><cell cols="3">ImageNet-LT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Places-LT</cell></row><row><cell>Accuracy</cell><cell></cell><cell cols="2">Many</cell><cell cols="2">Medium</cell><cell>Few</cell><cell cols="2">Overall</cell><cell>Many</cell><cell></cell><cell>Medium</cell><cell cols="2">Few</cell><cell>Overall</cell></row><row><cell cols="2">End-to-end training</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Lifted Loss [33]</cell><cell></cell><cell cols="2">35.8</cell><cell>30.4</cell><cell></cell><cell>17.9</cell><cell>30.8</cell><cell></cell><cell>41.1</cell><cell></cell><cell>35.4</cell><cell></cell><cell>24</cell><cell>35.2</cell></row><row><cell>Focal Loss [25]</cell><cell></cell><cell cols="2">36.4</cell><cell>29.9</cell><cell></cell><cell>16</cell><cell>30.5</cell><cell></cell><cell>41.1</cell><cell></cell><cell>34.8</cell><cell cols="2">22.4</cell><cell>34.6</cell></row><row><cell cols="2">Range Loss [38]</cell><cell cols="2">35.8</cell><cell>30.3</cell><cell></cell><cell>17.6</cell><cell>30.7</cell><cell></cell><cell>41.1</cell><cell></cell><cell>35.4</cell><cell cols="2">23.2</cell><cell>35.1</cell></row><row><cell>OLTR [26]</cell><cell></cell><cell cols="2">43.2</cell><cell>35.1</cell><cell></cell><cell>18.5</cell><cell>35.6</cell><cell></cell><cell>44.7</cell><cell></cell><cell>37.0</cell><cell cols="2">25.3</cell><cell>35.9</cell></row><row><cell cols="2">Equalization Loss [35]</cell><cell>-</cell><cell></cell><cell>-</cell><cell></cell><cell>-</cell><cell>36.4</cell><cell></cell><cell>-</cell><cell></cell><cell>-</cell><cell></cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">Decoupled training</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cRT [18]</cell><cell></cell><cell>-</cell><cell></cell><cell>-</cell><cell></cell><cell>-</cell><cell>41.8</cell><cell></cell><cell>42.0</cell><cell></cell><cell>37.6</cell><cell cols="2">24.9</cell><cell>36.7</cell></row><row><cell>LWS [18]</cell><cell></cell><cell>-</cell><cell></cell><cell>-</cell><cell></cell><cell>-</cell><cell>41.4</cell><cell></cell><cell>40.6</cell><cell></cell><cell>39.1</cell><cell cols="2">28.6</cell><cell>37.6</cell></row><row><cell>BALMS</cell><cell></cell><cell cols="2">50.3</cell><cell>39.5</cell><cell></cell><cell>25.3</cell><cell>41.8</cell><cell></cell><cell>41.2</cell><cell></cell><cell>39.8</cell><cell cols="2">31.6</cell><cell>38.7</cell></row><row><cell>0.18 0.20 0.22</cell><cell cols="2">BS Softmax CBS</cell><cell></cell><cell cols="2">BS + CBS BS + Meta Sampler</cell><cell></cell><cell>0.016 0.020</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.16</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.14</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.012</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.12</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.008</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.08</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.004</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.06</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.04</cell><cell>0</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell></cell><cell>0.000</cell><cell>0</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell>80</cell><cell>100</cell></row><row><cell></cell><cell></cell><cell cols="3">CIFAR-10-LT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">CIFAR-100-LT</cell><cell></cell></row></table><note>Figure 2: Visualization of p(y) on test set with Meta Sampler and CBS. x-axis is the class labels with decreasing training samples and y-axis is the marginal likelihood p(y) on the test set. The result is on CIFAR-10/100-LT with imbalance factor 200. We use decoupled training for the experiment. BS: Balanced Softmax. BS + CBS shows a clear bias towards the tail classes, especially on CIFAR-100-LT. Compared to BS + CBS, BS + Meta Sampler effectively alleviates the over-balance problem.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Top 1 Accuracy on ImageNet-LT and Places-LT. We present results with ResNet-10 [26] for ImageNet-LT and ImageNet pre-trained ResNet-152 for Places-LT. Baseline results are taken from original papers. BALMS generally outperforms the SOTA models.</figDesc><table><row><cell>Method</cell><cell>APm</cell><cell>AP f</cell><cell>APc</cell><cell>APr</cell><cell>AP b</cell></row><row><cell>Softmax</cell><cell>23.7</cell><cell>27.3</cell><cell>24.0</cell><cell>13.6</cell><cell>24.0</cell></row><row><cell>Sigmoid</cell><cell>23.6</cell><cell>27.3</cell><cell>24.0</cell><cell>12.7</cell><cell>24.0</cell></row><row><cell>Focal Loss [25]</cell><cell>23.4</cell><cell>27.5</cell><cell>23.5</cell><cell>12.8</cell><cell>23.8</cell></row><row><cell>Class Balanced Loss [6]</cell><cell>23.3</cell><cell>27.3</cell><cell>23.8</cell><cell>11.4</cell><cell>23.9</cell></row><row><cell>LDAM [4]</cell><cell>24.1</cell><cell>26.3</cell><cell>25.3</cell><cell>14.6</cell><cell>24.5</cell></row><row><cell>LWS [18]</cell><cell>23.8</cell><cell>26.8</cell><cell>24.4</cell><cell>14.4</cell><cell>24.1</cell></row><row><cell>Equalization Loss [35]</cell><cell>25.2</cell><cell>26.6</cell><cell>27.3</cell><cell>14.6</cell><cell>25.7</cell></row><row><cell>Balanced Softmax  ?</cell><cell>26.3</cell><cell>28.8</cell><cell>27.3</cell><cell>16.2</cell><cell>27.0</cell></row><row><cell>BALMS</cell><cell>27.0</cell><cell>27.5</cell><cell>28.9</cell><cell>19.6</cell><cell>27.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>? 0.3 77.4 ? 0.8 90.0 ? 0.2 41.0 ? 0.3 45.3 ? 0.3 61.9 ? 0.1 (2) Balanced Softmax 1 4 71.6 ? 0.7 78.4 ? 0.9 90.5 ? 0.1 41.9 ? 0.2 46.4 ? 0.7 62.6 ? 0.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>CIFAR-10-LT</cell><cell></cell><cell></cell><cell>CIFAR-100-LT</cell><cell></cell></row><row><cell>Imbalance Factor</cell><cell>200</cell><cell>100</cell><cell>10</cell><cell>200</cell><cell>100</cell><cell>10</cell></row><row><cell>End-to-end training</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(1) Softmax</cell><cell cols="6">71.2 3</cell></row><row><cell>(3) Balanced Softmax</cell><cell cols="3">79.0 ? 0.8 83.1 ? 0.4 90.9 ? 0.4</cell><cell cols="3">45.9 ? 0.3 50.3 ? 0.3 63.1 ? 0.2</cell></row><row><cell>Decoupled training</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">(4) Balanced Softmax 1 4 +DT (5) Balanced Softmax 1 4 +DT+MS 76.2 ? 0.4 81.4 ? 0.1 91.0 ? 0.1 72.2 ? 0.1 79.1 ? 0.2 90.2 ? 0.0</cell><cell cols="3">42.3 ? 0.0 46.1 ? 0.1 62.5 ? 0.1 44.1 ? 0.2 49.2 ? 0.1 62.8 ? 0.2</cell></row><row><cell>(6) Balanced Softmax+DT</cell><cell cols="3">78.6 ? 0.1 83.7 ? 0.1 91.2 ? 0.0</cell><cell cols="3">45.1 ? 0.0 50.4 ? 0.0 63.4 ? 0.0</cell></row><row><cell>(7) Balanced Softmax+CBS+DT</cell><cell cols="3">80.6 ? 0.1 84.8 ? 0.0 91.2 ? 0.1</cell><cell cols="3">42.0 ? 0.0 47.4 ? 0.2 62.3 ? 0.0</cell></row><row><cell>(8) DT+MS</cell><cell cols="3">73.6 ? 0.2 79.9 ? 0.4 90.9 ? 0.1</cell><cell cols="3">44.2 ? 0.1 49.2 ? 0.1 63.0 ? 0.0</cell></row><row><cell>(9) Balanced Softmax+DT+MR</cell><cell cols="3">79.2 ? 0.0 84.1 ? 0.0 91.2 ? 0.1</cell><cell>45.3 ? 0.3</cell><cell>50.8 ? 0.0</cell><cell>63.5 ? 0.1</cell></row><row><cell>(10) BALMS</cell><cell>81.5 ? 0.0</cell><cell>84.9 ? 0.1</cell><cell>91.3 ? 0.1</cell><cell>45.5 ? 0.1</cell><cell cols="2">50.8 ? 0.0 63.0 ? 0.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Component Analysis on CIFAR-10/100-LT. CBS: class-balanced sampling. DT: decoupled training without CBS. MS: Meta Sampler. MR: Meta Reweighter. Balanced Softmax 1 4 : the loss variant in Eqn. 10. Balanced Softmax and Meta Sampler both contribute to the final performance.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>To justify the new term ? base , we recall the definition of error</figDesc><table><row><cell>err ?,j (t) = Pr (x,y)?Sj</cell><cell>[l(?) + ? j &gt; t]; err bal (t) =</cell><cell>Pr (x,y)?S bal</cell><cell>[l(?) &gt; t]</cell><cell>(47)</cell></row><row><cell cols="2">If we tweak the threshold t with the term ? base</cell><cell></cell><cell></cell><cell></cell></row><row><cell>err ?,j (t + ? base ) = Pr (x,y)?Sj</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>46)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Details of long-tailed datatsets. Notice that for both CIFAR-10-LT and CIFAR-100-LT, the number of tail class varies with different imbalance factors.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>CIFAR-10-LT</cell><cell></cell><cell></cell><cell>CIFAR-100-LT</cell><cell></cell></row><row><cell>Imbalance Factor</cell><cell>200</cell><cell>100</cell><cell>10</cell><cell>200</cell><cell>100</cell><cell>10</cell></row><row><cell>Focal Loss  *  [25]</cell><cell>65.29</cell><cell>70.38</cell><cell>86.66</cell><cell>35.62</cell><cell>38.41</cell><cell>55.78</cell></row><row><cell>Class Balanced Loss  *  [6]</cell><cell>68.89</cell><cell>74.57</cell><cell>87.49</cell><cell>36.23</cell><cell>39.60</cell><cell>57.99</cell></row><row><cell>L2RW  *  [30]</cell><cell>66.51</cell><cell>74.16</cell><cell>85.19</cell><cell>33.38</cell><cell>40.23</cell><cell>53.73</cell></row><row><cell>LDAM  ? [4]</cell><cell>-</cell><cell>73.35</cell><cell>86.96</cell><cell>-</cell><cell>39.6</cell><cell>56.91</cell></row><row><cell>LDAM-DRW  ? [4]</cell><cell>-</cell><cell>77.03</cell><cell>88.16</cell><cell>-</cell><cell>42.04</cell><cell>58.71</cell></row><row><cell>Meta-Weight-Net  *  [32]</cell><cell>68.89</cell><cell>75.21</cell><cell>87.84</cell><cell>37.91</cell><cell>42.09</cell><cell>58.46</cell></row><row><cell>Equalization Loss  ? [35]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>43.38</cell><cell>-</cell><cell>-</cell></row><row><cell>BALMS</cell><cell>81.5</cell><cell>84.9</cell><cell>91.3</cell><cell>45.5</cell><cell>50.8</cell><cell>63.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Comparisons with reported SOTA results on Top 1 accuracy for CIFAR-LT. * indicates results reported in</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>advocates the claim.</figDesc><table><row><cell>Feature Training</cell><cell cols="2">Classifier Training Accuracy</cell></row><row><cell>Softmax</cell><cell>Softmax</cell><cell>69.53</cell></row><row><cell>Softmax+CBS</cell><cell>Softmax</cell><cell>57.06</cell></row><row><cell>Balanced Softmax</cell><cell>Softmax</cell><cell>65.75</cell></row><row><cell>Softmax</cell><cell>Softmax+CBS</cell><cell>76.59</cell></row><row><cell>Softmax+CBS</cell><cell>Softmax+CBS</cell><cell>63.96</cell></row><row><cell>Balanced Softmax</cell><cell>Softmax+CBS</cell><cell>75.35</cell></row><row><cell>Softmax</cell><cell>Balanced Softmax</cell><cell>78.53</cell></row><row><cell>Softmax+CBS</cell><cell>Balanced Softmax</cell><cell>68.24</cell></row><row><cell>Balanced Softmax</cell><cell>Balanced Softmax</cell><cell>77.04</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Comparison of decoupled training results with features from Softmax and Balanced Softmax. The experiment is on CIFAR-10-LT with imbalanced factor 200. The Softmax pretrained features generally outperform the Balanced Softmax pretrained features.</figDesc><table><row><cell>Softmax</cell><cell>Softmax+CBS</cell><cell>Balanced Softmax</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B Detailed Description for Meta Sampler and Meta Reweighter B.1 Meta Sampler</head><p>To estimate the optimal sample rate, we first make the sampler differentiable. Normally, classbalanced samplers take following steps:</p><p>1. Define a class sample distribution ? = ? 1{y=1} 1 ? 1{y=2} 2 . . . ? 1{y=k} k . 2. Assign ? j to all instance-label pairs (x, y = j) and normalize over the dataset, to give the instance sample distribution ? = ?</p><p>3. Draw discrete image indexes from ? to form a batch with a size b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Augment the images and feed images into a model.</head><p>The steps where discrete sampling and image augmentation happen are usually not differentiable. We propose a simple yet effective method to back-propagate the gradient directly from the loss to the learnable sample rates.</p><p>Firstly, we use the Straight-through Gumbel Estimator <ref type="bibr" target="#b15">[16]</ref> to approximate the gradient through the multinomial sampling:</p><p>where s is the sample result, g is i.i.d. samples drawn from Gumbel(0, 1) and ? is the temperature coefficient. Straight-through means that we use argmax to discretize s to (0,1) during forward and use ?s during backward. Gumbel-Softmax re-parameterization is commonly found to have less variance in gradient estimation than score functions <ref type="bibr" target="#b15">[16]</ref>.</p><p>Then, we use an external memory to connect sampler with loss. We use the Straight-through Gumbel Estimator to draw b discrete samples from ?, we denote as s b?n . s b?n is matrix of a n-dimensional one-hot vectors, representing b selected images. Concretely, for the i-th sample, if the Gumbel Estimator gives a sampling result to be c-th image, we have s (i) to be</p><p>We save this matrix into an external memory during data preparation. After obtaining the classification loss l(?), which is the i-th loss in the batch computed from the c-th sample, we re-weight the loss b?</p><p>Notice that the re-weight will not change the loss value, it only connects sampling results with the classification loss in the computation graph. By doing so, the gradient from the loss can directly reach the learnable sample rate ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Meta Reweighter</head><p>Since one image might contain multiple instances from several categories, we use Meta Reweighter, rather than Meta Sampler on the LVIS dataset. Specifically, we assign the loss weight for instance i to be ? i = ? j , where ? is a learnable class weight and j is the class label of instance i. Next, we perform similar bi-level optimization as in Meta Sampler, where we re-weight the loss of an instance by its loss weight ? i instead of a discrete 0-1 sampling result s i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C Implementation Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Hardware</head><p>We use Intel Xeon Gold 6148 CPU @ 2.40GHz with Nvidia V100 GPU for model training. We take a single GPU to train models on CIFAR-10-LT, CIRFAR-100-LT, ImageNet-LT and Places-LT, and 8 GPUs to train models on LVIS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D More Details Regarding Datasets D.1 Basic information</head><p>We hereby provide more details about datasets mentioned in the paper in <ref type="table">Table 6</ref> All the datasets are publicly available for downloading, we provide the download link as follows: ImageNet, CIFAR-10 and CIFAR-100, Places365, and LVIS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Long-tailed datasets generation</head><p>CIFAR10-LT and CIFAR100-LT. We generated the long-tailed version of CIFAR-10 and CIFAR-100 following Cui et al. <ref type="bibr" target="#b5">[6]</ref>. For both the original CIFAR-10 and CIFAR-100, they contain 50000 training images and 10000 test images at a size of 32 ? 32 uniformly distributed in 10 classes and 100 classes. The long-tailed version is created by randomly reducing training samples. In particular,</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Restricted decontamination for the imbalanced training sample problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Barandela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">Salvador</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesc J</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ferri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Iberoamerican Congress on Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1263" to="1284" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A systematic study of the class imbalance problem in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuto</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej A</forename><surname>Mazurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="249" to="259" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">What is the effect of importance weighting in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="872" to="881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning imbalanced datasets with label-distribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1567" to="1578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Smote: Synthetic minority over-sampling technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">W</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">O</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Philip</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9260" to="9269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">09</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Phu Mon Htut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01727</idno>
		<title level="m">Generalized inner loop metalearning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">LVIS: A dataset for large vocabulary instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Borderline-smote: a new over-sampling method in imbalanced data sets learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Yuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing-Huan</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Computing</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gaussian affinity for max-margin class imbalanced learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munawar</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbing</forename><surname>Syed Waqas Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning from imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1263" to="1284" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning deep representation for imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5375" to="5384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep imbalanced learning for face recognition and attribute prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Change</forename><surname>Loy Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rethinking class-balanced methods for long-tailed visual recognition from a domain adaptation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Categorical reparametrization with gumbel-softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings International Conference on Learning Representations</title>
		<meeting>International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the complexity of linear prediction: Risk bounds, margin bounds, and regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Sham M Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambuj</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="793" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<idno>abs/1910.09217</idno>
		<title level="m">Jiashi Feng, and Yannis Kalantidis. Decoupling representation and classifier for long-tailed recognition. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cost-sensitive learning of deep feature representations from imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Salman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munawar</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ferdous</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Togneri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3573" to="3587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012-05" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Addressing the curse of imbalanced training sets: One-sided selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miroslav</forename><surname>Kubat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Machine Learning</title>
		<meeting>the Fourteenth International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="179" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Gradient harmonized single-stage detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2999" to="3007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2532" to="2541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, highperformance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Relay backpropagation for effective learning of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="467" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Metaweight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1917" to="1928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The implicit bias of gradient descent on separable data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Soudry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mor</forename><surname>Shpigel Nacson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suriya</forename><surname>Gunasekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2822" to="2878" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Equalization loss for long-tailed object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingru</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changbao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7029" to="7039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Identifying and compensating for feature deviation in imbalanced deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han-Jia</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-You</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>De-Chuan Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.01385</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Range loss for deep face recognition with long-tailed training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5419" to="5428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
