<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PLOP: Learning without Forgetting for Continual Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Douillard</surname></persName>
							<email>arthur.douillard@heuritech.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifu</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Dapogny</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
							<email>matthieu.cord@lip6.fr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sorbonne</forename><surname>Universit?</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heuritech</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Datakalab</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valeo</forename><surname>Ai</surname></persName>
						</author>
						<title level="a" type="main">PLOP: Learning without Forgetting for Continual Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning approaches are nowadays ubiquitously used to tackle computer vision tasks such as semantic segmentation, requiring large datasets and substantial computational power. Continual learning for semantic segmentation (CSS) is an emerging trend that consists in updating an old model by sequentially adding new classes. However, continual learning methods are usually prone to catastrophic forgetting. This issue is further aggravated in CSS where, at each step, old classes from previous iterations are collapsed into the background. In this paper, we propose Local POD, a multi-scale pooling distillation scheme that preserves long-and short-range spatial relationships at feature level. Furthermore, we design an entropy-based pseudo-labelling of the background w.r.t. classes predicted by the old model to deal with background shift and avoid catastrophic forgetting of the old classes. Our approach, called PLOP, significantly outperforms state-of-the-art methods in existing CSS scenarios, as well as in newly proposed challenging benchmarks 1 .</p><p>1 Code is available at https://github.com/arthurdouillard/CVPR2021_PLOP old segmentation model (step t-1) new segmentation model (step t)</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Semantic segmentation is a fundamental problem of computer vision, that aims at assigning a label to each pixel of an image. In recent years, the introduction of Convolutional Neural Networks (CNNs) has addressed semantic segmentation in a traditional framework, where all classes are known beforehand and learned at once <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b11">12]</ref>. This setup, however, is quite limited for practical applications. In a more realistic scenario, the model should be able to continuously learn new classes without retraining from scratch. This setup, referred here as Continual Semantic Segmentation (CSS), has emerged very recently for medical applications <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref> before being proposed for general segmentation datasets <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>Deep learning approaches that deal with CSS face two main challenges. The first one, inherited from continual <ref type="figure">Figure 1</ref>: Our two-part strategy aims at learning a segmentation network in a continual learning framework, where old class pixels are collapsed into the background at current stage. We generate pseudo labels from old predictions (blue) to deal with the background shift, and retain shortand long-range spatial dependencies by Local POD distillation (red) to prevent catastrophic forgetting. learning, is called catastrophic forgetting <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b67">68]</ref>, and points to the fact that neural networks tend to completely and abruptly forget previously learned knowledge when learning new information <ref type="bibr" target="#b37">[38]</ref>. Catastrophic forgetting presents a real challenge for continual learning applications based on deep learning methods, especially when storing previously seen data is not allowed for privacy reasons.</p><p>The second issue, CSS specific, is the semantic shift of the background class. In a traditional semantic segmentation setup, the background contains pixels that don't belong to any other class. However, in CSS, the background contains pixels that don't belong to any of the current classes. Thus, for a specific learning step, the background can contain both future classes, not yet seen by the model, as well as old classes. Thus, if nothing is done to distinguish pixels belonging to the real background class from old class pix-els, this background shift phenomenon risks exacerbating the catastrophic forgetting even further <ref type="bibr" target="#b7">[8]</ref>.</p><p>In this paper, we propose a deep learning strategy to address these two challenges in CSS. Instead of reusing old images, our approach, called PLOP , standing for Pseudolabel and LOcal POD leverages the old model in two manners, as illustrated on <ref type="figure">Fig. 1</ref>. First, we propose a featurebased multi-scale distillation scheme to alleviate catastrophic forgetting. Second, we employ a confidence-based pseudo-labeling strategy to retrieve old class pixels within the background. For instance, if a current ground truth mask only distinguish pixels from class sofa and background, our approach allows to assign old classes to background pixels, e.g. classes person, dog or background (the semantic class).</p><p>We thoroughly validate PLOP on several datasets, showcasing significant performance improvements compared to the state-of-the-art methods in existing CSS scenarios. Furthermore, we propose several novel scenarios to further quantify the performances of CSS methods when it comes to long term learning, class presentation order and domain shift. Last but not least, we show that PLOP largely outperforms every CSS approach in these scenarios. To sum it up, our contributions are three-folds:</p><p>? We propose a multi-scale spatial distillation loss to better retain knowledge through the continual learning steps, by preserving long-and short-range spatial relationships, avoiding catastrophic forgetting. ? We introduce a confidence-based pseudo-labeling strategy to identify old classes for the current background pixels and deal with background shift. ? We show that PLOP significantly outperforms state-ofthe-art approaches in existing scenarios and datasets for CSS, as well as in several newly proposed challenging benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>CSS is a relatively new field where only a few recent papers addressed this specific problem. We thus start this section with a brief overview of the recent advances in semantic segmentation as well as continual learning and follow with a more in-depth discussion of existing approaches to CSS. Semantic Segmentation methods based on Fully Convolutional Networks (FCN) <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b64">65]</ref> have achieved impressive results on several segmentation benchmarks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b83">84,</ref><ref type="bibr" target="#b5">6]</ref>. These methods improve the segmentation accuracy by incorporating more spatial information or exploiting contextual information specifically. Atrous convolution <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b52">53]</ref> and encoder-decoder architecture <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b1">2]</ref> are the most common methods for retaining spatial information. Examples of recent works exploiting contextual information include attention mechanisms <ref type="bibr" target="#b75">[76,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b79">80]</ref>, and fixed-scale aggregation <ref type="bibr" target="#b81">[82,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b78">79]</ref>. More recently, Strip Pooling <ref type="bibr" target="#b29">[30]</ref> consists in pooling along the width or height dimensions similarly to POD <ref type="bibr" target="#b17">[18]</ref> as a complement to a spatial pyramid pooling <ref type="bibr" target="#b26">[27]</ref> to capture both global and local statistics.</p><p>Continual Learning models generally face the challenge of catastrophic forgetting of the old classes <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b22">23]</ref>. Several solutions exist to address this problem: for instance, rehearsal learning consists in keeping a limited amount of training data from old classes either as raw images <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b10">11]</ref>, compressed features <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b34">35]</ref>, or generated training data <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b47">48]</ref>. Other works focus on adaptive architectures that can extend themselves to integrate new classes <ref type="bibr" target="#b73">[74,</ref><ref type="bibr" target="#b44">45]</ref> or dynamically re-arrange coexisting sub-networks <ref type="bibr" target="#b21">[22]</ref> each specialized in one specific task <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b33">34]</ref>, or to explicitly correct the classifier drift <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref> that happens with continually changing class distributions. Last but not least, distillation-based methods aim at constraining the model as it changes, either directly on the weights <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b77">78]</ref>, the gradients <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b9">10]</ref>, the output probabilities <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>, intermediary features <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b17">18]</ref>, or combinations thereof.</p><p>Continual Semantic segmentation: Despite enormous progress in the two aforementioned areas respectively, segmentation algorithms are mostly used in an offline setting, while continual learning methods generally focus on image classification. Recent works extend existing continual learning methods <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b30">31]</ref> for medical applications <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref> and general semantic segmentation <ref type="bibr" target="#b53">[54]</ref>. The latter considers that the previously learned categories are properly annotated in the images of the new dataset. This is an unrealistic assumption that fails to consider the background shift: pixels labeled as background at the current step are semantically ambiguous, in that they can contain pixels from old classes (including the real semantic background class, which is generally deciphered first) as well as pixels from future classes. To the best of our knowledge, Cermelli et al. <ref type="bibr" target="#b7">[8]</ref> are the first to address this background shift problem along with catastrophic forgetting. To do so, they apply two loss terms at the output level. First, they use a knowledge distillation loss to reduce forgetting. However, only constraining the output of the network with a distillation term is not enough to preserve the knowledge of the old classes, leading to too much plasticity and, ultimately, catastrophic forgetting. Second, they propose to modify the traditional cross-entropy loss for background pixels to propagate only the sum probability of old classes throughout the continual learning steps. We argue that this constraint is not strong enough to preserve a high discriminative power w.r.t. the old classes when learning new classes under background shift. On the contrary, in what follows, we introduce our PLOP framework and show how it enables learning without forgetting for CSS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PLOP Segmentation Learning Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Continual semantic segmentation framework</head><p>CSS aims at learning a model in t = 1 . . . T steps. For each step, we present a dataset D t that consists in a set of pairs (I t , S t ), where I t denotes an input image of size W ? H and S t the corresponding ground truth segmentation mask. The latter only contains the labels of current classes C t , and all other labels (e.g. old classes C 1:t?1 or future classes C t+1:T ) are collapsed into the background class c bg . However, the model at step t shall be able to predict all the classes seen over time C 1:t . Consequently, we identify two major pitfalls in CSS: the first one, catastrophic forgetting <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b22">23]</ref>, suggests that the network will completely forget the old classes C 1:t?1 when learning C t . Furthermore, catastrophic forgetting is aggravated by the second pitfall, the background shift: at step t, the pixels labeled as background are indeed ambiguous, as they may contain either old (including the real background class, predicted in C 1 ) or future classes. <ref type="figure" target="#fig_1">Fig. 2</ref> (top row) illustrates background shift.</p><p>Classically, a deep model at step t can be written as the composition of a feature extractor f t (?) and a classifier g t (?). Features can be extracted at any layer l of the former f t l (?) , l ? {1, ...L}. We denote? t = g t ? f t (I) the output predicted segmentation mask and ? t the set of learnable parameters for the current network at step t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Multi-scale local distillation with Local POD</head><p>A common solution to alleviate catastrophic forgetting in continual learning consists of using a distillation loss between the predictions of the old and current models <ref type="bibr" target="#b46">[47]</ref>. This distillation loss should constitute a suitable trade-off between too much rigidity (i.e. enforcing too strong constraints, resulting in not being able to learn new classes) and too much plasticity (i.e. enforcing loose constraints, which leads to catastrophic forgetting of the old classes).</p><p>Among existing distillation schemes based on intermediate features <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b30">31]</ref>, POD <ref type="bibr" target="#b17">[18]</ref> consists in matching global statistics at different feature levels between the old and current models. Let x denote an embedding tensor of size H ? W ? C. Extracting a POD embedding ? consists in concatenating the H ?C width-pooled slices and the W ? C height-pooled slices of x:</p><formula xml:id="formula_0">?(x) = 1 W W w=1 x[:, w, :] 1 H H h=1 x[h, :, :] ? R (H+W )?C ,<label>(1)</label></formula><p>where [? ?] denotes concatenation over the channel axis. In our case, this embedding is computed at several layers, for both the old and current model. Then the POD loss consists in minimizing the L2 distance between the two sets of embeddings over the current network parameters ? t :</p><p>Step 1</p><p>Step 2</p><p>Step <ref type="formula" target="#formula_2">3</ref>    <ref type="table">(table)</ref>.</p><formula xml:id="formula_1">L pod (? t ) = 1 L L l=1 ?(f t l (I)) ? ?(f t?1 l (I)) 2 . (2)</formula><p>Due to its ability to constraint spatial statistics instead of raw pixel values, this approach yields state-of-the-art results in the context of continual learning for classification. In the frame of CSS, another interest arises: its ability to model long-range dependencies across a whole axis (horizontal or vertical). However, while spatial information is discarded by global pooling in classification, semantic segmentation requires a higher degree of spatial precision. Therefore, modeling statistics across the whole width or height leads to blurring local statistics important for smaller objects.</p><p>Hence, a suitable distillation scheme for CSS shall retain both long-range and short-range spatial relationships. Thus, inspired from the multi-scale literature <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b26">27]</ref>, we propose a novel Local POD feature distillation scheme, that consists in computing width and height-pooled slices on multiple regions extracted at different scales {1/2 s } s=0...S , as shown on <ref type="figure" target="#fig_2">Fig. 3</ref>. For an embedding tensor x of size H ? W ? C, and at scale 1/2 s , the Local POD embedding ? s (x) at scale s is computed as the concatenation of s 2 POD embeddings: </p><formula xml:id="formula_2">? s (x) = ?(x s 0,0 ) . . . ?(x s s?1,s?1 ) ? R (H+W )?C ,<label>(3)</label></formula><formula xml:id="formula_3">?(x) = ? 1 (x) . . . ? S (x) ? R (H+W )?C?S . (4)</formula><p>We provide in the supplementary materials the complete algorithm of Local POD embedding extraction. We compute Local POD embeddings for several layers of both old and current models. The final Local POD loss is:</p><formula xml:id="formula_4">L LocalPod (? t ) = 1 L L l=1 ?(f t l (I)) ? ?(f t?1 l (I)) 2 . (5)</formula><p>Note that while the first scale of Local POD (1/2 0 ) is equivalent to POD and models long-range dependencies, which are important for segmentation <ref type="bibr" target="#b69">[70,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b29">30]</ref>, the subsequent scales (s = 1/2 1 , 1/2 2 . . . ) enforce short-range dependencies. This constrains the old and current models to have similar statistics over more local regions. Thus, Local POD allows retaining both long-range and short-range spatial relationships, thus alleviating catastrophic forgetting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Solving background shift with pseudo-labeling</head><p>As described above, the pixels labelled as background at step t can belong to either old (including the semantic background class) or future classes. Thus, treating them as background would result in aggravating catastrophic forgetting. Rather, we address background shift with a pseudolabeling strategy for background pixels. Pseudo-labeling <ref type="bibr" target="#b43">[44]</ref> is commonly used in domain adaptation for semantic segmentation <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b63">64]</ref>, where a model is trained on the union of real labels of a source dataset and pseudo labels assigned to an unlabeled target dataset. In our case, we use predictions of the old model for background pixels as clues regarding their real class, most notably if they belong to any of the old classes, as illustrated on <ref type="figure" target="#fig_1">Fig. 2</ref> (middle row). Formally, let C t = card(C t ) ? 1 the cardinality of the current classes excluding the background class. Let? t ? R W,H,1+C 1 +???+C t denote the predictions of the current model (which include the real background class, all the old classes as well as the current ones). We defineS t ? R W,H,1+C 1 +???+C t the target as step t, computed using the one-hot ground-truth segmentation map S t ? R W,H,1+C t at step t as well as pseudo-labels extracted using the old</p><formula xml:id="formula_5">model predictions? t?1 ? R W,H,1+C 1 +???+C t?1</formula><p>as follows:</p><formula xml:id="formula_6">S t (w, h, c) = ? ? ? ? ? ? ? 1 if S t (w, h, c bg ) = 0 and c = argmax c ?C t S t (w, h, c ) 1 if S t (w, h, c bg ) = 1 and c = argmax c ?C 1:t?1? t?1 (w, h, c ) 0 otherwise<label>(6)</label></formula><p>In other words, in the case of non-background pixels we copy the ground truth label. Otherwise, we use the class predicted by the old model g t?1 (f t?1 (?)). This pseudolabel strategy allows to assign each pixel labelled as background his real semantic label if this pixel belongs to any of the old classes. However pseudo-labeling all background pixels can be unproductive, e.g. on uncertain pixels where the old model is likely to fail. Therefore we only retain pseudo-labels where the old model is "confident" enough. Eq. 6 can be modified to take into account this uncertainty:</p><formula xml:id="formula_7">S t (w, h, c)= ? ? ? ? ? ? ? ? ? 1if S t (w, h, c bg )=0 and c=argmax c ?C t S t (w, h, c ) 1if S t (w, h, c bg )=1 and c=argmax c ?C 1:t?1? t?1 (w, h, c ) and u&lt;?c 0 otherwise ,<label>(7)</label></formula><p>where u represents the uncertainty of pixel (w, h) and ? c is a class-specific threshold. Thus, we discard all the pixels for which the old model is uncertain (u ? ? c ) in Eq. 7 and decrement the normalization factor W H by one. We use entropy as the uncertainty measurement u. Specifically, before learning task t, we compute the median entropy for the old model over all pixels of D t predicted as c for all the previous classes c ? C 1:t?1 , which provides in thresholds ? c ? C 1:t?1 , as proposed in <ref type="bibr" target="#b63">[64]</ref>. The cross-entropy loss with pseudo-labeling of the old classes can be written as:</p><formula xml:id="formula_8">L pseudo (? t ) = ? ? W H W,H w,h c?C tS (w, h, c) log? t (w, h, c) ,<label>(8)</label></formula><p>where ? is the ratio of accepted old classes pixels over the total number of such pixels. This ponderation allows to adaptively weight the importance of the pseudo-labeling within the total loss. We call PLOP (standing for Pseudolabeling and LOcal Pod) the proposed approach, that uses both Local POD to avoid catastrophic forgetting, and our uncertainty-based pseudo-labeling to address background shift. To sum it up, the total loss in PLOP is:</p><formula xml:id="formula_9">L(? t ) = L pseudo (? t ) classification +? L localPod (? t ) distillation ,<label>(9)</label></formula><p>with ? an hyperparameter.  To ensure fair comparisons with state-of-the-art approaches, we follow the experimental setup of <ref type="bibr" target="#b7">[8]</ref> for datasets, protocol, metrics, and baseline implementations. Datasets: we evaluate PLOP on 3 segmentation datasets: Pascal-VOC 2012 <ref type="bibr" target="#b19">[20]</ref> (20 classes), ADE20k <ref type="bibr" target="#b83">[84]</ref> (150 classes) and CityScapes <ref type="bibr" target="#b14">[15]</ref> (19 classes from 21 different cities). Full details are in the supplementary materials. CSS protocols: <ref type="bibr" target="#b7">[8]</ref> describes two different CSS settings: Disjoint and Overlapped. In both, only the current classes are labeled vs. a background class C t . However, in the former, images of task t only contain pixels C 1:t?1 ? C t (old and current), while, in the latter, pixels can belong to any classes C 1:t?1 ? C t ? C t+1:T (old, current, and future). Thus, the Overlapped setting is the most challenging and realistic, as in a real setting there isn't any oracle method to exclude future classes from the background. Therefore, in our experiments, we focus on Overlapped CSS but more results for Disjoint CSS can be found in the supplementary materials. While the training images are only labeled for the current classes, the testing images are labeled for all seen classes. We evaluate several CSS protocols for each dataset, e.g. on VOC 19-1, 15-5, and 15-1 respectively consists in learning 19 then 1 class (T = 2 steps), 15 then 5 classes (2 steps), and 15 classes followed by five times 1 class (6 steps). The last setting is the most challenging due to its higher number of steps. Similarly, on ADE 100-50 means 100 followed by 50 classes (2 steps), 100-10 means 100 followed by 5 times 10 classes (6 steps), and so on.</p><p>Metrics: we compare the different models using traditional mean Intersection over Union (mIoU). Specifically, we compute mIoU after the last step T for the initial classes C 1 , for the incremented classes C 2:T , and for all classes C 1:T (all). These metrics respectively reflect the robustness to catastrophic forgetting (the model rigidity), the capacity to learn new classes (plasticity), as well as its overall performance (trade-of between both). We also introduce a novel avg metric (short for average), which measures the average of mIoU scores measured step after step, integrating performance over the whole continual learning process. Baselines: We benchmark our model against the latest stateof-the-arts CSS methods ILT <ref type="bibr" target="#b53">[54]</ref> and MiB <ref type="bibr" target="#b7">[8]</ref>. We also evaluate general continual models based on weight constraints (EWC <ref type="bibr" target="#b39">[40]</ref>) and knowledge distillation (LwF-MC <ref type="bibr" target="#b59">[60]</ref>). More baselines are available in the supplementary materials. All models, ours included, don't use rehearsal learning <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b10">11]</ref> where a limited quantity of previous tasks data can be rehearsed. Finally, we also compare with a reference model learned in a traditional semantic segmentation setting ("Joint model" without continual learning), which may constitute an upper bound for CSS methods. Implementation Details: As in <ref type="bibr" target="#b7">[8]</ref>, we use a Deeplab-V3 <ref type="bibr" target="#b13">[14]</ref> architecture with a ResNet-101 <ref type="bibr" target="#b27">[28]</ref> backbone pretrained on ImageNet <ref type="bibr" target="#b15">[16]</ref> for all experiments. Full details are provided in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Quantitative Evaluation</head><p>First, we compare PLOP with state-of-the-art methods. Pascal VOC 2012: <ref type="table" target="#tab_0">Table 1</ref> shows quantitative experiments on VOC 19-1, 15-5, and 15-1. PLOP outperforms its clos-  Also, the joint model mIoU is 77.40%, thus PLOP narrows the gap compared to state-of-the-art approaches on every CSS scenario. The average mIoU is also improved by +24% compared to MiB, indicating that each CSS step benefits from the improvements related to our method. This is echoed by <ref type="figure" target="#fig_3">Fig. 4</ref>, which shows that while mIoU for both ILT and MiB deteriorates after only a handful of steps, PLOP 's mIoU remains very high throughout, indicating improved resilience to catastrophic forgetting and background shift.</p><p>ADE20k: <ref type="table" target="#tab_1">Table 2</ref> shows experiments on ADE 100-50, 100-10, and 50-50. This dataset is notoriously hard, as the joint model baseline mIoU is only 38.90%. ILT has poor performance in all three scenarios. PLOP shows comparable performance with MiB on the short setting 100-50 (only 2 tasks), improves by 1.09 p.p on the medium setting 50-50 (3 tasks), and significantly outperforms MiB with a wider margin of 2.35 p.p on the long setting 100-10 (6 tasks). In addition to being better on all settings, PLOP showcased an increased performance gain on longer CSS (e.g. 100-10) scenarios, due to increased robustness to catastrophic forgetting and background shift. To further validate this robustness, we propose harder novel CSS scenarios.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">New Protocols and Evaluation</head><p>Longer Continual Learning: We argue that CSS experiments should push towards more steps <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b6">7]</ref> to quantify the robustness of approaches w.r.t. catastrophic forgetting and background shift. We introduce two novel and much more challenging settings with 11 tasks, almost twice as many as the previous longest setting. We report results for VOC 10-1 in <ref type="table" target="#tab_2">Table 3</ref> (10 classes followed by 10 times 1 class) and ADE 100-5 in <ref type="table" target="#tab_3">Table 4</ref> (100 classes followed by 10 times 5 classes). The second previous State-ofthe-Art method, ILT, has a very low mIoU (&lt; 6 on VOC 10-1 and practically null on ADE 100-5). Furthermore, the gap between PLOP and MiB is even wider compared with previous benchmarks (e.g. ?3.6 mIoU on VOC for mIoU of base classes 1-10), which confirms the superiority of PLOP when dealing with long continual processes. Stability w.r.t. class ordering: We already showed that existing continual learning methods may be prone to instability. It has already been shown in related contexts <ref type="bibr" target="#b38">[39]</ref> that class ordering can have a large impact on performance. However, in real-world settings, the optimal class order can never be known beforehand: thus, the performance of an ideal CSS method should be as class order-invariant as possible. In all experiments done so far, this class order has been kept constant, as defined in <ref type="bibr" target="#b7">[8]</ref>. We report results in <ref type="figure" target="#fig_4">Fig. 5</ref> under the form of boxplots obtained by applying 20 random permutations of the class order on VOC 15-1. We report in <ref type="figure" target="#fig_4">Fig. 5 (from left to right)</ref>   <ref type="bibr" target="#b48">[49]</ref> for image classification. <ref type="table" target="#tab_4">Table 5</ref> compares the performance of ILT, MiB, and PLOP on CityScapes 11-5, 11-1, and 1-1, making 3, 11 and 21 steps of 11 + 2 times 5 cities, 11 + 10 times 1 city, and 1 + 20 times 1 city respectively. PLOP performs better by a significant margin in every such scenario compared with ILT and MiB which, in this setting, is equivalent to a simple cross-entropy plus basic knowledge distillation <ref type="bibr" target="#b28">[29]</ref>. Our Local POD, however, retains better domain-related information by modeling long and shortrange dependencies at different representation levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Model Introspection</head><p>We compare several distillation and classification losses on VOC 15-1 to stress the importance of the components of PLOP and report results in <ref type="table" target="#tab_6">Table 6</ref>. All comparisons are evaluated on a val set made with 20% of the train set, therefore results are slightly different from the main experiments. Distillation comparisons: <ref type="table" target="#tab_6">Table 6a</ref> compares different distillation losses when combined with our pseudo-labeling loss. As such, UNKD introduced in <ref type="bibr" target="#b7">[8]</ref> performs better than the Knowledge Distillation (KD) of <ref type="bibr" target="#b28">[29]</ref>, but not at every step (as indicated by the avg. value), which indicates instability during the training process. POD, proposed in <ref type="bibr" target="#b17">[18]</ref>, improves the results on the old classes, but not on the new classes <ref type="bibr" target="#b15">(16)</ref><ref type="bibr" target="#b16">(17)</ref><ref type="bibr" target="#b17">(18)</ref><ref type="bibr" target="#b18">(19)</ref><ref type="bibr" target="#b19">(20)</ref>. In fact, due to too much plasticity, POD model likely overfits and predicts nothing but the new classes, hence a lower mIoU. Finally, Local POD leads to , improves by merging the background with old classes, however, it still struggles to correctly model the new classes, whereas our pseudo-labeling propagates more finely information of the old classes, while learning to predict the new ones, dramatically enhancing the performance in both cases. This penultimate row represents our full PLOP strategy. Also notice that the performance for pseudo-labeling is very close to Pseudo-Oracle (where the incorrect pseudo-labels are removed), which may constitute a performance ceiling of our uncertainty measure. A comparison between these two results illustrates the relevance of our entropy-based uncertainty estimate.</p><p>Vizualisation: <ref type="figure" target="#fig_5">Fig. 6</ref> shows the predictions for both MiB and PLOP on VOC 15-1 across time. At first, both models output equivalent predictions. However, MiB quickly forgets the previous classes and becomes biased towards new classes. On the other hand, PLOP predictions are much more stable on old classes while learning new classes, thanks to Local POD alleviating catastrophic forgetting by spatially constraining representations, and pseudo-labeling dealing with background shift. <ref type="figure" target="#fig_6">Fig. 7</ref> more closely highlights this phenomenon: at first, the ground-truth only contains the class person. At step 5, the class train is introduced. As a result, MiB overfits on train and forgets person. PLOP, instead, manages to avoid forgetting person and predicts decent segmentation for both classes.</p><p>Step 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1-15</head><p>Step 2 <ref type="bibr">16 (plant)</ref> Step 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="17">(sheep)</head><p>Step 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="18">(sofa)</head><p>Step 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="19">(train)</head><p>Step <ref type="formula" target="#formula_6">6</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MiB</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PLOP GT</head><p>Step 1 <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> Step 5 <ref type="bibr">19 (train)</ref> Step <ref type="formula" target="#formula_6">6</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we paved the way for future research on Continual Semantic Segmentation, which is an emerging domain in computer vision. We highlighted two main challenges in Continual Semantic Segmentation (CSS), namely catastrophic forgetting and background shift. To deal with the former, we proposed Local POD, a multi-scale pooling distillation scheme that allows preserving long and shortrange spatial relationships between pixels, leading to a suitable trade-off between rigidity and plasticity for CSS and, ultimately, alleviating catastrophic forgetting. The proposed method is general enough to be used in other related distillation settings, where preserving spatial information is a concern. In addition, we introduced a new strategy to address the background shift based on an efficient pseudolabeling method. We validate our PLOP framework, on several existing CSS scenarios involving multiple datasets. In addition, we propose novel experimental scenarios to assess the performance of future CSS approaches in terms of long term learning capacity and stability. We showed that PLOP performs significantly better than all existing baselines in every such CSS benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Further Work</head><p>In our CSS setting, pixels of task T can belong to old C 1:t?1 , current C t , and future classes C t+1:T . In this paper we cover how to better handle old and current classes. Further works should investigate how to exploit the already present future information with Zeroshot <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b40">41]</ref> as already done in semantic segmentation <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b4">5]</ref> and explored for continual classification <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b18">19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Algorithm view of Local POD</head><p>In Algo. 1, we summarize the algorithm for the proposed Local POD. The algorithm consists in three functions. First, Distillation, loops over all L layers onto which we apply Local POD. Second, LocalPOD, computes the L2 distance (L.26) between POD embeddings of the current (L. <ref type="bibr" target="#b18">19</ref>) and old (L.20) models. It loops over S different scales (L.14) and ? computes the POD embedding given two features maps subsets (L. <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref> as defined in Eq. 1.</p><p>= denotes an in-place concatenation.   <ref type="bibr" target="#b19">[20]</ref>, ADE20k <ref type="bibr" target="#b83">[84]</ref>, and Cityscapes <ref type="bibr" target="#b14">[15]</ref>. VOC contains 20 classes, 10,582 training images, and 1,449 testing images. ADE20k has 150 classes, 20,210 training images, and 2,000 testing images. Cityscapes contains 2975 and 500 images for train and test, respectively. Those images represent 19 classes and were taken from 21 different cities. All ablations and hyperparameters tuning were done on a validation subset of the training set made of 20% of the images. For all datasets, we resize the images to 512 ? 512, with a center crop. An additional random horizontal flip augmentation is applied at training time.</p><p>Implementation details: For all experiments, we use a Deeplab-V3 <ref type="bibr" target="#b13">[14]</ref> architecture with a ResNet-101 <ref type="bibr" target="#b27">[28]</ref> backbone pretrained on ImageNet <ref type="bibr" target="#b15">[16]</ref>, as in <ref type="bibr" target="#b7">[8]</ref>. For all datasets, we set a maximum threshold for the uncertainty measure of Eq. 7 to ? = 1e ? 3. We train our model for 30 and 60 epochs per CSS step on Pascal VOC and ADE, respectively, with an initial learning rate of 1e ? 2 for the first CSS step, and 1e?3 for all the following ones. We reduce the learning rate exponentially with a decay rate of 9e ? 1. We use SGD optimizer with 9e?1 Nesterov momentum. The Local POD factor ? is set to 1e ? 2 and 5e ? 4 for intermediate feature maps and logits, respectively. Moreover, we multiply this factor by the adaptive weighting |C 1:t | /|C t | introduced by <ref type="bibr" target="#b30">[31]</ref> that increases the strength of the distillation the further we are into the continual process. For all feature maps, Local POD is applied before ReLU, with squared pixel values, as in <ref type="bibr" target="#b76">[77,</ref><ref type="bibr" target="#b17">18]</ref>. We use 3 scales for Local POD: 1, 1 /2, and 1 /4, as adding more scales experimentally brought diminishing returns. We use a batch size of 24 distributed on two GPUs. Contrary to many continual models, we don't have access to any task id in inference, therefore our setting/strategy has to predict a class among the set of all seen classes -a realist setting.</p><p>Classes ordering details: For all quantitative experiments on Pascal-VOC 2012 and ADE20k, the same class ordering was used across all evaluated models. For Pascal-VOC 2012 it corresponds to <ref type="bibr">[1, 2, ..., 20]</ref> and ADE20k to <ref type="bibr">[1, 2, .</ref>.., 150] as defined in <ref type="bibr" target="#b7">[8]</ref>. For continual-domain cityscapes, the order of the domains/cities is the following: aachen, bremen, darmstadt, erfurt, hanover, krefeld, strasbourg, tubingen, weimar, bochum, cologne, dusseldorf, hamburg, jena, monchengladbach, stuttgart, ulm, zurich, frankfurt, lindau, and munster.</p><p>In the main paper we showcased a boxplot featuring 20 different class orders for Pascal-VOC 2012 15-1. For the sake of reproducibility, we provide details on these orders: <ref type="bibr">[ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ,</ref>   <ref type="figure" target="#fig_1">1 4 , 9 , 5 , 2 , 1 5 , 8 , 2 0 , 6 , 1 6 , 1 8 , 7 , 1 1 , 1 0 , 1 9 , 3 , 4 , 1 7 , 1 2 , 1 3 ]  [ 1 6 , 1 3 , 1 , 1 1 , 1 2 , 1 8 , 6 , 1 4 , 5 , 3 , 7 , 9 , 2 0 , 1 9 , 1 5 , 4 , 2 , 1 0 , 8 , 1 7 ]  [ 1 0 , 7 , 6 , 1 9 , 1 6 , 8 , 1 7 , 1 , 1 4 , 4 , 9 , 3 , 1 5 , 1 1 , 1 2 , 2 , 1 8 , 2 0 , 1 3</ref> , 5 ] <ref type="bibr">[ 7 , 5 , 3 , 9 ,</ref>  <ref type="figure" target="#fig_1">1 3 , 1 2 , 1 4 , 1 9 , 1 0 , 2 , 1 , 4 , 1 6 , 8 , 1 7 , 1 5 , 1 8 , 6 , 1 1 , 2 0 ]  [ 1 8 , 4 , 1 4 , 1 7 , 1 2 , 1 0 , 7 , 3 , 9 , 1 , 8 , 1 5 , 6 , 1 3 , 2 , 5 , 1 1 , 2 0 , 1 6 , 1 9 ]  [ 5 , 4 , 1 3 , 1 8 , 1 4 , 1 0 , 1 9 , 1 5 , 7 , 9 , 3 , 2 , 8 , 1 6 , 2 0 , 1 , 1 2 , 1 1 , 6 , 1 7 ]  [ 9 , 1 2 , 1 3 , 1 8 , 7 , 1 , 1 5 , 1 7 , 1 0 , 8 , 4 , 5 , 2 0 , 1 6 , 6 , 1 4 , 1 9 , 1 1 , 2 , 3 ]  [ 3 , 1 4 , 1 3 , 1 8 , 2 , 1 1 , 1 5 , 1 7 , 1 0 , 8 , 4</ref> , 5 , 2 0 , 1 6 , 6 , 1 2 , 1 9 , 1 , 7 , 9 ] <ref type="bibr">[ 7 , 5 , 9 ,</ref>  <ref type="figure" target="#fig_1">1 , 1 5 , 1 8 , 1 4 , 3 , 2 0 , 1 0 , 4 , 1 9 , 1 1 , 1 7 , 1 6 , 1 2 , 8 , 6 , 2 , 1 3 ]  [ 3 , 1 4 , 6 , 1 , 2 , 1 1 , 1 2 , 1 7 , 7 , 2 0 , 4 , 5 , 9 , 1 6 , 1 9 , 1 5 , 1 3 , 1 8 , 1 0 , 8</ref> ] [ 1 , 2 , 1 2 , 1 4 , 6 , 1 9 , 1 8 , 1 7 , 5 , 2 0 , 8 , 4 , 9 , 1 6 , 1 0 , 3 , 1 5 , 1 3 , <ref type="bibr">1 1 , 7 ]</ref> In the 15-1 setting, we first learn the first fifteen classes, then increment the five remaining classes one by one. Note that the special class background (0) is always learned during the first task. Hardware and Code: For each experiment, we used two Titan Xp GPUs with 12 Go of VRAM each. The initial step t = 1 for each setting is common to all models, therefore we re-use the weights trained on this step. All models took less than 2 hours to train on Pascal-VOC 2012 15-1, and less than 16 hours on ADE20k 100-10. We distributed the batch size equally on both GPUs. All models are implemented in PyTorch <ref type="bibr" target="#b58">[59]</ref> and runned with half-precision for efficiency reasons with Nvdia's APEX library (https://github.com/NVIDIA/apex) using O1 optimization level. Our code base is based on <ref type="bibr" target="#b7">[8]</ref>'s code (https://github.com/fcdl94/MiB) that we modified to implement our strategy. It is available at https://github.com/arthurdouillard/CVPR2021 PLOP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Additional Experiments</head><p>Model ablation: <ref type="table" target="#tab_9">Table 7</ref> shows the construction of our model component by component on Pascal-VOC 2012 in 15-5 and 15-1. For this experiment, we train our model on 80% of the training set and evaluate on the validation set made of the remaining 20%. We report the mIoU at the final task ("all") and the average of the mIoU after each task ("avg"). We start with a crude baseline made of solely cross-entropy (CE). Pseudo-labeling by itself increases by a large margin performance (eg. 3.99 to 19.74 for 15-1). Applying Local POD reduces drastically the forgetting leading to a massive gain of performance (eg. 19.74 to 50.41 for 15-1). Finally our adaptive factor ? based on the ratio of accepted pseudo-labels over the number of background pixels further increases our overall results (eg. 50.41 to 52.31 for 15-1). The interest of ? arises when PLOP faces hard images where few pseudo-labels will be created due to an overall high uncertainty. In such a case, current classes will be over-represented, which can in turn lead to strong bias towards new classes (i.e. the model will have a tendency to predict one of the new classes for every pixel). The ? factor therefore decreases the overall classification loss on such images, and empirical results confirm its effectiveness. Pascal-VOC 2012 Disjoint: In the main paper, we reported results on Pascal-VOC 2012 Overlap. For reasons mentioned previously, Overlap is a more realist setting than Disjoint. Nevertheless, for the sake of comparison, we also provide results in <ref type="table" target="#tab_10">Table 8</ref> in the Disjoint setting. While PLOP has similar performance to MiB in 15-5 (the differences are not significant), it significantly outperforms previous state-of-the-art methods in both 19-1 and 15-1. Pascal-VOC 2012 Overlap with more baselines: In Table 9, we report results on Pascal-VOC 2012 Overlap with more baselines. In addition to the models presented in the main paper, we add a naive Fine Tuning, two continual models based on weights constraints (PI <ref type="bibr" target="#b77">[78]</ref> and RW <ref type="bibr" target="#b8">[9]</ref>), and one continual model based on knowledge distillation (LwF <ref type="bibr" target="#b46">[47]</ref>). PLOP surpasses these methods in all CSS scenarios.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Background shift example in ground truth masks (top row). At step 2 background pixels contain old (person) and future classes (bottle). The model's target (middle row) is the union of the ground-truth and the pseudo-labels (with transparent filtered uncertain pixels) generated by the previous model. The latter helps the current model predictions (bottom row) to retain information of the old classes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>where ?i = 0 . . . s?1, ?j = 0 . . . s?1, x s i,j = x[iH/s : (i+1)H/s, jW/s : (j+1)W/s, :] is a sub-region of the embedding tensor x of size W/s ? H/s. We then concatenate (along channel axis) the Local POD embeddings ? s (x) of each scale s to form the final embedding: Illustration of local POD. An embedding of size W ? H ? C is pooled at S scales with POD with a spatialpyramid scheme. Here applying local POD with S = 2 and scales 1 and 1/2 respectively produces 1, and 4 POD embeddings making S ? C ? (H + W ) dimensions total.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>mIoU evolution on Pascal-VOC 2012 15-1. While MiB's mIoU quickly deteriorates, PLOP's mIoU remains high, due to improved resilience to catastrophic forgetting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Boxplots of the mIoU of initial classes<ref type="bibr" target="#b0">(1)</ref><ref type="bibr" target="#b1">(2)</ref><ref type="bibr" target="#b2">(3)</ref><ref type="bibr" target="#b3">(4)</ref><ref type="bibr" target="#b4">(5)</ref><ref type="bibr" target="#b5">(6)</ref><ref type="bibr" target="#b6">(7)</ref><ref type="bibr" target="#b7">(8)</ref><ref type="bibr" target="#b8">(9)</ref><ref type="bibr" target="#b9">(10)</ref><ref type="bibr" target="#b10">(11)</ref><ref type="bibr" target="#b11">(12)</ref><ref type="bibr" target="#b12">(13)</ref><ref type="bibr" target="#b13">(14)</ref><ref type="bibr" target="#b14">(15)</ref>, new<ref type="bibr" target="#b15">(16)</ref><ref type="bibr" target="#b16">(17)</ref><ref type="bibr" target="#b17">(18)</ref><ref type="bibr" target="#b18">(19)</ref><ref type="bibr" target="#b19">(20)</ref>, all, and average for 20 random class orderings. PLOP is significantly better and more stable than MiB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Visualization of MiB and PLOP predictions across time in VOC 15-1 for two test images. MiB quickly forgets the initial 15 classes (row 1: person and table, row 3: bird) in favor of new classes (plant, sheep, sofa, train) and is biased towards new classes. PLOP, however, barely suffers from catastrophic forgetting (rows 2+4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Visualization of MiB and PLOP predictions across time in VOC 15-1 on a test set image. At steps 1-4 only class person has been seen. At step 5, the class train is introduced, causing dramatic background shift. While MiB overfits on the new class and forget the old class, PLOP is able to predict both classes correctly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Algorithm 1 11 :</head><label>111</label><figDesc>Local POD algorithm 1: function DISTILLATION(f t , f t?1 , x, S) function LOCALPOD(h t , h t?1 , S)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Continual Semantic Segmentation results on Pascal-VOC 2012 in Mean IoU (%). ?: results excerpted from [8]. Other results comes from re-implementation. 23.59 69.15 73.28 76.37 49.97 70.08 75.12 34.22 13.50 29.29 54.19 PLOP 75.35 37.35 73.54 75.47 75.73 51.71 70.09 75.19 65.12 21.11 54.64 67.21</figDesc><table><row><cell></cell><cell></cell><cell cols="2">19-1 (2 tasks)</cell><cell></cell><cell cols="2">15-5 (2 tasks)</cell><cell></cell><cell></cell><cell cols="2">15-1 (6 tasks)</cell></row><row><cell>Method</cell><cell>0-19</cell><cell>20</cell><cell>all</cell><cell>avg</cell><cell>0-15 16-20</cell><cell>all</cell><cell>avg</cell><cell cols="2">0-15 16-20</cell><cell>all</cell><cell>avg</cell></row><row><cell>EWC  ? [40]</cell><cell cols="3">26.90 14.00 26.30</cell><cell></cell><cell cols="2">24.30 35.50 27.10</cell><cell></cell><cell>0.30</cell><cell>4.30</cell><cell>1.30</cell></row><row><cell cols="4">LwF-MC  ? [60] 64.40 13.30 61.90</cell><cell></cell><cell cols="2">58.10 35.00 52.30</cell><cell></cell><cell>6.40</cell><cell>8.40</cell><cell>6.90</cell></row><row><cell>ILT  ? [54]</cell><cell cols="3">67.10 12.30 64.40</cell><cell></cell><cell cols="2">66.30 40.60 59.90</cell><cell></cell><cell>4.90</cell><cell>7.80</cell><cell>5.70</cell></row><row><cell>ILT [54]</cell><cell cols="7">67.75 10.88 65.05 71.23 67.08 39.23 60.45 70.37</cell><cell>8.75</cell><cell>7.99</cell><cell cols="2">8.56 40.16</cell></row><row><cell>MiB  ? [8]</cell><cell cols="3">70.20 22.10 67.80</cell><cell></cell><cell cols="2">75.50 49.40 69.00</cell><cell></cell><cell cols="3">35.10 13.50 29.70</cell></row><row><cell>MiB [8]</cell><cell>71.43</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Continual Semantic Segmentation results on ADE20k in Mean IoU (%).</figDesc><table><row><cell></cell><cell></cell><cell cols="2">100-50 (2 tasks)</cell><cell></cell><cell cols="2">50-50 (3 tasks)</cell><cell></cell><cell></cell><cell>100-10 (6 tasks)</cell></row><row><cell cols="3">Method 0-100 101-150</cell><cell>all</cell><cell>avg</cell><cell>0-50 51-150</cell><cell>all</cell><cell>avg</cell><cell cols="2">0-100 101-150</cell><cell>all</cell><cell>avg</cell></row><row><cell cols="2">ILT [54] 18.29</cell><cell>14.40</cell><cell cols="2">17.00 29.42</cell><cell>3.53 12.85</cell><cell cols="2">9.70 30.12</cell><cell>0.11</cell><cell>3.06</cell><cell>1.09 12.56</cell></row><row><cell cols="2">MiB [8] 40.52</cell><cell>17.17</cell><cell cols="5">32.79 37.31 45.57 21.01 29.31 38.98</cell><cell>38.21</cell><cell>11.12</cell><cell>29.24 35.12</cell></row><row><cell>PLOP</cell><cell>41.87</cell><cell>14.89</cell><cell cols="5">32.94 37.39 48.83 20.99 30.40 39.42</cell><cell>40.48</cell><cell>13.61</cell><cell>31.59 36.64</cell></row><row><cell cols="2">4. Experiments</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>4.1. Datasets, Protocols, and Baselines</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Mean IoU on Pascal-VOC 2012 10-1. ] 12.25 13.09 12.65 42.67 PLOP 44.03 15.51 30.45 52.32</figDesc><table><row><cell></cell><cell cols="3">VOC 10-1 (11 tasks)</cell></row><row><cell cols="3">Method 0-10 11-20</cell><cell>all</cell><cell>avg</cell></row><row><cell>ILT [54]</cell><cell>7.15</cell><cell>3.67</cell><cell cols="2">5.50 25.71</cell></row><row><cell>MiB [8</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Mean IoU on ADE20k 100-5.</figDesc><table><row><cell></cell><cell cols="3">ADE 100-5 (11 tasks)</cell><cell></cell></row><row><cell cols="3">Method 0-100 101-150</cell><cell>all</cell><cell>avg</cell></row><row><cell>ILT [54]</cell><cell>0.08</cell><cell>1.31</cell><cell>0.49</cell><cell>7.83</cell></row><row><cell cols="2">MiB [8] 36.01</cell><cell>5.66</cell><cell cols="2">25.96 32.69</cell></row><row><cell>PLOP</cell><cell>39.11</cell><cell>7.81</cell><cell cols="2">28.75 35.25</cell></row></table><note>est contender, MiB [8] on all evaluated settings by a sig- nificant margin. On 19-1, the forgetting of old classes (1- 19) is reduced by 4.39 percentage points ( p.p) while per- formance on new classes is greatly improved (+13.76 p.p). On 15-5, our model is on par with our re-implementation of MiB, and surpasses the original paper scores [8] by 1 p.p. On the most challenging 15-1 setting, general con- tinual models (EWC and LwF-MC) and ILT all have very low mIoU. While MiB shows significant improvements, PLOP still outperforms it by a wide margin: +86% on all classes, +90% on old classes, and +56% on new classes.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Final mIoU for Continual-domain Cityscapes.</figDesc><table><row><cell cols="4">Method 11-5 (3 tasks) 11-1 (11 tasks) 1-1 (21 tasks)</cell></row><row><cell>ILT [54]</cell><cell>59.14</cell><cell>57.75</cell><cell>30.11</cell></row><row><cell>MiB [8]</cell><cell>61.51</cell><cell>60.02</cell><cell>42.15</cell></row><row><cell>PLOP</cell><cell>63.51</cell><cell>62.05</cell><cell>45.24</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>the mIoU for the old, new classes, all classes, and average over CSS steps. In all cases, PLOP surpasses MiB in term of avg mIoU. Furthermore, the standard deviation (e.g. 10% vs 5% on all) is always significantly lower, showing the excellent stability of PLOP compared with existing approaches.</figDesc><table /><note>Domain Shift: The previous experimental setups mainly assess the capacity of CSS methods to integrate new classes, i.e. to deal with catastrophic forgetting and background shift at a semantic level. However, a domain shift can also happen in CSS scenarios. Thus, we propose a novel bench- mark on Cityscapes to quantify robustness to domain shift, in which all 19 classes will be known from the start and, instead of adding new classes, each step brings a novel do- main (e.g. a new city), similarly to the NI setting of</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Comparison studies on Pascal-VOC 2012 15-1 on a validation subset of 20% of the training set. (a) Pseudo loss (Eq. 8) with different distillation losses.</figDesc><table><row><cell>Distillation loss</cell><cell cols="2">0-15 16-20</cell><cell>all</cell><cell>avg</cell></row><row><cell cols="2">Knowledge Distillation 29.72</cell><cell cols="3">4.42 23.69 49.18</cell></row><row><cell>UNKD</cell><cell>34.85</cell><cell cols="3">5.26 27.80 46.39</cell></row><row><cell>POD</cell><cell>43.94</cell><cell cols="3">4.82 34.62 53.35</cell></row><row><cell>Local POD (Eq. 5)</cell><cell cols="4">63.06 17.92 52.31 65.71</cell></row><row><cell cols="5">(b) Local POD loss (Eq. 5) with different classification losses.</cell></row><row><cell cols="3">Classification loss 0-15 16-20</cell><cell>all</cell><cell>avg</cell></row><row><cell>CE only on new</cell><cell>12.95</cell><cell cols="3">2.54 10.47 47.02</cell></row><row><cell>CE</cell><cell>33.80</cell><cell cols="3">4.67 26.87 50.79</cell></row><row><cell>UNCE</cell><cell>48.46</cell><cell cols="3">4.82 38.62 53.19</cell></row><row><cell>Pseudo (Eq. 8)</cell><cell cols="4">63.06 17.92 52.31 65.71</cell></row><row><cell>Pseudo-Oracle</cell><cell cols="4">63.69 23.35 54.09 66.05</cell></row></table><note>superior performance (+20 p.p) w.r.t. all metrics, due to its integration of both long and short-range dependencies. This final row represents our full PLOP strategy. Classification comparisons: Table 6b compares different classification losses when combined with our Local POD distillation loss. Cross-Entropy (CE) variants perform poorly, especially on new classes. UNCE, introduced in [8]</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>We evaluate our model on three datasets Pascal-VOC</figDesc><table><row><cell></cell><cell></cell><cell>A.3. Reproducibility</cell></row><row><cell></cell><cell></cell><cell>Datasets:</cell></row><row><cell>12:</cell><cell>P t ? [ ]</cell><cell></cell></row><row><cell>13:</cell><cell>P t?1 ? [ ]</cell><cell></cell></row><row><cell>14:</cell><cell>for s ? 0; s &lt; S; s++ do</cell><cell>Eq. 3</cell></row><row><cell>15:</cell><cell>w ? W /2 s</cell><cell></cell></row><row><cell>16:</cell><cell>h ? H /2 s</cell><cell></cell></row><row><cell>17:</cell><cell>for i ? 0; i &lt; W ? w; i+ = w do</cell><cell></cell></row><row><cell>18:</cell><cell>for j ? 0; j &lt; H ? h; j+ = h do</cell><cell></cell></row><row><cell>19:</cell><cell>p t ? ?(h t [i:i+w, j:j+h])</cell><cell>Eq. 1</cell></row><row><cell>20:</cell><cell>p t?1 ? ?(h t?1 [i:i+w, j:j+h])</cell><cell></cell></row><row><cell>21:</cell><cell>P t = p t</cell><cell></cell></row><row><cell>22:</cell><cell>P t?1 = p t?1</cell><cell></cell></row><row><cell>23:</cell><cell>end for</cell><cell></cell></row><row><cell>24:</cell><cell>end for</cell><cell></cell></row><row><cell>25: 26:</cell><cell>end for return P t ? P t?1 2</cell><cell>Eq. 5</cell></row><row><cell cols="2">27: end function</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Ablations of PLOP on the Pascal-VOC 2012 dataset in 15-5 and 15-1. Scores are measured on a validation subset made of 20% of the training set. 15-5 (2 tasks) 15-1 (6 tasks) 73.07 19.74 44.48 Pseudo + Local POD 70.29 75.13 50.41 64.95 ?Pseudo + Local POD 71.43 75.70 52.31 65.71</figDesc><table><row><cell>Model</cell><cell>all</cell><cell>avg</cell><cell>all</cell><cell>avg</cell></row><row><cell>CE</cell><cell cols="2">13.85 46.91</cell><cell cols="2">3.99 19.37</cell></row><row><cell>Pseudo</cell><cell>66.19</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>Mean IoU on the Pascal-VOC 2012 dataset for different incremental class learning scenarios, all in Disjoint. ? denotes results from Cermelli et al.[8]. 25.60 67.40 71.80 43.30 64.70 46.20 12.90 37.90 PLOP 75.37 38.89 73.64 75.71 71.00 42.82 64.29 72.05 57.86 13.67 46.48 62.67</figDesc><table><row><cell></cell><cell></cell><cell cols="2">19-1 (2 tasks)</cell><cell></cell><cell cols="2">15-5 (2 tasks)</cell><cell></cell><cell></cell><cell cols="2">15-1 (6 tasks)</cell></row><row><cell>Method</cell><cell>0-19</cell><cell>20</cell><cell>all</cell><cell>avg</cell><cell>0-15 16-20</cell><cell>all</cell><cell>avg</cell><cell cols="2">0-15 16-20</cell><cell>all</cell><cell>avg</cell></row><row><cell>Fine Tuning  ?</cell><cell cols="2">5.80 12.30</cell><cell>6.20</cell><cell></cell><cell>1.10 33.60</cell><cell>9.20</cell><cell></cell><cell>0.20</cell><cell>1.80</cell><cell>0.60</cell></row><row><cell>PI  ? [78]</cell><cell cols="2">5.40 14.10</cell><cell>5.90</cell><cell></cell><cell>1.30 34.10</cell><cell>9.50</cell><cell></cell><cell>0.00</cell><cell>1.80</cell><cell>0.40</cell></row><row><cell>EWC  ? [40]</cell><cell cols="3">23.20 16.00 22.90</cell><cell></cell><cell cols="2">26.70 37.70 29.40</cell><cell></cell><cell>0.30</cell><cell>4.30</cell><cell>1.30</cell></row><row><cell>RW  ? [9]</cell><cell cols="3">19.40 15.70 19.20</cell><cell></cell><cell cols="2">17.90 36.90 22.70</cell><cell></cell><cell>0.20</cell><cell>5.40</cell><cell>1.50</cell></row><row><cell>LwF  ? [47]</cell><cell>53.00</cell><cell cols="2">9.10 50.80</cell><cell></cell><cell cols="2">58.40 37.40 53.10</cell><cell></cell><cell>0.80</cell><cell>3.60</cell><cell>1.50</cell></row><row><cell cols="4">LwF-MC  ? [60] 63.00 13.20 60.50</cell><cell></cell><cell cols="2">67.20 41.20 60.70</cell><cell></cell><cell>4.50</cell><cell>7.00</cell><cell>5.20</cell></row><row><cell>ILT  ? [54]</cell><cell cols="3">69.10 16.40 66.40</cell><cell></cell><cell cols="2">63.20 39.50 57.30</cell><cell></cell><cell>3.70</cell><cell>5.70</cell><cell>4.20</cell></row><row><cell>MiB  ? [8]</cell><cell>69.60</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Mean IoU on the Pascal-VOC 2012 dataset for different incremental class learning scenarios, all in Overlap. ? denotes results from Cermelli et al. [8], all other results are from us. 10.88 65.05 71.23 67.08 39.23 60.45 70.37 8.75 7.99 8.56 40.16 MiB ? [8] 70.20 22.10 67.80 75.50 49.40 69.00 35.10 13.50 29.70 MiB [8] 71.43 23.59 69.15 73.28 76.37 49.97 70.08 75.12 34.22 13.50 29.29 54.19 PLOP 75.35 37.35 73.54 75.47 75.73 51.71 70.09 75.19 65.12 21.11 54.64 67.21</figDesc><table><row><cell></cell><cell></cell><cell cols="2">19-1 (2 tasks)</cell><cell></cell><cell cols="2">15-5 (2 tasks)</cell><cell></cell><cell></cell><cell cols="2">15-1 (6 tasks)</cell></row><row><cell>Method</cell><cell>0-19</cell><cell>20</cell><cell>all</cell><cell>avg</cell><cell>0-15 16-20</cell><cell>all</cell><cell>avg</cell><cell cols="2">0-15 16-20</cell><cell>all</cell><cell>avg</cell></row><row><cell>Fine Tuning  ?</cell><cell cols="2">6.80 12.90</cell><cell>7.10</cell><cell></cell><cell>2.10 33.10</cell><cell>9.80</cell><cell></cell><cell>0.20</cell><cell>1.80</cell><cell>0.60</cell></row><row><cell>PI  ? [78]</cell><cell cols="2">7.50 14.00</cell><cell>7.80</cell><cell></cell><cell>1.60 33.30</cell><cell>9.50</cell><cell></cell><cell>0.00</cell><cell>1.80</cell><cell>0.50</cell></row><row><cell>EWC  ? [40]</cell><cell cols="3">26.90 14.00 26.30</cell><cell></cell><cell cols="2">24.30 35.50 27.10</cell><cell></cell><cell>0.30</cell><cell>4.30</cell><cell>1.30</cell></row><row><cell>RW  ? [9]</cell><cell cols="3">23.30 14.20 22.90</cell><cell></cell><cell cols="2">16.60 34.90 21.20</cell><cell></cell><cell>0.00</cell><cell>5.20</cell><cell>1.30</cell></row><row><cell>LwF  ? [47]</cell><cell>51.20</cell><cell cols="2">8.50 49.10</cell><cell></cell><cell cols="2">58.90 36.60 53.30</cell><cell></cell><cell>1.00</cell><cell>3.90</cell><cell>1.80</cell></row><row><cell cols="4">LwF-MC  ? [60] 64.40 13.30 61.90</cell><cell></cell><cell cols="2">58.10 35.00 52.30</cell><cell></cell><cell>6.40</cell><cell>8.40</cell><cell>6.90</cell></row><row><cell>ILT  ? [54]</cell><cell cols="3">67.10 12.30 64.40</cell><cell></cell><cell cols="2">66.30 40.60 59.90</cell><cell></cell><cell>4.90</cell><cell>7.80</cell><cell>5.70</cell></row><row><cell>ILT [54]</cell><cell>67.75</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments: This work was granted access to the HPC resources of IDRIS under the allocation AD011011706 made by GENCI.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Memory aware synapses: Learning what (not) to forget</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahaf</forename><surname>Aljundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Babiloni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2017" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Il2m: Class incremental learning with dual memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eden</forename><surname>Belouadah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scail: Classifier weights scaling for class incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eden</forename><surname>Belouadah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Winter Conference on Application of Computer Vision (WACV)</title>
		<meeting>the IEEE Winter Conference on Application of Computer Vision (WACV)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Zero-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Coco-stuff: Thing and stuff classes in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Jasper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">End-to-end incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicol?s</forename><surname>Manuel J Mar?n-Jim?nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Guil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karteek</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Modeling the background for incremental learning in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Cermelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Riemannian walk for incremental learning: Understanding forgetting and intransigence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslan</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puneet</forename><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thalaiyasingam</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient lifelong learning with a-gem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslan</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elhoseiny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On tiny episodic memories in continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslan</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thalaiyasingam</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Puneet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML) Workshop</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Rethinking atrous convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
	<note>In arXiv preprint library</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Reheld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning without memorizing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prithviraj</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajat Vikram</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan-Chuan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Podnet: Pooled outputs distillation for small-tasks incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Douillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Ollion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Valle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Insights from the future for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Douillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Ollion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>In arXiv preprint library</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mark Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Ali Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">PathNet: Evolution Channels Gradient Descent in</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisantha</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Banarse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yori</forename><surname>Zwols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Super Neural Networks. arXiv preprint library</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The lottery ticket hypothesis: Finding sparse, trainable neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Carbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Catastrophic forgetting in connectionist networks. Trends in cognitive sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>French</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dual attention network for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijie</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Continual learning via neural pruning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siavash</forename><surname>Golkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS) Workshop</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Remind your neural network to prevent catastrophic forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><forename type="middle">L</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kushal</forename><surname>Kafle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robik</forename><surname>Shrestha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manoj</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Kanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Spatial pyramid pooling in deep convolutional networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS) Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Strip pooling: Rethinking spatial pooling for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning a unified classifier incrementally via rebalancing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saihui</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Ccnet: Criss-cross attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Ccnet: Criss-cross attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Humphrey</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<idno>2020. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Compacting, picking and growing for unforgetting continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Hao</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-En</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Hung</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Song</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Memory-efficient incremental learning through feature adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Zero-shot semantic segmentation via variational mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoki</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihiko</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoharu</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV) Workshop</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV) Workshop</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fearnet: Braininspired model for incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Kemker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Kanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Measuring catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Kemker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Mcclure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelina</forename><surname>Abitino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><forename type="middle">L</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Kanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Incremental learning with maximum entropy regularization: Rethinking forgetting and intransigence. arXiv preprint library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihwan</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeonsik</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghyun</forename><surname>Choi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kieran</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Generalized zero-shot learning via synthesized examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gundeep</forename><surname>Vinay Kumar Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning to detect unseen object classes by between-class attribute transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hermeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. Object Categorization: Computer and Human Vision Perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Ponce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML) Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learn to grow: A continual structure learning framework for overcoming catastrophic forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingbo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Mnemonics training: Multi-class incremental learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoyao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuting</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">An-An</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Core50: a new dataset and benchmark for continuous object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincenzo</forename><surname>Lomonaco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Maltoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Conference on Robot Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Rehearsal-free continual learning over small non-i.i.d. batches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincenzo</forename><surname>Lomonaco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Maltoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Pellegrini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshop</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshop</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Gradient episodic memory for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Efficient spatial pyramid of dilated convolutions for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anat</forename><surname>Caspi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><forename type="middle">G</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Incremental learning techniques for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umberto</forename><surname>Michieli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Zanuttigh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV) Workshop</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV) Workshop</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learn the new, keep the old: Extending pretrained models with new anatomy and images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Firat</forename><surname>Ozdemir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fuernstahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orcun</forename><surname>Goksel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Extending pretrained segmentation networks with additional anatomical structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Firat</forename><surname>Ozdemir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orcun</forename><surname>Goksel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International journal of computer assisted radiology and surgery</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Knowledge distillation for semantic segmentation using channel and spatial correlations and adaptive cross entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangyong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Seok Heo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sensors</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS) Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">icarl: Incremental classifier and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Sylvestre-Alvise Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Sperl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting, rehearsal and pseudorehearsal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Robins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samira</forename><forename type="middle">Ebrahimi</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Fitnets: Hints for thin deep nets. arXiv preprint library</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Esl: Entropy-guided self-supervised learning for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Saporta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
		<idno>2020. 4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshop</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshop</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Overfeat: Integrated recognition, localization and detection using convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Micha? Mathieu, Rob Fergus, and Yann LeCun</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Continual learning with deep generative replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanul</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehong</forename><surname>Jung Kwon Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Hierarchical multi-scale attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Sapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In arXiv preprint library, 2020. 1, 2</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Lifelong learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer Learning to Learn</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himalaya</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Axial-deeplab: Standalone axial-attention for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<idno>2020. 4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision</title>
		<meeting>the IEEE European Conference on Computer Vision</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Bookworm continual learning: beyond zero-shot learning and continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Herranz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjan</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van De Weijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV) Workshop, 2020</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV) Workshop, 2020</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Supermasks in superposition for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Wortsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosanne</forename><surname>Vivek Ramanujan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Large scale incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuancheng</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Lifelong learning with dynamically expandable networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehong</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunho</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeongtae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung</forename><forename type="middle">Ju</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Objectcontextual representations for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Ocnet: Object context network for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>In arXiv preprint library</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Continual learning through synaptic intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Friedemann</forename><surname>Zenke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Context encoding for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><forename type="middle">J</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambrish</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Agrawal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Resnest: Splitattention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongruo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Smola</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In arXiv preprint library, 2020. 1, 2</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Maintaining discrimination and fairness in class incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guojun</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shutao</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Psanet: Pointwise spatial attention network for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Scene parsing through ade20k dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adela</forename><surname>Barriuso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">M2kd: Multi-model and multilevel knowledge distillation for incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>arXiv preprint library</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Bvk Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Conference on Computer Vision (ECCV)</title>
		<meeting>the IEEE European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
