<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SRL4ORL: Improving Opinion Role Labeling Using Multi-Task Learning With Semantic Role Labeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><surname>Marasovi?</surname></persName>
							<email>marasovic@cl.uni-heidelberg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational Linguistics</orgName>
								<orgName type="laboratory">Research Training Group AIPHES</orgName>
								<orgName type="institution">Heidelberg University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Frank</surname></persName>
							<email>frank@cl.uni-heidelberg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational Linguistics</orgName>
								<orgName type="laboratory">Research Training Group AIPHES</orgName>
								<orgName type="institution">Heidelberg University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SRL4ORL: Improving Opinion Role Labeling Using Multi-Task Learning With Semantic Role Labeling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For over a decade, machine learning has been used to extract opinion-holder-target structures from text to answer the question Who expressed what kind of sentiment towards what?. Recent neural approaches do not outperform the state-of-the-art feature-based models for Opinion Role Labeling (ORL). We suspect this is due to the scarcity of labeled training data and address this issue using different multi-task learning (MTL) techniques with a related task which has substantially more data, i.e. Semantic Role Labeling (SRL). We show that two MTL models improve significantly over the single-task model for labeling of both holders and targets, on the development and the test sets. We found that the vanilla MTL model which makes predictions using only shared ORL and SRL features, performs the best. With deeper analysis we determine what works and what might be done to make further improvements for ORL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Fine-Grained Opinion Analysis (FGOA) aims to: (i) detect opinion expressions (O) that convey attitudes such as sentiments, agreements, beliefs or intentions (like feared in example (1)), (ii) measure their intensity (e.g. strong), (iii) identify their holders (H), i.e. entities that express an attitude (e.g. it), (iv) identify their targets (T), i.e. entities or propositions at which the attitude is directed (e.g. violence) and (v) classify their targetdependent attitude (e.g. negative sentiment) 1 .</p><p>(1) Australia said <ref type="bibr">[it]</ref> </p><formula xml:id="formula_0">H [feared] Oneg [violence] T</formula><p>if voters thought the election had been stolen.</p><p>As the commonly accepted benchmark corpus MPQA <ref type="bibr" target="#b42">(Wiebe et al., 2005)</ref> uses span-based annotations to represent opinion entities <ref type="bibr">(opinions, 1</ref> Examples are drawn from MPQA <ref type="bibr" target="#b42">(Wiebe et al., 2005).</ref> holders and targets), the task is usually approached with sequence labeling techniques and the BIO encoding scheme <ref type="bibr" target="#b5">(Choi et al., 2006;</ref><ref type="bibr" target="#b48">Yang and Cardie, 2013;</ref><ref type="bibr" target="#b21">Katiyar and Cardie, 2016)</ref>. Initially pipeline models were proposed which first predict opinion expressions and then, given an opinion, label its opinion roles, i.e. holders and targets <ref type="bibr" target="#b22">(Kim and Hovy, 2006;</ref><ref type="bibr" target="#b17">Johansson and Moschitti, 2013)</ref>. Pipeline models have been substituted with so-called joint models that simultaneously identify all opinion entities, and predict which opinion role is related to which opinion <ref type="bibr" target="#b5">(Choi et al., 2006;</ref><ref type="bibr" target="#b48">Yang and Cardie, 2013;</ref><ref type="bibr" target="#b21">Katiyar and Cardie, 2016)</ref>. Recently an LSTM-based joint model was proposed <ref type="bibr" target="#b21">(Katiyar and Cardie, 2016)</ref> that unlike the prior work <ref type="bibr" target="#b5">(Choi et al., 2006;</ref><ref type="bibr" target="#b48">Yang and Cardie, 2013)</ref> does not depend on external resources (such as syntactic parsers or named entity recognizers). The neural variant does not outperform the feature-based CRF model <ref type="bibr" target="#b48">(Yang and Cardie, 2013)</ref> in Opinion Role Labeling (ORL).</p><p>Both the neural and the CRF joint models achieve about 55% F1 score for predicting which targets relate to which opinions in MPQA. Thus, these models are not yet ready to answer the question this line of research is usually motivated with: Who expressed what kind of sentiment towards what?. Our goal is to investigate the limitations of neural models in solving different subtasks of FGOA on MPQA and to gain a better understanding of what is solved and what is next.</p><p>We suspect that one of the fundamental obstacles for neural models trained on MPQA is its small size. One way to address scarcity of labeled data is to use multi-task learning (MTL) with appropriate auxiliary tasks. A promising auxiliary task candidate for ORL is Semantic Role Labeling (SRL), the task of predicting predicate-argument structure of a sentence, which answers the question Who did what to whom, where and when?.  <ref type="table">-A1 A1  A1  A1  A1  A1  A1  A1  A1  A1  A1  fear.01</ref> --A0 -A1 AM-ADV AM-ADV AM-ADV AM-ADV AM-ADV AM-ADV AM-ADV AM-ADVthink <ref type="table">.01  ------A0  -A1  A1  A1  A1  A1  steal.01  --------A1  A1  ----Table 1</ref>: Output of the SRL demo. <ref type="table">Table 1</ref> illustrates the output of the SRL demo 2 for example (1), following the PropBank SRL scheme <ref type="bibr" target="#b32">(Palmer et al., 2005)</ref>  <ref type="bibr">3</ref> . SRL4ORL. The semantic roles of the predicate fear (marked blue bold) correspond to the opinion roles H and T, according to MPQA. For this reason, the output of SRL systems has been commonly used for feature-based FGOA models <ref type="bibr" target="#b22">(Kim and Hovy, 2006;</ref><ref type="bibr" target="#b17">Johansson and Moschitti, 2013;</ref><ref type="bibr" target="#b5">Choi et al., 2006;</ref><ref type="bibr" target="#b48">Yang and Cardie, 2013)</ref>. Additionally, a considerable amount of training data is available for training SRL models ( <ref type="table" target="#tab_4">Table 2</ref> in Sec. 3), which made neural SRL models successful <ref type="bibr" target="#b52">(Zhou and Xu, 2015;</ref><ref type="bibr" target="#b50">Yang and Mitchell, 2017)</ref>.</p><p>Obstacles. Although SRL is similar in nature to ORL, it cannot solve ORL for all cases <ref type="bibr" target="#b39">(Ruppenhofer et al., 2008)</ref>. In example (2) holder and target of the predicate please correspond to A1, A0 semantic roles respectively, wheres for the predicate fear in (1) holder and target correspond to A0, A1 respectively. We took into account this observation when deciding on an appropriate MTL model by splitting its parameters into shared and task-specific ones (i.e. hard-parameter sharing).</p><p>(2) [I] A1 H am very <ref type="bibr">[pleased]</ref> Opos that [the Council has now approved the Kyoto Protocol thus enabling the EU to proceed with its ratification] A0 T .</p><p>A further obstacle for properly exploiting SRL training data with MTL could be specificities, inconsistency and incompleteness of the MPQA annotations. In example (3), Rice expressed his negative sentiment towards the three countries in question by setting the criteria which states something negative about those countries: they are repressive and grave human rights violators <ref type="bibr">[...]</ref>. In this case, the model should not pick any local semantic role for the target.</p><p>( repressive and grave human rights violators, and aggressively seeking weapons <ref type="bibr">[...]</ref>.</p><p>In examples (4-5), the same opinion expression concerned realizes different scopes for the target. A model which exploits SRL knowledge could be biased to always label targets as complete SRL role constituents, as in example <ref type="formula">(5)</ref> The examples above show that incorporating SRL knowledge via multi-task learning is a reasonable way to improve ORL, but at the same time they alert us that given the specificities of MPQA and ORL annotations in general, it is not obvious whether MTL can overcome divergences in the annotation schemes of opinion and semantic role labeling. We investigate this research question by adopting one of the recent successful architectures for SRL <ref type="bibr" target="#b52">(Zhou and Xu, 2015)</ref> and experiment with different multi-task learning frameworks.</p><p>Our contributions are: (i) we adapt a recently proposed neural SRL model for ORL, (ii) we enhance the model using different MTL techniques with SRL to tackle the problem of scarcity of labeled data for ORL, (iii) we show that most of the MTL models improve the single-task model for labeling of both holders and targets on development and test sets, and two of them make yield significant improvements, (iv) by deeper analysis we provide a better understanding of what is solved and where to head next for neural ORL.  2 Neural MTL for SRL and ORL Neural multi-task learning (MTL) receives a lot of attention and new MTL architectures emerge regularly. Yet there is no clear consensus which MTL architecture to use in which conditions. We experiment with well-received architectures that could adapt to different cases of ORL from Section 1.</p><p>As a general neural architecture for single-and multi-task learning we use the recently proposed SRL model <ref type="bibr" target="#b52">(Zhou and Xu, 2015)</ref> (Z&amp;X-STL) which successfully labels semantic roles without any syntactic guidance. This model consists of a stack of bi-directional LSTMs and a CRF which makes the final prediction. The inputs to the first LSTM are not only token embeddings but three additional features: embedding of the predicate, embedding of the context of the predicate and an indicator feature (1 if the current token is in the predicate context, 0 otherwise). Thus, every sentence is processed as many times as there are predicates in it. Adapting this model for labeling of opinion roles is straightforward, the only difference being that opinion expressions can be multiwords and only two opinion roles are assigned.</p><p>MTL techniques aim to learn several tasks jointly by leveraging knowledge from all tasks. In the context of neural networks, MTL is commonly used in such a way that it is predefined which layers have tied parameters and which are taskspecific (i.e. hard-parameter sharing). There are various ways of defining which parameters should be shared and how to train them.</p><p>Fully-shared (FS) MTL model. A fully-shared model ( <ref type="figure" target="#fig_0">Fig. 1</ref>) shares all parameters of the general model except the output layer. Each task has a task-specific output layer which makes the prediction based on the representation produced by the final LSTM. When training on a mini-batch of a certain task, parameters of the output layer of the other tasks are not updated. This model should be effective for constructions with a clear mapping between opinion and semantic roles such as {H ? A0, T ? A1} as in example (1) (Sec. 1).</p><p>Hierarchical MTL (H-MTL) model. For NLP applications, often some given (high-level) task is supposed to benefit from another (low-level) task more than the other way around, e.g. parsing from POS tagging. This intuition lead to designing hierarchical MTL models <ref type="bibr" target="#b40">(S?gaard and Goldberg, 2016;</ref><ref type="bibr" target="#b12">Hashimoto et al., 2017)</ref> in which predictions for low-level tasks are not made on the basis of the representation produced at the final LSTM, but on the representation produced by a lower-layer LSTM <ref type="figure">(Fig. 2</ref>). Task-specific layers atop shared layers could potentially give the model more power to distinguish or ignore certain semantic roles. If so, this MTL model is more suitable for examples like (2) and (3) (Sec. 1).</p><p>Shared-private (SP) MTL model. In the stateprivate model, in addition to the stack of shared LSTMs, each task has a stack of task-specific LSTMs   <ref type="figure" target="#fig_2">(Fig. 3</ref>). Representations at the outermost shared LSTM and the taskspecific LSTM are concatenated and passed to the task-specific output layer. The ORL representation produced independently from SRL gives the model the ability to utilize the shared and entirely task-specific information. For labeling of targets, it is expected that for examples (1) &amp; (5) the model relies mostly on the shared representation, for examples (2) &amp; (4) on both shared and ORL-specific representations, and for example (3) solely on the ORL-specific representation.</p><p>Adversarial shared-private (ASP) model. The limitation of the SP model is that it does not prevent the shared layers from capturing taskspecific features. To ensure this, ASP extends the  SP model with a task discriminator . The task discriminator ( <ref type="figure" target="#fig_2">Fig. 3</ref>, marked red) predicts to which task the current batch of data belongs, based on the representation produced by the shared LSTMs. If the shared LSTMs are taskinvariant, the discriminator should perform badly. Thus, we update the shared parameters to maximize the discriminator's cross-entropy loss. At the same time we want the discriminator to challenge the shared LSTMs, so we update the discriminator's parameters to minimize its cross-entropy loss. This minmax optimization is known as adversarial training and recently it gained a lot of attention for NLP applications <ref type="bibr" target="#b4">Chen et al., 2017;</ref><ref type="bibr" target="#b23">Kim et al., 2017;</ref><ref type="bibr" target="#b35">Qin et al., 2017;</ref><ref type="bibr" target="#b47">Wu et al., 2017;</ref><ref type="bibr" target="#b11">Gui et al., 2017;</ref><ref type="bibr" target="#b25">Li et al., 2017;</ref><ref type="bibr">Joty et al., 2017)</ref>.</p><p>3 Experimental setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>For SRL we use the newswire CoNLL-2005 shared task dataset <ref type="bibr" target="#b2">(Carreras and M?rquez, 2005)</ref>, annotated with PropBank predicate-argument structures. Sections 2-21 of the WSJ corpus <ref type="bibr" target="#b3">(Charniak et al., 2000)</ref> are used for training and section 24 as dev set. The test set consists of section 23 of WSJ and 3 sections of the Brown corpus. For ORL we use the manually annotated MPQA 2.0. corpus <ref type="bibr" target="#b42">(Wiebe et al., 2005;</ref><ref type="bibr" target="#b46">Wilson, 2008)</ref>. It mostly contains news documents, but also travel guides, transcripts of spoken conversations, emails, fundraising letters, textbook chapters and translations of Arabic source texts.</p><p>We report detailed pre-processing of MPQA 4 and data statistics in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation metrics</head><p>For both tasks we adopt evaluation metrics from prior work. For SRL, precision is defined as the proportion of semantic roles predicted by a system 4 Examples how to use our scripts can be found at https://github.com/amarasovic/ naacl-mpqa-srl4orl/blob/master/generate_ mpqa_jsons.py.</p><p>which are correct, recall is the proportion of gold roles which are predicted by a system, F1 score is the harmonic mean of precision and recall.</p><p>In case of ORL, we report 10-fold CV 5 and repeated 4-fold CV with binary F1 score and proportional F1 score, for holders and targets separately. Binary precision is defined as the proportion of predicted holders (targets) that overlap with the gold holder (target), binary recall is the proportion of gold holders (targets) for which the model predicts an overlapping holder (target). Proportional recall measures the proportion of the overlap between a gold holder (target) and an overlapping predicted holder (target), proportional precision measures the proportion of the overlap between a predicted holder (target) and an overlapping gold holder (target). F1 scores are the harmonic means of (the corresponding) precision and recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training details</head><p>We evaluate our models using two evaluation setting. First, we follow <ref type="bibr" target="#b21">Katiyar and Cardie (2016)</ref> which set aside 132 documents for development and used the remaining 350 documents for 10-fold CV. However, in the 10-fold CV setting, the test sets are more than 3 times smaller than the dev set ( <ref type="table" target="#tab_4">Table 2, row 3)</ref>, and, consequently, results in high-variance estimates on the test sets. Therefore we additionally evaluate our models with 4-fold CV. We set aside 100 documents for development and use 25% of the remaining documents for testing. The resulting test sets are comparable in size to the dev set (Table 2, row 2). We run 4-fold CV twice with two different random seeds. We do not tune hyperparameters (HPs), but follow suggestions proposed in the comprehensive HPs study for sequence labeling tasks in <ref type="bibr" target="#b37">Reimers and Gurevych (2017)</ref>. All HPs can be found in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We evaluate all models after every train size batch size iteration on the ORL dev set and save them if they achieve a higher arithmetic mean of proportional F1 scores of holders and targets on the ORL dev set. The saved models are used for testing.</p><p>We report the mean of F1 scores over 10 folds and the standard deviation (appears as a subscript) of all models in <ref type="table" target="#tab_6">Table 3</ref>. We report the mean of F1 scores over 4 folds and 2 different seed (8 evalua-   tions) and the standard deviation of all models in <ref type="table" target="#tab_7">Table 4</ref>. Evaluation metrics follow Section 3.2. We mark significant difference between MTL models and the single-task (Z&amp;X-STL) model, observed using a Kolmogorov-Smirnov significance test (p &lt; 0.05) (Massey Jr, 1951), with ? in superscript and between the FS-MTL model and other MTL models with 3.</p><p>STL vs. MTL. In the 10-fold CV evaluation setting <ref type="table" target="#tab_6">(Table 3)</ref>, the FS-MTL and the H-MTL models improve over the Z&amp;X-STL model in all evaluation measures, for both holders and targets. When evaluated in the repeated 4-fold CV setting <ref type="table" target="#tab_7">(Table 4)</ref>, all MTL models improve over the Z&amp;X-STL model in all evaluation measures, for both holders and targets.</p><p>The FS-MTL and the H-MTL models improve significantly in all evaluation measures, for both holders and targets, on both dev and test sets, when evaluated with repeated 4-fold CV. With 10-fold CV the improvements are also significant, except for targets on the test set. This is probably due to the small size of the test sets <ref type="table" target="#tab_4">(Table 2, row 3)</ref>, which results in a high-variance estimate. Indeed, standard deviations on the 10-fold CV test sets are always much higher compared to the dev set or to the test sets of 4-fold CV.</p><p>It is not surprising that larger improvements are visible in the labeling of holders. They are usually short, less ambiguous and often presented with the A0 semantic role, whereas annotating targets is a challenging task even for humans. <ref type="bibr">6</ref> Larger improvements are visible for proportional F1 score than for binary F1 score. That is, more data and SRL knowledge helps the model to better annotate the scope of opinion roles.</p><p>Comparing MTL models. In Section 2 we introduced MTL models with task-specific LSTM layers hypothesizing that these layers should give MTL models more power to adapt to a variety of potentially problematic cases that we illustrated in the Introduction. However, our results show that the FS-MTL model performs significantly better or comparable to MTL models that include taskspecific layers. <ref type="bibr" target="#b37">Reimers and Gurevych (2017)</ref> show that MTL is especially sensitive to the selection of HPs. Thus, a firm and solid comparison of the different MTL models requires thorough HP optimization, to properly control the number of parameters and regularization of the models. We leave HP optimization for future work.</p><p>1 Malinga F S,ZX said according to the guidelines in the booklet, the election had been legitimate .</p><p>2 movie um-hum that 's interesting so that was a good movie too well do you F S,ZX think we've covered baseball i think so okay well have a good night 3</p><p>The nation F S,ZX should certainly be concerned about the plans to build a rocket launch pad , work on the infrastructure for which is due to start in 2002 , with launches beginning from 2004 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>Bam on Sunday said she F S,ZX believed Zimbabwe's election was not free and fair , adding they were not in line with international standards as well as those of her organisation .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5</head><p>The majority report , endorsed only by the ANC , said the observer mission F S,ZX had noted that over three million Zimbabweans had cast their votes and this substantially represented the will of the people . He said those who thought the election process would be rigged were supporters of the MDC party , adding that they were prejudging and wanted to direct the process F S,ZX .</p><p>5 People in the rural areas support the ruling party because our party has been genuine on its policy on land reform F S,ZX .   models on the ORL dev set using 4-fold CV repeated twice with different seeds (8 evaluation trials). We say that a model predicts a role of a given opinion expression correctly if the model predicts a role that overlaps with the correct role in at least 6 out of 8 evaluation trials. If a model predicts a role that overlaps with the correct role in at most 2 out of 8 trials, we say that the model predicts the role incorrectly. The requirement on 6-8 (in)correct predictions reduces the risk of analyzing inconsistent predictions and enables us to draw firmer conclusions. We analyze the following scenarios:</p><p>(i) both the FS-MTL model and the Z&amp;X-STL model make correct predictions <ref type="table" target="#tab_8">(Tables 5-6)</ref> (ii) the FS-MTL model makes a correct prediction, while the Z&amp;X-STL makes an incorrect prediction <ref type="table" target="#tab_4">(Tables 11-12)</ref> (iii) both models make wrong predictions <ref type="table" target="#tab_12">(Tables  9-10)</ref> In the following, we categorize predictions in case (i) as easy cases, and predictions in case (iii) as hard cases.</p><p>In <ref type="table" target="#tab_8">Tables 5-6</ref> and 9-12, the opinion expression is bolded, the correct role is italicized, predictions of the FS-MTL model are colored blue (subscript FS), predictions of the Z&amp;X-STL model are colored yellow (subscript ZX) and green marks predictions where both models agree. For simplicity, we show only holders or targets, although the models predict both roles jointly.</p><p>What works well? There are 668/1055 instances in the dev set for which both models predict holders correctly, and 663/1055 for targets.</p><p>Examples 1-5 in <ref type="table" target="#tab_8">Table 5</ref> suggest that holders that can be properly labeled by both models (easy 1 It would be entirely improper if , in its defense of Israel F S , the United States continues to exert pressure on [...] .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>Indonesia F S,ZX has come under pressure from several quarters to take tougher action against alleged terrorist leaders but has played down the threat .</p><p>3 Australia should adhere to the Cardinal Principle of International Law , which states that all nations in the world must first respect and promote the humanitarian interests and progress of all humankind .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>The department said that it will cost $ 600 for an HIV/AIDS patient per year at this time , and the following years this cost is expected to stand at just $ 400/year for one patient as the production of such drugs becomes stable .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5</head><p>The Organisation of African Unity OAU ZX also backed Zimbabwean President Robert Mugabe 's re-election , with its observer team F S,ZX describing the poll as " transparent , credible , free and fair " .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6</head><p>Regarding the American proposed Anti-Missile Defense System too , neither Russia , China , Japan , nor even the European Union , had shown any enthusiasm ; rather they F S had all F S,ZX expressed their reserves on the project .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7</head><p>The president renewed his pledge to thwart terrorist groups F S,ZX who want to " mate up " with regimes hoping to acquire weapons of mass destruction and said " nations will come with us " if the US-led war on terrorism is extended . 1 State-sanctioned land invasions , several times declared illegal by Zimbabwe 's courts , as well as a drought have disrupted Zimbabwe 's food production and famine is already looming in much of the country .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>But he told the nation F S,ZX that in spite of stiff opposition to the agrarian reforms from powerful Western countries , especially the country 's former colonial power of Britain , he would press ahead to seize farms from whites and [...] .</p><p>3</p><p>If the Europeans wish to influence Israel in the political arena -in a direction that many in Israel would support wholeheartedly -they will not be able to promote their positions in such a manner .</p><p>4 They F S,ZX are fully aware that these are dangerous individuals , he said during a press conference [...] .</p><p>5 And her little girl just complained , " I don't want to wash the dishes " .</p><p>6 During President Bush's speech , I thought of heckling ZX ; ' What are you going to do with the Kyoto Protocol ? F S ' 7 At first I didn't want to apply for it F S,ZX , but the principal called me during the summer months and said , " Sandra the time is running out , you need to apply ". cases) are subjects of their governing heads or A0 roles. The statistics in <ref type="table" target="#tab_10">Table 7</ref> (col. 1, rows 2-3) supports this observation. <ref type="bibr">7</ref> In contrast, holders that both models predict incorrectly (hard cases) are less frequently subjects or A0 roles (col. 2, rows 2-3). Also, easy holders are close to the corresponding opinion expression: the average distance is 1.54 tokens <ref type="table" target="#tab_10">(Table 7</ref>, row 4), contrary to the hard holders with the average distance of 7.56. Examples 1-5 in <ref type="table" target="#tab_9">Table 6</ref> suggest that targets that can be properly labeled by both models are objects of their governing heads or A1 roles. Table 8, row 3, shows that the majority of the easy targets are indeed A1 roles, in contrast to the hard targets. Similar to holders, the easy targets are in average 7 tokens closer to the opinion expression.</p><p>What to do for further improvement? There are 165/1055 instances in the dev set for which <ref type="bibr">7</ref> The statistics is calculated using the output of mate-tools <ref type="bibr" target="#b1">(Bj?rkelund et al., 2010).</ref> both models predict holders incorrectly, and 176 for targets.</p><p>As we have seen so far, many holders that are subjects or A0 roles, and targets that are A1 roles, are properly labeled by both models. However, a considerable amount of such holders and targets are not correctly predicted <ref type="table" target="#tab_10">(Table 7</ref>-8, col. 2, rows 2-3). Thus our models do not work flawlessly for all such cases. A distinguishing property of the hard cases is the distance of the role from the opinion. Thus, future work should advance the model' s ability to capture long-range dependencies. <ref type="table" target="#tab_12">Table 9</ref> demonstrate that holders, harder to label with our models, occur with the corresponding opinions in more complicated syntactic constructions. In the first example, the FS-MTL model does not recognize the possessive and is possibly biased towards picking the country (Isreal), which occurs immediately after the opinion. In the second example, the opinion expression is 1 Yoshihisa Murasawa , a management consultant for Booz-Allen &amp; Hamilton Japan Inc. , said his firm F S,ZX will likely be recommending acquisitions of Japanese companies more ZX often to foreign clients in the future .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Examples in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>The source F S , interviewed by Interfax in Grozny , expressed confidence that that the command of the Russian forces in Chechnya would soon " be able to obtain documentary confirmation " that Khattab was dead .</p><p>3</p><p>The Commonwealth team earlier this week F S said that " the conditions in Zimbabwe did not adequately allow the free and fair expression of will by the electorate ".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>Publishing such biased reports will only create mistrust among nations F S regarding the objectives and independence of the UN Commission on Human Rights .  1 In most cases he described the legal punishments F S like floggings and executions of murderers and major drug traffickers that are applied based on the Shria , or Islamic law as human rights violations .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>In another verbal attack Kharazi accused the United States F S of wanting to exercise " world dictatorship " since the " horrible attacks " of September 11 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head><p>He said those who thought the election process would be rigged were supporters of the MDC party , adding that they were prejudging and wanted to direct the process ZX .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>However , the fact that certain countries have a more balanced view of the conflict ZX is not the only reason to doubt that anti-Israeli decisions F S will , in fact , be adopted .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5</head><p>But his tough stand on P'yongyang F S has provoked concern in Seoul ZX , where President Kim Tae-chung , who is in the last year of his five-year term , has been trying to prise the hermit state out of isolation . a nominal predicate and the holder is its object. The sentence is in passive voice but the models probably interpret it in the active voice and thus make the wrong prediction. In the third example, the opinion expression is the head of the relative clause that modifies the holder. These examples raise the following questions: would improved consistency with syntax lead to improvements for ORL and could we train a dependency parsing model with SRL and ORL to help the models handle syntactically harder cases? Example 4 shows that holders specific to the MPQA annotation schema are hard to label as they require inference skills: from the department said, we can defeasibly infer that it is the department who expects [this cost] to stand at just $400/year <ref type="bibr">[...]</ref>. To handle such cases, it would be worth trying training our models jointly with models for recognizing textual entailment.</p><p>Examples 6-7 illustrate that some gap in per-formance stems from difficulties in processing MPQA. Example 5 has no gold holder, but the models make plausible predictions. For example 6, FS-MTL predicts the discontinuous holder they ... all, while MPQA allows only contiguous entities. Therefor our evaluation scripts interpret they and all as two separate holders and deem all as incorrect, resulting with lower precision. Finally, for example 7 our models make plausible predictions. However, the gold holder is always the entity from the coreference cluster that is the closest to the opinion. <ref type="bibr">8</ref> The evaluation scripts needs to be extended such that predicting any entity from the coreference cluster is considered to be correct. To conclude, to better evaluate future developments, it would be worth curating MPQA instances with missing roles and extending evaluation to account for coreferent holders and discontinuous roles. The examples in <ref type="table" target="#tab_13">Table 10</ref> demonstrate that dif-ficulties in labeling targets originate from similar reasons as for holders. Examples 1-3 demonstrate complex syntactic constructions, examples 4-6 MPQA-specific annotations that require inference and example 7 exemplifies a missing target. How does MTL help? There are 18/1055 instances in the dev set for which the FS model predicts the holder correctly and the Z&amp;X-STL model does not, and 19/1055 for targets.</p><p>For holders, for 9 out 18 of such examples, the Z&amp;X-STL model does not predict anything (as in Examples 2-5 in <ref type="table" target="#tab_15">Table 11</ref>). From Examples 1-5 we notice that SRL data helps to handle more complex syntactic constructions. From Examples 5-7 we observed that using MTL with SRL helps to handle cases when more than one person or organization is present in the close neighborhood of the opinion. For targets, for 11 out of 18 cases the Z&amp;X-STL model does not predict anything as in Examples 1-2 in <ref type="table" target="#tab_15">Table 11</ref>. We conclude that the greatest improvements from the FS-MTL model comes from having far fewer missing roles.</p><p>6 Related work FGOA. Closest to our work are <ref type="bibr" target="#b48">Yang and Cardie (2013)</ref> (Y&amp;C) and <ref type="bibr" target="#b21">Katiyar and Cardie (2016)</ref> (K&amp;C). They as well label both holders and targets in MPQA. By contrast, our focus is on the task of ORL. We thus refrain from predicting opinion expressions first, to ensure a reproducible evaluation setup on a fixed set of gold opinion expressions. The MTL models we develop in this work will, however, be the basis for the full task in a later stage. Because of these differences, direct comparison to Y&amp;C and K&amp;C is not possible. However, if we compare our results we notice a big gap that demonstrates that opinion expression extraction is the import step in FGOA. Similar to K&amp;C, <ref type="bibr" target="#b26">Liu et al. (2015)</ref> jointly labels opinion expressions and their targets in reviews. Some work focuses entirely on labeling of opinion expressions <ref type="bibr" target="#b49">(Yang and Cardie, 2014;</ref><ref type="bibr" target="#b16">Irsoy and Cardie, 2014)</ref>. Other work looks into specific subcategories of ORL: opinion role induction for verbal predicates <ref type="bibr" target="#b44">(Wiegand and Ruppenhofer, 2015)</ref>, categorization of opinion words into actor and speaker view <ref type="bibr" target="#b45">(Wiegand et al., 2016b)</ref>, opinion roles extraction on opinion compounds <ref type="bibr" target="#b43">(Wiegand et al., 2016a)</ref>. <ref type="bibr" target="#b44">Wiegand and Ruppenhofer (2015)</ref> report 72.54 binary F1 score for labeling of holders in MPQA (results for targets are not reported).</p><p>Neural SRL. New neural SRL models have emerged <ref type="bibr" target="#b14">(He et al., 2017;</ref><ref type="bibr" target="#b50">Yang and Mitchell, 2017;</ref><ref type="bibr" target="#b29">Marcheggiani and Titov, 2017)</ref> since we started this work. In future work we can improve our models with such new proposals.</p><p>Auxiliary tasks for MTL. Other work investigates under which conditions MTL is effective. Mart?nez <ref type="bibr" target="#b30">Alonso and Plank (2017)</ref> show that the best auxiliary tasks have low kurtosis of labels (usually a small label set) and high entropy (labels occur uniformly). We show that the best MTL model for ORL is the model which uses shared layers only. Thus it seems reasonable to consider only a small and uniform SRL label set {A0, A1}. <ref type="bibr" target="#b0">Bingel and S?gaard (2017)</ref> show that MTL works when the main task has a flattening learning curve, but the auxiliary task curve is still steep. We notice such behavior in our learning curves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We address the problem of scarcity of annotated training data for labeling of opinion holders and targets (ORL) using multi-task learning (MTL) with Semantic Role Labeling (SRL). We adapted a recently proposed neural SRL model for ORL and enhanced it with different MTL techniques. Two MTL models achieve significant improvements with all evaluation measures, for both holders and targets, on both dev and test set, when evaluated with repeated 4-fold CV. We recommend evaluation with comparable dev and test set sizes for future work, as this enables more reliable evaluation.</p><p>With deeper analysis we show that future developments should improve the ability of the models to capture long-range dependencies, investigate if consistency with syntax can improve ORL, and consider other auxiliary tasks such as dependency parsing or recognizing textual entailment. We emphasize that future improvements can be measured more reliably if the evaluation covers opinion expressions with missing roles and considers all mentions in opinion role coreference chains as well as discontinuous roles.</p><p>A MPQA Pre-processing MPQA is challenging not only because it captures a variety of phenomena as we have illustrated in the Introduction, but as well because it is hard to process it in such a way that it can be presented to a neural sequence labeling model. Code or sufficient description how the corpus was processed is not available from the prior work.</p><p>The first difficulty is that we are designing a model that labels at the token-level, but annotation spans are given in bytes. Thus, we used Stanford  CoreNLP  which tokenizes text and gives the byte span of every token. 9 However, due to to the absence of punctuation for transcripts of spoken conversations the sentence splitter treats a whole document as if it were one sentence. Therefore, for sentences longer than 150 tokens, we take 15 tokens preceding the opinion expression, the expression itself and 15 tokens after as proxy for a sentence that we present to the model. Opinion expressions we are interested in are annotated in MPQA as direct subjectives (DSEs). We discard implicit DSEs which frequently point to the attitude which covers the whole sentence and reflects the attitude of the author of the document as in example <ref type="formula">(6)</ref>. These DSEs are not useful for the task we are looking into. Although such DSEs should be marked with the implicit attribute, sometimes they are not. Some of such cases we capture by demanding that a DSE is longer than one byte and that the author is not the only holder. There are few DSEs for which byte spans did not match with any sentence, and we discard those as well.</p><p>(6) But there can not be any real [talk] O of success until the broad strategy against terrorism begins to bear fruit.</p><p>For every document, we collected from the corresponding annotation file: identifiers and byte <ref type="bibr">9</ref> We used python wrapper: https://github.com/ brendano/stanford_corenlp_pywrapper spans of all holders marked with GATE agent (H), attitudes marked with GATE attitude, and targets marked with GATE target. Holders and targets can be marked multiple times with the same id, but with different byte spans. If the nested-source attribute of a DSE or the target-link attribute of its attitude point to identifiers of such holders and targets, we pick the byte spans which are closest to the DSE. In many cases the nested-source attribute of a DSE pointed to a holder which is not marked in the annotation file ( / ? H). We tried to fix the nested-source attribute by doing the following transformations: (1) adding 'w' to the beginning (e.g. nhs ? w, nhs), (2) removing 'w' from the beginning (e.g. w, ip ? ip), (3) removing duplicates (e.g. w, mug, mug ? w, mug). Although these transformations helped a lot, they are a few holders and targets we could not trace.</p><p>In some cases, as in example <ref type="formula">(7)</ref>, an opinion expression and its opinion roles overlap. In average, we discard 74.7 such holders and 16.2 targets, because we train the output CRF to predict only one label by token. Notice that the prior work <ref type="bibr" target="#b21">(Katiyar and Cardie, 2016)</ref> had to do the same. We discard inferred attitudes, as labeling of their targets is considered to be another task <ref type="bibr" target="#b7">(Deng et al., 2013;</ref><ref type="bibr" target="#b8">Deng and Wiebe, 2014;</ref><ref type="bibr">Ruppenhofer # DSEs (incl.</ref>   and Brandes, 2016). Further, a DSE can have multiple attitudes and each attitude can point to different targets. Again, because the model can predict only one label by token, we have to pick one attitude and nonoverlapping targets. We chose attitudes according to the following priorities: sentiment, intention, agreement, arguing, other-attitude, speculation.</p><p>We kept DSEs with the insubstantial attribute which are either not significant (8) or not not real within the discourse (9). Our models should demonstrate the ability of properly labeling roles of insubstantial DSEs. However, note that when FGOA is used for opinion-oriented summarization or QA, opinion roles of insubstantial opinions should not be labeled. A full FGOA system should additionally predict whether an opinion is substantial within the discourse, before labeling its opinion roles. Finally, DSE, holder and target annotations allow an attribute that indicates whether an annotator was uncertain with possible values: somewhatand very-uncertain. We did not discard those be-lieving that they would have been discarded by the corpus creators if they are really incorrect.</p><p>For reproducibility we report detailed data statistics in <ref type="table" target="#tab_6">Tables 13 and 14</ref>: average number (calculated over folds) of all extracted DSEs, implicit DSEs, inferred DSEs, DSEs used in experiments (not implicit or inferred), somewhat uncertain DSEs used in experiments, very uncertain DSEs used in experiments, insubstantial DSEs used in experiments, the average number (calculated over folds) of DSEs used in experiments without a holder, without a target, without the attitude-link attribute, without both roles, the average number (calculated over folds) of holders, somewhat uncertain holders, very uncertain holders, targets, somewhat uncertain targets and very uncertain targets, the average number (calculated over folds) of different attitude types used in the experiments.</p><p>Examples how to easily use our MPQA pre-processing scripts can be found at https://github.com/amarasovic/ naacl-mpqa-srl4orl/blob/master/ mpqa2-pytools.ipynb.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Fully-shared (FS) MTL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure</head><label></label><figDesc>Figure 2: Hierarchical-MTL (H-MTL).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>(Adversarial) state-private ((A)SP) MTL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 7 )</head><label>7</label><figDesc>Mugabe said [Zimbabwe] T needed their continued support against what he called [hostile [international] H attention] O .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>arXiv:1711.00768v3 [cs.CL] 19 Apr 2018</figDesc><table><row><cell></cell><cell>Australia said it feared violence</cell><cell>if</cell><cell>voters</cell><cell>thought</cell><cell>the</cell><cell>election</cell><cell>had</cell><cell>been</cell><cell>stolen .</cell></row><row><cell>say.01</cell><cell>A0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc><ref type="bibr" target="#b21">Cardie, 2016)</ref> has shown that their model makes reasonable predictions in sentences which do not have annotations at all, e.g.[mothers] H [care] O for [their young] T , in: From the fact that mothers care for their young, we can not deduce that they ought to do so, Hume argued.</figDesc><table><row><cell>.</cell></row><row><cell>(4) Rice told us [the administration] H was</cell></row><row><cell>[concerned] Oneg that [Iraq] T would take ad-</cell></row><row><cell>vantage of the 9/11 attacks.</cell></row></table><note>(5) [The Chinese government] H is deeply [concerned] Oneg about [the sudden deterio- ration in the Middle East situation] T , Tang said. Regarding incompleteness, prior work (Kati- yar and</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Datasets w/ nb. of SRL predicates/ORL opinions in train, dev &amp; test set, size of label inventory.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>F1 binary F1 prop. F1 Z&amp;X-STL 80.15 1.10 76.87 1.26 74.62 0.67 70.23 1.04 F1 binary F1 prop. F1 Z&amp;X-STL 80.24 2.91 77.98 2.90 76.30 2.55 71.18 2.55</figDesc><table><row><cell cols="2">dev (MPQA)</cell><cell></cell><cell cols="2">test (MPQA)</cell></row><row><cell>holder</cell><cell cols="2">target</cell><cell>holder</cell><cell>target</cell></row><row><cell>binary F1 prop. FS-MTL 83.68 ? 0.44 81.45 ? 0.58 H-MTL 84.14 ? 0.72 81.86 ? 0.48 SP-MTL 82.18 ?3 0.89 79.66 ?3 0.72 ASP-MTL 82.63 ?3 0.84 80.20 ?3 0.99</cell><cell>76.23 ? 0.75 76.11 ? 0.61 74.99 3 1.17 74.24 ?3 0.58</cell><cell>73.01 ? 0.93 72.55 ? 0.73 71.32 3 1.81 70.16 3 1.29</cell><cell>binary F1 prop. FS-MTL 83.47 ? 2.26 81.80 ? 2.26 H-MTL 84.03 ? 2.65 82.34 ? 2.51 SP-MTL 82.19 ? 2.49 80.11 ?3 2.36 ASP-MTL 83.15 ? 2.92 81.12 ? 2.66</cell><cell>77.60 2.52 73.77 2.28 77.41 2.14 73.10 1.96 76.01 3.03 71.51 3.34 75.89 2.66 71.21 2.78</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>ORL 10-fold CV results.</figDesc><table><row><cell></cell><cell cols="2">dev (MPQA)</cell><cell></cell><cell cols="2">test (MPQA)</cell><cell></cell></row><row><cell cols="2">holder</cell><cell>target</cell><cell cols="2">holder</cell><cell cols="2">target</cell></row><row><cell cols="3">binary F1 prop. F1 binary F1 prop. F1</cell><cell cols="4">binary F1 prop. F1 binary F1 prop. F1</cell></row><row><cell cols="3">Z&amp;X-STL 79.73 1.19 77.06 1.14 76.09 0.94 70.45 1.07</cell><cell cols="4">Z&amp;X-STL 80.42 1.92 77.48 2.06 73.84 1.17 67.03 2.13</cell></row><row><cell>FS-MTL H-MTL SP-MTL ASP-MTL 81.41 3 83.58 ? 0.69 82.36 ?3 0.81 82.21 ?3 0.79 1.27</cell><cell>82.16 ? 0.59 80.84 ?3 0.98 80.23 ?3 0.88 79.39 ?3 1.45</cell><cell>78.32 ? 1.57 78.11 ? 0.82 76.14 3 1.18 76.49 1.39 72.13 ? 75.09 ? 2.27 74.89 ? 1.33 71.14 3 0.97 1.87</cell><cell>FS-MTL H-MTL SP-MTL ASP-MTL 81.77 3 83.67 ? 1.52 82.80 ? 1.87 82.51 ? 2.17 1.74</cell><cell>81.59 ? 1.50 80.40 ? 1.91 80.03 ? 2.00 79.32 3 1.62</cell><cell>77.04 ? 1.45 77.12 ? 1.34 74.61 3 1.32 74.92 ?3 0.84</cell><cell>73.01 ? 2.53 73.16 ? 1.78 68.70 3 2.32 69.89 ? 1.80</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>ORL repeated 4-fold CV results.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>The dev examples for which both models (FS-MTL, Z&amp;X-STL) correctly predict the holder in 6/8 trials.1   Indonesia has come under pressure from several quarters to take tougher action against alleged terrorist leaders but has played down the threat ZX F S .2Mugabe even talked about his desire to keep safeguarding Zimbabwe 's sovereignty and land ZX in spirit F S when he dies , a dream which the veteran leader said forced him to sacrifice a bright teaching career in the 1950s to lead [...].</figDesc><table /><note>3 Under his blueprint , the government hopes to stabilize the economy through curtailing state expenditure , reforming public enterprises and expanding agriculture F S,ZX . 4</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table><row><cell></cell><cell>easy</cell><cell>hard</cell></row><row><cell>% opinions that are predicates</cell><cell cols="2">91.32 93.33</cell></row><row><cell>% holders that are subjects</cell><cell cols="2">77.84 38.79</cell></row><row><cell>% holders that are A0 roles</cell><cell cols="2">74.10 33.33</cell></row><row><cell cols="2">avg. distance between holders &amp; opinions 1.54</cell><cell>7.56</cell></row></table><note>The dev examples for which both models (FS-MTL, Z&amp;X-STL) correctly predict the target in 6/8 trials.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Statistics of holder prediction.</figDesc><table><row><cell></cell><cell>easy</cell><cell>hard</cell></row><row><cell>% opinions that are predicates</cell><cell cols="2">92.58 89.20</cell></row><row><cell>% target's heads that are objects</cell><cell cols="2">22.12 14.77</cell></row><row><cell>% targets that are A1 roles</cell><cell cols="2">70.62 42.61</cell></row><row><cell>% targets that are A2 roles</cell><cell>9.00</cell><cell>0.57</cell></row><row><cell cols="2">avg. distance between targets &amp; opinions 2.29</cell><cell>8.46</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table /><note>Statistics of target prediction.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>The dev examples for which both models (FS-MTL, Z&amp;X-STL) incorrectly predict the holder in 6/8 trials.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc></figDesc><table /><note>The dev examples for which both models (FS-MTL, Z&amp;X-STL) incorrectly predict the target in 6/8 trials.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>5</head><label></label><figDesc>The Inkatha Freedom Party , Democratic Alliance , New National Party , African Christian Democratic Party , the Pan Africanist Congress and the United Christian Democratic Party ZX had disagreed with the ANC F S conclusion . 6 The Nigerian leader , President Olusegun Obasanjo ZX , had urged the minister F S,ZX not to attack Blair frontally over Britain 's negative position regarding Zimbabwe , but to deal [...] . 7 US diplomats ZX say Bush F S,ZX will seek to support Kim 's Nobel Prize winning policy by offering new talks with the North , while remaining firm about North Korea 's missile sales and its feared chemical and biological weapons programmes.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 :</head><label>11</label><figDesc>The dev examples for which the FS-MTL model correctly predicts the holder in 6/8 trials, whereas the Z&amp;X-STL model predicts incorrectly in 6/8 trials.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 12 :</head><label>12</label><figDesc>The dev examples for which the FS-MTL model correctly predicts the target in 6/8 trials, whereas the Z&amp;X-STL model predicts incorrectly in 6/8 trials.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 13 :</head><label>13</label><figDesc>Statistics of the ORL (MPQA) data for 4-fold CV.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head></head><label></label><figDesc>ignored) # implicit DSEs (ignored) # inferred DSEs (ignored) # very uncrt. filt. DSEs # no Hs filt. DSEs # no roles filt. DSEs # no Ts filt. DSEs # insubs. filt. DSEs</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell># filtered DSEs</cell><cell># some uncrt. filt. DSEs</cell></row><row><cell>TRAIN (avg)</cell><cell>4173.3</cell><cell>537.3</cell><cell>119.7</cell><cell>3516.3</cell><cell>137.7</cell></row><row><cell>TEST (avg)</cell><cell>457.8</cell><cell>43.9</cell><cell>29.9</cell><cell>349.3</cell><cell>15.2</cell></row><row><cell>DEV</cell><cell>1579</cell><cell>211</cell><cell>42</cell><cell>1326</cell><cell>67</cell></row><row><cell>TRAIN (avg)</cell><cell>47.7</cell><cell>187.2</cell><cell>77.4</cell><cell>459.9</cell><cell>567.9</cell></row><row><cell>TEST (avg)</cell><cell>7.3</cell><cell>19.3</cell><cell>11.8</cell><cell>82.6</cell><cell>150.5</cell></row><row><cell>DEV</cell><cell>16</cell><cell>76</cell><cell>25</cell><cell>185</cell><cell>252</cell></row><row><cell></cell><cell># Hs of filt. DSEs</cell><cell># Ts of filt. DSEs</cell><cell># some uncrt. Hs</cell><cell># some uncrt. Ts</cell><cell># overlap. entites</cell></row><row><cell>TRAIN (avg)</cell><cell>3251.7</cell><cell>21664.8</cell><cell>17.1</cell><cell>27.9</cell><cell>1064.7</cell></row><row><cell>TEST (avg)</cell><cell>957.4</cell><cell>1700</cell><cell>19.4</cell><cell>37.8</cell><cell>84.9</cell></row><row><cell>DEV</cell><cell>1225</cell><cell>7978</cell><cell>9</cell><cell>12</cell><cell>401</cell></row><row><cell></cell><cell>sentiment neg</cell><cell>sentiment pos</cell><cell>arguing pos</cell><cell>other attitude</cell><cell>intention pos</cell></row><row><cell>TRAIN (avg)</cell><cell>1008.9</cell><cell>949.5</cell><cell>471.6</cell><cell>440.1</cell><cell>266.4</cell></row><row><cell>TEST (avg)</cell><cell>107.8</cell><cell>89.4</cell><cell>50.7</cell><cell>40.2</cell><cell>25.6</cell></row><row><cell>DEV</cell><cell>438</cell><cell>333</cell><cell>189</cell><cell>144</cell><cell>88</cell></row><row><cell></cell><cell>arguing neg</cell><cell>agree pos</cell><cell>speculation</cell><cell>agree neg</cell><cell>intention neg</cell></row><row><cell>TRAIN (avg)</cell><cell>133.2</cell><cell>115.2</cell><cell>80.1</cell><cell>74.7</cell><cell>16.2</cell></row><row><cell>TEST (avg)</cell><cell>14.1</cell><cell>11.1</cell><cell>8.6</cell><cell>6.5</cell><cell>1.428571429</cell></row><row><cell>DEV</cell><cell>46</cell><cell>44</cell><cell>21</cell><cell>39</cell><cell>13</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 14 :</head><label>14</label><figDesc>Statistics of the ORL (MPQA) data for 10-fold CV.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head></head><label></label><figDesc>(8)[...]  it completely supports the [U.S.] H [stance] O [...]. (9) [...] Antonio Martino, meanwhile, said [...] that his country would not support an attack on Iraq without "proven proof" that [Baghdad] H is [supporting] O [al Qaeda] T .</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We used the same splits as the prior work<ref type="bibr" target="#b21">(Katiyar and Cardie, 2016)</ref>. We thank the authors for providing the splits.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">AnalysisOur aim in this section is to analyze what the proposed models are good at, in which ways MTL improves over the single-task ORL model and what could be done to achieve further progress.We evaluate the FS-MTL and the Z&amp;X-STL 6 Wilson (2008) reports annotator agreement for target labeling of 86.00 binary F1 score.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">We followed the prior work<ref type="bibr" target="#b21">(Katiyar and Cardie, 2016)</ref>.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been supported by the German Research Foundation as part of the Research Training Group Adaptive Preparation of Information from Heterogeneous Sources (AIPHES) under grant No. GRK 1994/1.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Training details</head><p>The code for training and evaluating our models can be found at https://github.com/ amarasovic/naacl-mpqa-srl4orl.</p><p>Input representation. We used 100d GloVe word embeddings <ref type="bibr" target="#b34">(Pennington et al., 2014)</ref> pre-trained on Gigaword and Wikipedia and did not fine-tune them. For MTL models vocabulary was built from all the words in the training data of both tasks, and OOV words were replaced with an UNK token. The embedding of the context of a predicate or an opinion is the average of the embeddings of the predicate or the opinion phrase, of 2 preceding words and 2 words after.</p><p>Weights initialization. The size of all LSTM hidden states was set to 100. The number of the backward and the forward LSTM layers is set to 3, which counts for 6 LSTM layers in Z&amp;X. Z&amp;X achieved circa 2% higher SRL F1 score with 8 LSTM layers, but such a deep model would cause overfitting on the small-sized ORL data. In the H-MTL model, SRL is supervised at the 2nd LSTM layer. We initialized the LSTM weights with random orthogonal matrices <ref type="bibr" target="#b15">(Henaff et al., 2016)</ref>, all other weight matrices with the He initialization <ref type="bibr" target="#b13">(He et al., 2015)</ref>. LSTM forget biases were initialized with 1s <ref type="bibr" target="#b20">(Jozefowicz et al., 2015)</ref>, all other biases with 0s.</p><p>Optimization. We trained our model in minibatches of size 32 using Adam <ref type="bibr" target="#b24">(Kingma and Ba, 2015)</ref> with the learning rate of 10 ?3 . For MTL we alternate batches from different tasks. We clip gradients by global norm <ref type="bibr" target="#b33">(Pascanu et al., 2013)</ref>, with a clipping value set to 1. Single-task models were trained for 10K iterations and MTL models for 20K. One epoch counts for train size batch size iterations. We stop training if the arithmetic mean of proportional F1 scores of holders and targets is not improved in 25 epochs. For the minmax optimization we use a gradient reversal layer <ref type="bibr" target="#b10">(Ganin and Lempitsky, 2015)</ref>. The discriminator's crossentropy loss is scaled with 0.1.</p><p>Regularization. Variational dropout <ref type="bibr" target="#b9">(Gal and Ghahramani, 2016)</ref> with a keep probability k p ? 0.85 was applied to the outputs and the recurrent connections of the LSTMs. Standard dropout <ref type="bibr" target="#b41">(Srivastava et al., 2014)</ref> was applied to the output classifier weights with a keep probability k p ? 0.85 and to the input embeddings with k p ? 0.7.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Identifying beneficial task relations for multi-task learning in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>S?gaard</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/E17-2026" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers. Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="164" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A high-performance syntactic and semantic dependency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Bj?rkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Love</forename><surname>Hafdell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics: Demonstrations. Association for Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Demonstrations. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="33" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llu?s</forename><surname>M?rquez</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W/W05/W05-0620" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005)</title>
		<meeting>the Ninth Conference on Computational Natural Language Learning (CoNLL-2005)<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="152" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Don</forename><surname>Blaheta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niyu</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<title level="m">Bllip 1987-89 wsj corpus release 1. Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adversarial multi-criteria learning for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P17-1110" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1193" to="1203" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Joint extraction of entities and relations for opinion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<ptr target="http://www.aclweb.org/anthology/W/W06/W06-1651" />
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="431" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Benefactive/malefactive event and writer attitude annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonjung</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P13-2022" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="120" to="125" />
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics, Sofia, Bulgaria</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sentiment propagation via implicature constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/E14-1040" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="377" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A theoretically grounded application of dropout in recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Zoubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1180" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Part-of-speech tagging for twitter with adversarial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlong</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-1255" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2401" to="2410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A joint many-task model: Growing a neural network for multiple nlp tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-1046" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="446" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep semantic role labeling: What works and what&apos;s next</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="17" to="1044" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics, Vancouver</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recurrent orthogonal networks and long-memory tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Machine Learning (ICML)</title>
		<meeting>the 33rd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2034" to="2042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Opinion mining with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1080" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="720" to="728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Relational Features in Fine-Grained Opinion Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="473" to="509" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<title level="m">Llu?s M?rquez, and Israa Jaradat. 2017. Cross-language Learning with</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Association for Computational Linguistics</title>
		<ptr target="http://aclweb.org/anthology/K17-1024" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Conference on Computational Natural Language Learning</title>
		<meeting>the 21st Conference on Computational Natural Language Learning<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="226" to="237" />
		</imprint>
	</monogr>
	<note>Adversarial Neural Networks</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An empirical exploration of recurrent network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning (ICML)</title>
		<meeting>the 32nd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2342" to="2350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Investigating LSTMs for Joint Extraction of Opinion Entities and Relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arzoo</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="16" to="1087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Extracting Opinions, Opinion Holders, and Topics Expressed in Online News Media Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Soo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hovy</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W/W06/W06-0301" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Sentiment and Subjectivity in Text</title>
		<meeting>the Workshop on Sentiment and Subjectivity in Text<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adversarial adaptation of synthetic or stale data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongchan</forename><surname>Kim</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="17" to="1119" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)<address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adversarial learning for neural dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-1229" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2147" to="2159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Finegrained opinion mining with recurrent neural networks and word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Meng</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D15-1168" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1433" to="1443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adversarial multi-task learning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="17" to="1001" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mc-Closky</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P/P14/P14-5010" />
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL) System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Encoding sentences with graph convolutional networks for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-1159" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1506" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">When is multitask learning effective? semantic sequence prediction under varying data conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alonso</forename><surname>H?ctor Mart?nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/E17-1005" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="44" to="53" />
		</imprint>
	</monogr>
	<note>Long Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The Kolmogorov-Smirnov test for goodness of fit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Massey</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American statistical Association</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">253</biblScope>
			<biblScope unit="page" from="68" to="78" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The Proposition Bank: An Annotated Corpus of Semantic Roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="71" to="106" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Glove: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adversarial connectiveexploiting networks for implicit discourse relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianhui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th</title>
		<meeting>the 55th</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
				<ptr target="http://aclweb.org/anthology/" />
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="17" to="1093" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Optimal hyperparameters for deep lstm-networks for sequence labeling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06799</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Effect functors for opinion inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Brandes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Finding the Sources and Targets of Subjective Expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swapna</forename><surname>Somasundaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC). Marrakech, Morocco</title>
		<meeting>the Sixth International Conference on Language Resources and Evaluation (LREC). Marrakech, Morocco</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2781" to="2788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep multi-task learning with low level tasks supervised at lower layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>S?gaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<ptr target="http://anthology.aclweb.org/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="16" to="2038" />
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Annotating Expressions of Opinions and Emotions in Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Opinion holder and target extraction on opinion compounds -a linguistic approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Bocionek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N16-1094" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="800" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Opinion holder and target extraction based on the induction of verbal categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/K15-1022" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Nineteenth Conference on Computational Natural Language Learning<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="215" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Separating actor-view from speakerview opinion expressions using linguistic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Schulder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N16-1092" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="778" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Fine-Grained Subjectivity And Sentiment Analysis: Recognizing The Intensity, Polarity, And Attitudes Of Private States</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilson</forename><surname>Theresa Ann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>University of Pittsburgh</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Adversarial training for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Russell</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-1187" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1779" to="1784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Joint Inference for Fine-grained Opinion Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P13-1161" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1640" to="1649" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Joint modeling of opinion expression extraction and attribute classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="505" to="516" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A joint sequential and relational model for frame-semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-1129" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1258" to="1267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Adversarial training for unsupervised bilingual lexicon induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="17" to="1179" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">End-to-end learning of semantic role labeling using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">China</forename><surname>Beijing</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/" />
		<imprint>
			<biblScope unit="page" from="15" to="1109" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
