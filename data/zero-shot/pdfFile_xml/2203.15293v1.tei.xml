<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Uncertainty-Aware Adaptation for Self-Supervised 3D Human Pose Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Science</orgName>
								<address>
									<settlement>Bangalore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kundu</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Seth</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Science</orgName>
								<address>
									<settlement>Bangalore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradyumna</forename><surname>Ym</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Science</orgName>
								<address>
									<settlement>Bangalore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Chakraborty</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Science</orgName>
								<address>
									<settlement>Bangalore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesh Babu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Science</orgName>
								<address>
									<settlement>Bangalore</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Uncertainty-Aware Adaptation for Self-Supervised 3D Human Pose Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The advances in monocular 3D human pose estimation are dominated by supervised techniques that require largescale 2D/3D pose annotations. Such methods often behave erratically in the absence of any provision to discard unfamiliar out-of-distribution data. To this end, we cast the 3D human pose learning as an unsupervised domain adaptation problem. We introduce MRP-Net 1 that constitutes a common deep network backbone with two output heads subscribing to two diverse configurations; a) model-free joint localization and b) model-based parametric regression. Such a design allows us to derive suitable measures to quantify prediction uncertainty at both pose and joint level granularity. While supervising only on labeled synthetic samples, the adaptation process aims to minimize the uncertainty for the unlabeled target images while maximizing the same for an extreme out-of-distribution dataset (backgrounds). Alongside synthetic-to-real 3D pose adaptation, the joint-uncertainties allow expanding the adaptation to work on in-the-wild images even in the presence of occlusion and truncation scenarios. We present a comprehensive evaluation of the proposed approach and demonstrate stateof-the-art performance on benchmark datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>3D human pose estimation forms a core component of several human-centric technologies such as augmented reality <ref type="bibr" target="#b23">[24]</ref>, gesture recognition <ref type="bibr" target="#b5">[6]</ref>, etc. Most of the 3D human pose estimation approaches heavily rely on fully supervised training objectives <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b79">80]</ref>, demanding access to largescale datasets with paired 3D pose annotation. However, the inconvenience of 3D pose acquisition stands as a significant bottleneck. Unlike a 2D pose, it is difficult to manually annotate an anthropomorphically constrained 3D pose for an in-the-wild RGB image. Thus, most of the paired 3D pose datasets are collected in lab environments via bodyworn sensors or multi-camera studio setups <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b77">78]</ref> that are * equal contribution. <ref type="bibr" target="#b0">1</ref> Project page: https://sites.google.com/view/mrp-net difficult to install outdoors. This often limits the dataset diversity in terms of the variety in poses, appearances (background and lighting conditions), and outfits.</p><p>Some works <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b70">71]</ref> propose weakly supervised techniques to bypass the requirement of 3D pose annotations. Several of these works leverage available paired 2D pose datasets or off-the-shelf image-to-2D pose estimation networks <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b82">83]</ref>. To address the inherent 2D-to-3D ambiguity, some works either rely on multi-view image pairs <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b37">38]</ref> or utilize unpaired 3D pose samples <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b87">88]</ref>. Though such methods perform well when evaluated on the same dataset, they lack cross-dataset generalization.</p><p>Consider a scenario where we want to deploy a 3D human pose estimation system in a new application environment (i.e. target domain). From the vendor's perspective, a general approach would be to improve the system's generalization via supervised training on a wide variety of labeled source domains <ref type="bibr" target="#b47">[48]</ref>. However, target-specific training usually achieves the best performance beyond the generic system. Though it is not convenient to collect annotations for every novel deployment scenario, an effective unsupervised adaptation framework stands as the most practical way forward. Unsupervised adaptation <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b83">84]</ref> seeks a learning technique that can minimize the domain discrepancy be- tween a labeled source and an unlabeled target. Thus, the vendor has to collect unlabeled RGB inputs from the new environment to enable the adaptation process. Let us consider a different scenario where the target environment is identical to one of the source domains implying no domainshift. Here, the vendor can choose to directly deploy the generic system without adaptation training. However, the system must have a provision to detect whether it is required to run the adaptation process. In other words, it should have the ability to discern out-of-distribution (OOD) scenarios <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b50">51]</ref>. Such an ability is more crucial while deploying in a continually changing environment <ref type="bibr" target="#b88">[89]</ref>, e.g. a model adapted for sunny weather conditions would fail while encountering rainy weather, thus requiring re-adaptation. We propose a novel domain adaptation (DA) framework, MRP-Net ( <ref type="figure" target="#fig_0">Fig. 1)</ref>, equipped with uncertainty estimation <ref type="bibr" target="#b34">[35]</ref> for the monocular 3D human pose estimation task. To this end, we use a multi-representation pose network with a common backbone followed by two pose estimation heads subscribing to two diverse output configurations; a) Heat-map based joint localization and b) Modelbased parametric regression. This not only encourages ensemble-diversity required for uncertainty estimation <ref type="bibr" target="#b17">[18]</ref> but also allows us to encompass the merits of both schools of thought <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b79">80]</ref>. The former configuration advocates maintaining the spatial structure via a fully-convolutional design <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b78">79]</ref> while lacking provisions to inculcate structural articulation and bone-length priors. The latter advocates regressing a parametric form of the pose as a whole (via fully-connected layers) <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b81">82]</ref> while allowing model-based structural prior infusion <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b66">67]</ref>. We use the 3D graphics-based synthetic SURREAL dataset <ref type="bibr" target="#b85">[86]</ref> as the labeled source domain to supervise our backbone network.</p><p>In addition, we derive useful measures to quantify the prediction uncertainty at two granularity levels; viz a) poseuncertainty, b) joint-uncertainty. During training, we utilize both a labeled source and a dataset of backgrounds (BG) to elicit the desired behavior of the uncertainties. Here, the backgrounds approximate an extreme out-ofdistribution scenario. Upon encountering the unlabeled target, the adaptation process seeks to reduce the target uncertainties alongside a progressive self-training on a set of re-liable pseudo-labels. Alongside the adaptation for datasets with full-body visibility, the joint-uncertainty lays a suitable ground to expand our adaptation to work on in-the-wild target domain (unlabeled) with partial body visibility (i.e. under external occlusion or truncated frame scenarios). We present an extensive evaluation of the proposed framework under a variety of source-to-target settings. In summary:</p><p>? We propose a novel domain adaptation framework, MRP-Net, that uses a multi-representation pose network. Here, pose-uncertainty is quantified as the disagreement between pose predictions through the two output heads subscribing towards two diverse design configurations (model-free versus model-based). ? We propose to utilize negative samples (backgrounds and simulated synthetic joint-level occlusions) to improve the effectiveness of the proposed pose and joint uncertainties. The presence of negatives also helps to retain the uncertainty estimation ability even while adapting to a novel target scenario. ? Our synthetic (SURREAL) to in-studio adaptation outperforms the comparable prior-arts on Hu-man3.6M <ref type="bibr" target="#b27">[28]</ref>. Our in-studio (Human3.6M) to in-thewild adaptation achieves state-of-the-art performance across four datasets. We show uncertainty-aware 3D pose estimation results for unsupervised adaptation to in-the-wild samples with partial body visibility. <ref type="table" target="#tab_0">Table 1</ref> shows a comparison of our approach against related prior approaches. Here, Sup. stands for supervision. Domain Adaptation. Cao et al. <ref type="bibr" target="#b8">[9]</ref> propose to apply discriminator based discrepancy minimization technique for the animal pose estimation task. To address the syntheticto-real domain gap for 3D human pose estimation, Doersch et al. <ref type="bibr" target="#b16">[17]</ref> propose to use optical-flow and 2D keypoints as the input as these representations are least affected by domain shift unlike RGB images (texture and lighting variations). Similarly, Zhang et al. <ref type="bibr" target="#b96">[97]</ref> propose to leverage multi-modal input, such as depth and body segmentation masks. Mu et al. <ref type="bibr" target="#b59">[60]</ref> leverage several consistency losses to effectively adapt from source to target. Our proposed framework does not access any such auxiliary input modality. Recently, some works <ref type="bibr" target="#b76">[77,</ref><ref type="bibr" target="#b95">96]</ref> propose online test-time adaptation of 3D human pose estimation from instudio source to in-the-wild target. Pose estimation in presence of occlusion. In literature, we find some methods that address human pose estimation in presence of partial occlusion. Several works design techniques to estimate location of the occluded keypoint conditioned on the unoccluded ones while accessing additional spatio-temporal <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b72">73]</ref> or scene related context <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b93">94,</ref><ref type="bibr" target="#b94">95]</ref>. Mehta et al. <ref type="bibr" target="#b54">[55]</ref> propose to use occlusionrobust pose-maps to address partial occlusion scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Monocular 3D human pose estimation. In literature, we find two broad categories viz. a) methods that directly infer the 3D pose representation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b74">75]</ref> and b) methods using model-based parametric representation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b63">64]</ref>. The former directly maps the input image to the 3D pose while the latter maps images to latent parameters of a predefined parametric human model. The latter setup provides a suitable ground to impose the kinematic pose priors via adversarial training <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b41">42]</ref>. The former setup is further categorized into one-stage <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b90">91,</ref><ref type="bibr" target="#b99">100]</ref> and two-stage methods <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b98">99]</ref>. One-stages approaches directly map images to the 3D poses. Whereas, two-stage methods first map images to an 2D pose representation followed by another mapping to perform the 2D-to-3D lifting. Pose estimation via multi-head architecture. PoseNet3D <ref type="bibr" target="#b80">[81]</ref> employs a student-teacher multi-head framework. However, the primary task is 2D-to-3D lifting where they rely on 2D pose predictions obtained from fully supervised image-to-2D pose model <ref type="bibr" target="#b60">[61]</ref>. Unlike PoseNet3D, we do not leverage in-the-wild 2D pose annotations or temporal consistency. Further, prior arts <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b71">72]</ref> also employ similar multi-head architecture to leverage auxiliary supervision or to improve predictions through consistency losses. To the best of our knowledge, none of the prior-arts utilize such architecture for OOD or self-adaptation to unlabeled target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>We aim to prepare a pose estimation network that can discern OOD samples by delivering a high prediction uncertainty for such inputs. Simultaneously, the network should not compromise on pose estimation performance for indomain inputs. Sec. 3.1 first discusses the pros and cons of the two widely used design configurations specific to output representation of human pose estimation networks. We describe the key design components of the proposed MRP-Net architecture, following which we propose intuitive ways to quantify the pose and joint uncertainties. Sec. 3.2 illustrates the training procedure to progressively strengthen and leverage the pose-uncertainty for the unsupervised DA setting. In Sec 3.3, we leverage the joint-uncertainties as a means to expand the adaptation to a broader scope, i.e. to in-thewild targets in the presence of occlusion and truncations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Pose estimation architecture</head><p>In literature, pose estimation architectures employ one of the following two design configurations. a) Localization-based representation. Most of the popular 2D pose estimation approaches employ fully convolutional architectures (such as hourglass networks <ref type="bibr" target="#b60">[61]</ref>), where the final pose is realized via J heatmaps, one for each joint <ref type="bibr" target="#b55">[56]</ref>. Here, the heatmaps are treated as spatial probability distributions (PDFs) with a probability peak near the spatial joint location. This can also be viewed as a localiza-tion based model-free design as it refrains from utilizing the joint-connectivity and the bone-length knowledge. b) Regression-based representation. Here, networks aim to directly regress joint coordinates or some rich parametric representations (latent) of the final pose <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b81">82]</ref>. Networks employ fully-connected layers after the back-bone CNN, thereby breaking away from the spatial structure to learn a highly non-linear mapping, unlike the localizationbased design. One can easily inculcate joint-connectivity or bone-length priors via model-based design with integrated forward kinematics <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b100">101]</ref>. However, such modelbased representation does not allow a provision to extract joint-level uncertainty as it sees the pose as a whole.</p><p>Normally trained systems often behave erratically in the absence of any provision to discard out-of-distribution inputs. In literature, ensemble-based systems <ref type="bibr" target="#b44">[45]</ref> have been used to derive useful uncertainty measures. Several approaches resort to random initialization or dataset bootstrapping to induce ensemble-diversity which is crucial to realize a robust uncertainty quantification metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">MRP-Net architecture</head><p>Keeping in mind the computational overhead of full network ensembles, we decide to develop multi-head ensembles with a common CNN backbone. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, the multi-head ensemble consists of a common encoder backbone E which is followed by two ensemble heads that are denoted as B L and B R . Unlike the random initialization strategy, we propose to maintain ensemble diversity by following the above discussed pose modeling configurations. a) Joint-localization at B L output. The localization branch B L is a convolutional decoder which outputs heatmap PDFs,h : {h (j) } J j=1 (via spatial-softmax). These heatmaps are converted to 2D joint coordinates via a softargmax operation,</p><formula xml:id="formula_0">q (j) = v (v)h (j) (v). Here, v : [v x , v y ]</formula><p>denotes the spatial grid index. We also extract jointconfidence,w asw (j) = max v h (j) (v). b) Kinematic-parameterization at B R output. On the other hand, the regression branch B R consists of several fully-connected layers to regress a 3D pose parameterization,p l and camera-parameters,?. We design a simple kinematic model based on the knowledge of hierarchical limb connectivity and relative bone-length ratios. We aim to disentangle the rigid camera variations (in camera space) from the non-rigid limb articulations (in canonical space). Here, the non-rigid articulations are modeled at the view-independent canonical space. Note that, in canonical space, the pelvis joint exactly aligns with the origin while the skeleton faces towards the positive X-axis, thus making it a view-independent pose representation,p c ? R J?3 . In our convention, the skeleton-face is obtained as the cross-product direction of two vectors; i.e., left-hip to neck and left-hip to right-hip. However, directly regressing the canonical pose coordinatesp c does not ensure the 3D bonelength constraints. Thus, we obtain the canonical pose via a forward-kinematic transformation where the pose-network regresses local limb vectors of unit magnitudes,p l ? R J?3 . For each joint j, the limb-vector is defined at a predefined convention of parent-relative joint space. Here, the forward-kinematic transformation T FK builds the canonical pose by recursively traversing over joints in the kinematic tree; while applying pre-fixed bone-length magnitudes along the transformed limb-vector directions (see <ref type="figure" target="#fig_1">Fig.  2B</ref>). Alongside the local limb-vectors, the pose-network regresses the Euler-rotations alongside the scale and spatial translation parameters (?: 3 angles, 1 scale, and 2 translation parameters). Following this, scaled orthographic projection T c outputs the projected image-space joint coordinatesq ? R J?2 . This also outputs the camera-space 3D posep ? R J?3 as an intermediate representation.</p><p>Next, we quantify uncertainty as follows: a) Quantifying pose-level uncertainty. In literature, ensemble disagreement provides a useful quantitative measure to evaluate the prediction uncertainty <ref type="bibr" target="#b17">[18]</ref>. For MRP-Net, we propose to rely on the diversity in design configuration between the two representations obtained via B L and B R . Thus, we define the pose-uncertainty as follows:</p><formula xml:id="formula_1">U (I) = |q ?q|;q = BL ?E(I),q = T ?BR ? E(I) (1)</formula><p>Here, ? denotes functional composition and T = T FK ? T c . b) Quantifying joint-level uncertainty. Among the two representations, joint-level uncertainty can be extracted from localization based spatial map distributions. For each joint prediction, the joint uncertainty associated with a joint j, is realized as the self-entropy of spatial distributions, i.e.</p><formula xml:id="formula_2">H(I, j) = ? vh (j) (v) logh (j) (v)<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pose-level adaptation framework</head><p>In unsupervised DA the primary goal is to transfer the task knowledge from a labeled source dataset D s (synthetic domain) to an unlabeled target dataset D t (real domain).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Preparing pose-uncertainty-aware MRP-Net</head><p>Let, L h (.) and L p (.) be the mean squared loss for the heatmap and the 3D pose respectively. The synthetic supervision loss is expressed as;</p><formula xml:id="formula_3">L (s) Sup (I ? Ds) = L h (h, hgt) + ?1Lp(p, pgt) + ?2U (s)<label>(3)</label></formula><p>Here, h gt and p gt denote the respective ground-truths (GT) with ? 1 and ? 2 being the balancing hyperparameters. The intended behaviour of pose-uncertainty is that it would elicit a high value for U (s) for unfamiliar inputs while being low for familiar in-domain samples, i.e. for I ? D s . However, training of MRP-Net solely on samples from D s outputs consistently low pose-uncertainty for both in-domain and out-of-domain samples during validation. One has to explicitly update the network parameters to obtain higher uncertainty for the unfamiliar inputs. In view of the human pose estimation task, we resort to a dataset of background images D b (i.e. images without any person in frame) to approximate an extreme out-of-distribution scenario.</p><p>In summary, the MRP-Net is trained to minimize L </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Adaptation via uncertainty minimization</head><p>Next, the uncertainty-aware network is exposed to the unlabeled target samples, I t ? D t . Analyzing the histogram from <ref type="figure" target="#fig_0">Fig. 1</ref> of the pose-uncertainties for samples from D s , D b , and D t shows that the uncertainties for D t spans a widerange of values with the same for D s and D b as peaky distributions at opposite extremes. One can relate the uncertainty gap between the samples from D b and D t as result of the distinction between data-uncertainty (or aleatoric uncertainty) and knowledge-uncertainty (or epistemic uncertainty), respectively. Here, data-uncertainty refers to the irreducible uncertainty in prediction as a result of noisy input, whereas the knowledge-uncertainty refers to the reducible uncertainty elicited as an outcome of the discrepancy in input distributions (i.e. the synthetic versus real domains). a) Adaptation. Motivated by the above discussion, we seek to minimize the pose-uncertainty for the target samples, i.e.</p><formula xml:id="formula_4">U (t) = U(I ? D t ) alongside minimizing L (s) Sup , while si- multaneously maximizing U (b) = U(I ? D b ). b) Self-training on target pseudo-labels.</formula><p>The literature <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b102">103]</ref> suggests that target supervision on a reliable pseudo-label subset helps to improve the adaptation performance. In classification tasks, the class predictions of the most confident targets are collected as a reliable pseudolabel subset <ref type="bibr" target="#b75">[76]</ref>. In the proposed scenario, the reliability of pseudo-label selection based on the pose-uncertainty is highly questionable, as it might be an outcome of the enforced uncertainty minimization loss instead of a genuine learning induced behaviour. Thus, in order to move away from such dependency, we utilize an equivariance consistency based pseudo-label selection criteria. This is realized by applying the most diverse spatial transformation i.e. image-flip. Essentially, the 2D pose predictions of a given image, I t and the corresponding flipped image, I ? t = F I (I t ) are compared after a left-right joint-id swapping operation F q . Thus, for each I t we obtain the following prediction?</p><formula xml:id="formula_5">q t ,q t , F q (q ? t ), F q (q ? t ).</formula><p>Finally, the pseudo-label subset D pl t is realized by selecting samples that have an equivarianceconsistency less than a preset threshold ? th p i.e.,</p><formula xml:id="formula_6">D pl t = {I t : (|q t ? F q (q ? t )| + |q t ? F q (q ? t )|) &lt; ? th p } (4)</formula><p>Next, we minimize the target pseudo-label supervision loss;</p><formula xml:id="formula_7">L (t) pSup (I ? D pl t ) = J j=1w (j) (L (j) h (h, h pl gt ) + ?L (j) p (p, p pl gt )) (5)</formula><p>Here, the supervised joint-wise loss is weighted by the normalized joint-confidences to avoid strong supervision on confusing joint predictions. p pl gt and h pl gt denote the estimated pseudo-label GT (i.e. prediction average over the equivariance instances). Here, D pl t alongside the pseudo-label GTs are updated at regular intervals during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Joint-level adaptation framework</head><p>Most of the prior 3D pose estimation approaches expect full-body visibility without external occlusion. However, in real-world deployment, the camera feed may capture human images having external object occlusions or truncations. In such scenarios, an intended behavior of the model would be to estimate a reasonably well joint localization specifically for the in-view joints with lower joint-uncertainty values, and higher joint-uncertainties for the out-view joints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Preparing joint-uncertainty-aware MRP-Net</head><p>Similar to pose-uncertainty, one must simulate joint-level uncertainties to enable the model to elicit the above discussed behavior. Note that, training on synthetic fullbody images (i.e. D s ) or the backgrounds (i.e. D b ) is not suitable enough as they do not encourage varying jointuncertainties for the same input instance. Thus, we simulate an occlusion-aware synthetic dataset, D O s with segregated set of in-view and out-view image-joint pairs, denoted as J s inV and J s outV respectively (see <ref type="figure" target="#fig_1">Fig. 2D</ref>). Broadly, we simulate occlusion of two kinds, viz, a) occlusion by an external object, and b) truncation of the image frame. We apply the following synthetic supervision loss.</p><formula xml:id="formula_8">L OA Sup (I ? D O s ) = 1 J s inV (L (j) h (h, hgt) + ?1L (j) p (p, pgt)) ? ?2H (s) J s outV<label>(6)</label></formula><p>Here, 1 denotes an indicator function. The last-term aims to maximize the joint-uncertainties only for the out-view joints. We also maximize joint-uncertainties of all the joints for the backgrounds D b by maximizing H</p><formula xml:id="formula_9">(b) ?j .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Adapting to unlabeled target with occlusion</head><p>Next, the joint-uncertainty-aware model is exposed to samples from the unlabeled target dataset containing images of varied kinds including full-body, truncated, and occluded samples. We denote this dataset as D O t against the full-body target D t . We follow the adaptation process very similar to that of the proposed pose-level adaptation with the poseuncertainties replaced by the joint-uncertainties.</p><p>We follow the similar equivariance-based pseudo-label selection criteria to pick the suitable (I t , j) pairs for creating the target pseudo-label subset, J t inV . Here, J t outV denotes the set of the (I t , j) pairs having joint-uncertainty greater than a preset threshold ? th h . Rest of the (I t , j) pairs can move either towards J t inV or J t outV over the course of adaptation training and are thus left untouched (no loss imposed).</p><formula xml:id="formula_10">J t inV = {(I t , j) : H(I t , j)(|q (j) t ? F (j) q (q ? t )|) &lt; ? th q } (7)</formula><p>The adaptation training involves minimizing H </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Inferring the final 3D pose</head><p>In the proposed MRP-Net, 3D pose can only be inferred through the B R branch (i.e.p). However, several recent  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We demonstrate effectiveness of MRP-Net (MRPN) by evaluating it on a variety of cross-dataset settings. Implementation details. We use ResNet-50 <ref type="bibr" target="#b24">[25]</ref> (till Res-4f), pre-trained on the ImageNet, as the common encoder E. The localization branch B L comprises of of transposed convolutional layers which progressively increase the spatial resolution to yield 17 heatmaps of size 56?56. The regression branch B R consists of a series of fully-connected (FC) layers which later bifurcate into two sub-branches to yield camera parameters? and local limb vectorsp l . We trained the framework on a NVIDIA P-100 GPU (16GB), with a batch size of eight. We employ separate Adam optimizers <ref type="bibr" target="#b30">[31]</ref> for each loss term. See Suppl. for more details.</p><p>Datasets. We use the following datasets. a) SURREAL (S) synthetic dataset <ref type="bibr" target="#b85">[86]</ref> is used both as source and target under different problem settings. Though the dataset encapsulates a wide range of diversity, synthetictrained model suffers from poor generalization on natural images due to synthetic-to-real domain-shift. b) Backgrounds. We use background images taken from; LSUN <ref type="bibr" target="#b91">[92]</ref>, Google Street View <ref type="bibr" target="#b92">[93]</ref>, Natural Scenes <ref type="bibr" target="#b20">[21]</ref>, and Campus Scenes <ref type="bibr" target="#b7">[8]</ref> to form the dataset, D b . c) Human3.6M (H). For a fair evaluation, we use the standard, in-studio Human3.6M (H3.6M) dataset <ref type="bibr" target="#b27">[28]</ref> as either source or target domain in different problem settings. d) Target datasets. 3DPW <ref type="bibr" target="#b86">[87]</ref>, HumanEva <ref type="bibr" target="#b77">[78]</ref>, and MPI-INF-3DHP (3DHP) <ref type="bibr" target="#b53">[54]</ref> are used as unlabeled target <ref type="table">Table 3</ref>. Quantitative comparison on Human3.6M. Our proposed method outperforms the prior-arts at various supervision levels. * denotes using MPII <ref type="bibr" target="#b1">[2]</ref> with 2D pose annotations. + denotes using additional in-the-wild data taken from the Internet. supervisiontype on target (H3.6M) is indicated under the Supervision column. Semi-sup (S1) denotes 3D pose supervision only on subject S1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Supervision PA-MPJPE? MPJPE? Martinez et al. <ref type="bibr" target="#b52">[53]</ref> Full-3D 52.5 67.5 Xu et al. <ref type="bibr" target="#b89">[90]</ref> Full-3D 36.2 45.6 Chen et al. <ref type="bibr" target="#b11">[12]</ref> Full-3D 32.7 47.3 Mitra et al. <ref type="bibr" target="#b56">[57]</ref> Semi-sup (S1) 90.8 120.9 Li et al. <ref type="bibr" target="#b49">[50]</ref> Semi-sup (S1) 66.5 88.8 Rhodin et al. <ref type="bibr" target="#b69">[70]</ref> Semi-sup (S1) 65.1 -Kocabas et al. <ref type="bibr" target="#b31">[32]</ref> Semi-sup (S1) 60. datasets to evaluate the unsupervised adaptation. Occlusion simulation. We perform occlusion simulation on both source and target. The simulation process works on the corresponding full-body instances. We paste external objects (like cars, chair, wardrobe, etc.) to simulate occlusions, whereas truncation is simulated by randomly zooming into the top or bottom region of the full-body images. Evaluation metrics. For a fair comparison, we evaluate our approach on the standard benchmark datasets described above. The standard mean per joint position error metric computed before and after Procrustes Alignment <ref type="bibr" target="#b21">[22]</ref> are denoted as MPJPE and PA-MPJPE respectively <ref type="bibr">[</ref>  domains, i.e., 3DHP, 3DPW, SURREAL, and HumanEva datasets when using Human3.6M as the source domain. Our baseline is trained only on the source domain Human3.6M. A direct transfer on the target domains performs poorly attributed to the vast domain gap induced due to changing pose, appearance, and backgrounds between source and target datasets. Our pose-level adaptation strategy helps MRPN improve upon the prior-arts even on in-the-wild 3DPW dataset by a significant margin, thereby validating ours superior generalizability. Ours+ISO is the variant which uses ISO <ref type="bibr" target="#b95">[96]</ref> for test time optimization. 4.1.3. Adaptation to partial body visibility. <ref type="table" target="#tab_4">Table 4</ref> reports a quantitative analysis to highlight the merits of our design choices against the standard prior-art techniques. Under Joint-level adaptation, the baseline on row-1 shows transfer results on the target before adaptation. Row-2 baseline employs uncertainty maximization on target as well. Finally, row-3 uses target pseudo labels for self-training. Ours(JU) outperforms LCR++ <ref type="bibr" target="#b73">[74]</ref> even in the absence of 2D/3D supervision on in-the-wild datasets like MPII. 4.1.4. Ablation study. In <ref type="table" target="#tab_4">Table 4</ref>, under pose-level adaptation, the baseline on row-5 uses MRPN architecture while employing an adversarial discriminator based discrepancy minimization on encoder features (DANN). The baseline on row-6 shows transfer results on the target before adaptation. Row-8 baseline employees self-training unlike in row-7 where only the target uncertainty is minimized. Our final model is depicted in row-9 where the pose predictions are obtained via the fusion-network unlike in row-4.  in-the-wild). <ref type="figure" target="#fig_5">Fig. 3</ref> presents extensive in-the-wild and partial body visibility scenarios. We also show results on images randomly taken from online sources. MRP-Net successfully estimates reasonable 3D poses for most of the occluded and truncated cases. However, our model may fail under certain drastic scenarios such as multi-level bodypart occlusion, high background clutter, and rare athletic poses. <ref type="figure">Fig. 5</ref> gives an insight into how MRP-Net adapts to both unoccluded and partial-body visibility scenarios with predictions better than LCR++ <ref type="bibr" target="#b73">[74]</ref>.  Societal impacts. We do not foresee a direct negative societal impact from our framework. However, it may be leveraged for human-tracking applications. We urge the readers to make ethical and responsible use of our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Qualitative evaluation and limitations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Model interpretability.</head><p>We also perform a thorough qualitative study to interpret the behaviour of our network for a wide variety of in-distribution and out-of-distribution samples. In <ref type="figure">Fig. 4</ref>, we analyze how samples from different domains (such as source, target, and backgrounds) are distributed along the uncertainty metrics, i.e. the poseuncertainty and joint-uncertainty. This gives an insight into how MRPN caters to OOD samples as well as the un-certainty associated with partial body visibility. <ref type="figure">Fig. 4A</ref> shows histogram of the predicted joint-uncertainties for the true in-view and out-view joints separately for source (i.e. inV-S and outV-S) and target (i.e. inV-T and outV-T). BG denotes the histogram of all out-view joints for backgrounds. The shaded regions in the bottom panel depicts J t inV and J t outV which are segregated using the preset thresholds ? th q and ? th h respectively (edges of the green-box). Our adaptation algorithm succeeds to separate inV-T and outV-T over the course of adaptation training. Next, <ref type="figure">Fig. 4B</ref> shows a similar analysis for pose-uncertainties. We show five different examples sampled from different regions of the histogram-bins. In the right-panel, we show that to maximize pose-uncertainty for backgrounds (OOD samples), MRPN estimates the 2D landmarks and 3D pose points separated towards opposite diagonal corners. Here, the 2D landmarks are collapsed to the top-left corner whereas the root joint (pelvis) of the model-based 3D predictions are seemed to have collapsed towards the bottom-right corner. In the bottom-panel, for uncertain target instances, we see two peaks in the joint heatmap distributions; one at the topleft corner (OOD-related) and the other near the actual joint location. During adaptation, the OOD-related peak suppresses while the joint-related peak rises to simultaneously reduce the uncertainty while converging towards the true pose outcome. Finally, on the left panel, joint-level uncertainty is indicated by the entropy of heatmap distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We presented a multi-representation pose network that embraces the pros and cons of both model-free and modelbased pose representations to realize a disagreement based pose-uncertainty measure. We develop learning techniques to make the model behave differently for the in-domain and out-of-domain scenarios. Later, the same instigated behaviour is used to devise effective unsupervised adaptation objectives. Formalizing prediction uncertainty in the presence of temporal context remains to be explored in future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Uncertainty-Aware Adaptation for Self-Supervised 3D Human Pose Estimation</head><p>The supplementary document is organized as follows:</p><p>? Section A: Notations </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Notations</head><p>Most of the notations used in this paper are summarized in <ref type="table" target="#tab_5">Table 5</ref>. In the first part, we list the general architecture related notations. Next, we group other notations into a) output of B L , b) output of B R , c) datasets, and finally the adaptation training related notations for both d) pose-level and e) joint-level adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Training algorithms</head><p>In this section, we clearly discuss the training algorithms which could not be included in the main paper. Algo. 1 and Algo. 3 show the training algorithm for pose-level and jointlevel adaptation respectively. We simultaneously train on samples from all the three datasets, i.e. on D s , D t , and D b for pose-level adaptation and on D O s , D O t , and D b for jointlevel adaptation. The pseudo-label selection procedure is clearly explained in both the algorithms (refer <ref type="table" target="#tab_5">Table 5</ref> for a description of the notations). Though we use the above for pose-level adaptation for a fair prior-art benchmarking, one is always free to relax this assumption. a) Under pose-level DA, synthetic training on D O s (truncated+full) would make it applicable for both full and truncated target. In <ref type="figure">Fig. 5</ref>, notice the medium level uncertainty elicited by MRPN(PU) for truncated target (a desirable behaviour). b) On the other hand, joint-level adaptation already suits to both the scenarios (MRPN(JU) in <ref type="figure" target="#fig_0">Fig. 10</ref> Algo. 2 shows a detailed training procedure to prepare the fusion network for the pose-level adaptation scenario. We prepare a separate fusion network for the jointlevel adaptation. <ref type="table" target="#tab_9">Table 7</ref> reports relative contributions of B R and B L outputs against the fused. In case of joint level adaptation the loss-term in L3 of Algo. 2 is replaced by 1 (I,j)?J s inV L (j) p (p, p gt ) (the second loss-term in L6 of  We trained the framework on an NVIDIA P-100 GPU (16GB) with a batch size of 8. We employ separate Adam Algorithm 1 Training algorithm for pose-level adaptation. Compute D pl t whereq t andq ? t are obtained using current state of network parameters ?, as follows:</p><formula xml:id="formula_11">D pl t = {I t : (|q t ? F q (q ? t )| + |q t ? F q (q ? t )|) &lt; ? th p } 5: end if B.</formula><p>Adaptation training (for pose-level adaptation).   Update ? f to minimize L p (p f , p gt ) on a mini-batch of D s using Adam optimizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Update ? f to minimize J j=1w (j) L (j) (p f , p pl gt ) on a mini-batch of D pl t using Adam optimizer. <ref type="bibr" target="#b4">5</ref> Compute J t inV and J t outV , whereq t andq ? t are obtained using the current state of the network parameters ?, as follows: 12: end while 4). Eq. 5 selectively imposes a strong loss on the more confident target samples. It is to be noted that, such segregation is highly subjective, and treating these soft-OOD samples as hard-OOD deteriorates the generalization performance.</p><formula xml:id="formula_12">J t inV = {(I t , j) : H(I t , j)(|q (j) t ? F (j) q (q ? t )|) &lt; ? th q } J t outV = {(I t , j) : H(I t , j)(|q (j) t ?F (j) q (q ? t )|) &gt; ? th h } 5: end if B.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Network architecture</head><p>The architecture consists of an ImageNet initialized ResNet-50 (till Res-4F) which bifurcates into two branches, B L and B R as shown in <ref type="figure" target="#fig_16">Fig. 8</ref>. B L is a convolutional decoder consisting of an alternate series of transposed convolution and general convolution which progressively increases the spatial resolution from 7?7 to 56?56. The final output of B L is 17 heatmap PDFs,h obtained via spatial softmax. These are then used to extract the correspond- <ref type="table">Table 6</ref>. Assets and the corresponding Licenses Asset used License Human3.6M <ref type="bibr" target="#b27">[28]</ref> Limited license for academic use MPI-INF-3DHP <ref type="bibr" target="#b53">[54]</ref> Limited license for academic use 3DPW <ref type="bibr" target="#b86">[87]</ref> Limited license for academic use HumanEva <ref type="bibr" target="#b77">[78]</ref> Limited license for academic use SURREAL <ref type="bibr" target="#b85">[86]</ref> Limited license for academic use    ing 2D joint coordinates,q and joint confidence,w. B R consists of a common branch with fully-connected residual blocks <ref type="bibr" target="#b87">[88]</ref> which further divides into camera,? and pose predictionp l sub-branches, each consisting of 2 residual blocks. The outputs,w,q, andp are concatenated and passed to the fusion network which is composed of a series of 3 residual blocks to regress the final 3D pose,p f . <ref type="figure" target="#fig_16">Fig. 8</ref> shows the detailed architecture. Further, ablation performance with fusion network is shown in <ref type="table" target="#tab_10">Table 8</ref> (MPJPE of #5-7, <ref type="table" target="#tab_4">Table 4</ref>). We see that a better adaptation further enhances the gain from fusion network. For uncertain target instances, we see two peaks in the joint heatmap PDFs; one at the top-left corner (OOD-related) and the other near the actual joint location. During adaptation, the OOD-related peak suppress while the joint-related peak rises to simultaneously reduce the uncertainty while converging towards the true pose outcome. Results on the left panel: Joint-level uncertainty is indicated by the entropy of heatmap PDF. <ref type="figure" target="#fig_0">Figure 10</ref>. Every pose prediction of MRPN is associated with a measure of uncertainty barometer. The barometer height indicates high uncertainty. The blue, green and orange barometers indicate the average prediction uncertainty for the full-pose, true-in-view joints and true-out-view joints respectively. The dotted gray rectangles highlight the failure cases of LCR++ in predicting the correct 3D inter-limb depth though the 2D landmarks align with the GT. In the last 2 rows, the filled redbox under GT column segregates the true out-view joints. The in-view joint predictions of MRPN(JU) (unfilled green rectangles) performs better against the same for LCR++ (unfilled red rectangles) when compared against the same under GT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Qualitative analysis</head><p>We perform a thorough qualitative study to interpret the behaviour of our network for a wide variety of indistribution and out-of-distribution samples (see <ref type="figure" target="#fig_15">Fig. 7</ref>). The analysis in <ref type="figure" target="#fig_17">Fig. 9A</ref> shows that the proposed jointlevel adaptation algorithm succeeds to separate inV-T and outV-T over the course of adaptation training, thereby aligning these with inV-S and outV-S respectively. In <ref type="figure" target="#fig_0">Fig. 10</ref>, MRPN(B1) indicates the occlusion-aware network before the adaptation training. MRPN(PU) and MRPN(JU) indicate the final networks after the pose-level and joint-level adaptations. Further we show the ground-truth (2D) and predictions on LCR++ <ref type="bibr" target="#b73">[74]</ref>. MRPN(PU) is not tuned to work on occluded/truncated images and thus yields a higher uncertainty for the last two rows. Whereas, the uncertainty predictions of MRPN(JU) for the green and orange barometer yield the expected behaviour.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>The proposed unsupervised adaptation framework utilizes a multi-representation consistency based uncertainty estimation for simultaneous OOD detection and adaptation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>An overview of the proposed framework. A. Design configuration for output representations of MRP-Net architecture. B. Details of the Forward-kinematics transformation. C. Applying rotation and camera transformations. D. An illustration of the datasets and loss terms for the proposed pose-level and joint-level adaptation. E. The occlusion simulation to obtain in-view and out-view joint-ids.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Sup while simultaneously maximizing the pose-uncertainty for backgrounds i.e. U (b) = U(I ? D b ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>uncertainties for J t inV and J t outV respectively), alongside minimizing the joint-supervision on target pseudo-labels, i.e. L OA pSup ((I, j) ? J t inV )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>works [ 58 ]</head><label>58</label><figDesc>advocate for a localization-based representation even for the 3D pose estimation by introducing another output for joint-wise depth-localization. Based on the pros and cons of both the modeling configurations, we decide to leverage the best of both worlds by training a fusion network to realize the final 3D pose predictionp f . The fusion network takes three inputs; a) 3D pose predictions via B R (i.e.p), b) 2D pose prediction via B L (i.e.q), and c) the joint-confidencesw. The fully-connected fusion network is trained to minimize a loss that is exactly similar to L (t) pSup but on samples from both source and target pseudo-label set. Please refer to Supplementary for more details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 .</head><label>3</label><figDesc>Qualitative analysis. 3D poses shown correspond to the original camera view and another azimuthal view (+30 ? or -30 ? ). For results in panel E and F the joints with uncertainty greater than a prefix threshold are highlighted with red-blobs. The model fails on rare poses, complex inter-limb occlusion and heavy background clutter as highlighted by red bases. Refer Suppl. for more results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 and</head><label>3</label><figDesc>Fig. 5analyze our pose prediction results across variations in pose complexity, occlusion/truncation scenarios and environmental conditions (i.e. in-studio and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>MRPN(B1) indicates the occlusion-aware network before the adaptation training. Without adaptation on target samples, the model predicts with high uncertainty. MRPN(PU) and MRPN(JU)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 .Figure 5 .</head><label>45</label><figDesc>A. Histogram of samples from different domains (source, target, and background) along the joint uncertainty metric. B. Visualizing how the model choose to maximizes uncertainty for background (on right) and and occluded joints (on middle). MRPN(B1) MRPN(PU) MRPN(JU) GT Pose prediction results showing measure of uncertainty values for pose, in-view, and out-view joints. The barometer height indicates high uncertainty. The blue, green and orange barometers indicate the prediction uncertainty for the full-pose, true-in-view joints and true-out-view joints respectively. indicate the final networks after the pose-level and jointlevel adaptations. MRPN(PU) is not tuned to work on occluded/truncated images and thus yields a higher uncertainty for the bottom two images. Whereas, the uncertainty predictions of MRPN(JU) for the green and orange barometer yield the expected behaviour. The red-blocks under GT column segregate the true out-view joints. The in-view joint predictions of MRPN(JU) match with the same under GT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>?</head><label></label><figDesc>Section B: Training algorithms ? Section C: Network architecture ? Section D: Qualitative analysis</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>l</head><label></label><figDesc>Local pose vectors (parent-relative) ? R J?3 c Camera parameters (3 angles, 1 scale, 2 translations) p c Canonical 3D pose coordinates ? R J?3 p Camera-relative 3D pose coordinates ? R J?3 q projected 2D pose coordinates ? R J?2 Datasets D s , D t Labeled source and unlabeled target datasets (full-body) D O s , D O t Source and target datasets with occlusion/truncation D b A dataset of background images (other than human) Pose-level U(I) Pose-level uncertainty for a given image L (s) Sup Supervised loss on D s samples (minimized) U (s) Pose-uncertainty of D s samples (minimized) U (b) Pose-uncertainty of D b samples (maximized) U (t) Pose-uncertainty of D t samples (minimized) L (t) pSup Loss on pseudo-label target subset D pl t (minimized) ? th p Threshold to select pseudo-labeled target subset D pl t Joint-level H(I, j) Joint-level uncertainty (JU) for a given image, joint-id pair L OA Sup Occlusion-aware supervised loss on D O s (minimized) H (s) J s outV JU of true out-view joints of D O s (maximized) H (b) ?j JU of all joints for backgrounds D b (maximized) H (t) J t inV JU of pseudo-selected in-view joints of D O t (minimized) H (t) J t outV JU of pseudo-selected out-view joints of D O t (maximized) L OA pSup Loss on pseudo-labeled target set (I, j) ? J t inV (minimized) ? th q Threshold to select pseudo-labeled target in-view set J t inV ? th h Threshold to select pseudo-labeled target out-view set J t outV Algo. 3). Similarly, the loss-term in L4 of Algo. 2 is replaced by j?J t inVw (j) L (j) (p, p pl gt ) (the second loss-term in L11 of Algo. 3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>6 :</head><label>6</label><figDesc>Update ? by minimizing L h (?, h gt ), L p (p, p gt ), and U (s) (i.e. the first two terms under L (s) Sup ) on a mini-batch of D s using separate Adam optimizers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>7 : 8 : 9 :Algorithm 2 1 :</head><label>78921</label><figDesc>Update ? by maximizing U (b) on a mini-batch of D b using Adam optimizer. Update ? by minimizing U (t) on a mini-batch of D t using Adam optimizer. Update ? by maximizing jw (j) L (j) (h, h pl gt ) and jw (j) L (j) (p, p pl gt ) (i.e. the two terms under L (t) pSup ) using separate Adam optimizers. 10: end while optimizers [31] for each loss term. Please refer Fig 6 for sensitivity analysis. Note that, we use fixed threshold values across all adaptation settings in Sec 4.1. Importance of OOD images. We would like to reiterate that the background images represent an objective segregation of hard-OOD samples. The poses outside of the training distribution are critical to identify and we segregate them via the pseudo-label subset selection criteria (Eq. Training algorithm for the fusion network. Input: Labeled source dataset D s and the pseudolabeled target subset D pl t . The network takes 3 inputs: a) 3D pose predictions via B R (i.e.p), b) 2D pose prediction via B L (i.e.q), and c) the joint-confidencesw via B L . Let ? f denote the learnable parameters of the fusion network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>2 :</head><label>2</label><figDesc>while iter &lt; MaxIter do 3:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 6 .</head><label>6</label><figDesc>Hyperparameter sensitivity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 7 .</head><label>7</label><figDesc>Qualitative analysis. 3D poses shown correspond to the original camera view and another azimuthal view at +30 ? or -30 ? depending on best viewing angle. For results in panel E and F the joints with uncertainty greater than a prefix threshold are highlighted with red-blobs. The model fails on rare poses, complex inter-limb occlusion and heavy background clutter as highlighted by red bases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 8 .</head><label>8</label><figDesc>Detailed architecture of the proposed MRP-Net. On the right we show the legend. Here, K3C256S2 denotes specifications of the convolutional layer, i.e. 3?3 filter size, 256 filters applied with a stride 2. Here, TConv denotes transposed convolution operation. FC denotes fully-connected layer. x2 and x3 depict number of residual blocks that are stacked to form the corresponding branch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 9 .</head><label>9</label><figDesc>A. Shows histogram of the predicted joint-uncertainties for the true in-view and out-view joints separately for source (i.e. inV-S and outV-S) and target (i.e. inV-T and outV-T). BG denotes the histogram of all out-view joints for backgrounds. The shaded regions in the bottom panel depictsJ t inV and J t outV which are segregated using the preset thresholds ? th q and ? th h respectively (edges of the green-box). Our adaptation algorithm succeeds to separate inV-T and outV-T over the course of adaptation training. B. Shows a similar analysis for pose-uncertainties. We show 5 different examples sampled from different regions of the histogram-bins. Results on right-panel: Notice that to maximize pose-uncertainty for backgrounds (OOD samples), MRPN estimates the 2D landmarks and 3D pose points separated towards opposite diagonal corners. Here, the 2D landmarks are collapsed to the top-left corner whereas the root joint (pelvis) of the modelbased 3D predictions are seemed to have collapsed towards the bottom-right corner. Result on bottom-panel:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of positive (in green) and negative (in red) attributes of ours against prior 3D human pose estimation methods.</figDesc><table><row><cell></cell><cell cols="3">Real Sup.</cell><cell>Synthetic</cell><cell cols="2">Generalization</cell></row><row><cell>Methods</cell><cell>Multi</cell><cell>2D</cell><cell>3D</cell><cell>3D pose</cell><cell></cell><cell>capability</cell></row><row><cell></cell><cell>view</cell><cell>pose</cell><cell>pose</cell><cell>Sup.</cell><cell cols="2">Occlusion Uncertainty</cell></row><row><cell>Zhou et al. [102]</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>Rhodin et al. [70]</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>Iqbal et al. [29]</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell cols="2">Doersch et al. [17] ?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>LCR-Net++ [74]</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>PoseNet3D [81]</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>Ours</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Quantitative results on 3DPW and 3DHP. Numbers and layout taken from<ref type="bibr" target="#b97">[98]</ref>. * denotes inference stage (or online) optimization. MPJPE? MPJPE? PA-MPJPE? MPJPE? PA-MPJPE? MPJPE? PA-MPJPE?</figDesc><table><row><cell cols="4">Adaptation type MPJPE? PA-General H3.6M?3DPW Methods DDC [85] 110.4 75.3 DAN [52] 107.5 73.2 DANN [19] 106.3 71.1 Adaptation Zhang et al. [98] 94.7 63.9</cell><cell cols="2">H3.6M?3DHP 115.6 91.5 109.5 89.2 107.9 88.0 99.3 81.5</cell><cell cols="2">H3.6M?SURREAL 117.5 80.1 114.2 78.4 113.6 77.2 103.3 69.1</cell><cell cols="2">H3.6M?HumanEva 83.8 64.9 78.5 62.7 76.3 60.8 69.2 53.5</cell></row><row><cell></cell><cell>Ours</cell><cell>91.9</cell><cell>62.1</cell><cell>96.2</cell><cell>78.6</cell><cell>99.6</cell><cell>67.2</cell><cell>66.8</cell><cell>51.9</cell></row><row><cell>Test-time Adaptation</cell><cell>ISO [96]  *  BOA [77]  *  Ours+ISO  *</cell><cell>-92.1 89.6</cell><cell>70.8 58.8 57.5</cell><cell>--92.9</cell><cell>75.8 77.4 76.3</cell><cell>--96.4</cell><cell>--65.1</cell><cell>--65.2</cell><cell>--50.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Ablation study. The column headings indicate usage of different loss terms during training. Ablations under poselevel adaptation are evaluated on Human3.6M. * denotes inference without the fusion network. Ablations under joint-level adaptation are evaluated on truncated/occluded 3DPW test-split, obtained via in-house occlusion simulations. Here, MPJPE is computed only for the true in-view joints. B1 and B2 denotes our baselines under joint-level and pose-level adaptations respectively.</figDesc><table><row><cell cols="5">Joint-level adaptation on 3DPW</cell></row><row><cell>No. Method</cell><cell cols="2">L OA Sup ? H</cell><cell cols="3">(b) ?j H (t) L OA pSup MPJPE?</cell></row><row><cell>1. B1(JU; H?3DPW)</cell><cell></cell><cell>?</cell><cell>-</cell><cell>-</cell><cell>191.2</cell></row><row><cell>2. B1(JU; H?3DPW)</cell><cell></cell><cell>?</cell><cell>?</cell><cell>-</cell><cell>130.7</cell></row><row><cell>3. Ours(JU; H?3DPW)</cell><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>98.0</cell></row><row><cell>4. LCR-Net++ [74]</cell><cell cols="4">H3.6M(3D), MPII(2D)</cell><cell>104.9</cell></row><row><cell cols="5">Pose-level adaptation on Human3.6M</cell></row><row><cell>No. Method</cell><cell>L</cell><cell cols="4">(s) Sup ? U (b) U t L (t) pSup MPJPE?</cell></row><row><cell cols="6">5. B2(S?H)*+DANN [20] only L (s) Sup Standard DA 116.8</cell></row><row><cell>6. B2(S?H)*</cell><cell></cell><cell>?</cell><cell>-</cell><cell>-</cell><cell>122.4</cell></row><row><cell>7. B2(S?H)*</cell><cell></cell><cell>?</cell><cell>?</cell><cell>-</cell><cell>113.4</cell></row><row><cell>8. Ours(S?H)*</cell><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>106.3</cell></row><row><cell>9. Ours(S?H)</cell><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>103.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Notation Table HeatmapPDF for j th joint ? R H ? ?W ? q (j) 2D pose coordinates for the j th joint ? R 2 w (j) Joint confidences for the j th joint ? [0, 1]</figDesc><table><row><cell></cell><cell cols="2">Symbol Description</cell></row><row><cell></cell><cell>J</cell><cell>Total no. of joints (17) indexed by j</cell></row><row><cell>Miscellaneous</cell><cell cols="2">E B L Localization branch (outputs heatmaps) Encoder as the common backbone CNN B R Regression branch (outputs 3D pose) T FK Forward-kinematics operation</cell></row><row><cell></cell><cell>T c</cell><cell>Weak-perspective projection operation</cell></row><row><cell>o/p of BL</cell><cell>h (j)</cell></row></table><note>O/p of BR?p</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>:</head><label></label><figDesc>Input: Labeled source dataset D s , unlabeled target dataset D t , and the background dataset D b . Let ? denote the learnable parameters of the MRP-Net architecture (excluding the fusion network). : while iter &lt; MaxIter do A. Pseudo-label update (after each K interval ).3:  if iter (mod K interval ) = 0 then</figDesc><table><row><cell>4:</cell></row></table><note>12</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>:</head><label></label><figDesc>: end while Algorithm 3 Training algorithm for joint-level adaptation. Input: Labeled source dataset D O s , unlabeled target dataset D O t , and the background dataset D b . Let ? denote the learnable parameters of the MRP-Net architecture (excluding the fusion network). : while iter &lt; MaxIter do A. Pseudo-label update (after each K interval ). 3: if iter (mod K interval ) = 0 then</figDesc><table><row><cell>4:</cell></row></table><note>12</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Adaptation training (for joint-level adaptation). Update ? to minimize H</figDesc><table><row><cell cols="3">6: Update ? by minimizing 1 (I,j)?J s inV L (j) h (h, h gt ) and</cell></row><row><cell cols="3">1 (I,j)?J s inV L (j) p (p, p gt ) (i.e. the first 2 terms under L OA Sup )</cell></row><row><cell cols="3">on a mini-batch of D O s using separate Adam optimizers.</cell></row><row><cell cols="3">7: Update ? to maximize H J s (s) outV</cell><cell>= 1 (I,j)?J s outV H(I, j) on</cell></row><row><cell cols="3">a mini-batch of D O s using Adam optimizer.</cell></row><row><cell cols="2">8: Update ? to maximize H</cell><cell>(b) ?j on a mini-batch of D b us-</cell></row><row><cell cols="2">ing Adam optimizer.</cell></row><row><cell></cell><cell cols="2">(t) J t inV</cell><cell>= 1 (I,j)?J t inV H(I, j) on a</cell></row><row><cell cols="3">mini-batch of D O t using Adam optimizer.</cell></row><row><cell cols="3">10: Update ? to maximize H J t (t) outV</cell><cell>= 1 (I,j)?J t outV H(I, j) on</cell></row><row><cell cols="3">a mini-batch of D O t using Adam optimizer.</cell></row><row><cell cols="3">11: Update ? to maximize j?J t inVw</cell><cell>(j) L (j) (h, h pl gt ) and</cell></row><row><cell>j?J t inVw</cell><cell cols="2">(j) L (j) (p, p pl gt ) (i.e. the two terms under</cell></row><row><cell cols="3">L OA pSup ) using separate Adam optimizers. Here,w (j) is</cell></row><row><cell cols="3">normalized such that j?J t inVw</cell><cell>(j) = 1.</cell></row></table><note>9:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 .</head><label>7</label><figDesc>Relative contribution of fusion network inputs on 3DPW, MPJPE (?).</figDesc><table><row><cell cols="2">Methodspqq +w Fused</cell></row><row><cell>Ours(H?3PDW)</cell><cell>100 122 115 91</cell></row><row><cell cols="2">Ours(JU:H?3DPW) 116 142 135 98</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 .</head><label>8</label><figDesc>Evaluation of #5-7 fromTable 4with fusion network.</figDesc><table><row><cell>No. Method</cell><cell>L</cell><cell cols="3">(s) Sup ? U (b) U t L (t) pSup</cell><cell>w/o fuse w/ fuse</cell></row><row><cell cols="6">5. B2(S?H)+DANN only L (s) Sup Standard DA 116.8 114.5 (2.3 ?)</cell></row><row><cell>6. B2(S?H)</cell><cell></cell><cell>?</cell><cell>-</cell><cell>-</cell><cell>122.4 122.1 (0.3 ?)</cell></row><row><cell>7. B2(S?H)</cell><cell></cell><cell>?</cell><cell>?</cell><cell>-</cell><cell>113.4 110.7 (2.7 ?)</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This work is supported by Uchhatar Avishkar Yojana (UAY, IISC 010), MoE, Govt. of India.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recovering 3D human pose from monocular images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="44" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">2D human pose estimation: New benchmark and state of the art analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">3D pictorial structures for multiple human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ilic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Structured output-associative regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Keep it SMPL: Automatic estimation of 3D human pose and shape from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning sign language by watching tv (using weakly aligned subtitles)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Buehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">3D pictorial structures for multiple view articulated pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Burenius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Optimal defocus estimation in individual natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Burge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Geisler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">40</biblScope>
			<biblScope unit="page" from="16849" to="16854" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cross-domain adaptation for animal pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinkun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Hao-Shu Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised 3D pose estimation with geometric self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Hang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambrish</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Drover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Rohith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Stojanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Weakly-supervised discovery of geometryaware representation for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwan-Yee</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Towards part-aware monocular 3D human pose estimation: An architecture search approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zerui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiru</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">3D human pose estimation using spatio-temporal networks with explicit occlusion training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Occlusion-aware networks for 3D human pose estimation in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wending</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning 3D human pose from structure and motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Dabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Mundhada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uday</forename><surname>Kusupati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Safeer</forename><surname>Afaque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep fully-connected part-based models for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>De Bem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Golodetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Sapienza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACML</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sim2real transfer learning for 3D human pose estimation: motion to the rescue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dropout as a bayesian approximation: Representing model uncertainty in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Domain-adversarial training of neural networks. The journal of machine learning research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Statistics for optimal point prediction in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey S</forename><surname>Geisler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Perry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="14" to="14" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Generalized procrustes analysis. Psychometrika</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gower</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="33" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Holopose: Holistic 3D human reconstruction in-the-wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alp</forename><surname>Riza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Guler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Shape recognition and pose estimation for mobile augmented reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Hagbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriel</forename><surname>Bergig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihad</forename><surname>El-Sana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Billinghurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A baseline for detecting misclassified and out-of-distribution examples in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exploiting temporal information for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imtiaz</forename><surname>Mir Rayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Human3.6m: Large scale datasets and predictive methods for 3D human sensing in natural environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Weaklysupervised 3D human pose learning via multi-view images in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umar</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavlo</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">End-to-end recovery of human shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Self-supervised learning of 3D human pose using multiview geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salih</forename><surname>Karagoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emre</forename><surname>Akbas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to reconstruct 3D human pose and shape via model-fitting in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep non-rigid structure from motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Lucey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Accurate uncertainties for deep learning using calibrated regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Kuleshov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Fenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Cross-conditioned recurrent networks for long-term synthesis of inter-person human motion interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Buckchash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priyanka</forename><surname>Mandikal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Jamkhandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R Venkatesh</forename><surname>Babu</surname></persName>
		</author>
		<idno>WACV, 2020. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Um-adapt: Unsupervised multitask adaptation using adversarial cross-task distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishank</forename><surname>Lakkakula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R Venkatesh</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Object pose estimation from monocular image using multi-view keypoint correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ganeshan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV Workshops</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Unsupervised cross-dataset adaptation via probabilistic amodal 3D human pose completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><surname>Patravali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R Venkatesh</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Appearance consensus driven self-supervised human mesh recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mugalodi</forename><surname>Rakesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unsupervised cross-modal alignment for multi-person 3D pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambareesh</forename><surname>Revanur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Govind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Waghmare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R Venkatesh</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Non-local latent relation distillation for self-adaptive 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Jamkhandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Pradyumna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R Venkatesh</forename><surname>Babu</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Self-supervised 3D human pose estimation via part guided novel image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mugalodi</forename><surname>Rakesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Venkatesh Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Kinematic-structure-preserved representation for unsupervised 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakesh</forename><surname>Mugalodi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Venkatesh Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Simple and scalable predictive uncertainty estimation using deep ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshops</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A simple unified framework for detecting out-of-distribution samples and adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Cascaded deep monocular 3D human pose estimation with evolutionary training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shichao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Pratama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Keung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwang-Ting</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">On boosting singleframe 3D human pose estimation via monocular videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Enhancing the reliability of out-of-distribution image detection in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayadurgam</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A simple yet effective baseline for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julieta</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayat</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Monocular 3D human pose estimation in the wild using improved cnn supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Single-shot multi-person 3D pose estimation from monocular rgb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">VNect: Real-time 3D human pose estimation with a single rgb camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Shafiei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Multiview-consistent semi-supervised learning for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Gundavarapu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">I2L-MeshNet: Image-to-lixel prediction network for accurate 3D human pose and mesh estimation from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kyoung Mu Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">3D human pose estimation from a single image via distance matrix regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesc</forename><surname>Moreno-Noguer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning from synthetic animals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiteng</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weichao</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Monocular 3D human pose estimation by predicting depth on joints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">X</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">C3DPO: Canonical 3D pose networks for non-rigid structure from motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Novotny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhila</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Neverova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Expressive body capture: 3D hands, face, and body from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Choutas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">A A</forename><surname>Osman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Ordinal depth supervision for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Coarse-to-fine volumetric prediction for single-image 3D human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Quaternet: A quaternion-based recurrent model for human motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Pavllo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Monocular image 3D human pose estimation under selfocclusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ibrahim</forename><surname>Radwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Dhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Goecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Aligning silhouette topology for self-adaptive 3D human pose recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mugalodi</forename><surname>Rakesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R Venkatesh</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Unsupervised geometry-aware representation for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Learning monocular 3D human pose estimation from multi-view images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rg</forename><surname>Sp?rri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isinsu</forename><surname>Katircioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Densepose: Dense human pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Iasonas Kokkinos Riza Alp Guler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neverova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">LCR-Net: Localization-classification-regression for human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Rogez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">LCR-Net++: Multi-person 2D and 3D pose detection in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Rogez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Learning body pose via specialized maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mer</forename><surname>Rosales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Asymmetric tri-training for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniaki</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Bilevel online adaptation for out-ofdomain human mesh reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guan</forename><surname>Shanyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jingwei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Yunbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Bingbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Xiaokang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2021</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Humaneva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Alexandru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Balan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Integral human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">PoseNet3D: Learning temporally consistent 3D human pose via knowledge distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhant</forename><surname>Ranade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambrish</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Agrawal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3DV, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Total capture: 3D human pose estimation fusing video and inertial sensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Trumble</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Malleson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Collomosse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Adversarial inverse graphics networks: Learning 2D-to-3D lifting and image-to-image translation from unpaired supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Yu Fish</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">W</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Seto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katerina</forename><surname>Fragkiadaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Deep domain confusion: Maximizing for domain invariance. ArXiv, abs/1412</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3474</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Learning from synthetic humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gul</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Recovering accurate 3D human pose in the wild using imus and a moving camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Timo Von Marcard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pons-Moll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Repnet: Weakly supervised training of an adversarial reprojection network for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Incremental adversarial domain adaptation for continually changing environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Wulfmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingmar</forename><surname>Posner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Deep kinematics analysis for monocular 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenbo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiancheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">3D human pose estimation in the wild by adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lsun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03365</idno>
		<title level="m">Construction of a large-scale image dataset using deep learning with humans in the loop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Image geolocalization based on multiple nearest neighbor feature matching using generalized graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Amir Roshan Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1546" to="1558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Monocular 3D pose and shape estimation of multiple people in natural scenes-the importance of multiple scene constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabeta</forename><surname>Marinoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Deep network for the integrated 3D sensing of multiple people in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabeta</forename><surname>Marinoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alin-Ionut</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Inference stage optimization for cross-scenario 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuecheng</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2020</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongkang</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><forename type="middle">S</forename><surname>Kankanhalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACMMM</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Learning causal representation for training cross-domain pose estimator via generative interventions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongkang</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juwei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><surname>Kankanhalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangdong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Semantic graph convolutional networks for 3D human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubbasir</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Towards 3D human pose estimation in the wild: A weakly-supervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Deep kinematic pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Sparseness meets deepness: 3D human pose estimation from monocular video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Leonardos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
