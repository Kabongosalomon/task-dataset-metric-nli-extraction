<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Sapienza University of Rome</orgName>
								<address>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Fondazione Bruno Kessler</orgName>
								<address>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Mapillary Research</orgName>
								<address>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Italian Institute of Technology</orgName>
								<address>
									<settlement>Genova</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Disclaimer: This work has been accepted for publication in the IEEE International Conference on Image Processing: link: https://2018.ieeeicip.org/ Copyright:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>From self-driving cars to assistive technologies for the cognitive and physically impaired, today we witness a pressing demand for visual recognition systems able to cope with the challenges of unconstrained settings. A crucial component for such systems is their ability to generalize across visual domains, i.e. to be able to achieve strong performances regardless of the underlying statistic of the data used for training (source domains), compared to the statistic of all the possible future test data (target domains). While the computer vision community has been aware for quite some time of the <ref type="figure">Fig. 1</ref>. Intuition behind the the proposed framework. Different domain-specific classifiers and the classifiers fusion are learned at training time on source domains, in a single end-toend trainable architecture. When a target image is processed, our deep model optimally combines the source models in order to compute the final prediction. existence of a dataset bias issue when considering different data collections <ref type="bibr" target="#b7">[8]</ref>, most efforts have been focused on reducing the domain shift among two distributions, corresponding to a specific source and a specific target domain. Such research efforts go under the name of Domain Adaptation, for which there is a large literature of shallow and deep approaches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>A less researched direction is Domain Generalization (DG), that consists in bridging the domain gap regardless of the target data distribution. This concretely corresponds to scenarios where it is costly to acquire in advance target data or it is impossible to predict a priori the specific target scenario where the system will operate. Besides practical considerations, DG attempts to address the issue of dataset bias in a more principled manner: a visual recognizer ready to work in the wild should guarantee robust performances in any target domain.</p><p>This paper contributes to this last research thread and we propose a novel deep network for addressing the problem of DG. Different from previous works for DG based on learning domain-invariant representations with deep architectures <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b4">5]</ref>, our intuition is that, given several source domains and their associated domain-specific classifiers, generality can be achieved at test time classifying each incoming target image by optimally fusing the prediction scores of the source-specific classifiers. This is achieved through an endto-end trainable deep architecture with two main components <ref type="figure">(Fig.1</ref>). The first implements the source-specific classifiers, while the second module is a network branch which computes the similarities of an input sample to all source domains, such as to assign weights to the source classifiers and properly merge their predictions. The second module is also designed in order to easily permit, if needed, the integration of a domain agnostic classifier which, acting in synergy with the domain-specific models, can further improve generalization. We assess our method on two public available datasets, obtaining state of the art performances.</p><p>Related Work. Although less researched than domain adaptation, the need for DG algorithms has been recognized for quite some time in the literature <ref type="bibr" target="#b15">[16]</ref>. The works presented so far can be roughly divided in two categories. The first category is based on the intuition that DG can be achieved by abstracting from the available sources some knowledge about the classes to be recognized that is domain independent. This idea is exploited by previous methods searching for a domain invariant feature space where to project the data <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b15">16]</ref> or by approaches attempting to generate domain agnostic classifiers using both shallow <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b5">6]</ref> or deep learning models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>The second category exploits the idea that it is possible to measure the similarity among the available source domains and every sample of the target domain. By exploiting this information robust classification models for the target domain are built constructing different source-specific classifiers and optimally combining them <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b12">13]</ref>. Our work falls into this second category. However, opposite to previous studies, we cast the idea into a deep learning framework, proposing to our knowledge one of the first end-to-end trainable deep architecture for DG maintaining source-specific representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">DOMAIN GENERALIZATION WITH</head><p>SOURCE-SPECIFIC CLASSIFIERS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Problem Definition and Notation</head><p>The goal of DG is to extend the knowledge acquired from a set of source domains to any unknown target domain. Specifically, let us consider a classification task where C is the number of categories. Our purpose is to learn a classification function f for the unknown target domain, having only access to source samples at training time. Formally, we denote with X T the target domain and with</p><formula xml:id="formula_0">X S = {X 1 S , . . . , X N S } = {(x i , y i , d i )} M i=1 the set of N source domains.</formula><p>Here, x i is an image, y i ? C a binary vector with a single non-zero entry indicating the semantic category associated to x i , d i ? {1, . . . , N } the label denoting the domain to which the sample belongs, M the total number of source samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source Specific Classifiers</head><p>x</p><formula xml:id="formula_1">? c f 1 (x,? 1 ) y f 2 (x,? 2 ) f N (x,? N )</formula><p>... The input image is fed to a series of domain specific classifiers and to the domain prediction branch. The latter produces the assignment w which is fed to the domain prediction loss. The same w is modulated by ? before being used to combine the output of each classifier. The final output of the architecture z, is fed to the classification loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Combining Source-specific Classifiers for DG</head><p>As discussed in the introduction, our aim is to address the DG problem classifying each sample of the target domain through an appropriate combination of domain specific models derived from source domains. Formally, we consider a classification function f (x i , ?) mapping an input image x i to a vector z i ? C of class predictions, i.e. :</p><formula xml:id="formula_2">z i = f (x i , ?) = N j=1 w i,j f j (x i , ? j )<label>(1)</label></formula><p>where f j indicates the classifier associated to the j-th domain, ? = {? j } N j=1 denotes the set of parameters to learn and each ? j the parameters corresponding to a specific domain j.</p><p>While several choices of f are possible, we choose to implement it with a convolutional neural network with many parallel branches, each corresponding to a domain-specific classifier f j . To avoid high computational cost, we consider the same architecture for each f j , sharing all the parameters except those of the last layer before the classifier. In formulas ? j = {? s ,? j }, where? s indicates the shared parameters and ? j the domain-specific ones.</p><p>The computation of the weights w i,j used to combine the domain-specific classifiers is at the core of our method and is discussed in the following.</p><p>In case of source samples, since each image is associated to a specific domain there is an obvious choice for setting the weights w i,j . Specifically, we can define w i,j = 1 di=j , where 1 di is an indicator function with value 1 if d i = j and 0 otherwise. This corresponds to learning N domain-specific classifiers independently. In fact, due to the presence of the indicator function, training the network using a standard classification loss L c (z i , y i ), e.g. a cross-entropy loss, we have ?Lc ?fj (xi,?j ) = 0 for j = d i . As a consequence, the parameter? ? j of the classifier relative to domain j are updated using only the losses computed on samples belonging to the set X J S .</p><p>Unfortunately, learning domain-specific classifiers as discussed above is not useful in a DG scenario. In fact, while at training time we can rely on the domain label d i to build the indicator functions, this is not possible at test time since we do not have this information for target samples. To solve this issue and learn the weights w i,j , we propose to incorporate into our deep architecture a parallel network branch, i.e. a domain prediction branch, mapping a given input image x i to the associated weight vector w i = [w i,1 , ? ? ? , w i,N ] T ? N . In other words we define w i = f dom (x i , ? dom ), where f dom is the mapping function corresponding to the domain prediction branch. For each input image x i , we impose 0 ? w i,j ? 1 and N j=1 w i,j = 1 for all 1 ? i ? N . Thus, each weight w i,j represents the probability that x i belongs to domain j.</p><p>Since at training time we have access to the domain labels d i of source samples x i , we can learn the parameters ? dom by minimizing a loss function L dom (w i ,d i ) between w i andd i , whered i ? N is a binary vector with a single non-zero entry corresponding to the domain label d i . In our implementation, since f dom shares parameters with the classification branches f j , we train the proposed architecture minimizing the following loss function:</p><formula xml:id="formula_3">L = 1 M M i=1 (L c (z i , y i ) + ? L dom (w i , d i ))<label>(2)</label></formula><p>where both the semantic classification loss L c and the domain prediction loss L dom are implemented with cross-entropy loss. The hyperparameter ? balances the contribution of the semantic classification and the domain prediction terms. One possible issue with the proposed deep architecture is that, as minimizing the domain loss promotes the learning of independent source classifiers, source sets with few samples may correspond to classifiers with poor performances. While parameter sharing among the deep models implementing f j naturally limits this effect, we further improve the robustness of our model adding a domain-agnostic component into the final classification function. In practice, we introduce a parameter 0 &lt; ? &lt; 1 and at training time we randomly switch with probability ? between using the computed weights w i,j or assigning to all of them the same value 1/N . This choice corresponds to modifying the classification model in Eqn.(1) as follows:</p><formula xml:id="formula_4">z i = (1 ? ?) N j=1 w i,j f j (x i , ? j ) + ? N N j=1 f j (x i , ? j ) (3)</formula><p>As shown in the formula the parameter ? is used to regulate the trade-off between the domain specific and the domain agnostic component. <ref type="figure" target="#fig_0">Figure 2</ref> provides an overview of the proposed end-to-end trainable deep architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTS</head><p>Datasets. We test the performance of our method on two publicly available benchmarks. The rotated-MNIST [5] is a dataset composed by different domains originated applying different degrees of rotations to images of the original MNIST digits dataset <ref type="bibr" target="#b8">[9]</ref>. We follow the experimental protocol of <ref type="bibr" target="#b14">[15]</ref>, randomly extracting 1000 images per class from the dataset and rotating them respectively of 0, 15, 30, 45, 60 and 75 degrees counterclockwise. As previous works, we consider one domain as target and the rest as sources. The PACS database <ref type="bibr" target="#b9">[10]</ref> is a recently proposed benchmark which is interesting due to the high domain shift within its domains. It contains images taken from different representations (i.e. Photo, Art paintings, Cartoon and Sketches) associated to seven semantic categories. Following the experimental protocol of <ref type="bibr" target="#b9">[10]</ref>, we train our model considering three domains as source datasets and the remaining one as target.</p><p>Networks and training protocols. In our evaluation we set the parameters ? = 0.25 and ? = 0.5. For the experiments on the rotated-MNIST dataset, we employ the LeNet architecture <ref type="bibr" target="#b8">[9]</ref> following <ref type="bibr" target="#b14">[15]</ref>. The network is trained from scratch, using a batch size of 250 with an equal number of samples for each source domain. We train the network for 10000 iterations, using Stochastic Gradient Descent (SGD) with an initial learning rate of 0.01, momentum 0.9 and weight decay 0.0005. The learning rate is decayed through an inverse schedule, following previous works <ref type="bibr" target="#b3">[4]</ref>. For the domain prediction branch, we take as input the image and perform two convolutions, with the same parameters of the first two convolutional layers of the main network. Each convolution is followed by a ReLU non linearity and a pooling operation. The domain prediction branch terminates with a global average pooling followed by a fully connected layer which outputs the final weights. To ensure that N j=1 w i,j = 1, we apply the softmax operator after the fully connected layer.</p><p>For PACS, we trained the standard AlexNet architecture, starting from the ImageNet pretrained model. We use a batch size of 192, with 64 samples for each source domain. The initial learning rate is set to 5 ? 10 ?4 with a weight decay of 10 ?6 and a momentum of 0.9. We train the network for 3000 iterations, decaying the initial learning rate by a factor of 10 after 2500 iterations, using SGD. For the domain prediction branch, we use the features of pool5 as input, performing a global average pooling followed by a fully-connected layer and a softmax operator which outputs the domain weights.</p><p>Our evaluation is performed using a NVIDIA GeForce 1070 GTX GPU, implementing all the models with the popular Caffe <ref type="bibr" target="#b6">[7]</ref> framework. For the baseline AlexNet architecture we take the pretrained model available in Caffe.</p><p>Results. We first test the effectiveness of our model on the rotated-MNIST benchmark. We compare our approach with the method in <ref type="bibr" target="#b14">[15]</ref> and the multi-task autoencoders in <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b16">[17]</ref>. The results from baseline methods are taken directly from <ref type="bibr" target="#b14">[15]</ref>. As shown in <ref type="table" target="#tab_0">Table 1</ref>, our model outperforms all the baselines. A remarkable gain in accuracy is achieved in the 45 o case. We ascribe this gain to the capability of our  deep network to assign, for each target image, more importance to the source domains corresponding to the closest orientations, increasing the weights of the associated classifiers. Indeed, since 45 o is in the middle of the range between all possible orientations, it is likely that a stronger classifier can be constructed since we can exploit all the source models appropriately re-weighted. To further verify the effectiveness of our framework and its ability to properly combine sourcespecific models, we also compute for target samples with different orientations the number of assignments to each source domain. In this experiment one target sample x i is assigned to a source domain by computing the arg max j w i,j . The results are shown in <ref type="figure" target="#fig_1">Fig. 3</ref> (the number of assignments are normalized for each row). The figure clearly shows that the proposed domain prediction branch tends to associate a target sample to the source domains corresponding to the closest orientations. Consequently, our deep network classifies target samples constructing a model from the most related source classifiers. This results into more accurate predictions than previous domain-agnostic models due to the specialization of source classifiers on specific orientations. We also perform experiments on the PACS dataset. We compare our model with both previous approaches using precomputed features (in this case DECAF-6 features <ref type="bibr" target="#b2">[3]</ref>) as input <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b15">16]</ref> and end-to-end trainable deep models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. For a fair comparison the deep models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> and our network are all based on the same architecture, i.e. AlexNet. <ref type="table" target="#tab_1">Table 2</ref> shows the results of our comparison. The performance of previous methods are taken directly from previous papers <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. For our approach and <ref type="bibr" target="#b9">[10]</ref> we also report results obtained without finetuning. Our model outperforms all previous methods. These results are remarkable because, differently from the rotated-MNIST dataset, in PACS the domain shift is significant and it is not originated by simple image per-  turbations. Therefore, the association between a target sample and the given source domains is more subtle to capture. For sake of completeness we also report the performances obtained with the standard AlexNet network. These results shows that state of the art deep models have excellent generalization abilities, typically outperforming shallow models. However, designing deep networks specifically addressing the DG problem as we do leads to higher accuracy. We also perform a sensitivity analysis to study the impact of the parameter ? on the performance and demonstrate the benefit of adding a domain-agnostic classifier. We consider the proposed approach without finetuning. As shown in Table 3, considering only the source-specific classifiers (? = 0) leads, on average, to the best performances, surpassing in the majority of the cases a domain agnostic classifier obtained by setting ? = 1. This confirms our original intuition that addressing DG by fusing multiple source models is an effective strategy. However, there are few situations where using only source models can lead to a decrease in accuracy (e.g. in the setting Cartoon) and incorporating a domain-agnostic component, even with reduced weight as ? = 0.25, improves generalization accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSIONS</head><p>We presented a novel deep architecture for addressing the problem of DG by exploiting multiple domain-specific classifiers. In the network a domain prediction branch chooses the optimal combination of source classifiers to use at test time, based on the similarity between the input image and the samples from the source domains. A domain agnostic component is also introduced in our framework further improving the performance of our method. Our experiments demonstrate the effectiveness of the proposed deep architecture which outperforms state of the art models in two benchmarks. Future works will include the exploration of different architectural choices for the domain prediction branch.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Simplified architecture of the proposed framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Rotated-MNIST dataset: analysis of the assignments computed by the domain prediction branch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Rotated-MNIST dataset: comparison with previous methods.</figDesc><table><row><cell>Method</cell><cell>0</cell><cell>15</cell><cell>30</cell><cell>45</cell><cell>60</cell><cell>75</cell><cell>Mean</cell></row><row><cell>[17]</cell><cell cols="7">72.1 95.3 92.6 81.5 92.7 79.3 85.5</cell></row><row><cell>[5]</cell><cell cols="7">82.5 96.3 93.4 78.6 94.2 80.5 87.5</cell></row><row><cell>[15]</cell><cell cols="7">84.6 95.6 94.6 82.9 94.8 82.1 89.1</cell></row><row><cell>Ours</cell><cell cols="7">85.6 95.0 95.6 95.5 95.9 84.3 92.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>PACS dataset: comparison with previous methods.</figDesc><table><row><cell>Model</cell><cell cols="5">Art Cartoon Photo Sketch Mean</cell></row><row><cell>[5]</cell><cell>60.3</cell><cell>58.7</cell><cell>91.1</cell><cell>47.9</cell><cell>64.5</cell></row><row><cell>[20]</cell><cell>59.7</cell><cell>52.9</cell><cell>85.5</cell><cell>37.9</cell><cell>58.9</cell></row><row><cell>[16]</cell><cell>64.6</cell><cell>64.5</cell><cell>91.8</cell><cell>51.1</cell><cell>68.0</cell></row><row><cell>[10] (no ft)</cell><cell>62.7</cell><cell>52.7</cell><cell>88.8</cell><cell>52.2</cell><cell>64.1</cell></row><row><cell>[10]</cell><cell>62.9</cell><cell>67.0</cell><cell>89.5</cell><cell>57.5</cell><cell>69.2</cell></row><row><cell>[11]</cell><cell>66.2</cell><cell>66.9</cell><cell>88.0</cell><cell>59.0</cell><cell>70.0</cell></row><row><cell>Ours (no ft)</cell><cell>64.1</cell><cell>60.6</cell><cell>90.4</cell><cell>49.4</cell><cell>66.1</cell></row><row><cell>Ours</cell><cell>64.1</cell><cell>66.8</cell><cell>90.2</cell><cell>60.1</cell><cell>70.3</cell></row><row><cell cols="2">AlexNet [10] 63.3</cell><cell>63.1</cell><cell>87.7</cell><cell>54.1</cell><cell>67.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>PACS dataset: sensitivity analysis.</figDesc><table><row><cell>?</cell><cell cols="4">Art Cartoon Photo Sketch</cell></row><row><cell>0</cell><cell>65.2</cell><cell>54.5</cell><cell>90.7</cell><cell>52.4</cell></row><row><cell cols="2">0.25 64.1</cell><cell>60.6</cell><cell>90.4</cell><cell>49.4</cell></row><row><cell>0.5</cell><cell>63.8</cell><cell>61.0</cell><cell>90.4</cell><cell>49.1</cell></row><row><cell cols="2">0.75 64.0</cell><cell>60.9</cell><cell>90.5</cell><cell>47.8</cell></row><row><cell>1</cell><cell>63.0</cell><cell>60.1</cell><cell>90.5</cell><cell>47.5</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Autodial: Automatic domain alignment layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bul?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Domain adaptation in computer vision applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-domain transfer component analysis for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Birlutiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sch?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Natschl?ger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Heskes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Processing Letters</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM-Multimedia</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Undoing the damage of dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Domain generalization and adaptation using low rank exemplar svms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust place categorization with deep domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2093" to="2100" />
			<date type="published" when="2018-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Boosting domain adaptation by discovering latent domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Auto-Encoders. Explicit invariance during feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Lampert. Beyond dataset bias: Multi-task unaligned shared knowledge transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Quadrianto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep cocktail network: Multi-source unsupervised domain adaptation with category shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploiting low-rank structure from latent domains for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
