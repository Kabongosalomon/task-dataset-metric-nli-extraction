<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reducing Information Bottleneck for Weakly Supervised Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jooyoung</forename><surname>Choi</surname></persName>
							<email>jy_choi@snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jisoo</forename><surname>Mok</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
							<email>sryoon@snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">ASRI</orgName>
								<orgName type="institution" key="instit1">INMC</orgName>
								<orgName type="institution" key="instit2">ISRC, and Institute of Engineering Research</orgName>
								<orgName type="institution" key="instit3">Seoul National University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Reducing Information Bottleneck for Weakly Supervised Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Weakly supervised semantic segmentation produces pixel-level localization from class labels; however, a classifier trained on such labels is likely to focus on a small discriminative region of the target object. We interpret this phenomenon using the information bottleneck principle: the final layer of a deep neural network, activated by the sigmoid or softmax activation functions, causes an information bottleneck, and as a result, only a subset of the task-relevant information is passed on to the output. We first support this argument through a simulated toy experiment and then propose a method to reduce the information bottleneck by removing the last activation function. In addition, we introduce a new pooling method that further encourages the transmission of information from non-discriminative regions to the classification. Our experimental evaluations demonstrate that this simple modification significantly improves the quality of localization maps on both the PASCAL VOC 2012 and MS COCO 2014 datasets, exhibiting a new state-ofthe-art performance for weakly supervised semantic segmentation. The code is available at: https://github.com/jbeomlee93/RIB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic segmentation is the task of recognizing objects in an image using pixel-level allocation of a semantic label. The development of deep neural networks (DNNs) has led to significant advances in semantic segmentation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b23">24]</ref>. Training a DNN for semantic segmentation requires a dataset containing a large number of images annotated with pixel-level labels. However, preparing such a dataset requires considerable effort; for example, producing a pixel-level annotation for a single image in the Cityscapes dataset [12] takes more than 90 minutes. This high dependence on pixel-level labels can be alleviated by weakly supervised learning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b62">63]</ref>.</p><p>The objective of weakly supervised semantic segmentation is to train a segmentation network with weak annotations, which provide less information about the location of a target object than pixellevel labels, but are cheaper to obtain. Weak supervision takes the form of scribbles [53], bounding boxes <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b50">51]</ref>, or image-level class labels <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b30">31]</ref>. In this study, we focus on image-level class labels, because they are the cheapest and most popular option of weak supervision. Most methods that use class labels <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b55">56]</ref> generate pseudo ground truths for training a segmentation network using localization (attribution) maps obtained from a trained classifier, such as a CAM <ref type="bibr" target="#b66">[67]</ref> or a Grad-CAM <ref type="bibr" target="#b47">[48]</ref>. However, these maps identify only small regions of a target object that are discriminative for the classification [2, 5, 31] and do not identify the entire region occupied by the object, making the attribution maps unsuitable for training a semantic segmentation network. We interpret this phenomenon using the information bottleneck principle <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55]</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The information bottleneck theory analyzes the information flow through sequential DNN layers: information regarding the input is compressed as much as possible as it passes through the layers of a DNN, while preserving as much of the task-relevant information as possible. This is advantageous for obtaining optimal representations for classification <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15]</ref> but is disadvantageous when applying the attribution maps from the resulting classifier to weakly supervised semantic segmentation. The information bottleneck prevents the non-discriminative information of the target object from being considered in the classification logit, and thus, the attribution maps focus on only the small discriminative regions of the target object.</p><p>We argue that the information bottleneck becomes prominent in the final layer of the DNN due to the use of the double-sided saturating activation function therein (e.g., sigmoid, softmax). We propose a method to reduce this information bottleneck in the final layer of the DNN by retraining the DNN without the last activation function. Additionally, we introduce a new pooling method that allows more information embedded in non-discriminative features, rather than discriminative features, to be processed in the last layer of a DNN. As a result, the attribution maps of the classifier obtained by our method contain more information on the target object.</p><p>The main contributions of this study are summarized as follows. First, we highlight that the information bottleneck occurs mostly in the final layer of the DNN, which causes the attribution maps obtained from a trained classifier to restrict their focus to small discriminative regions of the target object. Second, we propose a method to reduce this information bottleneck by simply modifying the existing training scheme. Third, our method significantly improves the quality of the localization maps obtained from a trained classifier, exhibiting a new state-of-the-art performance on the PASCAL VOC 2012 and MS COCO 2014 datasets for weakly supervised semantic segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Information Bottleneck</head><p>Given two random variables X and Y , the mutual information I(X; Y ) quantifies the mutual dependence between the two variables. Data processing inequality (DPI) <ref type="bibr" target="#b12">[13]</ref> infers that any three variables X, Y , and Z that form a Markov Chain X ? Y ? Z satisfy I(X; Y ) ? I(X; Z). Each layer in a DNN processes the input only from the previous layer, which means that the DNN layers form a Markov chain. Therefore, the information flow through these layers can be represented using DPI. More specifically, when an L?layered DNN generates an output? from a given input X through intermediate features T l (1 ? l ? L), it forms a Markov Chain X ? T 1 ? ? ? ? ? T L ?? , and the corresponding DPI chain can be expressed as follows: I(X; T 1 ) ? I(X; T 2 ) ? ? ? ? ? I(X; T L?1 ) ? I(X; T L ) ? I(X;? ).</p><p>(</p><p>This implies that the information regarding the input X is compressed as it passes through the layers of the DNN.</p><p>Training a classification network can be interpreted as extracting maximally compressed features of the input that preserve as much information as possible for classification; such features are commonly referred to as minimum sufficient features (i.e., discriminative information). The minimum sufficient features (optimal representations T * ) can be obtained by the information bottleneck trade-off between the mutual information of X and T (compression), and that of T and Y (classification) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b54">55]</ref>. In other words,</p><formula xml:id="formula_1">T * = argmin T I(X; T ) ? ?I(T ; Y ), where ? ? 0 is a Lagrange multiplier.</formula><p>Shwartz-Ziv et al. <ref type="bibr" target="#b49">[50]</ref> observe a compression phase in the process of finding the optimal representation T * : when observing I(X, T l ) for a fixed l, I(X, T l ) steadily increases during the first few epochs, but decreases in the later epochs. Saxe et al. <ref type="bibr" target="#b45">[46]</ref> argue that the compression phase is mainly observed in DNNs equipped with double-sided saturating non-linearities (e.g., tanh and sigmoid), and is not observed in those equipped with single-sided saturating non-linearities (e.g., ReLU). This implies that DNNs with single-sided saturating non-linearities experience less information bottleneck than those with double-sided saturating non-linearities. This can also be understood in terms of gradient saturation in the double-sided saturating non-linearities: the gradient of those non-linearities with respect to an input above a certain value saturates close to zero <ref type="bibr" target="#b7">[8]</ref>. Therefore, features above a certain value will have near-zero gradients during the back-propagation process and be restricted from additionally contributing to the classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Class Activation Mapping</head><p>A class activation map (CAM) <ref type="bibr" target="#b66">[67]</ref> identifies regions of an image focused by a classifier. The CAM is based on a convolutional neural network with global average pooling (GAP) before its final classification layer. This is realized by considering the class-specific contribution of each channel of the last feature map to the classification score. Given a classifier parameterized by ? = {? f , w} where f (?; ? f ) is the feature extractor prior to GAP, and w is the weight of the final classification layer, a CAM of the class c is obtained from an image x as follows:</p><formula xml:id="formula_2">CAM(x; ?) = w c f (x; ? f ) max w c f (x; ? f ) ,<label>(2)</label></formula><p>where max(?) is the maximum value over the spatial locations for normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Related Work</head><p>Weakly Supervised Semantic Segmentation: Weakly supervised semantic segmentation methods with image-level class labels first construct an initial seed by obtaining a high-quality localization map from a trained classifier. Erasure methods <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b56">57</ref>] prevent a classifier from only focusing on the discriminative parts of objects by feeding the image from which the discriminative regions have been erased to the classifier. Several contexts of a target object can be considered by combining multiple attribution maps obtained from differently dilated convolutions <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b57">58]</ref> or from the different layers of a DNN <ref type="bibr" target="#b34">[35]</ref>. Diverse images of a target class can be utilized by considering cross-image semantic similarities and differences <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b51">52]</ref>. Zhang et al. <ref type="bibr" target="#b62">[63]</ref> analyze the causalities among images, contexts, and class labels and propose CONTA to remove the confounding bias in the classification.</p><p>Because the localization maps obtained by a classification network cannot accurately represent the boundary of a target object, the initial seed obtained by the above methods is refined using subsequent boundary refinement techniques such as PSA <ref type="bibr" target="#b2">[3]</ref> and IRN <ref type="bibr" target="#b1">[2]</ref>.</p><p>Information Bottleneck: Tishby et al. <ref type="bibr" target="#b54">[55]</ref> and Shwartz et al. <ref type="bibr" target="#b49">[50]</ref> use the information bottleneck theory to analyze the inner workings of a DNN. The concept of the information bottleneck has been employed in many research fields. Dubois et al. <ref type="bibr" target="#b14">[15]</ref> and Achille et al. <ref type="bibr" target="#b0">[1]</ref> utilize the information bottleneck to obtain optimal representations from DNNs. DICE <ref type="bibr" target="#b44">[45]</ref> is proposed for a model ensemble with the information bottleneck principle: it aims to reduce not only the unnecessary mutual information between features and inputs but also the redundant information shared between features produced by separately trained DNNs. Jeon et al. <ref type="bibr" target="#b25">[26]</ref> study the disentangled representation learning of a generative model <ref type="bibr" target="#b18">[19]</ref> using the information bottleneck principle. Yin et al. <ref type="bibr" target="#b60">[61]</ref> design a regularization objective based on information theory to deal with the memorization problem in meta-learning. The information bottleneck principle can also be adopted to generate the visual saliency map of a classifier. Zhmoginov et al. <ref type="bibr" target="#b65">[66]</ref> find important regions for the classifier with the information bottleneck trade-off, and Schulz et al. <ref type="bibr" target="#b46">[47]</ref> restrict the information flow by adding noise to intermediate feature maps and quantify the amount of information contained in the image region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Method</head><p>Weakly supervised semantic segmentation methods using class labels produce a pixel-level localization map from a classifier using CAM <ref type="bibr" target="#b66">[67]</ref> or Grad-CAM <ref type="bibr" target="#b47">[48]</ref>; however, such a map identifies only small discriminative regions of the target object. We analyze this phenomenon with the information bottleneck theory in Section 3.1 and propose RIB, a method to address this problem, in Section 3.2. We then explain how we train a segmentation network with localization maps improved through RIB in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Motivation</head><p>As mentioned in Section 2.1, the DNN layers with double-sided saturating non-linearities have a larger information bottleneck than those with single-sided saturating non-linearities. The intermediate layers of popular DNN architectures (e.g., ResNet <ref type="bibr" target="#b20">[21]</ref> and DenseNet <ref type="bibr" target="#b22">[23]</ref>) are coupled with the ReLU activation function, which is a single-sided saturating non-linearity. However, the final layer of these networks is activated by a double-sided saturating non-linearity such as sigmoid or softmax, and the class probability p is computed with the final feature map T L and the final classification layer w, i.e., p = sigmoid(w GAP(T L )). Therefore, the final layer parameterized by w has a significant bottleneck, and the amount of information transmitted from the last feature T L to the actual classification prediction will be limited.</p><p>These arguments are analogous to the observations in existing methods. The information plane provided by Saxe et al. <ref type="bibr" target="#b45">[46]</ref> shows that the compression of information is more noticeable in the final layer than in the other layers. Bae et al. <ref type="bibr">[5]</ref> observe that although the final feature map of the classifier contains rich information on the target object, the final classification layer filters out most of it; thus, the CAM cannot identify the entire area of the target object. This observation empirically supports the occurrence of the information bottleneck in the final layer of a DNN.</p><p>To take a closer look at this phenomenon, we design a toy experiment. We collect images containing the digits '2' or '8' from the MNIST dataset <ref type="bibr" target="#b29">[30]</ref>. For only a small subset (10%) of these images, we add a circle ( ) and a square ( ) to the images containing the digits '2' and '8', respectively, at a random location (see <ref type="figure" target="#fig_0">Figure 1</ref>(a)). When classifying images into the digits '2' or '8', pixels corresponding to the digit are discriminative regions (R D ), those corresponding to the added circle or square are non-discriminative but class-relevant regions (R ND ), and those corresponding to the background are class-irrelevant regions (R BG ).</p><p>We train a neural network with five convolutional layers followed by a final fully connected layer. We obtain the gradient map G l of each feature T l with respect to an input image x:</p><formula xml:id="formula_3">G l = ? x u,v T l (u, v)</formula><p>, where u and v are the spatial and channel indices of the feature T l , and for the final classification layer (l = 6), G 6 = ? x y c . Because this gradient map indicates the extent to which each pixel of the image affects each feature, it can be used to examine how much information is passed from the input image to the feature maps of successive convolution layers.</p><p>We present examples of G l in <ref type="figure" target="#fig_0">Figure 1</ref>(b). As an input image passes through the convolution layers, the overall amount of gradient with respect to the input decreases, indicating the occurrence of the information bottleneck. Specifically, the gradient of R BG decreases early on (G 1 ? G 2 ), which implies that the task-irrelevant information is rapidly compressed. From G 1 to G 5 , the gradient in R D or R ND gradually decreases. However, the decrease in the amount of gradient is prominent in the final layer (G 5 ? G 6 ), and in particular, the gradients in R ND (red boxes) almost disappear. This supports our argument that there is significant information bottleneck in the final layer of a DNN, while also highlighting that the non-discriminative information in R ND is particularly compressed.</p><p>We analyze this quantitatively. We define the high gradient ratio (HGR) of region R as the ratio of pixels that have a gradient above 0.3 to the total pixels in region R. HGR quantifies the amount of transmitted information from region R of an input image to each feature. The trend in the HGR values of each region for each layer is shown in <ref type="figure" target="#fig_0">Figure 1</ref>(c). The observed trend is analogous to the above empirical observation, once again supporting that significant information bottleneck for R ND occurs in the final layer (the red box).</p><p>We argue that the information bottleneck causes the localization map obtained from a trained classifier to focus on small regions of the target object. According to Eq. 2, the CAM only includes information that is processed by the final classification weight w c . However, because only a subset of the information in the feature is passed through the final layer w c due to the information bottleneck, leaving out most of the non-discriminative information, CAM cannot identify the non-discriminative regions of the target object. It is undesirable to use such CAMs to train a semantic segmentation network, for which the entire region of the target object should be identified. Therefore, we aim to bridge the gap between classification and localization by reducing the information bottleneck.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Reducing Information Bottleneck</head><p>In Section 3.1, we observed that the information contained in an input image is compressed particularly in the final layer of the DNN, due to the use of the double-sided saturating activation function therein. Therefore, we propose a method to reduce the information bottleneck of the final layer by simply removing the sigmoid or softmax activation function used in the final layer of the DNN. We focus on a multi-class multi-label classifier, which is the default setting for weakly supervised semantic segmentation. Suppose we are given an input image x and the corresponding one-hot class label</p><formula xml:id="formula_4">t = [t 1 , ? ? ? , t C ], where t c ? {0, 1} (1 ? c ? C)</formula><p>is an indicator of a class c, and C is the set of all classes. While existing methods use the sigmoid binary cross-entropy (BCE) loss (L BCE ) to train a multi-label classifier, our method replaces it with another loss function L RIB that does not rely on the final sigmoid activation function:</p><formula xml:id="formula_5">L BCE = ? C c=1 t c log sigmoid(y c ) + (1 ? t c ) log(1 ? sigmoid(y c )), L RIB = ? C c=1 t c min(m, y c ),</formula><p>where m is a margin, and y c is the classification logit of image x.</p><p>However, training a classifier with L RIB from scratch causes instability in the training because the gradient cannot saturate (please see the Appendix). Therefore, we first train an initial classifier with L BCE whose trained weights are denoted by ? 0 , and for a given image x, we adapt the weights toward a bottleneck-free model of x. Specifically, we fine-tune the initial model using L RIB computed from</p><p>x and obtain a model parameterized by ? k (0 &lt; k ? K), where ? k = ? k?1 ? ?? ? k?1 L RIB , and K and ? are respectively the total number of iterations and the learning rate for fine-tuning. We name this fine-tuning process RIB. Employing RIB reduces the information bottleneck for x, and we can obtain CAMs that identify more regions of the target object, including non-discriminative regions. We repeat the RIB process for all the training images to obtain the CAMs.</p><p>However, the model that is adapted to a given image x can be easily over-fitted to x. Therefore, to further stabilize the RIB process, we construct a batch of size B for RIB by sampling random B ? 1 samples other than x at each RIB iteration. Note that for each iteration, B ? 1 samples are randomly selected, while x is fixed. </p><formula xml:id="formula_6">Image , k=0 , k=5 ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effectiveness of RIB:</head><p>We demonstrate the effectiveness of RIB by applying it to the same classifier as that used for the toy experiments described in Section 3.1. <ref type="figure" target="#fig_1">Figure 2</ref> presents (a) examples of G 6 and (b) the HGR values for R D , R ND , and R BG of G 6 , which showed the most significant information bottleneck, at each RIB iteration. The HGR values are averaged over 100 images. The HGR values of R BG remain fairly constant during the RIB process, while the HGR values of R D and R ND increase significantly. This indicates that the RIB process can indeed reduce the information bottleneck, thereby ensuring that more information corresponding to both R D and R ND is processed by the final classification layer.</p><p>Limiting the transmission of information from discriminative regions: Zhang et al. <ref type="bibr" target="#b64">[65]</ref> showed the relationship between a classification logit y and a CAM, i.e., y = GAP(CAM). This implies that increasing y c with RIB also increases the pixel values in the CAM. For a CAM to identify a wider area of the target object, it is important to increase the pixel scores of the non-discriminative regions, rather than the discriminative regions. Therefore, we introduce a new pooling method to the RIB process, so that the features that were previously delivering a small amount of information to the classification logit contribute more to the classification.</p><p>We propose a global non-discriminative region pooling (GNDRP). Contrary to GAP which aggregates all the values of the spatial location in the feature map T l , our GNDRP selectively aggregates the values of spatial locations whose CAM scores are below a threshold ? , as follows:</p><formula xml:id="formula_7">GAP(T l ) = 1 | U | u?U T l (u), GNDRP(T l ) = 1 | U ? | u?U? T l (u), U ? = {u ? U | CAM(u) ? ? },<label>(3)</label></formula><p>where U is a set of all spatial location indices in T l .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Refinement PASCAL VOC MS COCO Method</head><p>Seed CRF Mask Seed Mask PSA CVPR '18 <ref type="bibr" target="#b2">[3]</ref> PSA <ref type="bibr" target="#b2">[3]</ref> 48.0 -61.0 --Mixup-CAM BMVC '20 <ref type="bibr" target="#b5">[6]</ref> 50. Other methods of weakly supervised semantic segmentation also considered new pooling methods other than GAP to obtain better localization maps <ref type="bibr">[4,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b43">44]</ref>. The pooling methods introduced in previous works make the classifier focus more on discriminative parts. In contrast, GNDRP excludes highly activated regions, encouraging non-discriminative regions to be further activated.</p><p>Obtaining a final localization map: We obtain the final localization map M by aggregating all the CAMs obtained from the classifier at each RIB iteration k: M = 0?k?K CAM(x; ? k ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Weakly Supervised Semantic Segmentation</head><p>Because a CAM <ref type="bibr" target="#b66">[67]</ref> is obtained from down-sampled intermediate features produced by a classifier, it should be up-sampled to the size of the original image. Therefore, it tends to localize the target object coarsely and cannot represent its exact boundary. Many weakly supervised semantic segmentation methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b62">63]</ref> produce pseudo ground truths by modifying their initial seeds using established seed refinement methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref>. Similarly, we obtain pseudo ground truths by applying IRN <ref type="bibr" target="#b1">[2]</ref>, a state-of-the-art seed refinement method, to the coarse map M.</p><p>In addition, because an image-level class label is void of any prior regarding the shape of the target object, salient object mask supervision is popularly used in existing methods <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b59">60]</ref>. Salient object mask supervision can also be applied to our method to refine the pseudo ground truths: when a foreground pixel in a pseudo label is identified as background on this map, or a background pixel is identified as foreground, we ignore such pixels in the training of the segmentation network. Reproducibility. We implemented CAM <ref type="bibr" target="#b66">[67]</ref> by following the procedure from Ahn et al. <ref type="bibr" target="#b1">[2]</ref>, which is implemented with the PyTorch framework <ref type="bibr" target="#b42">[43]</ref>. We used the ResNet-50 <ref type="bibr" target="#b20">[21]</ref> backbone for the classification. We fine-tuned our classifier for K = 10 iterations with a learning rate of 8 ? 10 ?6 and a batch size of B = 20. We set the margin m to 600. For the GNDRP, we set ? to 0.4. For the final semantic segmentation, we used the PyTorch implementation of DeepLab-v2-ResNet101 offered by <ref type="bibr" target="#b41">[42]</ref>. We used an initial model pre-trained on the ImageNet dataset <ref type="bibr" target="#b13">[14]</ref>. For the MS COCO 2014 dataset, we cropped the training images with the crop size of 481?481 rather than 321?321 used for the PASCAL VOC 2012 dataset, considering the size of the images in this dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Weakly Supervised Semantic Segmentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Quality of the initial seed and pseudo ground truth</head><p>PASCAL VOC 2012 dataset: In <ref type="table">Table 1</ref>, we report the mIoU values of the initial seed and pseudo ground truth masks generated from our method and from other recent techniques. Following SEAM <ref type="bibr" target="#b55">[56]</ref>, we evaluate a range of thresholds to distinguish between the foreground and the background in the map M and then determine the best initial seeds. Our initial seeds exhibit 7.7%p improvement from the original CAMs, a baseline for comparison, and simultaneously outperform those from the other methods. Note that our initial seeds are better than those of SEAM, which further refines the initial CAM on a pixel-level by considering the relationship between pixels through an auxiliary self-attention module.</p><p>We applied a post-processing method based on conditional random field (CRF) <ref type="bibr" target="#b27">[28]</ref> for pixel-level refinement of the initial seeds obtained from the method proposed by Chang et al. <ref type="bibr" target="#b6">[7]</ref>, SEAM <ref type="bibr" target="#b55">[56]</ref>, IRN <ref type="bibr" target="#b1">[2]</ref>, and our method. On average, applying CRF improved all the seeds by more than 5%p, with the exception of SEAM. CRF improved SEAM by only 1.4%p, and it is reasonable to believe that this unusually small improvement occurred because the self-attention module had already refined the seed from CAM. When the seed produced by our method is refined with CRF, it is 6.1%p better than that from SEAM and consequently outperforms all the recent competitive methods by a large margin.</p><p>Additionally, we compare the pseudo ground truth masks obtained after seed refinement with those obtained using other methods. Most of the compared methods use PSA <ref type="bibr" target="#b2">[3]</ref> or IRN <ref type="bibr" target="#b1">[2]</ref> to refine their initial seeds. For a fair comparison, we generate pseudo ground truth masks using both seed refinement techniques. <ref type="table">Table 1</ref> shows that the masks from our method yield an mIoU of 68.6 with PSA <ref type="bibr" target="#b2">[3]</ref> and 70.6 with IRN <ref type="bibr" target="#b1">[2]</ref>, thereby outperforming other methods by a large margin.</p><p>MS COCO 2014 dataset: <ref type="table">Table 1</ref> presents the mIoU values of the initial seed and pseudo ground truth masks obtained by our method and by other recent methods for the MS COCO 2014 dataset. We obtained the results of IRN <ref type="bibr" target="#b1">[2]</ref> using the official code to set the baseline performance. Our method improved the initial seed and pseudo ground truth masks of our baseline IRN <ref type="bibr" target="#b1">[2]</ref>, by mIoU margins of 3.0%p and 2.7%p, respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Performance of weakly supervised semantic segmentation</head><p>PASCAL VOC 2012 dataset: <ref type="table">Table 2</ref> presents the mIoU values of the segmentation maps on PASCAL VOC 2012 validation and test images, predicted by our method and other recently introduced weakly supervised semantic segmentation methods, which use bounding box labels or image-level class labels. All the results in <ref type="table">Table 2</ref> were obtained using a ResNet-based backbone <ref type="bibr" target="#b20">[21]</ref>. Our method achieves mIoU values of 68. <ref type="bibr" target="#b2">3</ref>   the PASCAL VOC 2012 semantic segmentation benchmark, outperforming all the methods that use image-level class labels as weak supervision. In particular, our method outperforms CONTA <ref type="bibr" target="#b62">[63]</ref>, the best-performing method among our competitors, achieving an mIoU value of 66.1. However, CONTA depends on SEAM <ref type="bibr" target="#b55">[56]</ref>, which is known to outperform IRN <ref type="bibr" target="#b1">[2]</ref>. When CONTA was implemented with IRN for a fairer comparison with our method, its mIoU value decreased to 65.3, which our method surpasses by 3.0%p. <ref type="table" target="#tab_3">Table 3</ref> compares our method with other recent methods using additional salient object supervision. We utilized salient object supervision used by Li et al. <ref type="bibr" target="#b37">[38]</ref> and Yao et al. <ref type="bibr" target="#b59">[60]</ref>. Our method achieves mIoU values of 70.2 and 70.0 for the validation and test images, respectively, outperforming all the recently introduced methods under the same level of supervision. <ref type="figure">Figure 4(a)</ref> shows examples of predicted segmentation maps by our method with and without saliency supervision. The boundary information provided by saliency supervision allows our method to produce a more precise boundary (yellow boxes). However, the non-salient objects in an image are often ignored when using saliency supervision, while RIB successfully identifies them (e.g., a 'sofa' in the first column and 'person' in red boxes in <ref type="figure">Figure 4(a)</ref>). This empirical finding inspires a potential future work that can simultaneously identify a precise boundary and non-salient objects.  MS COCO 2014 dataset: <ref type="table" target="#tab_5">Table 4</ref> compares our method with other recent methods on MS COCO 2014 validation images. Our method achieves an improvement of 2.4%p in terms of the mIoU score compared with our baseline IRN <ref type="bibr" target="#b1">[2]</ref>, and outperforms the other recent competitive methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b62">63]</ref> by a large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>In the comparison with CONTA <ref type="bibr" target="#b62">[63]</ref>, the result of IRN reported in CONTA <ref type="bibr" target="#b62">[63]</ref> differs from the one we obtained. Therefore, we compare relative improvements: CONTA achieves a 0.8%p improvement compared with   <ref type="figure">Figure 4(b)</ref> presents examples of predicted segmentation maps by our method for the MS COCO 2014 validation images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablative Studies</head><p>In this section, we analyze our method through various ablation studies conducted on the PASCAL VOC 2012 dataset to provide more information about the effectiveness of each component of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RIB iteration (K)</head><p>mIoU (%) <ref type="figure">Figure 5</ref>: Analysis of RIB with GAP or GNDRP in terms of mIoU of the initial seed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Influence of the total number of RIB iterations K:</head><p>We analyze the influence of the iteration number K on the effectiveness the RIB process. <ref type="figure">Figure 5</ref> shows the mIoU score of the initial seed obtained by our baseline CAM, and that of each iteration of the RIB process with GAP or GNDRP. As the RIB process progresses, the localization map is significantly improved, regardless of the pooling method. However, the increase in the performance of RIB with GAP is limited, and even slightly decreases in later iterations (K &gt; 5). This is because GAP allows features that have already delivered sufficient information to the classification to become even more involved in the classification. Because our proposed GNDRP limits the increase in the contribution of these discriminative regions to the classification, RIB with GNDRP can effectively allow non-discriminative information to be more involved in the classification, resulting in a better localization map in later iterations. We observe that changing the value of K to be larger than 10 (even 20) produces less than 0.8%p drop in mIoU, suggesting that it is not difficult to select a good value of K.</p><p>Fine-tuning with L RIB : To verify the effectiveness of L RIB , we fine-tune a model using the BCE loss with various double-sided saturating activation functions. <ref type="table" target="#tab_7">Table 5</ref> (a) shows the mIoU scores of the initial seeds, obtained from a model fine-tuned by the BCE loss with sigmoid, tanh, and softsign activations, and our L RIB . We adjusted the output of tanh and softsign to have a value between zero and one through the affine transform. Fine-tuning using the BCE loss with double-sided saturating activations improves the initial seed to some extent, which demonstrates the effectiveness of per-sample adaptation; however, their performance improvement is limited due to the remaining information bottleneck. Note that the softsign activation function provides better localization maps than tanh and sigmoid. We believe this is because the gradients from softsign reach zero at a higher value compared with the others (please see the Appendix), and consequently, softsign has less information bottleneck. Our L RIB effectively addresses the information bottleneck and achieves the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of the sensitivity to hyper-parameters:</head><p>We analyze the sensitivity of the mIoU of the initial seed to the hyper-parameters involved in the RIB process. <ref type="table" target="#tab_7">Table 5</ref> (b) presents the mIoU values of the initial seed obtained using different combinations of values for the margin m and the learning rate ?. Overall, a slightly lower performance is observed when the strength of the RIB process is weakened by small values of m and ?. For sufficiently large m and ?, the performance of the RIB process is competitive.   <ref type="table">Table 7</ref>: mIoU (%) of the initial seed for 'boat' and 'train' classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis of Spurious Correlation</head><p>In a natural image, the target object and the background can be spuriously correlated when objects of a certain class primarily occur together in a specific context <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b62">63]</ref> (e.g., a boat on the sea and a train on the rail). Since image-level class labels do not provide an explicit localization cue of the target object, the classifier trained with these labels is vulnerable to spurious correlation. The localization map obtained from the classifier may also highlight the spuriously correlated background, which reduces precision. This is a long-standing problem that is commonly found in weakly supervised semantic segmentation and object localization.</p><p>RIB may also activate some portion of the spurious background. However, we find that the amount of discovered areas correctly belonging to the foreground is noticeably more significant by comparing the precision, recall, and F1-score of our method with those of other recent methods in <ref type="table" target="#tab_9">Table 6</ref>. Chang et al. <ref type="bibr" target="#b6">[7]</ref> achieve high recall but experience a large decrease in precision. SEAM <ref type="bibr" target="#b55">[56]</ref> avoids this loss of precision with the help of pixel-level refinement implemented with an additional module mentioned in Section 4.2.1. Our method improves precision as well as recall of our baseline IRN <ref type="bibr" target="#b1">[2]</ref> without an external module.</p><p>To further analyze the spuriously correlated background, we present class-wise seed improvement by our method and other recent methods. We select two representative classes, 'boat' and 'train', which are known to have the background that is spuriously correlated with the foreground (a boat on the sea and a train on the rail). <ref type="table">Table 7</ref> shows that RIB can improve localization quality (mIoU) even for classes known to have a spurious foreground-background correlation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this study, we addressed the major challenge in weakly supervised semantic segmentation with image-level class labels. Through the information bottleneck principle, we first analyzed why the localization map obtained from a classifier identifies only a small region of the target object. Our analysis highlighted that the amount of information delivered from an input image to the output classification is largely determined by the final layer of the DNN. We then developed a method to reduce the information bottleneck through two simple modifications to the existing training scheme: the removal of the final non-linear activation function in the DNN and the introduction of a new pooling method. Our method significantly improved the localization maps obtained from a classifier, exhibiting a new state-of-the-art performance on the PASCAL VOC 2012 and MS COCO 2014 datasets.</p><p>Societal implications: This work may have the following societal impacts. Object segmentation without the need for pixel-level annotation will save resources for research and commercial development. It is particularly useful in fields such as medicine, where expert annotation is costly. However, there are companies that provide annotations for images as a part of their services. If the dependence of DNNs on labels is reduced by weakly supervised learning, these companies may need to change their business models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Implementation Details</head><p>Optimization details for semantic segmentation: For the PASCAL VOC 2012 dataset, we set the batch size to 10, the number of training iterations to 30K, and the learning rate to 2.0 ? 10 ?4 . For the MS COCO 2014 dataset, we set the batch size to 10, the number of training iterations to 100K, and the learning rate to 2.5 ? 10 ?4 . We use a similar re-training technique to the previous methods <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63]</ref>. In the map obtained after executing random walk of IRN <ref type="bibr" target="#b1">[2]</ref>, we define pixels with a value greater than 0.3 as foreground and pixels with values less than 0.2 as background, and ignore the remaining pixels (P ignore ) in the initial segmentation training process. We fill the labels of P ignore using the segmentation maps predicted by the initially trained segmentation network, and train the network again with all the pseudo labels filled in. Without the re-training technique, our method obtains 67.83 mIoU, which outperforms all the methods presented in <ref type="table">Table 2</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Additional Analysis</head><p>Training a classifier with L RIB from scratch: In Section 3.2, we argue that training a classifier with L RIB from scratch causes instability in training. We support this with loss curves obtained with different values of the learning rate in <ref type="figure" target="#fig_0">Figure A1(a)</ref>. Since the gradient of the loss does not saturate, the loss diverges to ?? after a few iterations.</p><p>Different double-sided saturating activation functions: In Section 4.3, we fine-tuned the initial model with the BCE loss with tanh, sigmoid, and softsign activations. As shown in <ref type="figure" target="#fig_0">Figure A1(b)</ref>, the tanh activation saturates the fastest, and the softsign activation shows the most linear-like behavior, indicating that the information bottleneck is largest in tanh and smallest in softsign. This is supported by our experimental results in <ref type="table" target="#tab_7">Table 5</ref>(a) of the main paper: the fine-tuning process was effective in the order of softsign, sigmoid, and tanh.</p><p>Error bars: We repeat our RIB process five times to investigate the sensitivity of the initial seed to the random seeds. The obtained mIoU score is 56.44 ? 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sensitivity of a batch size B:</head><p>We analyze the sensitivity of the mIoU of the initial seed to the values of a batch size B. <ref type="table" target="#tab_11">Table A1</ref> shows the mIoU scores of the initial seed for the PASCAL VOC dataset for different values of B. The RIB process is more effective when using additional B ? 1 samples other than the target image x to construct a batch than when using only x as a batch (B = 1). In addition, the performance starts to saturate above a certain value of B, which shows that selecting a good value of B is rather straightforward.</p><p>More examples: <ref type="figure" target="#fig_1">Figures A2 and A3</ref> present examples of localization maps gradually refined by the RIB process for the PASCAL VOC and the MS COCO datasets. <ref type="figure">Figure A4</ref> presents examples of segmentation maps predicted by our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Per-class mIoU scores:</head><p>We present the per-class mIoU of our method and other recently introduced methods for the PASCAL VOC dataset <ref type="table" target="#tab_12">(Table A2</ref>) and the MS COCO dataset <ref type="table" target="#tab_3">(Table A3)</ref>.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(a) Examples of toy images. (b) Examples of gradient maps G k . (c) Plot of HGR values of R D , R ND , and R BG for each layer, averaged over 100 images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Analysis of G 6 for R D , R ND , and R BG at each RIB iteration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Examples of localization maps obtained during the RIB process for (a) PASCAL VOC 2012 training images and (b) MS COCO 2014 training images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3</head><label>3</label><figDesc>illustrates localization maps gradually refined by the RIB process for the PASCAL VOC 2012 and the MS COCO 2014 datasets. More samples are shown in the Appendix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure</head><label></label><figDesc>A1: (a) Loss curves with different values of the learning rate. (b) Visualization of tanh, sigmoid, and softsign activations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure A2 :Figure A4 :</head><label>A2A4</label><figDesc>Examples of localization maps obtained during the RIB process for PASCAL VOC training images. Image RIB process Figure A3: Examples of localization maps obtained during the RIB process for MS COCO training images. Examples of predicted segmentation masks from IRN [2] and our method for (a) PASCAL VOC 2012 validation images and (b) MS COCO 2014 validation images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>We evaluated our method quantitatively and qualitatively by conducting experiments on the PASCAL VOC 2012<ref type="bibr" target="#b15">[16]</ref> and the MS COCO 2014<ref type="bibr" target="#b38">[39]</ref> datasets. Following the common practice in weakly supervised semantic segmentation<ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b62">63]</ref>, we used the PASCAL VOC 2012 dataset, which is augmented by Hariharan et al.<ref type="bibr" target="#b19">[20]</ref>, containing 10,582 training images with objects from 20 classes. The MS COCO 2014 dataset contains approximately 82K training images containing objects of 80 classes. We evaluated our method on 1,449 validation images and 1,456 test images from the PASCAL VOC 2012 dataset and on 40,504 validation images from the MS COCO 2014 dataset, by calculating the mean intersection-over-union (mIoU) values.</figDesc><table><row><cell>4 Experiments</cell></row><row><cell>4.1 Experimental Setup</cell></row><row><cell>Dataset and evaluation metric:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>and 68.6 for the validation and test images, respectively, on</figDesc><table><row><cell>(a)</cell><cell>Image</cell><cell>Ground Truth</cell><cell>RIB</cell><cell cols="2">RIB w/. Sal</cell><cell>(b)</cell><cell>Image</cell><cell cols="2">Ground Truth</cell><cell>RIB</cell></row><row><cell cols="10">Figure 4: Examples of predicted segmentation masks from IRN [2] and our method for (a) PASCAL</cell></row><row><cell cols="9">VOC 2012 validation images and (b) MS COCO 2014 validation images.</cell></row><row><cell cols="2">Method</cell><cell></cell><cell>val</cell><cell>test</cell><cell cols="2">Method</cell><cell></cell><cell></cell><cell>Sup.</cell><cell>val</cell><cell>test</cell></row><row><cell cols="4">Supervision: Bounding box labels</cell><cell></cell><cell cols="3">SeeNet NeurIPS '18 [22]</cell><cell></cell><cell>S</cell><cell>63.1 62.8</cell></row><row><cell cols="3">Song et al. CVPR '19 [51]</cell><cell>70.2</cell><cell>-</cell><cell cols="4">FickleNet CVPR '19 [31]</cell><cell>S</cell><cell>64.9 65.3</cell></row><row><cell cols="3">BBAM CVPR '21 [34]</cell><cell cols="2">73.7 73.7</cell><cell cols="3">CIAN AAAI '20 [17]</cell><cell></cell><cell>S</cell><cell>64.3 65.3</cell></row><row><cell cols="5">Supervision: Image class labels IRN CVPR '19 [2] 63.5 64.8 SEAM CVPR '20 [56] 64.5 65.7 BES ECCV '20 [10] 65.7 66.6 Chang et al. CVPR '20 [7] 66.1 65.9 RRM AAAI '20 [62] 66.3 66.5 CONTA NeurIPS '20 [63] 66.1 66.7</cell><cell cols="4">Zhang et al. ECCV '20 [64] Fan et al. ECCV '20 [18] Sun et al. ECCV '20 [52] LIID TPAMI '20 [41] Li et al. AAAI '21 [38] Yao et al. CVPR '21 [60] RIB (Ours)</cell><cell>S S S S I S S S</cell><cell>66.6 66.7 67.2 66.7 66.2 66.9 66.5 67.5 68.2 68.5 68.3 68.5 70.2 70.0</cell></row><row><cell cols="2">RIB (Ours)</cell><cell></cell><cell cols="2">68.3 68.6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Table 2: Comparison of semantic segmenta-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">tion performance on PASCAL VOC 2012 val-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">idation and test images.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Comparison of semantic segmentation performance on PASCAL VOC 2012 validation and test images using explicit localization cues. S: salient object, S</figDesc><table /><note>I : salient instance.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Comparison of semantic segmenta- tion on MS COCO validation images.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Comparison of mIoU scores of the initial seed (a) with different activation functions for the final layer, (b) with different values of m and ?, and (c) with different values of ? . IRN (32.6 ? 33.4), whereas our method achieves 2.4%p (41.4 ? 43.8).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5</head><label>5</label><figDesc>(c) analyzes the influence of the threshold ? involved in the GNDRP. Increasing ? from 0.3 to 0.5 results in less than 1%p change in the mIoU, and thus, we conclude that the RIB process is robust against the changes in ? .</figDesc><table><row><cell>Method</cell><cell cols="3">Prec. Recall F1-score</cell></row><row><cell>IRN CVPR '19 [2]</cell><cell>66.0</cell><cell>66.4</cell><cell>66.2</cell></row><row><cell cols="2">Chang et al. CVPR '20 [7] 61.0</cell><cell>77.2</cell><cell>68.1</cell></row><row><cell>SEAM CVPR '20 [56]</cell><cell>66.8</cell><cell>76.8</cell><cell>71.5</cell></row><row><cell>RIB (Ours)</cell><cell>67.3</cell><cell>78.9</cell><cell>72.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Comparison of precision (Prec.), recall, and F1-score on PASCAL VOC 2012 train images.</figDesc><table><row><cell>Method</cell><cell>Boat Train</cell></row><row><cell>IRN CVPR '19 [2]</cell><cell>35.3 51.3</cell></row><row><cell cols="2">Chang et al. CVPR '20 [7] 34.1 53.1</cell></row><row><cell>SEAM CVPR '20 [56]</cell><cell>31.0 54.2</cell></row><row><cell>RIB (Ours)</cell><cell>38.8 55.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>by a large margin. Note that we do not employ the re-training technique for RIB with saliency and for the MS COCO dataset. Our experiments were performed on four NVIDIA Quadro RTX 8000 GPUs. The RIB process for Pascal VOC train split (1,464 images) takes 32 minutes and 43 minutes on four NVIDIA Quadro RTX 8000 and four NVIDIA Tesla V100 GPUs, respectively.</figDesc><table><row><cell>Computation Resources:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table A1 :</head><label>A1</label><figDesc>Comparison of mIoU scores of the initial seed with different values of B.</figDesc><table><row><cell>B</cell><cell>1</cell><cell>5</cell><cell>10</cell><cell>15</cell><cell>20</cell><cell>25</cell><cell>30</cell></row><row><cell cols="8">mIoU 55.3 55.5 55.8 56.2 56.5 56.6 56.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table A2 :</head><label>A2</label><figDesc>Comparison of per-class mIoU scores for the PASCAL VOC dataset. bkg aero bike bird boat bottle bus car cat chair cow table dog horse motor person plant sheep sofa train tv mIOU Results on PASCAL VOC 2012 validation images: PSA [3] 88.2 68.2 30.6 81.1 49.6 61.0 77.8 66.1 75.1 29.0 66.0 40.2 80.4 62.0 70.4 73.7 42.5 70.7 42.6 68.1 51.6 61.7 CIAN [17] 88.2 79.5 32.6 75.7 56.8 72.1 85.3 72.9 81.7 27.6 73.3 39.8 76.4 77.0 74.9 66.8 46.6 81.0 29.1 60.4 53.3 64.3 SEAM [56] 88.8 68.5 33.3 85.7 40.4 67.3 78.9 76.3 81.9 29.1 75.5 48.1 79.9 73.8 71.4 75.2 48.9 79.8 40.9 58.2 53.0 64.5 FickleNet [31] 89.5 76.6 32.6 74.6 51.5 71.1 83.4 74.4 83.6 24.1 73.4 47.4 78.2 74.0 68.8 73.2 47.8 79.9 37.0 57.3 64.6 64.9 SSDD [49] 89.0 62.5 28.9 83.7 52.9 59.5 77.6 73.7 87.0 34.0 83.7 47.6 84.1 77.0 73.9 69.6 29.8 84.0 43.2 68.0 53.4 64.9 RIB (Ours) 90.3 76.2 33.7 82.5 64.9 73.1 88.4 78.6 88.7 32.3 80.1 37.5 83.6 79.7 75.8 71.8 47.5 84.3 44.6 65.9 54.9 68.3 RIB-Sal (Ours) 91.7 85.2 37.4 80.4 69.5 72.8 89.2 81.9 89.7 29.7 84.2 30.8 85.5 84.1 79.5 75.8 52.4 83.5 38.2 74.2 59.3 70.2 Results on PASCAL VOC 2012 test images: PSA [3] 89.1 70.6 31.6 77.2 42.2 68.9 79.1 66.5 74.9 29.6 68.7 56.1 82.1 64.8 78.6 73.5 50.8 70.7 47.7 63.9 51.1 63.7 FickleNet [31] 90.3 77.0 35.2 76.0 54.2 64.3 76.6 76.1 80.2 25.7 68.6 50.2 74.6 71.8 78.3 69.5 53.8 76.5 41.8 70.0 54.2 65.3 SSDD [49] 89.0 62.5 28.9 83.7 52.9 59.5 77.6 73.7 87.0 34.0 83.7 47.6 84.1 77.0 73.9 69.6 29.8 84.0 43.2 68.0 53.4 64.9 RIB (Ours) 90.4 80.5 32.8 84.9 59.4 69.3 87.2 83.5 88.3 31.1 80.4 44.0 84.4 82.3 80.9 70.7 43.5 84.9 55.9 59.0 47.3 68.6 RIB-Sal (Ours) 91.8 89.4 37.1 84.7 56.7 69.2 89.6 84.0 89.8 24.6 81.3 37.9 85.4 84.5 81.1 75.5 50.7 85.9 44.7 71.9 54.0 70.0</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table A3 :</head><label>A3</label><figDesc>Comparison of per-class mIoU scores for the MS COCO dataset.</figDesc><table><row><cell>Image</cell><cell>RIB process</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Information dropout: Learning optimal representations through noisy computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of instance segmentation with inter-pixel relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning pixel-level semantic affinity with image-level supervision for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Single-stage semantic segmentation from image labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Araslanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rethinking class activation mapping for weakly supervised object localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonho</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhyug</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunhee</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="618" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mixup-cam: Weakly-supervised semantic segmentation via uncertainty regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ting</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaosong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robinson</forename><surname>Piramuthu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Weakly-supervised semantic segmentation via sub-category exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ting</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaosong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robinson</forename><surname>Piramuthu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Noisy softmax: Improving the generalization ability of dcnn via postponing the early softmax saturation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binghui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junping</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IEEE TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Weakly supervised semantic segmentation with boundary exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Attention-based dropout layer for weakly supervised single object localization and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjung</forename><surname>Shim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Elements of information theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cover</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning optimal representations with the decodable information bottleneck</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Schwab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedantam</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The pascal visual object classes (voc) challenge. IJCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Cian: Cross-image affinity net for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Employing multi-estimations for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semantic contours from inverse detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Arbel?ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Self-erasing network for integral object attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengtao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ccnet: Criss-cross attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Weakly-supervised semantic segmentation network with deep seeded region growing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ib-gan: Disengangled representation learning with information bottleneck generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonkwang</forename><surname>Insu Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeongjang</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunhee</forename><surname>Pyeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Seed, expand and constrain: Three principles for weakly-supervised image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient inference in fully connected crfs with gaussian edge potentials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Box2seg: Attention weighted loss and discriminative feature learning for weakly supervised segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viveka</forename><surname>Kulharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambrish</forename><surname>Tyagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Ficklenet: Weakly and semisupervised semantic image segmentation using stochastic inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunji</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jangho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Frame-to-frame aggregation of active regions in web videos for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunji</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jangho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Anti-adversarially manipulated attributions for weakly and semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunji</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Bbam: Bounding box attribution map for weakly supervised semantic and instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihun</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaehun</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Robust tumor localization with pyramid grad-cam</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jangho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chul-Kee</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.11393</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Tell me where to look: Guided attention inference network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuan-Chuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Guided attention inference network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuan-Chuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Group-wise semantic mining for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Weakly supervised segmentation with maximum bipartite graph matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weide</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung</forename><surname>Tzu-Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACMMM</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Leveraging instance-, image-and dataset-level information for weakly supervised instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Huan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Song</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Jun</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title/>
		<ptr target="https://github.com/kazuto1011/deeplab-pytorch" />
	</analytic>
	<monogr>
		<title level="j">Kazuto Nakashima. DeepLab with PyTorch</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">From image-level to pixel-level labeling with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pedro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1713" to="1721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dice: Diversity in deep ensembles via conditional redundancy adversarial estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Rame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On the information bottleneck theory of deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Michael Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yamini</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Dapello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madhu</forename><surname>Advani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artemy</forename><surname>Kolchinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><forename type="middle">Daniel</forename><surname>Tracey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">Daniel</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Restricting the flow: Information bottlenecks for attribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Sixt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Landgraf</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Grad-cam: Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramprasaath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Self-supervised difference detection for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wataru</forename><surname>Shimoda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keiji</forename><surname>Yanai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Opening the black box of deep neural networks via information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravid</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Ziv</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00810</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Box-driven class-wise region masking and filling rate guided loss for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Mining cross-image semantics for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Normalized cut loss for weakly-supervised cnn segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelaziz</forename><surname>Djelouah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Schroers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bialek</surname></persName>
		</author>
		<title level="m">The information bottleneck method. arXiv preprint physics/0004057</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep learning and the information bottleneck principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noga</forename><surname>Zaslavsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Information Theory Workshop (ITW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Self-supervised equivariant attention mechanism for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yude</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meina</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Object region mining with adversarial erasing: A simple classification to semantic segmentation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Revisiting dilated convolution: A simple approach for weakly-and semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Saliency guided self-attention network for weakly and semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>IEEE Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Non-salient region object mining for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhou</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosen</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fumin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenmin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Meta-learning without memorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhang</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Reliability does matter: An end-to-end weakly supervised semantic segmentation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaizhu</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Causal intervention for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiansheng</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Splitting vs. merging: Mining object regions with discrepancy and intersection loss for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weide</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Adversarial complementary learning for weakly supervised object localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Information-bottleneck approach to salient region discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Self-Supervised Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>d) Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes] Please see the Appendix</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">data, models) or curating/releasing new assets... (a) If your work uses existing assets, did you cite the creators? [Yes] Please see Section 4 (b) Did you mention the license of the assets?</title>
		<imprint/>
	</monogr>
	<note>If you are using existing assets (e.g., code,. N/A] (c) Did you include any new assets either in the supplemental material or as a URL? [N/A] (d) Did you discuss whether and how consent was obtained from people whose data you&apos;re using/curating? [N/A</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content</title>
		<imprint/>
	</monogr>
	<note>N/A</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A] (b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable</title>
		<imprint/>
	</monogr>
	<note>N/A] (c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
