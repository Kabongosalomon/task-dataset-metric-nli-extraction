<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MANTRA: Memory Augmented Networks for Multiple Trajectory Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Marchetti</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">MICC</orgName>
								<orgName type="institution" key="instit2">University of Florence</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Becattini</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">MICC</orgName>
								<orgName type="institution" key="instit2">University of Florence</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Seidenari</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">MICC</orgName>
								<orgName type="institution" key="instit2">University of Florence</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><forename type="middle">Del</forename><surname>Bimbo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">MICC</orgName>
								<orgName type="institution" key="instit2">University of Florence</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MANTRA: Memory Augmented Networks for Multiple Trajectory Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Autonomous vehicles are expected to drive in complex scenarios with several independent non cooperating agents. Path planning for safely navigating in such environments can not just rely on perceiving present location and motion of other agents. It requires instead to predict such variables in a far enough future. In this paper we address the problem of multimodal trajectory prediction exploiting a Memory Augmented Neural Network. Our method learns past and future trajectory embeddings using recurrent neural networks and exploits an associative external memory to store and retrieve such embeddings. Trajectory prediction is then performed by decoding in-memory future encodings conditioned with the observed past. We incorporate scene knowledge in the decoding state by learning a CNN on top of semantic scene maps. Memory growth is limited by learning a writing controller based on the predictive capability of existing embeddings. We show that our method is able to natively perform multi-modal trajectory prediction obtaining state-of-the art results on three datasets. Moreover, thanks to the non-parametric nature of the memory module, we show how once trained our system can continuously improve by ingesting novel patterns.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>What makes humans capable of succeeding in a large variety of tasks is the capacity to learn from experience, recalling past events and generalizing to new ones. Learning to drive is a clear example of this ability. In recent years a lot of effort has been made to imitate this skill and to develop autonomous vehicles that are able to safely drive among other agents, either autonomous or driven by humans. Whereas remarkable progress has been made for automotive <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b51">52]</ref>, current approaches still lack the ability to explicitly remember specific instances from experience when trying to infer possible future states of surrounding agents. This is particularly important for predicting future locations of moving agents, so to take appropriate decisions and avoid collisions or potentially dangerous situations. Predicting future trajectories of such agents is intrin-  <ref type="figure">Figure 1</ref>. MANTRA addresses multimodal trajectory prediction. We obtain multiple future predictions given an observed past relying on a Memory Augmented Neural Network. sically multimodal: vehicle dynamics give rise to a set of similarly likely outcomes for an external observer ( <ref type="figure">Fig. 1</ref>). While humans can address this task by implicit learning, i.e. exploiting procedural memory (knowing how to do things) from similar scenarios of previous experience, without explicit and conscious awareness, for machines this task has proven to be extremely hard. Common machine learning models, such as Recurrent Neural Networks, fail to address it. They are capable to store past information into an internal state, updated at every time step, and make predictions based on long term patterns. But in such networks, memory is a single hidden representation and is only addressable as a whole. State to state transition is unstructured and global. Instead, an element-wise addressable memory would be useful to selectively access only relevant pieces of information. This would allow to peak into likely futures to guide predictions.</p><p>In this paper we present MANTRA: Memory Augmented Neural TRAjectory predictor. MANTRA is a novel approach implementing a persistent Memory Augmented Neural Network (MANN) for vehicle trajectory prediction. In our model, an external associative memory is trained to write pairs of past and future trajectories and keep in mem-arXiv:2006.03340v2 [cs.CV] 3 Jun 2021 ory only the most meaningful and non-redundant samples.</p><p>The model incrementally creates a knowledge base that is used as experience to perform meaningful predictions. This mimics the way in which implicit human memory works. Since the knowledge base is built from trajectory samples, it can also include instances observed while the system is running, after it has been trained. In this way the system gains experience online increasing its accuracy and capability to generalise at no training cost.</p><p>To memorize samples, past and future trajectories are stored in the memory in an encoded form, separately. In fact, this permits to use the encoding of an observed trajectory as a memory key to read an encoded future and decode them jointly to generate a prediction. Therefore, the actual coordinates are obtained decoding a future read from memory, conditioning it with the observed past. In this way, the output is not a simple copy of previously seen examples, but is instead a newly generated trajectory obtained both from the system experience (i.e. its memory) and the instance observed so far. By reading multiple futures from memory, diverse meaningful predictions can be obtained. The main contributions of this paper are the following:</p><p>? We propose a novel architecture for multiple trajectory prediction based on Memory Augmented Neural Networks. To the best of our knowledge we are the first to adopt MANNs for trajectory prediction. ? Our formulation, exploiting an encoder-decoder pipeline augmented with an associative memory, is easier to inspect and provides naturally multimodal predictions, obtaining state-of-the-art results on three traffic datasets. ? Our model is able to improve incrementally, after it has been trained, when observing new examples online. This trait is important for industrial automotive applications and is currently lacking in other state of the art predictors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Trajectory Prediction Significant effort has been made in the past years regarding trajectory prediction. Several researchers have focused on trajectories of pedestrians <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b43">44]</ref>, either regarded as individuals or crowds, also exploiting social behaviors and interactivity between individuals <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b35">36]</ref>. While relevant for pedestrians, social behaviors are much less relevant for vehicles <ref type="bibr" target="#b24">[25]</ref>. In this context, focus shifts instead on the observation of motion of the individual agents (their past trajectory) and the understanding of the surrounding environment <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b46">47]</ref>. Traffic dynamics likely reduce to simpler scenarios where movement is limited and constrained by the environment. A notable exception is estimating lane changes on highways <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b22">23]</ref>. A few efforts have been made to understand and predict vehicle trajectories in urban scenarios <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b57">57]</ref>. Among them, DESIRE <ref type="bibr" target="#b24">[25]</ref> uses a Variational Autoencoder for estimating a distribution from which future trajectories can be sampled. The method though is not able to generate confidence scores to provide a ranked set of trajectories. A large number of predictions is needed to cover all the search space and Inverse Optimal Control is then used to extract a final ranked subset. INFER <ref type="bibr" target="#b46">[47]</ref> instead exploits a fully convolutional model that takes into account intermediate semantic representations and generates multimodal heatmaps of possible future locations, then looking for peaks of the distribution. In our work we address prediction of multiple vehicle trajectories in urban scenes. Examples of contexts where such multiple predictions may be necessary are roundabouts and crossroads where vehicles might take different equally possible paths. Differently from DESIRE <ref type="bibr" target="#b24">[25]</ref> our approach is able to directly estimate a small set of ranked trajectories which already exhibit sufficient diversity to cover multiple futures. Differently from INFER <ref type="bibr" target="#b46">[47]</ref> we directly work with coordinates instead of heatmaps, providing a better spatial resolution and more precise predictions. Differently from both DESIRE and INFER, we train a Memory Augmented Neural Network model to generate multimodal trajectories, which to the best of our knowledge has never been used with this purpose. The usage of MANNs has two main advantages: (i) multiple futures can be read from memory for a given trajectory observation, making the model capable to predict multiple outcomes, complying to the multimodal nature of the problem; (ii) by retrieving a likely future from memory we can rely on an oracle that suggests what is going to happen in the near future.</p><p>A conceptually similar research direction to ours is the one of intention-based methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b39">40]</ref>. Here, some anchor information (such as trajectories, actions or locations) are predefined and then used to guide predictions after estimating a probability distribution over each candidate. In <ref type="bibr" target="#b39">[40]</ref>, predictions are conditioned by the state of a robot agent, for which a goal is given or estimated. The authors of <ref type="bibr" target="#b7">[8]</ref> propose a model for intersections that generates a likelihood over 5 fixed map zones, entailing different motion patterns. In <ref type="bibr" target="#b4">[5]</ref>, anchor trajectories are created with k-means and random sampling over training data. To some extent, our memory entries can be interpreted as anchors encoding futures instead of intentions. However, we do not choose a reference agent to condition predictions or restrict the applicability to constrained scenarios.</p><p>In order to obtain meaningful predictions we also take context into account and its physical constraints. According to this, the set of trajectory proposals obtained by the MANN is refined by integrating knowledge of the surrounding environment using semantic maps. Finally, differently for prior work, our trajectory prediction model is also capable of growing online, improving incrementally its performance from new observations after it has been trained. Memory Networks Neural networks with memory capabilities have been introduced to solve several machine learning problems which require to model a temporal dimension. The most common models are Recurrent Neural Networks (RNN) and their variants such as Long-Short Term Memories (LSTM) <ref type="bibr" target="#b18">[19]</ref> and Gated Recurrent Units (GRU) <ref type="bibr" target="#b6">[7]</ref>. However, in these models memory is a single hidden state vector that encodes all the temporal information. So memory is addressable as a whole and they lack the ability to address individual elements of knowledge, necessary to apply algorithmic manipulation and rapid inference. Moreover, state to state transition is unstructured and global. Being the state updated at each time-step, eventually it fails to model very long term dependencies. Finally, the number of parameters is tied to the size of the hidden state. So adding knowledge from the external environment necessarily implies increasing the size of the state. These characteristics prevent to use these models to effectively solve classes of problems like the one we address in this paper.</p><p>Recent works <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54]</ref> have proposed Memory Augmented Neural Networks, or simply Memory Networks, to overcome the limitations of RNNs. The principal characteristic of this model is the usage of a controller network with an external element-wise addressable memory. This is used to store explicit information and access selectively relevant items. The memory controller is trained to dynamically managed memory content optimizing predictions. Differently from RNNs, state to state transitions are obtained through read/write operations and a set of independent states is maintained. An important consideration is that in Memory Networks the number of parameters is not tied to the size of the memory, i.e. increasing the memory slots will not increase the number of parameters.</p><p>While introduced recently, a number of applications of this model have already appeared in literature. The first em-bodiment of a Memory Network was proposed in Neural Turing Machines (NTM) <ref type="bibr" target="#b15">[16]</ref> to perform algorithmic tasks, such as sorting or copying, which require sequential manipulation steps. Thanks to a fully differentiable controller, the model interacts with the memory through read/write operations. The architecture was later extended to perform oneshot learning in <ref type="bibr" target="#b45">[46]</ref>. Differently from NTM they trained the MANN to implement a Least Recently Used memory access strategy to write into rarely used locations.</p><p>In <ref type="bibr" target="#b50">[51]</ref> MANNs have been proved to be able to effectively address Question Answering tasks, where the model has to answer questions related to a series of sentences. In <ref type="bibr" target="#b47">[48]</ref> the same problem is solved with an End-to-End Memory Network with attention weights to shift importance from one sentence to another. Recent approaches have proposed a MANN to address the more complex problem of Visual Question Answering <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b29">30]</ref>, training the MANN to learn uncommon question-answer pairs. Online learning has also been tackled using Memory Networks. Rebuffi et al. <ref type="bibr" target="#b38">[39]</ref> learn a classifier adding classes incrementally. MANNs for object tracking have been proposed where the model is trained to memorize templates, which are updated as the object is tracked <ref type="bibr" target="#b53">[54]</ref>.</p><p>All these MANNs rely on episodic memories. The system learns to write and read from memory but the stored data is limited only to the current set of observations (such as a list of numbers to be sorted in <ref type="bibr" target="#b15">[16]</ref> or a collection of sentences for question answering in <ref type="bibr" target="#b50">[51]</ref>). Differently from prior work, we build a MANN with a memory that is not episodic. Instead, it acts like a persistent memory which stores an experience of relevant data to perform accurate predictions for any observation and not just for a restricted episode or set of samples. The rationale behind this approach is that instead of solving simple algorithmic tasks as a Neural Turing Machine, we learn how to create a pool of samples to be used for future trajectory predictions.</p><p>The proposed model learns to store in memory only what is strictly needed to perform accurate predictions. Our usage of MANN si close to <ref type="bibr" target="#b34">[35]</ref>, but differs substantially. While they exploit the decoupling of embeddings to better fit data, we leverage the disjoint representation to create multiple outputs from a single input, leading to a fully multimodal predictive capability of the overall system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model</head><p>We formulate the task of vehicle trajectory prediction as the problem of estimating P (x F |x P , c), wherex F is the predicted future trajectory, x P is the observed trajectory (or past) and c is a representation of the context (e.g. roads, sidewalks). We consider vehicle trajectories as a sequence of 2-dimensional spatial coordinates. The past x P is given by its positions observed up to some reference point identified as present. Similarly, the future x F is the sequence of positions in which it will find itself at the next time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Memory Based Trajectory Prediction</head><p>Given a sample trajectory</p><formula xml:id="formula_0">x i = [x i P , x i F ], let ? i = ?(x i P ) and ? i = ?(x i F )</formula><p>be two encoding functions that map the 2D coordinates of past and future trajectories into two separate latent representations. Similarly, let ?(? i , ? i ) be a function that decodes a pair of past-future encodings into the coordinates of the future sub-trajectory x i F , as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. We define M = {? i , ? i } as an associative key-value memory containing |M | pairs of past-future encodings. When a new trajectory x k P is observed, its encoding ? k is used as key to retrieve meaningful samples from memory. Note that observed trajectories are all considered to be past trajectories, since the future counterpart is yet to be observed and is what we want to predict. The memory addressing mechanism is implemented as a cosine distance between past encodings, which produces similarity scores {s i } over all memory locations:</p><formula xml:id="formula_1">s i = ? k ? i ? k ? i i = 0, ..., |M |<label>(1)</label></formula><p>According to the similarity scores, the future encodings of the top-K elements ? j are separately combined with the encoding of the observed past ? k . The novel pairs of encodings are transformed into 2D coordinates using the decoding function ?:x j F = ?(? k , ? j ), with j = 1, ..., K. Note that ? k is fixed while ? j varies depending on the sample read from memory. Future encodings ? j act as an oracle which suggests possible outcomes based on the past observation. This strategy allows the model to look ahead into likely futures in order to predict the correct one. Since multiple ? j can be used independently, we can decode multiple futures and obtain a multimodal prediction in case of uncertainty (e.g. a bifurcation in the road). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Feature Representation Learning</head><p>The encoding-decoding functions ?, ?, ? are trained jointly as an autoencoder, as shown in <ref type="figure" target="#fig_2">Fig. 3</ref>. The encoders learn to map past and future points into a meaningful representation and the decoder learns to reproduce the future. Instead of using just the future as input, we condition the reconstruction process also with an encoding of the past. This is useful for two aspects. First, we are able to train two different encoders for past and future. The two encoders are used to obtain separate representations for both keys (past) and values (future) in memory. Second, we obtain reconstructions of the future that is compatible with the past. This is of crucial importance for prediction since at test time we synthesize trajectory encodings by combining past and future parts taken from different examples. This also allows to generate trajectories that differ from the ones in memory and are not just a simple copy of already observed samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Memory controller</head><p>Traditional Memory Augmented Neural Networks <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b50">51]</ref> are designed to observe collections of data, usually referred to as episodes. The models are equipped with a working memory to store relevant information about the episode in order to generate a meaningful output for the episode. Yet memory is cleared for each episode and what is trained is the controller that decides what to read/write. The supervision for training stems from the cost function at the end of the episode, tracing gradients back to the controller.</p><p>As in standard memories, we train a controller to emit a write probability P (w) every time that a sample is observed but, differently from these approaches, we train it to build a compact and expressive permanent memory. Training such a controller might result challenging since P (w) does not depend only on the intrinsic importance of the observed sample but also on the current state of the memory. To solve this issue, we do not rely on the prediction loss for supervision. We instead feed the reconstruction error e to the controller, which decides if the network was sufficiently close to the ground truth. To enforce this behavior we define the controller loss L c as:</p><formula xml:id="formula_2">L c = e ? (1 ? P (w)) + (1 ? e) ? P (w)<label>(2)</label></formula><p>where e is assumed to have values in [0, 1]. When the error is low, i.e. e ? 0, then</p><formula xml:id="formula_3">L c ? P (w)<label>(3)</label></formula><p>therefore the write probability is minimized. Conversely, when e ? 1, then</p><formula xml:id="formula_4">L c ? 1 ? P (w)<label>(4)</label></formula><p>and the controller maximizes the write probability. What the controller is learning is an adaptive threshold on the reconstruction error, that allows to store in memory only what is useful to predict accurately, limiting redundancy. If the model exhibits a large prediction error, the controller writes the current sample with its ground truth future encoding in memory. When this happens, it indicates that the memory lacks samples to accurately reconstruct the future. Hence, by writing the sample in memory, the model will improve its prediction capabilities.</p><p>To satisfy the assumption of a bounded error function with values in [0, 1] for the controller loss of Eq. 2, we introduce an adaptive miss rate error function with a threshold depending on the timestep:</p><formula xml:id="formula_5">e = 1 ? 1 N N i=1 1 i (x F , x F )<label>(5)</label></formula><p>where 1 i (x F , x F ) is an indicator function equal to 1 if the i-th point of the predictionx F lays within a threshold th from the ground truth and 0 otherwise. We use a different threshold for each timestep, allowing a given uncertainty for the farthest point (4 seconds) and linearly decreasing towards 0. In our experiments we use th 4s = 2m.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Iterative Refinement Module</head><p>To ensure compatibility with the environment, we refine predictions with an iterative procedure. Similarly to DE-SIRE <ref type="bibr" target="#b24">[25]</ref>, we adopt a feature pooling strategy: first, a CNN extracts a feature map ? k from the context c; then, predictions are overlapped with the feature map and, for each time step coordinates, we extract the correspondent feature values (one per channel); finally, the resulting vector is fed to a GRU and a fully connected that output trajectory offsets.</p><p>The CNN is: 8 ? (k3, s2, p1); 16 ? (k3, s1, p1), where k is kernel size, s stride, p padding. Both layers have Batch-Norm and ReLU. The GRU has a hidden state size of 48. We do 4 iterations and we observed that increasing them does not introduce substantial changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Training</head><p>We train our model to observe 2 seconds trajectories and predict 4 seconds in the future. To achieve translation and rotation invariance, each trajectory is normalized by shifting the present in the origin and rotating the trajectory in order to make it tangent with the Y-axis in the origin. In this way all futures start from (0, 0) in an upward direction.</p><p>First, a pretraining of both the encoders and the decoder is done jointly as an autoencoder. To do so, we feed pairs of past and future trajectories belonging to the same samples, reconstructing only the future coordinates. We then train the memory controller, exploiting the learned past encoder and future decoder and resetting memory after every epoch. As controller we use a linear layer with sigmoid activation. The trained controller allows the memory to be filled with useful and non-redundant training samples by iterating over the training set and measuring their reconstruction error. While in principle the order in which samples are presented to the memory for writing may result in different final content, in our experiments we found that this does not affect the final prediction result. As a last step, we jointly train the refinement module and finetune the decoder. Here we feed the decoder with past and future encodings belonging to different samples, since the future is read from memory.</p><p>The two encoders and the decoder are implemented as Gated Recurrent Units with a 48-dimensional hidden state for each encoder and 96-dimensional for the decoder. The GRU in the refinement module is initialized with the past embedding and takes as input the predicted coordinates. This provides the module with complete information about the whole trajectory. We optimize L c defined in Eq. 2 to train the controller and a Mean Squared Error loss for decoder and refinement. All components are trained with the Adam optimizer using a learning rate of 0.0001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>KITTI <ref type="bibr" target="#b13">[14]</ref> The dataset includes many annotations such as Velodyne LiDAR 3D scans, object bounding boxes and tracks, calibration, depth and IMU. Not all data is present for every video so we used the ones categorized as KITTI Raw Data, following the split of DESIRE <ref type="bibr" target="#b24">[25]</ref>. Although the split is known, how to divide trajectories in data chunks is not. To obtain samples we collect 6 seconds chunks (2 seconds for past and 4 for future) in a sliding window fashion from all trajectories in the dataset, including the egovehicle. We obtain 8613 top-view trajectories for training and 2907 for testing. Note that these numbers are different from the original DESIRE split since they claim to gather 2509 trajectories in total. To favor reproducibility and future comparison we will publicly release our version of the dataset upon publication. Since top-view maps are not provided by KITTI, we project semantic labels of static categories obtained with DeepLab-v3+ <ref type="bibr" target="#b5">[6]</ref> from all frames in a common top-view map using the Velodyne 3D point cloud and IMU. The resulting maps have a spatial resolution of 0.5 meters, and will be released along with the trajectories. Another smaller version of KITTI for trajectory prediction has been recently proposed by <ref type="bibr" target="#b46">[47]</ref> and is publicly available. The authors propose 5 different train/test splits and average results over all runs, so we follow this evaluation protocol. We report experiments on both variants of KITTI. In the following we will refer to KITTI as our split obtained following DESIRE, unless stated otherwise.</p><p>Oxford RobotCar <ref type="bibr" target="#b32">[33]</ref> &amp; Cityscapes <ref type="bibr" target="#b9">[10]</ref> The two datasets RobotCar and Cityscapes have been adapted for trajectory prediction in <ref type="bibr" target="#b46">[47]</ref> to show zero-shot transfer capabilities on different domains. Of particular interest is the ability to transfer to RobotCar since the sequences are acquired in the UK where cars drive on the left-side of the road. RobotCar has 6 seconds trajectories divided into 2 seconds for past and 4 for future. Cityscapes instead has shorter videos and predictions are made only up to one second in the future, as done in <ref type="bibr" target="#b46">[47]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation metrics and Baselines</head><p>We report results in two common metrics for vehicle trajectory prediction: Average Displacement Error (ADE) and Final Displacement Error (FDE), where ADE is the average L2 error between all future timesteps and FDE (sometimes referred to as Horizon error) is the error at a given timestep. As in <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b46">47]</ref> we take the best out of K predictions to account for the intrinsic multimodality of the task. We compare our approach with several baselines: a linear coordinate regressor (Linear); a Multi-Layer Perceptron with two layers trained as a coordinate regressor (MPL); a Kalman filter <ref type="bibr" target="#b20">[21]</ref>, with a constant speed model used to propagate the estimate without incorporating measures <ref type="bibr">(Kalman)</ref>. We implemented and tested the baselines on the KITTI dataset to show comparable results. When available we also report existing baselines from the literature. <ref type="table">Table 1</ref> shows the results on the KITTI dataset. Simply propagating the trajectory with a Kalman filter proves to be insufficient to accurately predict future positions, especially over long time spans, with a FDE@4s higher than 7m.  Learning based baselines all perform better than Kalman filter, with the Multi-Layer Perceptron performing slightly better than the linear regressor. Models that generate a single prediction fail to address the multimodality of the task, since they are trained to lower the error with a single output even when there might be multiple equally likely desired outcomes. What may happen is that in front of a bifurcation, the model predicts an average of the two possible trajectories, trying to satisfy both scenarios. Examples of this behavior are shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. Each prediction of MANTRA instead follows a specific path, ignoring the others. This leads to high errors on some examples when generating only one future, since the model may decide to follow a different likely path. On the other hand as soon as we generate K multiple predictions, the top-K error drastically decreases since we are able to cover diverse future paths. We also report results from DESIRE <ref type="bibr" target="#b24">[25]</ref> varying K. Even though these results are not directly comparable as explained in Section 4.1, it is interesting to observe how DESIRE quickly saturates when increasing K, while our method keeps lowering the error significantly. This suggests that MANTRA samples a higher diversity of futures both at a coarse level (i.e. taking one road or another) and at a fine level (i.e. different behaviors on the same road). Some qualitative results on KITTI are shown in <ref type="figure" target="#fig_3">Fig 4,</ref> comparing them with the baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>Additionally, we evaluate MANTRA on the KITTI split proposed in <ref type="bibr" target="#b46">[47]</ref>, as shown in <ref type="table" target="#tab_2">Table 2</ref>. Here we also report some available baselines from the state of the art, both for single and multimodal predictions. With K = 1 our method performs better or on par with INFER <ref type="bibr" target="#b46">[47]</ref> at low timesteps, yet losing some precision at 4s. Increasing K instead we are able to largely outperform INFER over all timesteps.</p><p>Following <ref type="bibr" target="#b46">[47]</ref>, we showcase the ability of our model to zero-shot transfer to other datasets. On Oxford RobotCar (Tab. 3) MANTRA is still able to provide satisfactory results, consistently outperforming INFER across timesteps for multimodal predictions. Analogously, on Cityscapes (Tab. 4) the model obtains a lower error than the other methods. Here we report only errors at 1s in the future, which is the maximum length of the trajectories in the dataset.    <ref type="table">Table 4</ref>. Results on the Cityscapes dataset at 1s in the future.</p><formula xml:id="formula_6">? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? (a) Linear (b) Kalman (c) MANTRA</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Incremental setting</head><p>Differently from prior work on trajectory prediction, MANTRA is able to improve its capabilities online, i.e. observing other agents' behaviors while driving. We simulate an online scenario on KITTI, iteratively removing a small set of 50 trajectories from the test set, presenting them to the memory controller. The controller incorporates novel patterns according to P (w). At each iteration we test the predictor on the remaining test set. In <ref type="figure" target="#fig_4">Fig. 5</ref> memory growth and test error are shown for MANTRA with K=5 multiple futures. Similar behaviors can be observed varying K. Interestingly, the memory size slowly grows while the error keeps decreasing. Note that the memory stores only the 16% of the newly seen examples. To cope with the error variance increase when the remaining set of samples decreases in size we average results over 100 runs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Model Analysis</head><p>In the following we perform ablation studies aimed at highlighting the importance of components in our model. We thoroughly investigate how the model organizes memory by checking what gets written and how it gets decoded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Studies</head><p>We investigate modifications of MANTRA reporting results in Tab. 5 on KITTI. We test the following: (i) without refinement; (ii) without decoder, i.e. reading from memory using encodings but just copying the correspondent future coordinates; (iii) without rotation invariance, i.e. using trajectories with random rotations; (iv) without memory controller, i.e. adding all training samples in memory; (v) without encoder-decoder, i.e. a Nearest Neighbor between past trajectory coordinates copying the future of the closest sample in coordinate space. On the one hand, when the memory is filled with all training samples instead of selecting them with a controller, the error drastically increases; on the other hand even worse results are obtained when the samples are not encoded and decoded with the recurrent GRU layers. Even removing just the decoder lowers the precision of predictions considerably. This should not come as a surprise, since the decoder has the important role of adapting the suggested future from memory to the current sample, making it coherent with its past. Surprisingly enough instead, the  <ref type="table">Table 5</ref>. Ablation study of the full method against variants without specific components: decoder, refinement, rotation invariance, trained controller, encoder-decoder. Errors are at K=5. Memory size is shown as number of samples and % of the training set. <ref type="figure">Figure 6</ref>. Decoded trajectories from memory. refinement module does not play a very important role in the reconstruction, suggesting that the originally generated trajectories are already precise. Rotation invariance proves to be very relevant in moderating memory size and improving accuracy. By adding rotation invariance to training we lower the memory size from the 25.2% to the 2.2% of the observed training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Memory inspection</head><p>To understand what the model is learning, we inspect what the controller stores in memory. We take each sample and plot its decoded future to depict a snapshot of every sample in memory. <ref type="figure">Fig. 6</ref> shows all samples from a memory filled for K=5 predictions.</p><p>In <ref type="figure" target="#fig_5">Fig. 7</ref> we plot T-SNE projections <ref type="bibr" target="#b31">[32]</ref> of past and future encodings in memory, as points. On the left we plot past embeddings, while on the right we report future embeddings. For each projected sample we show future trajectories generated by the decoder, displayed starting from T-SNE points. All trajectories in the image have an upward trend due to the rotation invariance we introduce for storing samples. Similar trajectories are clustered together, indicating that the encoders are learning a manifold where similar patterns are close. Observing the T-SNE of past encodings, the multimodal nature of the problem emerges. In fact, the space appears to be organized mostly by trajectory speed and for each point several possible future directions are present. When trajectories have lower speed, futures are free to span over many possible directions, while when trajectories have higher speed, the futures vary more in length rather than curvature.</p><p>Decoder Analysis We inspect the behavior of the decoder and the influence that different pasts have on future reconstructions. Encoder and decoder are jointly trained, but differently from standard autoencoders, only part of the input  is reconstructed, i.e. the future. The past has the important role of conditioning the reconstruction so that we can generalize to unseen examples. In <ref type="figure" target="#fig_6">Fig. 8</ref> we show several reconstructions of the same future, changing only the past encoding and keeping fixed the future one. The reconstructions of the original past yields a precise reconstruction. By changing the past by shortening it or stretching it, i.e. changing the velocity, the reconstruction gets accelerated or decelerated, affecting curvature. As a control experiment we also use a vector of zeros or a random embedding. In both cases the generated trajectories are very imprecise but still follow approximately the original trend. These tests justify using the decoder feeding a combination of encodings belonging to different samples, as we do at test time. In fact the generated trajectories are new compared to the samples in memory and they adapt to the current observation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We propose MANTRA, the first Memory Augmented Neural TRAjectory prediction framework. Our method, based on an associative memory, can natively grasp the inherently multi-modal nature of the future trajectory prediction problem, yielding state of the art results on three traffic datasets. Moreover, we show that the memory is able to ingest novel samples lowering the error on unseen data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Pedestrian Trajectory Prediction</head><p>We analyze the capabilities of the method to predict trajectories of pedestrians, which usually require an explicit modeling of social behaviors.</p><p>We exploit the most used datasets in literature for social trajectory prediction, namely ETH/UCY <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b36">37]</ref> and Stanford Drones Dataset (SDD) <ref type="bibr" target="#b41">[42]</ref>.</p><p>ETH <ref type="bibr" target="#b36">[37]</ref> and UCY <ref type="bibr" target="#b25">[26]</ref> are top-view datasets of pedestrians, with trajectories expressed in meters at 2.5Hz. The dataset has 5 different scenarios. In particular, ETH contains two scenarios (ETH, HOTEL) and UCY contains three additional ones (UNIV, ZARA1, ZARA2). In total there are 1536 unique pedestrians exhibiting social interactions such as group actions, collision avoidance and crossing trajectories. We use a leave-one-out strategy, following the state of the art.</p><p>SDD <ref type="bibr" target="#b41">[42]</ref> is a dataset of agents roaming in a university campus. Trajectories are acquired via a bird's eye view drone at a sampling frequency of 2.5 Hz. We use the split of Trajnet <ref type="bibr" target="#b42">[43]</ref>. The dataset contain 14k scenarios with multiple pedestrians. Trajectories are expressed in pixel coordinates.</p><p>In Tab. 8 and Tab. 7 we show the results on SDD, respectively for K=5 and K=20 predictions. In Tab. 6 we report results on ETH/UCY for K=20 predictions. Several baselines are reported for both datasets.</p><p>Overall, it can be seen that MANTRA is able to compete against recent methods that explicitly train a social interaction module to predict pedestrian trajectories. Interestingly, MANTRA outperforms baselines such as Social-GAN <ref type="bibr" target="#b16">[17]</ref> which has a generative model to output socially acceptable trajectories of multiple interacting pedestrians. Even compared to more recent approaches, such as goal-based method <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b33">34]</ref>, MANTRA is able to obtain comparable results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method ADE FDE</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Architecture of MANTRA. The encoding of an observed past trajectory is used as key to read likely future encodings from memory. A multimodal prediction is obtained by decoding each future encoding, conditioned by the observed past. The surrounding context is processed by a CNN and fed to the Refinement Module to adjust predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Representation learning: past and future trajectories are encoded separately; a decoder reconstructs future trajectory only.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>MANTRA compared to Linear regression (a) and Kalman filter (b). Methods (a),(b) lack multi-modal capability. Past trajectories are depicted in blue, ground truth in green and future predictions are cyan (a), purple (b) and red (c). In (c) highly ranked are darker.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Online setting. Mean and variance of memory growth (left) and error rate (right) averaged over 100 runs, increasing the observed samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>T-SNE representations of past (left) and future (right) encodings stored in memory. Each point in the embedding space is shown along with the decoded trajectory. Trajectories are color coded by orientation (green tones) and speed (red tones).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Influence of past in the decoder. (a) observed past; (b) slower past; (c) faster past; (d) past embedding zeroed; (e) multiple randomized past embeddings. Blue: past trajectory used for decoding. Red: future reconstruction. Green: original future.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>.54 0.93 1.4 0.46 1.18 2.18 3.32 Linear 0.31 0.56 0.89 1.28 0.47 1.13 1.94 2.87 MLP 0.30 0.54 0.88 1.28 0.46 1.12 1.94 2.88</figDesc><table><row><cell></cell><cell></cell><cell>ADE</cell><cell></cell><cell></cell><cell></cell><cell>FDE</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>1s</cell><cell>2s</cell><cell>3s</cell><cell>4s</cell><cell>1s</cell><cell>2s</cell><cell>3s</cell><cell>4s</cell></row><row><cell cols="5">Kalman 0.33 0RNN Enc-Dec [50] 0.68 1.94 3.20 4.46</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Markov [47]</cell><cell cols="4">0.70 1.41 2.12 2.99</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="5">Conv-LSTM (top 5) [47] 0.76 1.23 1.60 1.96</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>INFER (top 1) [47]</cell><cell cols="8">0.75 0.95 1.13 1.42 1.01 1.26 1.76 2.67</cell></row><row><cell>INFER (top 5) [47]</cell><cell cols="8">0.56 0.75 0.93 1.22 0.81 1.08 1.55 2.46</cell></row><row><cell>MANTRA (top 1)</cell><cell cols="8">0.37 0.67 1.07 1.55 0.60 1.33 2.32 3.50</cell></row><row><cell>MANTRA (top 5)</cell><cell cols="8">0.33 0.48 0.66 0.90 0.45 0.78 1.22 2.03</cell></row><row><cell>MANTRA (top 10)</cell><cell cols="8">0.31 0.43 0.57 0.78 0.43 0.67 1.04 1.78</cell></row><row><cell>MANTRA (top 20)</cell><cell cols="8">0.29 0.41 0.55 0.74 0.41 0.64 1.00 1.68</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Results on the KITTI dataset (INFER split).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Results on the Oxford RobotCar dataset.</figDesc><table><row><cell>Method</cell><cell cols="2">ADE FDE</cell></row><row><cell cols="2">Conv-LSTM (top 1) [47] 1.50</cell><cell>-</cell></row><row><cell cols="2">Conv-LSTM (top 3) [47] 1.36</cell><cell>-</cell></row><row><cell cols="2">Conv-LSTM (top 5) [47] 1.28</cell><cell>-</cell></row><row><cell>INFER (top 1) [47]</cell><cell cols="2">1.11 1.59</cell></row><row><cell>INFER (top 3) [47]</cell><cell cols="2">0.99 1.45</cell></row><row><cell>INFER (top 5) [47]</cell><cell cols="2">0.91 1.38</cell></row><row><cell>MANTRA (top 1)</cell><cell cols="2">0.81 1.42</cell></row><row><cell>MANTRA (top 3)</cell><cell cols="2">0.66 1.15</cell></row><row><cell>MANTRA (top 5)</cell><cell cols="2">0.60 1.00</cell></row><row><cell>MANTRA (top 10)</cell><cell cols="2">0.54 0.86</cell></row><row><cell>MANTRA (top 20)</cell><cell cols="2">0.49 0.79</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>rot. inv. 0.25 0.51 0.88 1.38 0.45 1.09 2.10 3.58 2170 (25.2 %) MANTRA w/o ctrl. 0.20 0.45 0.82 1.34 0.37 1.02 2.07 3.64 8613 (100 %) MANTRA w/o enc-dec. 0.24 0.58 1.08 1.75 0.47 1.36 2.74 4.68 8613 (100 %)</figDesc><table><row><cell></cell><cell></cell><cell>ADE</cell><cell></cell><cell></cell><cell></cell><cell>FDE</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>1s</cell><cell>2s</cell><cell>3s</cell><cell>4s</cell><cell>1s</cell><cell>2s</cell><cell>3s</cell><cell>4s</cell><cell>Memory Size</cell></row><row><cell>MANTRA (top 5)</cell><cell cols="8">0.17 0.36 0.61 0.94 0.30 0.75 1.43 2.48</cell><cell>190 (2.2 %)</cell></row><row><cell>MANTRA w/o ref.</cell><cell cols="8">0.18 0.39 0.67 1.04 0.33 0.85 1.59 2.65</cell><cell>190 (2.2 %)</cell></row><row><cell>MANTRA w/o dec.</cell><cell cols="8">0.25 0.46 0.76 1.18 0.42 0.91 1.75 3.12</cell><cell>190 (2.2 %)</cell></row><row><cell>MANTRA w/o</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>GAN [17] 0.81/1.52 0.72/1.61 0.60/1.26 0.34/0.69 0.42/0.84 0.58/1.18 SoPhie [44] 0.70/1.43 0.76/1.67 0.54/1.24 0.30/0.63 0.38/0.78 0.54/1.15 CGNS [27] 0.62/1.40 0.70/0.93 0.48/1.22 0.32/0.59 0.35/0.71 0.49/0.97 S-BiGAT [22] 0.69/1.29 0.49/1.01 0.55/1.32 0.30/0.62 0.36/0.75 0.48/1.00 MATF [56] 1.01/1.75 0.43/0.80 0.44/0.91 0.26/0.45 0.26/0.57 0.48/0.90 GOAL-GAN [11] 0.59/1.18 0.19/0.35 0.60/1.19 0.43/0.87 0.32/0.65 0.43/0.85 Transformer [15] 0.61/1.12 0.18/0.30 0.35/0.65 0.22/0.38 0.17/0.32 0.31/0.55 PECNet [34] 0.54/0.87 0.18/0.24 0.35/0.60 0.22/0.39 0.17/0.30 0.29/0.48 Trajectron++ [45] 0.39/0.83 0.12/0.19 0.22/0.43 0.17/0.32 0.12/0.25 0.20/0.40 MANTRA 0.48/0.88 0.17/0.33 0.37/0.81 0.27/0.58 0.30/0.67 0.32/0.65 Table 6. Results on the ETH/UCY datasets. Each model generates K=20 multiple predictions. Errors are expressed in meters.</figDesc><table><row><cell>ETH</cell><cell>HOTEL</cell><cell>UNIV</cell><cell>ZARA1</cell><cell>ZARA2 AVERAGE</cell></row><row><cell>Social-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 .Table 8 .</head><label>78</label><figDesc>Results on SDD for K=20 predictions. Errors are expressed in pixels. Results on SDD for K=5 predictions. Errors are expressed in pixels.</figDesc><table><row><cell cols="2">Social-GAN [17] 27.25 41.44</cell></row><row><cell>CGNS [27]</cell><cell>15.60 28.20</cell></row><row><cell>SoPhie [44]</cell><cell>16.27 29.38</cell></row><row><cell>CF-VAE [2]</cell><cell>12.60 22.30</cell></row><row><cell>P2TIRL [13]</cell><cell>12.58 22.07</cell></row><row><cell>Goal-GAN [11]</cell><cell>12.20 22.10</cell></row><row><cell>SimAug [28]</cell><cell>10.27 19.71</cell></row><row><cell>PECNet [34]</cell><cell>9.96 15.88</cell></row><row><cell>MANTRA</cell><cell>8.96 17.76</cell></row><row><cell>Method</cell><cell>ADE FDE</cell></row><row><cell>DESIRE [25]</cell><cell>19.25 34.05</cell></row><row><cell cols="2">Ridel et al. [41] 14.92 27.97</cell></row><row><cell>PECNet [34]</cell><cell>12.79 25.98</cell></row><row><cell>TNT [55]</cell><cell>12.23 21.16</cell></row><row><cell>MANTRA</cell><cell>13.51 27.34</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments We thank NVIDIA for donating a Titan Xp GPU. This work is partially founded by IMRA Europe S.A.S.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social lstm: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kratarth</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="961" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Conditional flow variational autoencoders for structured sequence prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apratim</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hanselmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph-Nikolas</forename><surname>Straehle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">End to end learning for self-driving cars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariusz</forename><surname>Bojarski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><forename type="middle">Del</forename><surname>Testa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dworakowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Firner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beat</forename><surname>Flepp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasoon</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathew</forename><surname>Jackel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urs</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiakai</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.07316</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Memory matching networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingwei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenggang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4080" to="4088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Multipath: Multiple probabilistic anchor trajectory hypotheses for behavior prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.05449</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Rethinking atrous convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05587</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Drogon: A causal reasoning framework for future trajectory forecast</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiho</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Malla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.00024</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">End-to-end driving via conditional imitation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felipe</forename><surname>Codevilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Miiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Goalgan: Multimodal trajectory prediction based on goal position estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Dendorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljosa</forename><surname>Osep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taixe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asian Conference on Computer Vision (ACCV)</title>
		<meeting>the Asian Conference on Computer Vision (ACCV)</meeting>
		<imprint>
			<date type="published" when="2020-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-modal trajectory prediction of surrounding vehicles with maneuver based lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nachiket</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1179" to="1184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nachiket</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trivedi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00735</idno>
		<title level="m">Trajectory forecasts in unknown environments conditioned on grid-based plans</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Are we ready for autonomous driving? the kitti vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3354" to="3361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Transformer networks for trajectory forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Giuliari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irtiza</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Galasso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.08111</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
		<title level="m">Neural turing machines</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Social force model for pedestrian dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Molnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">4282</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03129</idno>
		<title level="m">Learning to remember rare events</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A new approach to linear filtering and prediction problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolph</forename><forename type="middle">Emil</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalman</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Socialbigat: Multimodal trajectory forecasting using bicycle-gan and graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Martin-Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Imitating driver behavior with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kuefler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykel</forename><surname>Kochenderfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="204" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ask me anything: Dynamic memory networks for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ondruska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1378" to="1387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namhoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="336" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Crowds by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiorgos</forename><surname>Chrysanthou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="655" to="664" />
			<date type="published" when="2007-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Conditional generative neural system for probabilistic trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengbo</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Simaug: Learning robust representations from simulation for trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="275" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Social and scene-aware trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Lisotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Coscia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lamberto</forename><surname>Ballan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Anton van den Hengel, and Ian Reid. Visual question answering with memory-augmented networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6975" to="6984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Trafficpredict: Trajectory prediction for heterogeneous traffic-agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinge</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sibo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruigang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenping</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinesh</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6120" to="6127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">1 year, 1000 km: The oxford robotcar dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Maddern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Pascoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Linegar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karttikeya</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harshayu</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreyas</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan-Hui</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.02025</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>It is not the journey but the destination: Endpoint conditioned trajectory prediction</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amir-Hossein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03126</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">You&apos;ll never walk alone: Modeling social behavior for multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE 12th International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Improving data association by joint modeling of pedestrian trajectories and groupings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Kostas Daniilidis, Petros Maragos, and Nikos Paragios</title>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="452" to="465" />
		</imprint>
	</monogr>
	<note>Computer Vision -ECCV 2010</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Neural episodic control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benigno</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriram</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adria</forename><forename type="middle">Puigdomenech</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Demis</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2827" to="2836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">icarl: Incremental classifier and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Sylvestre-Alvise Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Sperl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Precog: Prediction conditioned on goals in visual multi-agent settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2821" to="2830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Scene compliant trajectory forecast with agent-centric spatio-temporal grids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ridel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2816" to="2823" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning social etiquette: Human trajectory understanding in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2016</title>
		<editor>Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="549" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Trajnet: Towards a benchmark for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noriaki</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1349" to="1358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Trajectron++: Multi-agent generative trajectory forecasting with heterogeneous data for control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Punarjay</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pavone</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.03093</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Meta-learning with memory-augmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Infer: Intermediate representations for future prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Srikanth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Junaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarthak</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Endto-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Using deep learning to predict obstacle trajectories for collision avoidance in autonomous vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaskaran</forename><surname>Virdi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>UC San Diego</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.3916</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Memory networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Endto-end learning of driving models from large-scale video datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huazhe</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2174" to="2182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Few-shot object recognition from machine-labeled web images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongwen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1164" to="1172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning dynamic memory networks for object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="152" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Tnt: Target-driven trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congcong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<idno>abs/2008.08294</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathew</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying Nian</forename><surname>Wu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Multi-agent tensor fusion for contextual trajectory prediction</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12126" to="12134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Naturalistic driver intention and path prediction using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Zyner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stewart</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Nebot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
