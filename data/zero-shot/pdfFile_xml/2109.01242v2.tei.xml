<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Entity Linking and Discovery via Arborescence-based Supervised Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Agarwal</surname></persName>
							<email>dagarwal@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Angell</surname></persName>
							<email>rangell@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Monath</surname></persName>
							<email>nmonath@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
							<email>mccallum@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Entity Linking and Discovery via Arborescence-based Supervised Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Previous work has shown promising results in performing entity linking by measuring not only the affinities between mentions and entities but also those amongst mentions. In this paper, we present novel training and inference procedures that fully utilize mention-tomention affinities by building minimum arborescences (i.e., directed spanning trees) over mentions and entities across documents in order to make linking decisions. We also show that this method gracefully extends to entity discovery, enabling the clustering of mentions that do not have an associated entity in the knowledge-base. We evaluate our approach on the Zero-Shot Entity Linking dataset and MedMentions, the largest publicly available biomedical dataset, and show significant improvements in performance for both entity linking and discovery compared to identically parameterized models. We further show significant efficiency improvements with only a small loss in accuracy over previous work, which use more computationally expensive models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Entities are often mentioned ambiguously in natural language corpora, such as biomedical research papers <ref type="bibr" target="#b31">(Leaman and Lu, 2016;</ref><ref type="bibr" target="#b46">Sung et al., 2020)</ref> , news <ref type="bibr" target="#b37">(Milne and Witten, 2008;</ref><ref type="bibr" target="#b22">Hoffart et al., 2011)</ref>, and web page text <ref type="bibr" target="#b16">(Gabrilovich et al., 2013;</ref><ref type="bibr" target="#b29">Lazic et al., 2015)</ref>. Resolving the ambiguity of these entity mentions requires either linking each mention to a knowledge-base (KB) or, if there is no suitable KB entry, adding a new entity to the KB. The latter task, entity discovery, is often done by discovering coreference relationships among mentions and providing each coreferent mention an identifier that represents the newly added entity <ref type="bibr" target="#b36">(McNamee and Dang, 2009;</ref><ref type="bibr" target="#b42">Radford et al., 2011)</ref>. Linking and discovery are important for question answering <ref type="bibr" target="#b12">(Das et al., 2019)</ref> and building KBs <ref type="bibr" target="#b33">(Ling et al., 2015)</ref> or semantic indexes <ref type="bibr" target="#b31">(Leaman and Lu, 2016)</ref>. <ref type="bibr">'</ref>Post-acute COVID' (known colloquially as 'long COVID') is emerging as a prevalent syndrome. It encompasses a plethora of debilitating symptoms (including breathlessness, chest pain, palpitations and orthostatic intolerance) which can last for weeks or more following mild illness. We describe a series of individuals with symptoms of 'long COVID', and we posit that this condition may be related to a virus-or immune-mediated disruption of the autonomic nervous system resulting in orthostatic intolerance syndromes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C1535893</head><p>Orthostatic intolerance</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C0008031</head><p>Chest Pain</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>New Entity</head><p>Long COVID Entity KB <ref type="figure">Figure 1</ref>: Linking &amp; Discovery. We consider the task of both entity linking and discovery (also known as NIL clustering), in which ambiguous mentions are either ground to existing KB entities or form new ones.</p><p>Entity linking is particularly challenging in zeroshot settings, where not every entity has labeled training data <ref type="bibr" target="#b32">(Lin et al., 2017;</ref><ref type="bibr" target="#b35">Logeswaran et al., 2019)</ref>. In such settings, we rely on entity descriptions, types, and aliases to form entity representations, which are used for linking predictions.</p><p>Entity linking and coreference are closely related, with linking decisions implying coreference relationships amongst mentions <ref type="bibr" target="#b14">(Dutta and Weikum, 2015a)</ref>. Recent work <ref type="bibr" target="#b1">(Angell et al., 2021)</ref> has demonstrated how a clustering-based approach for entity linking prediction can share linking decisions by predicting coreference between mentions. This approach, however, uses cross-encoder based transformer models , which are prohibitively expensive when it comes to running in cross-document settings -the number of input sequences passed through the transformer encoder scales quadratically with the number of mentions. This limits the approach to only consider pairs of mentions within the same document when computing mention-to-mention affinities.</p><p>Inspired by this recent work on clustering-based inference, we present a new model for clustering that uses a graph-based approach of modeling directed nearest-neighbor relationships among men-tions in an arboresence (directed minimum spanning tree). We demonstrate how this approach uses a bi-encoder  in order to be significantly more efficient. To complement this, we propose a supervised clustering training objective motivated by our inference procedure. We further show how our model can be used as a unified approach for both linking entities as well as discovering them.</p><p>We evaluate our approach on two entity linking datasets, both of which are in the zero-shot domain. We compare the performance of our training procedure against two standard bi-encoder training procedures using both independent inference (linking each mention individually) and clusteringbased inference. We find that our training improves performance by 13.1 percentage points on Med-Mentions and 11.1 &amp; 0.6 points on the two training variants compared on ZeShEL. In addition, we run experiments for entity discovery by removing a fraction of entities from the KB and demonstrate that our training and inference procedures are better suited for this task. Compared to cross-encoder based approaches, our bi-encoder approach is more that two times more efficient with only a small loss in accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Definition</head><p>Each document d of a corpus D contains a set of entity mention spans M d = {m d 1 , m d 2 , . . . , m d N }. All mentions in the corpus are given by M = d?D M d . Following <ref type="bibr" target="#b35">(Logeswaran et al., 2019;</ref><ref type="bibr" target="#b1">Angell et al., 2021)</ref>, we assume that these mentions are pre-identified spans of text.</p><p>Entity Linking We first consider the task of entity linking in which we are provided a knowledgebase of entities E and our task is to predict an entity e d i ? E for each mention m d i . We use e d i to refer to the ground truth entity label for m d i . Zero-Shot Linking The zero-shot task refers to the setting where there are entities in the knowledge base that do not have any labeled training data. Linking decisions must, instead, rely on provided information for entities such as a description, aliases, and/or the entity type.</p><p>Linking + Discovery We also consider a setting in which the complete knowledge-base of entities may not be known in advance and new entities must be discovered. For this task, we assign every entity mention m d i a cluster/coreference label c d i ? C that is independent of the entity labels in the KB, i.e. C ? E = ?. In this setting, a mention m d i may be assigned e d i = NIL, indicating that m d i refers to an entity not present in the knowledge-base. Non-NIL assignment decisions imply coreference between mentions.</p><p>It is important to note the distinctions between zero-shot linking and discovery. In the zero-shot setting, entities are known in the KB ahead of time, but there is no training data. In the discovery setting, we do not know all the entities a priori, and our performance, then, is evaluated in terms of the correctness of clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Linking &amp; Discovering Entities with</head><p>Graph-Based Clustering</p><p>In this section, we describe our proposed approach for making entity linking and discovery decisions.</p><p>We define a distance measure between mentions and entities in terms of a directed graph, where nodes refer to both mentions as well as entities, and the edges are inferred by the model. Clusters are then constructed from this graph such that no cluster contains more than one entity. Linking decisions are made by assigning each mention within a cluster to the entity node present within the same cluster. In this way, clusters represent new (discovered) entities if a set of mentions is clustered without an entity node. Our approach generalizes the clustering-based approach of <ref type="bibr" target="#b1">Angell et al. (2021)</ref> by <ref type="formula" target="#formula_0">(1)</ref> proposing a clustering approach on directed graphs (2) using all mentions in the corpus rather than operating in a within-document setting.</p><p>There are four main components to our approach: (1) graph-based dissimilarity measure, (2) models to provide edge weights, (3) approach for inferring latent graph, and (4) building constrained clusters.</p><p>Graph-based Dissimilarity Let G be a graph with nodes V = M ? E and directed edges E ? V ? V . Each edge (x, y) of the graph has an associated weight w x,y . We define a dissimilarity function f between two nodes u, v ? V to be the weight of the minimax path between the nodes, i.e.</p><formula xml:id="formula_0">f (u, v) = min p?u v max (x,y)?p wx,y, if connected(u, v) ?, otherwise<label>(1)</label></formula><p>where connected(u, v) is true if there exists a directed path from node u to v in G, and u v is the set of all paths between u and v. In words, the dissimilarity between u and v is the minimum of the highest weight edges in all paths between the two nodes, and this is often referred to as the "bottleneck edge". This measure has the property of emitting low dissimilarities between nodes even when the direct edge weight w u,v is high by connecting them through a chain of low-weight edges providing an inductive bias well-suited for coreference, i.e. not all pairs of points in a cluster are nearby, see <ref type="figure" target="#fig_1">Figure 2</ref> for an example. This inductive bias is not achieved if we sum edge weights and simply find the minimum path.</p><p>Edge Weights With this definition of dissimilarity, we now define how edge weights are calculated. We use two models: a mention-pair affinity model, ? : M ? M ? R, and a mention-entity affinity model, ? : E ? M ? R. An edge between two mentions m i and m j has weight:</p><formula xml:id="formula_1">w m i ,m j = ? ?(m i , m j ),<label>(2)</label></formula><p>and the weight of the edge from entity e to m i is:</p><formula xml:id="formula_2">w e,m i = ? ?(e, m i )<label>(3)</label></formula><p>Each of ?(?, ?) and ?(?, ?) are parameterized by biencoder transformer models <ref type="bibr" target="#b18">(Gillick et al., 2019;</ref><ref type="bibr" target="#b23">Humeau et al., 2019)</ref>. We train two independently parameterized transformer encoder models: one for mentions, Enc M , and one for entities, Enc E . The affinity models are simply the inner products of the associated encoded representations:</p><formula xml:id="formula_3">?(m i , m j ) = Enc M (m i ) T Enc M (m j ) ?(e, m i ) = Enc E (e) T Enc M (m i )<label>(4)</label></formula><p>For the mention encoder, Enc M , the input to the transformer is the mention's surrounding context with the mention span marked by special tokens [START] and [END]:</p><formula xml:id="formula_4">[CLS]c left [START]m i [END]c right [SEP]</formula><p>where c left and c right are the left and right contexts of the mention m i in the document. For the entity encoder, Enc E , the transformer takes as input the title and description of the entity:</p><formula xml:id="formula_5">[CLS]e title [TITLE]e desc [SEP]</formula><p>In this input, e desc is the token sequence corresponding to the description of the entity, which could include natural language text related to the entity, such as a "wiki" entry or a list of synonym representations of the entity, or any other available features useful in forming an entity representation.</p><p>Building the Graph The structure of the graph G impacts the dissimilarity function by changing the paths between pairs of nodes in addition to changing which pairs of nodes are connected. We advocate for a simple, deterministic approach to construct this graph. For each mention m, construct E m by (1) adding edges from m's k-nearest neighbor mentions in M to m, and (2) adding an edge from m's nearest entity to m:</p><formula xml:id="formula_6">E m = (u, m) u ? argmink m ? M w m ,m ? u = argmin e ? E w e,m<label>(5)</label></formula><p>The complete collection of edges E in G is given by</p><formula xml:id="formula_7">E(G) = m?M E m .</formula><p>There are other ways that one could conceivably pick the pairs of mentions to be connected in the graph. For example, one could use the minimum spanning tree over the mentions. This approach, however, has several drawbacks: (1) the directionality of nearest neighbor relationships is ignored leading to added noise in the graph, and (2) the resultant graph includes edges that clearly cross cluster boundaries due to this approach forcing all pairs of mentions to be connected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Forming Clusters &amp; Making Predictions</head><p>The graph G is input to a constrained clustering problem that partitions G into disjoint clusters C = {C 1 , . . . , C M } such that each cluster contains at most one entity. There are three constraints that every C ? C must satisfy:</p><formula xml:id="formula_8">i. |C ? E| ? 1, ii. ?u, v ? C, connected(u, v) =? f (u, v) ? ?, iii. ?u, v ? C, connected(u, v) ? connected(v, u)</formula><p>where ? is a specified hyperparameter representing the dissimilarity threshold. These constraints ensure that (i) there is at most one entity in each cluster, (ii) if u is reachable from v then every edge in the path from v to u has a weight ? ?, and (iii) each node in the cluster has a path connecting it with every other node in the cluster. We solve this constrained clustering problem, i.e., partition graph G, using a process similar to <ref type="bibr" target="#b1">Angell et al. (2021)</ref>. Specifically, we first remove all edges in graph G with weight greater than ?. We then evaluate each edge (u, v) ? E in descending order of dissimilarity and check if its presence violates any of the three constraints defined above, removing the edge from E if it does. If not, we evaluate whether there is an entity in the connected component of node u, i.e. |C u ? E| = 1. We infer that C u refers to a new entity not present in the KB if an entity is not found. If, however, |C u ? E| = 1, we temporarily drop edge (u, v) and check whether v can still be reached by an entity node. If reachable, we permanently drop (u, v), maintaining the validity of constraint (i) as well as our minimax dissimilarity function f (?, ?). If an entity cannot reach v, we retain edge (u, v), preserving the connectivity of the cluster, and iterate further. Our predicted clusters are the resultant connected components in the partitioned graph G. We refer to this procedure as directed inference when we respect the direction of the edges and undirected inference when we disregard the direction (see <ref type="figure" target="#fig_1">Figure 2</ref>).</p><p>To make linking decisions for each mention m d i , we assign the ID of the entity present in the mention's cluster as the linking label (or NIL if there is no entity in the cluster). Let C(m d i ) be the predicted cluster of mention m d i , then:</p><formula xml:id="formula_9">e d i = C(m d i ) ? E, if |C(m d i ) ? E| = 1 NIL, otherwise .<label>(6)</label></formula><p>Furthermore, the clusters we predict for in the entity discovery setting are exactly C.</p><p>Cluster Spanning Arborescence For every cluster with an entity node, the edge structure is a directed analogue of the minimum spanning tree where there is a directed path from the entity node to every other node in the cluster. This structure is often referred to as the minimum spanning arborescence, thus lending its name to our method, i.e. ARBORESCENCE-BASED linking and discovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Training</head><p>In this section, we present our approach for training the affinity models, ?(?, ?) and ?(?, ?), and their associated encoders, Enc M and Enc E . Our objective is to optimize the dissimilarity function f (?, ?) such that the clustering procedure infers a set of clusters that each contains exactly one entity, and every mention is assigned to the cluster containing its ground truth entity. We optimize f (?, ?) using mini-batch gradient descent methods. To achieve this, we sequentially build mini-batches of mentions B ? M over the training data, where each m i ? B has ground truth entity e i . We then build a graph G B , where the nodes are all m i ? B, all mentions coreferent to m i ? B, and the set of ground truth entities for each m i ? B.</p><p>For each m i , we build a set of edges,</p><formula xml:id="formula_10">E m i = (e i , m ) m ? M e i ? (m , m p ) m , m p ? M e i<label>(7)</label></formula><p>The complete set of edges in graph G B for a minibatch B is then given by</p><formula xml:id="formula_11">E(G B ) = m i ?B E m i .</formula><p>Observe that the resultant edges ensure that each connected component contains exactly one entity (namely, the ground truth entity for the mentions in that component). We then sparsify G B by computing a partitioned target graph G B = {E m i | m i ? B} using the inference procedure defined in the previous section, setting ? = ?. After this sparsification, G B becomes a disjoint set of minimum spanning arborescences rooted at the entity nodes.</p><p>We use E m i to optimize the parametric encoder models. Note that each mention node in a target edge set E m i has only one incoming edge originating from either an entity or a mention, and the selection of E m i was done in a way to minimize f (?, ?) between mentions and entities with the same label (maximize opposite labels) on the subgraph of the mini-batch. Akin to the graph embedding objectives used by <ref type="bibr" target="#b39">Nickel and Kiela (2018)</ref> and others, we construct our objective by sampling negative edges. For each mention m i ? B, the set of negative edges N(m i ) is the k/2 lowest-weight incoming edges from E \ {e i } and the k/2 lowest-weight incoming edges from M \ M e i , where k is a specified hyperparameter. Take ?(m</p><formula xml:id="formula_12">i ) = {u | (u, m i ) ? E * m i } ? {u | (u, m i ) ? N(m i )}</formula><p>to be the set of all neighbors with an outgoing edge to m i in the training graph. Let I u,m i be the indicator variable such that I u,m i = 1 if (u, m i ) ? E * m i and I u,m i = 0 otherwise. Our loss function with respect to each mention m i ? B is as follows:</p><formula xml:id="formula_13">L(m i ) = u??(m i ) I u,m i log(? u (w u,m i ))<label>(8)</label></formula><formula xml:id="formula_14">+ (1 ? I u,m i ) log(1 ? ? u (w u,m i )) ,</formula><p>where ?(?) is the softmax function over all edges in ?(m i ) ? {m i }. The loss for the entire batch B is the mean of losses over all mentions in B. Optimizing this loss function requires simultaneously increasing the likelihood of the positive edges and decreasing the likelihood of the negative edges. This objective and training routine are inspired by the supervised single-linkage clustering proposed by <ref type="bibr" target="#b49">Yadav et al. (2019)</ref>, but differs in the choice of loss function and selection of negative examples. We also experimented with the standard cross-entropy loss, but found its performance subpar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We perform entity linking and discovery experiments using two datasets that require generalization to unseen entities at test time <ref type="table" target="#tab_4">(Table 4)</ref>. We analyze the improvements using our proposed approach as compared to similarly parameterized bi-encoder methods. We provide an analysis of the performance of each component of our approach, comparing our proposed graph clustering and training objective to sensible baselines, and show that our model has much higher accuracy while being as efficient as these baselines. We further compare our approach to a state-of-the-art cross-encoder method and show that our approach produces comparable accuracy results while being much more efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>MedMentions (Mohan and Li, 2019) 1 is a collection of titles and abstractions of bio-medical research papers. The KB that is used for this dataset is the 2017AA full-version of UMLS. The validation and test sets contain both entities that are present in the training set as well as entities that are zero-shot (never seen at training time). We use the author-recommended ST21pv subset.</p><p>ZeShEL <ref type="bibr" target="#b35">(Logeswaran et al., 2019</ref>) is a collection of Fandom Wikias. The Wikias are divided into train / dev / test splits, with no set overlapping in entities. In this way, all entities that appear at validation and test time are not seen during training.</p><p>Entity Discovery For this setting, we modify each dataset by randomly sampling 10% of the entities in the dev and test partitions, and remove them from the knowledge-base. These removals are the new entities that we attempt to discover in this task. To our knowledge, other ED systems include <ref type="bibr" target="#b0">(Andrews et al., 2014)</ref>, <ref type="bibr" target="#b15">(Dutta and Weikum, 2015b)</ref>, <ref type="bibr" target="#b41">(Pershina et al., 2015)</ref>. However, incorporating BERT-based encoder models in these approaches is not straightforward, therefore a comparison was outside the scope of this work.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MedMentions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Methods Compared</head><p>We analyze our proposed approach through comparisons with various sensible alternatives for graph clustering and training.</p><p>Training Objectives We compare the proposed graph-based training objective, which directly trains both the mention-mention similarity function ?(?, ?) and the mention-entity similarity function ?(?, ?) to baselines, which only explicitly train ?(?, ?) (and rely on the structure of ?(?, ?) sharing representions with ?(?, ?) to provide meaningful mention-mention similarities). We compare to two baselines: (1) training ?(?, ?) with random negatives (IN-BATCH) and (2) training ?(?, ?) with hard negatives (K-NN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linking Procedures</head><p>We compare our proposed clustering-based inference procedure to a state-ofthe-art independent procedure (INDEPENDENT), which directly links each mention to its nearest entity. This model was used by <ref type="bibr" target="#b48">Wu et al. (2020)</ref> to generate candidates for a cross-encoder model trained on ZeShEL. We further compare our approach to using undirected rather than directed edges in the graph clustering step.</p><p>Cross-Encoder Models / SOTA To measure how much we pay in accuracy to use these more efficient bi-encoder models vis-?-vis cross-encoder models, we compare our performance to the stateof-the-art cross-encoder based model that uses clustering-based inference as that is most directly comparable to our method. <ref type="bibr" target="#b1">Angell et al. (2021)</ref> train two cross-encoder models, one for mentionmention affinities and one for mention-entity affinities, and use an inference procedure equivalent to our undirected clustering-based inference. The cross-encoder procedure they use necessitates limiting the potential mention-mention and mentionentity edges in the graph used for clustering since it is intractable to consider all pairs, while our method requires no such restriction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Linking Results</head><p>We report the linking accuracy on MedMentions and ZeShEL in <ref type="table">Table 1</ref>. We refer to our training procedure as ARBORESCENCE-BASED, and show comparisons in performance of our model with IN-BATCH NEGATIVES and K-NN NEGATIVES, as described in the previous section. We use three inference procedures, including our clustering-based approach in both DIRECTED and UNDIRECTED modes. We report test set accuracy at k that performed best on the validation set.</p><p>MedMentions We follow previous work in not supplying gold entity type information during inference. This makes the task significantly more challenging. In addition to reporting the overall linking accuracy, we measure the accuracy on Seen and Unseen subsets, which correspond to the ground truth entities that were seen and unseen (i.e., zero-shot) at training, respectively.</p><p>In <ref type="table">Table 1</ref>, we observe that regardless of the chosen inference, the ARBORESCENCE-BASED model significantly outperforms the other models   by at least 13.1 points in terms of overall accuracy, 13.5 points on Seen, and 4.4 points on Unseen mentions. We further see that UNDIRECTED clustering marginally outperforms the DIRECTED variant in the three categories by 0.1, 0.1, and 0.5 points, respectively. In <ref type="table" target="#tab_1">Table 2</ref>, we report Re-call@64, defined as the accuracy of predicting a gold entity from any of the top-64 predictions for a mention. We see that ARBORESCENCE-BASED achieves 7.93 and 9.78 points of improvement over In-Batch and k-NN models.</p><p>These improvements in accuracy indicate that our training procedure enables the model to learn much better representations of mentions and entities than previous approaches.</p><p>We also compare the efficiency / accuracy tradeoffs between our models and <ref type="bibr" target="#b1">Angell et al. (2021)</ref>. <ref type="table" target="#tab_6">Table 5</ref> shows the training time, inference time, and accuracy for all training and inference procedures considered on MedMentions. In less than half of the training and inference time, without any external information or preprocessing, and a much weaker architecture, our method is able to achieve accuracy within 2 points of the SOTA cross-encoder model. This highlights the effectiveness of our approach in producing a highly accurate, yet efficient, model.</p><p>ZeShEL On this dataset, we evaluate assuming gold entity type information is provided at both training and inference time. Since entities in the validation and test sets are from domains different than those in the test set, our evaluation is fully zero-shot.</p><p>In <ref type="table" target="#tab_1">Table 2</ref>, we show that the ARBORESCENCE-BASED model achieves better Recall@64 by 1.07 points and 0.34 points over In-batch and k-NN, respectively. In <ref type="table">Table 1</ref>, we present accuracy results, which prior work using bi-encoder models, to the best of our knowledge, does not report. We see that the ARBORESCENCE-BASED model is more accurate than the In-batch and k-NN models by 11.1 and 0.6 points of accuracy, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Entity Discovery Results</head><p>In this setting, we evaluate the predicted clusters of our proposed approach on a modified test set for MedMentions and ZeShEL by removing 10% of the entities appearing in the test data from the knowledge-base and training new models with the held-out entities removed during training. We report performance in terms of two frequently-used clustering metrics -normalized mutual information (NMI) and adjusted rand index (ARI) -in <ref type="table" target="#tab_3">Table 3</ref>. We compare the graph clustering-based inference procedures, which utilize entity information, to one that only uses the mention-mention similarities. We select the hyperparameters, k and ?, on the dev set.</p><p>The results indicate that the ARBORESCENCE-BASED training procedure achieves significantly better ARI score compared to the In-batch Negatives training on both datasets (10 points on Med-Mentions and 5 points on ZeShEL). The represen-  <ref type="bibr">(Ours)</ref> 32.1 k-NN Graph (UNDIRECTED) 1.6 72.3 k-NN Graph <ref type="bibr">(DIRECTED)</ref> 1.6 72.2 CLUSTERING-BASED <ref type="bibr" target="#b1">(Angell et al., 2021)</ref> 72.0 k-NN Graph (UNDIRECTED) 4.0 74.1 tations from our proposed training procedure seem to provide more meaningful clusters of mentions than simply taking the layer before the softmax of a trained linking model (i.e., the In-batch and k-NN settings). We hypothesize that the improvements are achieved because the Arboresence-based training is closely aligned with the clustering inference procedure. We further observe that the DI-RECTED approach offers significant improvement over UNDIRECTED on ZeShEL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Experiment Details</head><p>Our experiments are run on top of BLINK <ref type="bibr" target="#b48">(Wu et al., 2020)</ref>, a PyTorch <ref type="bibr" target="#b40">(Paszke et al., 2019)</ref> implementation of the bi-encoder architecture for entity linking. Each training procedure is run on a single machine using 2 NVIDIA Quadro RTX 8000 GPUs. Our models for Zeshel and MedMentions have 218M and 230M parameters, respectively. Each variant of our bi-encoder models is optimized using mini-batch gradient descent using the Adam optimizer for 5 epochs using a mini-batch size of 128 to accumulate the gradients. Experiments with batch sizes &lt; 128 performed poorly possibly due to increased fluctuation of gradients, and sizes &gt; 128 were computationally infeasible to run given our resources. For ZeShEL, each model is trained using 192 warm-up steps and learning rates of 1e-5, 3e-5, and 3e-5 for In-batch, k-NN, and Arborescence-based models, respectively. For MedMentions, each model is trained using 464 warm-up steps and a learning rate of 3e-5. We use FAISS 2 <ref type="bibr" target="#b27">(Johnson et al., 2017)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Entity Linking Entity linking has been widely studied <ref type="bibr" target="#b37">(Milne and Witten, 2008;</ref><ref type="bibr" target="#b11">Cucerzan, 2007;</ref><ref type="bibr" target="#b29">Lazic et al., 2015;</ref><ref type="bibr" target="#b20">Gupta et al., 2017;</ref><ref type="bibr" target="#b43">Raiman and Raiman, 2018;</ref><ref type="bibr" target="#b28">Kolitsas et al., 2018;</ref><ref type="bibr">Cao et al., 2021, inter alia)</ref>. Apart from <ref type="bibr" target="#b1">Angell et al. (2021)</ref>, we note the similarities of our work and that of <ref type="bibr" target="#b14">Dutta and Weikum (2015a)</ref>, which combines clustering-based cross-document coreference decisions and linking. However, <ref type="bibr" target="#b14">Dutta and Weikum (2015a)</ref> is based around using sparse bag-of-word representations and is not well suited for the embedded-based representations used in this work. <ref type="bibr" target="#b22">Hoffart et al. (2011);</ref><ref type="bibr" target="#b8">Cheng and Roth (2013)</ref>; Ganea and Hofmann (2017); <ref type="bibr" target="#b30">Le and Titov (2018)</ref> use global objectives instead of independent predictions, measuring the compatibility of entity links. Contemporaneous work by <ref type="bibr">Jiang et al. (2022)</ref> also explores a joint paradigm by building clusters of mentions and entities in order to solve a maximum spanning tree problem.</p><p>Cross-document Coreference Models have also been developed for the cross-document coreference setting where no entity KB is assumed in advance <ref type="bibr" target="#b2">(Bagga and Baldwin, 1998;</ref><ref type="bibr" target="#b19">Gooi and Allan, 2004;</ref><ref type="bibr" target="#b45">Singh et al., 2011;</ref><ref type="bibr" target="#b3">Barhom et al., 2019;</ref><ref type="bibr" target="#b6">Cattan et al., 2020;</ref><ref type="bibr">Caciularu et al., 2021;</ref><ref type="bibr" target="#b44">Ravenscroft et al., 2021;</ref><ref type="bibr">Logan IV et al., inter alia)</ref>. In future work, one might explore using our proposed approach for entity discovery in these settings to understand room for improvement of such systems using entity KB information.</p><p>Alternatives to Cross-Encoders Our work demonstrates how clustering-based training and prediction improves bi-encoder based models for linking and discovery. If prediction efficiency, and not training efficiency, was the only concern, one could use model distillation <ref type="bibr" target="#b21">(Hinton et al., 2015;</ref><ref type="bibr">Izacard and Grave, 2021, inter alia)</ref>. We could also consider models such as poly-encoders as an alternative to bi-encoders <ref type="bibr" target="#b24">(Humeau et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ultrametric Fitting &amp; Supervised Clustering</head><p>The proposed training objective is related to supervised clustering <ref type="bibr" target="#b49">(Yadav et al., 2019)</ref>. Algorithms for minimizing the minimax path distance is closely related to fitting ultrametrics <ref type="bibr" target="#b9">(Chierchia and Perret, 2019;</ref><ref type="bibr">Cohen-Addad et al., 2020, inter alia)</ref>.</p><p>Loss Augmented Inference Our proposed training objective uses our graph-clustering procedure to determine the loss. This is reminiscent structured prediction approaches such as structured SVMs <ref type="bibr" target="#b47">(Tsochantaridis et al., 2004)</ref>, in which inference is run during training time and the loss is a function of predicted and target structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we presented novel arboresence-based training and inference procedures of bi-encoder models for entity linking and discovery. Our results indicate that our training procedure yields biencoder models which far outperform those models trained with standard procedures on challenging entity linking and entity discovery tasks. Future work includes using cross-encoder models, model distillation, and loss functions for directly optimizing clustering metrics in entity discovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Ethical Considerations</head><p>The base models, which we fine-tuned, and evaluation datasets are all publicly available. We will also make our code and models publicly available. The task of entity resolution and discovery is relatively innocuous. However, there are several ways in which models could be biased and there is the potential for those biases to have harmful downstream consequences. There is a large body of work studying the biases of language models (such as those used for fine-tuning here) and coreference models. Most notably in understanding when error rates in coreference differ across certain populations (e.g., genders, races, or any entity-type more broadly). If entity linking and discovery systems are used to build / populate knowledge-bases, those systems may propagate these biased predictions. This could be particularly problematic if one used such a biased knowledge-base with this realization. For instance, if entity mentions are author names on citation data and the entities are scientific authors, statistics like h-index or citation count could be biased if the algorithms used to disambiguate the author names are biased. Lastly, we note entity linking and discovery are related to surveillance and tracking in computer vision, which bear a substantial weight of ethical considerations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Inference for Entity Linking and Discovery. Mentions are represented by circles and entities by rectangles. The left sub-figure shows the k-nearest neighbor graph over all mentions across all documents and all entities in the knowledge-base. Dashed edges are edges that were dropped since they have edge weights above the threshold ? = 0.4 and solid edges represent the resulting graph, which is input to the inference algorithms. The center sub-figure shows the result of undirected inference and the right figure shows the result of directed inference. In both sub-figures, the dark edges are the edges kept and the light edges are those removed by the inference procedure. Both inference procedures result in one cluster that does not contain an entity, predicting this cluster of mentions as a new discovered KB entity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Bi-Encoder Linking Results: Recall@64</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Bi-Encoder Discovery Results. ( ? Predictions based on mention-to-mention similarity only)</figDesc><table><row><cell></cell><cell></cell><cell cols="2">MedMentions ZeShEL</cell></row><row><cell></cell><cell>Train</cell><cell>120K</cell><cell>49K</cell></row><row><cell>|M|</cell><cell>Dev</cell><cell>40K</cell><cell>10K</cell></row><row><cell></cell><cell>Test</cell><cell>40K</cell><cell>10K</cell></row><row><cell></cell><cell>Train</cell><cell>19K</cell><cell>26K</cell></row><row><cell>|E|</cell><cell>Dev</cell><cell>9K</cell><cell>7K</cell></row><row><cell></cell><cell>Test</cell><cell>8K</cell><cell>7K</cell></row><row><cell>|E \ ETrain|</cell><cell>Dev Test</cell><cell>4K 4K</cell><cell>7K 7K</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Dataset Statistics. |M| is the number of mentions. |E| is the number of unique entities in the labeled partition, not the total KB size. |E \E Train | is the number of zero-shot entities. The total KB size of MedMentions and ZeShEL are 2M and 500K respectively.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Efficiency-Accuracy Trade-Off ( ? Predictions based on entity-to-mention affinity only)</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/chanzuckerberg/ MedMentions</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Nishant Yadav, Sunil Mohan, and members of UMass IESL and NLP groups for helpful discussion and feedback. This work is funded in part by the Center for Data Science and the Center for Intelligent Information Retrieval, and in part by the National Science Foundation under Grants No. 1763618, and in part by the Chan Zuckerberg Initiative under the project Scientific Knowledge Base Construction. The work reported here was supported in part by the Center for Data Science and the Center for Intelligent Information Retrieval, and in part using high performance computing equipment obtained under a grant from the Collaborative R&amp;D Fund managed by the Massachusetts Technology Collaborative. Rico Angell is supported by the National Science Foundation Graduate Research Fellowship under Grant No. 1938059. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust entity clustering via phylogenetic inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="775" to="785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Clusteringbased inference for biomedical entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Angell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Monath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunil</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Entitybased cross-document coreferencing using the vector space model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Breck</forename><surname>Baldwin</surname></persName>
		</author>
		<idno type="DOI">10.3115/980845.980859</idno>
	</analytic>
	<monogr>
		<title level="m">36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="79" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Revisiting joint modeling of cross-document entity and event coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shany</forename><surname>Barhom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Eirew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bugert</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1409</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4179" to="4189" />
		</imprint>
	</monogr>
	<note>Nils Reimers, and Ido Dagan</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avi</forename><surname>Caciularu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Cattan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dagan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00406</idno>
		<imprint/>
	</monogr>
	<note type="report_type">2021. Crossdocument language modeling. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Autoregressive entity retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Streamlining crossdocument coreference resolution: Evaluation and modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><surname>Cattan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Eirew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.11032</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Scico: Hierarchical cross-document coreference for scientific concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><surname>Cattan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophie</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Hope</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08809</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Relational inference for wikification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1787" to="1796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ultrametric fitting by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Chierchia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Perret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08" />
			<biblScope unit="page" from="3175" to="3186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On efficient low distortion ultrametric embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Cohen-Addad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Karthik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lagarde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="2078" to="2088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Large-scale named entity disambiguation based on Wikipedia data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silviu Cucerzan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="708" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-step entity-centric information retrieval for multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameya</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Kavarthapu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Machine Reading for Question Answering</title>
		<meeting>the 2nd Workshop on Machine Reading for Question Answering</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="113" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">C3EL: A joint model for cross-document co-reference resolution and entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourav</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1101</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="846" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">C3el: A joint model for cross-document co-reference resolution and entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourav</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="846" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Facc1: Freebase annotation of clueweb corpora, version 1 (release date 2013-06-26</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>format version 1, correction level 0</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep joint entity disambiguation with local neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Octavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hofmann</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1277</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2619" to="2629" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning dense representations for entity retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sayali</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Lansing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Presta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Ie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Garcia-Olano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 23rd Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Crossdocument coreference on a large scale corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename><surname>Heong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gooi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004</title>
		<meeting>the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004<address><addrLine>Boston, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Entity linking via joint encoding of types, descriptions, and context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1284</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2681" to="2690" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust disambiguation of named entities in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">Amir</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilaria</forename><surname>Bordino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hagen</forename><surname>F?rstenau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilyana</forename><surname>Taneva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Thater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK. Asso</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="782" to="792" />
		</imprint>
	</monogr>
	<note>ciation for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Humeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Humeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Distilling knowledge from reader to retriever for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Thomas Demeester, and Chris Develder. 2022. Towards consistent document-level entity linking: Joint models for entity linking and coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klim</forename><surname>Zaporojets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Deleu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08734</idno>
		<title level="m">Billion-scale similarity search with gpus</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">End-to-end neural entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Kolitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Octavian-Eugen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hofmann</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K18-1050</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Conference on Computational Natural Language Learning</title>
		<meeting>the 22nd Conference on Computational Natural Language Learning<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="519" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Plato: A selective context model for entity resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nevena</forename><surname>Lazic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="503" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improving entity linking by modeling latent relations between mentions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phong</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1148</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1595" to="1604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Taggerone: joint named entity recognition and normalization with semi-markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="2839" to="2846" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">List-only entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-2085</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="536" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Design challenges for entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00141</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="315" to="328" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Benchmarking scalable methods for streaming cross document entity coreference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename><surname>Robert L Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bikel</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Zero-shot entity linking by reading entity descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lajanugen</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1335</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3449" to="3460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Overview of the tac 2009 knowledge base population track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Analysis Conference (TAC)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="111" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning to link with wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Milne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM conference on Information and knowledge management</title>
		<meeting>the 17th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="509" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunil</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghui</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09476</idno>
		<title level="m">Medmentions: A large biomedical corpus annotated with umls concepts</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning continuous hierarchies in the lorentz model of hyperbolic geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximillian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3779" to="3788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Junjie Bai, and Soumith Chintala</editor>
		<meeting><address><addrLine>Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Personalized page rank for named entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pershina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="238" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Na?ve but effective nil clustering baselines-cmcrc at tac 2011</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Hachey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Text Analysis Conference</title>
		<meeting>Text Analysis Conference</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deeptype: multilingual entity linking by neural type system evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Raiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Raiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Ravenscroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><surname>Cattan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Clare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Liakata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.12637</idno>
		<title level="m">Cd2cr: Coreference resolution across documents and domains</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Large-scale cross-document coreference using distributed inference and hierarchical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="793" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Biomedical entity representations with synonym marginalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mujeen</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwisang</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.335</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3641" to="3650" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Support vector machine learning for interdependent and structured output spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasemin</forename><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twentyfirst international conference on Machine learning</title>
		<meeting>the twentyfirst international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Zero-shot entity linking with dense entity retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Josifoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Supervised hierarchical clustering with exponential linkage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Kobren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Monath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="6973" to="6983" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
