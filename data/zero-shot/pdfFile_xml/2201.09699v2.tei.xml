<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EASY -Ensemble Augmented-Shot Y-shaped Learning: State-Of-The-Art Few-Shot Classification with Simple Ingredients</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yassir</forename><surname>Bendou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Hu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Orange Labs</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Lafargue</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giulia</forename><surname>Lioi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastien</forename><surname>Pasdeloup</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Pateux</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Orange Labs</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Gripon</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IMT Atlantique</orgName>
								<orgName type="institution" key="instit2">Technopole Brest Iroise</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">EASY -Ensemble Augmented-Shot Y-shaped Learning: State-Of-The-Art Few-Shot Classification with Simple Ingredients</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Few-shot learning aims at leveraging knowledge learned by one or more deep learning models, in order to obtain good classification performance on new problems, where only a few labeled samples per class are available. Recent years have seen a fair number of works in the field, introducing methods with numerous ingredients. A frequent problem, though, is the use of suboptimally trained models to extract knowledge, leading to interrogations on whether proposed approaches bring gains compared to using better initial models without the introduced ingredients. In this work, we propose a simple methodology, that reaches or even beats state of the art performance on multiple standardized benchmarks of the field, while adding almost no hyperparameters or parameters to those used for training the initial deep learning models on the generic dataset. This methodology offers a new baseline on which to propose (and fairly compare) new techniques or adapt existing ones.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Learning with few examples, or few-shot learning, is a domain of research that has become increasingly popular in the past few years. Reconciling the remarkable performances of deep learning (DL), which are generally obtained thanks to access to huge databases, with the constraint of having a very small number of examples may seem paradoxical. Yet the answer lies in the ability of DL to transfer knowledge acquired when solving a previous task toward a different new one.</p><p>The classical few-shot setting consists of two parts:</p><p>? A generic dataset, which contains many examples of many classes. Since this dataset does not suffer from data thriftiness, it can be used to efficiently train DL architectures. Authors often split the generic dataset into two disjoint subsets, called base and validation. As usual in classification, the base dataset is used during training and the validation dataset is then used as a proxy to measure generalization performance on unseen data and therefore can be leveraged to fix hyperparameters. However, contrary to common classification settings, in few-shot the validation and base datasets usually contain distinct classes, so that the generalization performance is assessed on new classes. Drawing knowledge from the generic dataset can be performed with multiple strategies, as will be further discussed in Section II; ? A novel dataset, which consists of classes that are distinct from those of the generic dataset. We are only given a few labeled examples for each class, resulting in a fewshot problem. The labeled samples are often called the support set, and the remaining ones the query set. When benchmarking, it is common to use a large novel dataset from which artificial few-shot tasks are sampled uniformly at random, what we call a run. In that case, the number of classes n (named ways), the number of shots per class k and the number of query samples per class q are given by the benchmark. Reported performance are often averaged over a large number of runs. In order to exploit knowledge previously learned by models on the generic dataset, a common approach is to remove their final classification layer. The resulting models, now seen as feature extractors, are generally termed backbones, and can be used to transform the support and query datasets into feature vectors. This is a form of transfer learning. In this work, we do not consider the use of additional data such as other datasets, neither semantic nor segmentation information. Additional preprocessing steps may also be used on the samples and/or on the associated feature vectors, before the classification task. Another major approach uses meta-learning <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, as mentioned in Section II.</p><p>It is important to distinguish two types of problems:</p><p>? In inductive few-shot learning, only the support dataset is available to the few-shot classifier, and prediction is performed on each sample of the query dataset independently from each other; ? In transductive few-shot learning, the few-shot classifier has access to both the support and the full query datasets when performing predictions. Both problems have connections with real-world situations. In general, inductive few-shot corresponds to cases where data acquisition is expensive, whereas transductive few-shot corresponds to cases where data labeling is expensive.</p><p>In recent years, a large number of contributions have introduced methodologies to cope with few-shot problems. There are a lot of ingredients involved, including distillation <ref type="bibr" target="#b7">[8]</ref>, contrastive learning <ref type="bibr" target="#b8">[9]</ref>, episodic training <ref type="bibr" target="#b9">[10]</ref>, mixup <ref type="bibr" target="#b10">[11]</ref>, manifold mixup <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b6">[7]</ref> and self-supervision <ref type="bibr" target="#b11">[12]</ref>. As a consequence, it can appear quite opaque what are the effective ingredients, and whether their performance can be reproduced across different datasets or settings. More problematically, we noticed that many of these contributions start with suboptimal training procedures or architectures. Admittedly, they show significant performance boost using their proposed method, but reach at the end only a fair performance compared with better initial models without the proposed ingredient.</p><formula xml:id="formula_0">z 1 z 2 z b f ? i f ? i Concatenate features</formula><p>... <ref type="figure">Fig. 1</ref>. Illustration of our proposed method. Y: We first train an ensemble of backbones using the generic dataset. We use two cross-entropy losses in parallel: one for the classification of base classes, and the other for the self-supervised targets (rotations). We also use manifold mixup <ref type="bibr" target="#b6">[7]</ref>. All the backbones are trained using the exact same routine, except that their initialization is different (random) and the order in which data batches are presented is also potentially different; AS: Then, for each image in the novel dataset, we generate multiple crops, then compute their feature vectors, that we average; E: Each image becomes represented as the concatenation of the outputs of AS for each backbone; Preprocessing: We add a few classical preprocessing steps, including centering by removing the mean of the feature vectors of the base dataset in the inductive case or the novel feature vectors for the transductive case, and projecting on the hypersphere. Finally, we use a simple nearest class mean classifier (NCM) if in inductive setting or a soft K-means algorithm in transductive setting.</p><p>In this paper, we are interested in proposing a very simple method combining ingredients commonly found in the literature and yet achieving competitive performance. As such this contribution does not propose anything completely new, but we believe it will help having a clearer view on how to efficiently implement few-shot learning for real-world applications. Our main motivation is to define a proper baseline to compare to and to start with, on which obtaining boost of performance is going to be much more challenging than starting from a poorly trained backbone. We also aim at showing that a simple approach reaches higher performance than increasingly complex methods proposed in the recent few-shot literature.</p><p>More precisely, in this paper, we:</p><p>? Introduce a very simple methodology, illustrated in <ref type="figure">Figure  1</ref>, for inductive or transductive few-shot learning, that comes with almost no hyperparameters but those used for training the backbones; ? Show the ability of the proposed methodology to reach or even beat state-of-the-art performance on multiple standardized benchmarks of the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>There have been many approaches proposed recently in the field of few-shot learning. We introduce some of them following the classical pipeline. Note that our proposed methodology uses multiple ingredients from those presented thereafter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data augmentation</head><p>First, data augmentation or augmented sampling are generally used on the generic dataset to artificially produce additional samples, for example using rotations <ref type="bibr" target="#b11">[12]</ref>, crops <ref type="bibr" target="#b12">[13]</ref>, jitter, GANs <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, or other techniques <ref type="bibr" target="#b15">[16]</ref>. Data augmentation on support and query sets however is less frequent. Approaches exploring this direction include <ref type="bibr" target="#b8">[9]</ref>, where authors propose to select the foreground objects of images by identifying the right crops using a relatively complex mechanism; and <ref type="bibr" target="#b16">[17]</ref>, where the authors propose to mimic the neighboring base classes distribution to create augmented latent space vectors.</p><p>In addition, mixup <ref type="bibr" target="#b10">[11]</ref> and manifold-mixup <ref type="bibr" target="#b6">[7]</ref> are also used to address the challenging lack of data. Both can be seen as regularization methods through linear interpolations of samples and labels. Mixup creates linear interpolations at the sample level while manifold mixup focuses on feature vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Backbone training</head><p>Mixup is often used in conjunction with Self-supervision (S2) <ref type="bibr" target="#b11">[12]</ref> to make backbones more robust. Most of the time, S2 is implemented as an auxiliary loss meant to train the backbone to recognize which transformation was applied to an image.</p><p>A well known training strategy is episodic training. The idea behind it boils down to having the same train and test conditions. Thus, the backbone training strategy, often based on gradient descent, does not select random batches, but uses batches designed as few-shot problems <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b18">[19]</ref>.</p><p>Meta-Learning, or learning to learn, is a major line of research in the field. This method typically learns a good initialization or a good optimizer such that new classes can be learned in a few gradient steps <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. In this regard, episodic training is often used, and recent work leveraged this concept to generate augmented tasks in the training of the backbone <ref type="bibr" target="#b19">[20]</ref>.</p><p>Contrastive learning aims to train a model to learn to maximize similarities between transformed instances of the same image and minimize agreement between transformed instances of different images <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b8">[9]</ref>. Supervised contrastive learning is a variant which has been recently used in few-shot learning, where similarity is maximized between instances of a class instead of the same image <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Exploiting multiple backbones</head><p>Distillation has been recently used in the few-shot literature. The idea is to transfer knowledge from a teacher model to a student model by forcing the latter to match the class probabilities distribution of the teacher <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b7">[8]</ref>.</p><p>Ensembling consists in the concatenation of features extracted by different backbones. It was used to improve performances in few-shot learning <ref type="bibr" target="#b19">[20]</ref>. It can be seen as a more straightforward alternative to distillation. To limit the computationally expensive training of multiple backbones, some authors propose the use of snapshots <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Few-shot classification</head><p>Over the past years, classification methods in the inductive setting have mostly relied on simple methods such as nearest class mean <ref type="bibr" target="#b28">[29]</ref>, cosine classifiers <ref type="bibr" target="#b29">[30]</ref> and logistic regression <ref type="bibr" target="#b16">[17]</ref>.</p><p>More diverse methods can be implemented in the transductive setting. Clustering algorithms <ref type="bibr" target="#b8">[9]</ref>, embedding propagation <ref type="bibr" target="#b30">[31]</ref> and optimal transport <ref type="bibr" target="#b31">[32]</ref> were leveraged successfully to outrun performances in the inductive setting by a large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHODOLOGY</head><p>The proposed methodology consists of 5 steps, described thereafter and illustrated in <ref type="figure">Figure 1</ref>. In the experiments we also report ablation results when omitting the optional steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Backbone training (Y)</head><p>We use data augmentation with random resized crops, random color jitters and random horizontal flips, which is standard in the field.</p><p>We use a cosine-annealing scheduler <ref type="bibr" target="#b32">[33]</ref>, where at each step the learning rate is updated. During a cosine cycle, the learning rate evolves between ? 0 and 0. At the end of the cycle, we warm-restart the learning procedure and start over with a diminished ? 0 . We start with ? 0 = 0.1 and reduce ? 0 by 10% at each cycle. We use 5 cycles with 100 epochs each.</p><p>We train our backbones using the methodology called S2M2R described in <ref type="bibr" target="#b11">[12]</ref>. Basically, the principle is to take a standard classification architecture (e.g., ResNet12 <ref type="bibr" target="#b33">[34]</ref>), and to branch a new logistic regression classifier after the penultimate layer, in addition to the one used to identify the classes of input samples, thus forming a Y-shaped model (c.f. <ref type="figure">Figure 1</ref>). This new classifier is meant to retrieve which one of four possible rotations (quarters of 360?turns) has been applied to the input samples. We use a two-step forward-backward pass at each step, where a first batch of inputs is only fed to the first classifier, combined with manifold-mixup <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b6">[7]</ref>. A second batch of inputs is then applied arbitrary rotations and fed to both classifiers. After this training, backbones are frozen.</p><p>We experiment using a standard ResNet12 as described in <ref type="bibr" target="#b33">[34]</ref>, where the feature vectors are of dimension 640. These feature vectors are obtained by computing a global average pooling over the output of the last convolution layer. Such a backbone contains ? 12 million trainable parameters. We also experiment with reduced-size ResNet12, denoted ResNet12 1 2 where we divide each number of feature maps by 2, resulting in feature vectors of dimension 320, and ResNet12 1 ? 2 , where the number of feature maps is divided roughly by ? 2, resulting in feature vectors of dimension 450. The numbers of parameters are respectively ? 3 million and ? 6 million.</p><p>Using common notations of the field, if we denote x an input sample, and f the mathematical function of the backbone, then z = f (x) denotes the feature vector associated with x.</p><p>From this point on, we use the frozen backbones to extract feature vectors from the base, validation and novel datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Augmented samples (AS)</head><p>We propose to generate augmented feature vectors for each sample from the validation and novel datasets. To this end, we use random resized crops from the corresponding images. We obtain multiple versions of each feature vector and average them. In practice, we use = 30 crops per image, as larger values do not benefit accuracy much. This step is optional.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ensemble of backbones (E)</head><p>To boost performance even further, we propose to concatenate the feature vectors obtained from multiple backbones trained using the same previously described routine, but with different random seeds. To perform fair comparisons, when comparing a backbone with an ensemble of b backbones, we reduce the number of parameters in the ensemble backbones such that the total number of parameters remains identical. We believe that this strategy is an alternative to performing distillation, with the interest of not requiring extra-parameters and considerably reducing training time. Again, this step is optional and we perform ablation tests in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Feature vectors preprocessing</head><p>Finally, we apply two transforms as in <ref type="bibr" target="#b28">[29]</ref> on feature vectors z. Denote z the average feature vector of the base dataset if in inductive setting or of the few-shot considered problem if in transductive setting. The first operation (C -centering of z) consists in computing:</p><formula xml:id="formula_1">z C = z ? z .<label>(1)</label></formula><p>The second operation (H -projection of z C on the hypersphere) is then:</p><formula xml:id="formula_2">z CH = z C z C 2 .<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Classification</head><p>Let us denote S i (i ? {1, . . . , n}) the set of feature vectors (preprocessed as z CH ) corresponding to the support set for the i-th considered class, and Q the set of (also preprocessed) query feature vectors.</p><p>In the case of inductive few-shot learning, we use a simple Nearest Class Mean classifier (NCM). Predictions are obtained by first computing class barycenters from labeled samples:</p><formula xml:id="formula_3">?i : c i = 1 |S i | z?Si z ,<label>(3)</label></formula><p>then associating to each query the closest barycenter:</p><formula xml:id="formula_4">?z ? Q : C ind (z, [c 1 , . . . , c n ]) = arg min i z ? c i 2 . (4)</formula><p>In the case of transductive learning, we use a soft K-means algorithm. We compute the following sequence indexed by t, where the initial c i are computed as in Equation <ref type="formula" target="#formula_3">(3)</ref> :</p><formula xml:id="formula_5">?i, t : ? ? ? c i 0 = c i , c i t+1 = z?Si?Q w(z,ci t ) z ?S i ?Q w(z ,ci t ) z ,<label>(5)</label></formula><p>where w(z, c i t ) is a weighting function on z, that gives it a probability of being associated with barycenter c i t :</p><formula xml:id="formula_6">w(z, c i t ) = ? ? ? ? ? exp ?? z?ci t 2 2 n j=1 exp(?? z?cj t 2 2 ) if z ? Q , 1 if z ? S i .<label>(6)</label></formula><p>Contrary to the simple K-means algorithm, we use a weighted average where weight values are calculated via a decreasing function of the L 2 distance between data points and class barycenters -here, a softmax adjusted by a temperature value ?. In our experiments, we use ? = 5, which led to consistent results across datasets and backbones-. In practice, we use a finite number of steps. By denoting c ? i the resulting vectors, predictions are:</p><formula xml:id="formula_7">?z ? Q : Ctra(z, [c1 ? , . . . , cn ? ]) = arg min i z ? ci ? 2 . (7)</formula><p>F. Methods</p><p>In the end, our main method consists of assembling the 5 previously described steps, resulting in the acronym EASY. We have two optional steps, creating the methods Y (without ensemble and augmented samples), ASY (without ensemble) and EY (without augmented samples) for ablation tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Ranking on standard benchmarks</head><p>We first report results comparing our method with state of the art using classical settings and datasets. For each method, we specify the number of trainable parameters, the accuracy on 1-shot or 5-shot runs. Experiments always use q = 15 query samples per class and results are averaged over 10,000 runs. Results are presented in Tables I-V for the inductive setting and Tables VII-X for the transductive setting 1 .</p><p>Let us first emphasize that our proposed methodology states a new state-of-the-art performance for MiniImageNet (inductive), TieredImageNet (inductive) and FC100 (both inductive and transductive), while showcasing competitive results on other benchmarks. We believe that, combined with other more elaborate methods, these results could be improved by a fair margin, leading to a new standard of performance for fewshot benchmarks. In the transductive setting, the proposed methodology is less often ranked #1, but contrary to many alternatives it does not use any prior on class balance in the generated few-shot problems. We provide such experiments in the supplementary material, where we show that the proposed method greatly outperforms existing techniques when considering imbalanced classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Ablation study</head><p>To better understand the relative contributions of ingredients in the proposed method, we also compare, for each dataset, the performance of various combinations in <ref type="table" target="#tab_0">Table XI for  the inductive setting, and Table XII</ref> for the transductive setting. Interestingly, the full proposed methodology (EASY) is not always the most efficient. We believe that for large datasets such as MiniImageNet and TieredImageNet, the considered ResNet12 backbones contain too few parameters. When reducing this number for ensemble solutions, the drop of performance due to the reduction in size is not compensated by the diversity of the multiple backbones. All things considered, only AS is consistently beneficial to the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper we introduced a very simple method to perform few-shot classification in both inductive and transductive settings. We showed the ability of the method to obtain state of the art results on multiple standardized benchmarks, even beating previous methods by a fair margin in some cases. There is no real new ingredient in this methodology, but we expect it to serve as a baseline for future work. </p><formula xml:id="formula_8">Method 1-shot 5-shot ? 12M ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?</formula><p>SimpleShot <ref type="bibr" target="#b28">[29]</ref> 62.85 ? 0.20 80.02 ? 0.14 Baseline++ <ref type="bibr" target="#b29">[30]</ref> 53.97 ? 0.79 75.90 ? 0.61 TADAM <ref type="bibr" target="#b34">[35]</ref> 58.50 ? 0.30 76.70 ? 0.30 ProtoNet <ref type="bibr" target="#b9">[10]</ref> 60.37 ? 0.83 78.02 ? 0.57 R2-D2 (+ens) <ref type="bibr" target="#b19">[20]</ref> 64.79 ? 0.45 81.08 ? 0.32 FEAT <ref type="bibr" target="#b35">[36]</ref> 66.78 82.05 CNL <ref type="bibr" target="#b37">[37]</ref> 67.96 ? 0.98 83.36 ? 0.51 MERL <ref type="bibr" target="#b38">[38]</ref> 67.40 ? 0.43 83.40 ? 0.28 Deep EMD v2 <ref type="bibr" target="#b12">[13]</ref> 68.77 ? 0.29 84.13 ? 0.53 PAL <ref type="bibr" target="#b7">[8]</ref> 69.37 ? 0.64 84.40 ? 0.44 inv-equ <ref type="bibr" target="#b39">[39]</ref> 67.28 ? 0.80 84.78 ? 0.50 CSEI <ref type="bibr" target="#b40">[40]</ref> 68.94 ? 0.28 85.07 ? 0.50 COSOC <ref type="bibr" target="#b8">[9]</ref> 69. <ref type="bibr" target="#b27">28</ref>   <ref type="bibr" target="#b19">[20]</ref> 76.51 ? 0.47 87.63 ? 0.34 invariance-equivariance <ref type="bibr" target="#b39">[39]</ref> 77.87 ? 0.85 89.74 ? 0.57   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EASY 2?ResNet12</head><formula xml:id="formula_9">Method 1-shot 5-shot ? 12M ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?</formula><p>SimpleShot <ref type="bibr" target="#b28">[29]</ref> 69.09 ? 0.22 84.58 ? 0.16 ProtoNet <ref type="bibr" target="#b9">[10]</ref> 65.65 ? 0.92 83.40 ? 0.65 FEAT <ref type="bibr" target="#b35">[36]</ref> 70.80 ? 0.23 84.79 ? 0.16 PAL <ref type="bibr" target="#b7">[8]</ref> 72.25 ? 0.72 86.95 ? 0.47 DeepEMD v2 <ref type="bibr" target="#b12">[13]</ref> 74.29 ? 0.32 86.98 ? 0.60 MERL <ref type="bibr" target="#b38">[38]</ref> 72.14 ? 0.51 87.01 ? 0.35 COSOC <ref type="bibr" target="#b8">[9]</ref> 73.57 ? 0.43 87.57 ? 0.10 CNL <ref type="bibr" target="#b37">[37]</ref> 73.42 ? 0.95 87.72 ? 0.75 invariance-equivariance <ref type="bibr" target="#b39">[39]</ref> 72.21 ? 0.90 87.08 ? 0.58 CSEI <ref type="bibr" target="#b40">[40]</ref> 73.76 ? 0.32 87.83 ? 0.59 ASY ResNet12 <ref type="bibr">(ours)</ref> 74.31 ? 0.22 87.86 ? 0.15</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>36M</head><p>S2M2R <ref type="bibr" target="#b11">[12]</ref> 73.71 ? 0.22 88.52 ? 0.14 EASY 3?ResNet12 <ref type="bibr">(ours)</ref> 74.71 ? 0.22 88.33 ? 0.14 </p><formula xml:id="formula_10">Method 1-shot 5-shot ? 12M ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? TIM-GD [42]</formula><p>73.90 85.00 ODC <ref type="bibr" target="#b43">[43]</ref> 77.20 ? 0.36 87.11 ? 0.42 PEMnE-BMS * <ref type="bibr" target="#b31">[32]</ref> 80.56 ? 0.27 87.98 ? 0.14 SSR <ref type="bibr" target="#b44">[44]</ref> 68.10 ? 0.60 76.90 ? 0.40 iLPC <ref type="bibr" target="#b45">[45]</ref> 69.79 ? 0.99 79.82 ? 0.55 EPNet <ref type="bibr" target="#b30">[31]</ref> 66.50 ? 0.89 81.60 ? 0.60 DPGN <ref type="bibr" target="#b46">[46]</ref> 67.77 ? 0.32 84.60 ? 0.43 ECKPN <ref type="bibr" target="#b47">[47]</ref> 70. <ref type="bibr" target="#b48">48</ref>  </p><formula xml:id="formula_11">36M ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? SSR [44]</formula><p>72.40 ? 0.60 80.20 ? 0.40 fine-tuning(train+val) <ref type="bibr" target="#b49">[49]</ref> 68.11 ? 0.69 80.36 ? 0.50 SIB+E 3 BM <ref type="bibr" target="#b50">[50]</ref> 71.40 81.20 LR+DC <ref type="bibr" target="#b16">[17]</ref> 68.57 ? 0.55 82.88 ? 0.42 EPNet <ref type="bibr" target="#b30">[31]</ref> 70.74 ? 0.85 84.34 ? 0.53 TIM-GD <ref type="bibr" target="#b42">[42]</ref> 77.80 87.40 PT+MAP <ref type="bibr" target="#b51">[51]</ref> 82.92 ? 0.26 88.82 ? 0.13 iLPC <ref type="bibr" target="#b45">[45]</ref> 83.05 ? 0.79 88.82 ? 0.42 ODC <ref type="bibr" target="#b43">[43]</ref> 80.64 ? 0.34 89.39 ? 0.39 PEMnE-BMS * <ref type="bibr" target="#b31">[32]</ref> 83.35 ? 0.25 89.53 ? 0.13 EASY 3?ResNet12 <ref type="bibr">(ours)</ref> 84.04 ? 0.23 89.14 ? 0.11   <ref type="bibr" target="#b49">[49]</ref> 78.36 ? 0.70 87.54 ? 0.49 iLPC <ref type="bibr" target="#b45">[45]</ref> 86.51 ? 0.75 90.60 ? 0.48 PT+MAP <ref type="bibr" target="#b51">[51]</ref> 87.69 ? 0.23 90.68 ? 0.15 EASY 3?ResNet12 <ref type="bibr">(ours)</ref> 87.16 ? 0.21 90.47 ? 0.15 </p><formula xml:id="formula_12">Method 1-shot 5-shot ? 12M ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? PT+MAP [51]</formula><p>85.67 ? 0.26 90.45 ? 0.14 TIM-GD <ref type="bibr" target="#b42">[42]</ref> 79.90 88.50 ODC <ref type="bibr" target="#b43">[43]</ref> 83.73 ? 0.36 90.46 ? 0.46 SSR <ref type="bibr" target="#b44">[44]</ref> 81.20 ? 0.60 85.70 ? 0.40 Rot+KD+POODLE <ref type="bibr" target="#b48">[48]</ref> 79.67 86.96 DPGN <ref type="bibr" target="#b46">[46]</ref> 72.45 ? 0.51 87.24 ? 0.39 EPNet <ref type="bibr" target="#b30">[31]</ref> 76.53 ? 0.87 87.32 ? 0.64 ECKPN <ref type="bibr" target="#b47">[47]</ref> 73.59 ? 0.45 88.13 ? 0.28 iLPC <ref type="bibr" target="#b45">[45]</ref> 83.49 ? 0.88 89.48 ? 0.47 ASY ResNet12 <ref type="bibr">(ours)</ref> 83.98 ? 0.24 89.26 ? 0.14</p><formula xml:id="formula_13">36M ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? SIB+E 3 BM [50]</formula><p>75.60 84.30 SSR <ref type="bibr" target="#b44">[44]</ref> 79.50 ? 0.60 84.80 ? 0.40 fine-tuning (train+val) <ref type="bibr" target="#b49">[49]</ref> 72.87 ? 0.71 86.15 ? 0.50 TIM-GD <ref type="bibr" target="#b42">[42]</ref> 82.10 89.80 LR+DC <ref type="bibr" target="#b16">[17]</ref> 78. <ref type="bibr" target="#b18">19</ref>   Following the methodology recently proposed in <ref type="bibr" target="#b52">[52]</ref>, we also report performance in transductive setting when the number of query vectors is varying for each class and is unknown. Results are presented in Tables XIII-XV. We note that the proposed methodology is able to outperform existing ones by a fair margin. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B ADDITIONAL ABLATION STUDIES</head><p>A. Influence of the temperature in the transductive setting</p><p>In <ref type="figure">Figure 2</ref>, we show how different values of the temperature ? of the soft K-means influence the performance of our model. We observe that ? = 5 seems to lead to the best results on the two considered datasets, which is why we chose this value in our other experiments. Note that we use three ResNet12 with 30 augmented samples in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Influence of the number of crops</head><p>In <ref type="figure" target="#fig_0">Figure 3</ref>, we show how the performance of our model is influenced by the number of crops used during Augmented Sampling (AS). When using = 1, we report the performance of the method using no crops but a global reshape instead. We observe that the performance keeps increasing as long as the number of crops used is increased, except for a small drop of performance when switching from a global reshape to crops -this drop can easily be explained as crops are likely to miss the object of interest-. However, the computational time to generate the crops also increases linearly. Therefore, we use = 30 as a trade-off between performance and time complexity. Here, we use a single ResNet12 for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Influence of the number of backbones</head><p>In <ref type="figure">Figure 4</ref>, we show how the performance of our model is influenced by the number of backbones b used during the Ensemble step (E). The performance increases steadily with a strong diminishing return. We use 30 augmented samples in this experiment. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Ablation study of Augmented Samples, we perform 10 5 runs for each value of .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 4 .</head><label>24</label><figDesc>Ablation study of Temperature of the soft K-means used in the transductive setting. We perform 10 5 runs for each value of ?. Ablation study of the number of backbones, we perform 10 5 runs for each value of b.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I 1</head><label>I</label><figDesc>-SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON MINIIMAGENET IN INDUCTIVE SETTING.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON CUB-FS IN INDUCTIVE SETTING. SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON CIFAR-FS IN INDUCTIVE SETTING.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>? 0.49</cell><cell>85.16 ? 0.42</cell></row><row><cell></cell><cell></cell><cell>EASY 2?ResNet12 1 ? 2</cell><cell>(ours)</cell><cell cols="2">70.63 ? 0.20 86.28 ? 0.12</cell></row><row><cell>36M</cell><cell>? ? ?</cell><cell>S2M2R [12] LR + DC [17] EASY 3?ResNet12 (ours)</cell><cell></cell><cell cols="2">64.93 ? 0.18 68.55 ? 0.55 71.75 ? 0.19 87.15 ? 0.12 83.18 ? 0.11 82.88 ? 0.42</cell></row><row><cell></cell><cell></cell><cell cols="3">TABLE II</cell></row><row><cell cols="3">1-Method</cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>? 12M</cell><cell>? ? ? ? ? ? ? ? ?</cell><cell cols="2">FEAT [36] LaplacianShot [41] ProtoNet [10] DeepEMD v2 [13] EASY 4?ResNet12 1 2 (ours)</cell><cell>68.87 ? 0.22 80.96 66.09 ? 0.92 79.27 ? 0.29 77.97 ? 0.20</cell><cell>82.90 ? 0.10 88.68 82.50 ? 0.58 89.80 ? 0.51 91.59 ? 0.10</cell></row><row><cell>36M</cell><cell></cell><cell>S2M2R [12] EASY 3?ResNet12 (ours)</cell><cell></cell><cell cols="2">80.68 ? 0.81 90.85 ? 0.44 78.56 ? 0.19 91.93 ? 0.10</cell></row><row><cell></cell><cell></cell><cell cols="3">TABLE III</cell></row><row><cell cols="3">1-Method</cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>? 12M</cell><cell>? ? ? ? ?</cell><cell>S2M2R [12] R2-D2 (+ens)</cell><cell></cell><cell>63.66 ? 0.17</cell><cell>76.07 ? 0.19</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV 1</head><label>IV</label><figDesc>-SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON FC-100 IN INDUCTIVE SETTING.</figDesc><table><row><cell></cell><cell></cell><cell>Method</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>? 12M</cell><cell>? ? ? ? ? ? ? ? ? ? ? ? ?</cell><cell>DeepEMD v2 [13] TADAM [35] ProtoNet [10] invariance-equivariance [39] R2-D2 (+ens) [20] EASY 2?ResNet12 1 ? 2 (ours)</cell><cell cols="2">46.60 ? 0.26 40.10 ? 0.40 41.54 ? 0.76 47.76 ? 0.77 44.75 ? 0.43 47.94 ? 0.19 64.14 ? 0.19 63.22 ? 0.71 56.10 ? 0.40 57.08 ? 0.76 65.30 ? 0.76 59.94 ? 0.41</cell></row><row><cell>36M</cell><cell></cell><cell>EASY 3?ResNet12 (ours)</cell><cell cols="2">48.07 ? 0.19 64.74 ? 0.19</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V 1</head><label>V</label><figDesc>-SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON TIEREDIMAGENET IN INDUCTIVE SETTING.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI 1</head><label>VI</label><figDesc>-SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON MINIIMAGENET IN TRANSDUCTIVE SETTING.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VII 1</head><label>VII</label><figDesc>-SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON CUB-FS IN TRANSDUCTIVE SETTING.</figDesc><table><row><cell></cell><cell></cell><cell>Method</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>? 12M</cell><cell>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?</cell><cell>TIM-GD [42] ODC [43] DPGN [46] ECKPN [47] iLPC [45] Rot+KD+POODLE [48] EASY 4?ResNet12 1 2 (ours)</cell><cell cols="2">82.20 85.87 75.71 ? 0.47 77.43 ? 0.54 89.00 ? 0.70 89.93 90.50 ? 0.19 93.50 ? 0.09 90.80 94.97 91.48 ? 0.33 92.21 ? 0.41 92.74 ? 0.35 93.78</cell></row><row><cell></cell><cell>?</cell><cell>LR+DC [17]</cell><cell>79.56 ? 0.87</cell><cell>90.67 ? 0.35</cell></row><row><cell>36M</cell><cell>? ? ? ?</cell><cell>PT+MAP [51] iLPC [45] EASY 3?ResNet12 (ours)</cell><cell cols="2">91.55 ? 0.19 93.99 ? 0.10 91.03 ? 0.63 94.11 ? 0.30 90.56 ? 0.19 93.79 ? 0.10</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VIII 1</head><label>VIII</label><figDesc>-SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON CIFAR-FS IN TRANSDUCTIVE SETTING.</figDesc><table><row><cell></cell><cell></cell><cell>Method</cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>? 12M</cell><cell>? ? ? ? ? ? ? ? ?</cell><cell>SSR [44] iLPC [45] DPGN [46] ECKPN [47] EASY 2?ResNet12 1 ? 2</cell><cell>(ours)</cell><cell cols="2">76.80 ? 0.60 77.14 ? 0.95 77.90 ? 0.50 79.20 ? 0.40 86.99 ? 0.21 90.20 ? 0.15 83.70 ? 0.40 85.23 ? 0.55 90.02 ? 0.40 91.00 ? 0.50</cell></row><row><cell>36M</cell><cell>? ? ? ? ? ? ? ? ?</cell><cell>SSR [44] fine-tuning (train+val)</cell><cell></cell><cell>81.60 ? 0.60</cell><cell>86.00 ? 0.40</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE IX 1</head><label>IX</label><figDesc>-SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODSAND PROPOSED SOLUTION ON FC-100 IN TRANSDUCTIVE SETTING. SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON TIEREDIMAGENET IN TRANSDUCTIVE SETTING.</figDesc><table><row><cell></cell><cell></cell><cell>Method</cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>? 12M</cell><cell cols="2">? ? ? EASY 2?ResNet12 1 ? 2</cell><cell>(ours)</cell><cell>54.47 ? 0.24 65.82 ? 0.19</cell></row><row><cell>36M</cell><cell>? ? ? ? ? ? ? ? ?</cell><cell>SIB+E 3 BM [50] fine-tuning (train) [49] ODC [43] fine-tuning (train+val) [49] EASY 3?ResNet12 (ours)</cell><cell></cell><cell>46.00 43.16 ? 0.59 47.18 ? 0.30 50.44 ? 0.68 54.13 ? 0.24 66.86 ? 0.19 57.10 57.57 ? 0.55 59.21 ? 0.56 65.74 ? 0.60</cell></row><row><cell></cell><cell></cell><cell cols="3">TABLE X</cell></row><row><cell>1-</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE XI ABLATION</head><label>XI</label><figDesc>STUDY OF THE STEPS OF PROPOSED SOLUTION IN INDUCTIVE SETTING, FOR A FIXED NUMBER OF TRAINABLE PARAMETERS IN THE CONSIDERED BACKBONES. WHEN USING ENSEMBLES, WE USE 2?RESNET12 1</figDesc><table><row><cell></cell><cell>?</cell><cell>2</cell><cell cols="3">INSTEAD OF A SINGLE RESNET12.</cell></row><row><cell>Dataset</cell><cell>E</cell><cell></cell><cell>AS</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>68.43 ? 0.19</cell><cell>83.78 ? 0.13</cell></row><row><cell>MiniImageNet</cell><cell></cell><cell></cell><cell></cell><cell>70.84 ? 0.19</cell><cell>85.70 ? 0.13</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>68.69 ? 0.20</cell><cell>84.84 ? 0.13</cell></row><row><cell cols="3">*  IMT Atlantique, Technopole Brest Iroise, France</cell><cell></cell><cell>70.63 ? 0.20</cell><cell>86.28 ? 0.12</cell></row><row><cell>? Orange Labs, Rennes, France</cell><cell></cell><cell></cell><cell></cell><cell>74.13 ? 0.20</cell><cell>89.08 ? 0.11</cell></row><row><cell>CUB-FS</cell><cell></cell><cell></cell><cell></cell><cell>77.40 ? 0.20</cell><cell>91.15 ? 0.10</cell></row><row><cell>APPENDIX A TRANSDUCTIVE TESTS WITH IMBALANCED SETTINGS</cell><cell></cell><cell></cell><cell></cell><cell>75.01 ? 0.20 77.59 ? 0.20</cell><cell>89.38 ? 0.11 91.07 ? 0.11</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>73.38 ? 0.21</cell><cell>87.42 ? 0.15</cell></row><row><cell>CIFAR-FS</cell><cell></cell><cell></cell><cell></cell><cell>74.26 ? 0.21</cell><cell>88.16 ? 0.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>74.36 ? 0.21</cell><cell>87.82 ? 0.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">75.24 ? 0.20 88.38 ? 0.14</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>45.68 ? 0.19</cell><cell>62.78 ? 0.19</cell></row><row><cell>FC-100</cell><cell></cell><cell></cell><cell></cell><cell>46.43 ? 0.19</cell><cell>64.16 ? 0.19</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>47.52 ? 0.19</cell><cell>63.92 ? 0.19</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">47.94 ? 0.20 64.14 ? 0.19</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>72.52 ? 0.22</cell><cell>86.79 ? 0.15</cell></row><row><cell>TieredImageNet</cell><cell></cell><cell></cell><cell></cell><cell cols="2">74.17 ? 0.22 87.81 ? 0.14</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>72.14 ? 0.22</cell><cell>86.66 ? 0.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>73.36 ? 0.22</cell><cell>87.37 ? 0.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">TABLE XII</cell></row><row><cell cols="6">ABLATION STUDY OF THE STEPS OF PROPSOED SOLUTION IN</cell></row><row><cell cols="6">TRANSDUCTIVE SETTING, FOR A FIXED NUMBER OF TRAINABLE</cell></row><row><cell cols="6">PARAMETERS IN THE CONSIDERED BACKBONES. WHEN USING ENSEMBLES,</cell></row><row><cell cols="4">WE USE 2?RESNET12 1 ? 2</cell><cell cols="2">INSTEAD OF A SINGLE RESNET12.</cell></row><row><cell>Dataset</cell><cell>E</cell><cell></cell><cell>AS</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>80.42 ? 0.23</cell><cell>86.72 ? 0.13</cell></row><row><cell>MiniImageNet</cell><cell></cell><cell></cell><cell></cell><cell>83.02 ? 0.23</cell><cell>88.36 ? 0.12</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>80.27 ? 0.23</cell><cell>87.45 ? 0.12</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>82.31 ? 0.24</cell><cell>88.57 ? 0.12</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>86.93 ? 0.21</cell><cell>91.53 ? 0.11</cell></row><row><cell>CUB-FS</cell><cell></cell><cell></cell><cell></cell><cell>89.80 ? 0.20</cell><cell>93.12 ? 0.10</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>87.28 ? 0.21</cell><cell>91.89 ? 0.10</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">90.05 ? 0.19 93.17 ? 0.10</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>84.18 ? 0.23</cell><cell>89.56 ? 0.15</cell></row><row><cell>CIFAR-FS</cell><cell></cell><cell></cell><cell></cell><cell>85.55 ? 0.23</cell><cell>90.07 ? 0.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>84.89 ? 0.22</cell><cell>89.60 ? 0.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">86.99 ? 0.21 90.20 ? 0.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>51.74 ? 0.23</cell><cell>65.39 ? 0.19</cell></row><row><cell>FC-100</cell><cell></cell><cell></cell><cell></cell><cell>52.93 ? 0.23</cell><cell>66.51 ? 0.19</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>53.39 ? 0.23</cell><cell>65.71 ? 0.19</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>54.47 ? 0.24</cell><cell>65.82 ? 0.19</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>82.32 ? 0.24</cell><cell>88.45 ? 0.15</cell></row><row><cell>TieredImageNet</cell><cell></cell><cell></cell><cell></cell><cell cols="2">83.98 ? 0.24 89.26 ? 0.14</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>81.48 ? 0.25</cell><cell>88.40 ? 0.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>83.20 ? 0.25</cell><cell>88.92 ? 0.14</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE XIII 1</head><label>XIII</label><figDesc>-SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON MINIIMAGENET IN IMBALANCED</figDesc><table><row><cell></cell><cell></cell><cell cols="2">TRANSDUCTIVE SETTING.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Method</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>? 12M</cell><cell cols="2">? MAML [53] ? ? ? ? ? ? LR+ICI [54] PT+MAP [55] LaplacianShot [41] ? ? ? ? TIM [42] ? ? ?-TIM [52]</cell><cell>47.6 58.7 60.1 65.4 67.3 67.4</cell><cell>64.5 73.5 67.1 81.6 79.8 82.5</cell></row><row><cell>36M</cell><cell>? ? ? ? ? ? ? ? ? ? ? ? ?</cell><cell>PT+MAP [55] SIB [56] LaplacianShot [41] TIM [42] ?-TIM [52] EASY 3?ResNet12 (ours)</cell><cell>60.6 64.7 68.1 69.8 69.8 76.04</cell><cell>66.8 72.5 83.2 81.6 84.8 87.23</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE XIV 1</head><label>XIV</label><figDesc>-SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON TIEREDIMAGENET IN IMBALANCED SHOT AND 5-SHOT ACCURACY OF STATE-OF-THE-ART METHODS AND PROPOSED SOLUTION ON CUB-FS IN IMBALANCED TRANSDUCTIVE</figDesc><table><row><cell></cell><cell></cell><cell cols="2">TRANSDUCTIVE SETTING.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Method</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>? 12M</cell><cell cols="2">? Entropy-min [57] ? ? ? ? ? ? PT+MAP [55] LaplacianShot [41] TIM [42] ? ? ? ? LR+ICI [54] ? ? ?-TIM [52]</cell><cell>61.2 64.1 72.3 74.1 74.6 74.4</cell><cell>75.5 70.0 85.7 84.1 85.1 86.6</cell></row><row><cell>36M</cell><cell>? ? ? ? ? ? ? ? ? ? ? ? ?</cell><cell>Entropy-min [57] PT+MAP [55] LaplacianShot [41] TIM [42] ?-TIM [52] EASY 3?ResNet12 (ours)</cell><cell>62.9 65.1 73.5 75.8 76.0 78.46</cell><cell>77.3 71.0 86.8 85.4 87.8 87.85</cell></row><row><cell></cell><cell></cell><cell>TABLE XV</cell><cell></cell><cell></cell></row><row><cell cols="3">1-SETTING.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Method</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>36M</cell><cell>? ? ? ? ? ? ? ? ? ? ? ? ?</cell><cell>PT+MAP [55] Entropy-min [57] LaplacianShot [41] TIM [42] ?-TIM [52] EASY 3?ResNet12 (ours)</cell><cell>65.1 67.5 73.7 74.8 75.7 83.63</cell><cell>71.3 82.9 87.7 86.9 89.8 92.35</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The codes allowing to reproduce our experiments are available at https: //github.com/ybendou/easy.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Rapid Adaptation with Conditionally Shifted Neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<ptr target="https://aka.ms/csns" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Meta-Learning with Differentiable Convex Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Services</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">C</forename><surname>San Diego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Amherst</surname></persName>
		</author>
		<ptr target="https://github.com/kjunelee/MetaOptNet" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Adapted Deep Embeddings: A Synthesis of Methods for k-Shot Inductive Transfer Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ridgeway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Meta Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<title level="m">Meta Navigator: Search for a Good Adaptation Policy for Few-shot Learning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Manifold mixup: Better representations by interpolating hidden states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beckham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">36th International Conference on Machine Learning, ICML 2019</title>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="page">205</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Partner-assisted learning for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Abd-Almageed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rectifying the shortcut learning of background for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1703.05175" />
		<imprint>
			<date type="published" when="2017-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">MixUp: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<ptr target="https://github.com/facebookresearch/mixup-cifar10" />
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018 -Conference Track Proceedings</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Charting the right manifold: Manifold mixup for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mangla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Balasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2218" to="2227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deepemd: Few-shot image classification with differentiable earth mover&apos;s distance and structured classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Face generation for low-shot learning using generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1940" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adversarial feature hallucination networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="470" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Low-shot visual recognition by shrinking and hallucinating features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3018" to="3027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Free lunch for few-shot learning: Distribution calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06395</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">OPTIMIZATION AS A MODEL FOR FEW-SHOT LEARNING</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Matching Networks for One Shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wierstra</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2016/file/90e1357833654983612fb05e3ec9148c-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing</title>
		<editor>Systems, D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Task augmentation by rotating for meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-M</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00804</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Rectifying the Shortcut Learning of Background for Few-Shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<ptr target="https://github.com/Frankluox/FewShotCodeBase" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning a Few-shot Embedding Model with Contrastive Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://ojs.aaai.org/index.php/AAAI/article/view/17047" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="8635" to="8643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Boosting few-shot classification with view-learnable contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Revisiting contrastive learning for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Polito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bhotika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">01</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Supervised Contrastive Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/d89a66c7c80a29b1bdbab0f2a1a94af8-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="661" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Rethinking Few-shot Image Classification: A Good Embedding is All You Need?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<ptr target="http://github.com/WangYueFt/rfs/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00109</idno>
		<title level="m">Snapshot ensembles: Train 1, get m for free</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Simpleshot: Revisiting nearest-neighbor classification for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-L</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.04623</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/pdf/1904.04232" />
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Embedding propagation: Smoother manifold for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laradji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Drouin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="121" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Squeezing backbone feature distributions to the max for efficient few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gripon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pateux</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.09446</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="http://image-net.org/challenges/LSVRC/2015/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Decem</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="721" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Few-Shot Learning via Embedding Adaptation with Set-to-Set Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-C</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<ptr target="http://arxiv.org/abs/1812.03664" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Looking wider for better adaptive representation in few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="981" to="991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Melr: Meta-learning via modeling episode-level relationships for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Exploring complementary strengths of invariant and equivariant representations for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Rizve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10" to="836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning intact features by erasing-inpainting for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="8401" to="8409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Laplacian Regularized Few-Shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ziko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ben Ayed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Transductive information maximization for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Boudiaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">I</forename><surname>Masud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Piantanida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.11297</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Transductive Few-Shot Classification on the Oblique Manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2108.04009" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Re-ranking for image retrieval and transductive few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sbai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aubry</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Iterative label cleaning for transductive and semi-supervised few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lazarou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Stathaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Avrithis</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dpgn: Distribution propagation graph network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">ECKPN: Explicit Class Knowledge Propagation Network for Transductive Few-shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6592" to="6601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">POODLE: Improving Few-shot Learning via Penalizing Out-of-Distribution Samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-S</forename><surname>Hua</surname></persName>
		</author>
		<ptr target="https://github.com/VinAIResearch/poodle" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">A Baseline for Few-Shot Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1909.02729" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An Ensemble of Epoch-Wise Empirical Bayes for Few-Shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">12361</biblScope>
			<biblScope unit="page" from="404" to="421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Leveraging the Feature Distribution in Transfer-Based Few-Shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gripon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pateux</surname></persName>
		</author>
		<ptr target="https://github.com/yhu01/PT-MAP" />
	</analytic>
	<monogr>
		<title level="m">Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">12892</biblScope>
			<biblScope unit="page" from="487" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Realistic evaluation of transductive few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Veilleux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Boudiaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Piantanida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ben Ayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Instance credibility inference for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12" to="836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Leveraging the feature distribution in transfer-based few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gripon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pateux</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.03806</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Empirical bayes transductive meta-learning with synthetic gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Damianou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.12696</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.02729</idno>
	</analytic>
	<monogr>
		<title level="m">EASY -Ensemble Augmented-Shot Y-shaped Learning: State-Of-The-Art Few-Shot Classification with Simple Ingredients</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Supplementary material</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yassir</forename><surname>Bendou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">* ?</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Lafargue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giulia</forename><surname>Lioi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastien</forename><surname>Pasdeloup * St?phane Pateux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Gripon</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
