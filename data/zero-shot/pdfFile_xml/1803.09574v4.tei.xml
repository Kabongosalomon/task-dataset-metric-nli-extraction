<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Long short-term memory and learning-to-learn in networks of spiking neurons</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bellec</surname></persName>
							<email>bellec@igi.tugraz.at</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Theoretical Computer Science</orgName>
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darjan</forename><surname>Salaj</surname></persName>
							<email>salaj@igi.tugraz.at</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Theoretical Computer Science</orgName>
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Subramoney</surname></persName>
							<email>subramoney@igi.tugraz.at</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Theoretical Computer Science</orgName>
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Legenstein</surname></persName>
							<email>legenstein@igi.tugraz.at</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Theoretical Computer Science</orgName>
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maass</surname></persName>
							<email>maass@igi.tugraz.at</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Theoretical Computer Science</orgName>
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Long short-term memory and learning-to-learn in networks of spiking neurons</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>* equal contributions</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recurrent networks of spiking neurons (RSNNs) underlie the astounding computing and learning capabilities of the brain. But computing and learning capabilities of RSNN models have remained poor, at least in comparison with artificial neural networks (ANNs). We address two possible reasons for that. One is that RSNNs in the brain are not randomly connected or designed according to simple rules, and they do not start learning as a tabula rasa network. Rather, RSNNs in the brain were optimized for their tasks through evolution, development, and prior experience. Details of these optimization processes are largely unknown. But their functional contribution can be approximated through powerful optimization methods, such as backpropagation through time (BPTT). A second major mismatch between RSNNs in the brain and models is that the latter only show a small fraction of the dynamics of neurons and synapses in the brain. We include neurons in our RSNN model that reproduce one prominent dynamical process of biological neurons that takes place at the behaviourally relevant time scale of seconds: neuronal adaptation. We denote these networks as LSNNs because of their Long short-term memory. The inclusion of adapting neurons drastically increases the computing and learning capability of RSNNs if they are trained and configured by deep learning (BPTT combined with a rewiring algorithm that optimizes the network architecture). In fact, the computational performance of these RSNNs approaches for the first time that of LSTM networks. In addition RSNNs with adapting neurons can acquire abstract knowledge from prior learning in a Learning-to-Learn (L2L) scheme, and transfer that knowledge in order to learn new but related tasks from very few examples. We demonstrate this for supervised learning and reinforcement learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recurrent networks of spiking neurons (RSNNs) are frequently studied as models for networks of neurons in the brain. In principle, they should be especially well-suited for computations in the temporal domain, such as speech processing, as their computations are carried out via spikes, i.e., events in time and space. But the performance of RSNN models has remained suboptimal also for temporal processing tasks. One difference between RSNNs in the brain and RSNN models is that RSNNs in the brain have been optimized for their function through long evolutionary processes, complemented by a sophisticated learning curriculum during development. Since most details of these biological processes are currently still unknown, we asked whether deep learning is able to mimic these complex optimization processes on a functional level for RSNN models. We used BPTT as the deep learning method for network optimization. Backpropagation has been adapted previously for feed forward networks with binary activations in <ref type="bibr">[1,</ref><ref type="bibr">2]</ref>, and we adapted BPTT to work 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montr?al, Canada. in a similar manner for RSNNs. In order to also optimize the connectivity of RSNNs, we augmented BPTT with DEEP R, a biologically inspired heuristic for synaptic rewiring <ref type="bibr">[3,</ref><ref type="bibr">4]</ref>. Compared to LSTM networks, RSNNs tend to have inferior short-term memory capabilities. Since neurons in the brain are equipped with a host of dynamics processes on time scales larger than a few dozen ms <ref type="bibr">[5]</ref>, we enriched the inherent dynamics of neurons in our model by a standard neural adaptation process.</p><p>We first show (section 4) that this approach produces new computational performance levels of RSNNs for two common benchmark tasks: Sequential MNIST and TIMIT (a speech processing task). We then show that it makes L2L applicable to RSNNs (section 5), similarly as for LSTM networks. In particular, we show that meta-RL <ref type="bibr">[6,</ref><ref type="bibr">7]</ref> produces new motor control capabilities of RSNNs (section 6). This result links a recent abstract model for reward-based learning in the brain <ref type="bibr">[8]</ref> to spiking activity. In addition, we show that RSNNs with sparse connectivity and sparse firing activity of 10-20 Hz (see <ref type="figure">Fig. 1D</ref>, 2D, S1C) can solve these and other tasks. Hence these RSNNs compute with spikes, rather than firing rates.</p><p>The superior computing and learning capabilities of LSNNs suggest that they are also of interest for implementation in spike-based neuromorphic chips such as Brainscales <ref type="bibr">[9]</ref>, SpiNNaker <ref type="bibr">[10]</ref>, True North <ref type="bibr">[2]</ref>, chips from ETH Z?rich <ref type="bibr">[11]</ref>, and Loihi <ref type="bibr" target="#b11">[12]</ref>. In particular, nonlocal learning rules such as backprop are challenges for some of these neuromorphic devices (and for many brain models). Hence alternative methods for RSNN learning of nonlinear functions are needed. We show in sections 5 and 6 that L2L can be used to generate RSNNs that learn very efficiently even in the absence of synaptic plasticity.</p><p>Relation to prior work: We refer to <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref> for summaries of preceding results on computational capabilities of RSNNs. The focus there was typically on the generation of dynamic patterns. Such tasks are not addressed in this article, but it will be shown in <ref type="bibr" target="#b16">[17]</ref> that LSNNs provide an alternative model to <ref type="bibr" target="#b15">[16]</ref> for the generation of complex temporal patterns. Huh et al. <ref type="bibr" target="#b14">[15]</ref> applied gradient descent to recurrent networks of spiking neurons. There, neurons without a leak were used. Hence, the voltage of a neuron could used in that approach to store information over an unlimited length of time.</p><p>We are not aware of previous attempts to bring the performance of RSNNs for time series classification into the performance range of LSTM networks. We are also not aware of any previous literature on applications of L2L to SNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">LSNN model</head><p>Neurons and synapses in common RSNN models are missing many of the dynamic processes found in their biological counterparts, especially those on larger time scales. We integrate one of them into our RSNN model: neuronal adaptation. It is well known that a substantial fraction of excitatory neurons in the brain are adapting, with diverse time constants, see e.g. the Allen Brain Atlas for data from the neocortex of mouse and humans. We refer to the resulting type of RSNNs as Long short-term memory Spiking Neural Networks (LSNNs). LSNNs consist of a population R of integrate-and-fire (LIF) neurons (excitatory and inhibitory), and a second population A of LIF excitatory neurons whose excitability is temporarily reduced through preceding firing activity, i.e., these neurons are adapting (see <ref type="figure">Fig. 1C</ref> and Suppl.). Both populations R and A receive spike trains from a population X of external input neurons. Results of computations are read out by a population Y of external linear readout neurons, see <ref type="figure">Fig. 1C</ref>. Common ways for fitting models for adapting neurons to data are described in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>. We are using here the arguably simplest model: We assume that the firing threshold B j (t) of neuron j increases by some fixed amount ?/? a,j for each spike of this neuron j, and then decays exponentially back to a baseline value b 0 j with a time constant ? a,j . Thus the threshold dynamics for a discrete time step of ?t = 1 ms reads as follows</p><formula xml:id="formula_0">B j (t) = b 0 j + ?b j (t),<label>(1)</label></formula><formula xml:id="formula_1">b j (t + ?t) = ? j b j (t) + (1 ? ? j )z j (t),<label>(2)</label></formula><p>where ? j = exp(? ?t ?a,j ) and z j (t) is the spike train of neuron j assuming values in {0, 1 ?t }. Note that this dynamics of thresholds of adaptive spiking neurons is similar to the dynamics of the state of context neurons in <ref type="bibr" target="#b21">[22]</ref>. It generally suffices to place the time constant of adapting neurons into the desired range for short-term memory (see <ref type="table">Suppl.</ref> for specific values used in each experiment).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Applying BPTT with DEEP R to RSNNs and LSNNs</head><p>We optimize the synaptic weights, and in some cases also the connectivity matrix of an LSNN for specific ranges of tasks. The optimization algorithm that we use, backpropagation through time (BPTT), is not claimed to be biologically realistic. But like evolutionary and developmental processes, BPTT can optimize LSNNs for specific task ranges. Backpropagation (BP) had already been applied in <ref type="bibr">[1]</ref> and <ref type="bibr">[2]</ref> to feedforward networks of spiking neurons. In these approaches, the gradient is backpropagated through spikes by replacing the non-existent derivative of the membrane potential at the time of a spike by a pseudo-derivative that smoothly increases from 0 to 1, and then decays back to 0. We reduced ("dampened") the amplitude of the pseudo-derivative by a factor &lt; 1 (see Suppl. for details). This enhances the performance of BPTT for RSNNs that compute during larger time spans, that require backpropagation through several 1000 layers of an unrolled feedforward network of spiking neurons. A similar implementation of BPTT for RSNNs was proposed in <ref type="bibr" target="#b14">[15]</ref>. It is not yet clear which of these two versions of BPTT work best for a given task and a given network.</p><p>In order to optimize not only the synaptic weights of a RSNN but also its connectivity matrix, we integrated BPTT with the biologically inspired <ref type="bibr">[3]</ref> rewiring method DEEP R <ref type="bibr">[4]</ref> (see Suppl. for details). DEEP R converges theoretically to an optimal network configuration by continuously updating the set of active connections <ref type="bibr" target="#b22">[23,</ref><ref type="bibr">3,</ref><ref type="bibr">4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Computational performance of LSNNs</head><p>Sequential MNIST: We tested the performance of LSNNs on a standard benchmark task that requires continuous updates of short term memory over a long time span: sequential MNIST <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>. We compare the performance of LSNNs with that of LSTM networks. The size of the LSNN, in the case of full connectivity, was chosen to match the number of parameters of the LSTM network. This led to 120 regular spiking and 100 adaptive neurons (with adaptation time constant ? a of 700 ms) in comparison to 128 LSTM units. Actually it turned out that the sparsely connected LSNN shown in <ref type="figure">Fig. 1C</ref>, which was generated by including DEEP R in BPTT, had only 12% of the synaptic connections but performed better than the fully connected LSNN (see "DEEP R LSNN" versus "LSNN" in The task is to classify the handwritten digits of the MNIST dataset when the pixels of each handwritten digit are presented sequentially, one after the other in 784 steps, see <ref type="figure">Fig. 1A</ref>. After each presentation of a handwritten digit, the network is required to output the corresponding class. The grey values of pixels were given directly to artificial neural networks (ANNs), and encoded by spikes for RSNNs. We considered both the case of step size 1 ms (requiring 784 ms for presenting the input image) and 2 ms (requiring 1568 ms for each image, the adaptation time constant ? a was set to 1400 ms in this case, see <ref type="figure">Fig. 1B</ref>.). The top row of <ref type="figure">Fig. 1D</ref> shows a version where the grey value of the currently presented pixel is encoded by population coding through the firing probability of the 80 input neurons. Somewhat better performance was achieved when each of the 80 input neurons is associated with a particular threshold for the grey value, and this input neuron fires whenever the grey value crosses its threshold in the transition from the previous to the current pixel (this input convention is chosen for the SNN results of <ref type="figure">Fig. 1B</ref>). In either case, an additional input neuron becomes active when the presentation of the 784 pixel values is finished, in order to prompt an output from the network. The firing of this additional input neuron is shown at the top right of the top panel of <ref type="figure">Fig. 1D</ref>. The softmax of 10 linear output neurons Y is trained through BPTT to produce, during this time segment, the label of the sequentially presented handwritten digit. We refer to the yellow shading around 800 ms of the output neuron for label 3 in the plot of the dynamics of the output neurons Y in <ref type="figure">Fig. 1D</ref>. This output was correct.</p><p>A performance comparison is given in <ref type="figure">Fig. 1B</ref>. LSNNs achieve 94.7% and 96.4% classification accuracy on the test set when every pixel is presented for 1 and 2ms respectively. An LSTM network achieves 98.5% and 98.0% accuracy on the same task setups. The LIF and RNN bars in <ref type="figure">Fig. 1B</ref> show that this accuracy is out of reach for BPTT applied to spiking or nonspiking neural networks without enhanced short term memory capabilities. We observe that in the sparse architecture discovered by DEEP R, the connectivity onto the readout neurons Y is denser than in the rest of the network (see <ref type="figure">Fig. 1C</ref>). Detailed results are given in the supplement. <ref type="figure">Figure 1</ref>: Sequential MNIST. A The task is to classify images of handwritten digits when the pixels are shown sequentially pixel by pixel, in a fixed order row by row. B The performance of RSNNs is tested for three different setups: without adapting neurons (LIF), a fully connected LSNN, and an LSNN with randomly initialized connectivity that was rewired during training (DEEP R LSNN). For comparison, the performance of two ANNs, a fully connected RNN and an LSTM network are also shown. C Connectivity (in terms of connection probabilities between and within the 3 subpopulations) of the LSNN after applying DEEP R in conjunction with BPTT. The input population X consisted of 60 excitatory and 20 inhibitory neurons. Percentages on the arrows from X indicate the average connection probabilities from excitatory and inhibitory neurons. D Dynamics of the LSNN after training when the input image from A was sequentially presented. From top to bottom: spike rasters from input neurons (X), and random subsets of excitatory (E) and inhibitory (I) regularly spiking neurons, and adaptive neurons (A), dynamics of the firing thresholds of a random sample of adaptive neurons; activation of softmax readout neurons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speech recognition (TIMIT):</head><p>We also tested the performance of LSNNs for a real-world speech recognition task, the TIMIT dataset. A thorough study of the performance of many variations of LSTM networks on TIMIT has recently been carried out in <ref type="bibr" target="#b25">[26]</ref>. We used exactly the same setup which was used there (framewise classification) in order to facilitate comparison. We found that a standard LSNN consisting of 300 regularly firing (200 excitatory and 100 inhibitory) and 100 excitatory adapting neurons with an adaptation time constant of 200 ms, and with 20% connection probability in the network, achieved a classification error of 33.2%. This error is below the mean error around 40% from 200 trials with different hyperparameters for the best performing (and most complex) version of LSTMs according to <ref type="figure" target="#fig_2">Fig. 3</ref> of <ref type="bibr" target="#b25">[26]</ref>, but above the mean of 29.7% of the 20 best performing choices of hyperparameters for these LSTMs. The performance of the LSNN was however somewhat better than the error rates achieved in <ref type="bibr" target="#b25">[26]</ref> for a less complex version of LSTMs without forget gates (mean of the best 20 trials: 34.2%).</p><p>We could not perform a similarly rigorous search over LSNN architectures and meta-parameters as was carried out in <ref type="bibr" target="#b25">[26]</ref> for LSTMs. But if all adapting neurons are replaced by regularly firing excitatory neurons one gets a substantially higher error rate than the LSNN with adapting neurons: 37%. Details are given in the supplement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">LSNNs learn-to-learn from a teacher</head><p>One likely reason why learning capabilities of RSNN models have remained rather poor is that one usually requires a tabula rasa RSNN model to learn. In contrast, RSNNs in the brain have been optimized through a host of preceding processes, from evolution to prior learning of related tasks, for their learning performance. We emulate a similar training paradigm for RSNNs using the L2L setup. We explore here only the application of L2L to LSNNs, but L2L can also be applied to RSNNs without adapting neurons <ref type="bibr" target="#b26">[27]</ref>. An application of L2L to LSNNs is tempting, since L2L is most commonly applied in machine learning to their ANN counterparts: LSTM networks see e.g. <ref type="bibr">[6,</ref><ref type="bibr">7]</ref>. LSTM networks are especially suited for L2L since they can accommodate two levels of learning and representation of learned insight: Synaptic connections and weights can encode, on a higher level, a learning algorithm and prior knowledge on a large time-scale. The short-term memory of an LSTM network can accumulate, on a lower level of learning, knowledge during the current learning task. It has recently been argued <ref type="bibr">[8]</ref> that the pre-frontal cortex (PFC) similarly accumulates knowledge during fast reward-based learning in its short-term memory, without using dopamine-gated synaptic plasticity, see the text to Suppl. <ref type="figure" target="#fig_2">Fig. 3</ref> in <ref type="bibr">[8]</ref>. The experimental results of <ref type="bibr" target="#b27">[28]</ref> suggest also a prominent role of short-term memory for fast learning in the motor cortex.</p><p>The standard setup of L2L involves a large, in fact in general infinitely large, family F of learning tasks C. Learning is carried out simultaneously in two loops (see <ref type="figure" target="#fig_1">Fig. 2A</ref>). The inner loop learning involves the learning of a single task C by a neural network N , in our case by an LSNN. Some parameters of N (termed hyper-parameters) are optimized in an outer loop optimization to support fast learning of a randomly drawn task C from F. The outer loop training -implemented here through BPTT -proceeds on a much larger time scale than the inner loop, integrating performance evaluations from many different tasks C of the family F. One can interpret this outer loop as a process that mimics the impact of evolutionary and developmental optimization processes, as well as prior learning, on the learning capability of brain networks. We use the terms training and optimization interchangeably, but the term training is less descriptive of the longer-term evolutionary processes we mimic. Like in <ref type="bibr" target="#b28">[29,</ref><ref type="bibr">6,</ref><ref type="bibr">7]</ref> we let all synaptic weights of N belong to the set of hyperparameters that are optimized through the outer loop. Hence the network is forced to encode all results from learning the current task C in its internal state, in particular in its firing activity and the thresholds of adapting neurons. Thus the synaptic weights of the neural network N are free to encode an efficient algorithm for learning arbitrary tasks C from F.</p><p>When the brain learns to predict sensory inputs, or state changes that result from an action, this can be formalized as learning from a teacher (i.e., supervised learning). The teacher is in this case the environment, which provides -often with some delay -the target output of a network. The L2L results of <ref type="bibr" target="#b28">[29]</ref> show that LSTM networks can learn nonlinear functions from a teacher without modifying their synaptic weights, using their short-term memory instead. We asked whether this form of learning can also be attained by LSNNs.</p><p>Task: We considered the task of learning complex non-linear functions from a teacher. Specifically, we chose as family F of tasks a class of continuous functions of two real-valued variables (x 1 , x 2 ). This class was defined as the family of all functions that can be computed by a 2-layer artificial neural network of sigmoidal neurons with 10 neurons in the hidden layer, and weights and biases from [-1, 1], see <ref type="figure" target="#fig_1">Fig. 2B</ref>. Thus overall, each such target network (TN) from F was defined through 40 parameters in the range [-1, 1]: 30 weights and 10 biases. We gave the teacher input to the LSNN for learning a particular TN C from F in a delayed manner as in <ref type="bibr" target="#b28">[29]</ref>: The target output value was given after N had provided its guessed output value for the preceding input.</p><p>This delay of the feedback is consistent with biologically plausible scenarios. Simultaneously, having a delay for the feedback prevents N from passing on the teacher value as output without first producing a prediction on its own. Implementation: We considered a LSNN N consisting of 180 regularly firing neurons (population R) and 120 adapting neurons (population A) with a spread of adaptation time constants sampled uniformly between 1 and 1000 ms and with full connectivity. Sparse connectivity in conjunction with rewiring did not improve performance in this case. All neurons in the LSNN received input from a population X of 300 external input neurons. A linear readout received inputs from all neurons in R and A. The LSNN received a stream of 3 types of external inputs (see top row of <ref type="figure" target="#fig_1">Fig. 2D</ref>): the values of x 1 , x 2 , and of the output C(x 1 , x 2 ) of the TN for the preceding input pair x 1 , x 2 (set to 0 at the first trial), all represented through population coding in an external population of 100 spiking neurons. It produced outputs in the form of weighted spike counts during 20 ms windows from all neurons in the network (see bottom row of <ref type="figure" target="#fig_1">Fig. 2D</ref>), where the weights for this linear readout were trained, like all weights inside the LSNN, in the outer loop, and remained fixed during learning of a particular TN.</p><p>The training procedure in the outer loop of L2L was as follows: Network training was divided into training episodes. At the start of each training episode, a new target network TN was randomly chosen and used to generate target values C(x 1 , x 2 ) ? [0, 1] for randomly chosen input pairs (x 1 , x 2 ). 500 of these input pairs and targets were used as training data, and presented one per step to the LSNN during the episode, where each step lasted 20 ms. LSNN parameters were updated using BPTT to minimize the mean squared error between the LSNN output and the target in the training set, using gradients computed over batches of 10 such episodes, which formed one iteration of the outer loop. In other words, each weight update included gradients calculated on the input/target pairs from 10 different TNs. This training procedure forced the LSNN to adapt its parameters in a way that supported learning of many different TNs, rather than specializing on predicting the output of single TN. After training, the weights of the LSNN remained fixed, and it was required to learn the input/output behaviour of TNs from F that it had never seen before in an online manner by just using its short-term memory and dynamics. See the suppl. for further details.</p><p>Results: Most of the functions that are computed by TNs from the class F are nonlinear, as illustrated in <ref type="figure" target="#fig_1">Fig. 2G</ref> for the case of inputs (x 1 , x 2 ) with x 1 = x 2 . Hence learning the input/output behaviour of any such TN with biologically realistic local plasticity mechanisms presents a daunting challenge for a SNN. <ref type="figure" target="#fig_1">Fig. 2C</ref> shows that after a few thousand training iterations in the outer loop, the LSNN achieves low MSE for learning new TNs from the family F, significantly surpassing the performance of an optimal linear approximator (linear regression) that was trained on all 500 pairs of inputs and target outputs, see orange curve in <ref type="figure" target="#fig_1">Fig. 2C</ref>,E. In view of the fact that each TN is defined by 40 parameters, it comes at some surprise that the resulting network learning algorithm of the LSNN for learning the input/output behaviour of a new TN produces in general a good approximation of the TN after just 5 to 20 trials, where in each trial one randomly drawn labelled example is presented. One sample of a generic learning process is shown in <ref type="figure" target="#fig_1">Fig. 2D</ref>. Each sequence of examples evokes an internal model that is stored in the short-term memory of the LSNN. <ref type="figure" target="#fig_1">Fig. 2H</ref> shows the fast evolution of internal models of the LSNN for the TN during the first trials (visualized for a 1D subset of the 2D input space). We make the current internal model of the LSNN visible by probing its prediction C(x 1 , x 2 ) for hypothetical new inputs for evenly spaced points (x 1 , x 2 ) in the domain (without allowing it to modify its short-term memory; all other inputs advance the network state according to the dynamics of the LSNN). One sees that the internal model of the LSNN is from the beginning a smooth function, of the same type as the ones defined by the TNs in F. Within a few trials this smooth function approximated the TN quite well. Hence the LSNN had acquired during the training in the outer loop of L2L a prior for the types of functions that are to be learnt, that was encoded in its synaptic weights. This prior was in fact quite efficient, since <ref type="figure" target="#fig_1">Fig. 2E</ref> and F show that the LSNN was able to learn a TN with substantially fewer trials than a generic learning algorithm for learning the TN directly in an artificial neural network as in <ref type="figure" target="#fig_1">Fig. 2A</ref>: BP with a prior that favored small weights and biases (see end of Sec. 3 in suppl.). These results suggest that L2L is able to install some form of prior knowledge about the task in the LSNN. We conjectured that the LSNN fits internal models for smooth functions to the examples it received.</p><p>We tested this conjecture in a second, much simpler, L2L scenario. Here the family F consisted of all sinus functions with arbitrary phase and amplitudes between 0.1 and 5. <ref type="figure" target="#fig_1">Fig. 2I</ref> shows that the LSNN also acquired an internal model for sinus functions (made visible analogously as in <ref type="figure" target="#fig_1">Fig. 2H</ref>) in this setup from training in the outer loop. Even when we selected examples in an adversarial manner, which happened to be in a straight line, this did not disturb the prior knowledge of the LSNN.</p><p>Altogether the network learning that was induced through L2L in the LSNNs is of particular interest from the perspective of the design of learning algorithms, since we are not aware of previously documented methods for installing structural priors for online learning of a recurrent network of spiking neurons.  Before training, the agent performs a random walk (C). In this example it does not find the goal within the limited episode duration. After training (D), the LSNN had acquired an efficient exploration strategy that uses two pieces of abstract knowledge: that the goal always lies on the border, and that the goal position is the same throughout an episode. Note that all synaptic weights of the LSNNs remained fixed after training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">LSNNs learn-to-learn from reward</head><p>We now turn to an application of meta reinforcement learning (meta-RL) to LSNNs. In meta-RL, the LSNN receives rewards instead of teacher inputs. Meta-RL has led to a number of remarkable results for LSTM networks, see e.g. <ref type="bibr">[6,</ref><ref type="bibr">7]</ref>. In addition, <ref type="bibr">[8]</ref> demonstrates that meta-RL provides a very interesting perspective of reward-based learning in the brain. We focused on one of the more challenging demos of <ref type="bibr">[6]</ref> and <ref type="bibr">[7]</ref>, where an agent had to learn to find a target in a 2D arena, and to navigate subsequently to this target from random positions in the arena. This task is related to the well-known biological learning paradigm of the Morris water maze task <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>. We study here the capability of an agent to discover two pieces of abstract knowledge from the concrete setup of the task: the distribution of goal positions, and the fact that the goal position is constant within each episode. We asked whether the agent would be able to exploit the pieces of abstract knowledge from learning for many concrete episodes, and use it to navigate more efficiently.</p><p>Task: An LSNN-based agent was trained on a family of navigation tasks with continuous state and action spaces in a circular arena. The task is structured as a sequence of episodes, each lasting 2 seconds. The goal was placed randomly for each episode on the border of the arena. When the agent reached the goal, it received a reward of 1, and was placed back randomly in the arena. When the agent hit a wall, it received a negative reward of -0.02 and the velocity vector was truncated to remain inside the arena. The objective was to maximize the number of goals reached within the episode. This family F of tasks is defined by the infinite set of possible goal positions. For each episode, an optimal agent is expected to explore until it finds the goal position, memorize it and exploits this knowledge until the end of the episode by taking the shortest path to the goal. We trained an LSNN so that the network could control the agent's behaviour in all tasks, without changing its network weights.</p><p>Implementation: Since LSNNs with just a few hundred neurons are not able to process visual input, we provided the current position of the agent within the arena through a place-cell like Gaussian population rate encoding of the current position. The lack of visual input made it already challenging to move along a smooth path, or to stay within a safe distance from the wall. The agent received information about positive and negative rewards in the form of spikes from external neurons. For training in the outer loop, we used BPTT together with DEEP R applied to the surrogate objective of the Proximal Policy Optimization (PPO) algorithm <ref type="bibr" target="#b31">[32]</ref>. In this task the LSNN had 400 recurrent units (200 excitatory, 80 inhibitory and 120 adaptive neurons with adaptation time constant ? a of 1200 ms), the network was rewired with a fixed connectivity of 20%. The resulting network diagram and spike raster is shown in Suppl. <ref type="figure">Fig. 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results:</head><p>The network behaviour before, during, and after L2L optimization is shown in <ref type="figure" target="#fig_2">Fig. 3</ref>. <ref type="figure" target="#fig_2">Fig. 3A</ref> shows that a large number of training episodes finally provides significant improvements. With a close look at <ref type="figure" target="#fig_2">Fig. 3B</ref>, one sees that before 52k training episodes, the intermediate path plan-ning strategies did not seem to use the discovered goal position to make subsequent paths shorter. Hence the agents had not yet discovered that the goal position does not change during an episode. After training for 300k episodes, one sees from the sample paths in <ref type="figure" target="#fig_2">Fig. 3D</ref> that both pieces of abstract knowledge had been discovered by the agent. The first path in <ref type="figure" target="#fig_2">Fig. 3D</ref> shows that the agent exploits that the goal is located on the border of the maze. The second and last paths show that the agent knows that the position is fixed throughout an episode. Altogether this demo shows that meta-RL can be applied to RSNNs, and produces previously not seen capabilities of sparsely firing RSNNs to extract abstract knowledge from experimentation, and to use it in clever ways for controlling behaviour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>We have demonstrated that deep learning provides a useful new tool for the investigation of networks of spiking neurons: It allows us to create architectures and learning algorithms for RSNNs with enhanced computing and learning capabilities. In order to demonstrate this, we adapted BPTT so that it works efficiently for RSNNs, and can be combined with a biologically inspired synaptic rewiring method (DEEP R). We have shown in section 4 that this method allows us to create sparsely connected RSNNs that approach the performance of LSTM networks on common benchmark tasks for the classification of spatio-temporal patterns (sequential MNIST and TIMIT). This qualitative jump in the computational power of RSNNs was supported by the introduction of adapting neurons into the model. Adapting neurons introduce a spread of longer time constants into RSNNs, as they do in the neocortex according to <ref type="bibr" target="#b32">[33]</ref>. We refer to the resulting variation of the RSNN model as LSNNs, because of the resulting longer short-term memory capability. This form of short-term memory is of particular interest from the perspective of energy efficiency of SNNs, because it stores and transmits stored information through non-firing of neurons: A neuron that holds information in its increased firing threshold tends to fire less often.</p><p>We have shown in <ref type="figure" target="#fig_1">Fig. 2</ref> that an application of deep learning (BPTT and DEEP R) in the outer loop of L2L provides a new paradigm for learning of nonlinear input/output mappings by a RSNN. This learning task was thought to require an implementation of BP in the RSNN. We have shown that it requires no BP, not even changes of synaptic weights. Furthermore we have shown that this new form of network learning enables RSNNs, after suitable training with similar learning tasks in the outer loop of L2L, to learn a new task from the same class substantially faster. The reason is that the prior deep learning has installed abstract knowledge (priors) about common properties of these learning tasks in the RSNN. To the best of our knowledge, transfer learning capabilities and the use of prior knowledge (see <ref type="figure" target="#fig_1">Fig. 2I</ref>) have previously not been demonstrated for SNNs. <ref type="figure" target="#fig_2">Fig 3 shows</ref> that L2L also embraces the capability of RSNNs to learn from rewards (meta-RL). For example, it enables a RSNN -without any additional outer control or clock -to embody an agent that first searches an arena for a goal, and subsequently exploits the learnt knowledge in order to navigate fast from random initial positions to this goal. Here, for the sake of simplicity, we considered only the more common case when all synaptic weights are determined by the outer loop of L2L. But similar results arise when only some of the synaptic weights are learnt in the outer loop, while other synapses employ local synaptic plasticity rules to learn the current task <ref type="bibr" target="#b26">[27]</ref>.</p><p>Altogether we expect that the new methods and ideas that we have introduced will advance our understanding and reverse engineering of RSNNs in the brain. For example, the RSNNs that emerged in <ref type="figure" target="#fig_2">Fig. 1-3</ref> all compute and learn with a brain-like sparse firing activity, quite different from a SNN that operates with rate-codes. In addition, these RSNNs present new functional uses of short-term memory that go far beyond remembering a preceding input as in <ref type="bibr" target="#b33">[34]</ref>, and suggest new forms of activity-silent memory <ref type="bibr" target="#b34">[35]</ref>.</p><p>Apart from these implications for computational neuroscience, our finding that RSNNs can acquire powerful computing and learning capabilities with very energy-efficient sparse firing activity provides new application paradigms for spike-based computing hardware through non-firing. 785907 (Human Brain Project SGA2). We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Quadro P6000 GPU used for this research. Research leading to these results has in parts been carried out on the Human Brain Project PCP Pilot Systems at the J?lich Supercomputing Centre, which received co-funding from the European Union (Grant Agreement No. 604102). We gratefully acknowledge Sandra Diaz, Alexander Peyser and Wouter Klijn from the Simulation Laboratory Neuroscience of the J?lich Supercomputing Centre for their support. The computational results presented have been achieved in part using the Vienna Scientific Cluster (VSC). We provide in this supplement detailed information on the models and simulations of the main text, structured according to the corresponding sections therein.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary information for: Long short-term memory and learning-to-learn in networks of spiking neurons</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">LSNN model</head><p>Neuron model: In continuous time the spike trains x i (t) and z j (t) are formalized as sums of Dirac pulses. Neurons are modeled according to a standard adaptive leaky integrate-and-fire model. A neuron j spikes as soon at its membrane potential V j (t) is above its threshold B j (t). At each spike time t, the membrane potential V j (t) is reset by subtracting the current threshold value B j (t) and the neuron enters a strict refractory period where it cannot spike again. Importantly at each spike the threshold B j (t) of an adaptive neuron is increased by a constant ?/? a,j . Then the threshold decays back to a baseline value b 0 j . Between spikes the membrane voltage V j (t) and the threshold B j (t) are following the dynamics</p><formula xml:id="formula_2">? mVj (t) = ?V j (t) + R m I j (t) (1) ? a,j?j (t) = b 0 j ? B j (t),<label>(2)</label></formula><p>where ? m is the membrane time constant, ? a,j is the adaptation time constant and R m is the membrane resistance. The input current I j (t) is defined as the weighted sum of spikes from external inputs and other neurons in the network:</p><formula xml:id="formula_3">I j (t) = i W in ji x i (t ? d in ji ) + i W rec ji z i (t ? d rec ji ),<label>(3)</label></formula><p>where W in ji and W rec ji denote respectively the input and the recurrent synaptic weights and d in ji and d rec ji the corresponding synaptic delays. All network neurons are connected to a population of readout neurons with weights W out kj . When network neuron j spikes, the output synaptic strength W out kj is added to the membrane voltage y k (t) of all readout neurons k. y k (t) also follows the dynamics of a leaky integrator ? m?k (t) = ?y k (t). Implementation in discrete time: Our simulations were performed in discrete time with a time step ?t = 1 ms. In discrete time, the spike trains are modeled as binary sequences x i (t), z j (t) ? {0, 1 ?t }, so that they converge to sums of Dirac pulses in the limit of small time steps. Neuron j emits a spike at time t if it is currently not in a refractory period, and its membrane potential V j (t) is above its threshold B j (t). During the refractory period following a spike, z j (t) is fixed to 0. The dynamics of the threshold is defined by B j (t) = b 0 j + ?b j (t) where ? is a constant which scales the deviation b j (t) from the baseline b 0 j . The neural dynamics in discrete time reads as follows where ? = exp(? ?t ?m ) and ? j = exp(? ?t ?a,j ). The term B j (t)z j (t)?t implements the reset of the membrane voltage after each spike. The current I j (t) is the weighted sum of the incoming spikes. The definition of the input current in equation <ref type="formula" target="#formula_3">(3)</ref> holds also for discrete time, with the difference that spike trains now assume values in {0, 1 ?t }.</p><formula xml:id="formula_4">V j (t + ?t) = ?V j (t) + (1 ? ?)R m I j (t) ? B j (t)z j (t)?t (4) b j (t + ?t) = ? j b j (t) + (1 ? ? j )z j (t),<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Applying BPTT with DEEP R to RSNNs and LSNNs</head><p>Propagation of gradients in recurrent networks of LIF neurons: In artificial recurrent neural networks such as LSTMs, gradients can be computed with backpropagation through time (BPTT). For BPTT in spiking neural networks, complications arise from the non-differentiability of the output of spiking neurons, and from the fact that gradients need to be propagated either through continuous time or through many time steps if time is discretized. Therefore, in <ref type="bibr">[1,</ref><ref type="bibr">2]</ref> it was proposed to use a pseudo-derivative.</p><formula xml:id="formula_5">dz j (t) dv j (t) := max{0, 1 ? |v j (t)|},<label>(6)</label></formula><p>where v j (t) denotes the normalized membrane potential v j (t) =</p><formula xml:id="formula_6">Vj (t)?Bj (t) Bj (t)</formula><p>. This made it possible to train deep feed-forward networks of deterministic binary neurons <ref type="bibr">[1,</ref><ref type="bibr">2]</ref>. We observed that this convention tends to be unstable for very deep (unrolled) recurrent networks of spiking neurons. To achieve stable performance we dampened the increase of back propagated errors through spikes by using a pseudo-derivative of amplitude ? &lt; 1 (typically ? = 0.3):</p><formula xml:id="formula_7">dz j (t) dv j (t) := ? max{0, 1 ? |v j (t)|}.<label>(7)</label></formula><p>Note that in adaptive neurons, gradients can propagate through many time steps in the dynamic threshold. This propagation is not affected by the dampening.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rewiring and weight initialization of excitatory and inhibitory neurons:</head><p>In all experiments except those reported in <ref type="figure" target="#fig_1">Fig. 2</ref>, the neurons were either excitatory or inhibitory. When the neuron sign were not constrained, the initial network weights were drawn from a Gaussian distribution W ji ? w0 ? nin N (0, 1), where n in is the number of afferent neurons in the considered weight matrix (i.e., the number of columns of the matrix), N (0, 1) is the zero-mean unit-variance Gaussian distribution and w 0 is a weightscaling factor chosen to be w 0 = 1Volt Rm ?t. With this choice of w 0 the resistance R m becomes obsolete but the vanishing-exploding gradient theory <ref type="bibr">[3,</ref><ref type="bibr">4]</ref> can be used to avoid tuning by hand the scaling of W ji . In particular the scaling 1 ? nin used above was sufficient to initialize networks with realistic firing rates and that can be trained efficiently.</p><p>When the neuron sign were constrained, all outgoing weights W rec ji or W out ji of a neuron i had the same sign. In those cases, DEEP R <ref type="bibr">[5]</ref> was used as it maintains the sign of each synapse during training. The sign is thus inherited from the initialization of the network weights. This raises the need of an efficient initialization of weight matrices for given fractions of inhibitory and excitatory neurons. To do so, a sign ? i ? {?1, 1} is generated randomly for each neuron i by sampling from a Bernoulli distribution. The weight matrix entries are then sampled from W ji ? ? i |N (0, 1)| and post-processed to avoid exploding gradients. Firstly, a constant is added to each weight so that the sum of excitatory and inhibitory weights onto each neuron j ( i W ji ) is zero <ref type="bibr">[6]</ref> (if j has no inhibitory or no excitatory incoming connections this step is omitted). To avoid exploding gradients it is important to scale the weight so that the largest eigenvalue is lower of equal to 1 <ref type="bibr">[3]</ref>. Thus, we divided W ji by the absolute value of its largest eigenvalue. When the matrix is not square, eigenvalues are ill-defined. Therefore, we first generated a large enough square matrix and selected the required number of rows or columns with uniform probabilities. The final weight matrix is scaled by w 0 for the same reasons as before.</p><p>To initialize matrices with a sparse connectivity, dense matrices were generated as described above and multiplied with a binary mask. The binary mask was generated by sampling uniformly the neuron coordinates that were non-zero at initialization. DEEP R maintains the initial connectivity level throughout training by dynamically disconnecting synapses and reconnecting others elsewhere. The L 1 -norm regularization parameter of DEEP R was set to 0.01 and the temperature parameter of DEEP R was left at 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Computational performance of LSNNs</head><p>MNIST setup: The pixels of an MNIST image were presented sequentially to the LSNN in 784 time steps. Two input encodings were considered. First, we used a population coding where the grey scale value (which is in the range [0, 1]) of the currently presented pixel was directly used as the firing probability of each of the 80 input neurons in that time step.</p><p>In a second type of input encoding -that is closer to the way how spiking vision sensors encode their input -each of the 80 input neurons was associated with a particular threshold for the grey value, and this input neuron fired whenever the grey value of the currently presented pixel crossed its threshold. Here, we used two input neurons per threshold, one spiked at threshold crossings from below, and one at the crossings from above. This input convention was chosen for the LSNN results of <ref type="figure">Fig. 1.B</ref>.</p><p>The output of the network was determined by averaging the readout output over the 56 time steps following the presentation of the digit. The network was trained by minimizing the cross entropy error between the softmax of the averaged readout and the label distributions. The best performing models use rewiring with a global connectivity level of 12% was used during training to optimize a sparse network connectivity structure (i.e., when randomly picking two neurons in the network, the probability that they would be connected is 0.12). This implies that only a fraction of the parameters were finally used as compared to a similarly performing LSTM network.</p><p>Tables S1 and S2 contain the results and details of training runs where each time step lasted for 1 ms and 2 ms respectively.  <ref type="table">Table S1</ref>: Results on the sequential MNIST task when each pixel is displayed for 1ms. For an LSNN, DEEP R is used to optimize the network under a sparse connectivity constraint, we report the number of parameters including and not including the disconnected synapses.  <ref type="table">Table S2</ref>: Results on the sequential MNIST task when each pixel is displayed for 2ms.</p><p>TIMIT setup: To investigate if the performance of LSNNs can scale to real world problems, we considered the TIMIT speech recognition task. We focused on the frame-wise classification where the LSNN has to classify each audio-frame to one of the 61 phoneme classes.</p><p>We followed the convention of Halberstadt <ref type="bibr">[7]</ref> for grouping of training, validation, and testing sets (3696, 400, and 192 sequences respectively). The performance was evaluated on the core test set for consistency with the literature. Raw audio is preprocessed into 13 Mel Frequency Cepstral Coefficients (MFCCs) with frame size 10 ms and on input window of 25 ms. We computed the first and the second order derivatives of MFCCs and combined them, resulting in 39 input channels. These 39 input channels were mapped to 39 input neurons which unlike in MNIST emit continuous values x i (t) instead of spikes, and these values were directly used in equation 3 for the currents of the postsynaptic neurons.</p><p>Since we simulated the LSNN network in 1 ms time steps, every input frame which represents 10 ms of the input audio signal was fed to the LSNN network for 10 consecutive 1 ms steps. The softmax output of the LSNN was averaged over every 10 steps to produce the prediction of the phone in the current input frame. The LSNN was rewired with global connectivity level of 20%.</p><p>Parameter values: For adaptive neurons, we used ? j = 1.8, and for regular spiking neurons we used ? j = 0 (i.e. B j is constant). The baseline threshold voltage was b 0 j = 0.01 and the membrane time constant ? m = 20 ms. Networks were trained using the default Adam optimizer, and a learning rate initialized at 0.01. The dampening factor for training was ? = 0.3.</p><p>For sequential MNIST, all networks were trained for 36000 iterations with a batch size of 256. Learning rate was decayed by a factor 0.8 every 2500 iterations. The adaptive neurons in the LSNN had an adaptation time constant ? a = 700 ms (1400 ms) for 1 ms (2 ms) per pixel setup. The baseline artificial RNN contained 128 hidden units with the hyperbolic tangent activation function. The LIF network was formed by a fully connected population of 220 regular spiking neurons.</p><p>For TIMIT, the LSNN network consisted of 300 regular neurons and 100 adaptive neurons which resulted in approximately 400000 parameters. Network was trained for 80 epochs with batches of 32 sequences. Adaptation time constant of adaptive neurons was set to ? a = 200 ms. Refractory period of the neurons was set to 2 ms, the membrane time constant of the output Y neurons to 3 ms, and the synaptic delay was randomly picked from {1, 2} ms.</p><p>We note that due to the rewiring of the LSNN using DEEP R <ref type="bibr">[5]</ref> method, only a small fraction of the weights had non-zero values (8185 in MNIST, ? 80000 in TIMIT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">LSNNs learn-to-learn from a teacher</head><p>Experimental setup:</p><p>Function families: The LSNN was trained to implement a regression algorithm on a family of functions F. Two specific families were considered: In the first function family, the functions were defined by feed-forward neural networks with 2 inputs, 1 hidden layer consisting of 10 hidden neurons, and 1 output, where all the parameters (weights and biases) were chosen uniformly randomly between [?1, 1]. The inputs were between [?1, 1] and the outputs were scaled to be between [0, 1]. We call these networks Target Networks (TNs). In the second function family, the targets were defined by sinusoidal functions y = A sin(? + x) over the domain x ? [?5, 5]. The specific function to be learned was defined then by the phase ? and the amplitude A, which were chosen uniformly random between [0, ?] and [0.1, 5] respectively.</p><p>Input encoding: Analog values were transformed into spiking trains to serve as inputs to the LSNN as follows: For each input component, 100 input neurons are assigned values m 1 , . . . m 100 evenly distributed between the minimum and maximum possible value of the input. Each input neuron has a Gaussian response field with a particular mean and standard deviation, where the means are uniformly distributed between the minimum and maximum values to be encoded, and with a constant standard deviation. More precisely, the firing rate r i (in Hz) of each input neuron i is given by</p><formula xml:id="formula_8">r i = r max exp ? (mi?zi) 2 2 ? 2</formula><p>, where r max = 200 Hz, m i is the value assigned to that neuron, z i is the analog value to be encoded, and ? = (mmax?mmin) 1000 , m min with m max being the minimum and maximum values to be encoded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LSNN setup and training schedule:</head><p>The standard LSNN model was used, with 300 hidden neurons for the TN family of learning tasks, and 100 for the sinusoidal family. Of these, 40% were adaptive in all simulations. We used all-to-all connectivity between all neurons (regular and adaptive). The output of the LSNN was a linear readout that received as input the mean firing rate of each of the neurons per step i.e the number of spikes divided by 20 for the 20 ms time window that the step consists of.</p><p>The network training proceeded as follows: A new target function was randomly chosen for each episode of training, i.e., the parameters of the target function are chosen uniformly randomly from within the ranges above (depending on whether its a TN or sinusoidal). Each episode consisted of a sequence of 500 steps, each lasting for 20 ms. In each step, one training example from the current function to be learned was presented to the LSNN. In such a step, the inputs to the LSNN consisted of a randomly chosen vector x with its dimensionality d and range determined by the target function being used (d = 2 for TNs, d = 1 for sinusoidal target function). In addition, at each step, the LSNN also got the target value C(x ) from the previous step, i.e., the value of the target calculated using the target function for the inputs given at the previous step (in the first step, C(x ) is set to 0).</p><p>All the weights of the LSNN were updated using our variant of BPTT, once per iteration, where an iteration consists of a batch of 10 episodes, and the weight updates are accumulated across episodes in an iteration. The Adam <ref type="bibr">[8]</ref> variant of BP was used with standard parameters and a learning rate of 0.001. The loss function for training was the mean squared error (MSE) of the LSNN predictions over an iteration (i.e. over all the steps in an episode, and over the entire batch of episodes in an iteration). In addition, a regularization term was used to maintain a firing rate of 20 Hz. Specifically, the regularization term R is defined as the mean squared difference between the average neuron firing rate in the LSNN and a target of 20 Hz. The total loss L was then given by L = M SE + 30 R. In this way, we induce the LSNN to use sparse firing. We trained the LSNN for 5000 iterations in all cases.</p><p>Parameter values: The LSNN parameters were as follows: 5 ms neuronal refractory period, delays spread uniformly between 0 ? 5 ms, adaptation time constants of the adaptive neurons spread uniformly between 1 ? 1000 ms, ? = 1.6 for adaptive neurons (0 for regular neurons), membrane time constant ? = 20 ms, 0.03 mV baseline threshold voltage. The dampening factor for training was ? = 0.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis and comparison:</head><p>The linear baseline was calculated using linear regression with L2 regularization with a regularization factor of 100 (determined using grid search), using the mean spiking trace of all the neurons. The mean spiking trace was calculated as follows: First the neuron traces were calculated using an exponential kernel with 20 ms width and a time constant of 20 ms. Then, for every step, the mean value of this trace was calculated to obtain the mean spiking trace. In <ref type="figure" target="#fig_1">Fig. 2C</ref>, for each episode consisting of 500 steps, the mean spiking trace from a random subset of 450 steps was used to train the linear regressor, and the mean spiking trace from remaining 50 steps was used to calculate the test error. The reported baseline is the mean of the test error over one batch of 10 episodes with error bars of one standard deviation. In <ref type="figure" target="#fig_1">Fig. 2E</ref>, for each episode, after every step k, the mean spiking traces from the first k ? 1 steps were used to train the linear regressor, and the test error was calculated using the mean spiking trace for the kth step. The reported baseline is a mean of the test error over one batch of 10 episodes with error bars of one standard deviation.</p><p>For the case where neural networks defined the function family, the total test MSE was 0.0056 ? 0.0039 (linear baseline MSE was 0.0217 ? 0.0046). For the sinusoidal function family, the total test MSE was 0.3134 ? 0.2293 (linear baseline MSE was 1.4592 ? 1.2958).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with backprop:</head><p>The comparison was done for the case where the LSNN is trained on the function family defined by target networks. A feed-forward (FF) network with 10 hidden neurons and 1 output was constructed. The input to this FF network were the analog values that were used to generate the spiking input and targets for the LSNN. Therefore the FF had 2 inputs, one for each of x 1 and x 2 . The error reported in <ref type="figure" target="#fig_1">Fig 2F</ref> is the mean training error over 10 batches with error bars of one standard deviation.</p><p>The FF network was initialized with Xavier normal initialization <ref type="bibr">[9]</ref> (which had the best performance, compared to Xavier uniform and plain uniform between [?1, 1]). Adam <ref type="bibr">[8]</ref> with AMSGrad <ref type="bibr">[10]</ref> was used with parameters ? = 10 ?1 , ? 1 = 0.7, ? 2 = 0.9, C = 10 ?5 . These were the optimal parameters as determined by a grid search. Together with the Xavier normal initialization and the weight regularization parameter C, the training of the FF favoured small weights and biases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">LSNNs learn-to-learn from reward</head><p>Experimental setup:</p><p>Task family: An LSNN-based agent was trained on a family of navigation tasks in a two dimensional circular arena. For all tasks, the arena is a circle with radius 1 and goals are smaller circles of radius 0.3 with centres uniformly distributed on the circle of radius 0.85. At the beginning of an episode Supplementary <ref type="figure">Figure S1</ref>: Meta-RL results for an LSNN. A Samples of paths after training. B Connectivity between sub-populations of the network after training. The global connectivity in the network was constrained to 20%. C The network dynamics that produced the behavior shown in A. Raster plots and thresholds are displayed as in <ref type="figure">Fig. 1</ref>.D, only 1 second and 100 neurons are shown in each raster plots. and after the agent reaches a goal, the agent's position is set randomly with uniform probability within the arena. At every timestep, the agent chooses an action by generating a small velocity vector of Euclidean norm smaller or equal to a scale = 0.02. When the agent reaches the goal, it receives a reward of 1. If the agent attempts to move outside the arena, the new position is given by the intersection of the velocity vector with the border and the agent receives a negative reward of ?0.02. Input encoding: Information of the current environmental state s(t) and the reward r(t) were provided to the LSNN at each time step t as follows: The state s(t) is given by the x and y coordinate of the agent's position (see top of <ref type="figure">Fig. S1C</ref>). Each position coordinate ?(t) ? [?1, 1] is encoded by 40 neurons which spike according to a Gaussian population rate code defined as follows: a preferred coordinate value ? i , is assigned to each of the 40 neurons, where ? i 's are evenly spaced between ?1 and 1. The firing rate of neuron i is then given by r max exp(?100(? i ? ?) 2 ) where r max is 500 Hz. The instantaneous reward r(t) is encoded by two groups of 40 neurons (see green row at the top of <ref type="figure">Fig. S1C</ref>). All neuron in the first group spike in synchrony each time a reward of 1 is received (i.e., the goal was reached), and the second group spikes when a reward of ?0.02 is received (i.e., the agent moved into a wall).</p><p>Output decoding: The output of the LSNN is provided by five readout neurons. Their membrane potentials y i (t) define the outputs of the LSNN. The action vector a(t) = (a x (t), a y (t)) T is sampled from the distribution ? ? which depends on the network parameters ? through the readouts y i (t) as follows: The coordinate a x (t) (a y (t)) is sampled from a Gaussian distribution with mean ? x = tanh(y 1 (t)) (? y = tanh(y 2 (t))) and variance ? x = ?(y 3 (t)) (? y = ?(y 4 (t))). The velocity vector that updates the agent's position is then defined as a scale a(t). If this velocity has a norm larger than a scale , it is clipped to a norm of a scale . The last readout output y 5 (t) is used to predict the value function V ? (t). It estimates the expected discounted sum of future rewards R(t) = t &gt;t ? t ?t r(t ), where ? = 0.99 is the discount factor and r(t ) denotes the reward at time t . To enable the network to learn complex forms of exploration we introduced current noise in the neuron model in this task. At each time step, we added a small</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>LSNNs learn to learn from a teacher. A L2L scheme for an SNN N . B Architecture of the two-layer feed-forward target networks (TNs) used to generate nonlinear functions for the LSNN to learn; weights and biases were randomly drawn from[-1,1]. C Performance of the LSNN in learning a new TN during (left) and after (right) training in the outer loop of L2L. Performance is compared to that of an optimal linear predictor fitted to the batch of all 500 experiments for a TN. D Network input (top row, only 100 of 300 neurons shown), internal spike-based processing with low firing rates in the populations R and A (middle rows), and network output (bottom row) for 25 trials of 20 ms each. E Learning performance of the LSNN for 10 new TNs. Performance for a single TN is shown as insert, a red cross marks step 7 after which output predictions became very good for this TN. The spike raster for this learning process is the one depicted in C. Performance is compared to that of an optimal linear predictor, which, for each example, is fitted to the batch of all preceding examples. F Learning performance of BP for the same 10 TNs as in D, working directly on the ANN from A, with a prior for small weights. G Sample input/output curves of TNs on a 1D subset of the 2D input space, for different weight and bias values. H These curves are all fairly smooth, like the internal models produced by the LSNN while learning a particular TN. I Illustration of the prior knowledge acquired by the LSNN through L2L for another family F (sinus functions). Even adversarially chosen examples (Step 4) do not induce the LSNN to forget its prior.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Meta-RL results for an LSNN. A, B Performance improvement during training in the outer loop. C, D Samples of navigation paths produced by the LSNN before and after this training.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research/project was supported by the HBP Joint Platform, funded from the European Union's Horizon 2020 Framework Programme for Research and Innovation under the Specific Grant Agreement No. 720270 (Human Brain Project SGA1) and under the Specific Grant Agreement No.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Network training: To train the network we used the Proximal Policy Optimization algorithm (PPO) <ref type="bibr">[11]</ref>. For each training iteration, K full episodes of T timesteps were generated with fixed parameters ? old (here K = 10 and T = 2000). We write the clipped surrogate objective of PPO as O P P O (? old , ?, t, k) (this is defined under the notation L CLIP in <ref type="bibr">[11]</ref>). The loss with respect to ? is then defined as follows:</p><p>where H(? ? ) is the entropy of the distribution ? ? , f 0 is a target firing rate of 10 Hz, and ? v , ? e , ? f iring are regularization hyper-parameters. Importantly probability distributions used in the definition of the loss L (i.e. the trajectories) are conditioned on the current noises, so that for the same noise and infinitely small parameter change from ? old to ? the trajectories and the spike trains are the same. At each iteration this loss function L is then minimized with one step of the ADAM optimizer.</p><p>Parameter values: In this task the LSNN had 400 hidden units (200 excitatory neurons, 80 inhibitory neurons and 120 adaptive neurons with adaptation time constants ? a = 1200 ms) and the network was rewired with a fixed global connectivity of 20% <ref type="bibr">[5]</ref>. The membrane time constants were similarly sampled between 15 and 30 ms. The adaptation amplitude ? was set to 1.7. The refractory period was set to 3 ms and delays were sampled uniformly between 1 and 10 ms. The regularization parameters ? v , ? e and ? f iring were respectively 1, 0.001, and 100. The parameter of the PPO algorithm was set to 0.2. The learning rate was initialized to 0.01 and decayed by a factor 0.5 every 5000 iterations. We used the default parameters for ADAM, except for the parameter which we set to 10 ?5 .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itay</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Soudry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>El-Yaniv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02830</idno>
		<title level="m">Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Convolutional networks for fast, energy-efficient neuromorphic computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">A</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">V</forename><surname>Merolla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">S</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rathinakumar</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Appuswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Andreopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Mckinstry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davis</forename><forename type="middle">R</forename><surname>Melano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carmelo</forename><surname>Barch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallab</forename><surname>Di Nolfo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnon</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myron</forename><forename type="middle">D</forename><surname>Taba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dharmendra</forename><forename type="middle">S</forename><surname>Flickner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Modha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">41</biblScope>
			<biblScope unit="page" from="11441" to="11446" />
			<date type="published" when="2016-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Rewardbased stochastic self-configuration of neural circuits. eNEURO</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kappel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Legenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Habenschuss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bellec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kappel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Legenstein</surname></persName>
		</author>
		<title level="m">Deep rewiring: Training very sparse deep networks. International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hierarchical process memory: memory as an integral component of information processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janice</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher J</forename><surname>Honey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="304" to="313" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeb</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruva</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Tirumala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">Z</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blundell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05763</idno>
		<title level="m">Dharshan Kumaran, and Matt Botvinick. Learning to reinforcement learn</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">RL 2 : Fast reinforcement learning via slow reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02779</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Prefrontal cortex as a meta-reinforcement learning system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeb</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dharshan</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruva</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Tirumala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">Z</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Demis</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A wafer-scale neuromorphic hardware system for large-scale neural modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Schemmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Br?derle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Gr?bl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karlheinz</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Millner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Circuits and systems (ISCAS), proceedings of 2010 IEEE international symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1947" to="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Overview of the spinnaker system architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Furber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><forename type="middle">A</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><forename type="middle">D</forename><surname>Plana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eustace</forename><surname>Garside</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Painkras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew D</forename><surname>Temple</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2454" to="2467" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A reconfigurable on-line learning spiking neuromorphic processor comprising 256 neurons and 128k synapses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hesham</forename><surname>Mostafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Corradi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Osswald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Stefanini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dora</forename><surname>Sumislawska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giacomo</forename><surname>Indiveri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in neuroscience</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">141</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Loihi: A neuromorphic manycore processor with on-chip learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narayan</forename><surname>Srinivasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Han</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautham</forename><surname>Chinya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Sri Harsha Choday</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasad</forename><surname>Dimou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nabil</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shweta</forename><surname>Imam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="99" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">How to build a brain: A neural architecture for biological cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Eliasmith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Using firing-rate dynamics to train recurrent networks of spiking model neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Depasquale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Churchland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abbott</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.07620</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsung</forename><surname>Huh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrence</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04698</idno>
		<title level="m">Gradient descent for spiking neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Supervised learning in spiking neural networks with force training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilten</forename><surname>Nicola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Clopath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2208</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Computational properties of networks of spiking neurons with adapting neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bellec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darjan</forename><surname>Salaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Subramoney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Legenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>in preparation</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Neuronal dynamics: From single neurons to networks and models of cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wulfram</forename><surname>Gerstner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><forename type="middle">M</forename><surname>Kistler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Naud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Paninski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automated high-throughput characterization of single neurons by means of simplified spiking models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Pozzorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Skander</forename><surname>Mensi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Hagens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Naud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wulfram</forename><surname>Gerstner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1004275</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Systematic generation of biophysically detailed models for diverse cortical neuron types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Nathan W Gouwens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Staci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkui</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Hawrylycz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arkhipov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Generalized leaky integrate-and-fire models classify multiple neuron types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinne</forename><surname>Teeter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishnan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vilas</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Gouwens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Szafer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Cain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkui</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hawrylycz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.7753</idno>
		<title level="m">Learning longer memory in recurrent neural networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Network Plasticity as Bayesian Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kappel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Habenschuss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Legenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1004485</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A simple way to initialize recurrent networks of rectified linear units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<idno>abs/1504.00941</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Cortical microcircuits as gated-recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Ioannis Alexandros Assael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shillingford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="272" to="283" />
		</imprint>
	</monogr>
	<note>Nando de Freitas, and Tim Vogels</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">LSTM: A search space odyssey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rupesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koutn?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Steunebrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Recurrent networks of spiking neurons learn to learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Subramoney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bellec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><surname>Scherr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Legenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>in preparation</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A neural population mechanism for rapid learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">A</forename><surname>Perich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><forename type="middle">E</forename><surname>Gallego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning to learn using gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Younger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter R Conwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Developments of a water-maze procedure for studying spatial learning in the rat</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of neuroscience methods</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="60" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Spike-based reinforcement learning in continuous state and action space: when policy gradient methods fail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Vasilaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Fr?maux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Urbanczik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Senn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wulfram</forename><surname>Gerstner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1000586</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Allen Institute for Brain Science. Allen Cell Types Database, cell feature search. Available from: celltypes.brain-map.org/data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><surname>Institute</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Synaptic theory of working memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianluigi</forename><surname>Mongillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Misha</forename><surname>Tsodyks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">5869</biblScope>
			<biblScope unit="page" from="1543" to="1546" />
			<date type="published" when="2008-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Activity-silent&apos; working memory in prefrontal cortex: a dynamic coding framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stokes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="394" to="405" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itay</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Soudry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>El-Yaniv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02830</idno>
		<title level="m">Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Convolutional networks for fast, energy-efficient neuromorphic computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">A</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">V</forename><surname>Merolla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">S</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rathinakumar</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Appuswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Andreopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Mckinstry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davis</forename><forename type="middle">R</forename><surname>Melano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carmelo</forename><surname>Barch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallab</forename><surname>Di Nolfo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnon</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myron</forename><forename type="middle">D</forename><surname>Taba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dharmendra</forename><forename type="middle">S</forename><surname>Flickner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Modha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">41</biblScope>
			<biblScope unit="page" from="11441" to="11446" />
			<date type="published" when="2016-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning long-term dependencies with gradient descent is difficult</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrice</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="166" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note>Neural Networks</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Random walk initialization for training very deep feedforward networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sussillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abbott</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6558</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bellec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kappel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Legenstein</surname></persName>
		</author>
		<title level="m">Deep rewiring: Training very sparse deep networks. International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Eigenvalue spectra of random matrices for neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Kanaka Rajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abbott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review letters</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page">188104</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Heterogeneous acoustic measurements and multiple classifiers for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">K</forename><surname>Halberstadt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">02</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth international conference on artificial intelligence and statistics</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">On the convergence of adam and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sashank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satyen</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
