<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scribosermo: Fast Speech-to-Text models for German and other Languages</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bermuth</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Software &amp; Systems Engineering</orgName>
								<orgName type="institution">University of Augsburg</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Poeppel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Software &amp; Systems Engineering</orgName>
								<orgName type="institution">University of Augsburg</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Reif</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Software &amp; Systems Engineering</orgName>
								<orgName type="institution">University of Augsburg</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Scribosermo: Fast Speech-to-Text models for German and other Languages</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms: fast speech to text</term>
					<term>multilingual transfer- learning</term>
					<term>automatic speech recognition</term>
					<term>embedded hardware</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent Speech-to-Text models often require a large amount of hardware resources and are mostly trained in English. This paper presents Speech-to-Text models for German, as well as for Spanish and French with special features: (a) They are small and run in real-time on microcontrollers like a RaspberryPi. (b) Using a pretrained English model, they can be trained on consumer-grade hardware with a relatively small dataset. (c) The models are competitive with other solutions and outperform them in German. In this respect, the models combine advantages of other approaches, which only include a subset of the presented features. Furthermore, the paper provides a new library for handling datasets, which is focused on easy extension with additional datasets and shows an optimized way for transfer-learning new languages using a pretrained model from another language with a similar alphabet.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Speech-to-Text models based on neural networks are mostly trained in English and often require large amounts of training resources. But there exist many other languages and those who are interested in training a speech-to-text system for their own language do not always have access to high-performance server hardware. A few papers and projects focus on the aforementioned problems, but most are solving them only partially.</p><p>The authors of IMS-Speech <ref type="bibr" target="#b0">[1]</ref> trained a German STT model, which so far had the best results on the German Tuda dataset <ref type="bibr" target="#b1">[2]</ref>. In a comparison with Google's STT service (executed 01/2019), their network could outperform it in English as well as in German.</p><p>In VoxPopuli <ref type="bibr" target="#b2">[3]</ref>, an approach for training multilingual models using a large unlabeled dataset is investigated. A mix of 50k hours of unlabeled data in different languages from the European Parliament and a comparatively small labeled dataset for semi-supervised training are used. This approach proved very effective and achieves a Word-Error-Rate (WER) of 7.8 % / 9.6 % / 10.0 % in German / Spanish / French on the CommonVoice datasets <ref type="bibr" target="#b3">[4]</ref>, which so far have been the best results on these datasets.</p><p>Luo et al. <ref type="bibr" target="#b4">[5]</ref> used the same network architecture as this work, but in Nvidia's original implementation, and also trained it for other languages like German or Spanish, using very small datasets and following a different transfer-learning approach of reinitializing the last network layer if the alphabet changes.</p><p>Mozilla's DeepSpeech project <ref type="bibr" target="#b5">[6]</ref> provides pretrained English models that are relatively small and one of the few that are able to run in real-time on a RaspberryPi. It achieves a WER of 7.1 % on the LibriSpeech <ref type="bibr" target="#b6">[7]</ref> testset. Some early experiments on multilingual trainings have been run with this network, but per-formance was much lower than the results presented in the following chapters. They still can be found in the project's repository which is linked later.</p><p>Park et al. <ref type="bibr" target="#b7">[8]</ref> built a model for embedded devices, which reached a WER of 9.0 % on LibriSpeech and could run on an ARM-Cortex-A57. Zhang et al. <ref type="bibr" target="#b8">[9]</ref> trained a very small model on a large in-house Chinese dataset which can run faster than real-time on an ARMv7 chip. He et al. <ref type="bibr" target="#b9">[10]</ref> did train an English model on a very large in-house dataset which can run twice as fast than real-time on a Google-Pixel smartphone.</p><p>Ghoshal et al. <ref type="bibr" target="#b10">[11]</ref> and Thomas et al. <ref type="bibr" target="#b11">[12]</ref> did run early explorations of transfer-learning for different languages using deep neural networks. The first approach replaces the last language specific layer of a network with a new one and finetunes the whole network on the new language, while the second uses a multilingual training of the first network layers, and different output layers for each language. This paper presents a small Speech-to-Text model for German, as well as for Spanish and French, that combines the advantages of the aforementioned approaches. The main contributions of project Scribosermo are: (a) The models are competitive with the models from IMS-Speech and VoxPopuli. (b) Providing pretrained models in multiple languages that can run in real-time even on single-board computers like a RaspberryPi. (c) The models can be trained on a relatively small dataset, like the models from VoxPopuli and only require consumer-grade hardware for training. (d) Shows a fast transfer-learning approach with a single step through the concept of alphabet adaption. (e) Improved SOTA performance for German STT.</p><p>Furthermore, the paper provides a new library for handling datasets, which is focused on easy extension with additional datasets and shows a simple way for transfer-learning new languages using a pretrained model from a language with an almost similar alphabet, which is demonstrated for English to Spanish and Spanish to Italian transfer-learning.</p><p>The training code and models are provided as open source at: https://gitlab.com/Jaco-Assistant/Scribosermo For reasons of readability, the results of the experiments are not presented in full detail, but can instead be found in the project's repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Pre-processing</head><p>The datasets are converted into single channel 16 kHz audio with wav encoding and a tab separated csv file for each partition, with at least the keys duration, filepath and text. Afterwards an additional data cleaning step is executed. All numbers are converted to their textual form, as well as commonly used units like kg or m?. After replacing some special characters (lik? a?ae), all remaining characters, which do not match the used language's alphabet are removed. All of those rules are collected in a simple json file, to ease adding new languages.</p><p>In early training executions the transcriptions of some files did not match the recordings, which resulted in errors if they were much too short or much too long. Therefore, and in order to improve training speed, an automatic cleaning process was implemented, which excludes all files matching one of the following metrics:</p><p>(1) Audio shorter than half a second.</p><p>(2) Audio longer than 30 seconds.</p><p>(3) Transcription has more than 512 characters.</p><p>(4) Recording is spoken 2x faster than the average. The second and third items are used to exclude long files to allow for a greater training batch size. The forth and fifth metrics exclude too quickly or too slowly spoken utterances. The last is intended for slow recordings, too, but with an exception for short clips, because those may have longer pauses at the start or end of the recording.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Language model</head><p>To improve the predicted transcriptions of the trained network, the predictions are rescored with a 5-gram language model. For German a large 8-million sentence collection from <ref type="bibr" target="#b12">[13]</ref> is used and combined with the transcriptions from the training dataset. The same text normalization steps as described in the last chapter are executed. In Spanish and French the Europarl and News sentence collections from <ref type="bibr" target="#b13">[14]</ref> are used additionally, and the Italian training sentences are extended with the Mitads dataset <ref type="bibr" target="#b14">[15]</ref> The language model is created with Poco-LM <ref type="bibr" target="#b15">[16]</ref> and optimized with tools provided by Mozilla's Deep-Speech project <ref type="bibr" target="#b5">[6]</ref>. For decoding their ds-ctcdecoder is used as well. The language models were filtered to a maximum size of 165M n-grams, which results in a size of about 850MB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments with QuartzNet</head><p>For the experiments the QuartzNet architecture <ref type="bibr" target="#b16">[17]</ref> was implemented, using the open source code from Nvidia's NeMo project <ref type="bibr" target="#b17">[18]</ref> as reference. The QuartzNet architecture ( <ref type="figure" target="#fig_1">Figure 1</ref>) was chosen, because its size is comparatively small, which results in fast inference on standard computers and low power devices. Nvidia provides pretrained weights for English, which reach a greedy WER of 3.8 % on the LibriSpeech devset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Reimplementation in TensorFlow</head><p>Instead of directly using Nvidia's PyTorch implementation, the network was reimplemented for TensorFlow. The main reason was that the trained network can be directly converted into the TensorFlow-Lite format, which greatly improves inference speed on low power devices. Another benefit was that the tools already implemented for Mozilla's DeepSpeech framework and some of their data augmentation features could be integrated more easily into the new project.</p><p>The pretrained weights from Nvidia's NeMo project were transferred layer by layer from the PyTorch format to Tensor-Flow using Open Neural Network Exchange (ONNX) as intermediate format. While this did work well for the network itself, there were problems due to differences in PyTorch's and Tensor-Flow's spectrogram calculation. To reduce the impact of these, the transferred network was trained for four additional epochs on the LibriSpeech dataset. The performance is still slightly worse than Nvidia's reference implementation, but much better than Mozilla's current DeepSpeech release <ref type="table" target="#tab_0">(Table 1)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Training in German</head><p>For the following trainings the CommonVoice (v6) dataset was used. The full training partitions are larger than the amount used in VoxPopuli <ref type="bibr" target="#b2">[3]</ref>, therefore a random subset was selected to match the overall duration. In order to get the same alphabet as in English, the German umlauts (?,?,?) have been replaced with their transliteration (ae, oe, ue). <ref type="table" target="#tab_1">Table 2</ref> shows that the implemented QuartzNet15x5 network and training procedure, named Scribosermo in the table, can outperform other approaches for German speech recognition. The training setup of simply training over a pretrained English network, without any further changes, is straightforward, and does not require a semi-supervised pretraining on multiple languages.</p><p>In <ref type="table" target="#tab_2">Table 3</ref> some different training modalities are investigated. The first section uses the complete German training partition of CommonVoice, which slightly improves the results. This training took 3 days on a PC with two 1080Ti GPUs, which shows that the training process itself is very fast, too, and can be executed on consumer-grade hardware. The second part shows  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Training in other languages</head><p>Scribosermo's approach is competitive in other languages like Spanish and French as well, which is shown in <ref type="table" target="#tab_3">Table 4</ref>. To simplify the transfer-learning process the usual two-step frozen and unfrozen training with a reinitialized last layer was replaced with a simpler approach that does not require freezing of parts of the network. First, the alphabet size of the two languages was reduced, using the rules for cross-word puzzles, which replace letters that contain diacritics and ligatures with their basic form.</p><p>Using the cross-word puzzles rules has the advantage that they are commonly known and therefore should not pose a problem for humans reading the predicted transcriptions. Following this approach, the French alphabet now has the same letters as the English, only the Spanish has an extra letter (?). Thus, the size of the last layer for Spanish still has to be changed, but instead of completely reinitializing the new layer, it is only extended with new weights for the extra letter. Thereby the pretrained English weights for the other letters can be kept, which greatly improves the results, similar to only training over the pretrained weights in German. A future optimization step could include replacing phonetically similar but otherwise different characters in the base alphabet with ones from the target alphabet, which was explored in more depth by <ref type="bibr" target="#b19">[20]</ref> for training-free language adoption.</p><p>To compare the influence of the alphabet extension, a separate experiment was run following the usual training approach of reinitializing the complete last layer for the larger Spanish alphabet. The first part of <ref type="table" target="#tab_4">Table 5</ref> shows that the single-step approach with alphabet extension performs better than a simple single-step training with reinitialization of the last layer, as the deeper layers' weights are not so much influenced by backpropagation of prediction errors coming from the random weights Similar to extending the last layer of the network for new alphabet letters, it is also possible to drop characters to reduce the alphabet size. Following the cross-word puzzle approach, the converted Italian alphabet is the same as the English one. But as Italian sounds more similar to Spanish than to English, it is beneficial to use a Spanish network to train upon, after dropping the extra Spanish letter ( <ref type="table" target="#tab_4">Table 5</ref>, second part). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Inference speed</head><p>The main benefit of a small network is fast inference speed on low powered devices. This usually comes with a trade-off of a loss in recognition accuracy as larger models can store more information in their weights, but a fast model that can run even on devices with low computation capabilities is a key feature of this work. The full model itself has a size of about 75MB, the quantized model about 20MB.</p><p>The transcription speed is evaluated in <ref type="table" target="#tab_5">Table 6</ref>, which shows that the presented models are much faster than the model of IMS-Speech, and that they can run faster than real-time on a RaspberryPi. To reduce the memory requirements for very long inputs, they can also be transcribed chunk by chunk in a streaming manner. Here the full CTC-labels were calculated and afterwards given as input to the decoder, similar as in IMS-Speech. The authors of VoxPopuli did not publish the inference speed of their network. A comparison of the network parameter count between their wav2vec-base net, which has about 95M params, and QuartzNet15x5 which only has 19M, allows an estimation that it might run about 5x slower. DeepSpeech TLO 0.7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Training with all datasets</head><p>After demonstrating the performance of the presented approach with relatively small datasets, an experiment was run to measure the influence of larger datasets on the transcription performance. In total 37 datasets for German <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref>, 8 datasets for Spanish <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b66">55,</ref><ref type="bibr" target="#b67">56]</ref>, 7 datasets for French <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b66">55]</ref> and 5 datasets for Italian <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b66">55]</ref> were collected. The trainings were continued with the models of the trainings with CommonVoice only, and afterwards the models were finetuned on this dataset again. The results can be found in <ref type="table" target="#tab_6">Table 7</ref> and show that the advantage of using more data is relatively small. Possible explanations might be that the quality of the mixed datasets is not very good or differs too much from the test recordings, or that the small network is reaching its maximum information capacity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Corcua</head><p>In this chapter the library which was built to handle the above datasets is presented. Often speech-to-text frameworks like Mozilla's DeepSpeech or Nvidia's NeMo have customized scripts for downloading and converting a range of supported datasets into their custom dataset format. But many datasets are used in multiple frameworks, so large parts of the scripts have overlapping tasks. The audiomate <ref type="bibr" target="#b68">[57]</ref> library was built to ease the use of different audio datasets for machine learning tasks and is able to load 18 different datasets and export them into 4 different speech-to-text frameworks. But extending it with new datasets is quite complicated and requires a deeper understanding of the architecture. The goal in creating corcua was not only to build a library to load different audio datasets and export them to different framework formats, but also to make adding new datasets as easy as possible.</p><p>Corcua's architecture is split into three different parts, downloading, reading and writing. The downloader's task is to download and extract a dataset to a local directory. Helper functions for common formats like zip and tar.gz or downloading from a server directory are already pre-implemented. A reader loads the audio files, transcriptions and optionally other information included in the dataset into an easy to handle dictionary format and returns a list of items like this: item = { "filepath": "path/to/audiofile", "speaker": "Newton", "text": "That damn apple!" } A writer takes a list of dictionaries and saves them into the requested framework's dataset format, like csv or json. It also converts the audio files from different codecs to the commonly used wav encoding.</p><p>Besides mere dataset processing, there are also tools to print some statistics about the dataset, like total duration or the most recorded speakers. Corcua also supports splitting datasets into different partitions, like train and test, either randomly or by key separated classes, for example that all utterances of one speaker are in the same partition.</p><p>Compared to audiomate, conversions of some datasets are much faster. Converting the German CommonVoice-v5 dataset (701 h) with audiomate took about 12 h on a modern CPU, while converting the slightly larger CommonVoice-v6 dataset (777 h) with corcua takes less than 3 h.</p><p>Currently corcua can load 34 different datasets (18 of them are German only, 13 are available in more than three languages), and is able to write them into 3 framework formats. Some of the multilingual datasets have been extracted from computer games like Skyrim or The Witcher, which often provide high quality dialogs. With the included support of extracting labels from manually transcribed YouTube videos, it is possible to create audio datasets for almost any language. Corcua has been released as open source project and can be accessed under: https://gitlab.com/Jaco-Assistant/corcua</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper small Speech-to-Text models for German, as well as for Spanish, French and Italian, were presented. The models combine the advantages of other approaches. They are competitive with the best models to date on the CommonVoice dataset in German, Spanish and French, as well as with the best one on the German Tuda dataset. At the same time they can run in real-time on single-board computers like a RaspberryPi and can be trained on consumer-grade hardware with a comparatively small dataset. These models are especially interesting for embedded or offline speech applications, for example in smart home systems running on edge-devices with low power consumption, or on smartphones in environments where no stable internet connection is available. Running offline on standard hardware also has advantages if users do not want and companies are not allowed to use cloud providers for privacy reasons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">References</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 5 )</head><label>5</label><figDesc>Less than one character per three seconds is spoken.(6) (chars/second &lt; average?3) and (duration &gt; average/5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Network architecture of Nvidia's QuartzNet<ref type="bibr" target="#b16">[17]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Performance on English LibriSpeech dataset. Sometimes predictions are rescored with an additional 5-gram language model (LM), else the greedy WER is measured.</figDesc><table><row><cell>Network</cell><cell>Notes</cell><cell>WER</cell></row><row><cell>DeepSpeech</cell><cell>LS-test-clean + LM</cell><cell>7.06 %</cell></row><row><cell cols="2">QuartzNet15x5 Nvidia, LS-dev-clean</cell><cell>3.79 %</cell></row><row><cell cols="2">QuartzNet15x5 Converted, LS-dev-clean</cell><cell>5.15 %</cell></row><row><cell cols="2">QuartzNet15x5 Trained, LS-dev-clean</cell><cell>4.35 %</cell></row><row><cell cols="2">QuartzNet15x5 above, LS-test-clean</cell><cell>4.57 %</cell></row><row><cell cols="3">QuartzNet15x5 above, LS-test-clean + LM 3.71 %</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>German training results. Above networks have been tested on CommonVoice, below on Tuda dataset.</figDesc><table><row><cell></cell><cell>Notes</cell><cell>Duration</cell><cell>WER</cell></row><row><cell>Scribosermo</cell><cell>using CV v6</cell><cell>314h</cell><cell>7.7 %</cell></row><row><cell>VoxPopuli [3]</cell><cell>using CV v5</cell><cell>314h</cell><cell>7.8 %</cell></row><row><cell>Luo et al. [5]</cell><cell>greedy on devset</cell><cell>119h</cell><cell>18.7 %</cell></row><row><cell>Scribosermo</cell><cell>above model</cell><cell>314h</cell><cell>11.7 %</cell></row><row><cell cols="2">IMS-Speech [1] mixed dataset</cell><cell>806h</cell><cell>12.0 %</cell></row><row><cell cols="4">that training results can be improved by a larger margin if the</cell></row><row><cell cols="4">training is run again with the same parameters, but using the</cell></row><row><cell cols="4">current model checkpoint as initialization model. This follows</cell></row><row><cell cols="4">the ideas of Stochastic Gradient Descend with Restart [19], but</cell></row><row><cell cols="4">uses the already implemented early-stopping with learning rate</cell></row><row><cell cols="4">reductions on plateaus approach instead of a cosine annealing</cell></row><row><cell>learning rate.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Testing different training setups.</figDesc><table><row><cell>Notes</cell><cell cols="2">Duration WER</cell></row><row><cell>full CV trainset</cell><cell>720h</cell><cell>7.5 %</cell></row><row><cell>Iteration 1</cell><cell>314h</cell><cell>8.3 %</cell></row><row><cell>Iteration 2</cell><cell>314h</cell><cell>7.8 %</cell></row><row><cell>Iteration 3</cell><cell>314h</cell><cell>7.7 %</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Spanish and French training results on CommonVoice testset. Above is Spanish, below is French.</figDesc><table><row><cell></cell><cell>Notes</cell><cell>Duration</cell><cell>WER</cell></row><row><cell>Scribosermo</cell><cell>using CV v6</cell><cell>203h</cell><cell>10.9 %</cell></row><row><cell cols="2">VoxPopuli [3] using CV v5</cell><cell>203h</cell><cell>9.6 %</cell></row><row><cell>Luo et al. [5]</cell><cell>greedy on devset</cell><cell>96h</cell><cell>15.0 %</cell></row><row><cell>Scribosermo</cell><cell>using CV v6</cell><cell>364h</cell><cell>12.5 %</cell></row><row><cell cols="2">VoxPopuli [3] using CV v5</cell><cell>364h</cell><cell>10.0 %</cell></row><row><cell cols="4">of the last layer at the beginning of the training. Compared to</cell></row><row><cell cols="4">the more usual two-step training which solves this problem it is</cell></row><row><cell cols="4">much faster (trainings were executed on 2? Nvidia-V100).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Influence of finetuning with alphabet extension on Spanish (above) and alphabet shrinking for Italian (below).</figDesc><table><row><cell>Notes</cell><cell>WER</cell><cell>Traintime</cell></row><row><cell>single-step reinitialization</cell><cell>11.66 %</cell><cell>18h</cell></row><row><cell>two-step training</cell><cell>11.11 %</cell><cell>13+18h</cell></row><row><cell>alphabet extension</cell><cell>11.05 %</cell><cell>19h</cell></row><row><cell>Notes</cell><cell>Duration</cell><cell>WER</cell></row><row><cell>English ? Italian</cell><cell>111h</cell><cell>13.8 %</cell></row><row><cell>Spanish ? Italian</cell><cell>111h</cell><cell>12.2 %</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Inference Speed, measured as Real Time Factor</figDesc><table><row><cell>Device</cell><cell>Model</cell><cell>RTF</cell></row><row><cell>PC -1 core AMD3700X</cell><cell></cell><cell>0.24</cell></row><row><cell>PC -1 core (unknown)</cell><cell>net of IMS-Speech [1]</cell><cell>14.2</cell></row><row><cell>RaspberryPi-4 -4gb</cell><cell>tflite full</cell><cell>1.3</cell></row><row><cell>RaspberryPi-4 -4gb</cell><cell>tflite optimized (TLO)</cell><cell>0.7</cell></row><row><cell>RaspberryPi-4 -4gb</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Training with all accessible datasets in German (DE), Spanish (ES), French (FR) and Italian (IT). Datasets for testing are either CommonVoice (CV) or Tuda (TD).</figDesc><table><row><cell cols="3">Language #Datasets Duration</cell><cell>WER</cell></row><row><cell>DE-CV</cell><cell>37</cell><cell>2370 h</cell><cell>6.6 %</cell></row><row><cell>DE-TD</cell><cell></cell><cell></cell><cell>10.2 %</cell></row><row><cell>ES-CV</cell><cell>8</cell><cell>817 h</cell><cell>10.0 %</cell></row><row><cell>FR-CV</cell><cell>7</cell><cell>1028 h</cell><cell>11.0 %</cell></row><row><cell>IT-CV</cell><cell>5</cell><cell>360 h</cell><cell>11.5 %</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Ims-speech: A speech to text tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Denisov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">T</forename><surname>Vu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.04743</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Open source german distant speech recognition: Corpus and acoustic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Radeck-Arneth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Milde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gouv?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Radomski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>M?hlh?user</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Text, Speech, and Dialogue</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="480" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rivi?re</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Talnikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Haziza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dupoux</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00390</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Common voice: A massively-multilingual speech corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ardila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henretty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.06670</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cross-Language Transfer Learning and Domain Adaptation for End-to-End Automatic Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kucsko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>O&amp;apos;neill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Balam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Flores</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Project DeepSpeech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mozilla</surname></persName>
		</author>
		<ptr target="https://github.com/mozilla/DeepSpeech" />
		<imprint>
			<date type="published" when="2021-02" />
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Librispeech: an asr corpus based on public domain audio books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Panayotov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5206" to="5210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fully neural network based speech recognition on mobile and embedded devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">630</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tiny transducer: A highly-efficient speech recognition model on edge devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6024" to="6028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Streaming end-to-end speech recognition for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Prabhavalkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mcgraw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rybach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6381" to="6385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multilingual training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghoshal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Swietojanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Renals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="7319" to="7323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multilingual MLP features for low-resource LVCSR systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganapathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hermansky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="4269" to="4272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Open source german distant speech recognition: Corpus and acoustic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Radeck-Arneth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Milde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gouv?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Radomski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>M?hlh?user</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Text, Speech, and Dialogue</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="480" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
				<ptr target="https://www.statmt.org/wmt13/translation-task.html" />
	</analytic>
	<monogr>
		<title level="m">ACL 2013 EIGHTH WORKSHOP ON STATISTICAL MACHINE TRANSLATION</title>
		<imprint>
			<date type="published" when="2013-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">DeepSpeech-Italian-Model: Mitads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mozillaitalia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Poco LM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Povey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Quartznet: Deep automatic speech recognition with 1d time-channel separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kriman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Beliaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lavrukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6124" to="6128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Nvidia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nemo</surname></persName>
		</author>
		<ptr target="https://github.com/NVIDIA/NeMo" />
		<imprint>
			<date type="published" when="2021-02" />
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Building Large-Vocabulary ASR Systems for Languages Without Any Audio Training Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Van Esch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Mortensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="271" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Voxforge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Voxforge</surname></persName>
		</author>
		<ptr target="http://www.voxforge.org/" />
		<imprint>
			<date type="published" when="2021-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">FORMTASK</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>For Speech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Signals</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11022/1009-0000-0005-8535-9" />
		<imprint>
			<date type="published" when="2017-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<title level="m">SprecherInnen</title>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mulc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Gothic 1-3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>S. Piranha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bytes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thq Nordic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gmbh</surname></persName>
		</author>
		<ptr target="https://www.gog.com/game/gothic" />
		<imprint>
			<date type="published" when="2001-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Kurzgesagt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kurzgesagt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">LinguaLibre</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lingualibre</surname></persName>
		</author>
		<ptr target="https://lingualibre.org/wiki/LinguaLibre:MainPage" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Musstewissen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Musstewissen Deutsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mathe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chemie</forename><surname>Physik</surname></persName>
		</author>
		<ptr target="https://www.youtube.com/c/musstewissenChemie/videos" />
		<imprint>
			<date type="published" when="2021-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M-Ailabs</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>The</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M-Ailabs Speech</forename><surname>Dataset</surname></persName>
		</author>
		<ptr target="https://www.caito.de/2019/01/the-m-ailabs-speech-dataset/" />
		<imprint>
			<date type="published" when="2019-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Puls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Puls Reportage</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Mining the Spoken Wikipedia for Speech Data and Beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>K?hn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Stegen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016</title>
		<editor>N. C. C. Chair), K. Choukri, T. Declerck, M. Grobelnik, B. Maegaard, J. Mariani, A. Moreno, J. Odijk, and S. Piperidis</editor>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA)</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Tatoeba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tatoeba</surname></persName>
		</author>
		<ptr target="https://tatoeba.org/eng/" />
		<imprint>
			<date type="published" when="2021-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Zdf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Terrax</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-Kollektiv ; Y-Kollektiv</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2021-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Zamia-Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goofy</surname></persName>
		</author>
		<ptr target="https://goofy.zamia.org/zamia-speech/corpora/zamiade/" />
		<imprint>
			<date type="published" when="2021-03" />
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Alcohol Language Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>For Speech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Signals</surname></persName>
		</author>
		<idno>1009-0000-0001-88E5-3</idno>
		<ptr target="http://hdl.handle.net/11022/" />
		<imprint>
			<date type="published" when="2016-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Brothers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0001-55C3-3" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Hempel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0002-F80E-8" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Phattsessionz</surname></persName>
		</author>
		<idno>1009-0000-0000-CC6A-4</idno>
		<ptr target="http://hdl.handle.net/11022/" />
		<imprint>
			<date type="published" when="2016-03" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename><surname>Phonedat1</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0001-D20B-6" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Rvg1</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0004-3FF4-3" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Rvg-J</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0004-AE1D-9" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Sc10</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0002-1129-D" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Shc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<ptr target="http://hdl.handle.net/" />
		<title level="m">Available</title>
		<imprint>
			<date type="published" when="1009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Si100</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0007-E9CF-A" />
		<title level="m">Available</title>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="volume">46</biblScope>
		</imprint>
		<respStmt>
			<orgName>SMC</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0005-C50F-D" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Vm1</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0000-EB31-0" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Vm2</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0000-FC55-5" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename><surname>Wasep</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0007-3D30-F" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Ziptel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
				<ptr target="http://hdl.handle.net/11022/1009-0000-0003-1E02-A" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Thorsten M?ller (TTS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>M?ller</surname></persName>
		</author>
		<ptr target="http://www.openslr.org/95/" />
		<imprint>
			<date type="published" when="2021-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Guild2-Renaissance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T N</forename><surname>Gmbh</surname></persName>
		</author>
		<ptr target="https://www.gog.com/game/theguild2renaissance" />
		<imprint>
			<date type="published" when="2010-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Skyrim-Legacy+DLCs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bethesda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Witcher3-GOTY</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Red</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Multilingual TEDx Corpus for Speech Recognition and Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Salesky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wiesner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bremerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cattoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Post</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Librivox-Spanish</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">audiomate: A Python package for working with audio datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>B?chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ahlenstorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">52</biblScope>
			<biblScope unit="page">2135</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
