<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A More Fine-Grained Aspect-Sentiment-Opinion Triplet Extraction Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuncong</forename><surname>Li</surname></persName>
							<email>yuncongli@tencent.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Tencent Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Software Engineering</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Hua</forename><surname>Zhong</surname></persName>
							<email>csshzhong@szu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Software Engineering</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunxiang</forename><surname>Yin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tencent Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yancheng</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tencent Inc</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A More Fine-Grained Aspect-Sentiment-Opinion Triplet Extraction Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Aspect Sentiment Triplet Extraction (ASTE) aims to extract aspect term, sentiment and opinion term triplets from sentences and tries to provide a complete solution for aspectbased sentiment analysis (ABSA). However, some triplets extracted by ASTE are confusing, since the sentiment in a triplet extracted by ASTE is the sentiment that the sentence expresses toward the aspect term rather than the sentiment of the aspect term and opinion term pair. In this paper, we introduce a more finegrained Aspect-Sentiment-Opinion Triplet Extraction (ASOTE) Task. ASOTE also extracts aspect term, sentiment and opinion term triplets. However, the sentiment in a triplet extracted by ASOTE is the sentiment of the aspect term and opinion term pair. We build four datasets for ASOTE based on several popular ABSA benchmarks. We propose a Positionaware BERT-based Framework (PBF) to address this task. PBF first extracts aspect terms from sentences. For each extracted aspect term, PBF first generates aspect term-specific sentence representations considering both the meaning and the position of the aspect term, then extracts associated opinion terms and predicts the sentiments of the aspect term and opinion term pairs based on the sentence representations. Experimental results on the four datasets show the effectiveness of PBF.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Aspect-based sentiment analysis (ABSA) <ref type="bibr">(Hu and Liu, 2004;</ref><ref type="bibr" target="#b6">Pontiki et al., 2014</ref><ref type="bibr" target="#b5">Pontiki et al., , 2015</ref><ref type="bibr" target="#b4">Pontiki et al., , 2016</ref>) is a fine-grained sentiment analysis <ref type="bibr">(Nasukawa and Yi, 2003;</ref><ref type="bibr">Liu, 2012)</ref> task and can provide more detailed information than general sentiment analysis. To solve the ABSA task, many subtasks have been proposed, such as, Aspect Term Extraction (ATE), Aspect Term Sentiment Analysis TOWE ATSA "attractive" conflict positive TOWE ATSA ASTE ("atmosphere" , conflict, "uncomfortable") ("atmosphere" , conflict, "attractive") ("servers", positive, "friendly") ASOTE ("atmosphere", negative, "uncomfortable") ("atmosphere", positive, "attractive") ("servers", positive, "friendly") <ref type="figure">Figure 1</ref>: An example showing the inputs and outputs of the tasks. For each arrow, when the head is a task name, the tail is an input of the task; when the tail is a task name, the head is an output of the task. The bold words are aspects. The underlined words are opinions.</p><p>(ATSA) and Target-oriented Opinion Words Extraction (TOWE) <ref type="bibr">(Fan et al., 2019</ref>). An aspect term (aspect for short) is a word or phrase that refers to a discussed entity in a sentence. An opinion term (opinion for short) is a word or phrase that expresses a subjective attitude. ATE extracts aspects from sentences. Given a sentence and an aspect in the sentence, ATSA and TOWE predict the sentiment and opinions associated with the aspect. These subtasks can work together to tell a complete story, i.e. the discussed aspect, the sentiment of the aspect, and the cause of the sentiment. However, no previous ABSA study tried to provide a complete solution in one shot. <ref type="bibr" target="#b2">Peng et al. (2020)</ref> proposed the Aspect Sentiment Triplet Extraction (ASTE) task, which attempted to provide a complete solution for ABSA. A triplet extracted from a sentence by ASTE contains an aspect, the sentiment that the sentence expresses toward the aspect, and one opinion associated with the aspect. The example in <ref type="figure">Figure 1</ref> shows the inputs and outputs of the tasks mentioned above. However, the triplet extracted from a sentence by ASTE becomes confusing when the sentence has multiple opinions about the aspect and these opinions express different sentiments toward the aspect, since the sentiment in a triplet extracted by ASTE is the sentiment that the sentence expresses ID Sentences</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ASTE Result ASOTE Result (ours)</head><p>1 The atmosphere is attractive , but a little uncomfortable.</p><p>("atmosphere", conflict, "attractive") ("atmosphere", conflict, "uncomfortable") ("atmosphere", positive, "attractive") ("atmosphere", negative, "uncomfortable") 2 Very "normal Indian food", but done really well.</p><p>("Indian food", positive, "normal") ("Indian food", positive, "well") ("Indian food", neutral, "normal") ("Indian food", positive, "well")</p><p>3 Food was just average...if they lowered the prices just a bit, it would be a bigger draw.</p><p>("Food", negative, "average") ("Food", neutral, "average")</p><p>The sentiment toward the aspect "Food" The sentiment of the aspect-opinion pair ("Food", "average") Figure 2: Differences between ASOTE and ASTE. In the third sentence, the negative sentiment toward the aspect "Food" is expressed without an annotatable opinion.</p><p>toward the aspect rather than the sentiment of the aspect and opinion pair. The third column in <ref type="figure">Figure 2</ref> shows the extraction results of ASTE from the corresponding sentences. When seeing the triplets where the words indicating sentiments are red, people will be confused. Moreover, downstream tasks can not benefit from these triplets.</p><p>In this paper, we introduce a more finegrained Aspect-Sentiment-Opinion Triplet Extraction (ASOTE) task. ASOTE also extracts aspect, sentiment and opinion triplets. In the triplet extracted by ASOTE the sentiment is the sentiment of the aspect and opinion pair. The fourth column in <ref type="figure">Figure 2</ref> shows the extraction results of the ASOTE task from the corresponding sentences. In addition, we build four datasets for ASOTE based on several popular ABSA benchmarks.</p><p>We propose a Position-aware BERT-based Framework (PBF) to address ASOTE. PBF first extracts aspects from sentences. For each extracted aspect, PBF then extracts associated opinions and predicts the sentiments of the aspect and opinion pairs. PBF obtains triplets by merging the results. Since a sentence may contain multiple aspects associated with different opinions, to extract the corresponding opinions of a given aspect, similar to previous models proposed for the TOWE task <ref type="bibr">(Fan et al., 2019;</ref><ref type="bibr" target="#b19">Wu et al., 2020b;</ref><ref type="bibr" target="#b7">Pouran Ben Veyseh et al., 2020;</ref><ref type="bibr">Jiang et al., 2021)</ref>, PBF generates aspect-specific sentence representations. To accurately generate aspect-specific sentence representations, both the meaning and the position of the aspect are important. Some methods has been proposed to integrate the position information of aspects into non-BERT based models for some ABSA subtasks, such as, <ref type="bibr">Gu et al. (2018);</ref><ref type="bibr">Li et al. (2018a)</ref> for ATSA, however, how to integrate the position information of aspects into BERT (Devlin et al., 2019) based modes has not been studied well. PBF generates aspect-specific sentence representations considering both the meaning and the position of the aspect. We explore several methods integrating the position information of aspects into PBF.</p><p>Our contributions are summarized as follows:</p><p>? We introduce a new aspect based sentiment analysis subtask: Aspect-Sentiment-Opinion Triplet Extraction (ASOTE).</p><p>? We build four datasets for ASOTE and release the datasets for public use as a benchmark.</p><p>? We propose a Position-aware BERT-based Framework (PBF) to address ASOTE.</p><p>? Experimental results on the four datasets demonstrate the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Aspect-based sentiment analysis (ABSA) <ref type="bibr">(Hu and Liu, 2004;</ref><ref type="bibr" target="#b6">Pontiki et al., 2014</ref><ref type="bibr" target="#b5">Pontiki et al., , 2015</ref><ref type="bibr" target="#b4">Pontiki et al., , 2016</ref>) is a finegrained sentiment analysis task. ABSA has many subtasks, such as, Aspect Term Extraction (ATE), Opinion Term Exaction (OTE) 2 , Aspect Term Sentiment Analysis (ATSA) and  <ref type="formula">(2020)</ref> jointly modeled ATE and ATSA, then generated aspect-sentiment pairs. <ref type="bibr" target="#b14">Wang et al. (2016</ref><ref type="bibr" target="#b15">Wang et al. ( , 2017</ref>; Dai and Song (2019) 3 jointly modeled ATE and OTE, then output aspect set and opinion set. The extracted aspects and opinions are not in pairs. ; Chen et al.</p><p>(2020b) jointly modeled ATE and TOWE, then generated aspect-opinion pairs. He et al. <ref type="formula" target="#formula_7">(2019)</ref>; Chen and Qian (2020) jointly modeled ATE, OTE and ATSA, then output aspect-sentiment pairs and opinion set. However, the extracted aspects and opinions are also not in pairs, that is, the aspects, sentiments and opinions do not form triplets. The Aspect Sentiment Triplet Extraction (ASTE) task proposed by <ref type="bibr" target="#b2">Peng et al. (2020)</ref> extracted aspects, the sentiments of the aspects, and opinions which could form triplets. Some methods have been proposed for ASTE <ref type="bibr" target="#b10">Sutherland et al., 2020;</ref><ref type="bibr">Chen et al., 2020a;</ref><ref type="bibr" target="#b18">Wu et al., 2020a;</ref><ref type="bibr" target="#b24">Zhang et al., 2020;</ref><ref type="bibr">Mao et al., 2021;</ref><ref type="bibr">Chen et al., 2021)</ref> 4 . However, ASTE has the problem mentioned in Section 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset Construction</head><p>Data Collection We annotate four datasets (i.e., 14res, 14lap, 15res, 16res) for our propsoed Aspect-Sentiment-Opinion Triplet Extraction (ASOTE) task. First, we construct four Aspect Sentiment Triplet Extraction (ASTE) datasets. Similar to previous studies <ref type="bibr" target="#b2">(Peng et al., 2020;</ref>, we obtain four ASTE datasets by aligning the four SemEval Challenge datasets <ref type="bibr" target="#b5">(Pontiki et al., 2015</ref><ref type="bibr" target="#b4">(Pontiki et al., , 2016</ref>   <ref type="bibr" target="#b2">(Peng et al., 2020;</ref>, the ASTE datasets we generate, 1) keep the triplets with conflict sentiments, 2) keep all the sentences in the four SemEval Challenge datasets. That is, the sentences, which don't contain triplets and therefore are not included in the ASTE datasets used in The atmosphere is attractive , but a little uncomfortable.</p><formula xml:id="formula_0">----------------------------------------------------------------------------------- aspect term sentiment: conflict aspect_term opinion_term opinion_term unannotated unannotated (a) Before annotation</formula><p>The atmosphere is attractive , but a little uncomfortable.  previous studies <ref type="bibr" target="#b2">(Peng et al., 2020;</ref>, are included in the ASTE datasets we generate. We think datasets including these sentences can better evaluate the performance of ASOTE methods, since ASOTE methods can encounter this kind of sentences in real-world scenarios.</p><formula xml:id="formula_1">----------------------------------------------------------------------------------- aspect</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Annotation</head><p>We invited a researcher who works on natural language processing (NLP) and an undergraduate to annotate the sentiments of the aspect-opinion pairs in the triplets of the four ASTE datasets. The annotation tool we used is brat <ref type="bibr" target="#b9">(Stenetorp et al., 2012)</ref>. Each time, we only provided triplets of one aspect term to the annotators. For each aspect term, not only the aspect term and its corresponding opinion terms but also the sentiment of the aspect term were provided to the annotators. <ref type="figure" target="#fig_1">Figure 3</ref> (a) shows an example of what we provided to the annotators and <ref type="figure" target="#fig_1">Figure 3</ref> (b) shows the results of annotation. When annotating the sentiment of an aspect-opinion pair, the annotators need to consider both the opinion itself and the context of the opinion. For example, given the sentence, "The decor is night tho...but they REALLY need to clean that vent in the ceiling...its quite un-appetizing, and kills your effort to make this place look sleek and modern." 5 and one aspect-opinion pair, ("place", "sleek"), the sentiment should be negative, even though the sentiment of "sleek" is positive. The kappa statistic <ref type="bibr">(Cohen, 1960)</ref>   <ref type="table">Table 1</ref>: Statistics of our ASOTE datasets. #zero_t, #one_t and #m_t represent the number of aspects without triplet, with one triplet and with multiple triplets, respectively. #d_s1 represents the number of aspects that have multiple triplets with different sentiments. #d_s2 represents the number of aspects which only have one triplet and whose sentiments are not conflict and are different from the sentiment of the corresponding triplet. #t_d represents the number of the triplets whose sentiments are different from the sentiments of the aspects in them.</p><p>on NLP.</p><p>Dataset Analysis The statistics of the four ASOTE datasets are summarized in <ref type="table">Table 1</ref>. Since #diff_s2 is always greater than 0, the annotators have to annotate the sentiments of the triplets in which the aspect only have one triplet and the sentiment of the aspect is not conflict. That is, we can not treat the sentiment of the aspect in these triplets as the sentiment of these triplets. For example, for the third sentence in <ref type="figure">Figure 2</ref>, the aspect "Food" has negative sentiment, while the correct sentiment of its only one triplet, ("Food", neutral, "average"), is neutral.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head><p>In this section, we describe our Positionaware BERT-based Framework (PBF) for Aspect-Sentiment-Opinion Triplet Extraction (ASOTE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task Definition</head><p>Given a sentence S = {w 0 , ..., w i , ..., w n?1 } containing n words, ASOTE aims to extract a set of triplets:</p><formula xml:id="formula_2">T = {(a, s, o) t } |T |?1 t=0</formula><p>, where a is an aspect, o is an opinion, s is the sentiment of the aspect-opinion pair (a, o), and |T | is the number of triplets in the sentence. When a sentence does not contain triplets, |T | = 0. <ref type="figure" target="#fig_2">Figure 4</ref> shows the overview of PBF. PBF contains three models. Given a sentence S = {w 0 , ..., w i , ..., w n?1 }, the Aspect Term Extraction (ATE) model first extracts a set of aspects A = {a 0 , ..., a j , ..., a m?1 }. For each extracted aspect, a j , the Target-oriented Opinion Words Extraction (TOWE) model then ex-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">PBF</head><formula xml:id="formula_3">tracts its opinions O = {o 0 j , ..., o k j , ..., o l j ?1 j },</formula><p>where l j is the number of opinions with respect to the j-th aspect and l j ? 0. Finally, for each extracted aspect-opinion pair (a j , o k j ), the Aspect-Opinion Pair Sentiment Classification (AOPSC) model predicts its sentiment s k j ? P = {positive, neutral, negative}. PBF obtains the triplets by merging the results of the three models:</p><formula xml:id="formula_4">T = {(a 0 , s 0 0 , o 0 0 ), ..., (a m?1 , s l m?1 m?1 , o l m?1 m?1 )}.</formula><p>In PBF, all three models use BiLSTM (Graves et al., 2013) with BERT (Devlin et al., 2019) as sentence encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Input</head><p>The input of PBF is a sentence S = {w 0 , ..., w i , ..., w n?1 } consisting of n words.</p><p>Given the sentence, to obtain the inputs of the ATE model <ref type="figure" target="#fig_2">(Figure 4 (a)</ref>), we first convert the sentence S to a new sentence, S B = {w 0 , ..., w i , ..., w q }, where w 0 is "[CLS]" and w q is "[SEP]". We then generate segment indices I seg = {0, ..., 0} and position indices I pos = {0, ..., q} for the new sentence.</p><p>Since a sentence may contain multiple aspects associated with different opinions, to extract the associated opinions of a particular aspect, the TOWE model generates aspect-specific sentence represen- tations for the aspect. It's intuitive that both the meaning and the position of the aspect are important for producing aspect-specific sentence representations. In other words, we need to tell the TOWE model what the aspect is and where the aspect is in the sentence. Given the sentence S and an aspect a j in the sentence, we first replace the words of the aspect with the word "aspect", which tells the TOWE model where the aspect is in the sentence. We then append the words of the aspect to the end of the sentence, which tells the model what the aspect is. Finally, we obtain a new sentence</p><formula xml:id="formula_5">S A B = {w 0 , ..., w i , ..., w q }.</formula><p>We also generate segment indices I A seg = {0, ..., 1} and position indices I A pos = {0, ..., q} for the new sentence. The encoder of the TOWE model <ref type="figure" target="#fig_2">(Figure 4 (b)</ref>) takes S A B , I A seg and I A pos as inputs, and can generate aspectspecific sentence representations.</p><p>To predict the sentiment of an aspect-opinion pair, the AOPSC model <ref type="figure" target="#fig_2">(Figure 4 (c)</ref>) also generate aspect-specific sentence representations for the aspect. The inputs of the AOPSC model are the same as the TOWE model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">ATE</head><p>We formulate ATE as a sequence labeling problem. The encoder takes S B , I seg and I pos as inputs, and outputs the corresponding sentence representation,</p><formula xml:id="formula_6">H A = {h A 0 , ..., h A i , ..., h A q }. ATE model uses h A i</formula><p>to predict the tag y A i ? {B, I, O} (B: Begin, I: Inside, O: Outside) of the word w i . It can be regarded as a three-class classification problem at each position of S B . We use a linear layer and a softmax layer to compute prediction probability? A i :</p><formula xml:id="formula_7">y A i = sof tmax(W A 1 h A i + b A 1 )<label>(1)</label></formula><p>where W A 1 and b A 1 are learnable parameters. The cross-entropy loss of ATE task can be defined as follows:</p><formula xml:id="formula_8">L AT E = ? q i=0 t?{B,I,O} I(y A i = t)log(? A it ) (2)</formula><p>where y A i denotes the ground truth label. I is an indicator function. If y A i == t, I = 1, otherwise I = 0. We minimize L AT E to optimize the ATE model. Finally, ATE model decodes the tag sequence of the sentence and outputs a set of aspects A = {a 0 , ..., a j , ..., a m?1 }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">TOWE</head><p>We aslo formulate TOWE as a sequence labeling problem. The TOWE model has the same architecture as the ATE model, but they do not share the parameters. The TOWE model takes S A B , I A seg and I A pos as inputs and outputs the opinions</p><formula xml:id="formula_9">O = {o 0 j , ..., o k j , ..., o l j ?1 j } of the aspect a j .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">AOPSC</head><p>Given an aspect a j and its opin- </p><formula xml:id="formula_10">ions {o 0 j , ..., o k j , ..., o l j ?1 j }, the AOPSC model predicts the sentiments {s 0 j , ..., s k j , ..., s l j ?1 j } of all aspect-opinion pairs, {(a j , o 0 j ), ..., (a j , o k j ), ..., (a j , o l j ?1 j )},</formula><formula xml:id="formula_11">H S = {h S 0 , ..., h S q }.</formula><p>We then obtain the representation of an opinion by averaging the hidden representations of the words in the opinion. The representation h o j k of opinion o k j is used to make sentiment prediction? o j k of opinion o k j :</p><formula xml:id="formula_12">y o j k = sof tmax(W S 1 h o j k + b S 1 )<label>(3)</label></formula><p>where W S 1 and b S 1 are learnable parameters. The loss of the AOPSC task is the sum of all opinions' cross entropy of the aspect:</p><formula xml:id="formula_13">L AOP SC = ? l j ?1 k=0 t?P I(y o j k = t)log? o j k t (4)</formula><p>where y o j k denotes the ground truth label. We minimize L AOP SC to optimize the AOPSC model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and Metrics</head><p>We evaluate our method on two types of datasets:</p><p>TOWE-data (Fan et al., 2019) is used to compare our method with previous methods proposed for the Target-oriented Opinion Words Extraction (TOWE) task on the TOWE task. TOWE-data only includes the sentences that contain pairs of aspect and opinion and the aspect associated with at least one opinion. Following previous works <ref type="bibr">(Fan et al., 2019;</ref><ref type="bibr" target="#b19">Wu et al., 2020b)</ref>, We randomly select 20% of training set as development set for tuning hyperparameters and early stopping.</p><p>ASOTE-data is the data we build for our Aspect-Sentiment-Opinion Triplet Extraction (ASOTE) task and is used to compare the methods on the ASOTE task. ASOTE-data can also be used to evaluate the TOWE models on the TOWE task. Compared with TOWE-data, ASOTE-data additionally includes the sentences that do not contain aspect-opinion pairs and includes the aspects without opinions. Since methods can encounter these kind of examples in real-world scenarios, ASOTEdata is more appropriate to evaluate methods on the TOWE task.</p><p>We use precision (P), recall (R), and F1-score (F1) as the evaluation metrics. For the ASOTE task, an extracted triplet is regarded as correct only if predicted aspect spans, sentiment, opinion spans and ground truth aspect spans, sentiment, opinion spans are exactly matched.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Our Methods</head><p>We provide the comparisons of several variants of our Position-aware BERT-based Framework (PBF). The difference between these variants is the way they generate the new sentence S A B , the segment indices I A seg and the position indices I A pos . PBF -w/o A doesn't append the words of the aspect to the end of the original sentence. In other words, this variant doesn't know what the aspect is.  <ref type="figure">Figure 5</ref>: The inputs of PBF-M1, PBF-M2 and PBF-M2, given the sentence "Rice is too dry, tuna was n't so fresh" and the aspect "Rice".</p><p>PBF -w/o P does not replace the words of the aspect with the word "aspect", namely that this variant does not know where the aspect is. This model has been used on some aspect-based sentiment analysis subtasks to generate aspect-specific sentence representations <ref type="bibr">(Jiang et al., 2019;</ref><ref type="bibr">Li et al., 2020b)</ref>.</p><p>PBF -w/o AP neither appends the words of the aspect to the end of the original sentence, nor replaces the words of the aspect with the word "aspect".</p><p>PBF-M1 does not replace the words of the aspect with the word "aspect". In order to tell the model the position of the aspect, the words of the aspect in the original sentence and the words of the aspect appended to the original sentence have the same position indices. This method has been used on relation classification (Zhong and Chen, 2020).</p><p>PBF-M2 does not replace the words of the aspect with the word "aspect". In order to tell the model the position of the aspect, the position indices of the words of the aspect in the original sentence are marked as 0, and the position indices of other words are the relative distance to the aspect. This method has been used on the aspect-term sentiment analysis task <ref type="bibr">(Gu et al., 2018)</ref>.</p><p>PBF-M3 modifies the original sentence S by inserting the special token # at the beginning of the aspect and the special token $ at the end of the aspect. Special tokens were first used by <ref type="bibr" target="#b17">Wu and He (2019)</ref> to incorporate target entities information into BERT on the relation classification task. <ref type="figure">Figure 5</ref> shows inputs examples for PBF-M1, PBF-M2 and PBF-M3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Implementation Details</head><p>We implement our models in PyTorch <ref type="bibr" target="#b1">(Paszke et al., 2017)</ref>. We use the uncased basic pre-trained BERT. The BERT is fine-tuned during training. The batch size is set to 32 for all models. All models are optimized by the Adam optimizer <ref type="table" target="#tab_8">(Kingma and Ba,   14res   14lap  15res  16res  Method  P  R  F1  P  R  F1  P  R  F1  P  R  F1  OTE-</ref>   2014). The learning rates is 0.00002. we apply a dropout of p = 0.5 after the BERT and BiLSTM layers. We apply early stopping in training and the patience is 10. We run all models for 5 times and report the average results on the test datasets. For the baseline models of the ASOTE task, we first convert our datasets to the datasets which has the same formats as the inputs of the baseline models, then run the code that the authors released on the converted datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Exp-I: ASOTE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Comparison Methods</head><p>On the ASOTE task,we compare our methods with several methods proposed for the Aspect Sentiment Triplet Extraction (ASTE) task. These methods also extract aspect, sentiment, opinion triplets from sentences. These methods include MTL from </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Results</head><p>The results of the ASOTE task are shown in Table 2. We have several observations from <ref type="table" target="#tab_5">Table 2</ref>. First, MTL outperforms JET t on all datasets, because JET t can extract at most one triplet for an aspect. Although JET o can extract at most one triplet for an opinion, JET o outperforms JET t on all datasets and surpasses MTL on 3 of 4 datasets, because the opinions belonging to multiple triplets are less than the aspects belonging to multiple triplets 9 . Second, GTS-CNN and GTS-BiLSTM outperform both JET t and JET o on all datasets, and GTS-BERT also achieves better performance than JET t +bert and JET o +bert . GTS-BERT is the best baseline model. Third, our proposed PBF surpasses GTS-BERT on all datasets. Since the Aspect Term Extraction (ATE) model and the Aspect-Opinion Pair Sentiment Classification (AOPSC) model in PBF are vanilla 10 , compared with previous models, the advantages of PBF are from the TOWE model. However, GTS-BERT can not be applied to the TOWE 8 https://github.com/l294265421/GTS-ASOTE 9 More statistics about our ASOTE datasets can be found in the Appendix B. <ref type="bibr">10</ref> The results of PBF and its variants on AOPSC can be found in the Appendix C. Compared with PBF -w/o AP, PBF and the other variants can't obtain better performance consistently on all datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ID</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ground truth PBF -w/o A PBF -w/o P PBF</head><p>1 We really enjoy the food, was areally great food.</p><p>("food", positive, "enjoy") ("food", positive, "great") ("food", positive, "enjoy") ("food", positive, "great") ("food", positive, "enjoy") ("food", positive, "great") ("food", positive, "enjoy") ("food", positive, "great") ("food", positive, "enjoy") ("food", positive, "great") 2 Then they somehow made a dry and burnt crust, around a raw and cold inside.</p><p>("crust", negative, "dry") ("crust", negative, "burnt") ("crust", negative, "dry") ("crust", negative, "raw") ("crust", negative, "burnt") ("crust", negative, "cold") ("crust", negative, "dry") ("crust", negative, "burnt") ("crust", negative, "dry") ("crust", negative, "burnt") <ref type="figure">Figure 6</ref>: Case study. Red triplets are incorrect predictions.</p><p>task directly, so we compare PBF with GTS-BERT on the aspect-Opinion Pair Extraction (OPE) <ref type="bibr" target="#b18">(Wu et al., 2020a)</ref> task. The results of OPE are shown in <ref type="table" target="#tab_6">Table 3</ref>, which shows that PBF also outperforms GTS-BERT on all datasets. Fourth, PBF outperforms PBF -w/o P on all datasets, indicating that integrating position information of aspects can boost the model performance. Fifth, PBF -w/o A surpasses PBF -w/o P on the 14lap, 15res and 16res datasets, which indicates that the position information of aspects is more effective than the meanings of aspects on these datasets. Sixth, PBF outperforms PBF-M1 and PBF-M2, which shows that our method that tells the model where the aspect is is more effective. Although the mehtod used by PBF-M2 to integrate the position information of aspects into it has been successfully applied to non-BERT based models, it is not effective enough for BERT-based models. Seventh, PBF outperforms PBF-M3, indicting our method is more effective than the method that integrating the position information and meaning of an aspect into a model by inserting special aspect markers for the aspect. The possible reason is that the additional special tokens may destroy the syntax knowledge learned by BERT. Last but not least, PBF -w/o AP obtains the worst performance among all variants, which further demonstrates that both the position and the meaning of an aspect are important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.3">Case Study</head><p>To further understand the effect of the position and the meaning of an aspect, we perform a case study on two sentences, as displayed in <ref type="figure">Figure 6</ref>. In the first sentence, the bold "food" and underlined "food" are different aspects. The positions of the aspects help PBF and PBF -w/o A to extract different opinions for aspects with the same meaning. In the second sentence, with the help of the meaning of the aspect "crust", PBF and PBF -w/o P do not extract "raw" and "cold" as the opinions of "crust".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Exp-II: TOWE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Comparison Methods</head><p>On the TOWE task, we compare our methods with <ref type="formula" target="#formula_7">(1)</ref>     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">Results</head><p>The results on ASOTE-data are shown in <ref type="table" target="#tab_8">Table 4</ref> and the results on TOWE-data are shown in <ref type="table" target="#tab_9">Table 5</ref>. We draw the following conclusions from the results. First, PBF outperforms all baselines proposed for TOWE on the TOWE-data, indicating the effectiveness of our method. Second, PBF -w/o P also surpasses all baselines on the TOWE-data. To the best of our knowledge, no previous study evaluates the performance of this method on TOWE. Third, regarding PBF and its variants, we can obtain conclusions from <ref type="table" target="#tab_5">Table 4 similar to the conclusions  obtained from Table 2</ref>, because the differences of these models' performance on ASOTE are mainly brought by the differences of their performacnes on TOWE. Fourth, since the methods (i.e., PBF, PBF -w/o A, PBF -w/o P and PBF -w/o AP) obtain better performance on TOWE-data than on ASOTE-data, ASOTE-data is a more challenging dataset for TOWE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we introduce the Aspect-Sentiment-Opinion Triplet Extraction (ASOTE) task. ASOTE is more fine-grained than Aspect Sentiment Triplet Extraction (ASTE). The sentiment of an triplet extracted by ASOTE is the sentiment of the aspectopinion pair in the triplet. We manually annotate four datasets for ASOTE. Moreover, We propose a Position-aware BERT-based Framework (PBF) to address ASOTE. Although PBF is a pipeline method, it obtains better performance than several joint models, which demonstrates the effectiveness of our method.</p><p>Since Aspect Term Extraction (ATE) and Targetoriented Opinion Words Extraction (TOWE) are highly correlated with each other, and TOWE and Aspect-Opinion Pair Sentiment Classification (AOPSC) are also highly correlated with each other, we can improve PBF by turning it into a joint model which jointly trains the ATE model, the TOWE model and the AOPSC model. However, it is not easy to jointly train the ATE model and the TOWE model, since we need to use the aspects that the ATE model extracts to modify the sentences that the TOWE model takes as input. In the future, we will explore how to jointly train the ATE model and the TOWE model. A More Related Work <ref type="bibr" target="#b14">Wang et al. (2016</ref><ref type="bibr" target="#b15">Wang et al. ( , 2017</ref> have annotated the opinions and thier sentiments of the sentences in the restaurant and laptop datasets from <ref type="bibr">SemEval-2014</ref><ref type="bibr">Task 4(Pontiki et al., 2014</ref> and the restaurant dataset from SemEval-2015 Task 12 <ref type="bibr" target="#b5">(Pontiki et al., 2015)</ref>. Is it necessary to annotate the sentiments of the aspect and opinion pairs in the Aspect Sentiment Triplet Extraction (ASTE) datasets for obtaining our Aspect-Sentiment-Opinion Triplet Extraction (ASOTE) datasets? The answer is yes. The reasons are as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>? The sentiments of aspect and opinion pairs are different from the sentiments of opinions.</p><p>? The opinions annotated by <ref type="bibr" target="#b14">Wang et al. (2016</ref><ref type="bibr" target="#b15">Wang et al. ( , 2017</ref> are different from the opinions annotated in the Target-oriented Opinion Words Extraction (TOWE) datasets <ref type="bibr">(Fan et al., 2019)</ref> which are used to construct our ASOTE datasets. For example, given this sentence, "those rolls were big , but not good and sashimi wasn't fresh.", the opinions and their sentiments annotated by <ref type="bibr" target="#b14">Wang et al. (2016</ref><ref type="bibr" target="#b15">Wang et al. ( , 2017</ref> are ("big", positive), ("good", positive), and ("fresh", positive), while the opinions annotated in the TOWE datasets are "big", "not good" and "wasn't fresh" and the triplets containing "not good" and "wasn't fresh" are negative. We think the opinions annotated in the TOWE datasets are more appropriate for the ASOTE task. <ref type="bibr" target="#b24">Zhang et al. (2020)</ref> defined their Opinion Triplet Extraction task as an integration of aspectsentiment pair extraction <ref type="bibr">(Zhou et al., 2019;</ref><ref type="bibr">Li et al., 2019;</ref><ref type="bibr" target="#b3">Phan and Ogunbona, 2020)</ref> and aspectopinion co-extraction <ref type="bibr" target="#b14">(Wang et al., 2016</ref><ref type="bibr" target="#b15">(Wang et al., , 2017</ref><ref type="bibr">Dai and Song, 2019)</ref>. The obtained Opinion Triplet Extraction task has the same goal as our ASOTE task. However, the authors used the ASTE datasets to evaluate the perfromances of their models on the Opinion Triplet Extraction task and said that the Opinion Triplet Extraction task is the same as the ASTE task in the corresponding github repository of their paper. In fact, combining aspect-sentiment pair extraction with aspect-opinion co-extraction can obtain neither the ASTE task nor our ASOTE task. Therefore, we don't think they introduce the ASOTE task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B More Data Statistics</head><p>More statistics about our ASOTE-data are shown in <ref type="table" target="#tab_12">Table 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C More Experimental Results</head><p>The results including precision (P), recall (R) and F1 (F) score of the aspect-opinion pair extraction task on the ASOTE-data are shown in <ref type="table" target="#tab_13">Table 7</ref>.</p><p>The results including precision (P), recall (R) and F1 (F) score of the TOWE task on the ASOTEdata are shown in <ref type="table" target="#tab_14">Table 8</ref>.</p><p>The results including precision (P), recall (R) and F1 (F) score of the TOWE task on the TOWEdata are shown in <ref type="table">Table 9</ref>.</p><p>The results of the Aspect-Opinion Pair Sentiment Classification (AOPSC) task are shown in <ref type="table" target="#tab_16">Table 10</ref>. Position-aware BERT-based Framework (PBF) and its variants including PBF -w/o AP obtain similar performance.</p><p>The results of the Aspect Term Extraction (ATE) task are shown in <ref type="table" target="#tab_17">Table 11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Case Study</head><p>The extraction results of our Position-aware BERTbased Framework (PBF) on the sentence "We been there and we really enjoy the food, was areally great food, and the service was really good. " are shown in <ref type="figure">Figure 7</ref>. From the results, we can see that all variants except for PBF -w/o P include the position information of aspects. <ref type="figure">Figure 8</ref> shows three sentences. While PBF correctly extracts all triplets from these sentences, GTS-BERT can't correctly extract all triplets from these sentences.     <ref type="table">Table 9</ref>: Results of the TOWE task on the TOWE-data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence</head><p>We been there and we really enjoy the food, was areally great food, and the service was really good. Ground truth ("food", positive, "enjoy") ("food", positive, "great") ("service", positive, "good") PBF ("food", positive, "enjoy") ("food", positive, "great") ("service", positive, "good") PBF -w/o A ("food", positive, "enjoy") ("food", positive, "great") ("service", positive, "good") PBF -w/o P ("food", positive, "enjoy") ("food", positive, "great") ("food", positive, "great") ("food", positive, "enjoy") ("service", positive, "good") PBF-M1 ("food", positive, "enjoy") ("food", positive, "great") ("food", positive, "great") ("service", positive, "good") PBF-M2 ("food", positive, "enjoy") ("food", positive, "great") ("service", positive, "enjoy") PBF-M3 ("food", positive, "enjoy") ("food", positive, "great") ("service", positive, "good") Figure 7: Case study. Red triplets are incorrect predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ID Sentence Ground truth GTS-BERT PBF</head><p>1 A nice space , as long as it does n't get too crowded and a singleminded devotion to its chosen cuisine make Mare a great choice for seafood lovers.</p><p>("space", positive, "nice") ("seafood", positive, "great") ("space", positive, "nice") ("cuisine", positive, "chosen") ("seafood", positive, "great") ("space", positive, "nice") ("seafood", positive, "great") 2 The service is excellent and always informative without an air.</p><p>("service", positive, "excellent") ("service", positive, "informative") ("service", positive, "excellent") ("service", positive, "informative without") ("service", positive, "excellent") ("service", positive, "informative") 3 It 's traditional, simple italian food.</p><p>("italian food", positive, "traditional") ("italian food", positive, "simple") ("italian food", positive, "simple") () ("italian food", positive, "traditional") ("italian food", positive, "simple")   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>An example of annotating the sentiments of the aspect and opinion pairs on the ASTE triplets for the ASOTE task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Our proposed Position-aware BERT-based Framework (PBF).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc><ref type="bibr" target="#b24">Zhang et al. (2020)</ref> 6 , JET t , JET o , JET t +bert and JET o +bert where M = 6 from Xu et al. (2020) 7 , GTS-CNN, GTS-BiLSTM and GTS-BERT from Wu et al. (2020a) 8 . All these baselines are joint models, which are jointly trained to extract the three elements of ASOTE triplets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>et al., 2019), LOTN (Wu et al., 2020b), ARGCN (Jiang et al., 2021) (2) two BERT-based models: ARGCN +bert (Jiang et al., 2021) and ONG (Pouran Ben Veyseh et al., 2020).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>at once. The encoder of the AOPSC model takes the new sentence S A B , the segment indices I A seg and the position indices I A pos as inputs and outputs the aspect-specific sentence representation,</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>MTL 63.8 52.1 57.3 51.3 36.8 42.7 56.3 44.0 49.3 58.3 52.4 55.0 JET t 66.0 48.4 55.8 41.0 36.5 38.6 45.3 47.8 46.5 58.1 46.9 51.9 JET o 61.5 53.9 57.5 48.8 36.7 41.9 57.5 47.2 51.8 61.0 56.8 58.8</figDesc><table><row><cell>GTS-CNN</cell><cell>66.4 58.5 62.2 55.3 37.4 44.6 56.3 48.1 51.8 61.4 60.0 60.5</cell></row><row><cell cols="2">GTS-BiLSTM 71.1 54.5 61.5 58.0 33.9 42.8 67.3 42.9 52.4 64.6 55.8 59.8</cell></row><row><cell>JET t +bert JET o +bert</cell><cell>65.1 51.7 57.6 50.2 41.7 45.5 50.7 48.2 49.4 55.0 52.1 53.5 66.0 54.5 59.7 49.7 42.8 46.0 53.8 52.9 53.3 58.3 60.3 59.2</cell></row><row><cell>GTS-BERT</cell><cell>67.5 67.2 67.3 59.4 48.6 53.5 61.8 52.0 56.4 62.0 67.1 64.4</cell></row><row><cell>PBF</cell><cell>69.3 69.0 69.2 56.6 55.1 55.8 55.8 61.5 58.5 61.2 72.7 66.5</cell></row><row><cell>PBF -w/o A</cell><cell>67.3 69.3 68.3 55.9 55.7 55.8 56.4 61.6 58.8 60.7 71.3 65.5</cell></row><row><cell>PBF -w/o P</cell><cell>68.6 69.7 69.1 56.6 54.8 55.7 56.2 60.4 58.2 59.6 71.8 65.1</cell></row><row><cell>PBF -w/o AP</cell><cell>44.4 51.9 47.4 45.1 48.8 46.7 41.7 50.9 45.7 46.1 59.8 52.0</cell></row><row><cell>PBF-M1</cell><cell>66.6 69.7 68.1 58.8 54.1 56.3 57.8 59.4 58.4 59.3 72.1 65.0</cell></row><row><cell>PBF-M2</cell><cell>63.0 63.6 63.3 51.8 47.3 49.4 50.2 56.2 53.0 56.6 65.8 60.8</cell></row><row><cell>PBF-M3</cell><cell>66.8 69.2 68.0 56.8 53.3 54.9 54.2 61.7 57.7 60.4 71.1 65.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Results of ASOTE task. The bold F1 scores are the best scores among PBF and the baselines. The underlined F1 scores are the best scores among PBF and its variants.</figDesc><table><row><cell>Method</cell><cell cols="4">14res 14lap 15res 16res</cell></row><row><cell cols="2">GTS-BERT 71.7</cell><cell>60.2</cell><cell>61.5</cell><cell>68.1</cell></row><row><cell>PBF</cell><cell>74.0</cell><cell>63.8</cell><cell>63.9</cell><cell>70.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Results of the OPE task in terms of F1.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Results of the TOWE task in terms of F1 on the ASOTE-data.</figDesc><table><row><cell>Method</cell><cell cols="4">14res 14lap 15res 16res</cell></row><row><cell>IOG</cell><cell>80.0</cell><cell>71.3</cell><cell>73.2</cell><cell>81.6</cell></row><row><cell>LOTN</cell><cell>82.2</cell><cell>72.0</cell><cell>73.2</cell><cell>83.6</cell></row><row><cell>ARGCN</cell><cell>84.6</cell><cell>75.3</cell><cell>76.7</cell><cell>85.1</cell></row><row><cell cols="2">ARGCN +bert 85.4</cell><cell>76.3</cell><cell>78.2</cell><cell>86.6</cell></row><row><cell>ONG</cell><cell>82.3</cell><cell>75.7</cell><cell>78.8</cell><cell>86.0</cell></row><row><cell>PBF</cell><cell>85.9</cell><cell>81.5</cell><cell>80.8</cell><cell>89.2</cell></row><row><cell>PBF -w/o A</cell><cell>86.1</cell><cell>81.2</cell><cell>80.4</cell><cell>87.9</cell></row><row><cell>PBF -w/o P</cell><cell>86.3</cell><cell>80.3</cell><cell>79.8</cell><cell>88.8</cell></row><row><cell cols="2">PBF -w/o AP 61.6</cell><cell>67.9</cell><cell>59.0</cell><cell>69.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Results of the TOWE task in terms of F1 on the TOWE-data. The results of the baselines cite form the original papers.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Zhuang Chen and Tieyun Qian. 2020. Relation-aware collaborative learning for unified aspect-based sentiment analysis. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3685-3694. Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '04, page 168-177, New York, NY, USA. Association for Computing Machinery. Sujian Li, Xiaodong Zhang, and Houfeng Wang. 2017. Interactive attention networks for aspect-level sentiment classification. arXiv preprint arXiv:1709.00893. Linlin Hou, and Ou Wu. 2020b. Modeling sentiment dependencies with graph convolutional networks for aspect-level sentiment classification. Knowledge-Based Systems, 193:105443.Zexuan Zhong and Danqi Chen. 2020. A frustratingly easy approach for joint entity and relation extraction. arXiv preprint arXiv:2010.12812.</figDesc><table><row><cell>Junfeng Jiang, An Wang, and Akiko Aizawa. 2021. Attention-based relational graph convolutional net-Pinlong Zhao, Yan Zhou, Longtao Huang, Tao Guo, Jizhong Han, and work for target-oriented opinion words extraction. Songlin Hu. 2019. A span-based joint model for In Proceedings of the 16th Conference of the Euro-opinion target extraction and target sentiment clas-pean Chapter of the Association for Computational line. Association for Computational Linguistics. Linguistics: Main Volume, pages 1986-1997, On-sification. In IJCAI, pages 5485-5491.</cell><cell>Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20(1):37-46. Hongliang Dai and Yangqiu Song. 2019. Neural as-pect and opinion term extraction with mined rules as weak supervision. In Proceedings of the 57th An-nual Meeting of the Association for Computational Linguistics, pages 5268-5277. Dehong Ma, Yue Mao, Yi Shen, Chao Yu, and Longjun Cai. 2021. A joint training dual-mrc framework for aspect based sentiment analysis. arXiv preprint arXiv:2101.00816. Tetsuya Nasukawa and Jeonghee Yi. 2003. Sentiment analysis: Capturing favorability using natural lan-CAP '03, page 70-77, New York, NY, USA. Associ-ternational Conference on Knowledge Capture, K-guage processing. In Proceedings of the 2nd In-</cell></row><row><cell>Methods in Natural Language Processing and the Proceedings of the 2019 Conference on Empirical tive models for aspect-based sentiment analysis. In Min Yang. 2019. A challenge dataset and effec-Qingnan Jiang, Lei Chen, Ruifeng Xu, Xiang Ao, and</cell><cell>roberta. arXiv preprint arXiv:2104.04986. baseline for aspect-based sentiment analysis with Xipeng Qiu. 2021. Does syntax matter? a strong Junqi Dai, Hang Yan, Tianxiang Sun, Pengfei Liu, and ation for Computing Machinery.</cell></row><row><cell>9th International Joint Conference on Natural Lan-guage Processing (EMNLP-IJCNLP), pages 6280-6285, Hong Kong, China. Association for Computa-tional Linguistics.</cell><cell>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language under-standing. In Proceedings of the 2019 Conference of</cell></row><row><cell>Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.</cell><cell>the North American Chapter of the Association for Computational Linguistics: Human Language Tech-nologies, Volume 1 (Long and Short Papers), pages 4171-4186.</cell></row><row><cell>Kun Li, Chengbo Chen, Xiaojun Quan, Qing Ling, and Yan Song. 2020a. Conditional augmentation for aspect term extraction via masked sequence-to-sequence generation. In Proceedings of the 58th An-nual Meeting of the Association for Computational Linguistics, pages 7056-7066, Online. Association for Computational Linguistics.</cell><cell>Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, Ming Zhou, and Ke Xu. 2014. Adaptive recursive neural network for target-dependent twitter sentiment clas-sification. In Proceedings of the 52nd annual meet-ing of the association for computational linguistics (volume 2: Short papers), pages 49-54.</cell></row><row><cell>Lishuang Li, Yang Liu, and AnQiao Zhou. 2018a. Hier-archical attention based position-aware network for aspect-level sentiment analysis. In Proceedings of the 22nd Conference on Computational Natural Lan-guage Learning, pages 181-189, Brussels, Belgium. Association for Computational Linguistics.</cell><cell>Zhifang Fan, Zhen Wu, Xinyu Dai, Shujian Huang, and Jiajun Chen. 2019. Target-oriented opinion words extraction with target-fused neural sequence label-ing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-nologies, Volume 1 (Long and Short Papers), pages</cell></row><row><cell>Xin Li, Lidong Bing, Piji Li, and Wai Lam. 2019. A</cell><cell>2509-2518.</cell></row><row><cell>Peng Chen, Shaowei Chen, and Jie Liu. 2020a. Hierar-unified model for opinion target extraction and target sentiment prediction. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 6714-6721. chical sequence labeling model for aspect sentiment Xin Li, Lidong Bing, Piji Li, Wai Lam, and Zhimou triplet extraction. In Natural Language Process-ing and Chinese Computing, pages 654-666, Cham. Springer International Publishing. Yang. 2018b. Aspect term extraction with history at-tention and selective transformation. arXiv preprint arXiv:1805.00760. Shaowei Chen, Jie Liu, Yu Wang, Wenzheng Zhang, Yuncong Li, Cunxiang Yin, Sheng-hua Zhong, and and Ziming Chi. 2020b. Synchronous double-Xu Pan. 2020b. Multi-instance multi-label learning channel recurrent network for aspect-opinion pair networks for aspect-category sentiment analysis. In extraction. In Proceedings of the 58th Annual Meet-Proceedings of the 2020 Conference on Empirical ing of the Association for Computational Linguistics, pages 6515-6524. Shaowei Chen, Yu Wang, Jie Liu, and Yuelin Wang. Methods in Natural Language Processing (EMNLP), pages 3550-3560, Online. Association for Computa-tional Linguistics.</cell><cell>Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. 2013. Speech recognition with deep recur-rent neural networks. In 2013 IEEE international conference on acoustics, speech and signal process-ing, pages 6645-6649. IEEE. Shuqin Gu, Lipeng Zhang, Yuexian Hou, and Yin Song. 2018. A position-aware bidirectional attention net-work for aspect-level sentiment analysis. In Pro-ceedings of the 27th International Conference on Computational Linguistics, pages 774-784, Santa Fe, New Mexico, USA. Association for Computa-tional Linguistics. Ruidan He, Wee Sun Lee, Hwee Tou Ng, and Daniel Dahlmeier. 2019. An interactive multi-task learn-ing network for end-to-end aspect-based sentiment</cell></row><row><cell>2021. Bidirectional machine reading comprehen-Bing Liu. 2012. Sentiment analysis and opinion min-</cell><cell>analysis. In Proceedings of the 57th Annual Meet-</cell></row><row><cell>sion for aspect sentiment triplet extraction. arXiv ing. Synthesis lectures on human language technolo-</cell><cell>ing of the Association for Computational Linguistics,</cell></row><row><cell>preprint arXiv:2103.07665. gies, 5(1):1-167.</cell><cell>pages 504-515.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 12</head><label>12</label><figDesc></figDesc><table><row><cell>shows some hard sentences that both</cell></row><row><cell>GTS-BERT and PBF can not correctly extract all</cell></row><row><cell>triplets from.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 6 :</head><label>6</label><figDesc>More statistics.</figDesc><table><row><cell></cell><cell>14res</cell><cell></cell><cell></cell><cell>14lap</cell><cell></cell><cell></cell><cell>15res</cell><cell></cell><cell></cell><cell>16res</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>GTS-CNN</cell><cell cols="12">64.2 61.7 62.9 56.4 44.1 49.4 54.4 54.4 54.1 59.5 63.9 61.4</cell></row><row><cell cols="13">GTS-BiLSTM 71.6 58.7 64.5 67.3 38.1 48.5 69.0 48.4 56.8 66.8 59.4 62.6</cell></row><row><cell>GTS-BERT</cell><cell cols="12">72.3 71.1 71.7 64.5 56.6 60.2 63.8 59.3 61.5 64.9 71.9 68.1</cell></row><row><cell>PBF</cell><cell cols="12">74.2 73.9 74.0 64.7 63.0 63.8 61.0 67.3 63.9 65.2 77.4 70.8</cell></row><row><cell>PBF -w/o A</cell><cell cols="12">72.1 74.3 73.2 64.0 63.8 63.9 61.8 67.5 64.5 65.4 76.9 70.6</cell></row><row><cell>PBF -w/o P</cell><cell cols="12">73.0 74.2 73.6 65.3 63.2 64.3 61.2 65.8 63.3 64.0 77.1 69.9</cell></row><row><cell>PBF -w/o AP</cell><cell cols="12">48.0 56.1 51.3 52.7 57.1 54.6 45.1 55.0 49.4 49.9 64.7 56.3</cell></row><row><cell>PBF-M1</cell><cell cols="12">71.2 74.5 72.8 66.9 61.6 64.0 63.4 65.1 64.1 63.7 77.5 69.9</cell></row><row><cell>PBF-M2</cell><cell cols="12">68.1 68.8 68.4 60.0 54.8 57.3 56.3 63.0 59.4 61.6 71.7 66.2</cell></row><row><cell>PBF-M3</cell><cell cols="12">71.5 74.2 72.8 65.8 61.7 63.7 59.4 67.7 63.2 64.5 76.0 69.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 7 :</head><label>7</label><figDesc>Results of aspect-opinion pair extraction on the ASOTE-data.</figDesc><table><row><cell></cell><cell>14res</cell><cell></cell><cell></cell><cell>14lap</cell><cell></cell><cell></cell><cell>15res</cell><cell></cell><cell></cell><cell>16res</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>PBF</cell><cell cols="12">82.8 80.3 81.5 73.6 74.5 74.0 75.5 80.4 77.9 77.1 87.9 82.1</cell></row><row><cell>PBF -w/o A</cell><cell cols="12">80.5 80.9 80.7 72.7 75.7 74.1 76.9 80.4 78.6 76.8 87.2 81.6</cell></row><row><cell>PBF -w/o P</cell><cell cols="12">81.3 80.5 80.9 73.8 74.1 74.0 76.2 78.6 77.3 75.2 87.7 81.0</cell></row><row><cell cols="13">PBF -w/o AP 53.0 60.8 56.1 58.9 66.0 61.9 56.2 65.7 60.5 58.0 73.7 64.8</cell></row><row><cell>PBF-M1</cell><cell cols="12">79.4 80.8 80.1 74.8 71.4 73.0 78.1 76.8 77.4 74.0 88.3 80.5</cell></row><row><cell>PBF-M2</cell><cell cols="12">75.6 74.6 75.1 67.5 64.9 66.1 71.4 74.5 72.9 72.2 81.5 76.5</cell></row><row><cell>PBF-M3</cell><cell cols="12">80.0 80.8 80.3 74.0 73.1 73.6 74.6 80.7 77.5 75.6 85.8 80.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 8 :</head><label>8</label><figDesc>Results of the TOWE task on the ASOTE-data.</figDesc><table><row><cell></cell><cell>14res</cell><cell></cell><cell></cell><cell>14lap</cell><cell></cell><cell></cell><cell>15res</cell><cell></cell><cell></cell><cell>16res</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>IOG</cell><cell cols="12">82.8 77.3 80.0 73.2 69.6 71.3 76.0 70.7 73.2 85.2 78.5 81.6</cell></row><row><cell>LOTN</cell><cell cols="12">84.0 80.5 82.2 77.0 67.6 72.0 76.6 70.2 73.2 86.5 80.8 83.6</cell></row><row><cell>ARGCN</cell><cell cols="12">86.6 82.7 84.6 79.4 71.6 75.3 76.5 76.8 76.7 86.1 84.1 85.1</cell></row><row><cell cols="13">ARGCN +bert 87.3 83.5 85.4 75.8 76.9 76.3 78.8 77.6 78.2 88.4 84.9 86.6</cell></row><row><cell>ONG</cell><cell cols="12">83.2 81.4 82.3 73.8 77.7 75.7 76.6 81.1 78.8 87.7 84.3 86.0</cell></row><row><cell>PBF</cell><cell cols="12">85.5 86.2 85.9 81.8 81.2 81.5 79.3 82.4 80.8 89.2 89.3 89.2</cell></row><row><cell>PBF -w/o A</cell><cell cols="12">85.9 86.3 86.1 82.4 80.0 81.2 78.4 82.5 80.4 86.8 89.1 87.9</cell></row><row><cell>PBF -w/o P</cell><cell cols="12">85.7 87.0 86.3 80.2 80.4 80.3 77.5 82.4 79.8 87.4 90.3 88.8</cell></row><row><cell cols="13">PBF -w/o AP 57.9 66.2 61.6 63.1 73.8 67.9 50.4 71.8 59.0 65.2 74.0 69.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>Figure 8: Case study. Red triplets are incorrect predictions.</figDesc><table><row><cell>Method</cell><cell cols="4">14res 14lap 15res 16res</cell></row><row><cell cols="2">PBF -w/o AP 90.8</cell><cell>82.9</cell><cell>89.2</cell><cell>91.2</cell></row><row><cell>PBF</cell><cell>90.8</cell><cell>83.4</cell><cell>88.5</cell><cell>92.0</cell></row><row><cell>PBF -w/o P</cell><cell>91.0</cell><cell>82.8</cell><cell>88.8</cell><cell>91.6</cell></row><row><cell>PBF -w/o A</cell><cell>90.6</cell><cell>83.2</cell><cell>89.3</cell><cell>91.5</cell></row><row><cell>PBF-M1</cell><cell>90.9</cell><cell>83.2</cell><cell>88.2</cell><cell>91.5</cell></row><row><cell>PBF-M2</cell><cell>89.2</cell><cell>80.7</cell><cell>85.2</cell><cell>89.2</cell></row><row><cell>PBF-M3</cell><cell>90.9</cell><cell>82.6</cell><cell>89.0</cell><cell>92.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 10 :</head><label>10</label><figDesc>Results of AOPSC task in terms of accuracy.</figDesc><table><row><cell></cell><cell cols="2">14res</cell><cell></cell><cell>14lap</cell><cell></cell><cell>15res</cell><cell></cell><cell>16res</cell><cell></cell></row><row><cell cols="2">Method P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1 P</cell><cell>R F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>PBF</cell><cell cols="10">87 88.4 87.7 82.7 81.3 82 68.4 73 70.5 75.3 76.5 75.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 11 :</head><label>11</label><figDesc>Results of the Aspect Term Extraction (ATE) task.</figDesc><table><row><cell>Sentence</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">OTE extracts opinions from sentences.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">More analysis about the works of<ref type="bibr" target="#b14">Wang et al. (2016</ref><ref type="bibr" target="#b15">Wang et al. ( , 2017</ref> can be found in the Appendix A.4 More analysis about the work of<ref type="bibr" target="#b24">Zhang et al. (2020)</ref> can be found in the Appendix A.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The triplets extracted by ASOTE from this sentence, i.e. ("place", negative, "sleek") and ("place", negative, "modern"), are also confusing, since the sentiment shifter expression is complicated and therefore is not annotated as part of the opinions. One simple solution to this problem is to add a reversing word (e.g.,"not") to this kind of opinions (e.g., "not sleek" and "not modern") when we annotate opinions, which is left for future exploration.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">https://github.com/l294265421/OTE-MTL-ASOTE 7 https://github.com/l294265421/Position-Aware-Taggingfor-ASOTE</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ground Truth GTS-BERT PBF</head><p>Simple healthy unglamorous food cheap.</p><p>("food", positive, "Simple"), ("food", positive, "cheap"), ("food", positive, "healthy"), ("food", positive, "unglamorous") ("food", positive, "Simple healthy unglamorous") ("food", positive, "cheap"), ("food", positive, "healthy"), ("food", positive, "unglamorous") The staff should be a bit more friendly .</p><p>("staff", negative, "friendly") ("staff", positive, "friendly") ("staff", positive, "friendly") The gnocchi literally melts in your mouth! ("gnocchi", positive, "melts")</p><p>The avocado salad is a personal fave .</p><p>("avocado salad", positive, "fave") good food good wine that 's it .</p><p>("food", positive, "good"), ("wine", positive, "good") ("food", positive, "good"), ("wine", positive, "good"), ("wine", positive, "good") ("wine", positive, "good")</p><p>Save room for deserts -they 're to die for .</p><p>("deserts", positive, "die for")</p><p>Service was good and so was the atmosphere.</p><p>("Service", positive, "good"), ("atmosphere", positive, "good") ("Service", positive, "good") ("Service", positive, "good") Try the homemade breads.</p><p>("homemade breads", positive, "Try") ("breads", positive, "Try")</p><p>The help was extremely nice and did not rush us.</p><p>("help", positive, "nice") ("help", positive, "nice") </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">PhraseRNN: Phrase recursive neural network for aspect-based sentiment analysis</title>
		<idno type="DOI">10.18653/v1/D15-1298</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>Thien Hai Nguyen and Kiyoaki Shirai</editor>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2509" to="2514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Knowing what, how and why: A near complete solution for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modelling context and syntactical features for aspectbased sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><surname>Hieu Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">O</forename><surname>Ogunbona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3211" to="3220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SemEval-2016 task 5: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al-</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmoud</forename><surname>Smadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Al-Ayyoub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orph?e</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V?ronique</forename><surname>De Clercq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marianna</forename><surname>Hoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Apidianaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Loukachevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kotelnikov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S16-1002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>Nuria Bel, Salud Mar?a Jim?nez-Zafra, and G?l?en Eryigit; San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="19" to="30" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SemEval-2015 task 12: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S15-2082</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="486" to="495" />
		</imprint>
	</monogr>
	<note>Suresh Manandhar, and Ion Androutsopoulos</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">SemEval-2014 task 4: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harris</forename><surname>Papageorgiou</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/S14-2004</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
		<meeting>the 8th International Workshop on Semantic Evaluation<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="27" to="35" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Introducing syntactic structures into target opinion word extraction with deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Amir Pouran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasim</forename><surname>Veyseh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franck</forename><surname>Nouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejing</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thien Huu</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.719</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8947" to="8956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Opinion word expansion and target extraction through double propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="9" to="27" />
		</imprint>
	</monogr>
	<note>Computational linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">brat: a web-based tool for NLP-assisted text annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goran</forename><surname>Topi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="102" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tell me why you feel that way: Processing compositional dependency for tree-lstm aspect sentiment triplet extraction (taste)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suna</forename><surname>Bensch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hellstr?m</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Magg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Wermter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks and Machine Learning -ICANN 2020</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="660" to="671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effective LSTMs for target-dependent sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3298" to="3307" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dependency graph enhanced dualtransformer structure for aspect-based sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiji</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6578" to="6588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Relational graph attention network for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhou</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.12362</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokui</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06679</idno>
		<title level="m">Recursive neural conditional random fields for aspect-based sentiment analysis</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Coupled multi-layer attentions for co-extraction of aspect and opinion terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokui</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Don&apos;t eclipse your arts due to small discrepancies: Boundary repositioning with a pointer network for aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenkai</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowei</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yao Jianmin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3678" to="3684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Enriching pretrained language model with entity information for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanchan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2361" to="2364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Grid tagging scheme for aspect-oriented fine-grained opinion extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengcan</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.234</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2576" to="2585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Latent opinions transfer network for target-oriented opinion words extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin-Yu</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.01989</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Double embeddings and cnn-based sequence labeling for aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S Yu</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="592" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Position-aware tagging for aspect sentiment triplet extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.183</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2339" to="2349" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Aspect based sentiment analysis with gated convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1234</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2514" to="2523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Unsupervised word and dependency path embeddings for aspect term extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaimeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07843</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A multi-task learning framework for opinion triplet extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuchi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.72</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="819" to="828" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Spanmlt: A span-based multi-task learning framework for pair-wise aspect and opinion terms extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longtao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3239" to="3248" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
