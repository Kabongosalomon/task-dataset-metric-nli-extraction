<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Klexikon: A German Dataset for Joint Summarization and Simplification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Aumiller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">Heidelberg University</orgName>
								<address>
									<addrLine>Im Neuenheimer Feld 205</addrLine>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gertz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">Heidelberg University</orgName>
								<address>
									<addrLine>Im Neuenheimer Feld 205</addrLine>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Klexikon: A German Dataset for Joint Summarization and Simplification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Summarization</term>
					<term>Text Simplification</term>
					<term>German</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Traditionally, Text Simplification is treated as a monolingual translation task where sentences between source texts and their simplified counterparts are aligned for training. However, especially for longer input documents, summarizing the text (or dropping less relevant content altogether) plays an important role in the simplification process, which is currently not reflected in existing datasets. Simultaneously, resources for non-English languages are scarce in general and prohibitive for training new solutions. To tackle this problem, we pose core requirements for a system that can jointly summarize and simplify long source documents. We further describe the creation of a new dataset for joint Text Simplification and Summarization based on German Wikipedia and the German children's encyclopedia "Klexikon", consisting of almost 2,900 documents. We release a document-aligned version that particularly highlights the summarization aspect, and provide statistical evidence that this resource is well suited to simplification as well. Code and data are available on Github: https://github.com/dennlinger/klexikon</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The goal of Text Simplification (TS) is to produce easily understandable texts that benefit disadvantaged readers such as children, dyslexic, or language learners. Simplifications are often generated by adapting a source text written for adult/native readers. However, recent work in simplification has mostly addressed TS as a monolingual translation task, where individual sentences are "translated" into a simplified version <ref type="bibr" target="#b40">(Zhu et al., 2010;</ref><ref type="bibr" target="#b4">Coster and Kauchak, 2011;</ref><ref type="bibr" target="#b12">Hwang et al., 2015)</ref>. The main focus is put on either lexicographic replacements, paraphrasing, sentence splitting, or the dropping of words within a single sentence <ref type="bibr" target="#b0">(Amancio and Specia, 2014)</ref>, which implies that the simplification of any input document will consist of roughly the same number of sentences. While this approach is appropriate for sufficiently short source documents, longer articles become strenuous for disadvantaged readers. As can be seen in <ref type="table" target="#tab_0">Table 1</ref>, articles in different corpora come with varying lengths of their respective source texts. When simplifications are generated via manual sentence-by-sentence translations, the simplified texts tend to have more sentences than the source documents. When alignments are constructed from a source and simplification text on the same topic instead, they exhibit a drastic length disparity. Current simplification systems are, however, inherently limited in their ability to address the problem of joint simplification and summarization from much longer input documents. Sentence-level alignments were traditionally seen as one way to circumvent certain problems in TS, namely:</p><p>1. Human feedback for judging simplification quality is more consistent for sentences, compared to longer samples, such as entire documents.  <ref type="bibr" target="#b37">(Xu et al., 2015;</ref><ref type="bibr" target="#b11">Hewett and Stede, 2021)</ref>, we refer to the respective simplified corpora with simplification level 1.</p><p>2. Metrics such as BLEU <ref type="bibr" target="#b26">(Papineni et al., 2002)</ref> or SARI <ref type="bibr" target="#b38">(Xu et al., 2016)</ref> rely on (aligned) reference texts for automated evaluation. 3. Prior alignment of sentences limits the length of input samples, which is essential for algorithms with non-linear runtime, or length constraints.</p><p>In this work, we present remedies to the problem of missing document alignments, and argue that the inclusion of summarization into the broader context of Text Simplification is a necessary step towards end-toend solutions for longer input texts. Specifically, it addresses the following problems:</p><p>1. Long-form documents can be compressed into significantly shorter summarized simplifications. 2. Document alignments provide context for models that are otherwise based on single sentence pairs. 3. The amount of accessible training data increases, which is especially important for languages other than English, where data is generally scarce.</p><p>Simultaneously, TS offers interesting challenges to the summarization community, which hopefully facilitates exchange between the two fields: On existing summarization datasets, simply taking the leading three sentences offers strikingly good results <ref type="bibr" target="#b22">(Nallapati et al., 2017)</ref>, which may lead to systems learning specific extractive strategies instead of generalizing to broader textual relevance. Preliminary experiments show that our dataset poses a harder challenge for summarization systems, due to the additional simplification aspect. Our proposed resource was obtained from semiautomated alignments between the German Wikipedia and the children's encyclopedia "Klexikon" <ref type="bibr" target="#b29">(Schulte and van Dijk, 2015)</ref>, written for children aged 8 to 13 years. 1 With almost 2,900 articles, it is the largest non-English resource with document alignments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Related work can broadly be categorized into relevant simplification work, and associated works on resources for (German) summarization datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Text Simplification</head><p>Previously mentioned work frequently deals with data aligned based on Simple Wikipedia <ref type="bibr" target="#b40">(Zhu et al., 2010;</ref><ref type="bibr" target="#b4">Coster and Kauchak, 2011;</ref><ref type="bibr" target="#b12">Hwang et al., 2015)</ref>. The main differences between these approaches lie in their alignment strategies and underlying simplification model. The only work on Simple Wikipedia that specifically introduces a document-aligned version is <ref type="bibr" target="#b14">(Kauchak, 2013)</ref>, who investigates performance gains from supplementing language models with additional (non-simplified) texts. Importantly, it is not explicitly used for learning simplification. <ref type="bibr" target="#b10">(Hancke et al., 2012)</ref> introduced a first German resource containing simplified texts based on unaligned articles from GEO and GEOlino, a German magazine similar to National Geographic, and its edition specifically for children. They build a classification system that is able to classify between normal and simplified texts for several article categories. A larger and improved version from the same source was collected by <ref type="bibr" target="#b35">(Wei? and Meurers, 2018)</ref>, who also introduce a resource based on transcripts from German TV broadcasts (Tagesschau/Logo!), again without any alignment. The first mention of an aligned corpus for German can be found in <ref type="bibr" target="#b15">(Klaper et al., 2013)</ref>, who automatically align websites with their corresponding versions in accessible language. Their corpus contains a total of about 270 articles. Most recently, <ref type="bibr" target="#b2">(Battisti et al., 2020)</ref> collected a larger corpus, where 378 texts contain document alignments. Arguably, unaligned resources might still be helpful to facilitate pre-training of models. In an attempt to circumvent data scarcity, <ref type="bibr" target="#b20">(Mallinson et al., 2020)</ref> em-ploy multi-lingual pre-training, which they tested with a small, manually labeled German evaluation set. To our knowledge, <ref type="bibr" target="#b11">(Hewett and Stede, 2021)</ref> were the first to utilize alignments between Wikipedia and Klexikon, with an additional extension to MiniKlexikon, a secondary simplification level. Due to the further required alignments, the overall size of their data is about 10% of our presented corpus. To avoid problems stemming from extreme length discrepancies, they also only extract introduction and abstracts for Wikipedia articles, which is something we explicitly encourage in our version. This also explains the different lengths while using the same document sources, as reported in <ref type="table" target="#tab_0">Table 1</ref> . <ref type="bibr" target="#b27">(Parmanto et al., 2005)</ref> are the first to explicitly explore summarization and simplification in a common context, albeit for the task of website accessibility. Further work models summarization itself as a simplification technique, e.g., <ref type="bibr" target="#b21">(Margarido et al., 2008)</ref> investigated extractive summarization approaches and how they help disadvantaged readers. A similar experiment was conducted by <ref type="bibr" target="#b31">(Smith and J?nsson, 2011)</ref> for Swedish texts, who find summarized texts to be more readable as well. Also dealing with extractive summarizers, (Finegan-Dollak and Radev, 2016) look at simplifications in the biomedical and legal domain, but their findings indicate that altered sentences lead to fewer correctly answered questions by domain experts. Simplification has also been suggested for multidocument summarization: <ref type="bibr" target="#b30">(Siddharthan et al., 2004)</ref> select relevance exclusively over syntactically simplified sentences, whereas other works use simplification as an alternative to regular sentence selection <ref type="bibr" target="#b39">Yih et al., 2007)</ref>. Closest to a unified framework is the work by <ref type="bibr" target="#b19">(Ma and Sun, 2017)</ref>, who use the same neural encoder-decoder architecture for separate simplification and summarization tasks, which highlights the shared similarities in terms of shared model architectures and training. To our knowledge, there exist few resources for German single-document summarization. <ref type="bibr" target="#b23">(Nitsche, 2019)</ref> mention a (private) resource, provided by the German Press Agency (dpa), which uses headlines as target summaries. <ref type="bibr" target="#b9">(Frefel, 2020</ref>) generate a corpus based on German Wikipedia articles, and treat the overview paragraph at the beginning as the summary of the article. A similar approach including cross-lingual alignments between English and German has also been recently published <ref type="bibr" target="#b6">(Fatima and Strube, 2021)</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Summarization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Text Simplification with Joint Summarization</head><p>As previous work has shown, summarization in itself can already be considered a weaker form of simplification <ref type="bibr" target="#b21">(Margarido et al., 2008;</ref><ref type="bibr" target="#b31">Smith and J?nsson, 2011)</ref>, although existing work never formalizes TS as a summarization problem. Several points have to be addressed by both simplification and summarization components for a full end-to-end solution. In this section, we outline suggestions for a unified system design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Considerations for Simplification</head><p>As previously stated, current simplification systems cannot generate significantly shorter output texts when simplifying individual sentences. This is mainly due to the sentence-aligned training setup instead of training with the entire input document. Further, this drops a sizable portion of the source text from training, since sentences are only considered when they align directly with a simplified part. Several resources also lack a document alignment altogether, which completely precludes them from being used as a training resource for end-to-end systems. Importantly, relevance of individual segments (sentences or paragraphs) has to be computed without knowledge about the output corpus. This can, for example, be achieved by pre-training strategies on monolingual corpora <ref type="bibr" target="#b20">(Mallinson et al., 2020)</ref>, but could otherwise be learned as an intermediate step in neural architectures. This has been previously shown to work well for multi-document summarization <ref type="bibr" target="#b17">(Liu and Lapata, 2019)</ref>, where paragraph relevance was learned across several documents. Further, existing manually annotated corpora are frequently generating simplifications of short texts by "translating" sentence-by-sentence. This reinforces the bias towards equally long documents, which cannot be observed in post-aligned resources (i.e., where existing simplified texts were written independently on the same topic, cf. <ref type="table" target="#tab_0">Table 1</ref>). An amended assumption is that simplifications may only be up to a certain length, due to varying attention spans of the target groups. This then requires additional "simplification" based on the length of the source document. This could also be used as a parameter to model levels of difficulty, which is available for some resources, see the Newsela corpus <ref type="bibr" target="#b37">(Xu et al., 2015)</ref>. Lastly, existing evaluation metrics strictly focus on sentence-level references <ref type="bibr" target="#b38">(Xu et al., 2016)</ref>. Extend-ing system evaluations to document-level simplifications poses challenges that need to be overcome in order to collect both manual and automated feedback on the simplification quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Considerations for Summarization</head><p>For summarization, TS offers additional challenges not considered by current works. Given a high enough compression rate, simplification can be seen as a special case of summarization. However, existing metrics, such as ROUGE <ref type="bibr" target="#b16">(Lin, 2004)</ref>, rely on the re-appearance of n-grams in the target summary (in our case, the simplification). This is not guaranteed, given that the simplification can appear in the form of lexicographic replacements. It is thus unclear whether simplification should be considered a separate criterion or jointly modeled for the evaluation of summaries, specifically when considering other input factors as well (ter Hoeve et al., 2020). Additionally, the varying vocabulary and sentence structure pose a challenge to summarization systems, especially extractive approaches. See Section 4.3 for experiments on our Klexikon corpus. Previous work in that direction has mostly dealt with sentence-level lexicographic simplifications <ref type="bibr" target="#b30">(Siddharthan et al., 2004)</ref>, yet there are several other simplification operations to be considered <ref type="bibr" target="#b0">(Amancio and Specia, 2014)</ref> in a joint end-to-end system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Klexikon Dataset</head><p>We introduce a new dataset, loosely inspired in its construction by English Simple Wikipedia, to facilitate future research in joint simplification and summarization. Specifically, we use the German children's encyclopedia "Klexikon" to obtain simplifications, and align them with reference articles from the German Wikipedia. Compared to Simple Wikipedia, which can be freely edited, Klexikon specifically targets children between roughly the age of 8-13 as readers, and follows a strict reviewing procedure for individual articles, resulting in higher quality texts. We only consider Wikipedia articles with a minimum length of 15 paragraphs, which helps to filter out disambiguation pages or stubs . Additionally, this results in a clear contrast in overall article length between source and simplified texts (cf. <ref type="table" target="#tab_0">Table 1</ref> and <ref type="figure" target="#fig_0">Figure 1</ref>). The final dataset consists of 2,898 article pairs, with Wikipedia documents having on average 8.94 times more sentences compared to their Klexikon counterparts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Corpus Creation</head><p>All manual steps during corpus creation were performed by the first author of this work. We begin the extraction based on the list of all available articles from the Klexikon overview page in April 2021 2 . At the time of experimentation, this returned 3,150 Klexikon articles, although more articles have been added since 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Document Alignment Strategy</head><p>For the identification of matching articles between German Wikipedia and Klexikon, the following steps were performed: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Text Extraction</head><p>The Klexikon website runs on the Wiki software, which makes text extraction across platforms very similar. For both websites, we extract all direct children elements of the main content block (div-class: mw-parser-output). Of those, we only use text within &lt;p&gt; tags as the main paragraph content, and heading elements &lt;h1&gt;-&lt;h5&gt;. This simultaneously discards non-textual contents, e.g., images, as well as malformed text elements, such as image captions or lists. We note that the removal of lists can also remove valid content, but frequently suffers from inconsistent grammatical correctness; while some bullet lists  are equivalent to a self-contained paragraph, more often than not, it simply contains enumerations. Further limitations for summarization include the potential content split on Wikipedia. For example, in the Klexikon article about the city of Aarhus, there is explicit information about the ARoS (Aarhus art museum); however, on Wikipedia, this information would be found in the article about the museum itself, and not in the page about the city. For now, we defer these edge cases to future extensions including multi-document summarization/simplification. To avoid encoding errors, we drop any character that appears less than 100 times in the corpus; more frequently appearing special characters are mapped to the closest latin character (e.g.,? to a), with the exception of????, which are part of the standard German alphabet. In the absence of a close mapping (e.g., for Cyrillic letters), the character is dropped as well. This assumes that foreign characters are irrelevant for simplified texts, which we can indeed observe from the utilized character set in Klexikon articles. We process the raw text with spaCy's 6 de-core-news-md model to separate sentences. Our final data format maintains the following document representation:</p><p>1. Line-by-line sentence representations based on spaCy boundary detection, 2. Additional indication of separation of paragraphs (original &lt;p&gt; elements), and 3. Highlighted headings according to the indicated level (heading, subheading, etc.), available primarily for the Wikipedia documents.</p><p>A statistical view of the corpus can be found in <ref type="table" target="#tab_3">Table 2</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">Sentence Alignments</head><p>We also experimented with the creation of an automatically sentence-aligned variant of our data set. Unfortunately, existing alignment algorithms from the TS community are not applicable here. <ref type="bibr">CATS (?tajner et al., 2018)</ref> is one representative from the class of greedy alignment algorithms; these base their alignments on the assumption that a similar order of the content exists for both the source and simplification texts. This does not apply to our dataset, since texts have been written independently. Algorithms with non-greedy align-ment strategies exist <ref type="bibr" target="#b24">(Paetzold et al., 2017;</ref><ref type="bibr" target="#b13">Jiang et al., 2020)</ref>, but lack compatibility with German texts. We instead experimented with alignments based on sentence embeddings from sentencetransformers <ref type="bibr">(Reimers and Gurevych, 2019) 7</ref> , and selecting the most similar source sentence (or pair of sentences) for each Klexikon sentence. However, sentence splitting and merging are impossible to model with this naive alignment strategy, but were frequently found to be the issue of sub-par alignments in a manual review of preliminary results. In particular, we also note that there were both cases of several relevant Wikipedia sentences for a single Klexikon sentence (highlighting the importance of a notion of "relevance"), as well as instances of long sentences from Wikipedia splitting into several (non-consecutive) sentences in the Klexikon text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison to Existing Resources</head><p>The only other two German datasets with document alignments are the recent resource by <ref type="bibr" target="#b2">(Battisti et al., 2020)</ref>, as well as a smaller version of Klexikon data by <ref type="bibr" target="#b11">(Hewett and Stede, 2021)</ref>. <ref type="bibr" target="#b2">(Battisti et al., 2020)</ref> compiled documents from accessibility options on websites. Compared to our dataset, they potentially cover a more heterogeneous set of topics, but only provide alignments for a subset of articles. As mentioned before, <ref type="bibr" target="#b11">(Hewett and Stede, 2021)</ref> provide additional alignments to MiniKlexikon, and otherwise limit the maximum length of articles, which reduces the number of available alignments between all three resources to 295 documents. Even when considering only the equivalent Klexikon-Wikipedia alignments, there are less than 1,000 documents, with additional constraints to the completeness of the Wikipedia texts. Concerns raised about the quality of Wikipedia as a resource <ref type="bibr" target="#b37">(Xu et al., 2015)</ref> mention the problems with sentence alignment, inadequate simplifications, and poor generalization. Our version of the Klexikon dataset partially alleviates these issues:</p><p>1. We provide document and (automated) sentence alignments, which allows focusing on both summarization and simplification in a joint manner. 2. Articles for Klexikon are written following stricter guidelines both in their content structure, and we include stricter pre-processing criteria for the Wikipedia articles, resulting in a high-quality collection of text documents. 3. We provide sufficient training samples for potential neural approaches, by increasing the Klexikon-based resource to almost 2,900 articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Baseline Performance</head><p>To quantify the quality of our automatically generated alignments, we investigate the dataset from both a summarization and simplification perspective. 7 paraphrase-multilingual-mpnet-base-v2, a multilingual variant also suitable for German texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Summarization</head><p>To verify the suitability of our corpus for summarization purposes, we computed several baselines and compared them to the Klexikon articles as a presumable gold standard summary:</p><p>1. Lead-3: A baseline frequently used in news article summarization, which consists of the first three sentences. In our case, this corresponds to the first three sentences of the Wikipedia article. 2. Lead-k: A related baseline, taking all sentences of the overview section in the Wikipedia article. 3. Full article: The full Wikipedia article as a reference for the maximum possible vocabulary overlap (this corresponds to ROUGE-1 recall). 4. ROUGE-2 oracle: As an approximation of the upper limit for extractive summaries on this dataset, we select the sentence maximizing ROUGE-2 F1 scores for each sentence in the Klexikon article and 5. Luhn: A simple unsupervised baseline for extractive summaries can be generated by Luhn's algorithm <ref type="bibr" target="#b18">(Luhn, 1958)</ref>. We use a target of 25 extracted sentences for each generated summary, which corresponds roughly to the median number of sentences in the Klexikon articles. 6. LexRank S-T: As a more sophisticated baseline, this approach supplies LexRank <ref type="bibr" target="#b5">(Erkan and Radev, 2004)</ref> with embeddings extracted by sentence-transformers <ref type="bibr" target="#b28">(Reimers and Gurevych, 2019)</ref> 8 . The length is similarly limited to at most 25 extracted sentences.</p><p>We use ROUGE <ref type="bibr" target="#b16">(Lin, 2004)</ref> to gauge summarization quality, which evaluates n-gram overlap between system outputs and gold references. In particular, we report F1 scores for ROUGE-1, ROUGE-2 and ROUGE-L. Results in <ref type="table" target="#tab_5">Table 3</ref> indicate that our dataset poses a significantly harder challenge compared to performance of baselines on standard summarization corpora, such as CNN/DailyMail <ref type="bibr" target="#b22">(Nallapati et al., 2017)</ref>, where simple lead-3 baselines obtain extremely high ROUGE scores due to an overly pronounced lead bias. On our dataset, lead-3 likely struggles with the very different output lengths and comparatively low recall scores; the opposite is true for the full article baseline, which does not summarize at all, and therefore scores poorly in terms of precision. However, the full article baseline obtains a recall score of 77.3% ROUGE-1, implying there is still a sizable vocabulary overlap between the Klexikon and Wikipedia articles. With proper summarization methods, it is therefore possible to produce decent ROUGE scores, and another indicator of the corpus' suitability to summarization. Bestsuited as a baseline is lead-k, which is a decent approximation of the actual target article length. Even so, lead-k is shorter than the corresponding Klexikon articles. Based on these results, coupled with varying  compression levels between articles (cf. <ref type="figure" target="#fig_0">Figure 1 )</ref>, a high sensitivity to the overall input length seems to be required in order to generate appropriate summaries. From the extractive summaries generated by unsupervised methods, it becomes obvious that content from sections outside the overview paragraph is beneficial in terms of ROUGE scores, which is a promising distinction from other summarization datasets, especially in German. Finally, the ROUGE-2 oracle gives insights into the limitations of extractive summarization methods on this dataset. In particular, the differing expressiveness and vocabulary impacts the achievable ROUGE-2 and ROUGE-L scores. It should be noted, however, that the determination of output lengths seems to play a crucial role in the overall balance between precision and recall scores. Given that both unsupervised baselines work with informed choices of the expected summary length, their results should also be taken within the correct context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Simplification</head><p>We further provide different metrics to estimate the level of simplification present in the available documents. For this, we compute Flesch reading-ease scores <ref type="bibr" target="#b8">(Flesch, 1948)</ref>, specifically an adjusted variation for German <ref type="bibr" target="#b1">(Amstad, 1978)</ref>. In addition, we hypothesize that the average sentence length (in tokens), as well as the average number of characters per words are suitable proxies for simplification. The latter is especially important for German, which is famous for its long compound words. In particular, we limit the word length calculation to "content word classes", i.e., nouns, verbs, adjectives, and adverbs only.</p><p>To cover lexicographic peculiarities in the data, we estimate the underlying vocabulary. Notably, the overall texts are quite different in lengths, so an absolute count of distinct tokens would heavily bias the results on Wikipedia. Instead, we approximate this problem by looking at corpus-specific lemma coverage. By computing a corpus-specific list of the 1000 most frequently occurring lemmas, we are then able to compute what fraction of all used lemmas is contained in this top-1000 list. A higher percentage likely points to fewer rare words used, and greater reliance on commonly understood words or an overall smaller vocabulary. Indeed, we find a consistent pattern in our data (cf. Ta-Wikipedia Klexikon Avg. Flesch score 40.1 ? 7.3 66.7 ? 6.0 Avg. sentence length 22.7 ? 2.6 13.5 ? 1.5 Avg. word length 8.7 ? 4.0 6.9 ? 3.0 Share of top 1000 lemmas 68.8% 82.3% <ref type="table">Table 4</ref>: Indicators of simplified target texts: averages for Flesch complexity scores (between 0 to 100; higher scores indicate simpler texts); average sentence length in tokens; average word length in characters (nouns, verbs, adjectives, adverbs); percentage share of occurrences of the top-1000 corpus-specific lemmas.</p><p>ble 4), where Klexikon data indicates simpler language on all our metrics, which confirms the suitability of our dataset for simplification tasks. We would like to point out the general consensus of the field that heuristics are only scratching the surface of representative readability judgments <ref type="bibr" target="#b3">(Chall, 1958)</ref>, but still offer a chance for initial exploratory analysis of data suitability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>In this work, we laid out basic requirements for a unified Text Simplification and Summarization framework. Specifically, we also provided a documentaligned resource of German texts to facilitate future research in this area, and provide quantitative evidence of the suitability of our dataset. We see the following points as the most critical issues for successful joint models: i) Learned sentence relevance and simplification in a joint setting. This can be potentially achieved by modeling sentence alignments similar to existing methods <ref type="bibr">(?tajner et al., 2018;</ref><ref type="bibr" target="#b13">Jiang et al., 2020)</ref>, but already during the training of an end-to-end system, instead of a separate pre-processing step. ii) Implementation of automated evaluation metrics that align both with human judgments of appropriateness for the summary, as well as simplification steps taken. ROUGE, based on n-grams, potentially suffers similar shortcomings to BLEU as an evaluation metric, since it fails to capture lexicographic simplifications. Existing simplification metrics, however, are unable to quantize the quality based on much longer source documents.</p><p>iii) Extension of current abstractive summarization systems towards lexicographic simplification, potentially in the form of regularization during training.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Histogram of our Klexikon dataset by number of sentences. Displayed are the distribution for source texts (left; bin width 50), simplified articles (center; bin width 5), and compression ratio of source over simplified lengths (right; bin width 2). Vertical lines represent median length (continuous orange), mean length (dashed black) and one standard deviation (dotted black).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Corpus statistics for datasets with document alignments in German (top) and English (bottom).</figDesc><table><row><cell></cell><cell cols="3">Aligned Avg. #Sentences</cell></row><row><cell>Resource</cell><cell cols="3">Articles Source Simple</cell></row><row><cell>Klexikon (Ours)</cell><cell cols="2">2,898 242.09</cell><cell>32.51</cell></row><row><cell cols="2">(Hewett and Stede, 2021) 978</cell><cell>10.12</cell><cell>43.54</cell></row><row><cell>(Battisti et al., 2020)  *</cell><cell>378</cell><cell>45.29</cell><cell>55.75</cell></row><row><cell>(Kauchak, 2013)</cell><cell>59,775</cell><cell>64.52</cell><cell>8.46</cell></row><row><cell>(Xu et al., 2015)  *</cell><cell>1,130</cell><cell>49.59</cell><cell>51.27</cell></row></table><note>* indicates resources created by simplifying arti- cles sentence-by-sentence. For</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Corpus statistics of the Klexikon dataset. SD refers to one standard deviation.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Average ROUGE F1 for simple extractive baselines. 95% confidence intervals for all scores differ by less than one point.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://klexikon.zum.de/wiki/Hilfe: Grunds%C3%A4tze, accessed: 15.01.2022</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://klexikon.zum.de/wiki/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">https://spacy.io , version 3.2</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">The same model as mentioned in footnote 7 is used.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Resources and Parameters</head><p>For the evaluation of ROUGE scores, we used the Python implementation provided by Google Research. <ref type="bibr">9</ref> We replace the original stemmer with Cistem (Weissweiler and Fraser, 2017) to account for appropriate treatment of German tokens. Flesch complexity scores were computed with the textstat library 10 , using the function for German. Sentence length in tokens was derived from the tokenization mentioned in the main article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Data Split</head><p>We additionally present a stratified data split for the corpus, with an approximate 80/10/10 split for training, validation and testing. For stratification, we represent each pair of source/simplification documents by their respective lengths in number of sentences. We then divide the coordinate system into a rectangular grid (steps of 100 for Wikipedia article length, step size 10 for Klexikon), and proceed to sample from each grid block according to our pre-defined split (10% of grid samples are selected for validation, 10% for testing, and </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An analysis of crowdsourced text simplifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Amancio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR)</title>
		<meeting>the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR)<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-04" />
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Wie verst?ndlich sind unsere Zeitungen? Studenten-Schreib-Service</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Amstad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A corpus for automatic readability assessment and text simplification of German</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Battisti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pf?tze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>S?uberli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kostrzewa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ebling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3302" to="3311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Readability: An appraisal of research and application. Number 34. Ohio State University</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Chall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Simple English Wikipedia: A new text simplification task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Coster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kauchak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="665" to="669" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Lexrank: Graphbased lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A novel Wikipedia based dataset for monolingual and cross-lingual summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fatima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on New Frontiers in Summarization</title>
		<meeting>the Third Workshop on New Frontiers in Summarization<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11" />
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Sentence simplification, compression, and disaggregation for summarization of sophisticated documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finegan-Dollak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2437" to="2453" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A new readability yardstick</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Flesch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of applied psychology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">221</biblScope>
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Summarization corpora of Wikipedia articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Frefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France, May</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6651" to="6655" />
		</imprint>
	</monogr>
	<note>European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Readability classification for German using lexical, syntactic, and morphological features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hancke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vajjala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meurers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<meeting><address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-12" />
			<biblScope unit="page" from="1063" to="1080" />
		</imprint>
	</monogr>
	<note>Proceedings of COLING 2012</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatically evaluating the conceptual complexity of German texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hewett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Conference on Natural Language Processing (KONVENS 2021)</title>
		<meeting>the 17th Conference on Natural Language Processing (KONVENS 2021)<address><addrLine>D?sseldorf, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Aligning sentences from standard Wikipedia to Simple Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-05" />
			<biblScope unit="page" from="211" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural CRF model for sentence alignment in text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maddela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="7943" to="7960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving text simplification language modeling using unsimplified text data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kauchak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1537" to="1546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Building a German/simple German parallel corpus for automatic text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klaper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ebling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Volk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Predicting and Improving Text Readability for Target Reader Populations</title>
		<meeting>the Second Workshop on Predicting and Improving Text Readability for Target Reader Populations<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hierarchical transformers for multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07" />
			<biblScope unit="page" from="5070" to="5081" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The automatic creation of literature abstracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Luhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="165" />
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A semantic relevance based neural network for text summarization and text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.02318</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Zero-shot crosslingual sentence simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mallinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="5109" to="5126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic summarization for text simplification: Evaluating text understanding by poor readers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Margarido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Antonio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Fuentes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Aires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Alu?sio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fortes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the XIV Brazilian Symposium on Multimedia and the Web</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="310" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Summarunner: A recurrent neural network based sequence model for extractive summarization of documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Towards German Abstractive Text Summarization using Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nitsche</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>HAW Hamburg</publisher>
		</imprint>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">MASSAlign: Alignment and annotation of comparable documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Alva-Manchego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IJCNLP 2017</title>
		<meeting>the IJCNLP 2017</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
	<note>System Demonstrations</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taiwan</forename><surname>Tapei</surname></persName>
		</author>
		<imprint>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002-07" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Access: accessibility through simplification &amp; summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Parmanto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ferrydiansyah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saptono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Sugiantara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hackett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 international cross-disciplinary workshop on web accessibility (W4A)</title>
		<meeting>the 2005 international cross-disciplinary workshop on web accessibility (W4A)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="18" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using Siamese BERTnetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11" />
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schulte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Van Dijk</surname></persName>
		</author>
		<title level="m">Free Children&apos;s Encyclopedia Project</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Syntactic simplification for improving content selection in multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddharthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING 2004: Proceedings of the 20th International Conference on Computational Linguistics</title>
		<meeting><address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>COLING</publisher>
			<date type="published" when="2004-08-23" />
			<biblScope unit="page" from="896" to="902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic summarization as means of simplifying texts, an evaluation for Swedish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>J?nsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Nordic Conference of Computational Linguistics (NODALIDA 2011)</title>
		<meeting>the 18th Nordic Conference of Computational Linguistics (NODALIDA 2011)<address><addrLine>Riga, Latvia, May</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="198" to="205" />
		</imprint>
	</monogr>
	<note>Northern European Association for Language Technology (NEALT)</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">CATS: A tool for customized alignment of text simplification corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Stajner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">What makes a good summary? reconsidering the focus of automatic summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ter Hoeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kiseleva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.07619</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Beyond SumBasic: Taskfocused summarization with sentence simplification and lexical expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1606" to="1618" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Modeling the readability of German targeting adults and children: An empirically broad analysis and its cross-corpus validation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wei?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meurers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA, August. As</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="303" to="317" />
		</imprint>
	</monogr>
	<note>sociation for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Developing a stemmer for german based on a comparative analysis of publicly available stemmers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Weissweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the German Society for Computational Linguistics and Language Technology</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="81" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Problems in current text simplification research: New data can help</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Napoles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="283" to="297" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Optimizing statistical machine translation for text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="401" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi-document summarization by maximizing informative content-words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Suzuki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In IJCAI</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1776" to="1782" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A monolingual tree-based translation model for sentence simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-08" />
			<biblScope unit="page" from="1353" to="1361" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
