<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Shape-aware Multi-Person Pose Estimation from Multi-View Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>Dong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otmar</forename><surname>Hilliges</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>Z?rich</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Shape-aware Multi-Person Pose Estimation from Multi-View Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T19:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we contribute a simple yet effective approach for estimating 3D poses of multiple people from multi-view images. Our proposed coarse-to-fine pipeline first aggregates noisy 2D observations from multiple camera views into 3D space and then associates them into individual instances based on a confidence-aware majority voting technique. The final pose estimates are attained from a novel optimization scheme which links high-confidence multi-view 2D observations and 3D joint candidates. Moreover, a statistical parametric body model such as SMPL is leveraged as a regularizing prior for these 3D joint candidates. Specifically, both 3D poses and SMPL parameters are optimized jointly in an alternating fashion. Here the parametric models help in correcting implausible 3D pose estimates and filling in missing joint detections while updated 3D poses in turn guide obtaining better SMPL estimations. By linking 2D and 3D observations, our method is both accurate and generalizes to different data sources because it better decouples the final 3D pose from the interperson constellation and is more robust to noisy 2D detections. We systematically evaluate our method on public datasets and achieve state-of-the-art performance. The code and video will be available on the project page: https://ait.ethz.ch/projects/2021/multi-human-pose/.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Markerless human motion capture is one of the fundamental problems in computer vision. In recent years much progress has been made in estimating the configuration of the human body in 2D <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b49">50]</ref> and 3D <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b51">52]</ref> from a single RGB image as input. However, if we consider settings in which multiple people are depicted and in particular if these people are interacting with each other at close range, we can expect a multitude of difficulties due to the heavy and complicated occlusions and depth ambiguities. To robustly estimate the poses of such groups, multi-camera setups are indispensable to provide additional observations from different views which can resolve occlusion and provide stereo cues for 3D estimation. <ref type="figure">Figure 1</ref>. Shape-aware multi-person pose estimation: We propose a novel pipeline for robust recovery of 3D poses and shapes of multiple people from a few camera views. A formulation that links 2D and 3D observations and that is regularized via a parametric body model is robust to noisy and missing 2D detections. Articulated poses can even be recovered under heavy occlusion.</p><p>Due to the real-world importance of this problem, several recent approaches have attempted to predict the poses of multiple people, observed from multiple cameras <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b53">54]</ref>. Such methods can loosely be categorized into two groups. The first group formulates the problem as a cross-view matching and association problem <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b53">54]</ref>. For example, Zhang et al. <ref type="bibr" target="#b53">[54]</ref> introduce an optimization formulation that attempts to jointly solve the per-view parsing and cross-view matching problems as an instance of the multicut problem. The formulation is based on an association graph that links joints within and across multiple views. While the formulation is elegant, in practice it requires traversing the dense, cyclic association graph which results in an NP-hard problem. To attain a computationally tractable approach, the authors revert to a greedy heuristic which is sensitive to noisy 2D joint detections and imperfect visual features which limits the accuracy of the method.</p><p>Other methods, such as Tu et al. <ref type="bibr" target="#b45">[46]</ref> combine the features from individual camera views into a 3D voxel space. This volume is then segmented into sub-volumes by a learned person detector. The final 3D human pose configurations are regressed from these sub-volumes. Because the pipeline can be trained end-to-end, high accuracy can be achieved if the training and test distributions are similar. However, owing to the reliance on the volumetric feature representation -which encapsulates the joint distribution of different individuals, their location in 3D space, the camera setup and even the 2D joint detections -learning such a representation requires a vast amount of data. In the absence of a large corpus of annotated multi-people, multi-view data, such methods face generalization issues and are sensitive to distribution shifts (Tab. 4).</p><p>Embracing this challenging problem, we propose a simple yet effective coarse-to-fine pipeline to estimate 3D multi-person poses from multi-view images. Our method combines concepts from both bottom-up and top-down methods. To avoid having to solve the association problem with partial local evidence, we aggregate initial 3D pose proposals in a 3D feature space. Our first insight is that, in pose estimation, the uncertainty associated with the 2D features (i.e., joint detections) can be trusted more than in many other computer vision domains due to semantics. Thus we forgo neural-network based classifiers and propose a simple confidence-aware majority voting technique to obtain initial 3D proposals. We experimentally show that it is more robust to distribution differences in terms of human poses, location of individuals and cameras in space and thus leads to better generalization behavior. This coarse 3D localization step is followed by a refinement step to correct poses and fill in missing joints via an optimization scheme that leverages multi-view constraints directly, where high confidence 2D observations are available, and regularizes the 3D pose via a parametric body model.</p><p>More precisely, the first part of our pipeline consists of triangulating the 3D coordinates of all pairs of 2D detections with the same part label. This is followed by a confidence-aware majority voting technique to cluster the proposals. The technique is based on the insight that if a joint has been seen and predicted accurately (i.e., with high confidence) in several views, then there will be a dense cluster of 3D candidates for that joint and low confidence, isolated candidates can be discarded. Furthermore, we leverage the observation that certain joints, for example, the hip, are detected more reliably than end-effectors and can be used as a heuristic to decide the number and location of individual humans. While simple, experiments (Tab. 1) show that our approach outperforms the SOTA learning-based method <ref type="bibr" target="#b45">[46]</ref> and matching-based method <ref type="bibr" target="#b53">[54]</ref> in terms of the detection performance.</p><p>The second part of our pipeline refines the initial 3D estimates based on a novel 2D-3D objective (Eq.(5)). In our formulation, we optimize the 3D joint locations directly by minimizing the 2D re-projection error if the corresponding 2D joint detections are of high confidence (Eq.(1)). To regularize the fitting procedure and to attain complete and kinematically plausible poses we leverage SMPL for lowconfidence 3D candidates (Eq.(3)). Importantly, the SMPL parameters are aligned directly to the updated 3D observations (current state of the 3D joint locations). For this we use the learned per-parameter gradient method (Eq. <ref type="formula" target="#formula_5">(6)</ref>). This approach is fundamentally different from most existing approaches <ref type="bibr" target="#b3">[4]</ref> that fit SMPL parameters directly to 2D observations. We experimentally show that the triangulated 3D joints are more accurate than the PCA-based SMPL skeleton -if they stem from confident 2D observations ( <ref type="figure" target="#fig_2">Fig. 4</ref>). Both initial 3D pose proposal and SMPL parameters are optimized in an alternating manner (Alg. 1). This is motivated by the insight that a good estimate of 3D poses helps in fitting SMPL, while better SMPL estimates make 3D poses more robust. Finally, detailed experiments are performed to demonstrate that both components improve the robustness and accuracy of the pose estimation task. In summary, our main contributions are:</p><p>? A coarse-to-fine confidence-aware pipeline to aggregate noisy 2D observations from all camera views into 3D space and associate them into individual instances.</p><p>? A novel refinement pipeline which optimizes 3D poses and their corresponding SMPL models in an alternating fashion. The parametric models help in regularizing low-confidence 3D poses while updated 3D poses in turn guide the SMPL parameter estimation.</p><p>? Our method is general since we only leverage off-theshelf 2D pose detector and body pose priors distilled from motion capture datasets. SOTA performance is achieved on public datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>A vast amount of work on single-person 3D pose estimation from monocular <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b46">47]</ref> and multi-view <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b38">39]</ref> images exists. Since we study the setting of multi-person pose estimation from multiple views <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b53">54]</ref>, the focus of this literature review is on multi-person pose estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Person 2D Pose Estimation</head><p>A natural approach to multi-person 2D pose estimation is to detect people first and then estimate the body pose independently. Pishchulin et al. <ref type="bibr" target="#b37">[38]</ref> employs a pictorial structure model to locate the person and subsequently estimate the pose. More recent top-down approaches also follow a similar strategy but instead use CNN-based person detectors and pose estimation models <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b50">51]</ref>.</p><p>In contrast, bottom-up approaches <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43]</ref> begin with localizing identity-free body part proposals and associates them into individual instances. The seminal work by Pishchulin et al. <ref type="bibr" target="#b36">[37]</ref> proposed a framework that jointly labels part candidates and also associates them into individual people. More recently, Cao et al. <ref type="bibr" target="#b4">[5]</ref> introduced a representation of pairwise scores via the so-called Part Affinity Fields (PAF). The authors demonstrated that PAFs are able to provide effective features for the part association that a simple greedy bipartite parse can be directly applied achieving state-of-the-art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Person 3D Pose Estimation</head><p>When only one camera is available, the problem is underdetermined since many 3D poses may correspond to the same 2D pose. Leveraging the learning-based method, 3D poses can be recovered by lifting detected 2D poses <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b54">55]</ref>, or directly regressing 3D poses <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b52">53]</ref>, or by fitting parametric human body models <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b52">53]</ref>. However, the reconstruction accuracy of these methods is limited due to the depth ambiguities and strong occlusions when multiple humans are close to each other.</p><p>Most closely related to ours are methods that leverage multi-view images. A straightforward approach for this problem is to find correspondences across views, either leveraging high-level features such as human instances, or low-level features such as joints. Early work implicitly solves this matching and parsing problem by leveraging 3D pictorial structure models, in which nodes represent 3D locations of body joints and edges encode pairwise relations between them <ref type="bibr" target="#b1">[2]</ref>. However, such methods are computationally expensive due to the large state space in 3D. Joo et al. <ref type="bibr" target="#b22">[23]</ref> rely on local features from dense multi-view images to vote for possible 3D joint positions, which can be seen as an implicit form of matching.</p><p>The method proposed by Dong et al. <ref type="bibr" target="#b9">[10]</ref> first performs per-view person parsing, followed by a cross-view person matching via a convex optimization method constrained by cycle consistency. In <ref type="bibr" target="#b53">[54]</ref>, the authors formulate parsing, matching, and tracking in a unified graph optimization framework to simultaneously address 4D information. In contrast to these matching-based methods, a recent work <ref type="bibr" target="#b45">[46]</ref> directly localizes all people and estimates their corresponding 3D poses in 3D voxel space. Due to the reliance on the 3D feature representation as input for subsequent learning-based steps, this method faces challenges in generalization with different configurations of people, poses and cameras. In our work, we propose a simple yet effective pipeline that triangulates joint candidates and associates them into individual instances via a simple confidence-aware voting scheme. A 2D-3D optimization technique, optimized via learned gradient descent, produces highly accurate 3D pose estimates. We show that this pipeline outperforms both matching-based approaches and end-to-end learning methods. <ref type="figure" target="#fig_0">Fig. 2</ref> provides an overview of our proposed approach, which contains two stages: 3D human proposal generation and shape-aware 3D pose optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>In the first stage, we generate 3D joint candidates by triangulating 2D human pose estimates from different views. Then a confidence-aware voting-based technique is applied to cluster joint candidates from noisy observations and determine human instances. To generate a pose proposal for each human instance, a 3D bounding box is placed around its hip and is projected back to the images. The image observations surrounding the body's limbs are used to filter joint candidates from closely interacting people.</p><p>In the second stage, an energy formulation which includes a multi-view re-projection term E 2d (X) and a 3D body model fitting term E shape (X, ?) is introduced, to refine the initial pose X 0 . Both 3D poses X and SMPL parameters ? are optimized jointly in an alternating manner. For each iteration, the gradient updating network first takes current 3D poses X and SMPL estimation ? as input to guide updating SMPL prediction. Then the current 3D poses X are optimized by minimizing the multi-view re-projection error when they stem from confident 2D observations and the updated SMPL prediction is leveraged for regularizing low-confidence or missing 3D joint candidates. After a small number of iterations, our method can generate complete and accurate 3D human poses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">3D Human Proposal Generation</head><p>One of the main challenges for multi-person pose estimation from multiple views is to associate 2D poses from different views with consistent identities. Prior matching-based work <ref type="bibr" target="#b53">[54]</ref>, is sensitive to imperfect 2D detections due to its local heuristic, and purely learning-based methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b45">46]</ref> are prone to overfitting. In contrast, we propose an effective approach to generate initial 3D pose proposals based on a confidence-aware voting technique, operating in the global 3D space of joint candidates that have been triangulated from pairs of 2D noisy detections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3D Joint Candidates Reconstruction.</head><p>To reconstruct 3D joint candidates, we first run an off-theshelf 2D human pose detector <ref type="bibr" target="#b4">[5]</ref> on each input image to generate 2D joint detections ( <ref type="figure" target="#fig_0">Fig. 2, (a)</ref>). Then pairs of joints with the same label from different views are triangulated into 3D joint candidates ( <ref type="figure" target="#fig_0">Fig. 2, (b)</ref>). We use standard linear algebraic triangulation <ref type="bibr" target="#b14">[15]</ref>, solving the linear system defined on the homogeneous 3D coordinate vector y j : A j?j = 0, where A j ? R (2C,4) is a matrix composed of the components from the projection matrices and 2D poses. In our case, we perform the triangulation from each pair of 2D poses and set C to 2. Candidates Association. The next step is to associate triangulated 3D joint candidates into individual instances. Our insight for the association is simple: since we triangulate pairs of joint detections, joints that are visible in several views produce dense clusters of 3D candidates. Based on this observation, we propose an efficient and effective voting-based algorithm.</p><p>For the set C i of all the 3D joint candidates with part label i, we initialize an empty set S i and update it iteratively. In each iteration, we first find the point p k with the highest confidence in C i . Next, a subset s k ? C i containing all the neighboring 3D candidates around p k with a distance less than threshold ? is selected. We add s k to S i and remove s k from C i . We repeat the above until C i becomes the empty set. Since outliers usually stem from falsely associated 2D detections or wrong detections in one specific view, there will only be few neighboring candidates around them. We thus eliminate clusters with less than three points. For the remaining clusters, we use their center to represent its position in 3D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human Proposal Generation.</head><p>The filtered 3D joint candidates need to be associated with individual instances. We experimentally find that the hip joint is one of the most reliable parts and can be leveraged to robustly decide the number of instances and also the location of each instance. Hence, we simply place a 3D bounding box with fixed size and orientation using the hip candidates as anchors. Furthermore, we keep the anchors whose corresponding 3D bounding box contains more than 90% of body parts and whose average confidences are larger than an empirically derived threshold. These bounding boxes may still contain joints of other closely interacting people. In order to distinguish them, we project the 3D bounding box back to the image space and use the part affinity fields <ref type="bibr" target="#b4">[5]</ref> to determine which 3D joints belong to other person instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Shape-aware 3D Pose Optimization</head><p>The initial pose proposals do not yet adhere to kinematic constraints and may have missing joints due to imperfect 2D joint detections. We refine these initial poses X via both multi-view re-projection evidence E 2d (X) and a parametric body model prior E shape (X, ?). The 3D poses X and SMPL parameters ? are optimized alternatively. The reprojection term aligns 3D joints X with the 2D observations for high-confidence joint detections. Whereas missing or low-confidence joints are determined by leveraging the updated SMPL estimation to regularize the 3D pose, leading to complete and kinematically plausible 3D pose estimates. For SMPL parameters ?, they are optimized to align to the current 3D joints X via a learned gradient updating network. This refinement finally leads to complete and kinematically plausible 3D pose estimates after a small number of iterations. The alternating process is shown in <ref type="figure" target="#fig_0">Fig. 2</ref>, II.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Objectives.</head><p>Given an initial 3D pose proposal X and its corresponding 2D observations x ij , where i ? (1 . . . N ) stands for the joint label and j ? (1 . . . K) represents the view indices, we want to refine the 3D pose by leveraging multi-view constraints where the 2D observations have high confidence:</p><formula xml:id="formula_0">E 2D (X) = N i=1 K j=1 w ij ? ij d 2D (? j X i , x ij )<label>(1)</label></formula><p>Here E 2D (X) denotes the re-projection error between the 2D joint projections into each view and the detected 2D joints. ? j is the projection matrix of view j. w ij is the confidence of detected joint i in the view j and ? ij is an indicator function denoting if joint i in view j is discarded:</p><formula xml:id="formula_1">? ij = 1, d 2D (? j X i , x ij ) &lt; ? 2D 0, otherwise<label>(2)</label></formula><p>where ? 2D is a threshold for selecting inliers.</p><p>To complement E 2D we leverage a body shape term E shape to regularize the 3D pose via a parametric body model when 2D detections are missing or have low associated confidence. For this purpose, we use the SMPL model <ref type="bibr" target="#b28">[29]</ref>. It is a differentiable function that outputs a triangulated mesh M (?, ?) taking the pose parameters ? ? R 23?3 and the shape parameters ? ? R 10 as input. The 3D body joints can be obtained by a linear regressor W taking the mesh as input (X(?, ?) = W (M (?, ?))). We jointly optimize predicted 3D poses X and SMPL parameters ?, ?:</p><formula xml:id="formula_2">E shape (X, ?, ?) = N i=1 ?(w i )d 3D (X i ,X i (?, ?))<label>(3)</label></formula><p>where w i is the average confidence of detected 2D joint i across views. ?(w i ) is an indicator function denoting whether the initial 3D joints i has high enough confidence:</p><formula xml:id="formula_3">?(w i ) = 1, w i &lt; ? 3D 0, otherwise<label>(4)</label></formula><p>The final energy is the weighted sum of Eq. <ref type="formula" target="#formula_0">(1)</ref> and <ref type="formula" target="#formula_2">(3)</ref>:</p><formula xml:id="formula_4">E(X, ?, ?) = w 2D E 2D (X)+w shape E shape (X, ?, ?). (5) Algorithm 1 -Alternative Optimization X 0 ? initial 3D pose proposal ? 0 ? {? 0 , ? 0 } ? 0 for n = 0, ..., N ? 1 do ? (0) ? ? n for m = 0, ..., M ? 1 do L shape (? (m) ) ? E shape (X n , ? (m) ) ?? (m) ? N w ( ?L shape (? (m) ?? (m) , ? (m) , X n ) ? (m+1) ? ? (m) + ?? (m) end for ? n+1 ? ? (M ) L(X n ) ? w 2d E 2d (X n ) + w shape E shape (X n , ? n+1 ) X n+1 = X n + ? ?L(Xn) ?Xn end for</formula><p>Alternating Optimization. To optimize Eq. (5) we employ a custom gradient descent strategy. We start by fixing X to its initial value and optimize ?, ?. Since fitting SMPL parameters to 3D observations is a non-convex and highly non-linear problem, this can be slow and error-prone with traditional methods such as that by Bogo et al. <ref type="bibr" target="#b3">[4]</ref>. We take inspiration from a recent 2D-3D lifting approach <ref type="bibr" target="#b43">[44]</ref> that solves the fitting of 3D human body by leveraging a neural network to predict the parameter update rule. We adopt a similar concept for fitting the human model to the 3D candidates. To accelerate fitting of ? = {?, ?} we replace the standard gradient descent rule by a learned per-parameter update:</p><formula xml:id="formula_5">? (m+1) = ? (m) + N w ( ?E shape ?? (m) , ? (m) , X)<label>(6)</label></formula><p>where N w is a deep network parameterized by a set of weights w, ?E shape ?? (m) is the partial derivative wrt ? and X is the fitting target. N w is trained with samples of poses and shapes from AMASS <ref type="bibr" target="#b29">[30]</ref>. Please refer to <ref type="bibr" target="#b43">[44]</ref> and supplementary for more details of the training process.</p><p>Once ? is optimized, we keep it fixed and optimize X via standard gradient descent. We optimize X, ? in an alternating fashion until convergence. The overall routine is detailed as pseudo-code in Alg. 1, where n is the iteration index for the overall optimization routine while m is for the body fitting process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Test Datasets</head><p>We conduct experiments on two standard datasets for multi-view multi-person 3D human pose estimation, which consist of challenging scenarios including interactions between individuals with heavy occlusions. Shelf <ref type="bibr" target="#b0">[1]</ref> contains 3200 frames from 5 cameras. In terms of evaluation setting and evaluation metric, we follow prior work <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b53">54]</ref> and test on a separate test set and report the percentage of correctly estimated parts (PCP@0.5) to measure performance. Association Dataset <ref type="bibr" target="#b53">[54]</ref> is one of the most challenging public datasets for this task. It contains 3 sequences with 2-4 closely interacting people observed from 6 cameras. Following <ref type="bibr" target="#b53">[54]</ref>, we use all the sequences for test and report the precision, recall and F1-score as evaluation metrics. A joint is considered correct if its Euclidean distance to the ground truth annotation is less than 0.2m.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Training Data Comparison</head><p>For training, our method only uses AMASS, a collection of 3D human bodies with varying poses <ref type="bibr" target="#b29">[30]</ref>. For clarity, we would like to emphasize that our primary goal is to boost the robustness and effectiveness to new, entirely unseen humans and poses. Note that, learning-based methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b45">46]</ref> generally require direct 3D supervision via annotated pairs of multi-people, multi-view data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>To validate the effectiveness of our method, we conduct a detailed analysis on both the initial 3D pose proposal and the shape-aware pose refinement. All the experiments are conducted on the Association dataset. When comparing with the learning-based method <ref type="bibr" target="#b45">[46]</ref>, we deploy its model trained on the CMU Panoptic Dataset <ref type="bibr" target="#b21">[22]</ref>, which is the largest training dataset for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Evaluation of 3D Human Proposal Generation</head><p>To evaluate the effectiveness of our human proposal generation technique, we compare our method with two SOTA methods <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b53">54]</ref>. Following the metric of <ref type="bibr" target="#b53">[54]</ref>, one human proposal is valid if the error of its hip joint is less than 0.2m. As shown in Tab. 1, our method achieves significantly better performance compared to <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b53">54]</ref>. The learning-based method <ref type="bibr" target="#b45">[46]</ref> faces generalization issues to unseen human poses and motion. The bottom-up method <ref type="bibr" target="#b53">[54]</ref> suffers from low recall since the greedy algorithm is sensitive to noisy 2D joint detections. More ablation study on the proposal generation can be found in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Precision(%) Recall(%) F1-score(%) VoxelPose <ref type="bibr" target="#b45">[46]</ref> 68  <ref type="table">Table 1</ref>. Evaluation of human proposal generation on the Association Dataset. A human proposal is valid if the error of its hip joint is less than 0.2m. Ours achieves better performance compared to other SOTA ones especially for recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Evaluation of Shape-aware Pose Optimization</head><p>In this section, we validate the effectiveness of our shapeaware optimization. As seen in the last two rows in Tab. 4, the initial pose proposal can be dramatically improved under all metrics by leveraging multi-view constraints and regularization with the parametric body model. There are two main reasons for this improvement. First, the full-body constraint of SMPL can infill missing joints and corrects implausible poses (see orange and purple circles in <ref type="figure" target="#fig_1">Fig. 3</ref>). Furthermore, the weighted re-projection error contributes to refine the joint predictions, shown in blue circles in <ref type="figure" target="#fig_1">Fig. 3</ref>. Human Body Constraint. Note that the SMPL model is used as a full-body constraint to help infill missing joints and also to correct non-kinematic poses. We conduct the experiment to fit SMPL model to the initial 3D proposal and draw the MPJPEs of the joints before and after fitting in <ref type="figure" target="#fig_2">Fig. 4</ref>. For joints with associated low average confidence, regularizing the 3D pose via a parametric body model can boost performance. For joints with higher confidence (confidence&gt;0.25), the effect of full-body constraint is not obvious. This is caused by a slight difference in the skeletal configurations between <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b28">[29]</ref>, which causes some systematic error. Therefore we only use the multiview constraints to optimize high-confidence joints as described in the method section. Comparison with SMPL-only. We compare our method with approaches that optimize only SMPL parameters to align the joint re-projections with 2D observations <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b18">19]</ref>. For a fair comparison, we apply a multi-view variant of SM-PLify. The comparison on the Association dataset is summarized in Tab. 2. Our method outperforms the SMPL-only baseline by a significant margin. This is in part due to the inherent approximation error stemming from differences in the skeletal configurations between <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b28">[29]</ref> in part due to fitting errors. This experimental evidence is an important motivation for the design of our 3D pose fitting formulation. Furthermore, leveraging learned gradient descent for optimization leads to significant performance increases both in terms of runtime (20x speed-up, 0.1s vs 2s), convergence rate (14 vs 100 iters) and precision (90.1% vs 78.3%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Quantitative Results</head><p>We compare our method with SOTA methods quantitatively on the Shelf and Association datasets. The compar-     model for test. As a result, our method outperforms this learning-based method largely, even when they use ground truth 3D bounding boxes. This shows that the learningbased method is prone to overfit to the training distribution. We also compare our algorithm with matching-based methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b53">54]</ref>. Note that to have a fair comparison with <ref type="bibr" target="#b53">[54]</ref>, we compare with its static version only relying on images while it is originally a tracking method which leverages video information. We can see that these bottom-up based methods have relatively low recall due to the fact that they solve the global optimization with a greedy algorithm which is sensitive to missing 2D joint detections. Each row is an independent sample and the results are the projected 2D poses from the 3D predictions. Our method is more accurate compared to others especially in challenging scenarios with strong occlusions or highly articulated poses. <ref type="figure">Figure 6</ref>. Results of our method on (a) Association Dataset(6 views) and (b) Shelf (5 views). The 2D reprojections of predicted 3D skeletons and SMPL mesh model are shown in two different views (left and middle); Skeletons and SMPL models of all the actors in 3D are demonstrated in the right column. More results can be found in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Qualitative Comparison</head><p>We show qualitative comparison in <ref type="figure" target="#fig_3">Fig. 5</ref>. Generally, our method is more accurate and robust compared to others especially in challenging scenarios with strong occlusions or when highly articulated poses are presented. Specifically, other methods tend to generate extra actors (red rectangles), abnormal (purple circles) or incorrect (blue circles) human poses. The reason is that it is difficult for the learning-based method <ref type="bibr" target="#b45">[46]</ref> to generalize to unseen poses and motions. For the image-based version of <ref type="bibr" target="#b53">[54]</ref>, without temporal information, solving the 3D association graph is sensitive to noisy 2D joint detections. In <ref type="figure">Fig. 6</ref>, we demonstrate more results of our method on both the Association and Shelf datasets. The first row is the predicted 3D poses and their projections on two views. The second row shows the predicted SMPL models in 3D space and also their projections in 2D images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose an effective coarse-to-fine pipeline to estimate 3D multi-person poses from multi-view images. To avoid having to solve the association problem with local evidence, we aggregate initial 3D pose proposals in a 3D feature space and associate them into individual instances. This coarse 3D localization step is followed by a refinement step that corrects poses and fills in missing joints via an optimization routine leveraging multi-view constraints directly where high confidence 2D observations are available and regularizing the 3D pose via a parametric body model. We systematically evaluate our method on public datasets and SOTA performance is achieved.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Pipeline structure. Stage I: (a): We apply a 2D human pose estimation method<ref type="bibr" target="#b4">[5]</ref> to obtain 2D joint candidates. (b): 2D candidate pairs with the same part label are triangulated into 3D space to produce 3D joint candidates. (c): A confidence-aware votingbased algorithm is used for clustering joint candidates from partial observations. (d): The position of human instances can be detected based on a reliable joint. (e): For each 3D human proposal, we project it back into the image space and leverage the part affinity field feature (PAF<ref type="bibr" target="#b4">[5]</ref>) to filter the joint candidates from closely interacting people and obtain initial 3D pose proposals. Stage II: We refine the initial 3D poses X0 by optimizing a 2D-3D objective. Both 3D poses X and SMPL parameters ? are optimized alternatively. For each iteration, the 3D joint locations X are optimized by a 2D re-projection error when the corresponding 2D joint detections are of high confidence. To obtain kinematically plausible poses, we leverage updated SMPL estimation for regularizing the low-confidence 3D joint candidates. The SMPL parameters ? are encouraged to align to the updated 3D poses in each iteration via a learned gradient updating network. After a small number of iteration, our method can generate complete and accurate 3D human poses and output SMPL parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Comparison between our initial poses and final poses after optimization. (a) The orange circle is set for missing joints (note that we set the missing joints to the origin point) (b) The blue circle is set for incorrect joint predictions;(c) The purple circle is set for abnormal human poses. After the shape-aware optimization, our method generates more complete and accurate 3D human poses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Comparison of MPJPE (m) between our initial proposals (init) and the predicted poses after regularizing with SMPL (after smpl). The horizontal axis represents the associated confidence of the 3D joints from the initial proposal. When the confidence is under 0.25, our algorithm achieves better performance after regularizing the 3D pose via a parametric body model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Qualitative comparison with VoxelPose [46] and Zhang et al. [54] on the Association Dataset. Different colors stand for different types of errors: red rectangles for extra actors; blue circles for incorrect joint positions; purple circles for abnormal human poses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Comparison between our method and the traditional method<ref type="bibr" target="#b3">[4]</ref> Our method outperforms the SMPL-only baseline for both precision and recall. ison on the Shelf is shown in Tab. 3. We achieve slightly better results compared to methods<ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b53">54]</ref> which do not rely on 3D supervision and achieve comparable performance compared to learning-based methods<ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b45">46]</ref> which train the model based on this dataset. Since the test frames lack pose variations compared to the training set, this dataset is considered less challenging than the Association one, which also has a more strict evaluation metric.The quantitative result on the Association dataset is shown in Tab. 4. Since this is a pure test set, for SOTA learning-based method<ref type="bibr" target="#b45">[46]</ref>, we directly deploy their trained</figDesc><table><row><cell>Method</cell><cell>Anno</cell><cell>A1</cell><cell>A2</cell><cell>A3</cell><cell>Avg</cell></row><row><cell>VoxelPose [46]</cell><cell>Yes</cell><cell cols="3">99.3 94.1 97.6</cell><cell>97.0</cell></row><row><cell>Huang et al. [18]</cell><cell>Yes</cell><cell cols="3">98.8 96.2 97.2</cell><cell>97.3</cell></row><row><cell>Belagiannis et al. [1]</cell><cell>No</cell><cell cols="3">66.1 65.0 83.2</cell><cell>71.4</cell></row><row><cell>Belagiannis et al. [2]</cell><cell>No</cell><cell cols="3">75.3 69.7 87.6</cell><cell>77.5</cell></row><row><cell>Ershadi-Nasab et al. [12]</cell><cell>No</cell><cell cols="3">93.3 75.9 94.8</cell><cell>88.0</cell></row><row><cell>*Zhang et al. [54]</cell><cell>No</cell><cell cols="3">96.5 86.8 97.0</cell><cell>93.4</cell></row><row><cell>Dong et al. [10]</cell><cell>No</cell><cell cols="4">98.6 93.7 97.8 96.7(96.9)</cell></row><row><cell>Ours(final)</cell><cell>No</cell><cell>99.1</cell><cell>93.5</cell><cell>98.1</cell><cell>96.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .Table 4 .</head><label>34</label><figDesc>Evaluation on Shelf dataset. Quantitative comparison on the Shelf dataset using a percentage of correct parts (PCP) metric. '*' denotes that the method discards temporal information from its original setting. 'A1'-'A3' correspond to the results of three actors, respectively. The averaged result is in column 'Avg'. The column 'Anno' indicates if the method relies on 3D supervision. Evaluation on the Association Dataset. '*' denotes that the method discards temporal information from its original setting. ' ?' means the method uses 3D bounding box ground truth.</figDesc><table><row><cell>Method</cell><cell cols="2">Precision(%) Recall(%)</cell><cell>F1-score(%)</cell></row><row><cell>VoxelPose [46]</cell><cell>55.1</cell><cell>66.5</cell><cell>60.3</cell></row><row><cell>*Zhang et al. [54]</cell><cell>97.1</cell><cell>48.8</cell><cell>65.0</cell></row><row><cell>?VoxelPose [46]</cell><cell>68.8</cell><cell>79.2</cell><cell>73.6</cell></row><row><cell>Dong et al. [10]</cell><cell>71.0</cell><cell>80.2</cell><cell>75.3</cell></row><row><cell>Ours(init)</cell><cell>83.7</cell><cell>82.8</cell><cell>83.4</cell></row><row><cell>Ours(final)</cell><cell>90.1</cell><cell>89.0</cell><cell>89.2</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements: Xu Chen was supported by the Max Planck ETH Center for Learning Systems.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bernt Schiele, Nassir Navab, and Slobodan Ilic. 3d pictorial structures for multiple human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sikandar</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1669" to="1676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bernt Schiele, Nassir Navab, and Slobodan Ilic. 3d pictorial structures revisited: Multiple human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sikandar</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1929" to="1942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pandanet: Anchor-based single-shot multi-person 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdallah</forename><surname>Benzine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Chabot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><surname>Luvison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuong</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Achard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6856" to="6865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Keep it smpl: Automatic estimation of 3d human pose and shape from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="561" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Openpose: realtime multi-person 2d pose estimation using part affinity fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gines</forename><surname>Hidalgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-En</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.08008</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Multi-person 3d pose estimation in crowded scenes based on multi-view geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hee</forename><surname>Gim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chirikjian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.10986</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Higherhrnet: Scale-aware representation learning for bottom-up human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5386" to="5395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Markerless motion capture through visual hull, articulated icp and subject specific model generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Corazza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>M?ndermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiliano</forename><surname>Gambaretto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giancarlo</forename><surname>Ferrigno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">P</forename><surname>Andriacchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page">156</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Performance capture from sparse multi-view video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Edilson De Aguiar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stoll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveed</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2008 papers</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast and robust multi-person 3d pose estimation from multiple views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junting</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hujun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7792" to="7801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Chris Bregler, Bernt Schiele, and Christian Theobalt. Efficient convnet-based marker-less motion capture in general scenes with a low number of cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Elhayek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Edilson De Aguiar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andriluka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3810" to="3818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Ershadi-Nasab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erfan</forename><surname>Noury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shohreh</forename><surname>Kasaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esmaeil</forename><surname>Sanaei</surname></persName>
		</author>
		<title level="m">Multiple human 3d pose estimation from multiview images. Multimedia Tools and Applications</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="15573" to="15601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Compressed volumetric heatmaps for multi-person 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Fabbri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Lanzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Calderara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Alletto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7204" to="7213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">RMPE: Regional multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuqin</forename><surname>Hao-Shu Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Multiple view geometry in computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Epipolar transformer for multi-view human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katerina</forename><surname>Fragkiadaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoou-I</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1036" to="1037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">End-to-end dynamic matching network for multiview multi-person 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congzhentao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Traish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard Yi Da</forename><surname>Xu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Towards accurate marker-less human shape and pose estimation over time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ijaz</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 international conference on 3D vision (3DV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="421" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learnable triangulation of human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karim</forename><surname>Iskakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Egor</forename><surname>Burkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yury</forename><surname>Malkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7718" to="7727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Coherent reconstruction of multiple humans from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5579" to="5588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Panoptic studio: A massively multiview system for social motion capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Nabbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shohei</forename><surname>Nobuhara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3334" to="3342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Panoptic studio: A massively multiview system for social interaction capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xulong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Godisart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Nabbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Matthews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="190" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Total capture: A 3d deformation model for tracking faces, hands, and bodies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8320" to="8329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">End-to-end recovery of human shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7122" to="7131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Markerless tracking of complex human motions from multiple views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="190" to="209" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Crowdpose: Efficient crowded scenes pose estimation and a new benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiefeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihuan</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao-Shu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10863" to="10872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Markerless motion capture of multiple characters using multiview image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yebin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Stoll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qionghai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2720" to="2735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Smpl: A skinned multiperson linear model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM transactions on graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Amass: Archive of motion capture as surface shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nikolaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Troje</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5442" to="5451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A simple yet effective baseline for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julieta</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayat</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2640" to="2649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Vnect: Real-time 3d human pose estimation with a single rgb camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Shafiei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Associative embedding: End-to-end learning for joint detection and grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05424</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="483" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Personlab: Person pose estimation and instance segmentation with a bottom-up, part-based, geometric embedding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="269" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Harvesting multiple views for marker-less 3d human pose annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konstantinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6988" to="6997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Deepcut: Joint subset partition and labeling for multi person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eldar</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06645</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Articulated people detection and pose estimation: Reshaping the future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Thorm?hlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3178" to="3185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Cross view fusion for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibo</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4342" to="4351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Lightweight multi-view 3d pose estimation through camera-disentangled representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edoardo</forename><surname>Remelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shangchen</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sina</forename><surname>Honari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6040" to="6049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Lcr-net: Localization-classification-regression for human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Rogez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3433" to="3441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Lcr-net++: Multi-person 2d and 3d pose detection in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Rogez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1146" to="1161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">End-to-end learning for graph decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otmar</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10093" to="10102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Human body model fitting by learned gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otmar</forename><surname>Hilliges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="744" to="760" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XX 16</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Thin-slicing network: A deep structured model for pose estimation in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otmar</forename><surname>Hilliges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4220" to="4229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Voxelpose: Towards multi-camera 3d human pose estimation in wild environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanyue</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Articulated mesh animation from multi-view silhouettes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Vlasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Baran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Matusik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jovan</forename><surname>Popovi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2008 papers</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Hmor: Hierarchical multi-person ordinal relations for monocular multi-person 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiefeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="242" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Deep high-resolution representation learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaorui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Convolutional pose machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shih-En</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Ramakrishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4724" to="4732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Convolutional pose machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shih-En</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Ramakrishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4724" to="4732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Monocular 3d pose and shape estimation of multiple people in natural scenes-the importance of multiple scene constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabeta</forename><surname>Marinoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2148" to="2157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deep network for the integrated 3d sensing of multiple people in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabeta</forename><surname>Marinoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alin-Ionut</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="8410" to="8419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">4d association graph for realtime multi-person motion capture using multiple video cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yebin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1324" to="1333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Smap: Single-shot multiperson absolute 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hujun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="550" to="566" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
