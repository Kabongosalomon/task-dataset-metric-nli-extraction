<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Feature Generation for Long-tail Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021">2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Acm Reference Format: Rahul</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><forename type="middle">T</forename><surname>Vigneswaran</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Law</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vineeth</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makarand</forename><forename type="middle">N</forename><surname>Balasubramanian</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tapaswi</surname></persName>
						</author>
						<title level="a" type="main">Feature Generation for Long-tail Classification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of 12th Indian Conference on Computer Vision, Graphics and Image Processing</title>
						<meeting>12th Indian Conference on Computer Vision, Graphics and Image Processing						</meeting>
						<imprint>
							<date type="published" when="2021">2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3490035.3490300</idno>
					<note>(ICVGIP&apos;21). ACM, New York, NY, USA, Article 43, 9 pages. https://doi.org/ 10.1145/3490035.3490300</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Long-tail classification, Feature generation</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The visual world naturally exhibits an imbalance in the number of object or scene instances resulting in a long-tailed distribution. This imbalance poses significant challenges for classification models based on deep learning. Oversampling instances of the tail classes attempts to solve this imbalance. However, the limited visual diversity results in a network with poor representation ability. A simple counter to this is decoupling the representation and classifier networks and using oversampling only to train the classifier.</p><p>In this paper, instead of repeatedly re-sampling the same image (and thereby features), we explore a direction that attempts to generate meaningful features by estimating the tail category's distribution. Inspired by ideas from recent work on few-shot learning [53], we create calibrated distributions to sample additional features that are subsequently used to train the classifier. Through several experiments on the CIFAR-100-LT (long-tail) dataset with varying imbalance factors and on mini-ImageNet-LT (long-tail), we show the efficacy of our approach and establish a new state-ofthe-art. We also present a qualitative analysis of generated features using t-SNE visualizations and analyze the nearest neighbors used to calibrate the tail class distributions. Our code is available at https://github.com/rahulvigneswaran/TailCalibX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Computing methodologies ? Supervised learning by classification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Modern machine learning is driven by large scale datasets, employed in both supervised <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36]</ref> and self-supervised <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b39">39]</ref> scenarios. However, creation of these labeled datasets is a challenging and costly affair <ref type="bibr" target="#b0">[1]</ref> and may also lead to unforeseen biases <ref type="bibr" target="#b41">[41]</ref>. Often, these datasets are created by querying images through a search engine <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b35">36]</ref>, followed by post-processing and Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). ICVGIP <ref type="bibr">'</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Before generation</head><p>After generation <ref type="figure">Figure 1</ref>: Long-tail distributions consist of few categories with many samples (head of the long tail, in red) and many categories with few to very-few samples (green, blue). Due to the larger diversity of the head classes, decision boundaries are often favourable for the head class, while being errorprone for the tail classes. The goal of our work is to generate meaningful additional features for the tail classes so that a balanced training set is created for the classifier. To this end, we estimate the distribution of the tail classes based on individualized instances and sample additional features through this calibrated tail distribution.</p><p>"cleaning" to ensure a balanced distribution that has an (approximately) equal number of instances for each category. However, the world we live in is naturally long-tail, and like the language modality, even visual data follows the Zipf's law <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b57">57]</ref>. This is easily illustrated through examples we encounter in our daily lives: people living in a city are more likely to see multiple instances and a large diversity of cars than elephants for transportation, and tables and chairs than tree stumps as furniture. This natural distribution of categories is reflected in the datasets that are collected through community efforts, e.g. iNaturalist <ref type="bibr" target="#b44">[44]</ref> that features a large image collection of biodiversity; or annotations for a collection of randomly sampled raw data -action labels from the Atomic Visual Actions dataset <ref type="bibr" target="#b12">[13]</ref>; or interaction and relationship labels from movie datasets <ref type="bibr" target="#b46">[46]</ref>.</p><p>Modern deep learning methods perform well on balanced distributions and have even shown super-human performance for some datasets and tasks in diverse domains including image classification <ref type="bibr" target="#b13">[14]</ref> and language understanding <ref type="bibr" target="#b48">[48]</ref>. This has led to a steadily growing interest in adapting methods to work well with few training samplesfew-shot learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b51">51]</ref> or naturally occurring long-tail distributions <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b56">56]</ref>. Interestingly, it is observed that popular techniques used in shallow learning (e.g. SVMs) such as loss re-weighting or balanced sampling <ref type="bibr" target="#b18">[19]</ref> do not perform well when they are applied with deep neural networks, as they may hurt the representation learning <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b56">56]</ref>. Instead, decoupling the feature learning (i.e. CNN backbone) from the classifier (i.e. final linear layers) is found to be necessary and useful <ref type="bibr" target="#b19">[20]</ref>.</p><p>In this work, we are interested in answering the following question. Can we learn to generate feature representations for the impoverished tail classes, instead of requiring re-weighting (e.g. <ref type="bibr" target="#b56">[56]</ref>) or multi-network distillation (e.g. <ref type="bibr" target="#b16">[17]</ref>) strategies? Inspired by the recent success of distribution calibration on few-shot learning <ref type="bibr" target="#b53">[53]</ref>, we estimate and calibrate the feature distribution of tail classes to sample additional features that are in turn used to train a classifier -we term this as TailCalibration (see <ref type="figure">Fig. 1</ref>). Note that our work is different from <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b20">21</ref>] that attempt to reconstruct or generate images for the tail class; or from <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b54">54]</ref> that use convex combinations of input samples or features and their labels. TailCalibration is agnostic to the training approach of the backbone, and therefore, adopting better classification setups (e.g. CosineCE <ref type="bibr" target="#b27">[28]</ref>) or using distillation (e.g. CBD <ref type="bibr" target="#b16">[17]</ref>) can further improve overall performance.</p><p>Our contribution can be summarized as follows: We explore feature generation as a means to address the challenges of long-tail classification, and show that TailCalibration, an adapted version of <ref type="bibr" target="#b53">[53]</ref>, is an effective strategy to generate meaningful additional features (Sec. 3). We empirically validate our approach through multiple ablation studies on the CIFAR-100-LT achieving the stateof-the-art performance (Sec. 4). Our analysis also holds for a longtailed version of a similarly sized dataset called mini-ImageNet-LT <ref type="bibr" target="#b47">[47]</ref> that had been introduced for few-shot learning. We also present a qualitative analysis of generated features using t-SNE visualizations and analyze the category-level nearest neighbors used to calibrate the tail class distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We discuss and contrast related work on long-tail classification with our proposed approach. While imbalanced learning has had a long history, we focus primarily on modern techniques applied to deep learning. In general, we can group related works in 4 broad categories: (i) modifications to the loss function or re-weighting of samples; (ii) decoupling the learning process of the representation and classifier; (iii) using distillation or multiple experts; and (iv) perhaps closest to our work, ideas related to sample or feature generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Re-weighting or Adapting the Loss Function</head><p>Class re-weighting or balanced sampling are popular approaches to deal with long-tail datasets especially in shallow architectures <ref type="bibr" target="#b18">[19]</ref>. However, with deep learning, as the same loss function trains both the representation network and the classifier, the above ideas are not directly applicable. The cross-entropy (CE) loss is modified to down-weight easier examples while focusing on harder ones <ref type="bibr" target="#b23">[24]</ref>, or to include the effective number of training samples via a re-weighting term <ref type="bibr" target="#b7">[8]</ref>.</p><p>As an alternative to CE, there has also been work on deriving a class-specific margin parameter to be inversely proportional to the fourth root of number of samples for a margin-based loss <ref type="bibr" target="#b2">[3]</ref>. Long-tail classification and label corruption are also attempted simultaneously through meta-learning networks for re-weighting instances <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b38">38]</ref>. Recently, a simple logit adjustment that can be applied post-hoc to trained models <ref type="bibr" target="#b29">[30]</ref> is proposed as a means to unify many of the above approaches.</p><p>A few different perspectives applied to long-tail classification include viewing it as a domain adaptation task (target shift) <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref>, or as a causal framework where stochastic gradient descent's momentum term is treated as a confounder <ref type="bibr" target="#b40">[40]</ref>.</p><p>Our work does not belong to this category and can be thought of as orthogonal to any of the techniques above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Decoupling Representation and Classifier</head><p>One of the key challenges of deep learning on long-tail datasets is exposed by <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b56">56]</ref>. Both works demonstrate that (i) representation learning suffers when applying balancing or re-weighting techniques on end-to-end training paradigms, and (ii) classifier performance of tail classes is adversely impacted when using standard instance sampling. As remedies, a two stage approach is suggested. In the first stage, usual end-to-end training is performed using instance sampling. In the second stage, the classifier is decoupled from the network and is trained with balanced sampling <ref type="bibr" target="#b19">[20]</ref>. While this two-stage strategy improves the performance, <ref type="bibr" target="#b55">[55]</ref> discovers that this may lead to domain shift between the representation and the classifier parts when seen from the perspective of transfer learning and proposes MiSLAS -a batch normalization based trick to resolve this. On similar lines, a dual network with shared backbone is proposed by <ref type="bibr" target="#b56">[56]</ref> with an adaptive trade-off parameter that balances the two objectives.</p><p>Our work is related to the above -we also decouple the training of the backbone from the classifier. The key difference is that instead of balanced sampling, we attempt to generate meaningful features for the tail classes that are subsequently used to train the classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Distilling Information across Networks</head><p>An alternative approach to long-tail classification is using (multiple) teachers to distill information into a student network. One idea here involves learning separate classifiers for sets of categories such that the segregated imbalance factor is reduced before combining them <ref type="bibr" target="#b52">[52]</ref>. Along those lines, RIDE <ref type="bibr" target="#b50">[50]</ref> trains multiple experts with shared earlier layers and routes the inference through a subset of trained experts to improve tail class performance. These subset of experts can be self-distilled from the a larger subset of experts for further improvement. An alternative idea considers an ensemble of teachers trained on instance sampling that are used to uphold the quality of the representation network while training the student on a balanced sampling schedule <ref type="bibr" target="#b16">[17]</ref>.</p><p>Our strategy is orthogonal to this approach and we show that applying TailCalibration on the distilled model from <ref type="bibr" target="#b16">[17]</ref> further improves performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Instance or Feature Generation</head><p>The final set of approaches address the challenges of long-tail classification through generation or augmentation of samples or features. Among sample generation, SMOTE <ref type="bibr" target="#b4">[5]</ref> is an old but popular choice that generates new instances through interpolation between samples of the same (often, the tail) class. Parallel to our work, SMOTE has been extended to deep learning where an encoder-decoder framework is used to generate additional images, DeepSMOTE <ref type="bibr" target="#b8">[9]</ref>. Similar to SMOTE, mixup is a general supervised learning paradigm that allows models to learn from convex combinations of not only input samples, but also their labels <ref type="bibr" target="#b54">[54]</ref>. Specifically designed for visual long-tail classification, M2m translation transfers the diversity of samples from the head class to the tail through gradient updates, resulting in minor visual transformations that lead to significant impact on classification scores <ref type="bibr" target="#b20">[21]</ref>. Similar to M2m, <ref type="bibr" target="#b6">[7]</ref> explicitly models class-specific and class-generic features which are then mixed together to transfer the sample diversity from the head class to the tail.</p><p>While mixup is applied on the input space, manifold mixup is applied on the semantic (feature) space <ref type="bibr" target="#b45">[45]</ref> and is effective at generating convex feature combinations. Specific data augmentation strategies relevant for long-tail classification transfer the implicit knowledge of features from the head classes that exhibit a high variance, to the tail classes that lack intra-class diversity <ref type="bibr" target="#b24">[25]</ref>. This is done by constructing a feature cloud around the existing tail data points to match the head class variance. A recent work MODALS <ref type="bibr" target="#b5">[6]</ref> suggests multiple modality agnostic feature augmentation strategies based on hard example interpolation, extrapolation, and Gaussian noise around the samples.</p><p>Our work is related to these ideas, but differs in the actual method for feature generation. By calibrating distributions we expect to learn from the diversity of head classes and generate features for tail classes to balance the inputs seen by the classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>We present details of our proposed method, TailCalibration, that generates additional features for the tail classes. We start by formulating the long-tail classification task through some notation and a discussion of multiple strategies to train the backbone network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>We address class supervised classification on a training dataset D = {(x , )} =1 with samples. x represents the th image and y is the one-hot encoding of the category label ? {1, . . . , }. For simplicity, we denote the set of samples belonging to category by D , and denote its cardinality by = |D |. A long-tail setup can be defined by ordering the number of samples per category, i.e. 1 ? 2 ? . . . ? (without loss of generality), such that = . The imbalance factor of the dataset is indicated as the ratio of samples in the head to tail class, 1 / , where a higher imbalance often translates to worse performance on the tail categories.</p><p>We train a network ? consisting of two components: (i) a backbone or representation network (CNN for images) that translates an image to a feature representation (x ) = z where z ? R , and (ii) a classifier W ? R ? that predicts the category specific scores (logits) (z ) = s . When not specified otherwise, we assume s = (z ) = Wz . We ignore writing the bias term of the linear layer for brevity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training the Backbone</head><p>Our approach on generating features is independent from the manner in which the representation network is trained. Below, we present three ways of obtaining a trained backbone network .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CE.</head><p>We consider a batch-wise training approach with instance sampling, where each sample x has equal probability of being considered as part of a mini-batch B. Specifically, the parameters of the backbone and the classifier are trained end-to-end using the cross-entropy (CE) loss:</p><formula xml:id="formula_0">= ? ?? y log(p ) ,<label>(1)</label></formula><p>where p is a vector of probabilities obtained by transforming the logits s through the softmax operation.</p><p>CosineCE. As an alternative to the standard dot-product classifier, a cosine normalization based classifier is proposed to reduce the variance of the output neuron <ref type="bibr" target="#b27">[28]</ref>. The key difference lies in the computation of the dot product -the feature vector z and each row (category ) of the classifier, w , are ? 2 -normalized prior to computing the dot product. The logit score for sample x and category is computed as follows:</p><formula xml:id="formula_1">CosCE = z ? w ?z ? 2 ?w ? 2 where z = (x ),<label>(2)</label></formula><p>where ? R + is a positive normalization constant that ensures that CosCE ? [? , ]. We treat as a learnable parameter and use the softplus operator to ensure that it remains positive. We recall that the operator is defined as ? ? R, softplus( ) = log(1 + ). The loss function used to train the model remains unchanged from the above Eq. <ref type="formula" target="#formula_0">(1)</ref>. This formulation has also been adopted by recent works on fewshot learning <ref type="bibr" target="#b11">[12]</ref> and long-tail classification <ref type="bibr" target="#b16">[17]</ref>. In particular, the cosine similarity based score computation embeds all samples close to a single point on the hypersphere (i.e. a ( ?1)-sphere embedded in R ) indicated by the classifier vector. We believe that this makes the distribution of features on the hypersphere closely resemble a Gaussian distribution or a von Mises-Fisher distribution <ref type="bibr" target="#b1">[2]</ref>. We will show the benefits of using CosineCE through our ablation studies.</p><p>Class-balanced Distillation (CBD). Parallel to our work, Iscen et al. <ref type="bibr" target="#b16">[17]</ref> show the use of teacher-student distillation with the goal of improving both the backbone representation and the classifier. We briefly summarize their approach. First, a teacher network ? : ( , ) is trained using standard instance sampling and the CosineCE classifier described above. Then, a student network ? : ( , ) is trained with balanced sampling along with distillation, i.e. the intermediate feature representation (x ) is constrained to be similar to (x ), while harnessing the benefits of balanced sampling for the classifier . We decouple the backbone network trained through a combination of the classification and distillation losses, and show that TailCalibration can use these improvements to obtain additional performance gains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">TailCalibration</head><p>The primary objective of our work is to generate additional features z * such that they can be used to balance the data that is used to train the classifier. Distribution calibration (DC) was proposed recently in the context of few-shot learning: samples are generated for the few-shot classes by relying on statistics of the base classes <ref type="bibr" target="#b53">[53]</ref>. We investigate the applicability of DC in the context of long-tail classification, and present the generation process below.  <ref type="figure">Figure 2</ref>: We visualize the process of feature generation. We first estimate the class statistics, and apply the Tukey transformation to convert the data into a distribution closer to a Gaussian. We find the nearest neighbor categories for each instance, calibrate the tail class distribution, and sample from this to generate additional features. The process is repeated until all categories have balanced number of features, which are used as training data for the classifier.</p><p>Our approach can be simplified into three steps, also illustrated in <ref type="figure">Fig. 2. (i)</ref> We first estimate the distribution of each category based on a Gaussian assumption; (ii) Categorical neighbors of each instance in the tail classes are used to create a calibrated distribution; and (iii) We sample several new features from these distributions to balance the training data seen by a classifier.</p><p>All operations below are in the feature space. Given a trained backbone (discussed in Sec. 3.2), we first precompute feature representations for the entire dataset. These features of true samples are denoted by F = {z } =1 . F denotes features of images corresponding to the subset D , or belonging to the category .</p><p>Due to the inherent randomness in sampling from a distribution, we can generate features multiple times and use them as a fresh dataset from which the classifier can learn something new in each epoch.</p><p>Class statistics. We start by computing the statistics for each category, assuming that the feature distribution is Gaussian. Note that this assumption may be particularly reasonable when using a backbone trained with the CosineCE loss function.</p><formula xml:id="formula_2">= 1 ?? ? F z , and<label>(3)</label></formula><formula xml:id="formula_3">? = 1 ? 1 ?? ? F (z ? )(z ? ) ,<label>(4)</label></formula><p>where ? R and ? ? R ? denote the mean and full covariance of the Gaussian distribution for category .</p><p>Tukey's Ladder of Powers transformation. Sometimes referred to as the Bulging rule, this transformation helps change the shape of a skewed distribution so that it becomes closer to a Normal distribution <ref type="bibr" target="#b42">[42]</ref>. In particular, it is applied to each dimension of the feature as follows:</p><formula xml:id="formula_4">z = z if ? 0 log(z ) otherwise .<label>(5)</label></formula><p>where &gt; 0 is a hyperparameter of our model and z raises each element of z to the power . In fact, ? 1 is found to perform well for most of our experiments.</p><p>Calibration and generation. For each class, we sample 1 ? additional features, such that the resulting feature dataset is completely balanced and all classes have 1 instances. Sampling is performed based on an instance specific calibrated distribution. Specifically, each z ( th feature from category ) is responsible for generating [ 1 / ? 1] + features where [ ] + rounds to the nearest integer greater than or equal to . As 1 / may be a fraction, we randomly choose an appropriate number of z so as to obtain a total of 1 samples.</p><p>Next, we compute the distances between class means and the selected feature. For each feature z , we first compute the distance between the instance and category means as</p><formula xml:id="formula_5">? , = ?z ? ? 2 .<label>(6)</label></formula><p>We identify the set of category indices that are neighbors N with smallest distance . Note that the distance computation uses the Tukey transformed featurez . The calibrated distribution is obtained as</p><formula xml:id="formula_6">z = 1 + 1 ?? ?N +z (7) ? z = 1 ?? ?N ? + ,<label>(8)</label></formula><p>where is an optional constant hyper-parameter to increase the spread of the calibrated distribution. We found that = 0 works reasonably well for multiple experiments.</p><p>Sampling. We initialize a multi-variate Gaussian distribution 1 for each instance z , and generate new features with the same associated class label as . We denote the generated features for category as F * , and together, |F ? F * | = 1 . This combined set of features is generated for all categories and used to train the classifier . ? 2 -normalized calibration. For the CosineCE backbone, we ? 2normalize the features z before feeding them to the TailCalibration pipeline, both for gathering statistics and Tukey transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we start by presenting a brief overview of the dataset and implementation details for our methods. We present some ablation studies comparing different aspects of the model, and finally perform a thorough comparison of our work against stateof-the-art approaches. We also include some analysis to obtain a better understanding of the feature generation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Experimental Setup</head><p>We benchmark our proposed method across two datasets, CIFAR-100-LT and mini-ImageNet-LT.</p><p>CIFAR-100-LT. CIFAR-100 is a balanced dataset containing 60K images from 100 categories, with 50K in train and 10K in validation. We use the synthetically created long-tail variants that have also been used by previous works <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b56">56]</ref>. There are three versions of the CIFAR-100-LT dataset, with the imbalance factor ( 1 / ) of {10, 50, 100}. An exponential decay is used for determining in between. Note that a higher imbalance factor mimics a stronger long-tail problem and is typically more challenging -we will see this through the performance of baseline models.</p><p>As the synthetically created variants involve randomly selecting images, all experiments are replicated with 3 seeds where different sets of images are selected. The average performance over all seeds is reported when not mentioned otherwise. As we will see in the ablation studies, this random sub-sampling often leads to a high variance, but we observe consistent improvements by using our approach. For evaluation, we use the entire balanced validation set of 10K images, 100 samples for each of the 100 categories.</p><p>mini-ImageNet-LT. mini-ImageNet was proposed by <ref type="bibr" target="#b47">[47]</ref> for fewshot learning evaluation, in an attempt to have a dataset like Ima-geNet while requiring fewer resources. Similar to the statistics for CIFAR-100-LT with an imbalance factor of 100, we construct a longtailed variant of mini-ImageNet that features all the 100 classes and an imbalanced training set with 1 = 500 and = 5 images. For evaluation, both the validation and test sets are balanced and contain 10K images, 100 samples for each of the 100 categories.</p><p>We report performance as accuracy. Note that average per-sample accuracy is equivalent to average per-class accuracy due to the balanced evaluation sets in both datasets. <ref type="bibr" target="#b0">1</ref> using PyTorch's MultivariateNormal distribution.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation details</head><p>Implementation details for CIFAR100-LT. We follow a similar setup to <ref type="bibr" target="#b56">[56]</ref>: the backbone is a ResNet-32 <ref type="bibr" target="#b14">[15]</ref> trained by minibatch stochastic gradient descent (SGD) with a momentum of 0.9 and a batch size of 128. For a fair comparison, we tune the other parameters to match the baseline accuracy of the rest of the reported works. The learning rate is decayed by a cosine scheduler <ref type="bibr" target="#b26">[27]</ref> from 0.2 to 0.0 in 150 epochs, and a weight decay of 5 ? 10 ?5 is used. We train our models on a single NVIDIA 1080Ti GPU.</p><p>Implementation details for mini-ImageNet-LT. We follow a similar setup to <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b40">40]</ref>: the backbone is a ResNeXt-50 trained by minibatch stochastic gradient descent (SGD) with a momentum of 0.9 for 111 epochs on a batch size of 512. Through hyperparameter tuning, we found that weight decay of 5 ? 10 ?4 with a constant learning rate of 0.01 provides a better performing baseline. We train all the models on a NVIDIA Tesla P100 GPU.</p><p>For the TailCalibration feature generation, we use the hyperparameters as stated in <ref type="table" target="#tab_2">Table 1</ref>. Subsequently, the classifier is retrained with a constant learning rate of 0.001 for CIFAR-100-LT and 0.01 for mini-ImageNet-LT. While the weight decay for retraining the classifier remains the same as the backbone for CIFAR-100-LT, we found that decreasing the weight decay from 5 ? 10 ?4 to 5 ? 10 ?5 improves performance for mini-ImageNet-LT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation studies on CIFAR-100-LT</head><p>We present a few ablation studies to compare various aspects of our proposed method. Note that we do all the necessary ablations only with CIFAR-100-LT and use the findings to guide our decisions on mini-ImageNet-LT. ? 2 -normalization. As indicated in the last paragraph of Sec. 3.3, when using CosineCE, we observed that it is better to ? 2 -normalize the feature vectors z before and after the generation. We show the impact of this normalization in <ref type="table" target="#tab_3">Table 2</ref>. Imbalance factors 100 and 10 see a small but consistent improvement across all three seeds, pointing to the relevance of this modification: +0.21%, +0.64%, and +0.38% for imbalance 100 and +0.77%, +0.4%, and +0.29% for imbalance 10. For imbalance 50, we see a small improvement for 2 of 3 seeds: +0.12%, +0.09%, and -0.19%, resulting in an overall negligible performance difference.</p><p>Backbones. We presented three main strategies to train our backbone in Sec. 3.2. <ref type="table" target="#tab_4">Table 3</ref> reports performance when applying Tail-Calibration (abbreviated as TailCalib) for features precomputed from various backbones (averaged across 3 seeds). Firstly, note that CosineCE outperforms CE, while CBD with teacher-student distillation outperforms both. TailCalibration shows a consistent improvement over backbones, especially for the higher imbalance factors of 50 and 100.</p><p>Training with multiple rounds of generation. As the feature generation process is quite fast, we can afford to generate samples on-the-fly for each epoch during the training of the classifier. In particular, we propose TailCalibX, denoting that TailCalib is employed multiple times. Specifically, we generate a set of features once every epoch and use them to train the classifier. We show the results for this experiment in <ref type="table" target="#tab_4">Table 3</ref>. TailCalibX provides incremental performance boosts over TailCalib.</p><p>Trends across different seeds. The variation across seeds is typically high as changing the seed not only changes the random initialization of the base network (this has a small impact), but also leads to the selection of a different subset of CIFAR-100 images for creating the synthetically imbalanced training data (this has a large impact). This is especially true for imbalance factor 50 and 10; we suspect that as there are very few training samples in the tail categories for imbalance factor 100, which samples are selected does not matter as much. For example, the accuracy of the CE baseline across 3 seeds is (43.8%, 44.8%, 46.1%) for imbalance factor 50. <ref type="figure" target="#fig_0">Fig. 3</ref> shows the absolute percentage points performance improvement over the specific backbone for each seed. We observe consistent performance improvement over progressively harder backbones by applying TailCalib or TailCalibX across various seeds. We can also see that while TailCalib may fail to provide performance improvements for low imbalance factors (CosineCE and CBD, imbalance 10), TailCalibX always provides a small boost. This indicates that the feature generation process may not be very reliable for datasets with a small long-tail effect, but the classifier can still extract meaningful information from multiple rounds of generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparison to state-of-the-art</head><p>We compare our proposed approach against several previous works grouping them in a manner similar to our related work in Sec. 2.</p><p>Results for most methods are taken from the respective papers or BBN <ref type="bibr" target="#b56">[56]</ref>. For the methods that did not report results on CIFAR-100-LT or mini-ImageNet-LT, we present additional details of our re-implementation.</p><p>? For CE and CosineCE, we choose hyperparameters (learning rate scheduler, number of epochs, etc.) to match the performance of CE on a previously reported work, BBN <ref type="bibr" target="#b56">[56]</ref>. ? cRT <ref type="bibr" target="#b19">[20]</ref> does not provide results on the CIFAR-100-LT and mini-ImageNet-LT datasets. We use their publicly available code to generate results for both the datasets.  On the x-axis, we indicate the seed and imbalance factor of each run. Please refer to <ref type="table" target="#tab_4">Table 3</ref> for averaged performance scores across the 3 seeds. ? CBD is a recent, and to the best of our knowledge, unpublished work <ref type="bibr" target="#b16">[17]</ref>. Through email conversations with the authors, we verified our implementation and present results with a single teacher trained on the both datasets. ? MODALS <ref type="bibr" target="#b5">[6]</ref> was trained with the Gaussian noise augmentation. We choose = 0.01 after performing a sweep across [0.1, 0.01, 0.001]. ? For mixup <ref type="bibr" target="#b54">[54]</ref>, we choose = 0.01 after performing a sweep across [0.01, 0.1, 0.2, 0.3, 0.5, 0.7]. <ref type="table" target="#tab_5">(Table 4</ref>). Firstly, note that the CosineCE training paradigm is superior to CE, and in fact, outperforms several loss reweighting based methods. CosineCE + TailCalibX outperforms all previous works ignoring distillation. In fact, it achieves performance close to CBD <ref type="bibr" target="#b16">[17]</ref> (especially on imbalance factors 100 and 50) that trains two networks -a teacher and student, and benefits from the advantages of ensembling. Finally, applying TailCalibX on top of a trained CBD model results in further performance improvements of 1-2% notably for imbalance factors 100 and 50. <ref type="table" target="#tab_7">(Table 5</ref>). TailCalibX outperforms all previous works. As compared to the CosineCE baseline, not only does it improve the accuracy for tail classes (few) by over 20%, we also see performance improvements for both the middle classes (mid, +4.93%) and head classes (many, +2.85%) as well. Surprisingly, CBD performs worse than classifier re-training (cRT), hence, we omit evaluation of TailCalibration as applied to a backbone trained with CBD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-100-LT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>mini-ImageNet-LT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Analysis</head><p>tSNE visualization. <ref type="figure">Fig. 4</ref> shows a few feature embeddings computed using t-SNE <ref type="bibr" target="#b43">[43]</ref> for head and tail categories from the CIFAR-100-LT dataset. For visual clarity, we show 10 validation samples for each class and up to 40 training + generated samples. We randomly choose 3 pairs of visually similar categories: tank and bus, woman and baby, and aquarium fish and turtle, such that one of them is from the bottom 15 tail categories, while the second belongs to the top 15 head categories.</p><p>In the left plot, before feature generation, we see that the validation samples (+) from the tail categories are often confused with visually similar and larger head classes: (i) five samples of the tank (red) are located close to the bus (blue) cluster; and (ii) roughly 7 of 10 samples of the woman category (purple) are potentially confused as belonging to the baby class (orange). In the right plot, we generate features using TailCalibration and re-compute the t-SNE embeddings. We observe a noticeable reduction in errors, even on this randomly picked toy sample. Now, 3 of 5 tank samples are close to the bus cluster, and 4 of 7 woman samples are close to the baby cluster, while the others are more easily separable.</p><p>Class nearest neighbors. Recall, to generate the calibrated tail distributions, we pick categories as nearest neighbors for each feature z . We analyze the classes that are most commonly used as nearest neighbors for the bottom 15 tail classes of the CIFAR-100-LT dataset in <ref type="table" target="#tab_8">Table 6</ref>. The table shows the nearest neighbors for imbalance factor 100 and = 3. We observe that the class for which we wish to generate samples is often the nearest centroid and is ignored in the table for brevity.</p><p>This split of CIFAR-100-LT is sorted alphabetically, i.e. the classes with letter a belong to the head, and classes with letters towards the end of the alphabet form the tail. We see that nearest neighbors need not belong to the head classes, even though it may be common. For example, we see that tiger distribution draws from the lion class, or television from couch, possibly due to the fact that images with a television have additional furniture in them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bus : Train</head><p>Baby : Train Aquarium Fish : Train Tank : Train Woman : Train Turtle : Train Bus : Validation Baby : Validation Aquarium Fish : Validation Tank : Validation Woman : Validation Turtle : Validation Bus : Generated Baby : Generated Aquarium Fish : Generated Tank : Generated Woman : Generated Turtle : Generated <ref type="figure">Figure 4</ref>: t-SNE visualization of a few head and tail classes from CIFAR-100-LT. The plot on the left is before generation, and the plot on the right is after generation. We show 10 validation samples for each class and limit to 40 training + generated samples for ease of interpretation. Markers: ? (dot) indicate training samples; + (plus) are validation samples; and ? (cross) are generated features also shown with a lighter version of the base color (e.g. black-gray for turtle). Head categories: bus (273), baby (455), aquarium fish (477). Tail categories: tank (9), woman (5), turtle (6). Class size is indicated in parenthesis. Please refer to the text, Sec. 4.5 for a more thorough discussion. Best seen in colour. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION AND FUTURE WORK</head><p>Learning to cope with long-tail distributions is an important problem for machine learning. Inspired by a recent work on few-shot learning <ref type="bibr" target="#b53">[53]</ref>, we explored one facet of this challenging task: feature generation as a means to balance the training data seen by a classifier. We analyzed the efficacy of distribution calibration and empirically validated that it can lead to substantial performance improvements. In this process, we achieved a new state-of-the-art on two synthetic datasets: CIFAR-100-LT and mini-ImageNet-LT, especially demonstrating that TailCalibration is orthogonal to, and can be combined with, other works such as CBD <ref type="bibr" target="#b16">[17]</ref>, to yield additional improvements.</p><p>Future work. In the future, we wish to analyze the feature generation process in a more thorough manner. In particular, we hope to discover the underlying class-specific manifolds on which the features would be expected to lie. While our initial attempts at evaluating TailCalibration on ImageNet did not yield significant improvement, we would like to extend our evaluation to other long-tail datasets, both synthetic: ImageNet-LT <ref type="bibr" target="#b25">[26]</ref> and Places-LT <ref type="bibr" target="#b25">[26]</ref>, and natural: iNaturalist <ref type="bibr" target="#b44">[44]</ref> or FineFoods dataset <ref type="bibr" target="#b31">[32]</ref>. Another possibility is to exploit the hierarchy of categories and learn appropriate models such as hyperbolic representations <ref type="bibr" target="#b21">[22]</ref> or their generalization to pseudo-Riemannian manifolds of constant nonzero curvature <ref type="bibr" target="#b22">[23]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Performance improvement in absolute percentage points across TailCalib and TailCalibX for all three backbones: CE (left), CosineCE (middle), CBD (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>21, December 2021, Jodhpur, India ? 2021 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-7596-2. https://doi.org/10.1145/3490035.3490300</figDesc><table><row><cell>Class 1</cell><cell>Validation data</cell><cell>Train distribution</cell></row><row><cell>Class 2</cell><cell>Generated data</cell><cell>Decision boundary</cell></row><row><cell>Class 3</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Hyperparameters used in TailCalibration feature generation across various imbalance ratios and datasets.</figDesc><table><row><cell></cell><cell cols="3">CIFAR-100-LT</cell><cell>mini-</cell></row><row><cell>Hyperparameters</cell><cell cols="4">Imbalance Ratios -ImageNet-</cell></row><row><cell></cell><cell cols="2">100 50</cell><cell>10</cell><cell>-LT</cell></row><row><cell cols="3">(Tukey value) 1.0 0.9</cell><cell>0.9</cell><cell>1.0</cell></row><row><cell>(Number of categories)</cell><cell>3</cell><cell>2</cell><cell>2</cell><cell>2</cell></row><row><cell cols="3">(Spread of generated features) 0.0 0.2</cell><cell>0.0</cell><cell>0.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Ablation study comparing the impact of ? 2normalization of features prior to TailCalibration. Backbone: CosineCE, Feature generation: TailCalib.</figDesc><table><row><cell>Method</cell><cell>Imbalance Ratios 100 50 10</cell></row><row><cell cols="2">without ? 2 -normalization 42.62 49.17 58.12</cell></row><row><cell>with ?</cell><cell></cell></row></table><note>2 -normalization 43.03 49.18 58.60</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Ablation study comparing the impact of backbones: CE vs. CosineCE vs. CBD. We also see that generating features multiple times can be beneficial for training: TailCalib vs. TailCalibX.</figDesc><table><row><cell>Backbone</cell><cell>Feature Generation</cell><cell>Imbalance Ratios 100 50 10</cell></row><row><cell></cell><cell>-</cell><cell>39.89 44.88 57.00</cell></row><row><cell>CE</cell><cell>TailCalib</cell><cell>42.28 46.37 56.81</cell></row><row><cell></cell><cell>-</cell><cell>41.44 45.72 58.58</cell></row><row><cell>CosineCE</cell><cell>TailCalib</cell><cell>43.03 49.18 58.60</cell></row><row><cell></cell><cell cols="2">TailCalibX 44.44 49.80 59.73</cell></row><row><cell></cell><cell>-</cell><cell>44.83 49.19 60.85</cell></row><row><cell>CBD [17]</cell><cell>TailCalib</cell><cell>46.22 50.87 60.78</cell></row><row><cell></cell><cell cols="2">TailCalibX 46.59 50.90 61.13</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Comparison of our approach (TailCalib, TailCalibX) against previous works on CIFAR-100-LT. Methods with a * indicate results produced by our re-implementations, please see the text for details about the implementation. Best results are highlighted in bold, next best and notable results with underline.</figDesc><table><row><cell cols="2">Type Method</cell><cell cols="3">Imbalance Ratios 100 50 10</cell></row><row><cell>Baseline</cell><cell>*CE *CosineCE</cell><cell cols="3">39.89 44.88 57.00 41.44 45.72 58.58</cell></row><row><cell></cell><cell>Focal Loss [24]</cell><cell cols="3">38.41 44.32 55.78</cell></row><row><cell></cell><cell cols="4">Class-Balanced Focal [8] 39.60 45.32 57.99</cell></row><row><cell></cell><cell>L2RW [35]</cell><cell cols="3">38.90 46.83 52.12</cell></row><row><cell cols="2">Loss or Meta-Weight Net [38]</cell><cell cols="3">41.61 45.66 58.91</cell></row><row><cell cols="5">Re-weighting Domain Adaptation [18] 39.31 48.53 59.58</cell></row><row><cell></cell><cell>LDAM-DRW [3]</cell><cell>42.04</cell><cell>-</cell><cell>58.71</cell></row><row><cell></cell><cell>Logit adjustment [30]</cell><cell>43.89</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>GBM [40]</cell><cell>44.1</cell><cell>50.3</cell><cell>59.6</cell></row><row><cell>Decouple</cell><cell>*cRT [20] BBN [56]</cell><cell cols="3">42.63 47.26 57.61 42.56 47.02 59.12</cell></row><row><cell>Distillation</cell><cell>LFME [52] *CBD [17]</cell><cell cols="3">42.3 44.83 49.19 60.85 --</cell></row><row><cell></cell><cell>M2M [21]</cell><cell>42.9</cell><cell>-</cell><cell>58.2</cell></row><row><cell>Generation</cell><cell>mixup [54] Manifold mixup [45]</cell><cell cols="3">39.54 44.99 58.02 38.25 43.09 56.55</cell></row><row><cell></cell><cell>*MODALS [6]</cell><cell cols="3">42.813 47.57 58.53</cell></row><row><cell></cell><cell>CosineCE + TailCalib</cell><cell cols="3">43.03 49.18 58.60</cell></row><row><cell>*Ours</cell><cell>CosineCE + TailCalibX</cell><cell cols="3">44.44 49.80 59.73</cell></row><row><cell></cell><cell>CBD + TailCalibX</cell><cell cols="3">46.59 50.90 61.13</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell cols="3">: Comparison of our approach (TailCalib, TailCalibX)</cell></row><row><cell cols="3">against previous works on mini-ImageNet-LT. Since we in-</cell></row><row><cell cols="3">troduce using mini-ImageNet in a long-tail variant, all meth-</cell></row><row><cell cols="3">ods are our re-implementations. Best results are highlighted</cell></row><row><cell cols="3">in bold, next best and notable results with underline.</cell></row><row><cell cols="2">Type Method</cell><cell>Many Mid Few All</cell></row><row><cell>Baseline</cell><cell>CE CosineCE</cell><cell>57.77 29.42 8.06 32.94 65.45 29.37 8.6 35.77</cell></row><row><cell cols="2">Decouple cRT [20]</cell><cell>66.00 31.99 29.3 43.09</cell></row><row><cell cols="2">Distillation CBD [17]</cell><cell>67.34 35.00 23.06 42.74</cell></row><row><cell>Generation</cell><cell>MODALS [6] mixup [54]</cell><cell>66.62 28.65 11.06 36.67 64.71 27.51 8.1 34.72</cell></row><row><cell>Ours</cell><cell cols="2">CosineCE + TailCalib 68.05 32.59 25.13 42.77 CosineCE + TailCalibX 68.3 34.3 29.4 44.73</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Two most frequently chosen nearest neighbor categories to calibrate the distributions for generating features for 20 tail categories of CIFAR-100-LT dataset.</figDesc><table><row><cell cols="3">Tail category # Train samples Nearest neighbors</cell></row><row><cell>tank</cell><cell>9</cell><cell>tractor, pickup_truck</cell></row><row><cell>telephone</cell><cell>9</cell><cell>streetcar, keyboard</cell></row><row><cell>television</cell><cell>8</cell><cell>couch, lamp</cell></row><row><cell>tiger</cell><cell>8</cell><cell>leopard, lion</cell></row><row><cell>tractor</cell><cell>7</cell><cell>lawn_mower, train</cell></row><row><cell>train</cell><cell>7</cell><cell>tractor, road</cell></row><row><cell>trout</cell><cell>7</cell><cell>dinosaur, caterpillar</cell></row><row><cell>tulip</cell><cell>6</cell><cell>rabbit, cattle</cell></row><row><cell>turtle</cell><cell>6</cell><cell>telephone, ray</cell></row><row><cell>wardrobe</cell><cell>6</cell><cell>television, skyscraper</cell></row><row><cell>whale</cell><cell>6</cell><cell>otter, seal</cell></row><row><cell>willow_tree</cell><cell>5</cell><cell>rabbit, oak_tree</cell></row><row><cell>wolf</cell><cell>5</cell><cell>rabbit, possum</cell></row><row><cell>woman</cell><cell>5</cell><cell>man, girl</cell></row><row><cell>worm</cell><cell>5</cell><cell>ray, woman</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. This work has been partly supported by the funding received from DST through the IMPRINT program (IMP / 2019 / 000250).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">2021. f-Domain Adversarial Learning: Theory and Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Acuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guojun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><forename type="middle">T</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Clustering on the Unit Hypersphere using von Mises-Fisher Distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Inderjit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joydeep</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Suvrit Sra, and Greg Ridgeway</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Theoretical Analysis of the Number of Shots in Few-Shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianshi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SMOTE: Synthetic Minority Over-sampling Technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">W</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">O</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Philip</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research (JAIR)</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">MODALS: Modality-agnostic Automated Data Augmentation in the Latent Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsz-Him</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Feature space augmentation for long-tailed data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaopeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Classbalanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">DeepSMOTE: Fusing Deep Learning and SMOTE for Imbalanced Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartosz</forename><surname>Chawla Damien Dablain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krawczyk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.02340</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Avinash Ravichandran, and Stefano Soatto. 2020. A Baseline for Few-Shot Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guneet</forename><surname>Singh Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Chaudhari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Audio Set: An ontology and human-labeled dataset for audio events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gemmeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aren</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manoj</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Plakal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ritter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Audio, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ICASSP</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dynamic Few-shot Visual Learning without Forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">AVA: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhui</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Pantofaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeqing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudheendra</forename><surname>Vijayanarasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susanna</forename><surname>Ricco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Disentangling Label Distribution for Long-tailed Visual Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngkyu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungju</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwanghee</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seokjun</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beomsu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buru</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Boqing Gong, and Cordelia Schmid. 2021. Class-Balanced Distillation for Long-Tailed Visual Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andr?</forename><surname>Araujo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.05279</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rethinking Class-Balanced Methods for Long-Tailed Visual Recognition from a Domain Adaptation Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Class Imbalance Problem: Significance and Strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathalie</forename><surname>Japkowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence (IC-AI)</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Jiashi Feng, and Yannis Kalantidis. 2020. Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">M2m: Imbalanced Classification via Major-to-minor Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehyung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongheon</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Lorentzian Distance Learning for Hyperbolic Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Ultrahyperbolic Representation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jos</forename><surname>Stam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Kaiming He, and Piotr Doll?r</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep Representation Learning on Long-tailed Data: A Learnable Embedding Augmentation Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuchu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Large-Scale Long-Tailed Recognition in an Open World</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">SGDR: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cosine normalization: Using cosine similarity instead of dot product in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohe</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks (ICANN)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Charting the Right Manifold: Manifold Mixup for Few-shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puneet</forename><surname>Mangla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nupur</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V N</forename><surname>Balasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Long-tail Learning via Logit Adjustment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Singh Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Miech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitri</forename><surname>Zhukov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Baptiste</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makarand</forename><surname>Tapaswi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiqing</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiling</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjiang</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liping</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.16107</idno>
		<title level="m">Xiaolin Wei, and Shuqiang Jiang. 2021. Large Scale Visual Food Recognition</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep Face Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Self-Supervised Real-to-Sim Scene Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aayush</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoubhik</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Francois</forename><surname>Lafleche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Cameracci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gavriel</forename><surname>State</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Birchfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><forename type="middle">T</forename><surname>Law</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to Reweight Examples for Robust Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Bin Yang, and Raquel Urtasun</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<imprint>
			<pubPlace>Alexander C</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset for Automatic Image Captioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Meta-weight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Revisiting Unreasonable Effectiveness of Data in Deep Learning Era</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">From ImageNet to Image Classification: Contextualizing Progress on Benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Exploratory Data Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Visualizing Data Using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Recognition (JMLR)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The iNaturalist Species Classification and Detection Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><forename type="middle">Mac</forename><surname>Grant Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Manifold Mixup: Better Representations by Interpolating Hidden States</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Beckham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">MovieGraphs: Towards Understanding Human-Centric Situations from Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Vicol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makarand</forename><surname>Tapaswi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Lluis Castrejon, and Sanja Fidler</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">GLUE: A Multi-task Benchmark and Analysis Platform for Natural Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Centroid-based Deep Metric Learning for Speaker Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><forename type="middle">T</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Rudzicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Brudno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>ICASSP</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Longtailed recognition by routing diverse distribution-aware experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lionel</forename><forename type="middle">M</forename><surname>Ni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.05046</idno>
		<title level="m">Generalizing from a Few Examples: A Survey on Few-Shot Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning From Multiple Experts: Self-paced Knowledge Distillation for Long-tailed Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuyu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiguang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Free Lunch for Few-Shot Learning: Distribution Calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">mixup: Beyond Empirical Risk Minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Improving Calibration for Long-Tailed Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Min</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Human behavior and the principle of least effort</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Zipf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1949" />
			<publisher>Addison-Wesley Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
