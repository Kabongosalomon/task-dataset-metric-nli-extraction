<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PerspectiveNet: 3D Object Detection from a Single RGB Image via Perspective Points</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Huang</surname></persName>
							<email>huangsiyuan@ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Statistics</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yuan</surname></persName>
							<email>taoyuan@ucla.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Statistics</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Qi</surname></persName>
							<email>syqi@cs.ucla.edu</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Zhu</surname></persName>
							<email>yixin.zhu@ucla.edu</email>
							<affiliation key="aff4">
								<orgName type="department">Department of Statistics</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
							<email>sczhu@stat.ucla.edu</email>
							<affiliation key="aff5">
								<orgName type="department">Department of Statistics</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PerspectiveNet: 3D Object Detection from a Single RGB Image via Perspective Points</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T17:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Detecting 3D objects from a single RGB image is intrinsically ambiguous, thus requiring appropriate prior knowledge and intermediate representations as constraints to reduce the uncertainties and improve the consistencies between the 2D image plane and the 3D world coordinate. To address this challenge, we propose to adopt perspective points as a new intermediate representation for 3D object detection, defined as the 2D projections of local Manhattan 3D keypoints to locate an object; these perspective points satisfy geometric constraints imposed by the perspective projection. We further devise PerspectiveNet, an end-to-end trainable model that simultaneously detects the 2D bounding box, 2D perspective points, and 3D object bounding box for each object from a single RGB image. PerspectiveNet yields three unique advantages: (i) 3D object bounding boxes are estimated based on perspective points, bridging the gap between 2D and 3D bounding boxes without the need of category-specific 3D shape priors. (ii) It predicts the perspective points by a template-based method, and a perspective loss is formulated to maintain the perspective constraints. (iii) It maintains the consistency between the 2D perspective points and 3D bounding boxes via a differentiable projective function. Experiments on SUN RGB-D dataset show that the proposed method significantly outperforms existing RGB-based approaches for 3D object detection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>If one hopes to achieve a full understanding of a system as complicated as a nervous system, . . . , or even a large computer program, then one must be prepared to contemplate different kinds of explanation at different levels of description that are linked, at least in principle, into a cohesive whole, even if linking the levels in complete details is impractical.</p><p>-David Marr <ref type="bibr" target="#b0">[1]</ref>, pp. <ref type="bibr" target="#b20">[20]</ref><ref type="bibr" target="#b21">[21]</ref> In a classic view of computer vision, <ref type="bibr">David Marr [1]</ref> conjectured that the perception of a 2D image is an explicit multi-phase information process, involving (i) an early vision system of perceiving textures <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> and textons <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> to form a primal sketch as a perceptually lossless conversion from the raw image <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>, (ii) a mid-level vision system to construct 2.1D (multiple layers with partial occlusion) <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref> and 2.5D <ref type="bibr" target="#b10">[11]</ref> sketches, and (iii) a high-level vision system that recovers the full 3D <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>. In particular, he highlighted the importance of different levels of organization and the internal representation <ref type="bibr" target="#b14">[15]</ref>.</p><p>In parallel, the school of Gestalt Laws <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b20">[20]</ref><ref type="bibr" target="#b21">[21]</ref><ref type="bibr" target="#b23">[22]</ref><ref type="bibr" target="#b24">[23]</ref> and perceptual organization <ref type="bibr" target="#b25">[24,</ref><ref type="bibr" target="#b26">25]</ref> aims to resolve the 3D reconstruction problem from a single RGB image without forming the depth cues; but rather, they often use some sorts of priors-groupings and structural cues <ref type="bibr" target="#b27">[26,</ref><ref type="bibr" target="#b28">27]</ref> that are likely to be invariant over wide ranges of viewpoints <ref type="bibr" target="#b29">[28]</ref>, resulting in the birth of the SIFT feature <ref type="bibr" target="#b30">[29]</ref>. Later, from a Bayesian perspective at a scene level, such priors, independent of any 3D scene structures,   were found in the human-made scenes, known as the Manhattan World assumption <ref type="bibr" target="#b31">[30]</ref>. Importantly, further studies found that such priors help to improve object detection <ref type="bibr" target="#b32">[31]</ref>.</p><p>In this paper, inspired by these two classic schools in computer vision, we seek to test the following two hypotheses using modern computer vision methods: (i) Could an intermediate representation facilitate modern computer vision tasks? (ii) Is such an intermediate representation a better and more invariant prior compared to the priors obtained directly from specific tasks?</p><p>In particular, we tackle the challenging task of 3D object detection from a single RGB image. Despite the recent success in 2D scene understanding (e.g., <ref type="bibr" target="#b33">[32,</ref><ref type="bibr" target="#b34">33]</ref>, there is still a significant performance gap for 3D computer vision tasks based on a single 2D image. Recent modern approaches directly regress the 3D bounding boxes <ref type="bibr" target="#b35">[34]</ref><ref type="bibr" target="#b36">[35]</ref><ref type="bibr" target="#b37">[36]</ref> or reconstruct the 3D objects with specific 3D object priors <ref type="bibr" target="#b38">[37]</ref><ref type="bibr" target="#b39">[38]</ref><ref type="bibr" target="#b40">[39]</ref><ref type="bibr" target="#b41">[40]</ref>.</p><p>In contrast, we propose an end-to-end trainable framework, PerspectiveNet, that sequentially estimates the 2D bounding box, 2D perspective points, and 3D bounding box for each object with a local Manhattan assumption <ref type="bibr" target="#b42">[41]</ref>, in which the perspective points serve as the intermediate representation, defined as the 2D projections of local Manhattan 3D keypoints to locate an object.</p><p>The proposed method offers three unique advantages. First, the use of perspective points as the intermediate representation bridges the gap between 2D and 3D bounding boxes without utilizing any extra category-specific 3D shape priors. As shown in <ref type="figure" target="#fig_1">Figure 1</ref>, it is often challenging for learning-based methods to estimate the 3D bounding boxes from 2D images directly; regressing 3D bounding boxes from 2D input is a highly under-constrained problem and can be easily influenced by appearance variations of shape, texture, lighting, and background. To alleviate this issue, we adopt the perspective points as an intermediate representation to represent the local Manhattan frame that each 3D object aligns with. Intuitively, the perspective points of an object are 3D geometric constraints in the 2D space. More specifically, the 2D perspective points for each object are defined as the perspective projection of the 3D object bounding box (concatenated with its center), and each 3D box aligns within a 3D local Manhattan frame. These perspective points are fused into the 3D branch to predict the 3D attributes of the 3D bounding boxes.</p><p>Second, we devise a template-based method to efficiently and robustly estimate the perspective points. Existing methods <ref type="bibr">[42-44, 33, 45]</ref> usually exploit heatmap or probability distribution map as the representation to learn the location of visual points (e.g., object keypoint, human skeleton, room layout), relying heavily on the view-dependent visual features, thus insufficient to resolve occlusions or large rotation/viewpoint changes in complex scenes; see an example in <ref type="figure" target="#fig_1">Figure 1 (b)</ref> where the five perspective points (in red) are challenging to emerge from pure visual features but could be inferred by the correlations and topology among other perspective points. To tackle this problem, we treat each set of 2D perspective points as the low dimensional embedding of its corresponding set of 3D points with a constant topology; such an embedding is learned by predicting the perspective points as a mixture of sparse templates. A perspective loss is formulated to impose the perspective constraints; the details are described in ? 3.2.</p><p>Third, the consistency between the 2D perspective points and 3D bounding boxes can be maintained by a differentiable projective function; it is end-to-end trainable, from the 2D region proposals, to the 2D bounding boxes, to the 2D perspective points, and to the 3D bounding boxes.</p><p>In the experiment, we show that the proposed PerspectiveNet outperforms previous methods with a large margin on SUN RGB-D dataset <ref type="bibr" target="#b47">[46]</ref>, demonstrating its efficacy on 3D object detection.</p><p>2 Related Work 3D object detection from a single image Detecting 3D objects from a single RGB image is a challenging problem, particularly due to the intrinsic ambiguity of the problem. Existing methods could be categorized into three streams: (i) geometry-based methods that estimate the 3D bounding boxes with geometry and 3D world priors <ref type="bibr" target="#b48">[47]</ref><ref type="bibr" target="#b49">[48]</ref><ref type="bibr" target="#b50">[49]</ref><ref type="bibr" target="#b51">[50]</ref><ref type="bibr" target="#b52">[51]</ref>; (ii) learning-based methods that incorporate category-specific 3D shape prior <ref type="bibr" target="#b53">[52,</ref><ref type="bibr" target="#b39">38,</ref><ref type="bibr" target="#b41">40]</ref> or extra 2.5D information (depth, surface normal, and segmentation) <ref type="bibr" target="#b38">[37,</ref><ref type="bibr" target="#b40">39,</ref><ref type="bibr" target="#b54">53]</ref> to detect 3D bounding boxes or reconstruct the 3D object shape; and (iii) deep learning methods that directly estimates the 3D object bounding boxes from 2D bounding boxes <ref type="bibr" target="#b55">[54,</ref><ref type="bibr" target="#b35">[34]</ref><ref type="bibr" target="#b36">[35]</ref><ref type="bibr" target="#b37">[36]</ref>. To make better estimations, various techniques have been devised to enforce consistencies between the estimated 3D and the input 2D image. Huang et al. <ref type="bibr" target="#b37">[36]</ref> proposed a two-stage method to learn the 3D objects and 3D layout cooperatively. Kundu et al. <ref type="bibr" target="#b38">[37]</ref> proposed a 3D object detection and reconstruction method using category-specific object shape prior by renderand-compare. Different from these methods, the proposed PerspectiveNet is a one-stage end-to-end trainable 3D object detection framework using perspective points as an intermediate representation;</p><p>the perspective points naturally bridge the gap between the 2D and 3D bounding boxes without any extra annotations, category-specific 3D shape priors, or 2.5D maps.</p><p>Manhattan World assumption Human-made environment, from the layout of a city to structures such as buildings, room, furniture, and many other objects, could be viewed as a set of parallel and orthogonal planes, known as the Manhattan World (MW) assumption <ref type="bibr" target="#b32">[31]</ref>. Formally, it indicates that most human-made structures could be approximated by planar surfaces that are parallel to one of the three principal planes of a common orthogonal coordinate system. This strict Manhattan World assumption is later extended by a Mixture of Manhattan Frame (MMF) <ref type="bibr" target="#b56">[55]</ref> to represent more complex real-world scenes (e.g., city layouts, rotated objects). In literature, MW and MMF have been adopted in vanish points (VPs) estimation and camera calibration <ref type="bibr" target="#b57">[56,</ref><ref type="bibr" target="#b58">57]</ref>, orientation estimation <ref type="bibr" target="#b59">[58]</ref><ref type="bibr" target="#b60">[59]</ref><ref type="bibr" target="#b61">[60]</ref>, layout estimation <ref type="bibr" target="#b62">[61]</ref><ref type="bibr" target="#b63">[62]</ref><ref type="bibr" target="#b64">[63]</ref><ref type="bibr" target="#b65">[64]</ref><ref type="bibr" target="#b45">44]</ref>, and 3D scene reconstruction <ref type="bibr">[65-67, 41, 68, 69]</ref>.</p><p>In this work, we extend the MW to local Manhattan assumption where the cuboids are aligned with the vertical (gravity) direction but with arbitrary horizontal orientation (also see Xiao and Furukawa <ref type="bibr" target="#b42">[41]</ref>), and perspective points are adopted as the intermediate representation for 3D object detection.</p><p>Intermediate 3D representation Intermediate 3D representations are bridges that narrow the gap and maintain the consistency between the 2D image plane and 3D world. Among them, 2.5D sketches have been broadly used in reconstructing the 3D shapes <ref type="bibr" target="#b71">[70]</ref><ref type="bibr" target="#b72">[71]</ref><ref type="bibr" target="#b73">[72]</ref> and 3D scenes <ref type="bibr" target="#b74">[73,</ref><ref type="bibr" target="#b39">38]</ref>. Other recent alternative intermediate 3D representations include: (i) Wu et al. <ref type="bibr" target="#b75">[74]</ref> uses pre-annotated and category-specific object keypoints as an intermediate representation, and (ii) Tekin et al. <ref type="bibr" target="#b76">[75]</ref> uses projected corners of 3D bounding boxes in learning the 6D object pose. In this paper, we explore the perspective points as an intermediate representation of 2D and 3D bounding boxes, and provide an efficient learning framework for 3D object detection.</p><p>3 Learning Perspective Points for 3D Object Detection</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overall Architecture</head><p>As shown in <ref type="figure" target="#fig_3">Figure 2</ref>, the proposed PerspectiveNet contains a backbone architecture for feature extraction over the entire image, a region proposal network (RPN) <ref type="bibr" target="#b33">[32]</ref> that proposes regions of interest (RoIs), and a network head including three region-wise parallel branches. For each proposed box, its RoI feature is fed into the three network branches to predict: (i) the object class and the 2D bounding box offset, (ii) the 2D perspective points (projected 3D box corners and object center) as a weighted sum of predicted perspective templates, and (iii) the 3D box size, orientation, and its distance from the camera. Detected 3D boxes are reconstructed by the projected object center, distance, box size, and rotation. The overall architecture of the PerspectiveNet resembles the R-CNN structure, and we refer readers to <ref type="bibr" target="#b33">[32,</ref><ref type="bibr" target="#b77">76,</ref><ref type="bibr" target="#b34">33]</ref> for more details of training R-CNN detectors.</p><p>During training, we define a multi-task loss on each proposed RoI as</p><formula xml:id="formula_0">L = L cls + L 2D + L pp + L p + L 3D + L proj ,<label>(1)</label></formula><p>where the classification loss L cls and 2D bounding box loss L 2D belong to the 2D bounding box branch and are identical to those defined in 2D R-CNNs <ref type="bibr" target="#b33">[32,</ref><ref type="bibr" target="#b34">33]</ref>. L pp and L p are defined on the perspective point branch ( ? 3.2), L 3D is defined on the 3D bounding box branch (see ? 3.3), and the L proj is defined on maintaining the 2D-3D projection consistency (see ? 3.4). For each proposed box, its RoI feature is fed into three network branches to predict: (i) the object class and the 2D box offset, (ii) 2D perspective templates (projected 3D box corners and object center) and the corresponding coefficients, and (iii) the 3D box size, orientation, and its distance from the camera. Detected 3D boxes are reconstructed by the projected object center, distance, box size, and rotation. By projecting the detected 3D boxes to 2D and comparing them with 2D perspective points, the network imposes and learns a consistency between the 2D inputs and 3D estimations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Perspective Point Estimation</head><p>The perspective point branch estimates the set of 2D perspective points for each RoI. Formally, the 2D perspective points of an object are the 2D projections of local Manhattan 3D keypoints to locate that object, and they satisfy certain geometric constraints imposed by the perspective projection. In our case, the perspective points ( <ref type="figure" target="#fig_1">Figure 1(b)</ref>) include the 2D projections of the 3D bounding box corners and the 3D object center. The perspective points are predicted using a template-based regression and learned by a mean squared error and a perspective loss detailed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Template-based Regression</head><p>Most of the existing methods <ref type="bibr">[42-44, 33, 45]</ref> estimate visual keypoints with heatmaps, where each map predicts the location for a certain keypoint. However, predicting perspective points by heatmaps has two major problems: (i) Heatmap prediction for different keypoints is independent, thus fail to capture the topology correlations among the perspective points. (ii) Heatmap prediction for each keypoint relies heavily on the visual feature such as corners, which may be difficult to detect (see an example in <ref type="figure" target="#fig_1">Figure 1</ref>(b)). In contrast, each set of 2D perspective points can be treated as a low dimensional embedding of a set of 3D points with a particular topology, thus inferring such points relies more on the relation and topology among the points instead of just the visual features.</p><p>To tackle these problems, we avoid dense per-pixel predictions. Instead, we estimate the perspective points by a mixture of sparse templates <ref type="bibr" target="#b78">[77,</ref><ref type="bibr" target="#b79">78]</ref>. The sparse templates are more robust when facing unfamiliar scenes or objects. Ablative experiments show that the proposed template-based method provides a more accurate estimation of perspective points than heatmap-based methods; see ? 5.1.</p><p>Specifically, we project both the 3D object center and eight 3D bounding box corners to 2D with camera parameters to generate the ground-truth 2D perspective points P gt ? R 2?9 . Since a portion of the perspective points usually lies out of the RoI, we calculate the location of the perspective points in an extended (doubled) size of RoI and normalize the locations to [0, 1].</p><p>We predict the perspective points by a linear combination of templates; see <ref type="figure">Figure 3</ref>. The perspective point branch has a C ? K ? 2 ? 9 dimensional output for the templates T , and a C ? K dimensional output for the coefficients w, where K denotes the number of templates for each class and C denotes the number of object classes. The templates T is scaled to [0, 1] by a sigmoid nonlinear function, and the coefficients w is normalized by a softmax function. The estimated perspective pointsP ? R C?2?9 can be computed by a linear combination:     The template design is both class-specific and instance-specific: (i) Class-specific: we decouple the prediction of the perspective point and the object class, allowing the network to learn perspective points for every class without competition among classes. (ii) Instance-specific: the templates are inferred for each RoI; hence, they are specific to each object instance. The templates are automatically learned for each object instance from data with the end-to-end learning framework; thus, both the templates and coefficients for each instance are optimizable and can better fit the training data.</p><formula xml:id="formula_1">P i = K k=1 w ik T ik , ?i = 1, ? ? ? , C.<label>(2)</label></formula><formula xml:id="formula_2">1 L F Y 2 4 8 b P F q T N y Y Z U h C W N t S y F Z q L 8 n M h o Z M 4 0 C 2 x l R H J t V b y 7 + 5 / V S D K / 9 T K g k R a 7 Y c l G Y S o I x m f 9 N h k J z h n J q C W V a 2 F s J G 1 N N G d p 0 S j Y E b / X l d d K u 1 z y 3 5 t 1 d V h r V P I 4 i n M E 5 V M G D K 2 j A L T S h B Q x G 8 A y v 8 O Z I 5 8 V 5 d z 6 W r Q U n n z m F P 3 A + f w A D 3 I 2 G &lt; / l a t e x i t &gt; &lt; l a</formula><formula xml:id="formula_3">1 L F Y 2 4 8 b P F q T N y Y Z U h C W N t S y F Z q L 8 n M h o Z M 4 0 C 2 x l R H J t V b y 7 + 5 / V S D K / 9 T K g k R a 7 Y c l G Y S o I x m f 9 N h k J z h n J q C W V a 2 F s J G 1 N N G d p 0 S j Y E b / X l d d K u 1 z y 3 5 t 1 d V h r V P I 4 i n M E 5 V M G D K 2 j A L T S h B Q x G 8 A y v 8 O Z I 5 8 V 5 d z 6 W r Q U n n z m F P 3 A + f w A D 3 I 2 G &lt; / l a t e x i t &gt; &lt; l a</formula><formula xml:id="formula_4">1 L F Y 2 4 8 b P F q T N y Y Z U h C W N t S y F Z q L 8 n M h o Z M 4 0 C 2 x l R H J t V b y 7 + 5 / V S D K / 9 T K g k R a 7 Y c l G Y S o I x m f 9 N h k J z h n J q C W V a 2 F s J G 1 N N G d p 0 S j Y E b / X l d d K u 1 z y 3 5 t 1 d V h r V P I 4 i n M E 5 V M G D K 2 j A L T S h B Q x G 8 A y v 8 O Z I 5 8 V 5 d z 6 W r Q U n n z m F P 3 A + f w A D 3 I 2 G &lt; / l a t e x i t &gt; &lt; l a</formula><formula xml:id="formula_5">1 L F Y 2 4 8 b P F q T N y Y Z U h C W N t S y F Z q L 8 n M h o Z M 4 0 C 2 x l R H J t V b y 7 + 5 / V S D K / 9 T K g k R a 7 Y c l G Y S o I x m f 9 N h k J z h n J q C W V a 2 F s J G 1 N N G d p 0 S j Y E b / X l d d K u 1 z y 3 5 t 1 d V h r V P I 4 i n M E 5 V M G D K 2 j A L T S h B Q x G 8 A y v 8 O Z I 5 8 V 5 d z 6 W r Q U n n z m F P 3 A + f w A D 3 I 2 G &lt; / l a t e x i t &gt; w 1 &lt; l a t</formula><p>The average mean squared error (MSE) loss is defined as L pp = MSE(P c , P gt ). For an RoI associated with ground-truth class c, L pp is only defined on the c's perspective points during training; perspective point outputs from other classes do not contribute to the loss. In inference, we rely on the dedicated classification branch to predict the class label to select the output perspective points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Perspective Loss</head><p>Under the assumption that each 3D bounding box aligns with a local Manhattan frame, we regularize the estimation of the perspective points to satisfy the constraint of perspective projection. Each set of mutually parallel lines in 3D can be projected into 2D as intersecting lines; see <ref type="figure">Figure 3</ref> (b). These intersecting lines should converge at the same vanishing point. Therefore, the desired algorithm would penalize the distance between the intersection points from the two sets of intersecting lines. For example in <ref type="figure">Figure 3</ref> (b), we select line ad and line eh as a pair of lines, bc and f g as another, and compute the distance between their intersection point u 1 and u 2 . Additionally, since we assume each 3D local Manhattan frame aligns with the vertical (gravity) direction, we enforce the edges in gravity direction (i.e., ae, bf , cg, and dh) to be parallel by penalizing the large slope variance.</p><p>The perspective loss is computed as L p = L d1 + L d2 + L grav , where L grav penalizes the slope variance in gravity direction, L d1 and L d2 penalize the intersection point distance for the two perpendicular directions along the gravity direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">3D Bounding Box Estimation</head><p>Estimating 3D bounding boxes is a two-step process. In the first step, the 3D branch estimates the 3D attributes, including the distance between the camera center and the 3D object center, as well as the 3D size and orientation following Huang et al. <ref type="bibr" target="#b37">[36]</ref>. Since the perspective point branch encodes rich 3D geometric features, the 3D attribute estimator aggregates the feature from perspective point branch with a soft gated function between [0, 1] to improve the prediction. The gated function serves as a soft-attention mechanism that decides how much information from perspective points should contribute to the 3D prediction.</p><p>In the second step, with the estimated projected 3D bounding boxes center (i.e., the first estimated perspective point) and the 3D attributes, we compose the 3D bounding boxes by the inverse projection from the 2D image plane to the 3D world following Huang et al. <ref type="bibr" target="#b37">[36]</ref> given camera parameters.</p><p>The 3D loss is computed by the sum of individual losses of 3D attributes and a joint loss of 3D bounding box L 3D = L dis + L size + L ori + L box3d . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">2D-3D Consistency</head><p>In contrast to prior work <ref type="bibr" target="#b75">[74,</ref><ref type="bibr" target="#b80">79,</ref><ref type="bibr" target="#b81">80,</ref><ref type="bibr" target="#b36">35,</ref><ref type="bibr" target="#b71">70,</ref><ref type="bibr" target="#b37">36]</ref> that enforces the consistency between estimated 3D objects and 2D image, we devise a new way to impose a re-projection consistency loss between 3D bounding boxes and perspective points. Specifically, we compute the 2D projected perspective points P proj by projecting the 3D bounding box corners back to 2D image plane and computing the distance with respect to ground-truth perspective points L proj = MSE(P proj , P gt ). Comparing with prior work to maintain the consistency between 2D and 3D bounding boxes by approximating the 2D projection of 3D bounding boxes <ref type="bibr" target="#b36">[35,</ref><ref type="bibr" target="#b37">36]</ref>, the proposed method uses the exact projection of projected 3D boxes to establish the consistency, capturing a more precise 2D-3D relationship.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation Details</head><p>Network Backbone Inspired by He et al. <ref type="bibr" target="#b34">[33]</ref>, we use the combination of residual network (ResNet) <ref type="bibr" target="#b82">[81]</ref> and feature pyramid network (FPN) <ref type="bibr" target="#b83">[82]</ref> to extract the feature from the entire image. A region proposal network (RPN) <ref type="bibr" target="#b33">[32]</ref> is used to produce object proposals (i.e., RoI). A RoIAlign <ref type="bibr" target="#b34">[33]</ref> module is adopted to extract a smaller features map (256 ? 7 ? 7) for each proposal.</p><p>Network Head The network head consists of three branches, and each branch has its individual feature extractor and predictor. Three feature extractors have the same architecture of two fully connected (FC) layers; each FC layer is followed by a ReLU function. The feature extractors take the 256 ? 7 ? 7 dimensional RoI features as the input and output a 1024 dimensional vector.</p><p>The predictor in the 2D branch has two separate FC layers to predict a C dimensional object class probabilities and a C ? 4 dimensional 2D bounding box offset. The predictor in the perspective point branch predicts C ? K ? 2 ? 9 dimensional templates and C ? K dimensional coefficients with two FC layers and their corresponding nonlinear activation functions (i.e., sigmoid, softmax). The soft gate in the 3D branch consists of an FC layer (1024-1) and a sigmoid function to generate the weight for feature aggregation. The predictor in the 3D branch consists of three FC layers to predict the size, the distance from the camera, and the orientation of the 3D bounding box. Experimental Setup To prepare valid data for training the proposed model, we discard the images with no 3D objects or incorrect correspondence between 2D and 3D bounding boxes, resulting 4783 training images and 4220 test images. We detect 30 categories of objects following Huang et al. <ref type="bibr" target="#b37">[36]</ref>.</p><p>Reproduciblity Details During training, an RoI is considered positive if it has the IoU with a ground-truth box of at least 0.5. L pp , L p , L 3D , and L proj are only defined on positive RoIs. Each image has N sampled RoIs, where the ratio of positive to negative is 1:3 following the protocol presented in Girshick <ref type="bibr" target="#b77">[76]</ref>.</p><p>We resize the images so that the shorter edges are all 800 pixels. To avoid over-fitting, a data augmentation procedure is performed by randomly flipping the images or randomly shifting the 2D bounding boxes with corresponding labels during the training. We use SGD for optimization with a batch size of 32 on a desktop with 4 Nvidia TITAN RTX cards (8 images each card). The learning rate starts at 0.01 and decays by 0.1 at 30,000 and 35,000 iterations. We implement our framework based on the code of Massa and Girshick <ref type="bibr" target="#b84">[83]</ref>. It takes 6 hours to train, and the trained PerspectiveNet provides inference in real-time (20 FPS) using a single GPU.</p><p>Since the consistency loss and perspective loss can be substantial during the early stage of the training process, we add them to the joint loss when the learning rate decays twice. The hyper-parameter (e.g., the weights of losses, the architecture of network head) is tuned empirically by a local search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metric</head><p>We evaluate the performance of 3D object detection using the metric presented in Song et al. <ref type="bibr" target="#b47">[46]</ref>. Specifically, we first calculate the 3D Intersection over Union (IoU) between the predicted 3D bounding boxes and the ground-truth 3D bounding boxes, and then compute the mean average precision (mAP). Following Huang et al. <ref type="bibr" target="#b37">[36]</ref>, we set the 3D IoU threshold as 0.15 in the absence of depth information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qualitative Results</head><p>The qualitative results of 2D object detection, 2D perspective point estimation, and 3D object detection are shown in <ref type="figure" target="#fig_8">Figure 4</ref>. Note that the proposed method performs accurate 3D object detection in some challenging scenes. For the perspective point estimation, even though some of the perspective points are not aligned with image features, the proposed method can still localize their positions robustly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantitative Results</head><p>Since the state-of-the-art method <ref type="bibr" target="#b37">[36]</ref> learns the camera extrinsic parameters jointly, we provide two protocals for evaluations for a fair comparison: (i) PerspectiveNet given ground-truth camera extrinsic parameter (full), and (ii) PerspectiveNet without ground-truth camera extrinsic parameter by learning it jointly following <ref type="bibr" target="#b37">[36]</ref> (w/o. cam).</p><p>We learn the detector for 30 object categories and report the precision-recall (PR) curve of 10 main categories in <ref type="figure">Figure 5</ref>. We calculate the area under the curve to compute AP; <ref type="table" target="#tab_2">Table 1</ref> shows the comparisons of APs of the proposed models with existing approaches (see supplementary materials for the APs of all 30 categories). Note that the critical difference between the proposed model and the state-of-the-art method <ref type="bibr" target="#b37">[36]</ref> is the intermediate representation to learn the 2D-3D consistency. Huang et al. <ref type="bibr" target="#b37">[36]</ref> uses 2D bounding boxes to enforce a 2D-3D consistency by minimizing the differences between projected 3D boxes and detected 2D boxes. In contrast, the proposed intermediate representation has a clear advantage since projected 3D boxes often are not 2D rectangles, and perspective points eliminate such errors.</p><p>Quantitatively, our full model improves the mAP of the state-of-the-art method <ref type="bibr" target="#b37">[36]</ref> by 14.71%, and the model without the camera extrinsic parameter improves by 10.91%. The significant improvement of the mAP demonstrates the efficacy of the proposed intermediate representation. We defer more analysis on how each component contributes to the overall performance in ? 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Ablative Analysis</head><p>In this section, we analyze each major component of the model to examine its contribution to the overall significant performance gain. Specifically, we design six variants of the proposed model. ? S 1 : The model trained without the perspective point branch, using the 2D offset to predict the 3D center of the object following Huang et al. <ref type="bibr" target="#b37">[36]</ref>.</p><p>? S 2 : The model that aggregates the feature from the perspective point branch and 3D branch directly without the gate function.</p><p>? S 3 : The model that aggregates the feature from the perspective point branch and 3D branch with a gate function that only outputs 0 or 1 (hard gate).</p><p>? S 4 : The model trained without the perspective loss.</p><p>? S 5 : The model trained without the consistency loss.</p><p>? S 6 : The model trained without the perspective branch, perspective loss, or consistency loss. <ref type="table" target="#tab_3">Table 2</ref> shows the mAP for each variant of the proposed model. The mAP drops 3.86% without the perspective point branch (S 1 ), 1.66% without the consistency loss (S 5 ), indicating that the perspective point and re-projection consistency influence the most to the proposed framework. In addition, the switch of gate function (S 2 , S 3 ) and perspective loss (S 4 ) contribute less to the final performance. Since S 6 is still higher than the state-of-the-art result <ref type="bibr" target="#b37">[36]</ref> with 9.32%, we conjecture this performance gain may come from the one-stage (vs. two-stage) end-to-end training framework and the usage of ground-truth camera parameter; we will further investigate this in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Heatmaps vs. Templates</head><p>As discussed in ? 3.2, we test two different methods for the perspective point estimation: (i) dense prediction as heatmaps following the human pose estimation mechanism in He et al. <ref type="bibr" target="#b34">[33]</ref> by adding a parallel heatmap prediction branch, and (ii) template-based regression by the proposed method. The qualitative results (see <ref type="figure" target="#fig_9">Figure 6</ref>) show that the heatmap-based estimation suffers severely from occlusion and topology change among the perspective points, whereas the proposed template-based regression eases the problem significantly by learning robust sparse templates, capturing consistent topological relations. We also evaluate the quantitative results by computing the average absolute distance between the ground-truth and estimated perspective points. The heatmap-based method has a 10.25 pix error, while the proposed method only has a 6.37 pix error, which further demonstrates the efficacy of the proposed template-based perspective point estimation.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Failure Cases</head><p>In a large portion of the failure cases, the perspective point estimation and the 3D box estimation fail at the same time; see <ref type="figure" target="#fig_10">Figure 7</ref>. It implies that the perspective point estimation and the 3D box estimation are highly coupled, which supports the assumptions that the perspective points encode richer 3D information, and the 3D branch learns meaningful knowledge from the 2D branch. In future work, we may need a more sophisticated and general 3D prior to infer the 3D locations of objects for such challenging cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Discussions and Future Work</head><p>Comparison with optimization-based methods. Assume the estimated 3D size or distance is given, it is possible to compute the 3D bounding box with an optimization-based method like efficient PnP. However, the optimization-based methods are sensitive to the accuracy of the given known variables. It is more suitable for tasks with smaller solution spaces (e.g., 6-DoF pose estimation where the 3D shapes of objects are fixed). However, it would be difficult for tasks with larger solution spaces (e.g., 3D object detection where the 3D size, distance, and object pose could vary significantly). Therefore, we argue that directly estimating each variable with constraints imposed among them is a more natural and more straightforward solution.</p><p>Potential incorporation with depth information. The PerspectiveNet estimates the distance between the 3D object center and camera center based on the color image only (pure RGB without any depth information). If the depth information was also provided, the proposed method should be able to make a much more accurate distance prediction.</p><p>Potential application to outdoor environment. It would be interesting to see how the proposed method would perform on outdoor 3D object detection datasets like KITTI <ref type="bibr" target="#b85">[84]</ref>. The differences between the indoor and outdoor datasets for the task of 3D object detection lie in various aspects, including the diversity of object categories, the variety of object dimension, the severeness of the occlusion, the range of the camera angles, and the range of the distance (depth). We hope to adopt the PerspectiveNet in future to the outdoor scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We propose the PerspectiveNet, an end-to-end differentiable framework for 3D object detection from a single RGB image. It uses perspective points as an intermediate representation between 2D input and 3D estimations. The PerspectiveNet adopts an R-CNN structure, where the region-wise branches predict 2D boxes, perspective points, and 3D boxes. Instead of using a direct regression of 2D-3D relations, we further propose a template-based regression for estimating the perspective points, which enforces a better consistency between the predicted 3D boxes and the 2D image input. The experiments show that the proposed method significantly improves existing RGB-based methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Traditional 3D object detection methods directly estimate (c) the 3D object bounding boxes from (a) the 2D bounding boxes, which suffer from the uncertainties between the 2D image plane and the 3D world. The proposed PerspectiveNet utilizes (b) the 2D perspective points as the intermediate representation to bridge the gap. The perspective points are the 2D perspective projection of the 3D bounding box corners, containing rich 3D information (e.g., positions, orientations). The red dots indicate the perspective points of the bed that are challenging to emerge based on the visual features, but could be inferred by the context (correlations and topology) among other perspective points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 RoIsFigure 2 :</head><label>12</label><figDesc>, w 2 , ..., w n ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 0 Y 5 5 A 7 c z 8 D R R s a N 5 y G T q 7 0 A a 3 o = " &gt; A A A B / X i c b Z D L S s N A F I Z P v N Z 6 i 5 e d m 8 E i V C g h K Y J d F t y 4 r G A v 0 I Y w m U 7 b o Z N J m J l Y a i m + i h s X i r j 1 P d z 5 N k 7 b L L T 1 h 4 G P / 5 z D O f O H C W d K u + 6 3 t b a + s b m 1 n d v J 7 + 7 t H x z a R 8 c N F a e S 0 D q J e S x b I V a U M 0 H r m m l O W 4 m k O A o 5 b Y b D m 1 m 9 + U C l Y r G 4 1 + O E + h H u C 9 Z j B G t j B f Z p c R R 4 J T Q K y i X k O M 6 M x G V g F 1 z H n Q u t g p d B A T L V A v u r 0 4 1 J G l G h C c d K t T 0 3 0 f 4 E S 8 0 I p 9 N 8 J 1 U 0 w W S I + 7 R t U O C I K n 8 y v 3 6 K L o z T R b 1 Y m i c 0 m r u / J y Y 4 U m o c h a Y z w n q g l m s z 8 7 9 a O 9 W 9 i j 9 h I k k 1 F W S x q J d y p G M 0 i w J 1 m a R E 8 7 E B T C Q z t y I y w B I T b Q L L m x C 8 5 S + v Q q P s e K 7 j 3 V 0 V q p U s j h y c w T k U w Y N r q M I t 1 K A O B B 7 h G V 7 h z X q y X q x 3 6 2 P R u m Z l M y f w R 9 b n D 0 Q P k n s = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 0 Y 5 5 A 7 c z 8 D R R s a N 5 y G T q 7 0 A a 3 o = " &gt; A A A B / X i c b Z D L S s N A F I Z P v N Z 6 i 5 e d m 8 E i V C g h K Y J d F t y 4 r G A v 0 I Y w m U 7 b o Z N J m J l Y a i m + i h s X i r j 1 P d z 5 N k 7 b L L T 1 h 4 G P / 5 z D O f O H C W d K u + 6 3 t b a + s b m 1 n d v J 7 + 7 t H x z a R 8 c N F a e S 0 D q J e S x b I V a U M 0 H r m m l O W 4 m k O A o 5 b Y b D m 1 m 9 + U C l Y r G 4 1 + O E + h H u C 9 Z j B G t j B f Z p c R R 4 J T Q K y i X k O M 6 M x G V g F 1 z H n Q u t g p d B A T L V A v u r 0 4 1 J G l G h C c d K t T 0 3 0 f 4 E S 8 0 I p 9 N 8 J 1 U 0 w W S I + 7 R t U O C I K n 8 y v 3 6 K L o z T R b 1 Y m i c 0 m r u / J y Y 4 U m o c h a Y z w n q g l m s z 8 7 9 a O 9 W 9 i j 9 h I k k 1 F W S x q J d y p G M 0 i w J 1 m a R E 8 7 E B T C Q z t y I y w B I T b Q L L m x C 8 5 S + v Q q P s e K 7 j 3 V 0 V q p U s j h y c w T k U w Y N r q M I t 1 K A O B B 7 h G V 7 h z X q y X q x 3 6 2 P R u m Z l M y f w R 9 b n D 0 Q P k n s = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 0 Y 5 5 A 7 c z 8 D R R s a N 5 y G T q 7 0 A a 3 o = " &gt; A A A B / X i c b Z D L S s N A F I Z P v N Z 6 i 5 e d m 8 Ei V C g h K Y J d F t y 4 r G A v 0 I Y w m U 7 b o Z N J m J l Y a i m + i h s X i r j 1 P d z 5 N k 7 b L L T 1 h 4 G P / 5 z D O f O H C W d K u + 6 3 t b a + s b m 1 n d v J 7 + 7 t H x z a R 8 c N F a e S 0 D q J e S x b I V a U M 0 H r m m l O W 4 m k O A o 5 b Y b D m 1 m 9 + U C l Y r G 4 1 + O E + h H u C 9 Z j B G t j B f Z p c R R 4 J T Q K y i X k O M 6 M x G V g F 1 z H n Q u t g p d B A T L V A v u r 0 4 1 J G l G h C c d K tT 0 3 0 f 4 E S 8 0 I p 9 N 8 J 1 U 0 w W S I + 7 R t U O C I K n 8 y v 3 6 K L o z T R b 1 Y m i c 0 m r u / J y Y 4 U m o c h a Y z w n q g l m s z 8 7 9 a O 9 W 9 i j 9 h I k k 1 F W S x q J d y p G M 0 i w J 1 m a R E 8 7 E B T C Q z t y I y w B I T b Q L L m x C 8 5 S + v Q q P s e K 7 j 3 V 0 V q p U s j h y c w T k U w Y N r q M I t 1 K A O B B 7 h G V 7 h z X q y X q x 3 6 2 P R u m Z l M y f w R 9 b n D 0 Q P k n s = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 0 Y 5 5 A 7 c z 8 D R R s a N 5 y G T q 7 0 A a 3 o = " &gt; A A A B / X i c b Z D L S s N A F I Z P v N Z 6 i 5 e d m 8 E i V C g h K Y J d F t y 4 r G A v 0 I Y w m U 7 b o Z N J m J l Y a i m + i h s X i r j 1 P d z 5 N k 7 b L L T 1 h 4 G P / 5 z D O f O H C W d K u + 6 3 t b a + s b m 1 n d v J 7 + 7 t H x z a R 8 c N F a e S 0 D q J e S x b I V a U M 0 H r m m l O W 4 m k O A o 5 b Y b D m 1 m 9 + U C l Y r G 4 1 + O E + h H u C 9 Z j B G t j B f Z p c R R 4 J T Q K y i X k O M 6 M x G V g F 1 z H n Q u t g p d B A T L V A v u r 0 4 1 J G l G h C c d K t T 0 3 0 f 4 E S 8 0 I p 9 N 8 J 1 U 0 w W S I + 7 R t U O C I K n 8 y v 3 6 K L o z T R b 1 Y m i c 0 m r u / J y Y 4 U m o c h a Y z w n q g l m s z 8 7 9 a O 9 W 9 i j 9 h I k k 1 F W S x q J d y p G M 0 i w J 1 m a R E 8 7 E B T C Q z t y I y w B I T b Q L L m x C 8 5 S + v Q q P s e K 7 j 3 V 0 V q p U s j h y c w T k U w Y N r q M I t 1 K A O B B 7 h G V 7 h z X q y X q x 3 6 2 P R u m Z l M y f w R 9 b n D 0 Q P k n s = &lt; / l a t e x i t &gt; ( , ,..., ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x Z K 5 u 1 P q 8 4 J e Q x x k + X + H O 0 P N b 8 s = " &gt; A A A C C X i c b V D L S g M x F L 3 j s 9 b X q E s 3 w S J U k G F G B L s s u H F Z w T 6 g L S W T Z t r Q T G Z I M k I Z 6 t K N v + L G h S J u / Q N 3 / o 3 p d C j a e k L g 5 J x 7 u b n H j z l T 2 n W / r Z X V t f W N z c J W c X t n d 2 / f P j h s q C i R h N Z J x C P Z 8 r G i n A l a 1 0 x z 2 o o l x a H P a d M f X U / 9 5 j 2 V i k X i T o 9 j 2 g 3 x Q L C A E a y N 1 L N R + Q F l 5 x z N i e M 4 8 9 d Z z y 6 5 j p s B L R M v J y X I U e v Z X 5 1 + R J K Q C k 0 4 V q r t u b H u p l h q R j i d F D u J o j E m I z y g b U M F D q n q p t k m E 3 R q l D 4 K I m m u 0 C h T f 3 e k O F R q H P q m M s R 6 q B a 9 q f i f 1 0 5 0 U O m m T M S J p o L M B g U J R z p C 0 1 h Q n 0 l K N B 8 b g o l k 5 q + I D L H E R J v w i i Y E b 3 H l Z d K 4 c D z X 8 W 4 v S 9 V K H k c B j u E E y u D B F V T h B m p Q B w K P 8 A y v 8 G Y 9 W S / W u / U x K 1 2 x 8 p 4 j + A P r 8 w f 7 6 Z a o &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x Z K 5 u 1 P q 8 4 J e Q x x k + X + H O 0 P N b 8 s = " &gt; A A A C C X i c b V D L S g M x F L 3 j s 9 b X q E s 3 w S J U k G F G B L s s u H F Z w T 6 g L S W T Z t r Q T G Z I M k I Z 6 t K N v + L G h S J u / Q N 3 / o 3 p d C j a e k L g 5 J x 7 u b n H j z l T 2 n W / r Z X V t f W N z c J W c X t n d 2 / f P j h s q C i R h N Z J x C P Z 8 r G i n A l a 1 0 x z 2 o o l x a H P a d M f X U / 9 5 j 2 V i k X i T o 9 j 2 g 3 x Q L C A E a y N 1 L N R + Q F l 5 x z N i e M 4 8 9 d Z z y 6 5 j p s B L R M v J y X I U e v Z X 5 1 + R J K Q C k 0 4 V q r t u b H u p l h q R j i d F D u J o j E m I z y g b U M F D q n q p t k m E 3 R q l D 4 K I m m u 0 C h T f 3 e k O F R q H P q m M s R 6 q B a 9 q f i f 1 0 5 0 U O m m T M S J p o L M B g U J R z p C 0 1 h Q n 0 l K N B 8 b g o l k 5 q + I D L H E R J v w i i Y E b 3 H l Z d K 4 c D z X 8 W 4 v S 9 V K H k c B j u E E y u D B F V T h B m p Q B w K P 8 A y v 8 G Y 9 W S / W u / U x K 1 2 x 8 p 4 j + A P r 8 w f 7 6 Z a o &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x Z K 5 u 1 P q 8 4 J e Q x x k + X + H O 0 P N b 8 s = " &gt; A A A C C X i c b V D L S g M x F L 3 j s 9 b X q E s 3 w S J U k G F G B L s s u H F Z w T 6 g L S W T Z t r Q T G Z I M k I Z 6 t K N v + L G h S J u / Q N 3 / o 3 p d C j a e k L g 5 J x 7 u b n H j z l T 2 n W / r Z X V t f W N z c J W c X t n d 2 / f P j h s q C i R h N Z J x C P Z 8 r G i n A l a 1 0 x z 2 o o l x a H P a d M f X U / 9 5 j 2 V i k X i T o 9 j 2 g 3 x Q L C A E a y N 1 L N R + Q F l 5 x z N i e M 4 8 9 d Z z y 6 5 j p s B L R M v J y X I U e v Z X 5 1 + R J K Q C k 0 4 V q r t u b H u p l h q R j i d F D u J o j E m I z y g b U M F D q n q p t k m E 3 R q l D 4 K I m m u 0 C h T f 3 e k O F R q H P q m M s R 6 q B a 9 q f i f 1 0 5 0 U O m m T M S J p o L M B g U J R z p C 0 1 h Q n 0 l K N B 8 b g o l k 5 q + I D L H E R J v w i i Y E b 3 H l Z d K 4 c D z X 8 W 4 v S 9 V K H k c B j u E E y u D B F V T h B m p Q B w K P 8 A y v 8 G Y 9 W S / W u / U x K 1 2 x 8 p 4 j + A P r 8 w f 7 6 Z a o &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x Z K 5 u 1 P q 8 4 J e Q x x k + X + H O 0 P N b 8 s = " &gt; A A A C C X i c b V D L S g M x F L 3 j s 9 b X q E s 3 w S J U k G F G B L s s u H F Z w T 6 g L S W T Z t r Q T G Z I M k I Z 6 t K N v + L G h S J u / Q N 3 / o 3 p d C j a e k L g 5 J x 7 u b n H j z l T 2 n W / r Z X V t f W N z c J W c X t n d 2 / f P j h s q C i R h N Z J x C P Z 8 r G i n A l a 1 0 x z 2 o o l x a H P a d M f X U / 9 5 j 2 V i k X i T o 9 j 2 g 3 x Q L C A E a y N 1 L N R + Q F l 5 x z N i e M 4 8 9 d Z z y 6 5 j p s B L R M v J y X I U e v Z X 5 1 + R J K Q C k 0 4 V q r t u b H u p l h q R j i d F D u J o j E m I z y g b U M F D q n q p t k m E 3 R q l D 4 K I m m u 0 C h T f 3 e k O F R q H P q m M s R 6 q B a 9 q f i f 1 0 5 0 U O m m T M S J p o L M B g U J R z p C 0 1 h Q n 0 l K N B 8 b g o l k 5 q + I D L H E R J v w i i Y E b 3 H l Z d K 4 c D z X 8 W 4 v S 9 V K H k c B j u E E y u D B F V T h B m p Q B w K P 8 A y v 8 G Y 9 W S / W u / U x K 1 2 x 8 p 4 j + A P r 8 w f 7 6 Z a o &lt; / l a t e x i t &gt; The proposed framework of the PerspectiveNet. Given an RGB Image, the backbone of PerspectiveNet extracts global features and propose candidate 2D bounding boxes (RoIs).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>= 2 &lt;</head><label>2</label><figDesc>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z T H 9 T t 7 q K o M W g h M F B a C M y t 6 6 i T Q = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I o B e h 4 M V j C / Y D 2 l A 2 2 0 m 7 d r M J u x u h h P 4 C L x 4 U 8 e p P 8 u a / c d v m o K 0 P B h 7 v z T A z L 0 g E 1 8 Z 1 v 5 3 C x u b W 9 k 5 x t 7 S 3 f 3 B 4 V D 4 + a e s 4 V Q x b L B a x 6 g Z U o + A S W 4 Y b g d 1 E I Y 0 C g Z 1 g c j f 3 O 0 + o N I / l g 5 k m 6 E d 0 J H n I G T V W a t 4 O y h W 3 5 i 5 A 1 o m X k w r k a A z K X / 1 h z N I I p W G C a t 3 z 3 M T 4 G V W G M 4 G z U j / V m F A 2 o S P s W S p p h N r P F o f O y I V V h i S M l S 1 p y E L 9 P Z H R S O t p F N j O i J q x X v X m 4 n 9 e L z X h j Z 9 x m a Q G J V s u C l N B T E z m X 5 M h V 8 i M m F p C m e L 2 V s L G V F F m b D Y l G 4 K 3 + v I 6 a V / W P L f m N a 8 q 9 W o e R x H O 4 B y q 4 M E 1 1 O E e G t A C B g j P 8 A p v z q P z 4 r w 7 H 8 v W g p P P n M I f O J 8 / h P u M p w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z T H 9 T t 7 q K o M W g h M F B a C M y t 6 6 i T Q = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I o B e h 4 M V j C / Y D 2 l A 2 2 0 m 7 d r M J u x u h h P 4 C L x 4 U 8 e p P 8 u a / c d v m o K 0 P B h 7 v z T A z L 0 g E 1 8 Z 1 v 5 3 C x u b W 9 k 5 x t 7 S 3 f 3 B 4 V D 4 + a e s 4 V Q x b L B a x 6 gZ U o + A S W 4 Y b g d 1 E I Y 0 C g Z 1 g c j f 3 O 0 + o N I / l g 5 k m 6 E d 0 J H n I G T V W a t 4 O y h W 3 5 i 5 A 1 o m X k w r k a A z K X / 1 h z N I I p W G C a t 3 z 3 M T 4 G V W G M 4 G z U j / V m F A 2 o S P s W S p p h N r P F o f O y I V V h i S M l S 1 p y E L 9 P Z H R S O t p F N j O i J q x X v X m 4 n 9 e L z X h j Z 9 x m a Q G J V s u C l N B T E z m X 5 M h V 8 i M m F p C m e L 2 V s L G V F F m b D Y l G 4 K 3 + v I 6 a V / W P L f m Na 8 q 9 W o e R x H O 4 B y q 4 M E 1 1 O E e G t A C B g j P 8 A p v z q P z 4 r w 7 H 8 v W g p P P n M I f O J 8 / h P u M p w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z T H 9 T t 7 q K o M W g h M F B a C M y t 6 6 i T Q = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I o B e h 4 M V j C / Y D 2 l A 2 2 0 m 7 d r M J u x u h h P 4 C L x 4 U 8 e p P 8 u a / c d v m o K 0 P B h 7 v z T A z L 0 g E 1 8 Z 1 v 5 3 C x u b W 9 k 5 x t 7 S 3 f 3 B 4 V D 4 + a e s 4 V Q x b L B a x 6 g Z U o + A S W 4 Y b g d 1 E I Y 0 C g Z 1 g c j f 3 O 0 + o N I / l g 5 k m 6 E d 0 J H n I G T V W a t 4 O y h W 3 5 i 5 A 1 o m X k w r k a A z K X / 1 h z N I I p W G C a t 3 z 3 M T 4 G V W G M 4 G z U j / V m F A 2 o S P s W S p p h N r P F o f O y I V V h i S M l S 1 p y E L 9 P Z H R S O t p F N j O i J q x X v X m 4 n 9 e L z X h j Z 9 x m a Q G J V s u C l N B T E z m X 5 M h V 8 i M m F p C m e L 2 V s L G V F F m b D Y l G 4 K 3 + v I 6 a V / W P L f m N a 8 q 9 W o e R x H O 4 B y q 4 M E 1 1 O E e G t A C B g j P 8 A p v z q P z 4 r w 7 H 8 v W g p P P n M I f O J 8 / h P u M p w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z T H 9 T t 7 q K o M W g h M F B a C M y t 6 6 i T Q = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I o B e h 4 M V j C / Y D 2 l A 2 2 0 m 7 d r M J u x u h h P 4 C L x 4 U 8 e p P 8 u a / c d v m o K 0 P B h 7 v z T A z L 0 g E 1 8 Z 1 v 5 3 C x u b W 9 k 5 x t 7 S 3 f 3 B 4 V D 4 + a e s 4 V Q x b L B a x 6 g Z U o + A S W 4 Y b g d 1 E I Y 0 C g Z 1 g c j f 3 O 0 + o N I / l g 5 k m 6 E d 0 J H n I G T V W a t 4 O y h W 3 5 i 5 A 1 o m X k w r k a A z K X / 1 h z N I I p W G C a t 3 z 3 M T 4 G V W G M 4 G z U j / V m F A 2 o S P s W S p p h N r P F o f O y I V V h i S M l S 1 p y E L 9 P Z H R S O t p F N j O i J q x X v X m 4 n 9 e L z X h j Z 9 x m a Q G J V s u C l N B T E z m X 5 M h V 8 i M m F p C m e L 2 V s L G V F F m b D Y l G 4 K 3 + v I 6 a V / W P L f m N a 8 q 9 W o e R x H O 4 B y q 4 M E 1 1 O E e G t A C B g j P 8 A p v z q P z 4 r w 7 H 8 v W g p P P n M I f O J 8 / h P u M p w = = &lt; / l a t e x i t &gt; w l a t e x i t s h a 1 _ b a s e 6 4 = " 9 n 9 5 1 3 0 Q L C L I + T 7 Y n o X d x J z F 9 1 k = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 I U Q Y 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 + D + q B c c W v u A m S d e D m p Q I 7 m o P z V H 8 Y s j b h C J q k x P c 9 N 0 M + o R s E k n 5 X 6 q e E J Z R M 6 4 j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " 9 n 9 5 1 3 0 Q L C L I + T 7 Y n o X d x J z F 9 1 k = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 I U Q Y 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 + D + q B c c W v u A m S d e D m p Q I 7 m o P z V H 8 Y s j b h C J q k x P c 9 N 0 M + o R s E k n 5 X 6 q e E J Z R M 6 4 j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " 9 n 9 5 1 3 0 Q L C L I + T 7 Y n o X d x J z F 9 1 k = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 I U Q Y 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 + D + q B c c W v u A m S d e D m p Q I 7 m o P z V H 8 Y s j b h C J q k x P c 9 N 0 M + o R s E k n 5 X 6 q e E J Z R M 6 4 j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " 9 n 9 5 1 3 0 Q L C L I + T 7 Y n o X d x J z F 9 1 k = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 I U Q Y 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 + D + q B c c W v u A m S d e D m p Q I 7 m o P z V H 8 Y s j b h C J q k x P c 9 N 0 M + o R s E k n 5 X 6 q e E J Z R M 6 4 j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>3 &lt;Figure 3 :</head><label>33</label><figDesc>e x i t s h a 1 _ b a s e 6 4 = " F D 6 s T j O X a R M f 6 L N D 7 2 5 Z q r H 0 e x g = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I U I 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 8 D b 1 C u u D V 3 A b J O v J x U I E d z U P 7 q D 2 O W R l w h k 9 S Y n u c m 6 G d U o 2 C S z 0 r 9 1 P C E s g k d 8 Z 6 l i k b c + N n i 1 B m 5 s M q Q h L G 2 p Z A s 1 N 8 T G Y 2 M m U a B 7 Y w o j s 2 q N x f / 8 3 o p h t d + J l S S I l d s u S h M J c G Y z P 8 m Q 6 E 5 Q z m 1 h D I t 7 K 2 E j a m m D G 0 6 J R u C t / r y O m l f 1 j y 3 5 t 1 d V R r V P I 4 i n M E 5 V M G D O j T g F p r Q A g Y j e I Z X e H O k 8 + K 8 O x / L 1 o K T z 5 z C H z i f P w J Y j Y U = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F D 6 s T j O X a R M f 6 L N D 7 2 5 Z q r H 0 e x g = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I U I 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 8 D b 1 C u u D V 3 A b J O v J x U I E d z U P 7 q D 2 O W R l w h k 9 S Y n u c m 6 G d U o 2 C S z 0 r 9 1 P C E s g k d 8 Z 6 l i k b c + N n i 1 B m 5 s M q Q h L G 2 p Z A s 1 N 8 T G Y 2 M m U a B 7 Y w o j s 2 q N x f / 8 3 o p h t d + J l S S I l d s u S h M J c G Y z P 8 m Q 6 E 5 Q z m 1 h D I t 7 K 2 E j a m m D G 0 6 J R u C t / r y O m l f 1 j y 3 5 t 1 d V R r V P I 4 i n M E 5 V M G D O j T g F p r Q A g Y j e I Z X e H O k 8 + K 8 O x / L 1 o K T z 5 z C H z i f P w J Y j Y U = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F D 6 s T j O X a R M f 6 L N D 7 2 5 Z q r H 0 e x g = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I U I 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 8 D b 1 C u u D V 3 A b J O v J x U I E d z U P 7 q D 2 O W R l w h k 9 S Y n u c m 6 G d U o 2 C S z 0 r 9 1 P C E s g k d 8 Z 6 l i k b c + N n i 1 B m 5 s M q Q h L G 2 p Z A s 1 N 8 T G Y 2 M m U a B 7 Y w o j s 2 q N x f / 8 3 o p h t d + J l S S I l d s u S h M J c G Y z P 8 m Q 6 E 5 Q z m 1 h D I t 7 K 2 E j a m m D G 0 6 J R u C t / r y O m l f 1 j y 3 5 t 1 d V R r V P I 4 i n M E 5 V M G D O j T g F p r Q A g Y j e I Z X e H O k 8 + K 8 O x / L 1 o K T z 5 z C H z i f P w J Y j Y U = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F D 6 s T j O X a R M f 6 L N D 7 2 5 Z q r H 0 e x g = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I U I 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 8 D b 1 C u u D V 3 A b J O v J x U I E d z U P 7 q D 2 O W R l w h k 9 S Y n u c m 6 G d U o 2 C S z 0 r 9 1 P C E s g k d 8 Z 6 l i k b c + N n i 1 B m 5 s M q Q h L G 2 p Z A s 1 N 8 T G Y 2 M m U a B 7 Y w o j s 2 q N x f / 8 3 o p h t d + J l S S I l d s u S h M J c G Y z P 8 m Q 6 E 5 Q z m 1 h D I t 7 K 2 E j a m m D G 0 6 J R u C t / r y O m l f 1 j y 3 5 t 1 d V R r V P I 4 i n M E 5 V M G D O j T g F p r Q A g Y j e I Z X e H O k 8 + K 8 O x / L 1 o K T z 5 z C H z i f P w J Y j Y U = &lt; / l a t e x i t &gt; w l a t e x i t s h a 1 _ b a s e 6 4 = " V F 7 q F g H 0 K v o 6 h a y d Z / M l 3 X D 0 A 3 s = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K o o M e C F 4 8 V 7 Q e 0 o W y 2 m 3 b p Z h N 2 J 0 o J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E h h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m T j V j D d Z L G P d C a j h U i j e R I G S d x L N a R R I 3 g 7 G N z O / / c i 1 E b F 6 w E n C / Y g O l Q g F o 2 i l + 6 f + R b 9 c c W v u H G S V e D m p Q I 5 G v / z V G 8 Q s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 6 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P 5 q V N y Z p U B C W N t S y G Z q 7 8 n M h o Z M 4 k C 2 x l R H J l l b y b + 5 3 V T D K / 9 T K g k R a 7 Y Y l G Y S o I x m f 1 N B k J z h n J i C W V a 2 F s J G 1 F N G d p 0 S j Y E b / n l V d I 6 r 3 l u z b u 7 r N S r e R x F O I F T q I I H V 1 C H W 2 h A E x g M 4 R l e 4 c 2 R z o v z 7 n w s W g t O P n M M f + B 8 / g A F Y I 2 H &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " V F 7 q F g H 0 K v o 6 h a y d Z / M l 3 X D 0 A 3 s = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K o o M e C F 4 8 V 7 Q e 0 o W y 2 m 3 b p Z h N 2 J 0 o J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E h h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m T j V j D d Z L G P d C a j h U i j e R I G S d x L N a R R I 3 g 7 G N z O / / c i 1 E b F 6 w E n C / Y g O l Q g F o 2 i l + 6 f + R b 9 c c W v u H G S V e D m p Q I 5 G v / z V G 8 Q s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 6 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P 5 q V N y Z p U B C W N t S y G Z q 7 8 n M h o Z M 4 k C 2 x l R H J l l b y b + 5 3 V T D K / 9 T K g k R a 7 Y Y l G Y S o I x m f 1 N B k J z h n J i C W V a 2 F s J G 1 F N G d p 0 S j Y E b / n l V d I 6 r 3 l u z b u 7 r N S r e R x F O I F T q I I H V 1 C H W 2 h A E x g M 4 R l e 4 c 2 R z o v z 7 n w s W g t O P n M M f + B 8 / g A F Y I 2 H &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " V F 7 q F g H 0 K v o 6 h a y d Z / M l 3 X D 0 A 3 s = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K o o M e C F 4 8 V 7 Q e 0 o W y 2 m 3 b p Z h N 2 J 0 o J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E h h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m T j V j D d Z L G P d C a j h U i j e R I G S d x L N a R R I 3 g 7 G N z O / / c i 1 E b F 6 w E n C / Y g O l Q g F o 2 i l + 6 f + R b 9 c c W v u H G S V e D m p Q I 5 G v / z V G 8 Q s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 6 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P 5 q V N y Z p U B C W N t S y G Z q 7 8 n M h o Z M 4 k C 2 x l R H J l l b y b + 5 3 V T D K / 9 T K g k R a 7 Y Y l G Y S o I x m f 1 N B k J z h n J i C W V a 2 F s J G 1 F N G d p 0 S j Y E b / n l V d I 6 r 3 l u z b u 7 r N S r e R x F O I F T q I I H V 1 C H W 2 h A E x g M 4 R l e 4 c 2 R z o v z 7 n w s W g t O P n M M f + B 8 / g A F Y I 2 H &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " V F 7 q F g H 0 K v o 6 h a y d Z / M l 3 X D 0 A 3 s = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K o o M e C F 4 8 V 7 Q e 0 o W y 2 m 3 b p Z h N 2 J 0 o J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E h h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m T j V j D d Z L G P d C a j h U i j e R I G S d x L N a R R I 3 g 7 G N z O / / c i 1 E b F 6 w E n C / Y g O l Q g F o 2 i l + 6 f + R b 9 c c W v u H G S V e D m p Q I 5 G v / z V G 8 Q s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 6 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P 5 q V N y Z p U B C W N t S y G Z q 7 8 n M h o Z M 4 k C 2 x l R H J l l b y b + 5 3 V T D K / 9 T K g k R a 7 Y Y l G Y S o I x m f 1 N B k J z h n J i C W V a 2 F s J G 1 F N G d p 0 S j Y E b / n l V d I 6 r 3 l u z b u 7 r N S r e R x F O I F T q I I H V 1 C H W 2 h A E x g M 4 R l e 4 c 2 R z o v z 7 n w s W g t O P n M M f + B 8 / g A F Y I 2 H &lt; / l a t e x i t &gt; w n &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z z W w 5 k 9 A 1 f x e I + g I 9 Z Q n G s 2 b d 1 w = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I U I 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 8 D N S h X 3 J q 7 A F k n X k 4 q k K M 5 K H / 1 h z F L I 6 6 Q S W p M z 3 M T 9 D O q U T D J Z 6 V + a n h C 2 Y S O e M 9 S R S N u / G x x 6 o x c W G V I w l j b U k g W 6 u + J j E b G T K P A d k Y U x 2 b V m 4 v / e b 0 U w 2 s / E y p J k S u 2 X B S m k m B M 5 n + T o d C c o Z x a Q p k W 9 l b C x l R T h j a d k g 3 B W 3 1 5 n b Q v a 5 5 b 8 + 6 u K o 1 q H k c R z u A c q u B B H R p w C 0 1 o A Y M R P M M r v D n S e X H e n Y 9 l a 8 H J Z 0 7 h D 5 z P H 1 7 M j c I = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z z W w 5 k 9 A 1 f x e I + g I 9 Z Q n G s 2 b d 1 w = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I U I 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 8 D N S h X 3 J q 7 A F k n X k 4 q k K M 5 K H / 1 h z F L I 6 6 Q S W p M z 3 M T 9 D O q U T D J Z 6 V + a n h C 2 Y S O e M 9 S R S N u / G x x 6 o x c W G V I w l j b U k g W 6 u + J j E b G T K P A d k Y U x 2 b V m 4 v / e b 0 U w 2 s / E y p J k S u 2 X B S m k m B M 5 n + T o d C c o Z x a Q p k W 9 l b C x l R T h j a d k g 3 B W 3 1 5 n b Q v a 5 5 b 8 + 6 u K o 1 q H k c R z u A c q u B B H R p w C 0 1 o A Y M R P M M r v D n S e X H e n Y 9 l a 8 H J Z 0 7 h D 5 z P H 1 7 M j c I = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z z W w 5 k 9 A 1 f x e I + g I 9 Z Q n G s 2 b d 1 w = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I U I 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 8 D N S h X 3 J q 7 A F k n X k 4 q k K M 5 K H / 1 h z F L I 6 6 Q S W p M z 3 M T 9 D O q U T D J Z 6 V + a n h C 2 Y S O e M 9 S R S N u / G x x 6 o x c W G V I w l j b U k g W 6 u + J j E b G T K P A d k Y U x 2 b V m 4 v / e b 0 U w 2 s / E y p J k S u 2 X B S m k m B M 5 n + T o d C c o Z x a Q p k W 9 l b C x l R T h j a d k g 3 B W 3 1 5 n b Q v a 5 5 b 8 + 6 u K o 1 q H k c R z u A c q u B B H R p w C 0 1 o A Y M R P M M r v D n S e X H e n Y 9 l a 8 H J Z 0 7 h D 5 z P H 1 7 M j c I = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z z W w 5 k 9 A 1 f x e I + g I 9 Z Q n G s 2 b d 1 w = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 K I U I 8 F L x 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T p Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q G W + x W M a 6 G 1 D D p V C 8 h Q I l 7 y a a 0 y i Q v B N M b u Z + 5 5 F r I 2 L 1 g N O E + x E d K R E K R t F K 9 0 8 D N S h X 3 J q 7 A F k n X k 4 q k K M 5 K H / 1 h z F L I 6 6 Q S W p M z 3 M T 9 D O q U T D J Z 6 V + a n h C 2 Y S O e M 9 S R S N u / G x x 6 o x c W G V I w l j b U k g W 6 u + J j E b G T K P A d k Y U x 2 b V m 4 v / e b 0 U w 2 s / E y p J k S u 2 X B S m k m B M 5 n + T o d C c o Z x a Q p k W 9 l b C x l R T h j a d k g 3 B W 3 1 5 n b Q v a 5 5 b 8 + 6 u K o 1 q H k c R z u A c q u B B H R p w C 0 1 o A Y M R P M M r v D n S e X H e n Y 9 l a 8 H J Z 0 7 h D 5 z P H 1 7 M j c I = &lt; / l a t e x i t &gt; + &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r Xu e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r Xu e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; + &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; + &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; + &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B 2 5 6 y N N w j w H m 0 r + c u y n G V 6 3 b F 8 E = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h I J R E B D 0 W v H h s w X 5 A G 8 p m O 2 n X b j Z h d y O U 0 F / g x Y M i X v 1 J 3 v w 3 b t s c t P X B w O O 9 G W b m B Y n g 2 r j u t 1 P Y 2 N z a 3 i n u l v b 2 D w 6 P y s c n b R 2 n i m G L x S J W 3 Y B q F F x i y 3 A j s J s o p F E g s B N M 7 u Z + 5 w m V 5 r F 8 M N M E / Y i O J A 8 5 o 8 Z K z c t B u e L W 3 A X I O v F y U o E c j U H 5 q z + M W R q h N E x Q r X u e m x g / o 8 p w J n B W 6 q c a E 8 o m d I Q 9 S y W N U P v Z 4 t A Z u b D K k I S x s i U N W a i / J z I a a T 2 N A t s Z U T P W q 9 5 c / M / r p S a 8 9 T M u k 9 S g Z M t F Y S q I i c n 8 a z L k C p k R U 0 s o U 9 z e S t i Y K s q M z a Z k Q / B W X 1 4 n 7 a u a 5 9 a 8 5 n W l X s 3 j K M I Z n E M V P L i B O t x D A 1 r A A O E Z X u H N e X R e n H f n Y 9 l a c P K Z U / g D 5 / M H a b O M l Q = = &lt; / l a t e x i t &gt; ... &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B I x u 0 A A Z w y 6 l / Z 5 K s U E G 5 W 7 R N y w = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 C I o M e C F 4 8 V 7 Q e 0 o W y 2 m 3 b p Z h N 2 J 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e m E p h 0 P O + n d L G 5 t b 2 T n m 3 s r d / c H h U P T 5 p m y T T j L d Y I h P d D a n h U i j e Q o G S d 1 P N a R x K 3 g k n t 3 O / 8 8 S 1 E Y l 6 x G n K g 5 i O l I g E o 2 i l B 9 d 1 B 9 W a 5 3 o L k H X i F 6 Q G B Z q D 6 l d / m L A s 5 g q Z p M b 0 f C / F I K c a B Z N 8 V u l n h q e U T e i I 9 y x V N O Y m y B e n z s i F V Y Y k S r Q t h W S h / p 7 I a W z M N A 5 t Z 0 x x b F a 9 u f i f 1 8 s w u g l y o d I M u W L L R V E m C S Z k / j c Z C s 0 Z y q k l l G l h b y V s T D V l a N O p 2 B D 8 1 Z f X S f v S 9 T 3 X v 7 + q N e p F H G U 4 g 3 O o g w / X 0 I A 7 a E I L G I z g G V 7 h z Z H O i / P u f C x b S 0 4 x c w p / 4 H z + A E Q S j Q g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B I x u 0 A A Z w y 6 l / Z 5 K s U E G 5 W 7 R N y w = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 C I o M e C F 4 8 V 7 Q e 0 o W y 2 m 3 b p Z h N 2 J 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e m E p h 0 P O + n d L G 5 t b 2 T n m 3 s r d / c H h U P T 5 p m y T T j L d Y I h P d D a n h U i j e Q o G S d 1 P N a R x K 3 g k n t 3 O / 8 8 S 1 E Y l 6 x G n K g 5 i O l I g E o 2 i l B 9 d 1 B 9 W a 5 3 o L k H X i F 6 Q G B Z q D 6 l d / m L A s 5 g q Z p M b 0 f C / F I K c a B Z N 8 V u l n h q e U T e i I 9 y x V N O Y m y B e n z s i F V Y Y k S r Q t h W S h / p 7 I a W z M N A 5 t Z 0 x x b F a 9 u f i f 1 8 s w u g l y o d I M u W L L R V E m C S Z k / j c Z C s 0 Z y q k l l G l h b y V s T D V l a N O p 2 B D 8 1 Z f X S f v S 9 T 3 X v 7 + q N e p F H G U 4 g 3 O o g w / X 0 I A 7 a E I L G I z g G V 7 h z Z H O i / P u f C x b S 0 4 x c w p / 4 H z + A E Q S j Q g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B I x u 0 A A Z w y 6 l / Z 5 K s U E G 5 W 7 R N y w = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 C I o M e C F 4 8 V 7 Q e 0 o W y 2 m 3 b p Z h N 2 J 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e m E p h 0 P O + n d L G 5 t b 2 T n m 3 s r d / c H h U P T 5 p m y T T j L d Y I h P d D a n h U i j e Q o G S d 1 P N a R x K 3 g k n t 3 O / 8 8 S 1 E Y l 6 x G n K g 5 i O l I g E o 2 i l B 9 d 1 B 9 W a 5 3 o L k H X i F 6 Q G B Z q D 6 l d / m L A s 5 g q Z p M b 0 f C / F I K c a B Z N 8 V u l n h q e U T e i I 9 y x V N O Y m y B e n z s i F V Y Y k S r Q t h W S h / p 7 I a W z M N A 5 t Z 0 x x b F a 9 u f i f 1 8 s w u g l y o d I M u W L L R V E m C S Z k / j c Z C s 0 Z y q k l l G l h b y V s T D V l a N O p 2 B D 8 1 Z f X S f v S 9 T 3 X v 7 + q N e p F H G U 4 g 3 O o g w / X 0 I A 7 a E I L G I z g G V 7 h z Z H O i / P u f C x b S 0 4 x c w p / 4 H z + A E Q S j Q g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B I x u 0 A A Z w y 6 l / Z 5 K s U E G 5 W 7 R N y w = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 C I o M e C F 4 8 V 7 Q e 0 o W y 2 m 3 b p Z h N 2 J 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e m E p h 0 P O + n d L G 5 t b 2 T n m 3 s r d / c H h U P T 5 p m y T T j L d Y I h P d D a n h U i j e Q o G S d 1 P N a R x K 3 g k n t 3 O / 8 8 S 1 E Y l 6 x G n K g 5 i O l I g E o 2 i l B 9 d 1 B 9 W a 5 3 o L k H X i F 6 Q G B Z q D 6 l d / m L A s 5 g q Z p M b 0 f C / F I K c a B Z N 8 V u l n h q e U T e i I 9 y x V N O Y m y B e n z s i F V Y Y k S r Q t h W S h / p 7 I a W z M N A 5 t Z 0 x x b F a 9 u f i f 1 8 s w u g l y o d I M u W L L R V E m C S Z k / j c Z C s 0 Z y q k l l G l h b y V s T D V l a N O p 2 B D 8 1 Z f X S f v S 9 T 3 X v 7 + q N e p F H G U 4 g 3 O o g w / X 0 I A 7 a E I L G I z g G V 7 h z Z H O i / P u f C x b S 0 4 x c w p / 4 H z + A E Q S j Q g = &lt; / l a t e x i t &gt; Perspective point estimation. (a) The perspective points are estimated by a mixture of templates through a linear combination. Each template encodes geometric cues including orientations and viewpoints. (b)The perspective loss enforces each set of 2D perspective points to be the perspective projection of a (vertical) 3D cuboid. For a vertical cuboid, the projected vertical edges (i.e., ae, bf , cg, and dh) should be parallel or near parallel (under small camera tilting angles). For 3D parallel lines that are perpendicular to the gravity direction, the vanishing points of their 2D projections should coincide (e.g., u1 and u2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 :</head><label>4</label><figDesc>Qualitative results (top 50%). For every three columns as a group: (Left) The RGB image with 2D detection results. (Middle) The RGB image with estimated perspective points. (Right) The results in 3D point cloud; point cloud is used for visualization only.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Heatmaps vs. templates for perspective point prediction. (Left) Estimated by heatmap-based method. (Right) Estimated by the proposed template-based method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Some failure cases. The perspective point estimation and the 3D box estimation fail at the same time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>,050 are test images. It has a rich annotation of scene categories, camera pose, and 3D bounding boxes. We evaluate the 3D object detection results of the proposed PerspectiveNet, make comparisons with the state-of-the-art methods, and further examine the contribution of each module in ablative experiments.</figDesc><table><row><cell></cell><cell>Bed</cell><cell></cell><cell>Chair</cell><cell></cell><cell>Sofa</cell><cell></cell><cell>Table</cell><cell></cell><cell>Desk</cell></row><row><cell>Precision</cell><cell></cell><cell>Precision</cell><cell></cell><cell>Precision</cell><cell></cell><cell>Precision</cell><cell></cell><cell>Precision</cell><cell></cell></row><row><cell></cell><cell>Recall</cell><cell></cell><cell>Recall</cell><cell></cell><cell>Recall</cell><cell></cell><cell>Recall</cell><cell></cell><cell>Recall</cell></row><row><cell></cell><cell>Toilet</cell><cell></cell><cell>Bin</cell><cell></cell><cell>Sink</cell><cell></cell><cell>Shelf</cell><cell></cell><cell>Lamp</cell></row><row><cell>Precision</cell><cell>Recall</cell><cell>Precision</cell><cell>Recall</cell><cell>Precision</cell><cell>Recall</cell><cell>Precision</cell><cell>Recall</cell><cell>Precision</cell><cell>Recall</cell></row><row><cell></cell><cell></cell><cell cols="7">Figure 5: Precision-Recall (PR) curves for 3D object detection on SUN RGB-D</cell><cell></cell></row><row><cell cols="3">5 Experiments</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">Dataset We conduct comprehensive experiments on SUN RGB-D [46] dataset. The SUN RGB-D</cell></row><row><cell cols="5">dataset has a total of 10,335 images, in which 5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Comparisons of 3D object detection on SUN RGB-D (AP). 13.56 28.37 12.12 4.79 16.50 0.63 2.18 1.29 2.41 14.01 CooP [36] 63.58 17.12 41.22 26.21 9.55 58.55 10.19 5.34 3.01 1.75 23.65 Ours (w/o. cam) 71.39 34.94 55.63 34.10 14.23 73.73 17.47 34.41 4.21 9.54 34.96 Ours (full) 79.69 40.42 62.35 44.12 20.19 81.22 22.42 41.35 8.29 13.14 39.09</figDesc><table><row><cell></cell><cell cols="4">bed chair sofa table desk toilet bin</cell><cell cols="4">sink shelf lamp mAP</cell></row><row><cell>3DGP [49]</cell><cell>5.62 2.31 3.24 1.23</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>HoPR [38]</cell><cell>58.29</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Ablative analysis of the proposed model on SUN RGB-D. We evaluate the mAP for 3D object detection.</figDesc><table><row><cell>Setting</cell><cell>S 1</cell><cell>S 2</cell><cell>S 3</cell><cell>S 4</cell><cell>S 5</cell><cell>S 6</cell><cell>Full</cell></row><row><cell>mAP</cell><cell>35.23</cell><cell>38.63</cell><cell>38.87</cell><cell>39.01</cell><cell>37.43</cell><cell>32.97</cell><cell>39.09</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments This work reported herein is supported by MURI ONR N00014-16-1-2007, DARPA XAI N66001-17-2-4029, ONR N00014-19-1-2153, and an NVIDIA GPU donation grant.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Vision: A computational investigation into the human representation and processing of visual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Marr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>WH Freeman</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Visual pattern discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bela</forename><surname>Julesz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="84" to="92" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Filters, random fields and maximum entropy (frame): Towards a unified theory for texture modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingnian</forename><surname>Song Chun Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="126" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Textons, the elements of texture perception, and their interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bela</forename><surname>Julesz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5802</biblScope>
			<biblScope unit="page">91</biblScope>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">What are textons?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Song-Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheng-En</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="121" to="143" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards a mathematical theory of primal sketch and sketchability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Cheng-En Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying Nian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Cheng-En Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying Nian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
		<title level="m">Primal sketch: Integrating structure and texture. Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="5" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The 2.1-d sketch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Nitzberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Layered representation for motion analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">A</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Edward H Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Representing moving images with layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">A</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Edward H Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="625" to="638" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Representation and recognition of the spatial organization of three-dimensional shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><forename type="middle">Keith</forename><surname>Nishihara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Royal Society of London. Series B. Biological Sciences</title>
		<meeting>the Royal Society of London. Series B. Biological Sciences</meeting>
		<imprint>
			<date type="published" when="1140" />
			<biblScope unit="volume">200</biblScope>
			<biblScope unit="page" from="269" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual perception by computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Binford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference of Systems and Control</title>
		<imprint>
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Symbolic reasoning among 3-d models and 2-d images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rodney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="285" to="348" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recovery of the three-dimensional shape of an object from a single view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="409" to="460" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A question of levels: Comment on McClelland and Rumelhart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Broadbent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<publisher>American Psychological Association</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Experimentelle studien uber das sehen von bewegung [experimental studies on the seeing of motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Wertheimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zeitschrift fur Psychologie</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="161" to="265" />
			<date type="published" when="1912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A century of gestalt psychology in visual perception: I. perceptual grouping and figure-ground organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Wagemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kubovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">A</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?diger Von Der</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heydt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1172</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A century of gestalt psychology in visual perception: Ii. conceptual and theoretical foundations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Wagemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergei</forename><surname>Gepshtein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Kimchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pomerantz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cees</forename><surname>Van Der Helm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Leeuwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1218</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Die physischen Gestalten in Ruhe und im station?renZustand. Eine naturphilosophische Untersuchung</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>K?hler</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>The physical Gestalten at rest and in steady state</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germany</forename><surname>Braunschweig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1920" />
			<publisher>Vieweg und Sohn</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Physical gestalten</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>K?hler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A source book of Gestalt psychology</title>
		<editor>Routledge &amp; Kegan Paul</editor>
		<meeting><address><addrLine>London, England</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1938" />
			<biblScope unit="page" from="17" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Untersuchungen zur lehre von der gestalt, ii</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Wertheimer</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>investigations in gestalt theory: Ii. laws of organization in perceptual forms</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Psychologische Forschung</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="301" to="350" />
			<date type="published" when="1923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Laws of organization in perceptual forms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Wertheimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A source book of Gestalt psychology</title>
		<editor>Routledge &amp; Kegan Paul</editor>
		<meeting><address><addrLine>London, England</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1938" />
			<biblScope unit="page" from="71" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Principles of Gestalt psychology. Routledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Koffka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Perceptual organization and visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lowe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Perceptual organization and the representation of natural form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">P</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Readings in Computer Vision</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="680" to="699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Understanding line drawings of scenes with shadows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Waltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The psychology of computer vision</title>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Interpreting line drawings as three-dimensional surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Harry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><forename type="middle">M</forename><surname>Barrow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="75" to="116" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Three-dimensional object recognition from single two-dimensional images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="355" to="395" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Manhattan world: Orientation and outlier detection by bayesian inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Coughlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Manhattan world: Compass direction from a single image by bayesian inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Coughlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Monocular 3d object detection for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaustav</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huimin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">3d bounding box estimation using deep learning and geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arsalan</forename><surname>Mousavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Ko?eck?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Cooperative holistic scene understanding: Unifying 3d object, layout, and camera pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinxue</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><forename type="middle">Nian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">3d-rcnn: Instance-level 3d object reconstruction via render-and-compare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhijit</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Holistic 3d scene parsing and reconstruction from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinxue</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">3d-aware scene manipulation via inverse graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunyu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Tzu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Mono3d++: Monocular 3d vehicle detection with two-scale 3d hypotheses and task priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.03446</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Reconstructing the world&apos;s museums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasutaka</forename><surname>Furukawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Roomnet: End-to-end room layout estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Yu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Layoutnet: Reconstructing the 3d room layout from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuhang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Colburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Hoiem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Discovery of latent 3d keypoints via end-to-end geometric reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Supasorn</forename><surname>Suwajanakorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Sun rgb-d: A rgb-d scene understanding benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Lichtenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Image parsing with stochastic scene grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scene parsing by integrating function, geometry and appearance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Understanding indoor scenes using 3d geometric phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wei</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Pantofaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Holistic scene understanding for 3d object detection with rgbd cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Panocontext: A whole-room 3d context model for panoramic scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Izadinia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Im2cad</surname></persName>
		</author>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Multi-level fusion based 3d object detection from monocular images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Sanja Fidler, and Raquel Urtasun. 3d object proposals for accurate object class detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaustav</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huimin</forename><surname>Berneshawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A mixture of manhattan frames: Beyond the manhattan world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Straub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Rosman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Freifeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">W</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Atlanta world: An expectation maximization framework for simultaneous low-level edge grouping and camera calibration in complex man-made environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grant</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Dellaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Joint vanishing point extraction and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Till</forename><surname>Kroeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Vanishing points and threedimensional lines from omni-directional video. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Rikoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Teller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Real-time manhattan world rotation estimation in 3d</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Straub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishchal</forename><surname>Bhandari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">W</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Robust manhattan frame estimation from a single rgb-d image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian Caba</forename><surname>Heilbron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Recovering the spatial layout of cluttered rooms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varsha</forename><surname>Hedau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Geometric reasoning for single image structure recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David C Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Thinking inside the box: Using appearance models and context based on room geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varsha</forename><surname>Hedau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Efficient structured prediction for 3d indoor scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamir</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Automatic single-image 3d reconstructions of indoor manhattan world scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erick</forename><surname>Delage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics Research</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="305" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Manhattan-world stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasutaka</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Basic level scene understanding: categories, attributes and structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genevieve</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krista</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">506</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Three-dimensional object detection and layout prediction using clouds of oriented gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhile</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">B</forename><surname>Sudderth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Single-view 3d scene reconstruction and parsing by attribute grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="710" to="725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Marrnet: 3d shape reconstruction via 2.5 d sketches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyuan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Visual object networks: Image generation with disentangled 3d representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoutong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Learning to reconstruct shapes from unseen classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiuming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoutong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Factoring shape, pose, and layout from the 2d image of a 3d scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubham</forename><surname>Tulsiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fouhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Single image 3d interpreter network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Real-time seamless single shot 6d object pose prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bugra Tekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sudipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Emergence of simple-cell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bruno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David J</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="issue">6583</biblScope>
			<biblScope unit="page">607</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Learning active basis model for object detection and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangzhang</forename><surname>Ying Nian Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="198" to="235" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Unsupervised learning of 3d structure from images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Heess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Perspective transformer nets: Learning single-view 3d object reconstruction without 3d supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijie</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">maskrcnn-benchmark: Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<ptr target="https://github.com/facebookresearch/maskrcnn-benchmark" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Vision meets robotics: The kitti dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Robotics Research (IJRR)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1231" to="1237" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
