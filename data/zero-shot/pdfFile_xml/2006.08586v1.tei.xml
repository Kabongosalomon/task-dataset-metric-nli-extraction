<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Coherent Reconstruction of Multiple Humans from a Single Image</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Jiang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Coherent Reconstruction of Multiple Humans from a Single Image</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input image</head><p>Baseline Ours <ref type="figure">Figure 1</ref>: Coherent reconstruction of pose and shape for multiple people. Typical top-down regression baselines (center) suffer from predicting people in overlapping positions, or in inconsistent depth orderings. Our approach (right) is trained to respect all these constraints and recover a coherent reconstruction of all the people in the scene in a feedforward manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In this work, we address the problem of multi-person 3D pose estimation from a single image. A typical regression approach in the top-down setting of this problem would first detect all humans and then reconstruct each one of them independently. However, this type of prediction suffers from incoherent results, e.g., interpenetration and inconsistent depth ordering between the people in the scene. Our goal is to train a single network that learns to avoid these problems and generate a coherent 3D reconstruction of all the humans in the scene. To this end, a key design choice is the incorporation of the SMPL parametric body model in our top-down framework, which enables the use of two novel losses. First, a distance fieldbased collision loss penalizes interpenetration among the reconstructed people. Second, a depth ordering-aware loss reasons about occlusions and promotes a depth ordering of people that leads to a rendering which is consistent with the annotated instance segmentation. This provides depth supervision signals to the network, even if the image has no explicit 3D annotations. The experiments show that our approach outperforms previous methods on standard 3D pose benchmarks, while our proposed losses enable more coherent reconstruction in natural images. The project website with videos, results, and code can be found at: https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recent work has achieved tremendous progress on the frontier of 3D human analysis tasks. Current approaches * Equal contribution. ? X. <ref type="bibr">Zhou</ref>  have established impressive performance for 3D keypoint estimation <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b56">57]</ref>, 3D shape reconstruction <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b61">62]</ref>, fullbody 3D pose and shape recovery <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b42">43]</ref>, or even going beyond that and estimating more detailed and expressive reconstructions <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b62">63]</ref>. However, as we progress towards more holistic understanding of scenes and people interacting in them, a crucial step is the coherent 3D reconstruction of multiple people from single images.</p><p>Regarding multi-person pose estimation, on one end of the spectrum, we have bottom-up approaches. The works following this paradigm, first detect all body joints in the scene and then group them, i.e., assigning them to the appropriate person. However, it is not straightforward how bottom-up processing can be extended beyond joints (e.g., use it for shape estimation, or mesh recovery). Different from bottom-up, top-down approaches first detect all people in the scene, and then estimate the pose for each one of them. Although they take a hard decision early on (person detection), they typically rely on state-of-the-art methods for person detection and pose estimation which allows them to achieve very compelling results, particularly in the 2D pose case, e.g., <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b63">64]</ref>. However, when reasoning about the pose of multiple people in 3D, the problems can be more complicated than in 2D. For example, the reconstructed people can overlap each other in the 3D space, or be estimated at depths that are inconsistent with the actual depth ordering, as is demonstrated in <ref type="figure">Figure 1</ref>. This means that it is crucial to go beyond just predicting a reasonable 3D pose for each person individually, and instead estimate a coherent reconstruction of all the people in the scene.</p><p>This coherency of the holistic scene is the primary goal of this work. We adopt the typical top-down paradigm, and our aim is to train a deep network that learns to estimate a coherent reconstruction of all the people in the scene. Start- Instance segmentation H ol is tic R en de rin g C ol lis io n Av oi da nc e Detections <ref type="figure">Figure 2</ref>: Overview of the proposed approach. We design an end-to-end framework for 3D pose and shape estimation of multiple people from a single image. An R-CNN-based architecture <ref type="bibr" target="#b18">[19]</ref> detects all people in the image and estimates their SMPL parameters <ref type="bibr" target="#b33">[34]</ref>. During training we incorporate constraints to promote a coherent reconstruction of all the people in the scene. First, we use an interpenetration loss to avoid people overlapping each other. Second, we apply a depth ordering-aware loss by rendering the meshes of all the people to the image and encouraging the rendered instance segmentation to match with the annotated instance masks.</p><p>ing with a framework that follows the R-CNN pipeline <ref type="bibr" target="#b47">[48]</ref>, a key decision we make is to use of the SMPL parametric model <ref type="bibr" target="#b33">[34]</ref> as our representation, and add a SMPL estimation branch to the R-CNN. The mesh representation provided by SMPL allows us to reason about occlusions and interpenetrations enabling the incorporation of two novel losses towards coherent 3D reconstruction. First, a common problem of predictions from regression networks is that the reconstructed people often overlap each other, since the feedforward nature does not allow for holistic feedback on the potential intersections. To train a network that learns to avoid this type of collisions, we introduce an interpenetration loss that penalizes intersections among the reconstructed people. This term requires no annotations and relies on a simple property of natural scenes, i.e., that people cannot intersect each other. Besides collisions, another source of incoherency in the results is that the estimated depths of the meshes are not respecting the actual depth ordering of the humans in the scene. Equipped with a mesh representation, we render our holistic scene prediction on the 2D image plane and penalize discrepancies of this rendering from the annotated instance segmentation. This loss enables reasoning about occlusion, encouraging the depth ordering of the people in the scene to be consistent with the annotated instance masks. Our complete framework <ref type="figure">(Figure</ref> 2) is evaluated on various benchmarks and outperforms previous multi-person 3D pose and shape approaches, while the proposed losses improve coherency of the holistic result both qualitatively and quantitatively.</p><p>To summarize, our main contributions are:</p><p>? We present a complete framework for coherent regression of 3D pose and shape for multiple people.</p><p>? We train with an interpenetration loss to avoid regress-ing meshes that intersect each other.</p><p>? We train with a depth ordering-aware loss to promote reconstructions that respect the depth ordering of the people in the scene.</p><p>? We outperfrom previous approaches for multi-person 3D pose and shape, while recovering significantly more coherent results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>In this Section we provide a short description of prior works that are more relevant to ours.</p><p>Single-person 3D pose and shape: Many recent works estimate 3D pose in the form of a skeleton, e.g., <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b66">67]</ref>, or 3D shape in a non-parmetric way, e.g., <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b61">62]</ref>. However, here we focus on full-body pose and shape reconstruction in the form of a mesh, typically using a parametric model, like SMPL <ref type="bibr" target="#b33">[34]</ref>. After the early works on the problem <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b51">52]</ref>, the first fully automatic approach, SMPLify, was proposed by Bogo et al. <ref type="bibr" target="#b3">[4]</ref>. SMPLify iteratively fits SMPL on the 2D joints detected by a 2D pose estimation network <ref type="bibr" target="#b45">[46]</ref>. This optimization approach was later extended in multiple ways; Lassner et al. <ref type="bibr" target="#b30">[31]</ref> use silhouettes for the fitting, Varol et al. <ref type="bibr" target="#b61">[62]</ref> use voxel occupancy grids, while Pavlakos et al. <ref type="bibr" target="#b41">[42]</ref> fit a more expressive parametric model, SMPL-X.</p><p>Despite the success of the aforementioned fitting approaches, recently we have observed an increased interest in approaches that regress the pose and shape parameters directly from images, using a deep network for this task. Many works focus on first estimating some form of intermediate representation before regressing SMPL parameters. Pavlakos et al. <ref type="bibr" target="#b44">[45]</ref> use keypoints and silhouettes, Omran et al. <ref type="bibr" target="#b40">[41]</ref> use semantic part segmentation, Tung et al. <ref type="bibr" target="#b60">[61]</ref> append heatmaps for 2D joints to the RGB input, while Kolotouros et al. <ref type="bibr" target="#b28">[29]</ref> regress the mesh vertices with a Graph CNN. Regressing SMPL parameters directly from RGB input is more challenging, but it avoids any handdesigned bottleneck. Kanazawa et al. <ref type="bibr" target="#b25">[26]</ref> use an adversarial prior to penalize improbable 3D shapes during training. Arnab et al. <ref type="bibr" target="#b2">[3]</ref> use temporal context to improve the regression network. G?ler et al. <ref type="bibr" target="#b14">[15]</ref> incorporate a test-time postprocessing based on 2D/3D keypoints and DensePose <ref type="bibr" target="#b15">[16]</ref>.</p><p>Multi-person 3D pose: For the multi-person case, the top-down paradigm is quite popular for 3D pose estimation, since it capitalizes on the success of the R-CNN works <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b18">19]</ref>. The LCR-Net approaches <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref> first detect each person, then classify its pose in a pose cluster and finally regress an offset for each joint. Dabral et al. <ref type="bibr" target="#b9">[10]</ref> first estimate 2D joints inside the bounding box and then regress 3D pose. Moon et al. <ref type="bibr" target="#b39">[40]</ref> contribute a root network to give an estimate of the depth of the root joint. Zanfir et al. <ref type="bibr" target="#b64">[65]</ref> rely on scene constraints to iteratively optimize the 3D pose and shape of the people in the scene. Alternatively, there are also approaches that follow the bottom-up paradigm. Mehta et al. <ref type="bibr" target="#b37">[38]</ref> propose a formulation based on occlusion-robust pose-maps, where Part Affinity Fields <ref type="bibr" target="#b5">[6]</ref> are used for the association problem. Follow-up work <ref type="bibr" target="#b36">[37]</ref>, improves, among others, the robustness of the system. Finally, Zanfir et al. <ref type="bibr" target="#b65">[66]</ref> solve a binary integer linear program to perform skeleton grouping.</p><p>In the context of pose and shape estimation in particular, there is a limited number of works that estimate full-body 3D pose and shape for multiple people in the scene. Zanfir et al. <ref type="bibr" target="#b64">[65]</ref> optimize the 3D shape of all the people in the image using multiple scene constraints. Our approach draws inspiration from this work and shares the same goal, in the sense of recovering a coherent 3D reconstruction. In contrast to them, instead of optimizing for this coherency at test-time, we train a feedforward regressor and use the scene constraints at training time to encourage it to produce coherent estimates at test-time. Using a feedforward network to estimate pose and shape for multiple people has been proposed by the work of Zanfir et al. <ref type="bibr" target="#b65">[66]</ref>. However, in that case, 3D shape is regressed based on 3D joints, which are the output of a bottom-up system. In contrast, our approach is top-down, and SMPL parameters are regressed directly from pixels, instead of using an intermediate representation, like 3D joints. In fact, it is non-trivial to design a framework for SMPL parameter regression in a bottom-up manner.</p><p>Coherency constraints: An important aspect of our work is the incorporation of loss terms that promote coherent 3D reconstruction of the multiple humans. Regarding our interpenetration loss, Bogo et al. <ref type="bibr" target="#b3">[4]</ref> and Pavlakos et al. <ref type="bibr" target="#b41">[42]</ref> use a relevant objective to avoid selfinterpenetrations of the human under consideration. In a more similar spirit to us, Zanfir et al. <ref type="bibr" target="#b64">[65]</ref> use a volume occupancy loss to avoid humans intersecting each other. In different applications, Hasson et al. <ref type="bibr" target="#b17">[18]</ref> penalize interpenetrations between the object and the hand that interacts with it, while Hassan et al. <ref type="bibr" target="#b16">[17]</ref> penalize interpenetrations between humans and their environment. The majority of the above works uses the interpenetration penalty to iteratively refine estimates at test-time. With the exception of <ref type="bibr" target="#b17">[18]</ref>, our work is the only one that uses an interpenetration term to guide the training of a feedforward regressor and promote colliding-free reconstructions at test time.</p><p>Regarding our depth ordering-aware loss, we follow the formulation of Chen et al. <ref type="bibr" target="#b7">[8]</ref>, which was also used in the context of 3D human pose by Pavlakos et al. <ref type="bibr" target="#b43">[44]</ref>. In contrast to them, we do not use explicit depth annotations, but instead, we leverage the instance segmentation masks to reason about occlusion and thus, depth ordering. The work of Rhodin et al. <ref type="bibr" target="#b48">[49]</ref> is also relevant, where inferring depth ordering is used as an intermediate abstraction for scene decomposition from multiple views. Our work also aims to estimate a coherent depth ordering, but we do so from a single image with the guidance of instance segmentation, while we retain a more explicit human representation in terms of meshes. Finally, using instance segmentation via render and compare has also been proposed by Kundu et al. <ref type="bibr" target="#b29">[30]</ref>. However, their multi-instance evaluation includes only rigid objects, specifically cars, whereas we investigate the, significantly more complex, non-rigid case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Technical approach</head><p>In this Section, we describe the technical approach followed in this work. We start with providing some information about the SMPL model (Subsection 3.1) and the baseline regional architecture we use (Subsection 3.2). Then we describe in detail our proposed losses promoting interpenetration-free reconstruction (Subsection 3.3) and consistent depth ordering (Subsection 3.4). Finally, we provide more implementation details (Subsection 3.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">SMPL parametric model</head><p>For the human body representation, we use the SMPL parametric model of the human body <ref type="bibr" target="#b33">[34]</ref>. What makes SMPL very appropriate for our work, in comparison with other representations, is that it allows us to reason about occlusion and interpenetration enabling the use of the novel losses we incorporate in the training of our network. The SMPL model defines a function M(?, ?) that takes as input the pose parameters ?, and the shape parameters ?, and outputs a mesh M ? R Nv?3 , consisting of N v = 6890 vertices. The model also offers a convenient mapping from mesh vertices to k body joints J, through a linear regressor W , such that joints can be expressed as a linear combination of mesh vertices, J = W M . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Baseline architecture</head><p>In terms of the architecture for our approach, we follow the familiar R-CNN framework <ref type="bibr" target="#b47">[48]</ref>, and use a structure that is most similar to the Mask R-CNN iteration <ref type="bibr" target="#b18">[19]</ref>. Our network consists of a backbone (here ResNet50 <ref type="bibr" target="#b19">[20]</ref>), a Region Proposal Network, as well as heads for detection and SMPL parameter regression (SMPL branch). Regarding the SMPL branch, its architecture is similar to the iterative regressor proposed by Kanazawa et al. <ref type="bibr" target="#b25">[26]</ref>, regressing pose and shape parameters, ? and ? respectively, as well as camera parameters ? = {s, t x , t y }. The camera parameters are predicted per bounding box but we later update them based on the position of the bounding box in the full image (details in the Sup.Mat.). Although there is no explicit feedback among bbox predictions, the receptive field of each proposal includes the majority of the scene. Since each bounding box is aware of neighboring people and their poses, it can make an informed pose prediction that is consistent with them.</p><p>For our baseline network, the various components are trained jointly in an end-to-end manner. The detection task is trained according to the training procedure of <ref type="bibr" target="#b18">[19]</ref>, while for the SMPL branch, the training details are similar to the ones proposed by Kanazawa et al. <ref type="bibr" target="#b25">[26]</ref>. In the rare cases that 3D ground truth is available, we apply a loss, L 3D , on the SMPL parameters and the 3D keypoints. In the most typical case that only 2D joints are available, we use a 2D reprojection loss, L 2D , to minimize the distance between the ground truth 2D keypoints and the projection of the 3D joints, J, to the image. Additionally, we also use a discriminator and apply an adversarial prior L adv on regressed pose and shape parameters, to encourage the output bodies to lie on the manifold of human bodies. Each of the above losses is applied independently to each proposal, after assigning it to the corresponding ground truth bounding box. More details about the above loss terms and the training of the baseline model are included in the Sup.Mat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Interpenetration loss</head><p>A critical barrier towards coherent reconstruction of multiple people from a single image is that the regression net-work can often predict the people to be in overlapping locations. To promote prediction of non-colliding people, we introduce a loss that penalizes interpenetrations among the reconstructed people. Our formulation draws inspiration from <ref type="bibr" target="#b16">[17]</ref>. An important difference is that instead of a static scene and a single person, our scene includes multiple people and it is generated in a dynamic way during training.</p><p>Let ? be a modified Signed Distance Field (SDF) for the scene that is defined as follows:</p><formula xml:id="formula_0">?(x, y, z) = ? min (SDF(x, y, z), 0) ,<label>(1)</label></formula><p>According to the above definition, inside each human, ? takes positive values, proportional to the distance from the surface, while it is simply 0 outside of the human. Typically, ? is defined on a voxel grid of dimensions N p ? N p ? N p . The na?ve generation of a single voxelized representation for the whole scene is definitely possible. However, we often require a very fine voxel grid, which depending on the extend of the scene, might make processing intractable in terms of memory and computation. One critical observation here is that we can compute a separate ? i function for each person in the scene, by calculating a tight box around the person and voxelizing it. This allows us to ignore empty scene space that is not covered by any person and we can instead use a fine spatial resolution to get a detailed voxelization of the body. Using this formulation, the collision penalty of person j for colliding with person i is defined as:</p><formula xml:id="formula_1">P ij = v?Mj? i (v),<label>(2)</label></formula><p>where? i (v) samples the ? i value for each 3D vertex v in a differentiable way from the 3D grid using trilinear interpolation ( <ref type="figure" target="#fig_1">Figure 3</ref>). The ? i computation for person i is performed by a custom GPU implementation. This computation does not have to be differentiable; ? i only defines a distance field from which we sample values in a differentiable way. By definition, P ij is non-negative. It takes value 0 if there is no collision between person i and j and increases as the distance of the surface vertices for person j move farther from the surface of person i. In theory, P ij can be used by itself as an optimization objective for interpenetration avoidance. However, in practice, we observed that it results in very large gradients for the person translation, leading to training instabilities when there are heavy collisions. Instead of the typical term, we use a robust version of this objective. More specifically, our final interpenetration loss for a scene with N people is defined as follows:</p><formula xml:id="formula_2">L P = N j=1 ? ? ? N i=1,i =j P ij ? ?<label>(3)</label></formula><p>where ? is the Geman-McClure robust error function <ref type="bibr" target="#b11">[12]</ref>.</p><p>To avoid penalizing intersections between boxes corre- <ref type="figure">Figure 4</ref>: Illustration of depth ordering-aware loss. For an RGB image (first image), we consider the annotated instance segmentation (second image), and the instances based on the rendering of the estimated meshes on the image plane (third image). In case that there is a disagreement between the person index, e.g., for pixel p, where y(p) =?(p), we penalize the corresponding depth estimates at this pixel with an ordinal depth loss. The pixel depths D y(p) (p) and D? (p) (p) are estimated by rendering the depth map independently for each person mesh (fourth and fifth image). This allows gradients to be backpropagated even to the non-visible vertices.</p><p>sponding to the same person, we use only the most confidence box proposal assigned to a ground truth box.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Depth ordering-aware loss</head><p>Besides interpenetration, another common problem in multi-person 3D reconstruction is that people are often estimated in incorrect depth order. This problem is more evident in cases where people overlap on the 2D image plane. Although it is obvious to the human eye which person is closer (due to the occlusion), the network predictions can still be incoherent. Fixing this depth ordering problem would be easy if we had access to pixel-level depth annotations. However, this type of annotations is rarely available.</p><p>Our key idea here is that we can leverage the instance segmentation annotations that are often available, e.g., in the large scale COCO dataset <ref type="bibr" target="#b31">[32]</ref>. Rendering the meshes of all the reconstructed people on the image plane can indicate the person corresponding to each pixel and optimize based on the agreement with the annotated instance annotation.</p><p>Although this idea sounds straightforward, its realization is more complicated. An obvious implementation would be to use a differentiable renderer, e.g., the Neural Mesh Renderer (NMR) <ref type="bibr" target="#b26">[27]</ref>, and penalize inconsistencies between the actual instance segmentation and the one produced by rendering the meshes to the image. The practical problem with <ref type="bibr" target="#b26">[27]</ref> is that it backpropagates errors only to visible mesh vertices; if there is a depth ordering error, it will not promote the invisible vertices to move closer to the camera. In practice, we observed that this tends to move most people farther away, collapsing our training. Liu et al. <ref type="bibr" target="#b32">[33]</ref> attempt to address this problem, but we observed that their softmax operation across the depths can result in vanishing gradients, while we also faced numerical instabilities.</p><p>Instead of rendering only the semantic segmentation of the scene, we also render the depth image D i for each person independently using NMR <ref type="bibr" target="#b26">[27]</ref>. Assuming the scene has N people, we assign a unique index i ? {1, 2, . . . , N } to each one of them. Let y(p) be the person index at pixel location p in the ground truth segmentation, and?(p) be the predicted person index based on the rendering of the 3D meshes. We use 0 to indicate background pixels. If for a pixel p the two estimates indicate a person (no background) and disagree, i.e., y(p) =?(p), then we apply a loss to the depth values of both people for this pixel, y(p) and?(p), to promote the correct depth ordering. The loss we apply is an ordinal depth loss, similar in spirit to <ref type="bibr" target="#b7">[8]</ref>. More specifically, the complete loss expression is:</p><formula xml:id="formula_3">L D = p?S log 1 + exp D y(p) (p) ? D? (p) (p)<label>(4)</label></formula><p>where S = {p ? I : y(p) &gt; 0,?(p) &gt; 0, y(p) =?(p)} represents the set of pixels for image I where we have depth ordering mistakes <ref type="figure">(Figure 4</ref>). The key detail here is that the loss is backpropagated to the mesh (and eventually the model parameters) of both people, instead of backpropagating gradients only to the visible person, as a conventional differentiable renderer would do. This promotes a more symmetric nature to the loss (and the updates), and eventually makes this loss practical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Implementation details</head><p>Our implementation is done using PyTorch and the publicly available mmdetection library <ref type="bibr" target="#b6">[7]</ref>. We resize all input images to 512x832, keeping the same aspect ratio as in the original COCO training. For the baseline model we train only with the losses specified in Subsection 3.2, while for our full model we include in our training the losses proposed in Subsections 3.3 and 3.4. Our training uses 2 1080Ti GPUs and a batch size of 4 images per GPU.</p><p>For the SDF computation, we reimplemented <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref> in CUDA. Voxelizing a single mesh in a 32 ? 32 ? 32 voxel grid requires about 45ms on an 1080Ti GPU. For efficiency, we perform 3D bounding box checks to detect overlapping 3D bounding boxes, and voxelize only the relevant meshes. Additionally, we reimplemented parts of NMR <ref type="bibr" target="#b26">[27]</ref> to make rendering large images more efficient. This allowed us to have more than an order of magnitude of speedup since the forward pass complexity dropped from O(F wh) to O(F + wh) on average, where F is the number of faces and w and h the image width and height respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this Section, we present the empirical evaluation of our approach. First, we describe the datasets used for training and evaluation (Subsection 4.1). Then, we focus on the quantitative evaluation <ref type="figure" target="#fig_1">(Subsections 4.2 and 4.3)</ref>, and finally we present more qualitative results (Subsection 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>Human3.6M <ref type="bibr" target="#b20">[21]</ref>: It is an indoor dataset where a single person is visible in each frame. It provides 3D ground truth for training and evaluation. We use Protocol 2 of <ref type="bibr" target="#b25">[26]</ref>, where Subjects S1,S5,S6,S7 and S8 are used for training, while Subjects S9 and S11 are used for evaluation. MuPoTS-3D <ref type="bibr" target="#b37">[38]</ref>: It is a multi-person dataset providing 3D ground truth for all the people in the scene. We use this dataset for evaluation using the same protocol as <ref type="bibr" target="#b37">[38]</ref>. Panoptic <ref type="bibr" target="#b23">[24]</ref>: It is a dataset with multiple people captured in the Panoptic studio. We use this dataset for evaluation, following the protocol of <ref type="bibr" target="#b64">[65]</ref>. MPI-INF-3DHP <ref type="bibr" target="#b35">[36]</ref>: It is a single person dataset with 3D pose ground truth. We use subjects S1 to S8 for training. <ref type="figure">PoseTrack [1]</ref>: In-the-wild dataset with 2D pose annotations. Includes multiple frames for each sequence. We use this dataset for training and evaluation. LSP <ref type="bibr" target="#b21">[22]</ref>, LSP Extended <ref type="bibr" target="#b22">[23]</ref>, MPII [2]: In-the-wild datasets with annotations for 2D joints. We use the training sets of these datasets for training. COCO <ref type="bibr" target="#b31">[32]</ref>: In-the-wild dataset with 2D pose and instance segmentation annotations. We use the 2D joints for training as we do with the other in the-wild datasets, while the instance segmentation masks are employed for the computation of the depth ordering-aware loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison with the state-of-the-art</head><p>For the comparison with the state-of-the-art, as a sanity check, we first evaluate the performance of our approach on a typical single person baseline. Our goal is always multiperson 3D pose and shape, but we expect our approach to achieve competitive results, even in easier settings, i.e., when only one person is in the image. More specifically, we evaluate the performance of our network on the popular Human3.6M dataset <ref type="bibr" target="#b20">[21]</ref>. The most relevant approach here is HMR by Kanazawa et al. <ref type="bibr" target="#b25">[26]</ref>, since we share similar architectural choices (iterative regressor, regression target), training practices (adversarial prior) and training data. The results are presented in <ref type="table" target="#tab_1">Table 1</ref>. Our approach outperforms HMR, as well as the approach of Arnab et al. <ref type="bibr" target="#b2">[3]</ref>, that uses the same network with HMR, but is trained with more data.</p><p>Having established that our approach is competitive in the single person setting, we continue the evaluation with  multi-person baselines. In this case, we consider approaches that also estimate pose and shape for multiple people. The most relevant baselines are the works of Zanfir et al. <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b65">66]</ref>. We compare with these approaches in the Panoptic dataset <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>, using their evaluation protocol (assuming no data from the Panoptic studio are used for training). The full results are reported in <ref type="table" target="#tab_2">Table 2</ref>. Our initial network (baseline), trained without our proposed losses, achieves performance comparable with the results reported by the previous works of Zanfir et al. More importantly though, adding the two proposed losses (full), improves performance across all subsequences and overall, while we also outperform the previous baselines. These results demonstrate both the strong performance of our approach in the multi-person setting, as well as the benefit we get from the losses we propose in this work. Another popular benchmark for multi-person 3D pose estimation is the MuPoTS-3D dataset <ref type="bibr" target="#b35">[36]</ref>. Since no multi-person 3D pose and shape approach reports results on this benchmark, we implement two strong top-down baselines, based on state-of-the-art approaches for singleperson 3D pose and shape. Specifically, we select a regression approach, HMR <ref type="bibr" target="#b25">[26]</ref>, and an optimization approach, SMPLify-X <ref type="bibr" target="#b41">[42]</ref>, and we apply them on detections provided by OpenPose <ref type="bibr" target="#b4">[5]</ref> (as is suggested by their public repositories), or by Mask-RCNN <ref type="bibr" target="#b18">[19]</ref> (for the case of HMR). The full results are reported in <ref type="table">Table 3</ref>. As we can see, our baseline model performs comparably to the other approaches, while our full model trained with the proposed losses improves significantly over the baseline. Similarly with the previous results, this experiment further justifies the use of our coherency losses. Besides this, we also demonstrate that na?ve baselines trained with a single person in mind are suboptimal for the multi-person setting of 3D pose. This is different from the 2D case, where a single-person network can perform particularly well in multi-person top-  <ref type="table">Table 3</ref>: Results on MuPoTS-3D. The numbers are 3DPCK. We report the overall accuracy (All), and the accuracy only for person annotations matched to a prediction (Matched).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MuPoTS-3D PoseTrack</head><p>Our baseline 114 653 Our baseline + L P 34 202 down pipelines as well, e.g., <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b63">64]</ref>. For the 3D case though, when multiple people are involved, making the network aware of occlusions and interpenetrations during training, can actually be beneficial at test-time too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablative studies</head><p>For this work, our interest in multi-person 3D pose estimation extends beyond just estimating poses that are accurate under the typical 3D pose metrics. Our goal is also to recover a coherent reconstruction of the scene. This is important, because in many cases we can improve the 3D pose metrics, e.g., get a better 3D pose for each detected person, but return incoherent results holistically. For example, the depth ordering of the people might be incorrect, or the reconstructed meshes might be positioned such that they overlap each other. To demonstrate how our proposed losses improve the network predictions under these coherency metrics even if they are only applied during training, we perform two ablative studies for more detailed evaluation.</p><p>First, we expect our interpenetration loss to naturally eliminate most of the overlapping people in our predictions. We evaluate this on MuPoTS-3D and PoseTrack, reporting the number of collisions with and without the interpenetration loss. The results are reported in <ref type="table" target="#tab_4">Table 4</ref>. As we expected, we observe significant decrease in the number of collisions when we train the network with the L P loss.</p><p>Moreover, our depth ordering-aware loss should improve the translation estimates for the people in the scene. Since for monocular methods it is not meaningful to evaluate metric translation estimates, we propose to evaluate only the returned depth ordering. More specifically, we consider all pairs of people in the scene, and we evaluate whether our method predicted the ordinal depth relation for this pair correctly. In the end, we report the percentage of correctly <ref type="bibr">Method</ref> Moon et al. <ref type="bibr" target="#b39">[40]</ref> Our baseline Our baseline + L D Accuracy 90.85% 92.17% 93.68% <ref type="table">Table 5</ref>: Ablative for depth-ordering-aware loss. Depth ordering results on MuPoTS-3D. We consider all pairs of people in the image, and we evaluate whether the approaches recovered the ordinal depth relation between the two people correctly. The numbers are percentages of correctly estimated ordinal depth relations. estimated ordinal relations in <ref type="table">Table 5</ref>. As expected, the depth ordering-aware loss improves upon our baseline. In the same <ref type="table">Table,</ref> we also report the results of the approach of Moon et al. <ref type="bibr" target="#b39">[40]</ref> which is the state-of-the-art for 3D skeleton regression. Although <ref type="bibr" target="#b39">[40]</ref> is skeleton-based and thus, not directly comparable to us, we want to highlight that even a state-of-the-art approach (under 3D pose metric evaluation) can still suffer from incoherency in the results. This provides evidence that we often might overlook the coherency of the holistic reconstruction, and we should also consider this aspect when we evaluate the quality of our results. Finally, we underline that we do not apply these coherency losses at test time. Instead, during training, our losses act as constraints to the reconstruction and ultimately provide better supervision to the network, for images that no explicit 3D annotations are available. The improved supervision leads to more coherent results at test time too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Qualitative evaluation</head><p>In this Subsection, we present more qualitative results of our approach. In <ref type="figure">Figure 5</ref> we compare our baseline with our full model trained with the proposed losses. As expected, our full model generates more coherent reconstructions, improving over the baseline as far as interpenetration and depth ordering mistakes are concerned. Errors can happen when there is significant scale difference among the people and there is no overlap on the image plane (last row of <ref type="figure">Figure 6</ref>). More results can be found in the Sup.Mat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Summary</head><p>In this work, we present an end-to-end approach for multi-person 3D pose and shape estimation from a single image. Using the R-CNN framework, we design a topdown approach that regresses the SMPL model parameters for each detected person in the image. Our main contribution lies on assessing the problem from a more holistic view and aiming on estimating a coherent reconstruction of the scene instead of focusing only on independent pose estimation for each person. To this end, we incorporate two novel losses in our framework that train the network such that a) it avoids generating overlapping humans and b) it is encouraged to position the people in a consistent depth ordering. We evaluate our approach in various benchmarks, demonstrating very competitive performance in the traditional 3D Input image Baseline Ours <ref type="figure">Figure 5</ref>: Qualitative effect of proposed losses. Results of our baseline model (center) and our full model trained with our proposed losses (right). As expected, we improve over our baseline in terms of coherency in the results (i.e., fewer interpenetrations, more consistent depth ordering for the reconstructed meshes). <ref type="figure">Figure 6</ref>: Qualitative evaluation. We visualize the reconstructions of our approach from different viewpoints; front (green background), top (blue background) and side (red background). More qualitative results can be found in the Sup.Mat. pose metrics, while also performing significantly better both qualitatively and quantitatively in terms of coherency of the reconstructed scene. In future work, we aim to more explicitly model interactions between people (besides the overlap avoidance), so that we can achieve a more accurate and detailed reconstruction of the scene at a finer level as well. In a similar vein, we can incorporate further information towards a holistic reconstruction of scenes. This can include constraints from the ground plane <ref type="bibr" target="#b64">[65]</ref>, background <ref type="bibr" target="#b16">[17]</ref>, or the objects that humans interact with <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b57">58]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Illustration of interpenetration loss. Left: Collision between person i (red) and j (beige). Center: Distance field ?i for person i, Right: Mesh Mj of person j. The vertices of Mj that collide with person i, i.e., located in non-zero areas of ?i and visualized with soft red, are penalized by the interpenetration loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and W. Jiang are affiliated with the State Key Lab of CAD&amp;CG, Zhejiang University. Email: xwzhou@zju.edu.cn.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Results on Human3.6M. The numbers are mean 3D joint errors in mm after Procrustes alignment (Protocol 2). The results of all approaches are obtained from the original papers.</figDesc><table><row><cell>Method</cell><cell cols="5">HMR [26] Arnab et al. [3] Ours</cell></row><row><cell>Reconst. Error</cell><cell>56.8</cell><cell></cell><cell>54.3</cell><cell></cell><cell>52.7</cell></row><row><cell>Method</cell><cell>Haggling</cell><cell cols="2">Mafia Ultim.</cell><cell>Pizza</cell><cell>Mean</cell></row><row><cell>Zanfir et al. [65]</cell><cell>140.0</cell><cell>165.9</cell><cell>150.7</cell><cell>156.0</cell><cell>153.4</cell></row><row><cell>Zanfir et al. [66]</cell><cell>141.4</cell><cell>152.3</cell><cell>145.0</cell><cell>162.5</cell><cell>150.3</cell></row><row><cell>Ours (baseline)</cell><cell>141.2</cell><cell>140.3</cell><cell>160.7</cell><cell>156.8</cell><cell>149.8</cell></row><row><cell>Ours (full)</cell><cell>129.6</cell><cell>133.5</cell><cell>153.0</cell><cell>156.7</cell><cell>143.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results on the Panoptic dataset. The numbers are mean per joint position errors after centering the root joint. The results of all approaches are obtained from the original papers.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Ablative for interpenetration loss. The results indicate the number of collisions on MuPoTS-3D and PoseTrack.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">PoseTrack: A benchmark for human pose estimation and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umar</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eldar</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">2D human pose estimation: New benchmark and state of the art analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploiting temporal context for 3D human pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Keep it SMPL: Automatic estimation of 3D human pose and shape from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">OpenPose: realtime multi-person 2D pose estimation using part affinity fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gines</forename><surname>Hidalgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-En</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Realtime multi-person 2D pose estimation using part affinity fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-En</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dazhi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qijie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07155</idno>
		<title level="m">Chen Change Loy, and Dahua Lin. MMDetection: Open mmlab detection toolbox and benchmark</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Singleimage depth perception in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cascaded pyramid network for multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Multi-person 3D human pose estimation from monocular images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Dabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gundavarapu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jain</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Moulding humans: Non-parametric 3D human shape estimation from single images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Gabeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-S?bastien</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Rogez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Statistical methods for tomographic image reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">E</forename><surname>Mcclure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of the International Statistical Institute</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="5" to="21" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Estimating human shape and pose from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Alexandru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Balan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">HoloPose: Holistic 3D human reconstruction in-the-wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alp</forename><surname>R?za</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>G?ler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">DensePose: Dense human pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>R?za Alp G?ler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Neverova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Resolving 3D human pose ambiguities with 3D scene constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Choutas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning joint reconstruction of hands and manipulated objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yana</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gul</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Kalevatykh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">Girshick</forename><surname>Mask R-Cnn</surname></persName>
		</author>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">6M: Large scale datasets and predictive methods for 3D human sensing in natural environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Human3</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1325" to="1339" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Clustered pose and nonlinear appearance models for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning effective human pose estimation from inaccurate annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Panoptic studio: A massively multiview system for social motion capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Nabbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shohei</forename><surname>Nobuhara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Panoptic studio: A massively multiview system for social interaction capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xulong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Godisart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Nabbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shohei</forename><surname>Nobuhara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="190" to="204" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">End-to-end recovery of human shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Neural 3D mesh renderer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroharu</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to reconstruct 3D human pose and shape via model-fitting in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Convolutional mesh regression for single-image human shape reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">3D-RCNN: Instance-level 3D object reconstruction via render-andcompare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhijit</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unite the people: Closing the loop between 3D and 2D human representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Kiefel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Microsoft COCO: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Soft rasterizer: A differentiable renderer for image-based 3D reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shichen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weikai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">SMPL: A skinned multiperson linear model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM transactions on graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A simple yet effective baseline for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julieta</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayat</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Monocular 3D human pose estimation in the wild using improved CNN supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">XNect: Real-time multi-person 3D human pose estimation with a single RGB camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elgharib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.00837</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Single-shot multi-person 3D pose estimation from monocular RGB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">VNect: Real-time 3D human pose estimation with a single RGB camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Shafiei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">44</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Camera distance-aware top-down approach for 3D multiperson pose estimation from a single RGB image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Neural body fitting: Unifying deep learning and model based human pose and shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Expressive body capture: 3D hands, face, and body from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Choutas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Osman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Texturepose: Supervising human mesh estimation with texture consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Ordinal depth supervision for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning to estimate 3D human pose and shape from a single color image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">DeepCut: Joint subset partition and labeling for multi person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eldar</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep multitask architecture for integrated 2D and 3D human sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alin-Ionut</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Neural scene decomposition for multi-person motion capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isinsu</forename><surname>Katircioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">LCR-Net: Localization-classification-regression for human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Rogez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">LCR-Net++: Multi-person 2D and 3D pose detection in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Rogez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Combined discriminative and generative articulated pose and non-rigid shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandru</forename><surname>Balan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">FACSIMILE: Fast and accurate scans from an image in less than a second</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paris</forename><surname>Mavroidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Learning shape completion from bounding boxes with CAD shape priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Stutz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>RWTH Aachen University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis, Masters thesis</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning 3D shape completion from laser scan data with weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Stutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Integral human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">H+O: Unified egocentric recognition of 3D hand-object poses and interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bugra Tekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning to fuse 2D and 3D image cues for monocular body pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bugra Tekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>M?rquez-Neila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Lifting from the deep: Convolutional 3D pose estimation from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Tome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lourdes</forename><surname>Agapito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Self-supervised learning of motion capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Yu</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Wei</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katerina</forename><surname>Fragkiadaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">BodyNet: Volumetric inference of 3D human body shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gul</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Monocular total capture: Posing face, body, and hands in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donglai</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Simple baselines for human pose estimation and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiping</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Monocular 3D pose and shape estimation of multiple people in natural scenes-the importance of multiple scene constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabeta</forename><surname>Marinoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Deep network for the integrated 3D sensing of multiple people in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabeta</forename><surname>Marinoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alin-Ionut</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Towards 3D human pose estimation in the wild: a weakly-supervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
