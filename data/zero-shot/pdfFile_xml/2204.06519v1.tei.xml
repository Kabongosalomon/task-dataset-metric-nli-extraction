<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CARCA: Context and Attribute-Aware Next-Item Recommendation via Cross-Attention</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-07">July 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Rashed</surname></persName>
							<email>ahmedrashed@ismll.uni-hildesheim.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Systems and Machine Learning Lab</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shereen</forename><surname>Elsayed</surname></persName>
							<email>elsayed@ismll.uni-hildesheim.de</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
							<email>schmidt-thieme@ismll.uni-hildesheim.de</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Information Systems and Machine Learning Lab</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CARCA: Context and Attribute-Aware Next-Item Recommendation via Cross-Attention</title>
					</analytic>
					<monogr>
						<meeting> <address><addrLine>Washington, DC, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="volume">17</biblScope>
							<date type="published" when="2017-07">July 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Sequential Recommendation</term>
					<term>Context-Aware Recommendation</term>
					<term>Attribute-Aware Recommendation</term>
					<term>Cross Multi-Head Attention</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In sparse recommender settings, users' context and item attributes play a crucial role in deciding which items to recommend next. Despite that, recent works in sequential and time-aware recommendations usually either ignore both aspects or only consider one of them, limiting their predictive performance. In this paper, we address these limitations by proposing a context and attributeaware recommender model (CARCA) that can capture the dynamic nature of the user profiles in terms of contextual features and item attributes via dedicated multi-head self-attention blocks that extract profile-level features and predicting item scores. Also, unlike many of the current state-of-the-art sequential item recommendation approaches that use a simple dot-product between the most recent item's latent features and the target items embeddings for scoring, CARCA uses cross-attention between all profile items and the target items to predict their final scores. This cross-attention allows CARCA to harness the correlation between old and recent items in the user profile and their influence on deciding which item to recommend next. Experiments on four real-world recommender system datasets show that the proposed model significantly outperforms all state-of-the-art models in the task of item recommendation and achieving improvements of up to 53% in Normalized Discounted Cumulative Gain (NDCG) and Hit-Ratio. Results also show that CARCA outperformed several state-of-the-art dedicated imagebased recommender systems by merely utilizing image attributes extracted from a pre-trained ResNet50 in a black-box fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Computing methodologies ? Artificial intelligence; Learning from implicit feedback; ? Information systems ? Recommender systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Nowadays, sequential recommendation systems play an essential role in many online platforms, including but not limited to online shops, online media providers, and social networks. In such platforms, users usually exhibit strong dynamic behavior heavily influenced by ever-changing users' contexts and content information. Due to such dynamic profiles, recent time-aware sequential recommendation approaches that capture sequential patterns in the user profiles <ref type="bibr">[12,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b36">36]</ref> have shown superior performance when compared against traditional non-sequential techniques <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b20">20]</ref> and context-aware models <ref type="bibr" target="#b18">[18]</ref>. However, despite their competitive performance, many of those approaches only utilize the sequential order of consumed items and assume equal time gaps between the interactions. Such an approach completely ignores the actual time gaps between the consumed products and the context in which the user interacted with them. These two aspects encapsulate vital information, which is crucial for determining what item to recommend next. A third aspect that usually gets left out is the item attributes, which are indispensable for any model to overcome highly sparse settings and achieve superior performance <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b36">36]</ref>. Additionally, many recent sequential ranking models for item recommendation share a principal limitation as they rely only on the latent features of the most recent item in the user profile to predict scores for the target items. Such a scoring approach significantly downweights the older items' influence on the next items to be recommended.</p><p>To tackle these limitations and address the three aspects, we propose a flexible context and attribute-aware recommendation model (CARCA) that captures user profiles' dynamic nature and contextual changes seamlessly alongside any available item attributes. CARCA utilizes several multi-head attention blocks to capture the evolving patterns in the user profile and utilizes a separate dedicated cross-attention block to capture the influence of all previous historical interactions on the target items to be recommended.</p><p>The contributions of this paper can be summarized as follows:</p><p>? We introduce a versatile context and attribute-aware model for item recommendation (CARCA), which can be applied to diverse settings and can leverage any additional item attributes. ? We evaluate the proposed model on four real-world datasets for item recommendation. Results show that the proposed CARCA model significantly outperforms all state-of-the-art models in item recommendation and achieves improvements of up to 53% in Normalized Discounted Cumulative Gain (NDCG) and Hit-Ratio. Results also show that CARCA outperforms several state-of-the-art image-based recommender systems by merely using precomputed image features. ? We conduct a comprehensive ablation study to show the effect of the different model components on the prediction performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>There has been a plethora of context and attribute-aware recommendation models that have shown consistent competitive performance on a wide variety of recommendation tasks, including, but not limited to, next-item recommendation <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b36">36]</ref>, rating prediction <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b31">31]</ref>, and click-through rate prediction <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b35">35]</ref>. Context-aware models <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b35">35]</ref> can achieve superior performance compared with other models due to their ability to capture the high variability of users' behaviors and anticipate their next preferences. On the other hand, attribute-aware models <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b36">36]</ref> utilize the additional item, and user attributes to generate rich latent representations and provide better recommendations. These additional attributes proved crucial in getting high-quality recommendations in highly sparse settings with rich item attributes such as in online fashion stores <ref type="bibr" target="#b8">[8]</ref> and unique item recommendation settings like online auctions <ref type="bibr" target="#b17">[17]</ref>.</p><p>Context-aware models can be categorized into two main groups, models that utilize contextual features and other additional attributes in plain single vector format <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b30">30]</ref> and time-aware models that utilize the time and the sequential order of user's interactions. A popular example that belongs to the first group is the factorization machines (FM) <ref type="bibr" target="#b18">[18]</ref> relying on mining interaction between latent embeddings of the various attributes and contextual features. Such a features extraction approach was later improved by adding deep neural networks <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b9">9]</ref> and attention mechanisms <ref type="bibr" target="#b29">[29]</ref> to capture higher-order interactions between the different features' latent vectors. DeepFM <ref type="bibr" target="#b6">[6]</ref> another popular model that utilizes a separate deep neural network to extract non-linear attributes representations along with a traditional FM component. We further shed light on this model in the experiments section, as we propose to use it as a baseline. Similarly, NFM <ref type="bibr" target="#b9">[9]</ref> uses a dedicated deep neural network component on top of the latent features extracted from an FM layer to capture higher-order interactions. Finally, CFM <ref type="bibr" target="#b30">[30]</ref> which is one of the latest model in this family, utilized convolutional neural networks on the attributes' latent vectors outer product for better representations learning. However, recent studies <ref type="bibr" target="#b5">[5]</ref> have shown that it performed significantly worse when compared against well tune simple baselines. Nevertheless, despite the competitiveness of such context-aware approaches in item rating prediction and click-through rate prediction tasks, they are significantly outperformed by time-aware sequential models when employed in item recommendation tasks in implicit feedback settings <ref type="bibr">[12,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b36">36]</ref>. Such inferior performance is due to their inability to capture the sequential patterns in the user's historical interactions as they only treat the contextual features as static input features vectors.</p><p>The second group of context-aware models are the timeaware sequential models <ref type="bibr">[12, 13, 15, 23, 25-27, 32, 36]</ref> which achieve state-of-art performances on item recommendation tasks. Even though these models do not use explicit contextual features, they can capture the evolving user behavior by mining the sequential patterns in their historical interactions. Earlier approaches such as GRU4Rec <ref type="bibr" target="#b10">[10]</ref> relied on recurrent neural networks to mine such sequential patterns. This approach was later improved by using bidirectional transformer blocks in BERT4Rec <ref type="bibr" target="#b23">[23]</ref>. Another recent approach proposed by Kang et al. <ref type="bibr">[12]</ref> that utilizes self-attention blocks to extract the sequential patterns in past user interactions is SASRec. SASRec also utilized a dot-product between the sequential latent features of the most recent item in the user profile and the target items' embeddings for scoring. SASRec was later extended by adding personalized latent user vectors in the current state-of-the-art model SSE-PT <ref type="bibr" target="#b28">[28]</ref>, adding more robust regularization through stochastic shared embeddings in SSE-SASRec <ref type="bibr" target="#b27">[27]</ref>, adding the ability to model the time intervals between interactions in TiSASRec <ref type="bibr" target="#b13">[13]</ref>, and finally adding the ability to handle sparse categorical attributes in the state-of-the-art hybrid S 3 Rec model <ref type="bibr" target="#b36">[36]</ref>. All of those approaches, however, maintained the same limited scoring approach that was used in the original SASRec. Lastly, a similar parallel work by Wang et al. <ref type="bibr" target="#b26">[26]</ref> proposed an occasionaware model (OAR) that utilizes the timestamps embeddings and recurrent memory network to predict the next item to be recommended. OAR also utilized the same dot-product scoring similar to SASRec. We propose using all of the later seven models as baselines in our experimental section as their implementations were readily available.</p><p>Besides context-aware models, attribute-aware models have also shown very competitive performance in various settings despite their inability to capture the users' contexts and their evolving behavior. Earlier approaches such as mSDA-CF <ref type="bibr" target="#b14">[14]</ref> utilized a dedicated denoising auto-encoder component for extracting latent item features from its attributes. This approach was later improved by using a contracted autoencoder in the AutoSVD model <ref type="bibr" target="#b31">[31]</ref>. Also, the VPBR model <ref type="bibr" target="#b8">[8]</ref> using pre-computed item attributes such as its latent image features has significantly outperformed many non-attribute-based approaches. This approach was later outperformed by a dedicated image-based item recommendation model <ref type="bibr" target="#b11">[11]</ref>, which utilizes two CNN networks ensembled to extract global features and local features from different regions of interest. We likewise propose using both approaches as baselines in our experiments. Another recent state-of-the-art attribute-aware model (GraphRec) was proposed by Rashed et al. <ref type="bibr" target="#b16">[16]</ref> that utilizes graph features along with users and items attributes for rating prediction. We further shed light on this model in the experimental section as we propose using it as an additional baseline.</p><p>With motivation set forth from the literature review, we draw the following insight: plenty of works where the user context, time, and item attributes have been actively used to model the user preferences in various recommendation tasks. However, many of these works only focus on one or two of these three aspects, ignoring the correlation between complete contextual information and the crucial item attributes. Also, many of the recent sequential next-item recommendation models rely only on the sequential latent features of the most recent item for scoring, which only captures a limited view of the full user profile. Another essential feature that needs to be considered is the ability to handle not just sparse categorical attributes besides the contextual information but also any number of real-valued attributes to ensure the mode generalizability for different settings. Our work is the first to tackle the all of these aspects and limitations simultaneously for the next-item recommendation task while having the ability to utilize any numerical item attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM DEFINITION</head><p>An item recommendation problem consists of a set U := {1, . . . , } of users, a set I := {1, . . . , } of items and a sequence D := (( 1 , 1 ), . . . , ( , )) ? (U ? I) * of their past interactions originating from an unknown distribution on user/item pairs (with , , ? N). Sought is a model?: U ? (R + 0 ) I for the unknown conditional density ( | ), i.e., given a loss function</p><formula xml:id="formula_0">L : I ? (R + 0 ) I ? R with minimal expected loss E ( , )? L ( ,?( ))</formula><p>One calls the problem having item attributes, if additionally there is a given matrix IT ? R ? containing for item an attribute vector with ? N attribute values each.</p><p>One calls the problem having context, if each interaction has additional attributes, i.e., D := (( 1 , 1 , 1 ), . . . , ( , , )) ? (U ? I ? R ) * (with ? N) is a sample from an unknown distribution on user/item/context triples and the goal is to find a model?: U ? R ? (R + 0 ) I for the unknown conditional density ( | , ), i.e., given a loss function L with minimal expected loss</p><formula xml:id="formula_1">E ( , , )? L ( ,?( , ))</formula><p>The most frequently encountered context is an absolute timestamp at which the user interacted with an item (for example measured as a real number in Unix Time).</p><p>Many papers simplify the problem, dropping the sequential nature of the problem. Consequently, they model the data as a set of user/item interactions (instead of as a sequence) and also evaluate on non-sequential splits, i.e., take out items at random positions (instead of only at the end). While this allows simpler models, it has the significant disadvantage that these splits cannot occur in reality. We will therefore look only at the sequential problem as stated above.</p><p>Sequential approaches on the other hand usually consider all users to have profiles that contain the sequence of their previously interacted items := { 1 , 2 , ..., | | } along with their attributes ? R | |? and their interactions' contextual features ? R | |? such as timestamps. The main goal of the sequential item recommendation task will be to rank a target list of items +1 := { 1 , 2 , ..., | +1 | } based on their likelihood of being interacted with by the target user at time + 1 while similarly considering their attributes and contextual features existing at that time point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODOLOGY</head><p>To capture the evolving users' behaviors existing in their profiles , the proposed CARCA model utilizes two analogous multi-head selfattention based branches. The left branch is a series of self-attention blocks that extract the user's profile's contextual information and item features. On the other hand, the right branch consists of a multi-head cross-attention block that captures the influence of the left branch's profile-level features on the target items +1 while taking into consideration the target items' attributes and contextual features. The second branch is also responsible for generating the ranking score for each target item in +1 . <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the architecture of the CARCA model, which will be discussed in detail in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Embedding Layers</head><p>The first part of the features extraction pipeline in both branches is the embedding functions that will extract the initial items latent features to be fed to the self-attention blocks. To achieve that, we utilize two separate dedicated embedding functions and . The first embedding function : R ? R is used to extract the first half of the item's latent features ? R , ? ? +1 from the item's one-hot encoded vectors ? R . The second function : R + ? R extracts the second half of the latent features ? R from the item's contextual features ? R and attributes ? R . After extracting the two partial latent feature vectors, both of them are concatenated and fed into a third embedding layer : R + ? R to generate the final item's latent features ? R as follows:</p><formula xml:id="formula_2">= ( ) = + , ? R ? , ? R (1) = ( , ) = concat ( , ) + , ? R ( + )? , ? R (2) = ( , ) = concat ( , ) + , ? R ( + )? , ? R (3) where , ,</formula><p>are the weight matrices of the embedding functions, and , , are their bias vectors. concat represents column-wise concatenation of vectors.</p><p>Finally, since both the user profile and the target items +1 have the same structure and format, we utilize the same embedding pipeline on both of them while sharing the network's weights. It is worthy to note that we also tried to use a single embedding layer for all input features concatenated into one long vector. However, the performance was inferior to this setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Self-Attention Blocks</head><p>After extracting the embeddings of all items in the user profile := { 1 , 2 , ..., | | } and the embeddings of the target items := { 1 , 2 , ..., | +1 | }, we use two separate self-attention components to extract profile-level features and ranking the target items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.1</head><p>Profile-Level Self-Attention Blocks. To extract the profilelevel features, we feed the item embeddings into a series of multi-head self-attention blocks. We first feed the item embeddings into the first part of a block, which is a multi-head self-attention layer that utilizes the scaled dot product. <ref type="bibr" target="#b24">[24]</ref> Attention(Q, </p><formula xml:id="formula_3">K, V) = softmax QK ?? V<label>(4)</label></formula><formula xml:id="formula_4">= SA(E ) = concat Attention(E W ? , E W ? , E W ? ) ?=1:<label>(5)</label></formula><p>where Q, K and V represents the queries, keys and values respectively. W ? , W ? , W ? ? R ? represent the linear projection matrices of the head at index ? and represents the total number of heads in the attention block. Additionally, concat concatenates vectors column-wise and ?? is a scaling factor that controls the values of the inner products.</p><p>The next step is to feed the output of the self-attention layer into the second part, which is a point-wise two-layer feed-forward network that is applied identically to all elements of with sharing parameters similar to the original transformers <ref type="bibr" target="#b24">[24]</ref> = FFN( )</p><formula xml:id="formula_5">= concat Leaky_ReLU( (1) + (1) ) (2) + (2) =1: | |<label>(6)</label></formula><p>where <ref type="bibr" target="#b0">(1)</ref> , <ref type="bibr" target="#b1">(2)</ref> ? R ? are the weight matrices of the two feed-forward layers, and <ref type="bibr" target="#b0">(1)</ref> , <ref type="bibr" target="#b1">(2)</ref> ? R are their bias vectors. Additionally, concat concatenates vectors row-wise. These feedforward networks introduce essential non-linearity, which allows us to capture higher-order interactions between the features.</p><p>Finally, to capture more expressive profile-level features, we stack a series of those self-attention blocks where the -th ( &gt; 1) blocks are defined as follows:</p><formula xml:id="formula_6">,( ) = SA(F ,( ?1) )<label>(7)</label></formula><p>,</p><formula xml:id="formula_7">( ) = FFN( ,( ) )<label>(8)</label></formula><p>where the 1-st block is defined as ,(1) = and ,(1) = Inspired by <ref type="bibr">[12,</ref><ref type="bibr" target="#b24">24]</ref>, we utilized residual connections <ref type="bibr" target="#b7">[7]</ref>, layer normalization <ref type="bibr" target="#b0">[1]</ref> and dropout <ref type="bibr" target="#b21">[21]</ref> to alleviate the problems of overfitting and instability. One slight difference, though, is that we used multiplicative residual connections instead of additive ones as they provided better performance and CARCA's architecture is relatively not very deep compared to the ResNet models. We also omitted the causality constrain to allow bidirectional representation learning similar to BERT <ref type="bibr" target="#b3">[4]</ref> and S 3 Rec [36] models. It is also important to note that we omitted the positional encoding since this information already exists explicitly in the contextual features such as the interaction's timestamp.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Target-Level</head><p>Cross-Attention Layer. Following the original transformers architecture and inspired by recent click-throughrating prediction models <ref type="bibr" target="#b34">[34]</ref>, and in contrast to many of the recent ranking-based sequential and context-aware item recommendation approaches <ref type="bibr">[12,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b36">36]</ref>, we utilize a dedicated multi-head cross-attention block to predict the likelihood scores of the target items. The dedicated block aims to capture the interaction between all profile-level features ,( ) and the targets items instead of the widely used approach of only using the dot product between the last most recent element in ,( ) and the target items initial embeddings . We further shed light on the comparison between these two approaches in the experimental section.</p><p>To calculate the scores?? R | +1 | of the target items +1 , we feed their embeddings in a multi-head cross-attention block as the query input while using the normalized profile features ,( ) from the left branch's last self-attention block as the keys and values</p><formula xml:id="formula_8">= CA(E , F ,( ) ) = concat Attention(E W ? , F ,( ) W ? , F ,( ) W ? ) ?=1:<label>(9)</label></formula><p>= FFN-Out( ) = concat ( + ) =1:| +1 | (10) where is the sigmoid activation.</p><p>? R ?1 and ? R are the weight matrices and bias vector of the output layer.</p><p>Such a setup allows us to generate different latent representations for the target items that capture the interactions between the full profile-level features and their embeddings. It also allows us to have an arbitrarily sized list of target items as an input +1 . It is also worth noting that we omitted the initial multi-head selfattention block that exists on top of the original transformers architecture's output tokens because the target items in our settings are scored independently. However, this component might be useful in other scenarios where the interactions between the target items are relevant to the prediction task, such as in the next basket recommendation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Optimizing CARCA</head><p>To simplify the training process, we followed the same training protocol proposed by SASRec and TiSASRec <ref type="bibr">[12,</ref><ref type="bibr" target="#b13">13]</ref>. For each user we exclude his last interaction and we convert the user profile sequence into a fixed-length input list of items = { 1 , 2 , ..., | |?1 } via truncation or padding. On the other hand, the list of target items is constructed by combining a list of positive items (+) and another list of negative items (?) with equal length. The positive items list is constructed by right shifting the input list to include the user's last interaction (+) = { 2 , 3 , ..., | | } while the negative items list is generated by selecting random negative items ? and they are given the same contextual features as their corresponding positive ones. It worth noting that we also tried using the last interaction as the only positive target in (+) = { | | }, however, the performance was inferior to the list-wise setup. We further shed the light on the comparison between the two splitting approaches in Section 5.5.</p><p>Finally, we optimize the CARCA model by minimizing the binary cross-entropy loss using an ADAM optimizer, and the padded items are masked to prevent them from contributing to the loss function. </p><formula xml:id="formula_9">L = ? ?? ? ?? ? (+) ? (?) log(?) + (1 ? ) log(1 ??)<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we conduct multiple experiments to evaluate the performance of CARCA and to answer the following research questions.</p><p>RQ1 How well does CARCA perform compared to the stateof-the-art recommender system models on item recommendation tasks? RQ2 How well does CARCA perform compared to the stateof-the-art image-based recommender system models while only using pre-computed item's image attributes? RQ3 What is the impact of adding the item's attributes and contextual features? RQ4 What are the impacts of the different components and design choices of the CARCA architecture?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>To evaluate the performance of CARCA and compare its performance against published results, we used the following four diverse and widely used real-world datasets extracted from products' reviews crawled from Amazon.com <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr">12,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b36">36]</ref>. All datasets' contextual features were extracted from the interactions' timestamps (i.e., day, month, year, day of week, day of year and week).</p><p>(  <ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b36">36]</ref>: This dataset contains all items that belong to beauty category. The item attributes in this dataset are the fine-grained categories and the item's brand. All of the items' attributes are also discrete and categorical.</p><p>To have a fair comparison against S 3 Rec [36] that uses only categorical attributes, we discretized all real-valued input features (attributes) into different levels. The number of levels was selected as the maximum number after which the S 3 Rec fails to run because of exceeding the total available memory of the GPU (1080Ti: 11 GB) or the system RAM (64GB). According to this, the maximum number of the selected equally spaced discretization levels were 10, 10, and 50 for the Men, Fashion, and Games datasets, respectively. <ref type="table" target="#tab_0">Table 1</ref> presents a summary of the most important statistics of the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance comparison with state-of-the-art item recommendation models (RQ1)</head><p>In this section, we compare the performance of the CARCA model against multiple state-of-the-art ranking-based next-item recommendation models with different capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Evaluation Protocol.</head><p>To evaluate CARCA and other baseline models' performance, we used the widely adopted leave-one-out protocol <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr">12,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b36">36]</ref>. In this protocol, the two last interactions of each user are held out for validation and test while the rest of the interactions are used for training. To evaluate the model's performance, we sample 100 negative items that were not interacted with by the user, give them all the same context as their corresponding positive test item, and rank the positive test item among them. Lastly, for each user, we truncate the ranked list at a threshold value of 10. We measure the overall quality using the average Hit-Ratio (HR) and the Normalized Discounted Cumulative Gain (NDCG) across users.</p><p>To ensure the statistical significance of the reported results, we report the average metrics across five different runs on the test set, each with a different set of random negative items, and we used a paired t-test for measuring the significance. The hyper-parameters of all models were tuned on the validation set using grid search. We also tried the best hyper-parameters reported in the baselines' original papers if they were available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Models.</head><p>(1) Random: A simple baseline model that ranks items randomly. : This is an extended version of the stateof-the-art attribute-aware GraphRec model for item recommendation in implicit feedback settings. We replaced the means squared error (MSE) loss function with a logistic loss function, and we trained the model by sampling positive and negative items. (5) DeepFM <ref type="bibr" target="#b6">[6]</ref>: A widely used model for click-through rate prediction that relies on learning high order feature interactions using an ensemble of Factorization Machines and deep neural networks. We modified this model for next-item recommendation by optimizing it using negative sampling and minimizing a logistic loss function. (6) SASRec <ref type="bibr">[12]</ref>: A state-of-the-art sequential recommendation model that utilizes self-attention blocks to predict the next item to be recommended. It also uses the dot-product between the most recent item's sequential latent features and the target item's embeddings as the scoring function. It is worth noting that we could not reproduce the original results of the SSE-PT model on the Beauty and Games datasets, although we used the authors' implementation because best hyper-parameters were neither mentioned in the paper nor the code. The authors are also no longer able to recover the best hyper-parameters as per the following GitHub issue 1 that other community members raised. To mitigate this issue, we report both our results and published results on those respective datasets. <ref type="table" target="#tab_2">Table 2</ref> show that CARCA with cross attention significantly outperforms all state-of-the-art context, sequential and attribute-aware models on various settings and with different item attribute types. CARCA is also able to achieve improvements up to 53% when compared against SSE-PT as it utilizes the full pre-computed item's image features on the Men and Fashion datasets without needing any data discretization, unlike the S 3 Rec that only handle categorical attributes. Additionally, CARCA was also able to significantly outperform S 3 Rec in speed (? 22 times faster) and accuracy on settings with categorical attributes such as the Games and Beauty datasets despite the competitive performance of S 3 Rec on them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Results. Results in</head><p>Results also show that the CARCA without the cross-attention branch, which utilizes the same dot-product scoring approach adopted by many recent sequential models, can outperform all baselines, including the SASRec++ extended version on three out of the four datasets. However, this version is still outperformed by the cross-attention version, which provides a further lift of 2% to 6% Published results of SSE-PT are indicated in parentheses.</p><p>in NDCG and HitRatio. This difference between the two CARCA versions shows that older items in the user profile have a significant influence on the next items to be interacted with, and such influence should not be ignored.</p><p>One interesting finding is that S 3 Rec was found to be slightly inferior to SASRec on the Men and Fashion datasets. This is mainly because of the features discretization step that S 3 Rec needs which leads to a negative impact on its performance due to the unavoidable information loss. On the other hand, this also explains why S 3 Rec is superior on the Games and Beauty datasets, which has mostly categorical features. Another interesting finding is that BERT4Rec was also inferior to SASRec although it is a more recent approach. These findings match similar results in recently published comparative studies <ref type="bibr" target="#b36">[36]</ref>.</p><p>Finally, it is worth mentioning that the TopPopular model was found to be very competitive on the Men, Fashion, and Beauty datasets due to unevenly distributed items popularities in these datasets similar to the Epinion dataset in the famous study by <ref type="bibr" target="#b1">[2]</ref>. We conducted a similar analysis on our test sets items, and we found out that the Gini indexes of the item's popularity in the Fashion and Men datasets (Gini indexes = 0.71 and 0.72) are significantly high, which explains the competitive performance of TopPopular model. Also, the Gini index on Beauty is slightly higher than Games (Beauty = 0.67 and Games = 0.63), which explains why the TopPopular achieved a very competitive performance on that dataset compared to its performance on the games dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Performance comparison with</head><p>state-of-the-art dedicated image-based item recommendation models (RQ2)</p><p>In this section, we compare the performance of the CARCA model against multiple state-of-the-art image-based item recommendation models on the Fashion dataset. Regarding the evaluation protocol, we used the same as the one proposed by SAERS <ref type="bibr" target="#b11">[11]</ref> with sampling 500 negative items instead of 100 and using the area under the curve (AUC) score instead of the HitRatio. This allows us to compare CARCA's performance against their published results directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Baselines.</head><p>(1) VBPR  <ref type="table" target="#tab_4">Table 3</ref> shows that CARCA is able to outperform SAERS and all other image-based models while merely utilizing pre-computed features and without any fine-tuned imagebased deep neural network components. These findings show that even fine-tuned image-based features are not sufficient for capturing user interests, but we also need to include the contextual features of the interactions.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Impact of item attributes and contextual features (RQ3)</head><p>To measure the impact of the item attributes and the contextual features on CARCA's performance, we conducted a comparative study between different CARCA versions that utilize different combinations of attributes and features. <ref type="figure" target="#fig_1">Figure 2</ref> shows that the impact of item attributes and contextual features are different across the datasets. On the Men and Fashion datasets, item attributes such as their image features have a significant impact on the performance compared to the interactions contexts that had a lower impact. On the other hand, contextual features have a higher impact on CARCA's performance on the Games dataset than item attributes because video games are much more volatile than clothes and fashion-based products as they are susceptible to critics and the satisfaction of their player-bases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Ablation Study (RQ4)</head><p>To measure the impact of each of the model components, multiple experiments on the Men dataset were conducted to compare the different possible configurations of the CARCA architecture. The hyper-parameters of each configuration were optimized separately on the validation set using grid search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Configurations.</head><p>(1) Default: This the default configuration of CARCA that was described in Section 4. (2) Additive residual connections : CARCA with additive residual connections in the multi-head attention blocks instead of multiplicative ones.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">Results</head><p>. <ref type="table" target="#tab_5">Table 4</ref> shows that replacing the context features with traditional positional encodings has a slight negative effect on the performance, indicating that the positional encoding can be used as a substitute for contextual features of the interaction if timestamps are missing. Results also show that the multiplicative residual connection in the multi-head attention blocks provides better prediction performance as they can recover the elementwise multiplicative interactions between the latent features similar to the matrix factorization techniques. Additionally, results show that using a single target for training the CARCA model is significantly inferior to using list-wise target items because the model failed to capture the sequential correlation between the inputs and target lists during training as this suppresses its bidirectional autoregressive capability. However, this can be solved by splitting the whole user's history into sequences with different lengths in a rolling window fashion. Moreover, in <ref type="table" target="#tab_5">Table 4</ref>, we can see that the combination strategy of the item attributes and contextual features has different impacts on the overall performance, with the default configuration being the best. Finally, results also showed that using the transformer architecture or using additional attention blocks on top of the cross-attention block has a significant negative effect on the overall performance.  <ref type="bibr" target="#b5">(5)</ref> 0.544 0.345 Additional self-attention blocks on output <ref type="bibr" target="#b6">(6)</ref> 0.427 0.231 CARCA with single target split <ref type="bibr" target="#b7">(7)</ref> 0.394 0.233 CARCA with transformer architecture <ref type="bibr" target="#b8">(8)</ref> 0.459 0.276</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>In this paper, we propose CARCA, a context and attribute-aware model that captures user profiles' dynamic nature and contextual changes seamlessly alongside leveraging any available item attributes. CARCA also uses a cross-attention component for scoring items by capturing the correlation between old and recent items in the user profile and their influence on deciding which item to recommend next. Experimental results on four diverse datasets show that CARCA significantly outperforms multiple state-of-the-art models on the task of item recommendation.</p><p>In future works, we plan to extend CARCA for next-basket recommendations scenarios. We also plan to extend the model capacity by exploring different regularization techniques such as stochastic shared embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A RUNTIME COMPARISON</head><p>We compared the average run-time of a batch of size 128 between the proposed CARCA models and the most recent state-of-the-art sequential baseline models on the Games dataset using 1080Ti GPU, and E5-1660v4 CPU with 64GB of RAM. Results in <ref type="table">table 6</ref> show that the average batch run-time of CARCA is very close to other sequential models with very little overhead due to adding the crossattention component and the additional features. Results also show that CARCA is about 22 times faster than S 3 Rec, which is the closest competitor because of S 3 Rec's computationally expensive mutual information maximization procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B REPRODUCIBILITY OF THE EXPERIMENTS</head><p>The source code of CARCA 2 is available at github. Regarding the hyper-parameters, all models were tuned using a grid search except the EASE model as it was optimized using a Bayesian optimization procedure existed in its source code <ref type="bibr" target="#b2">3</ref> by Dacrema et al. <ref type="bibr" target="#b1">[2]</ref>. The best found hyper-parmeters for our CARCA models is shown in <ref type="table">Table 5</ref> The source codes of all baseline models are available at their authors' GitHub repositories 456789101112 .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of the CARCA model, which is composed of two main branches, namely the profile-level features extraction branch on the left and the target items cross-attention scoring branch on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 2 )</head><label>2</label><figDesc>TopPopular: A naive baseline model that ranks items based on their popularity. (3) EASE [22]: A shallow auto-encoder based model that utilize the closed-form solution of the Frobenius norm objective function in highly sparse settings. (4) GraphRec [16]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 7 )</head><label>7</label><figDesc>TiSASRec [13]: An improved version of SASRec that utilizes time-aware positional embeddings for modeling time intervals between interactions. (8) OAR [26]: A state-of-the-art sequential recommendation model that utilizes recurrent memory networks and gating layers. This model also utilizes the timestamp as contextual features. (9) SSE-SASRec [27]: An improved version of SASRec that utilizes stochastic shared embeddings for regularization. (10) BERT4Rec [23]: A state-of-the-art model that utlizes bidirectional transformers for next item recommendations. (11) SSE-PT [28]: A state-of-the-art extended version of SASRec that utilizes the latent user vectors along with their historical interactions. (12) S 3 Rec [36]: A state-of-the-art attribute-aware sequential recommendation model that utilizes multiple self-supervised mutual information maximization loss components for better representation learning of item attributes. This model can handle categorical attributes only, and real-valued attributes will require discretization in order to be applicable. (13) SASRec++(Ours) [12]: This is our context and attributeaware extended version of SASRec. We used the same initial feature extraction pipeline used by CARCA, and we replaced the one-hot encoded input vectors of SASRec with the extracted items' embedding vectors. (14) CARCA (w/o CA) (Ours): A version of our proposed model CARCA that does not utilize the cross-attention component and only utilize the dot-product scoring function between the sequential features of the most recent item and target items similar to other sequential recommendation models. (15) CARCA (Ours): This is our proposed method with crossattention between all profile-level features and the target items' embeddings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Impact of the item's attributes and the contextual features on CARCA's performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>( 3 ) 6 )</head><label>36</label><figDesc>Concat. all features : CARCA with all input vectors concatenated in one long feature vector that goes through one embedding layer.(4) Concat. item features : CARCA with flipped feature extraction pipeline where item attributes are concatenated with the item's one-hot vectors instead of the contextual features. (5) Positional Encoding : CARCA with positional encoding instead of contextual features. (Additional self-attention blocks on output : CARCA with an additional multi-head attention block on top of the latent output vectors. (7) CARCA with single target split ; CARCA model trained with only one target item in the target items lists (+) = { | | } and (?) = { ? }.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>( 8 )</head><label>8</label><figDesc>CARCA with transformer architecture : CARCA with a similar architecture to the original transformers, which is a combination of configurations (2), (3),<ref type="bibr" target="#b5">(5)</ref>, and<ref type="bibr" target="#b7">(7)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Datasets Statistics</figDesc><table><row><cell cols="2">Dataset Users</cell><cell>Items</cell><cell cols="2">Interactions Item Attributes</cell></row><row><cell>Men</cell><cell cols="2">34,244 110,636</cell><cell>254,870</cell><cell>2048</cell></row><row><cell cols="3">Fashion 45,184 166,270</cell><cell>358,003</cell><cell>2048</cell></row><row><cell>Games</cell><cell cols="2">31,013 23,715</cell><cell>287,107</cell><cell>506</cell></row><row><cell>Beauty</cell><cell cols="2">52,204 57,289</cell><cell>394,908</cell><cell>6507</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison of the CARCA against state-of-the-art sequential (SEQ), context (CXT) and attribute-aware (ATT) recommendation models. Significantly outperforms the best baseline at the 0.01 levels.</figDesc><table><row><cell>Men</cell><cell>Fashion</cell><cell>Games</cell><cell>Beauty</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Performance comparison of the CARCA against state-of-the-art image-based models on the Fashion dataset.</figDesc><table><row><cell>Model</cell><cell cols="2">NDCG@10 AUC</cell></row><row><cell>Random</cell><cell>0.012</cell><cell>0.501</cell></row><row><cell>TopPop</cell><cell>0.125</cell><cell>0.595</cell></row><row><cell>VBPR [8]</cell><cell>0.085</cell><cell>0.771</cell></row><row><cell>JRL [33]</cell><cell>0.127</cell><cell>0.771</cell></row><row><cell>SAERS [11]</cell><cell>0.171</cell><cell>0.816</cell></row><row><cell>CARCA</cell><cell>0.184</cell><cell>0.841</cell></row><row><cell>Improvement over best baseline (%)</cell><cell>7.54</cell><cell>3.03</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Ablation analysis between different CARCA configurations on the Men dataset.</figDesc><table><row><cell>Configuration</cell><cell cols="2">HR@10 NDCG@10</cell></row><row><cell>Default (1)</cell><cell>0.550</cell><cell>0.349</cell></row><row><cell>Additive residual connections (2)</cell><cell>0.513</cell><cell>0.325</cell></row><row><cell>Concat. all features (3)</cell><cell>0.543</cell><cell>0.340</cell></row><row><cell>Concat. item features (4)</cell><cell>0.540</cell><cell>0.339</cell></row><row><cell>Positional encoding</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Conference'17, July 2017, Washington, DC, USA Rashed, et al.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/wuliwei9278/SSE-PT/issues/1</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Layer Normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">stat</title>
		<imprint>
			<biblScope unit="volume">1050</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Are we really making much progress? A worrying analysis of recent neural recommendation approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Maurizio Ferrari Dacrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietmar</forename><surname>Cremonesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jannach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM Conference on Recommender Systems</title>
		<meeting>the 13th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="101" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR09</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="https://github.com/ahmedrashed-ml/CARCA" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<ptr target="https://github.com/" />
		<title level="m">JiachengLi1995/TiSASRec for Computational Linguistics: Human Language Technologies</title>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Critically Examining the Claimed Value of Convolutions over User-Item Embedding Maps for Recommender Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Maurizio Ferrari Dacrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Parroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietmar</forename><surname>Cremonesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jannach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="355" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">DeepFM: A Factorization-Machine based Neural Network for CTR Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">VBPR: visual bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural factorization machines for sparse predictive analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recurrent neural networks with top-k gains for session-based recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bal?zs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM international conference on information and knowledge management</title>
		<meeting>the 27th ACM international conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="843" to="852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Explainable Fashion Recommendation: A Semantic Attribute Region Guided Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/650</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/650" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4681" to="4688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Self-attentive sequential recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Time interval aware selfattention for sequential recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th international conference on web search and data mining</title>
		<meeting>the 13th international conference on web search and data mining</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="322" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep collaborative filtering via marginalized denoising auto-encoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaya</forename><surname>Kawale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM international on conference on information and knowledge management</title>
		<meeting>the 24th ACM international on conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hierarchical gating networks for sequential recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="825" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Attribute-aware non-linear co-embeddings of graph features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Rashed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josif</forename><surname>Grabocka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM Conference on Recommender Systems</title>
		<meeting>the 13th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="314" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">MultiRec: A Multi-Relational Approach for Unique Item Recommendation in Auction Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Rashed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shayan</forename><surname>Jawed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Hintsches</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourteenth ACM Conference on Recommender Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="230" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Factorization machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steffen Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Data Mining. IEEE</title>
		<imprint>
			<biblScope unit="page" from="995" to="1000" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1205.2618</idno>
		<title level="m">BPR: Bayesian personalized ranking from implicit feedback</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Autoint: Automatic feature interaction learning via selfattentive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chence</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiping</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijian</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yewen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1161" to="1170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Embarrassingly shallow autoencoders for sparse data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><surname>Steck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3251" to="3257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhua</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwu</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM international conference on information and knowledge management</title>
		<meeting>the 28th ACM international conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1441" to="1450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Next-item recommendation with sequential hypergraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianling</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaize</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangjie</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Caverlee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1101" to="1110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Time to Shop for Valentine&apos;s Day: Shopping Occasions and Sequential Recommendation in E-commerce</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianling</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Louca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caitlin</forename><surname>Cellier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Caverlee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangjie</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
		<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="645" to="653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Stochastic Shared Embeddings: Data-driven Regularization of Embedding Layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuqing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Sharpnack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SSE-PT: Sequential recommendation via personalized transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuqing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Sharpnack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourteenth ACM Conference on Recommender Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="328" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Attentional factorization machines: learning the weight of feature interactions via attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>Hao Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 26th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3119" to="3125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">CFM: Convolutional Factorization Machines for Context-Aware Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joemon</forename><surname>Jose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="3926" to="3932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">AutoSVD++ An Efficient Hybrid Collaborative Filtering Model via Contractive Auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiwei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="957" to="960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Feature-level Deeper Self-Attention Network for Sequential Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengpeng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajie</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4320" to="4326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Joint representation learning for top-n recommendation with heterogeneous information sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1449" to="1458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep interest evolution network for click-through rate prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guorui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Na</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5941" to="5948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep interest network for click-through rate prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guorui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenru</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1059" to="1068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">S3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM &apos;20: The 29th ACM International Conference on Information and Knowledge Management, Virtual Event</title>
		<meeting><address><addrLine>Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020-10-19" />
			<biblScope unit="page" from="1893" to="1902" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
