<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Incremental Learning Techniques for Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umberto</forename><surname>Michieli</surname></persName>
							<email>umberto.michieli@dei.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padova</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Zanuttigh</surname></persName>
							<email>zanuttigh@dei.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padova</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Incremental Learning Techniques for Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning architectures exhibit a critical drop of performance due to catastrophic forgetting when they are required to incrementally learn new tasks. Contemporary incremental learning frameworks focus on image classification and object detection while in this work we formally introduce the incremental learning problem for semantic segmentation in which a pixel-wise labeling is considered. To tackle this task we propose to distill the knowledge of the previous model to retain the information about previously learned classes, whilst updating the current model to learn the new ones. We propose various approaches working both on the output logits and on intermediate features. In opposition to some recent frameworks, we do not store any image from previously learned classes and only the last model is needed to preserve high accuracy on these classes. The experimental evaluation on the Pascal VOC2012 dataset shows the effectiveness of the proposed approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction and Related Work</head><p>Deep neural networks are a key tool for computer vision systems. Despite their wide success on many visual recognition problems, neural networks struggle in learning new tasks whilst preserving good performance on previous ones since they suffer from catastrophic forgetting <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b20">21]</ref>. More precisely, the incremental learning problem is defined as the capability of machine learning architectures to continuously improve the learned model by feeding new data without losing previously learned knowledge. This has been widely studied in the context of problems like image classification and object detection <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35]</ref>. Traditional learning models require that all the samples corresponding to old and new tasks are available during all steps of the training stage; a real world system, instead, should be able to update its knowledge with few training steps incorporating the new tasks while preserving unaltered the previous ones. Such a behavior is inherently present in human brain which is incremental in the sense that new tasks are continuously incorporated but the existing knowledge is preserved.</p><p>Catastrophic forgetting represents one of the main limitations of neural networks. It has been addressed even before the rise of neural networks popularity <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b32">33]</ref>, but more recently it has been rediscovered and tackled in different ways. Some methods <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b35">36]</ref> exploit network architectures which grow during the training process. A different strategy consists in freezing or slowing down the learning process on some relevant parts of the network <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24]</ref>. Another way of retaining high performance on old tasks is knowledge distillation. This idea was originally proposed in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14]</ref> and then adapted in different ways in recent studies <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37]</ref> to maintain stable the responses of the network on the old tasks whilst updating it with new training samples. However, differently from this paper, previous works focus only on object detection or image classification problems.</p><p>Some studies keep a small portion of data belonging to previous tasks and use them to preserve the accuracy on old tasks when dealing with new problems <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b31">32]</ref>. The exemplar set to store is chosen at random or according to a relevance metric. In <ref type="bibr" target="#b4">[5]</ref> the classifier and the features for selecting the samples to be added in the representative memory are learned jointly and herding selection is then used. Another method of this family is the only work considering an incremental setting for semantic segmentation <ref type="bibr" target="#b31">[32]</ref>, which however focuses on a very specific setup related to satellite images and has several limitations when applied to generic semantic segmentation problems. Indeed, it considers the segmentation as a multi-task learning problem, where a binary classification for each class replaces the multi-class labeling, and it stores some patches of previously seen images. Furthermore it assumes that training images corresponding to an incremental step only contain new classes while the capabilities on old ones are preserved by storing a subset of the old images. For large amount of classes and wide range of applications the methodology does not scale properly.</p><p>Storing previously seen data could represent a serious limitation for certain applications where privacy issues or limited storage budgets are present. For this reason, some recent methods <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">35]</ref> do not store old data but com-pensate this by training Generative Adversarial Networks (GANs) to generate images containing previous classes while new classes are learned. Some other approaches do not make use of exemplars set <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b36">37]</ref>. In <ref type="bibr" target="#b29">[30]</ref> an end-to-end learning framework is proposed where the representation and the classifier are learned jointly without storing any of the original training samples. In <ref type="bibr" target="#b17">[18]</ref> previous knowledge is distilled directly from the last trained model. In <ref type="bibr" target="#b36">[37]</ref> the current model distills the knowledge from pruned versions of all previous model snapshots.</p><p>Even if previous studies focus on different tasks and no work has been conducted on incremental learning for dense labeling task, semantic segmentation is a key task that computer vision systems must face frequently in various applications e.g., in robotics or autonomous driving <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b21">22]</ref>. Notice that, differently from image classification, in semantic segmentation each image contains together pixels belonging to multiple classes and the labeling is dense. In particular the pixels could represent newly added classes and previously existing ones, making the problem conceptually different from incremental learning in image classification where typically a single object is present in the image and the outcome is a unique value. Furthermore, contrary to many existing methods, we consider the most challenging setting where images from old tasks are not stored and cannot be used to help the incremental process, which is particularly relevant for the vast majority of applications with privacy concerns or storage requirements.</p><p>In the first part of this paper we formalize the problem and we present possible settings for the incremental learning task. Then we introduce a novel framework to perform incremental learning for semantic segmentation. In particular we re-frame the distillation loss concept used in other fields and we propose a novel approach where the distillation loss is applied to the intermediate features level. Furthermore, we exploited the idea of freezing the encoder part of the network to preserve the feature extraction capabilities. To the best of our knowledge this is the first work on incremental learning for semantic segmentation which does not retain previously seen images and that has been evaluated on standard datasets, i.e., Pascal VOC2012 <ref type="bibr" target="#b9">[10]</ref>. Experimental results demonstrate that the proposed approaches obtain high accuracy even without storing any of the previous examples thanks to the proposed distillation schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem Formulation</head><p>The incremental learning task, when referring to semantic segmentation, can be defined as the ability of a learning system (e.g., a neural network) to learn the segmentation and the labeling of the new classes without forgetting or deteriorating too much the performance on previously learned ones. The performance of an incremental learning algo-rithm should be evaluated considering the accuracy on the new classes as well as the accuracy on the old ones. While the first should be as large as possible, meaning that the algorithm is able to learn the new classes, the second should be as close as possible to the one before the addition of the new classes, thus avoiding catastrophic forgetting. The key challenge then is how to balance between the preservation of previous segmentation and labeling knowledge and the capability of learning the new classes. Additionally, the considered problem is particularly hard when no data of previous tasks can be preserved, which is the scenario of interest in the majority of the applications. In this work we focus on the most general incremental learning framework in which: previously seen images are not used; the new images contain examples of the unseen classes combined together with pixels belonging to the old ones; the complexity of the approach scales well as the number of classes grows.</p><p>Let us assume that the available set of samples is D and is composed of N images. As usual part of the data is used for training and part for testing: we refer to the training split of D as D tr . Each pixel in each image of D is associated to a unique class belonging to the set C = {c 0 , c 1 , c 2 , ..., c C?1 } of C possible classes. In case a background class is present we associate it to class c 0 because it is considered a special class with a non-conventional behavior being present in almost all the images and having by far the largest occurrence among the elements of C.</p><p>In the incremental learning setting we assume that we have trained our network to recognize a subset S 0 ? C of seen classes using a labeled subset D tr 0 ? D tr , whose images contain only pixels belonging to the classes in S 0 . We then perform some incremental steps k = 1, 2, ... in which we want to recognize a new subset U k ? C of unseen classes. Notice that at the k-th incremental step the set of seen classes S k?1 is the union of all the classes previously learned and after the step we add the ones learned during the current step k: more formally, S k = S k?1 ? U k and S k?1 ? U k = ?. At each step a new set of training samples is available, i.e., D tr k ? D tr , whose images contain only pixels belonging to S k?1 ? U k . The set is disjoint from previously used samples, i.e., j=0,...,k?1 D tr j ? D tr k = ?. It is important to notice that, differently from image classification, images in D tr k could also contain classes belonging to S k?1 , however their occurrence is limited since D tr k is restricted to consider only images containing at least one class belonging to U k . Furthermore, the specific occurrence of a particular class belonging to S k?1 is highly correlated to the set of classes being added (i.e., U k ). For example if we assume that S k?1 = {chair , airplane} and that U k = {dining table}, then it is reasonable to expect that D tr k contains some images having the chair class, that typically appears together with the dining table, while the class airplane is extremely unlikely. Given this scenario, there exist many different ways of sampling the set U k ? C of unseen classes and of selecting the cardinality of the sets U k at each step, leading to different experiments. Previous work <ref type="bibr" target="#b29">[30]</ref> ordered the classes using the sequence provided by the creators of the dataset and analyzed the behavior of the algorithms to the addition of a single class, the addition of a batch of classes and the sequential addition of classes. Our results stick to these settings to reproduce the same scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intermediate Feature Space</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>In this work we start by re-framing incremental learning techniques developed for other fields in the semantic segmentation task. Then we propose some novel strategies explicitly targeted to this problem.</p><p>The proposed approaches can be fitted into any deep network architecture, however for the evaluation we chose the Deeplab v2 network (without the post-processing based on CRFs) with ResNet-101 as feature extractor <ref type="bibr" target="#b7">[8]</ref> pre-trained <ref type="bibr" target="#b22">[23]</ref> on the MSCOCO dataset <ref type="bibr" target="#b18">[19]</ref>. The pre-training of the feature extractor (as done also in other incremental learning works as <ref type="bibr" target="#b17">[18]</ref>) is needed since the Pascal VOC 2012 is too small to be used for training the Deeplab v2 from scratch. However MSCOCO data are used only for the initialization of the feature extractor and the contained labeling information, even if there are overlapping classes, is related to a different task (i.e., image classification).</p><p>The various procedures to achieve incremental learning in semantic segmentation are now introduced: see <ref type="figure" target="#fig_0">Fig. 1</ref> for a general overview of the approach. We start by training the chosen network architecture in the first stage to recognize the classes in S 0 with the corresponding training data D tr 0 . The network is trained in a supervised way with a standard cross-entropy loss and after training we save the obtained model as M 0 . Then, we perform a set of incremental steps indexed by k = 1, 2, ... to make the model learn every time a new set of classes U k . At the k-th incremental step, the current training set D tr k is built with images that contain samples from at least one of the new classes. Notice that they can possibly contain also pixels belonging to previously seen classes and of course the background class is present in almost all images. During step k, the model M k?1 is loaded and updated exploiting a linear combination of two losses: a cross-entropy loss L CE , which learns how label the classes, and a distillation loss L D , which helps to retain knowledge of previously seen classes and will be detailed in the following. After the k-th incremental step, we save the current model as M k and the described procedure is repeated every time a new set of classes to be learned is taken into account. The total loss L to train the model is:</p><formula xml:id="formula_0">L = L CE + ? D L D<label>(1)</label></formula><p>The parameter ? D balances the two terms. If we set ? D = 0 then we are considering the simplest scenario of fine-tuning in which no knowledge distillation is applied and the cross-entropy loss is applied to both unseen and seen classes (but in D tr k there is a large unbalance toward the new ones, see Section 2). As already pointed out, we expect this case to exhibit catastrophic forgetting.</p><p>During the k-th incremental step the cross-entropy loss L CE is applied to all the classes and it is defined as:</p><formula xml:id="formula_1">L CE = ? 1 |D tr k | Xn?D tr k c?S k?1 ?U k Y n [c]?log (M k (X n ) [c]) (2) where Y n [c] and M k (X n ) [c]</formula><p>are respectively the one-hot encoded ground truth and the output of the network corresponding to the estimated score for class c. Notice that the sum is computed on both old and new classes because in practice old classes will continue to appear. However since the new classes are much more likely in D tr k , there is a clear unbalance toward them leading to catastrophic forgetting <ref type="bibr" target="#b33">[34]</ref>. We introduce two possible strategies for defining the distillation loss L D which only depend on the previous model M k?1 avoiding the need for large storage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Distillation on the Output Layer (L D )</head><p>The first considered distillation term L D for semantic segmentation is the masked cross-entropy loss between the logits produced by the output of the softmax layer in the previous model M k?1 and the output of the softmax layer in the current model M k (assume that we currently are at the k-th incremental step). The cross-entropy is masked to consider already seen classes only since we want to guide the learning process to retain them, i.e.:</p><formula xml:id="formula_2">L D = ? 1 |D tr k | Xn?D tr k c?S k?1 M k?1 (X n )[c]?log (M k (X n )[c])<label>(3)</label></formula><p>The loss L D is our baseline model and some enhancements of the scheme have been evaluated. A first modification moves from the consideration that the encoder E aims at extracting some intermediate feature representation from the input information: hence the encoder part of the network can be frozen to the status it reached after the previous steps (E F in short, see <ref type="figure" target="#fig_1">Fig. 2</ref>). In this way the network is constrained to learn new classes only through the decoder, while preserving the features extraction capabilities unchanged from the previous training stage. We evaluated this approach both with and without the application of the distillation loss in Eq. (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Distillation on Intermediate Feature Space (L D )</head><p>A different approach we designed to preserve previous knowledge by keeping the encoder similar to the already learned model is to apply a knowledge distillation function to the intermediate level of the features space before the decoding stage. The distillation function on the features space in this case should be no longer the cross-entropy but rather the L2 loss. This choice is due to the fact that the considered layer is not anymore a classification layer but instead just an internal stage where the output should be kept close to the previous one in, e.g., L2-norm. Empirically, we found that using cross-entropy or L1 lead to worse results. Considering that model M k can be decomposed into an encoder E k and a decoder, the distillation term would become:</p><formula xml:id="formula_3">L D = E k?1 (X n ) ? E k (X n ) 2 2 |D tr k |<label>(4)</label></formula><p>where E k (X n ) denotes the features computed by E k when a generic image X n ? D tr k is fed as input. A summary of the proposed strategies is shown in <ref type="figure" target="#fig_0">Fig. 1</ref> where the different losses are shown. As a final remark, we also tried a combination of the described distillation losses but it did not provide relevant enhancements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>For the experimental evaluation we selected the Deeplab v2 architecture and we performed the tests on the Pascal VOC2012 <ref type="bibr" target="#b9">[10]</ref> benchmark. This widely used dataset consists of 10582 images in the training split and 1449 in the validation split with a total of 21 different classes (background included). Since the test set has not been made available, all the results have been computed on the validation split as done by most approaches in the literature.</p><p>We trained our network with Stochastic Gradient Descent (SGD) as done in <ref type="bibr" target="#b7">[8]</ref>. The initial stage of training of the network on the set S 0 is performed by setting the starting learning rate to 10 ?4 and training for |S 0 | ? 1000 steps decreasing the learning rate up to 10 ?6 with a polynomial decay rule with power 0.9. We included weight decay regularization of 10 ?4 and we employed a batch size of 4 images. The incremental training steps k = 1, 2, ... have been performed employing a lower learning rate to better preserve previous weights. In this case the learning rate starts from 5 ? 10 ?5 and decreases up to 10 ?6 after |U k | ? 1000 steps of polynomial decay. Notice that we train the network for a number of steps which is proportional to the number of new classes to be learned. We used TensorFlow <ref type="bibr" target="#b0">[1]</ref> to develop and train the network: the overall training procedure takes around 5 hours on a NVIDIA 2080 Ti GPU. The code is available online at https://lttm.dei. unipd.it/paper_data/IL. The metrics we considered are the most widely used for semantic segmentation: the per-class Intersection over Union (IoU), the mean Pixel Accuracy (mPA), the mean Class Accuracy (mCA) and the mean IoU (mIoU) <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Addition of One Class</head><p>Following <ref type="bibr" target="#b29">[30]</ref> we first analyze the addition of the last class, in alphabetical order, to our network. Specifically, we consider S 0 = {c 0 , c 1 , ..., c 19 } and U 1 = {c 20 } = {tv \monitor }. A summary of the evaluation of the proposed methodologies on the VOC2012 validation split is reported in <ref type="table">Table 1</ref>. We indicate as M 0 (0?19) the first standard training of the network using D tr 0 as training dataset. The network is then updated exploiting the dataset D tr 1 and the resulting model is referred to as M 1 <ref type="bibr" target="#b19">(20)</ref>. From the first row of <ref type="table">Table 1</ref> we can appreciate that fine-tuning the network leads to an evident degradation of the performance with a final mIoU of 65.1%. This is a clear confirmation of the catastrophic forgetting phenomenon in the semantic segmentation scenario even with the addition of just one single class. The reference model, indeed, where all the 21 classes are learned at once (we call it M 0 (0 ? 20)) achieves a mIoU of 73.6%. The main issue of the fine-tuning approach is that it predicts too frequently the last class, as proved by the fact that the model has a very high pixel accuracy for the tv /monitor class but a very poor IoU of 20.1%. This is due to the high number of false positive detection of the considered class which are not taken into account by the pixel accuracy measure. On the same class, the proposed methods are all able to outperform the fine-tuning approach in terms of IoU by large margin. Knowledge distillation strategies and the procedure of freezing the encoder provide  <ref type="table">Table 1</ref>. Per-class IoU on the Pascal VOC2012 under some settings when the last class, i.e. the tv/monitor class, is added.</p><p>better results because they act as regularization constraints. Interestingly those procedures allow to achieve higher accuracy not only on previously learned classes but also on newly added ones, which might be unexpected if we do not consider the regularization behavior of those terms. We can appreciate that the distillation on the output L D alone is able to improve the average mIoU by 3.3% with respect to the standard case. Furthermore it leads to a much better IoU on the new class, greatly reducing the aforementioned false positives issue. If we completely freeze the encoder E without applying knowledge distillation the model improves the mIoU by 5.4%. If we combine the two mentioned approaches, i.e. we freeze E and we apply L D as distillation loss, the mIoU further improves to 71.5% with an improvement of 6.4%, higher than each of the two methods alone (also the performance on the new class is higher).</p><p>If we apply a L2 loss at the intermediate features space, i.e., to use L D , the model achieves 71.6% of mIoU, which is 6.5% higher than the standard approach. It is noticeable that two completely different approaches to preserve knowledge from the previous model, namely "M 1 <ref type="bibr" target="#b19">(20)</ref> with E F , L D " (which applies a cross-entropy between the outputs with encoder frozen) and "M 1 (20) with L D " (which applies a L2loss between features spaces), achieve similar and high results both on the new class and on old ones. Notice that if the encoder is frozen then it does not make sense to enable the L D loss.</p><p>An interesting aspect is that the changes in performance on previously seen classes are correlated with the class being added. Some classes have even higher results in terms of mIoU than before because their prediction has been reinforced through the new training set. For example, objects of the classes sofa or dining table are typically present in scenes containing a tv /monitor . Classes containing uncorrelated objects that are not present inside the new set of samples D tr 1 instead get more easily lost, for example the bird or horse which are not present in indoor scenes typically associated with the tv/monitor class being added.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Addition of Five Classes</head><p>In this section we tackle a more challenging scenario where the initial learning stage is followed by one step of incremental learning with the last 5 classes to learn. First, the addition of the last 5 classes at once (referred to as 15?20) is discussed and the results are shown in <ref type="table" target="#tab_1">Table 2</ref>. In this setting the results are much lower than in the previous cases where a single class was added at a time since there is a larger amount of information to be learned. In particular, the fine-tuning approach exhibits an even larger drop in accuracy because it overestimates the presence of the new classes. We can confirm this by looking at the IoU scores of the newly added classes which are often lower than the proposed approaches by a large margin. In this setting the distillation on the output layer, "M 1 <ref type="bibr">(16 ? 20)</ref> with L D ", achieves the highest accuracy. In general in this case the approaches based on L D outperform the other ones. It is interesting to notice that some previously seen classes exhibit a clear catastrophic forgetting phenomenon because the updated models mislead them with visually similar classes belonging to the set of new classes. This is particularly true, for example, for the cow and chair classes which are often misled (low IoU and low pixel accuracy for these classes) with the newly added classes sheep and sofa that have similar shapes (low IoU but high pixel accuracy for these classes). This can be seen also in the qualitative results in <ref type="figure" target="#fig_2">Fig. 3</ref>. For example, in the first two rows the tv /monitor and the sofa classes (which are added during the incremental step) are erroneously predicted in the background region, while these classes are correctly handled by applying L D and freezing the encoder. Additionally, in the third row the na?ve approach predicts the person class in spite of the sofa while this artifact is not present when using L D .</p><p>The last experiment presented here is the one in which the last 5 classes are progressively added one by one: the final model is referred to as M 5 <ref type="bibr">(16 ? 20)</ref>. The results are reported in <ref type="table">Table 3</ref> where we can appreciate a large gain of 20% of mIoU between the best proposed method (i.e., "M 5 <ref type="bibr">(16 ? 20)</ref> with E F , L D ") and the standard approach. In this case freezing the encoder and distilling the knowledge is the best approach because the addition of one sin-  <ref type="table">Table 3</ref>. Per-class IoU on the Pascal VOC2012 under some settings when 5 classes are added sequentially.</p><formula xml:id="formula_4">RGB GT Fine-tuning M1E F L D M0</formula><p>background cat chair dog person plant sofa tv unlabeled  gle class do not alter too much the responses of the whole network: distilling the knowledge from the previous model when the encoder is fixed guides the decoder to modify only the responses for the new class. The evolution of the models' mean performance over time is reported in <ref type="table">Table 4</ref> where the distribution of the drop of performance during the different steps is analyzed. In particular we can notice how the accuracy drop is affected by the specific class being added. As expected the larger drop is experienced when the classes sheep or train are added (models M 2 (17) and M 4 <ref type="bibr" target="#b18">(19)</ref>) because such classes are only sparsely correlated with other classes (they mainly appear alone or with the person class).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>In this work we formally introduced the problem of incremental learning for semantic segmentation. A couple of novel distillation loss functions have been designed ad-hoc for the task. They have been combined with a cross-entropy loss and with the idea of freezing the encoder module to optimize the performance on new classes while preserving old ones. Our method does not need any stored image of previous datasets and only the previous model is used to update the current one thus reducing memory consumption.</p><p>Experiments on the Pascal VOC2012 dataset show that the proposed methods were able to largely outperform the standard fine-tuning approach, thus alleviating the catastrophic forgetting phenomenon. However, the problem of incremental learning for semantic segmentation is a novel challenging task that needs advanced strategies to be tackled. This is proved by the fact that the results are lower than the ones achieved by the same architecture after a one-step training, i.e., when all training examples are available and employed at the same time. In the future we plan to expand our set of experiments, to develop novel incremental learning strategies and to employ GANs to generate images containing already seen classes. Finally we will consider the scenario in which classes that will appear in the future are present from the beginning but labeled as background.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Overview of the k-th incremental step of our learning framework for semantic segmentation of RGB images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Freezing schemes of the encoder at k-th incremental step. The whole model at previous step, i.e. M k?1 , is always completely frozen and is employed only for knowledge distillation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Qualitative results on sample scenes for the addition of five classes all at once (best viewed in colors).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Fine-tuning 90.2 80.<ref type="bibr" target="#b7">8</ref> 33.3 83.1 53.7 68.2 84.6 78.0 83.2 32.1 73.4 52.6 76.6 72.7 68.8 79.8 43.8 76.5 46.5 68.4 67.3 20.1 65.1 90.7 76.5 L D 92.0 83.9 37.0 84.0 58.8 70.9 90.9 82.5 86.1 32.1 72.5 51.0 79.9 72.3 77.3 80.9 45.1 78.1 45.7 79.9 70.0 35.3 68.4 92.5 79.5 E F 92.7 86.2 32.6 82.9 61.7 74.6 92.9 83.1 87.7 27.4 79.4 59.0 79.4 76.9 77.2 81.2 49.6 80.8 49.3 83.4 71.9 43.3 70.5 93.2 81.4 E F , L D 92.9 86.1 37.1 83.6 62.2 76.1 93.2 82.9 88.3 30.6 79.6 58.5 80.3 77.6 77.2 81.8 49.8 81.0 47.0 84.5 72.5 51.4 71.5 93.4 82.5 L D 92.9 84.8 36.4 82.6 63.5 75.0 92.2 83.6 88.3 29.5 80.3 59.6 79.7 80.2 78.9 81.2 49.7 78.9 51.0 84.1 72.6 50.6 71.6 93.4 83.4 L D , L D 92.9 86.0 36.5 84.4 61.8 76.2 93.1 83.1 88.6 30.4 79.7 58.7 80.4 78.1 76.4 82.0 50.5 81.0 50.4 85.1 72.8 49.9 71.7 93.5 83.4 M 0 (0 ? 19) 93.4 85.5 37.1 86.2 62.2 77.9 93.4 83.5 89.3 32.6 80.7 57.3 81.5 81.2 77.7 83.0 51.5 81.6 48.2 85.0 73.4 -73.4 93.9 84.3 M 0 (0 ? 20) 93.4 85.4 36.7 85.7 63.3 78.7 92.7 82.4 89.7 35.4 80.9 52.9 82.4 82.0 76.8 83.6 52.3 82.4 51.1 86.4 73.7 70.5 73.6 93.9 84.2</figDesc><table><row><cell>M 1 (20)</cell><cell>backgr.</cell><cell>aero</cell><cell>bike</cell><cell>bird</cell><cell>boat</cell><cell>bottle</cell><cell>bus</cell><cell>car</cell><cell>cat</cell><cell>chair</cell><cell>cow</cell><cell>din. table</cell><cell>dog</cell><cell>horse</cell><cell>mbike</cell><cell>person</cell><cell>plant</cell><cell>sheep</cell><cell>sofa</cell><cell>train</cell><cell>mIoU old</cell><cell>tv</cell><cell>mIoU</cell><cell>mPA</cell><cell>mCA</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>M 1(16 ? 20)    Fine-tuning 89.7 59.<ref type="bibr" target="#b4">5</ref> 34.6 68.2 58.1 58.8 59.2 79.2 80.2 30.0 12.7 51.0 72.5 61.7 74.4 79.4 60.6 36.4 32.4 27.2 55.2 42.4 38.7 55.4 88.4 70.6 L D 91.4 85.0 35.6 84.8 61.8 70.5 85.6 77.9 83.6 30.7 72.0 45.4 76.1 76.9 77.0 81.3 71.0 33.8 54.9 30.8 73.9 51.6 49.0 65.7 91.6 78.0 E F , L D 91.7 83.4 35.6 78.7 60.9 73.0 65.8 82.2 87.0 30.2 58.0 55.3 80.0 78.3 78.5 81.4 70.0 35.3 46.1 32.3 62.1 53.5 45.8 64.2 91.5 76.1 L D 90.9 81.4 33.9 80.3 61.9 67.4 73.1 81.8 84.8 31.3 0.4 55.8 76.1 72.2 77.7 81.2 65.6 39.4 31.8 31.3 64.1 52.9 43.9 60.5 90.0 74.9 M 0 (0 ? 15) 94.0 83.5 36.1 85.5 61.0 77.7 94.1 82.8 90.0 40.0 82.8 54.9 83.4 81.2 78.3 83.? 20) 93.4 85.4 36.7 85.7 63.3 78.7 92.7 82.4 89.7 35.4 80.9 52.9 82.4 82.0 76.8 83.6 75.1 52.3 82.4 51.1 86.4 70.5 68.5 73.6 93.9 84.2 Per-class IoU on the Pascal VOC2012 under some settings when 5 classes are added all at once. ? 20) 93.4 85.4 36.7 85.7 63.3 78.7 92.7 82.4 89.7 35.4 80.9 52.9 82.4 82.0 76.8 83.6 75.1 52.3 82.4 51.1 86.4 70.5 68.5 73.6 93.9 84.2</figDesc><table><row><cell></cell><cell>backgr.</cell><cell>aero</cell><cell>bike</cell><cell>bird</cell><cell>boat</cell><cell>bottle</cell><cell>bus</cell><cell>car</cell><cell>cat</cell><cell>chair</cell><cell>cow</cell><cell>din. table</cell><cell>dog</cell><cell>horse</cell><cell>mbike</cell><cell>person</cell><cell>mIoU old</cell><cell>plant</cell><cell>sheep</cell><cell>sofa</cell><cell>train</cell><cell>tv</cell><cell>mIoU new</cell><cell>mIoU</cell><cell>mPA</cell><cell>mCA</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">2 75.5 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="4">-75.5 94.6 86.4</cell></row><row><cell>M 0 (0 M 5 (16 ? 20)</cell><cell>backgr.</cell><cell>aero</cell><cell>bike</cell><cell>bird</cell><cell>boat</cell><cell>bottle</cell><cell>bus</cell><cell>car</cell><cell>cat</cell><cell>chair</cell><cell>cow</cell><cell>din. table</cell><cell>dog</cell><cell>horse</cell><cell>mbike</cell><cell>person</cell><cell>mIoU old</cell><cell>plant</cell><cell>sheep</cell><cell>sofa</cell><cell>train</cell><cell>tv</cell><cell>mIoU new</cell><cell>mIoU</cell><cell>mPA</cell><cell>mCA</cell></row><row><cell cols="27">Fine-tuning 87.9 25.6 29.0 51.2 1.7 57.8 10.5 64.8 80.5 30.8 22.9 52.7 66.8 52.1 51.9 78.1 47.8 36.5 44.7 31.8 35.1 17.1 33.0 44.2 86.1 55.7</cell></row><row><cell>L D</cell><cell cols="26">89.7 51.2 29.7 77.5 15.0 62.7 29.1 78.5 75.7 24.4 55.6 44.8 76.2 62.5 65.6 80.1 57.4 25.5 35.7 30.8 42.3 40.4 34.9 52.0 88.6 63.2</cell></row><row><cell>E F , L D</cell><cell cols="26">91.1 73.9 31.9 81.4 59.5 71.9 73.1 82.1 87.1 27.2 77.4 56.4 79.1 79.9 76.1 80.7 70.5 31.6 55.3 30.4 62.2 41.4 44.2 64.3 91.3 75.2</cell></row><row><cell>L D</cell><cell cols="26">90.3 54.2 28.2 78.4 52.5 69.8 59.5 78.5 86.3 28.8 72.3 57.4 76.3 77.1 65.8 79.3 65.9 36.3 65.5 31.6 54.7 38.9 45.4 61.0 90.4 71.0</cell></row><row><cell cols="19">M 0 (0 ? 15) 94.0 83.5 36.1 85.5 61.0 77.7 94.1 82.8 90.0 40.0 82.8 54.9 83.4 81.2 78.3 83.2 75.5 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="4">-75.5 94.6 86.4</cell></row><row><cell>M 0 (0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>(16) 71.2 93.7 82.5 72.4 94.2 83.0 72.5 94.1 83.5 72.2 93.9 84.3 M 2 (17) 53.8 90.0 61.8 68.1 93.4 78.5 68.4 93.3 79.5 60.0 91.6 69.4 M 3 (18) 57.7 87.7 68.7 63.3 90.8 74.5 66.5 91.5 79.4 65.5 90.7 76.8 M 4 (19) 39.3 85.9 47.4 54.1 89.2 64.3 61.3 90.6 72.5 52.1 89.0 60.6 M 5 (20) 44.2 86.1 55.7 52.0 88.6 63.2 64.3 91.3 75.2 61.0 90.4 71.0 Table 4. Mean IoU, mPA and mCA on the Pascal VOC2012 under some settings when 5 classes are added sequentially.</figDesc><table><row><cell>Fine-tuning</cell><cell>L D</cell><cell>E F , L D</cell><cell>L D</cell></row><row><cell cols="4">mIoU mPA mCA mIoU mPA mCA mIoU mPA mCA mIoU mPA mCA</cell></row><row><cell>M 1</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th Symposium on Operating Systems Design and Implementation</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Memory aware synapses: Learning what (not) to forget</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Aljundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Babiloni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="139" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised Domain Adaptation for Semantic Segmentation of Urban Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Biasetton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Michieli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Agresti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zanuttigh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<publisher>CVPRW</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bucilu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<meeting>the 12th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="535" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">End-to-end incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Mar?n-Jim?nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Guil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Alahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="233" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incremental and decremental support vector machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cauwenberghs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="409" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Riemannian walk for incremental learning: Understanding forgetting and intransigence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="532" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">What is a good evaluation measure for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Larlus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meylan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">2013</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html.2,4" />
		<title level="m">The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting in connectionist networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>French</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="128" to="135" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Active long term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Furlanello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Tjan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02355</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An empirical investigation of catastrophic forgetting in gradient-based neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS) Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Lifelong learning via progressive distillation and retrospection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="437" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Istrate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C I</forename><surname>Malossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bekas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nikolopoulos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.10232</idno>
		<title level="m">Incremental training of deep convolutional neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clopath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="3521" to="3526" />
			<date type="published" when="2017" />
			<publisher>PNAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Gradient episodic memory for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6467" to="6476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Catastrophic interference in connectionist networks: The sequential learning problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Psychology of learning and motivation</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1989" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="109" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Game Theoretic Analysis of Road User Safety Scenarios Involving Autonomous Vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Michieli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Badia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Personal, Indoor and Mobile Radio Communications</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1377" to="1381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Pre-computed weights for ResNet-101</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nekrasov</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning and transferring mid-level image representations using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oquab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1717" to="1724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learn++: An incremental learning algorithm for supervised neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Polikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Upda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Upda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Honavar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Systems, Man, and Cybernetics, part C (Applications and Reviews)</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="497" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">icarl: Incremental classifier and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sperl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05800</idno>
		<title level="m">Tree-CNN: a hierarchical deep convolutional neural network for incremental learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ankit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.02719</idno>
		<title level="m">Incremental learning in deep convolutional neural networks using partial network sharing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Continual learning with deep generative replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2990" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Incremental learning of object detectors without catastrophic forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shmelkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Alahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="3400" to="3409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning without memorizing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Incremental Learning for Semantic Segmentation of Large-Scale Remote Sensing Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tasar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Alliez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.12448</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Is learning the n-th thing any easier than learning the first?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="640" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Large scale incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.00853</idno>
		<title level="m">Incremental classifier learning with generative adversarial networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Errordriven incremental learning in deep convolutional neural network for large-scale image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM International Conference on Multimedia (ACMMM)</title>
		<meeting>the 22nd ACM International Conference on Multimedia (ACMMM)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">M2kd: Multi-model and multi-level knowledge distillation for incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
