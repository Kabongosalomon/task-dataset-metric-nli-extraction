<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PP-Matting: High-Accuracy Natural Image Matting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guowei</forename><surname>Chen</surname></persName>
							<email>chenguowei01@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncai</forename><surname>Peng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuying</forename><surname>Hao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lutao</forename><surname>Chu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zewu</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiliang</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Dang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianhai</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PP-Matting: High-Accuracy Natural Image Matting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Natural image matting is a fundamental and challenging computer vision task. It has many applications in image editing and composition. Recently, deep learningbased approaches have achieved great improvements in image matting. However, most of them require a usersupplied trimap as an auxiliary input, which limits the matting applications in the real world. Although some trimapfree approaches have been proposed, the matting quality is still unsatisfactory compared to trimap-based ones. Without the trimap guidance, the matting models suffer from foreground-background ambiguity easily, and also generate blurry details in the transition area. In this work, we propose PP-Matting, a trimap-free architecture that can achieve high-accuracy natural image matting. Our method applies a high-resolution detail branch (HRDB) that extracts fine-grained details of the foreground with keeping feature resolution unchanged. Also, we propose a semantic context branch (SCB) that adopts a semantic segmentation subtask. It prevents the detail prediction from local ambiguity caused by semantic context missing. In addition, we conduct extensive experiments on two well-known benchmarks: Composition-1k and Distinctions-646. The results demonstrate the superiority of PP-Matting over previous methods. Furthermore, we provide a qualitative evaluation of our method on human matting which shows its outstanding performance in the practical application. The code and pre-trained models will be available at PaddleSeg: https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Natural image matting refers to accurately estimating the per-pixel opacity of the target foreground from an image. As a fundamental and challenging computer task, image matting has received great interest from both academia and industry and has been extensively studied in the past decades <ref type="bibr">[1-3, 7, 10, 12-15, 18, 19, 31]</ref>. Intuitively, image <ref type="bibr">Figure 1</ref>. Comparison of segmentation and matting. The original image is on the left, the segmentation results is in the middle, and the matting results is on the right. matting generates more natural and delicate foreground than semantic segmentation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25]</ref> as shown in <ref type="figure">Figure 1</ref>. It is a key technique of image/video editing and composition, which has been widely used in virtual reality, augmented reality, and film production <ref type="bibr" target="#b3">[4]</ref>.</p><p>Formally, an image I ? R H?W ?3 is a composite of a foreground image F ? R H?W ?3 and a background image B ? R H?W ?3 . The color of the i-th pixel in the given image can be formulated as a linear combination equation of foreground and background colors with alpha matte ? ? R H?W ,</p><formula xml:id="formula_0">I i = ? i F i + (1 ? ? i )B i<label>(1)</label></formula><p>where ? i is the foreground opacity at pixel i. The image matting problem is highly ill-posed with 7 values to be solved, but only 3 values are known for each pixel in a given RGB image. To decrease the difficulty of this problem, matting approaches usually require an auxiliary input, e.g.</p><p>trimap, in addition to the original image <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b17">18]</ref>. The trimap is a rough segmentation of the image into three parts: foreground, background and transition (regions with unknown opacity). Although deep learning-based approaches have been proven powerful in the field of image matting, most early works still need to take the extra trimap as the input, which limits the application of the network. Most users have difficulty in creating a trimap. In some cases, it is not feasible to provide the trimap, e.g. live video.</p><p>Recently, trimap-free approaches have emerged <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref>, which do not require a usersupplied trimap as the auxiliary input. Lin et al. <ref type="bibr" target="#b22">[23]</ref> and Sengupta et al. <ref type="bibr" target="#b31">[32]</ref> replace the trimap with a background image that is easier to obtain. However, if the provided background image is much different from the real background, the performance deteriorates dramatically, e.g. in a dynamic environment. Thus, using the background image as input is still not flexible, and using a single image as input would be promising in practice. The approaches in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b32">33]</ref> separate the trimap-free prediction into a semantic segmentation task and a matting task. The segmentation task takes the single image to generate a 3-classes mask that is taken as a trimap automatically, and then it is concatenated with the original image as input to the matting task. However, the multi-stage approaches could introduce the problem of accumulative error, if the former segmentation task outputs an incorrect mask. Besides, the training of the multi-stage model is difficult.</p><p>To overcome the multi-stage limitation, single-stage approaches have been proposed <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29]</ref>, where the single stage means they can be trained in an end-to-end way without the intermediate result generation. Qiao et al. <ref type="bibr" target="#b28">[29]</ref> propose spatial attention on appearance cues to filtrate image texture details and implicit global guidance, which is challenging to generate alpha well. Li et al. <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> design a glance branch and a focus branch to make semantic prediction and detail prediction, but the two branches do not have enough interaction. The downsample-upsample design of the focus branch also makes the details blurry in high-resolution images. Therefore, the previous approaches have difficulty in aggregating semantic and detail information, so they fail to carry out high-accuracy image matting.</p><p>In this work, we propose a semantic-aware architecture named PP-Matting, which achieves high-accuracy image matting. To obtain fine-grained details of the foreground, our method applies a high-resolution detail branch (HRDB). It keeps high resolution while extracting features in different levels rather than a downsample-upsample encoderdecoder structure. Due to a lack of semantics, the detail prediction is prone to foreground-background ambiguity. Thus, we propose a semantic context branch (SCB) that employs the segmentation subtask to ensure the semantic correctness of details. Then, the final alpha matte is obtained by fusing the detail prediction from HRDB with the semantic map of SCB. Furthermore, the extensive experiments on Composition-1k and Distinctions-646 demonstrate our state-of-the-art performance compared to previous methods.</p><p>Our main contributions are summarized as follows:</p><p>? We propose PP-Matting, a high-accuracy matting network, which takes a single image as input without any auxiliary information. The whole network can be trained easily in an end-to-end way.</p><p>? We propose the two-branch architecture that extracts detail and semantic features efficiently in parallel. With a guidance flow mechanism, the proper interaction of the two branches helps the network achieve better semantic-aware detail prediction.</p><p>? We evaluate PP-Matting on Composition-1k and Distinctions-646 datasets. The results demonstrate the superiority of PP-Matting over other methods. Another experiment on human matting also shows its outstanding performance in practical application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Natural image matting is an active topic in both academia and industry. In general, there are roughly two categories of matting approaches: traditional matting and deep-learning matting.</p><p>Traditional matting. Traditional approaches usually take an RGB-channel image together with additional inputs, i.e. trimap or scribbles. The trimap is a rough segmentation of the image into three parts: foreground, background, and transition region, while the scribbles indicate a small number of pixels belonging to the foreground or background. The purpose of the additional inputs is to reduce the difficulty of alpha mattes estimation, which is a highly ill-posed problem. According to how the additional inputs are used, traditional matting approaches are further divided into two categories: sampling-based approaches and affinity-based approaches. Sampling-based approaches <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b30">31]</ref> infer the alpha values of the transition region by a class model which is built by using the color features with additional low-level features of the sampled pixels. The accuracy of these methods often depends on the quality of the trimap. Affinity-based approaches <ref type="bibr">[1-3, 7, 14, 18, 19]</ref> leverage pixel similarities calculated by the spatial and color features to propagate the alpha values of the known foreground and background pixels to the transition regions. Due to the spatial proximity, affinity-based approaches can generate a more smooth matte than sampling-based ones.</p><p>Deep-learning matting. Over the past decade, deeplearning-based approaches have become dominant in the matting field. In early works, deep learning is an intermediate step in the whole matting process. Shen et al. <ref type="bibr" target="#b33">[34]</ref> use a deep learning model to predict the trimap and then estimate alpha matting through a traditional matting approach. Cho et al. <ref type="bibr" target="#b7">[8]</ref> take the results of traditional matting and normalized RGB colors as inputs into a CNN model to predict refined alpha mattes. Xu et al. <ref type="bibr" target="#b38">[39]</ref> adopt a VGG-like model to directly predict the alpha matte by using an RGB image and a trimap, which is regarded as a pioneer work in deep learning matting. After that, many trimap-based matting approaches using deep learning are proposed. Tang et al. <ref type="bibr" target="#b36">[37]</ref> propose a hybrid sampling-based and learningbased matting approach. Hou et al. <ref type="bibr" target="#b15">[16]</ref> present a contextaware natural image matting method for simultaneous foreground and alpha mattes estimation. Lu et al. <ref type="bibr" target="#b25">[26]</ref> propose a flexible network module named IndexNet, which dynamically generates indices conditioned on the feature map. Cai et al. <ref type="bibr" target="#b4">[5]</ref> propose AdaMatting, which disentangles the matting task into trimap adaptation and alpha estimation. Li et al. <ref type="bibr" target="#b21">[22]</ref> use guided contextual attention to propagate highlevel opacity information globally based on the learned lowlevel affinity. Sun et al. <ref type="bibr" target="#b34">[35]</ref> learn 20 semantic classes of matting patterns to improve matting. Yu et al. <ref type="bibr" target="#b39">[40]</ref> propose HDMatt, which processes high-resolution inputs in a patch-based crop-and-stitch manner. However, all of these approaches are based on trimap, which is difficult to be provided by inexperienced users so that the applications are limited.</p><p>To eliminate the trimap, Lin et al. <ref type="bibr" target="#b22">[23]</ref> and Sengupta et al. <ref type="bibr" target="#b31">[32]</ref> use the background image as an auxiliary input. However, if the provided background image is much different from the real background, the performance deteriorates dramatically. Besides, such an auxiliary input also limits the application in practice. Zhang et al. <ref type="bibr" target="#b41">[42]</ref> use two decoder branches for the foreground and background classification, respectively, which provides more degrees of freedom than a single decoder branch for the network to obtain better alpha values during training. Yu et al. <ref type="bibr" target="#b28">[29]</ref> employ spatial and channel-wise attention to integrate appearance cues and pyramidal features. Chen et al. <ref type="bibr" target="#b5">[6]</ref> and Deora et al. <ref type="bibr" target="#b10">[11]</ref> use a semantic network to predict trimap and then concatenate it with RGB images as the input of the matting network. Liu et al. <ref type="bibr" target="#b23">[24]</ref>, Yu et al. <ref type="bibr" target="#b40">[41]</ref>, and Ke et al. <ref type="bibr" target="#b16">[17]</ref> get the alpha mattes in a coarse-to-fine manner. Li et al. <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> predict the trimap parallel to the alpha matte of the transition region and then fuse them to obtain the final alpha matte.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Approach</head><p>Correct semantic context and clear details are two essential factors for high-accuracy image matting. In trimapbased approaches, the user-supplied trimap has already provided sufficient semantic context in advance, so that the network just focuses on the transition region. On the con-trary, trimap-free approaches have no such prepared semantic context. Therefore, semantic context extraction is critical in a trimap-free method. As shown in <ref type="figure">Figure 2</ref>, we propose a semantic-aware network named PP-Matting, which consists of the semantic context branch (SCB) and the highresolution detail branch (HRDB) to predict the semantic map and the detail map, respectively. To generate the final alpha matte, the semantic map and detail map are fused resulting in mutual enhancement. When a person looks at an image, global context information is usually taken as meaningful guidance to help him dive into details. Inspired by the fact, we propose the design of guidance flow that achieves high-accuracy image matting with better extraction of object details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Network Architecture</head><p>The proposed network consists of two branches, i.e. semantic context branch (SCB) and the high-resolution detail branch (HRDB), which share a common module as the encoder, i.e. shared encoder. The pyramid pooling module (PPM) has been proven to be effective in semantic segmentation, due to its powerful extraction of global context <ref type="bibr" target="#b42">[43]</ref>. Thus, before SCB, we apply a PPM to strengthen semantic context. The guidance flow is used to connect HRDB and SCB, which is helpful for details prediction with correct semantic guidance.</p><p>Shared Encoder. Efficient feature extraction is a common part of any deep learning method. A matting task needs to combine high-level abstract semantic segmentation with high-resolution detail regression. Therefore, in addition to low-resolution feature representation, a high-resolution one is also necessary for image matting. In our work, we adopt HRNet48 <ref type="bibr" target="#b37">[38]</ref> pre-trained on ImageNet as the shared encoder because of its powerful ability in high-resolution feature extraction. Rather than recovering high-resolution by upsampling, the shared encoder maintains high-resolution representation throughout the whole process and repeatedly fuses the multi-resolution representations to generate rich high-resolution features with strong position sensitivity. The encoder is shared between SCB and HRDB.</p><p>Semantic Context Branch. Without the trimap cues, previous matting approaches are hard to obtain correct semantic context and easily fall into local ambiguity. In this work, we design a separate semantic context branch (SCB) for global context extraction. The SCB consists of five blocks and the block consists of three ConvBNReLU (convolution, batch normalization (BN) and Rectified Linear Unit (ReLU)) and one bilinear upsample. Since high-level abstract features are important for a correct semantic map, we take 1/32 resolution outputs of the encoder as input of the SCB. Also, a PPM is used to strengthen semantic context further between the shared encoder and SCB. In addition, the output of SCB is supervised by a semantic segmen- <ref type="figure">Figure 2</ref>. The overview of network architecture. HRNet is used as the encoder, the low-resolution output is used as the input of PPM, and the high-resolution output is used as the input of the high-resolution detail branch (HRDB). The semantic context branch (SCB) has five blocks, and the first, third, and fifth blocks guide the HRDB to learn semantic context. The HRDB maintains high-resolution inference to have a high-quality detail prediction. tation task of three classes, i.e. foreground, background, and transition. As shown in <ref type="figure">Figure 2</ref>, the semantic map of SCB is very similar to a user-supplied trimap, which indicates the proposed model is capable of generating a reliable semantic-aware trimap automatically.</p><p>High-Resolution Detail Branch. As shown in <ref type="figure">Figure 1</ref>, the degree of fine-grained details is one major difference between matting and segmentation. The details representation is usually kept in high-resolution feature maps. However, existing encoder-decoder segmentation networks with the downsampling-upsampling architecture do not maintain high-resolution representation efficiently. In this work, we propose the high-resolution detail branch (HRDB) to obtain fine-grained details in high resolution. Specifically, the HRDB consists of three residual blocks followed by a convolution layer. The initial input of HRDB is a combination of two intermediate features with corresponding upsampling scales, which contain low-level texture information and high-level abstract information, respectively. Between two blocks, guidance flow is used to obtain semantic context from SCB. The output of the HRDB is detail map that focuses on details representation in the transition region, and then it is fused with the semantic map in SCB to generate the final alpha matte.</p><p>Guidance Flow. As we discussed above, the global semantic context provides meaningful guidance for details extraction. In this work, we apply the guidance flow strategy that guides semantic features of SCB to help details prediction in HRDB. Specifically, it is consisting of Gated Convolutional Layers (GCL) <ref type="bibr" target="#b35">[36]</ref>, which achieve the interaction between detail feature and semantic context as shown  <ref type="figure" target="#fig_0">Figure 3</ref>. In GCL, a guidance map g ? R H?W is obtained as:</p><formula xml:id="formula_1">g = ?(C 1?1 (s||d))<label>(2)</label></formula><p>where s and d denote intermediate features of the SCB and HRDB, respectively. || denotes a concatenation operation. C 1?1 denotes the normalized 1 ? 1 convolutional layer. ? denotes the sigmoid function. The new detail feature mapd is calculated as:d</p><formula xml:id="formula_2">= (d g + d) T w<label>(3)</label></formula><p>where denotes an element-wise product, and w denotes the channel-wise weighting kernel. In our method, we use three GCL modules with the first, third and last block of the SCB to guide the detail branch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Loss Function</head><p>Our model leverages three losses. The first loss is a semantic loss in SCB denoted as L s , which is a cross-entropy loss of the 3-class segmentation task.</p><formula xml:id="formula_3">L s = ? 3 c=1 ? i=1 g i c log(p i c )<label>(4)</label></formula><p>where c ? {1, 2, 3} denotes three classes in semantic map. p i c ? [0, 1] is the predicted probability for the cth class at the i-th pixel, g i c ? {0, 1} is the corresponding ground truth. ? denotes all pixels in the image.</p><formula xml:id="formula_4">? = ? f ? ? b ? ? t<label>(5)</label></formula><p>where ? f , ? b , and ? t denote a set of foreground pixels, background pixels, and transition pixels, respectively. The second loss is detail loss in HRDB denoted as L d . Following <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b38">39]</ref>, we sum alpha-prediction loss L ? and the gradient loss L grad as the detail loss. Since the HRDB is focusing on detail prediction, we only calculate it in the transition region.</p><formula xml:id="formula_5">L d = ? t i=1 (L i ? (d) + L i grad (d))<label>(6)</label></formula><p>The alpha-prediction loss is the absolute difference between the ground truth alpha values and the predicted alpha values at each pixel. For the differentiable property, it is formulated as follows.</p><formula xml:id="formula_6">L i ? (d) = (? i d ? ? i g ) 2 + 2 (7) L i grad (d) = |?? i d ? ?? i g |<label>(8)</label></formula><p>where ? i d is the detail map value at i-th pixel, and ? i g is the ground-truth alpha value. is a small value which is set to 10 ?6 in our experiment. ? denotes the calculation of the gradient magnitude.</p><p>The third loss is fusion loss in final alpha matte denoted as L f which consists of alpha-prediction loss, gradient loss and composition loss as follow.</p><formula xml:id="formula_7">L f = ? i (L i ? (p) + L i grad (p) + L i comp )<label>(9)</label></formula><p>where L i comp is the absolute difference between the ground truth RGB colors and the predicted RGB colors composited by the ground truth foreground, the ground truth background and the predicted alpha matte.</p><formula xml:id="formula_8">L i comp = (I i p ? I i g ) 2 + 2<label>(10)</label></formula><formula xml:id="formula_9">I i p = ? i p F i g + (1 ? ? i p )B i g<label>(11)</label></formula><p>where I p denotes the image composited by the predicted alpha, and I g denotes the ground truth image. is a small value which is set to 10 ?6 in our experiment. L i ? (p) and L i grad (p) are the same to Eq.7, 8, but the predicted alpha values are final alpha matte.</p><p>The final weighted loss is calculated as follows.</p><formula xml:id="formula_10">L = ? 1 L s + ? 2 L d + ? 3 L f<label>(12)</label></formula><p>4. Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>We conduct the experiments on two public datasets: Distinctions-646 <ref type="bibr" target="#b28">[29]</ref> and Adobe Composition-1k <ref type="bibr" target="#b38">[39]</ref>. In Distinctions-646, the training set contains 596 foreground objects with their corresponding ground truth alpha mattes. The test set contains 50 foreground images and their corresponding alpha mattes. In Adobe Composition-1k, there are 431 foreground images in the training set and 50 in the test set. For the two datasets, each foreground image is combined with 100 background images for training and 20 background images for testing, which is the same as <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>Training settings. In the training phase, input images are randomly cropped to 512?512, 640?640 and 800?800. Note that if the size of an image is smaller than 512, it is padded to 512 ? 512 without cropping. Then they are resized to a resolution of 512?512 and augmented by random distortion, random blurring, and random horizontal flipping. We apply stochastic gradient descent (SGD) optimizer with the momentum of 0.9 and weight decay of 4e ?5 . The learning rate is initialized to 0.01, and adjusted by the poly policy with the power of 0.9 and 300k iterations. The coefficients in eq.12 are set to ? 1 = ? 2 = ? 3 = 1.0. All of our experiments are conducted on a single Tesla V100 GPU with a batch size of 4 using PaddlePaddle 1 <ref type="bibr" target="#b27">[28]</ref>. Code and pretrained models will be available at PaddleSeg 2 <ref type="bibr" target="#b24">[25]</ref>.</p><p>Evaluation metrics. The alpha mattes are evaluated by four common quantitative metrics: the sum of absolute differences (SAD), mean squared error (MSE), gradient (Grad), and connectivity (Conn) proposed by <ref type="bibr" target="#b29">[30]</ref>. The lower value of the metric, The better the prediction quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluation Results</head><p>Distinctions-646 testing dataset. We evaluate the proposed PP-Matting with 8 previous matting methods on Disctinctions-646 testing dataset. The quantitative comparison results are given in <ref type="table">Table 1</ref>. Our method has much better results in all four metrics than the top-performing traditional methods, e.g., ClosedForm <ref type="bibr" target="#b17">[18]</ref>, KNN Matting <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SAD? MSE? Grad? Conn?</head><p>Share Matting <ref type="bibr" target="#b12">[13]</ref> 119.56 0.026 129.61 114.37 Global Matting <ref type="bibr" target="#b14">[15]</ref>  Compared with DIM, a trimap-based deep learning method, our method also shows comparable performance. Among the 4 metrics, SAD and Conn are better than DIM, and only the Grad metric is slightly worse. All methods at the upper part of the table require an RGB image with a usersupplied trimap, while our method only takes a single image to generate the alpha matte. In addition, we also compare PP-Matting with a recent state-of-the-art method, HAttMatting <ref type="bibr" target="#b28">[29]</ref>. Note that HAttMatting is not open-sourced, so we refer to the results in their paper directly. PP-Matting is better than HAttMatting on SAD and Conn metrics, while slightly worse than it on Grad.</p><p>Composition-1k testing dataset. On the Composition-1k testing dataset, we evaluate PP-Matting with 13 previous methods including more deep-learning methods. The quantitative comparison results are given in <ref type="table">Table 2</ref>. Our method has much better results in all four metrics than the traditional methods and trimap-based deep learning methods, i.e., DIM <ref type="bibr" target="#b38">[39]</ref>, AlphaGAN <ref type="bibr" target="#b26">[27]</ref>, SampleNet <ref type="bibr" target="#b36">[37]</ref>. Trimapbased methods can explicitly obtain stronger semantic context with the trimap input, while our method also achieves better results through using the semantic context branch. For trimap-free methods, PP-Matting is better than Late Fusion <ref type="bibr" target="#b41">[42]</ref> and HAttMatting on all metrics except SAD. The results demonstrate the superiority of PP-Matting over previous methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>In PP-Matting, the guidance flow of semantic context is a core design. To illustrate its effectiveness, we conduct ablation experiments on Distinctions-646. The experiment settings are the same as section 4.2 , but we reduce the number of training iters to 100k. As the results are shown in <ref type="table">Table 3</ref>, the design of guidance flow can improve the performance significantly. We can find that even using only one block in SCB benefits the SAD, Grad, and Conn metrics. In our experiment, we take the first, the third, and the fifth block in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SAD? MSE? Grad? Conn?</head><p>Share Matting <ref type="bibr" target="#b12">[13]</ref> 125.37 0.029 144.28 123.53 Global Matting <ref type="bibr" target="#b14">[15]</ref> 156.88 0.042 112.28 155.08 ClosedForm <ref type="bibr" target="#b17">[18]</ref> 124.68 0.025 115.31 106.06 KNN Matting <ref type="bibr" target="#b6">[7]</ref> 126.24 0.025 117.17 131.05 DCNN <ref type="bibr" target="#b33">[34]</ref> 115.82 0.023 107. <ref type="bibr" target="#b35">36</ref>   <ref type="table">Table 3</ref>. Ablation study on guidance flow. w/o GF: without guidance flow between SCB and HRDB. The number 5 means that using the first block in the SCB as guidance flow. The number 1, 3, 5 means using the first, the third, and the fifth block in SCB as guidance flow.</p><p>SCB as guidance flow, because there is no obvious benefit from continuing to increase the number of blocks. When we get the semantic map and detail map, we need to fuse them to the final alpha matte. In our experiments, we replace the transition region in the semantic map with the results of the detail map, which is denoted as Rep FM. There, we explore the other two methods. The first one is that we only use the detail map as the final alpha matte directly, denoted as w/o FM. The second one is that we concatenate the detail map and semantic map, and then use a 1x1 convolution layer to fuse it, denoted as Conv FM. The results in <ref type="table" target="#tab_2">Table 4</ref> show that the replacement method is more effective without extra computation overhead.</p><p>To further analyze the role of the guidance flow, we visualize the intermediate features of the network. As shown in <ref type="figure">figure 5</ref>, the s1, s2 and s3 are features from the first, third, and fifth block in the SCB. The g1, g2, and g3 are the first channel feature of the GCLs output in the HRDB. From s1 to s3, we can see that the semantic map specifies the transition region clearly, which guides the HRDB to focus on the detail and texture in the region and ignore the background and foreground as shown in g1, g2, and g3. Finally, the HRDB gets the high-accuracy detail map in the transition region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Human Matting</head><p>In natural image matting, human matting is a most popular application which is widely used in image composition, background replacement, and special effects. To evaluate the robustness of our PP-Matting in the real-world application, we collect and annotate more than 10k human images and collect 77k background images to train our model. Then we have a test in the real human images from AIM-500 <ref type="bibr" target="#b20">[21]</ref>. As shown in <ref type="figure">figure 6</ref>, the alpha mattes prediction results are comparable with the manual ground truth, which demonstrates our outstanding performance in the practical application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work, we propose a trimap-free matting architecture named PP-Matting that can generate high-accuracy alpha matte with a single RGB image. Our method applies the high-resolution detail branch that extracts fine-grained details of the foreground. With the proposed semantic context branch (SCB), PP-Matting improves the detail prediction because of better semantic correctness. The proper interaction of the two branches using guidance flow helps the network achieve better semantic-aware prediction of alpha mattes. Extensive experiments on popular benchmarks and real-world datasets demonstrate our state-of-the-art performance. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Guided flow architecture in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>Visualization of the features and results. Alpha matte is the final prediction result. s1, s2, and s3 are the feature maps from the SCB. Low-level feature is from the first block of the encoder. g1, g2, and g3 are the output of GCLs. Detail map is the output of HRDB. Example of the real human image. The real image is from AIM-500<ref type="bibr" target="#b20">[21]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .</head><label>4</label><figDesc>Ablation study on fusion module. w/o FM: use the HRDB to predict the final alpha matte. Conv FM: use the convolution module to fuse the sematic map and the detail map. Rep FM: replace the transition region in semantic map with results of detail map.</figDesc><table><row><cell>Methods</cell><cell cols="2">SAD? MSE? Grad? Conn?</cell></row><row><cell>w/o FM</cell><cell>58.71 0.0156 67.81</cell><cell>60.58</cell></row><row><cell cols="2">Conv FM 51.82 0.0124 53.39</cell><cell>53.16</cell></row><row><cell>Rep FM</cell><cell>50.79 0.0113 52.99</cell><cell>51.40</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/PaddlePaddle/Paddle 2 https://github.com/PaddlePaddle/PaddleSeg</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic soft segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yagiz</forename><surname>Aksoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae-Hyun</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Matusik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Designing effective inter-pixel information flow for natural image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yagiz</forename><surname>Aksoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Tunc Ozan Aydin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="29" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A geodesic framework for fast interactive image and video segmentation and matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 11th International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A survey on image matting techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jagruti</forename><surname>Boda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhatri</forename><surname>Pandya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 International Conference on Communication and Signal Processing (ICCSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="765" to="0770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Disentangled image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaofan</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoshuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqiang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8819" to="8828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic human matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiezheng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM international conference on Multimedia</title>
		<meeting>the 26th ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Knn matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingzeyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Keung</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2175" to="2188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural image matting using deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyeon</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inso</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="626" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pp-humanseg: Connectivity-aware portrait segmentation with a large-scale teleconferencing video dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lutao</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zewu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guowei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuying</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncai</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiliang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baohua</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="202" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A bayesian approach to digital matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yung-Yu</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Salesin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR</title>
		<meeting>the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Deora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishab</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinesh</forename><surname>Samuel Sathia Raj</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12337</idno>
		<title level="m">Salient image matting</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A cluster sampling method for image matting via sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxue</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zili</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="204" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Shared sampling for real-time alpha matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Eduardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel M</forename><surname>Gastal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="575" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Random walks for interactive alpha-matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Schiwietz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aharon</forename><surname>Shmuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?diger</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of VIIP</title>
		<meeting>VIIP</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="423" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A global sampling method for alpha matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="2049" to="2056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Context-aware image matting for simultaneous foreground and alpha estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiqi</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4130" to="4139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Is a green screen really necessary for real-time portrait matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanghan</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaican</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yurou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuhua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rynson Wh</forename><surname>Lau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.11961</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A closed-form solution to natural image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anat</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="228" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anat</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Rav-Acha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
		<title level="m">Spectral matting. IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1699" to="1712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bridging composite and real: towards end-to-end deep image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jizhizi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Maybank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jizhizi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.07235</idno>
		<title level="m">Deep automatic natural image matting</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Natural image matting via guided contextual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongtao</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11450" to="11457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Real-time high-resolution background matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanchuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Ryabtsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumyadip</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Brian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Boosting semantic human matting with coarse annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinlin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendi</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miaomiao</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuansong</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian-Sheng</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Paddleseg: A high-efficient development toolkit for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lutao</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guowei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zewu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baohua</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuying</forename><surname>Hao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06175</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Indices matter: Learning to index for deep image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songcen</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Lutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Amplianitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljosa</forename><surname>Smolic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alphagan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.10088</idno>
		<title level="m">Generative adversarial networks for natural image matting</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Paddlepaddle: An open-source deep learning platform from industrial practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianhai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers of Data and Domputing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="115" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Attention-guided hierarchical structure aggregation for image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingliang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A perceptually motivated online benchmark for image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margrit</forename><surname>Gelautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Rott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1826" to="1833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Alpha estimation in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Ruzon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No. PR00662)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No. PR00662)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="18" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Background matting: The world is your green screen</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumyadip</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Jayaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Alphanet: An attention guided deep network for automatic image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishab</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Deora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudha</forename><surname>Vishvakarma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 International Conference on Omnilayer Intelligent Systems (COINS)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep automatic portrait matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyun</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Semantic image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Keung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page" from="11120" to="11129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Gated-scnn: Gated shape cnns for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Towaki</forename><surname>Takikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Acuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5229" to="5238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning-based sampling for natural image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yagiz</forename><surname>Aksoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cengiz</forename><surname>Oztireli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tunc Ozan</forename><surname>Aydin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaorui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="3349" to="3364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haichao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Humphrey</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.06613</idno>
		<title level="m">High-resolution deep image matting</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Cascade image matting with deformable graph refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huijuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.02646</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A late fusion cnn for digital matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunke</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixue</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubin</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiran</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hujun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
