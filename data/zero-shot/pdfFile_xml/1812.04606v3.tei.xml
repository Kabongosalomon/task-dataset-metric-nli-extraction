<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DEEP ANOMALY DETECTION WITH OUTLIER EXPOSURE</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
							<email>hendrycks@berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
							<email>mantas@ttic.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Oregon State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DEEP ANOMALY DETECTION WITH OUTLIER EXPOSURE</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small-and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance. . Learning local feature descriptors with triplets and shallow convolutional neural networks. British Machine Vision Conference, 2016.</p><p>Peter L Bartlett and Marten H Wegkamp. Classification with a reject option using a hinge loss. . Learning phrase representations using rnn encoder-decoder for statistical machine translation. neural network robustness to common corruptions and surface variations. arXiv preprint, 2018.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Machine Learning systems in deployment often encounter data that is unlike the model's training data. This can occur in discovering novel astronomical phenomena, finding unknown diseases, or detecting sensor failure. In these situations, models that can detect anomalies <ref type="bibr" target="#b8">(Liu et al., 2018;</ref><ref type="bibr">Emmott et al., 2013)</ref> are capable of correctly flagging unusual examples for human intervention, or carefully proceeding with a more conservative fallback policy.</p><p>Behind many machine learning systems are deep learning models <ref type="bibr" target="#b3">(Krizhevsky et al., 2012)</ref> which can provide high performance in a variety of applications, so long as the data seen at test time is similar to the training data. However, when there is a distribution mismatch, deep neural network classifiers tend to give high confidence predictions on anomalous test examples . This can invalidate the use of prediction probabilities as calibrated confidence estimates <ref type="bibr">(Guo et al., 2017)</ref>, and makes detecting anomalous examples doubly important.</p><p>Several previous works seek to address these problems by giving deep neural network classifiers a means of assigning anomaly scores to inputs. These scores can then be used for detecting outof-distribution (OOD) examples <ref type="bibr" target="#b0">(Hendrycks &amp; Gimpel, 2017;</ref><ref type="bibr" target="#b6">Lee et al., 2018;</ref><ref type="bibr" target="#b8">Liu et al., 2018)</ref>. These approaches have been demonstrated to work surprisingly well for complex input spaces, such as images, text, and speech. Moreover, they do not require modeling the full data distribution, but instead can use heuristics for detecting unmodeled phenomena. Several of these methods detect unmodeled phenomena by using representations from only in-distribution data.</p><p>In this paper, we investigate a complementary method where we train models to detect unmodeled data by learning cues for whether an input is unmodeled. While it is difficult to model the full data distribution, we can learn effective heuristics for detecting out-of-distribution inputs by exposing the model to OOD examples, thus learning a more conservative concept of the inliers and enabling the detection of novel forms of anomalies. We propose leveraging diverse, realistic datasets for this purpose, with a method we call Outlier Exposure <ref type="bibr">(OE)</ref>. OE provides a simple and effective way to consistently improve existing methods for OOD detection.</p><p>Through numerous experiments, we extensively evaluate the broad applicability of Outlier Exposure. For multiclass neural networks, we provide thorough results on Computer Vision and Natural Published as a conference paper at ICLR 2019 Language Processing tasks which show that Outlier Exposure can help anomaly detectors generalize to and perform well on unseen distributions of outliers, even on large-scale images. We also demonstrate that Outlier Exposure provides gains over several existing approaches to out-of-distribution detection. Our results also show the flexibility of Outlier Exposure, as we can train various models with different sources of outlier distributions. Additionally, we establish that Outlier Exposure can make density estimates of OOD samples significantly more useful for OOD detection. Finally, we demonstrate that Outlier Exposure improves the calibration of neural network classifiers in the realistic setting where a fraction of the data is OOD. Our code is made publicly available at https://github.com/hendrycks/outlier-exposure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Out-of-Distribution Detection with Deep Networks. <ref type="bibr" target="#b0">Hendrycks &amp; Gimpel (2017)</ref> demonstrate that a deep, pre-trained classifier has a lower maximum softmax probability on anomalous examples than in-distribution examples, so a classifier can conveniently double as a consistently useful outof-distribution detector. Building on this work, <ref type="bibr">DeVries &amp; Taylor (2018)</ref> attach an auxiliary branch onto a pre-trained classifier and derive a new OOD score from this branch. <ref type="bibr" target="#b7">Liang et al. (2018)</ref> present a method which can improve performance of OOD detectors that use a softmax distribution. In particular, they make the maximum softmax probability more discriminative between anomalies and in-distribution examples by pre-processing input data with adversarial perturbations <ref type="bibr">(Goodfellow et al., 2015)</ref>. Unlike in our work, their parameters are tailored to each source of anomalies. <ref type="bibr" target="#b6">Lee et al. (2018)</ref> train a classifier concurrently with a GAN <ref type="bibr" target="#b20">(Radford et al., 2016;</ref><ref type="bibr">Goodfellow et al., 2014)</ref>, and the classifier is trained to have lower confidence on GAN samples. For each testing distribution of anomalies, they tune the classifier and GAN using samples from that out-distribution, as discussed in Appendix B of their work. Unlike <ref type="bibr" target="#b7">Liang et al. (2018)</ref>; <ref type="bibr" target="#b6">Lee et al. (2018)</ref>, in this work we train our method without tuning parameters to fit specific types of anomaly test distributions, so our results are not directly comparable with their results. Many other works <ref type="bibr">(de Vries et al., 2016;</ref><ref type="bibr" target="#b27">Subramanya et al., 2017;</ref><ref type="bibr" target="#b11">Malinin &amp; Gales, 2018;</ref><ref type="bibr">Bevandic et al., 2018</ref>) also encourage the model to have lower confidence on anomalous examples. Recently, <ref type="bibr" target="#b8">Liu et al. (2018)</ref> provide theoretical guarantees for detecting out-of-distribution examples under the assumption that a suitably powerful anomaly detector is available.</p><p>Utilizing Auxiliary Datasets. Outlier Exposure uses an auxiliary dataset entirely disjoint from test-time data in order to teach the network better representations for anomaly detection. <ref type="bibr">Goodfellow et al. (2015)</ref> train on adversarial examples to increased robustness. <ref type="bibr" target="#b23">Salakhutdinov et al. (2011)</ref> pre-train unsupervised deep models on a database of web images for stronger features. <ref type="bibr" target="#b21">Radford et al. (2017)</ref> train an unsupervised network on a corpus of Amazon reviews for a month in order to obtain quality sentiment representations. <ref type="bibr" target="#b32">Zeiler &amp; Fergus (2014)</ref> find that pre-training a network on the large ImageNet database <ref type="bibr" target="#b22">(Russakovsky et al., 2015)</ref> endows the network with general representations that are useful in many fine-tuning applications. Chen &amp; Gupta (2015); <ref type="bibr" target="#b10">Mahajan et al. (2018)</ref> show that representations learned from images scraped from the nigh unlimited source of search engines and photo-sharing websites improve object detection performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OUTLIER EXPOSURE</head><p>We consider the task of deciding whether or not a sample is from a learned distribution called D in . Samples from D in are called "in-distribution," and otherwise are said to be "out-of-distribution" (OOD) or samples from D out . In real applications, it may be difficult to know the distribution of outliers one will encounter in advance. Thus, we consider the realistic setting where D out is unknown. Given a parametrized OOD detector and an Outlier Exposure (OE) dataset D OE out , disjoint from D test out , we train the model to discover signals and learn heuristics to detect whether a query is sampled from D in or D OE out . We find that these heuristics generalize to unseen distributions D out . Deep parametrized anomaly detectors typically leverage learned representations from an auxiliary task, such as classification or density estimation. Given a model f and the original learning objective L, we can thus formalize Outlier Exposure as minimizing the objective</p><formula xml:id="formula_0">E (x,y)?Din [L(f (x), y) + ?E x ?D OE out [L OE (f (x ), f (x), y)]</formula><p>] over the parameters of f . In cases where labeled data is not available, then y can be ignored.</p><p>Outlier Exposure can be applied with many types of data and original tasks. Hence, the specific formulation of L OE is a design choice, and depends on the task at hand and the OOD detector used. For example, when using the maximum softmax probability baseline detector <ref type="bibr" target="#b0">(Hendrycks &amp; Gimpel, 2017)</ref>, we set L OE to the cross-entropy from f (x ) to the uniform distribution <ref type="bibr" target="#b6">(Lee et al., 2018)</ref>. When the original objective L is density estimation and labels are not available, we set L OE to a margin ranking loss on the log probabilities f (x ) and f (x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We evaluate OOD detectors with and without OE on a wide range of datasets. Each evaluation consists of an in-distribution dataset D in used to train an initial model, a dataset of anomalous examples D OE out , and a baseline detector to which we apply OE. We describe the datasets in Section 4.2. The OOD detectors and L OE losses are described on a case-by-case basis.</p><p>In the first experiment, we show that OE can help detectors generalize to new text and image anomalies. This is all accomplished without assuming access to the test distribution during training or tuning, unlike much previous work. In the confidence branch experiment, we show that OE is flexible and complements a binary anomaly detector. Then we demonstrate that using synthetic outliers does not work as well as using real and diverse data; previously it was assumed that we need synthetic data or carefully selected close-to-distribution data, but real and diverse data is enough. We conclude with experiments in density estimation. In these experiments we find that a cutting-edge density estimator unexpectedly assigns higher density to out-of-distribution samples than in-distribution samples, and we ameliorate this surprising behavior with Outlier Exposure. We evaluate out-of-distribution detection methods on their ability to detect OOD points. For this purpose, we treat the OOD examples as the positive class, and we evaluate three metrics: area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPR), and the false positive rate at N % true positive rate (FPRN ). The AUROC and AUPR are holistic metrics that summarize the performance of a detection method across multiple thresholds. The AUROC can be thought of as the probability that an anomalous example is given a higher OOD score than a in-distribution example <ref type="bibr">(Davis &amp; Goadrich, 2006)</ref>. Thus, a higher AUROC is better, and an uninformative detector has an AUROC of 50%. The AUPR is useful when anomalous examples are infrequent <ref type="bibr" target="#b12">(Manning &amp; Sch?tze, 1999)</ref>, as it takes the base rate of anomalies into account. During evaluation with these metrics, the base rate of D test out to D test in test examples in all of our experiments is 1:5.</p><p>Whereas the previous two metrics represent the detection performance across various thresholds, the FPRN metric represents performance at one strict threshold. By observing performance at a strict threshold, we can make clear comparisons among strong detectors. The FPRN metric <ref type="bibr" target="#b8">(Liu et al., 2018;</ref><ref type="bibr" target="#b5">Kumar et al., 2016;</ref><ref type="bibr">Balntas et al., 2016)</ref> is the probability that an in-distribution example (negative) raises a false alarm when N % of anomalous examples (positive) are detected, so a lower FPRN is better. Capturing nearly all anomalies with few false alarms can be of high practical value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">DATASETS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">IN-DISTRIBUTION DATASETS</head><p>SVHN. The SVHN dataset <ref type="bibr" target="#b16">(Netzer et al., 2011)</ref> contains 32 ? 32 color images of house numbers. There are ten classes comprised of the digits 0-9. The training set has 604, 388 images, and the test set has 26, 032 images. For preprocessing, we rescale the pixels to be in the interval [0, 1]. CIFAR. The two CIFAR <ref type="bibr" target="#b2">(Krizhevsky &amp; Hinton, 2009</ref>) datasets contain 32 ? 32 natural color images. CIFAR-10 has ten classes while CIFAR-100 has 100. CIFAR-10 and CIFAR-100 classes are disjoint but have similiarities. For example, CIFAR-10 has "automobiles" and "trucks" but not CIFAR-100's "pickup truck" class. Both have 50, 000 training images and 10, 000 test images. For this and the remaining image datasets, each image is standardized channel-wise. Tiny ImageNet. The Tiny ImageNet dataset (Johnson et al.) is a 200-class subset of the ImageNet <ref type="bibr" target="#b22">(Russakovsky et al., 2015)</ref> dataset where images are resized and cropped to 64 ? 64 resolution. The dataset's images were cropped using bounding box information so that cropped images contain the target, unlike Downsampled ImageNet <ref type="bibr">(Chrabaszcz et al., 2017)</ref>. The training set has 100, 000 images and the test set has 10, 000 images. Places365. The Places365 training dataset <ref type="bibr" target="#b33">(Zhou et al., 2017)</ref>   <ref type="bibr" target="#b26">(Socher et al., 2013)</ref> consists of movie reviews expressing positive or negative sentiment. SST has 8, 544 reviews for training and 2, 210 for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">OUTLIER EXPOSURE DATASETS</head><p>80 Million Tiny Images. 80 Million Tiny Images <ref type="bibr" target="#b29">(Torralba et al., 2008)</ref> is a large-scale, diverse dataset of 32?32 natural images scrapped from the web. We use this dataset as D OE out for experiments with SVHN, CIFAR-10, and CIFAR-100 as D in . We remove all examples of 80 Million Tiny Images which appear in the CIFAR datasets, so that D OE out and D test out are disjoint. In Section 5 we note that only a small fraction of this dataset is necessary for successful OE. ImageNet-22K. We use the ImageNet dataset with images from approximately 22 thousand classes as D OE out for Tiny ImageNet and Places365 since images from 80 Million Tiny Images are too low-resolution. To make D OE out and D test out are disjoint, images in ImageNet-1K are removed. WikiText-2. WikiText-2 is a corpus of Wikipedia articles typically used for language modeling. We use WikiText-2 as D OE out for language modeling experiments with Penn Treebank as D in . For classification tasks on 20 Newsgroups, TREC, and SST, we treat each sentence of WikiText-2 as an individual example, and use simple filters to remove low-quality sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MULTICLASS CLASSIFICATION</head><p>In what follows, we use Outlier Exposure to enhance the performance of existing OOD detection techniques with multiclass classification as the original task. Throughout the following experiments, we let x ? X be a classifier's input and y ? Y = {1, 2, . . . , k} be a class. We also represent the classifier with the function f : X ? R k , such that for any x, 1 T f (x) = 1 and f (x) 0.</p><p>Maximum Softmax Probability (MSP). Consider the maximum softmax probability baseline <ref type="bibr" target="#b0">(Hendrycks &amp; Gimpel, 2017)</ref> which gives an input x the OOD score ? max c f c (x). Out-ofdistribution samples are drawn from various unseen distributions (Appendix A). For each task, we test with approximately twice the number of D test out distributions compared to most other papers, and we also test on NLP tasks. The quality of the OOD example scores are judged with the metrics described in Section 4.1. For this multiclass setting, we perform Outlier Exposure by fine-tuning a pre-trained classifier f so that its posterior is more uniform on D OE out samples. Specifically, the fine-</p><formula xml:id="formula_1">tuning objective is E (x,y)?Din [? log f y (x)] + ?E x?D OE out [H(U; f (x))],</formula><p>where H is the cross entropy and U is the uniform distribution over k classes. When there is class imbalance, we could encourage f (x) to match (P (y = 1), . . . , P (y = k)); yet for the datasets we consider, matching U works well enough. Also, note that training from scratch with OE can result in even better performance than fine-tuning (Appendix C). This approach works on different architectures as well (Appendix D).</p><p>Unlike <ref type="bibr" target="#b7">Liang et al. (2018)</ref>; <ref type="bibr" target="#b6">Lee et al. (2018)</ref> and like <ref type="bibr" target="#b0">Hendrycks &amp; Gimpel (2017)</ref>; DeVries &amp; Taylor (2018), we do not tune our hyperparameters for each D test out distribution, so that D test out is kept unknown like with real-world anomalies. Instead, the ? coefficients were determined early in experimentation with validation D val out distributions described in Appendix A. In particular, we use ? = 0.5 for vision experiments and ? = 1.0 for NLP experiments. Like previous OOD detection methods involving network fine-tuning, we chose ? so that impact on classification accuracy is negligible.</p><p>For nearly all of the vision experiments, we train Wide Residual Networks <ref type="bibr" target="#b31">(Zagoruyko &amp; Komodakis, 2016)</ref> and then fine-tune network copies with OE for 10 epochs. However we use a pretrained ResNet-18 for Places365. For NLP experiments, we train 2-layer GRUs <ref type="bibr">(Cho et al., 2014)</ref> for 5 epochs, then fine-tune network copies with OE for 2 epochs. Networks trained on CIFAR-10 or CIFAR-100 are exposed to images from 80 Million Tiny Images, and the Tiny ImageNet and Places365 classifiers are exposed to ImageNet-22K. NLP classifiers are exposed to WikiText-2. Further architectural and training details are in Appendix B. For all tasks, OE improves average performance by a large margin. Averaged results are shown in Tables 1 and 2. Sample ROC curves are shown in <ref type="figure" target="#fig_4">Figures 1 and 4</ref>. Detailed results on individual D test out datasets are in <ref type="table" target="#tab_10">Table 7</ref> and <ref type="table" target="#tab_11">Table 8</ref> in Appendix A. Notice that the SVHN classifier with OE can be used to detect new anomalies such as emojis and street view alphabet letters, even though D test OE is a dataset of natural images. Thus, Outlier Exposure helps models to generalize to unseen D test out distributions far better than the baseline.      <ref type="bibr" target="#b15">(Nalisnick et al., 2019)</ref>. Consequently, density estimates are another means by which to score anomalies <ref type="bibr" target="#b34">(Zong et al., 2018)</ref>. We show the ability of OE to improve density estimates on low-probability, outlying data.</p><formula xml:id="formula_2">FPR95 ? AUROC ? AUPR ? D</formula><p>PixelCNN++. Autoregressive neural density estimators provide a way to parametrize the probability density of image data. Although sampling from these architectures is slow, they allow for evaluating the probability density with a single forward pass through a CNN, making them promising candidates for OOD detection. We use Pix-elCNN++ <ref type="bibr" target="#b25">(Salimans et al., 2017)</ref> as a baseline OOD detector, and we train it on CIFAR-10. The OOD score of example x is the bits per pixel (BPP), defined as nll(x)/num_pixels, where nll is the negative log-likelihood. With this loss we fine-tune for 2 epochs using OE, which we find is sufficient for the training loss to converge. Here OE is implemented with a margin loss over the log-likelihood difference between in-distribution and anomalous examples, so that the loss for a sample x in from D in and point x out from D OE out is max{0, num_pixels + nll(x in ) ? nll(x out )}.</p><p>Results are shown in <ref type="table" target="#tab_6">Table 5</ref>. Notice that PixelCNN++ without OE unexpectedly assigns lower BPP from SVHN images than CIFAR-10 images. For all D test out datasets, OE significantly improves results. Language Modeling. We next explore using OE on language models. We use QRNN <ref type="bibr" target="#b13">(Merity et al., 2018a;</ref><ref type="bibr">b)</ref> language models as baseline OOD detectors. For the OOD score, we use bits per character (BPC) or bits per word (BPW), defined as nll(x)/sequence_length, where nll(x) is the negative log-likelihood of the sequence x. Outlier Exposure is implemented by adding the cross entropy to the uniform distribution on tokens from sequences in D OE out as an additional loss term. For D in , we convert the language-modeling version of Penn Treebank, split into sequences of length 70 for backpropagation for word-level models, and 150 for character-level models. We do not train or evaluate with preserved hidden states as in BPTT. This is because retaining hidden states would  greatly simplify the task of OOD detection. Accordingly, the OOD detection task is to provide a score for 70-or 150-token sequences in the unseen D test out datasets. We train word-level models for 300 epochs, and character-level models for 50 epochs. We then fine-tune using OE on WikiText-2 for 5 epochs. For the character-level language model, we create a character-level version of WikiText-2 by converting words to lowercase and leaving out characters which do not appear in PTB. OOD detection results for the word-level and character-level language models are shown in  </p><formula xml:id="formula_3">FPR95 ? AUROC ? AUPR ? D in<label>D</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>Extensions to Multilabel Classifiers and the Reject Option. Outlier Exposure can work in more classification regimes than just those considered above. For example, a multilabel classifier trained on CIFAR-10 obtains an 88.8% mean AUROC when using the maximum prediction probability as the OOD score. By training with OE to decrease the classifier's output probabilities on OOD samples, the mean AUROC increases to 97.1%. This is slightly less than the AUROC for a multiclass model tuned with OE. An alternative OOD detection formulation is to give classifiers a "reject class" <ref type="bibr">(Bartlett &amp; Wegkamp, 2008)</ref>. Outlier Exposure is also flexible enough to improve performance in this setting, but we find that even with OE, classifiers with the reject option or multilabel outputs are not as competitive as OOD detectors with multiclass outputs.</p><p>Flexibility in Choosing D OE out . Early in experimentation, we found that the choice of D OE out is important for generalization to unseen D test out distributions. For example, adding Gaussian noise to samples from D in to create D OE out does not teach the network to generalize to unseen anomaly distributions for complex D in . Similarly, we found in Section 4.3 that synthetic anomalies do not work as well as real data for D OE out . In contrast, our experiments demonstrate that the large datasets of realistic anomalies described in Section 4.2.2 do generalize to unseen D test out distributions. In addition to size and realism, we found diversity of D OE out to be an important factor. Concretely, a CIFAR-100 classifier with CIFAR-10 as D OE out hardly improves over the baseline. A CIFAR-10 classifier exposed to ten CIFAR-100 outlier classes corresponds to an average AUPR of 78.5%. Exposed to 30 such classes, the classifier's average AUPR becomes 85.1%. Next, 50 classes corresponds to 85.3%, and from thereon additional CIFAR-100 classes barely improve performance. This suggests that dataset diversity is important, not just size. In fact, experiments in this paper often used around 1% of the images in the 80 Million Tiny Images dataset since we only briefly fine-tuned the models. We also found that using only 50,000 examples from this dataset led to a negligible degradation in detection performance. Additionally, D OE out datasets with significantly different statistics can perform similarly. For instance, using the Project Gutenberg dataset in lieu of WikiText-2 for D OE out in the SST experiments gives an average AUROC of 90.1% instead of 89.3%.</p><p>Closeness of D test out , D OE out , and D test in . Our experiments show several interesting effects of the closeness of the datasets involved. Firstly, we find that D test out and D OE out need not be close for training with OE to improve performance on D test out . In Appendix A, we observe that an OOD detector for SVHN has its performance improve with Outlier Exposure even though (1) D OE out samples are images of natural scenes rather than digits, and (2) D test out includes unnatural examples such as emojis. We observed the same in our preliminary experiments with MNIST; using 80 Million Tiny Images as D OE out , OE increased the AUPR from 94.2% to 97.0%.</p><p>Secondly, we find that the closeness of D OE out to D test in can be an important factor in the success of OE. In the NLP experiments, preprocessing D OE out to be closer to D in improves OOD detection performance significantly. Without preprocessing, the network may discover easy-to-learn cues which reveal whether the input is in-or out-of-distribution, so the OE training objective can be optimized in unintended ways. That results in weaker detectors. In a separate experiment, we use Online Hard Example Mining so that difficult outliers have more weight in Outlier Exposure. Although this improves performance on the hardest anomalies, anomalies without plausible local statistics like noise are detected slightly less effectively than before. Thus hard or close-to-distribution examples do not necessarily teach the detector all valuable heuristics for detecting various forms of anomalies. Real-world applications of OE could use the method of <ref type="bibr" target="#b28">Sun et al. (2018)</ref>  OE Improves Calibration. When using classifiers for prediction, it is important that confidence estimates given for the predictions do not misrepresent empirical performance. A calibrated classifier gives confidence probabilities that match the empirical frequency of correctness. That is, if a calibrated model predicts an event with 30% probability, then 30% of the time the event transpires.</p><p>Existing confidence calibration approaches consider the standard setting where data at test-time is always drawn from D in . We extend this setting to include examples from D test out at test-time since systems should provide calibrated probabilities on both in-and out-of-distribution samples. The classifier should have low-confidence predictions on these OOD examples, since they do not have a class. Building on the temperature tuning method of <ref type="bibr">Guo et al. (2017)</ref>, we demonstrate that OE can improve calibration performance in this realistic setting. Summary results are shown in <ref type="figure" target="#fig_2">Figure 3</ref>. Detailed results and a description of the metrics are in Appendix G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we proposed Outlier Exposure, a simple technique that enhances many current OOD detectors across various settings. It uses out-of-distribution samples to teach a network heuristics to detect new, unmodeled, out-of-distribution examples. We showed that this method is broadly applicable in vision and natural language settings, even for large-scale image tasks. OE can improve model calibration and several previous anomaly detection techniques. Further, OE can teach density estimation models to assign more plausible densities to out-of-distribution samples. Finally, Outlier Exposure is computationally inexpensive, and it can be applied with low overhead to existing systems. In summary, Outlier Exposure is an effective and complementary approach for enhancing out-of-distribution detection systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A EXPANDED MULTICLASS RESULTS</head><p>Expanded mutliclass out-of-distribution detection results are in <ref type="table" target="#tab_10">Table 7 and Table 8</ref>.   Anomalous Data. For each in-distribution dataset D in , we comprehensively evaluate OOD detectors on artificial and real anomalous distributions D test out following <ref type="bibr" target="#b0">Hendrycks &amp; Gimpel (2017)</ref>. For each learned distribution D in , the number of test distributions that we compare against is approximately double that of most previous works.</p><formula xml:id="formula_4">FPR95 ? AUROC ? AUPR ? D in D</formula><p>Gaussian anomalies have each dimension i.i.d. sampled from an isotropic Gaussian distribution. Rademacher anomalies are images where each dimension is ?1 or 1 with equal probability, so each dimension is sampled from a symmetric Rademacher distribution. Bernoulli images have each pixel sampled from a Bernoulli distribution if the input range is [0, 1]. Blobs data consist in algorithmically generated amorphous shapes with definite edges. Icons-50 is a dataset of icons and emojis <ref type="bibr" target="#b8">(Hendrycks &amp; Dietterich, 2018)</ref>; icons from the "Number" class are removed. Textures is a dataset of describable textural images <ref type="bibr">(Cimpoi et al., 2014)</ref>. Places365 consists in images for scene recognition rather than object recognition <ref type="bibr" target="#b33">(Zhou et al., 2017)</ref>. LSUN is another scene understanding dataset with fewer classes than Places365 <ref type="bibr" target="#b30">(Yu et al., 2015)</ref>. ImageNet anomalous examples are taken from the 800 ImageNet-1K classes disjoint from Tiny ImageNet's 200 classes, and when possible each image is cropped with bounding box information as in Tiny ImageNet. For the Places365 experiment, ImageNet is ImageNet-1K with all 1000 classes. With CIFAR-10 as D in , we use also CIFAR-100 as D test out and vice versa; recall that the CIFAR-10 and CIFAR-100 classes do not overlap. Chars74K is a dataset of photographed characters in various styles; digits and letters such as "O" and "l" were removed since they can look like numbers. Places69 has images from 69 scene categories not found in the Places365 dataset.</p><p>SNLI is a dataset of predicates and hypotheses for natural language inference. We use the hypotheses for D OE out . IMDB is a sentiment classification dataset of movie reviews, with similar statistics to those of SST. Multi30K is a dataset of English-German image descriptions, of which we use the English descriptions. WMT16 is the English portion of the test set from WMT16. Yelp is a dataset of restaurant reviews. English Web Treebank (EWT) consists of five individual datasets: Answers (A), Email (E), Newsgroups (N), Reviews (R), and Weblog (W). Each contains examples from the indicated domain.</p><p>Validation Data. For each experiment, we create a set of validation distributions D val out . The first anomalies are uniform noise anomalies where each pixel is sampled from U[0, 1] or U[?1, 1] depending on the input space of the classifier. The remaining D val out validation sources are generated by corrupting in-distribution data, so that the data becomes out-of-distribution. One such source of anomalies is created by taking the pixelwise arithmetic mean of a random pair of in-distribution images. Other anomalies are created by taking the geometric mean of a random pair of in-distribution images. Jigsaw anomalies are created by taking an in-distribution example, partitioning the image into 16 equally sized patches, and permuting those patches. Speckle Noised anomalies are created by applying speckle noise to in-distribution images. RGB Ghosted anomalies involves shifting and reordering the color channels of in-distribution images. Inverted images are anomalies which have some or all of their color channels inverted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B ARCHITECTURES AND TRAINING DETAILS</head><p>For CIFAR-10, CIFAR-100, and Tiny ImageNet classification experiments, we use a 40-2 Wide Residual Network <ref type="bibr" target="#b31">(Zagoruyko &amp; Komodakis, 2016)</ref>. The network trains for 100 epochs with a dropout rate of 0.3. The initial learning rate of 0.1 decays following a cosine learning rate schedule <ref type="bibr" target="#b9">(Loshchilov &amp; Hutter, 2017)</ref>. During fine-tuning of the entire network, we again use a cosine learning rate schedule but with an initial learning rate of 0.001. We use standard flipping and data cropping augmentation, Nesterov momentum, and 2 weight decay with a coefficient of 5 ? 10 ?4 . SVHN architectures are 16-4 Wide ResNets trained for 20 epochs with an initial learning rate of 0.01 and no data augmentation. For Places365, we use a ResNet-18 pre-trained on Places365. In this Places365 experiment, we tune with Outlier Exposure for 5 epochs, use 512 outlier samples per iteration, and start with a learning rate of 0.0001. Outlier Exposure fine-tuning occurs with each epoch being the length of in-distribution dataset epoch, so that Outlier Exposure completes quickly and does involve reading the entire D OE out dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C TRAINING FROM SCRATCH WITH OUTLIER EXPOSURE USUALLY IMPROVES DETECTION PERFORMANCE</head><p>Elsewhere we show results for pre-trained networks that are fine-tuned with OE. However, a network trained from scratch which simultaneously trains with OE tends to give superior results. For example, a CIFAR-10 Wide ResNet trained normally obtains a classification error rate of 5.16% and an FPR95 of 34.94%. Fine-tuned, this network has an error rate of 5.27% and an FPR95 of 9.50%. Yet if we instead train the network from scratch and expose it to outliers as it trains, then the error rate is 4.26% and the FPR95 is 6.15%. This architecture corresponds to a 9.50% RMS calibration error with OE fine-tuning, but by training with OE from scratch the RMS calibration error is 6.15%. Compared to fine-tuning, training a network in tandem with OE tends to produce a network with a better error rate, calibration, and OOD detection performance. The reason why we use OE for fine-tuning is because training from scratch requires more time and sometimes more GPU memory than fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D OE WORKS ON OTHER VISION ARCHITECTURES</head><p>Outlier Exposure also improves vision OOD detection performance for more than just Wide ResNets. <ref type="table">Table 9</ref> shows that Outlier Exposure also improves vision OOD detection performance for "All Convolutional Networks" <ref type="bibr" target="#b24">(Salimans &amp; Kingma, 2016</ref>  <ref type="table">Table 10</ref>: Comparison between the maximum softmax probability (MSP) and H(U; p) OOD scoring methods on a network fine-tuned with OE. Results are percentages and an average of 10 runs. For example, CIFAR-10 results are averaged over "Gaussian," "Rademacher," . . ., or "CIFAR-100" measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F EXPANDED LANGUAGE MODELING RESULTS</head><p>Detailed OOD detection results with language modeling datasets are shown in <ref type="table" target="#tab_14">Table 11</ref>.  </p><formula xml:id="formula_5">FPR90 ? AUROC ? AUPR ? D in D</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G CONFIDENCE CALIBRATION</head><p>Models integrated into a decision making process should indicate when they are trustworthy, and such models should not have inordinate confidence in their predictions. In an effort to combat a false sense of certainty from overconfident models, we aim to calibrate model confidence. A model is calibrated if its predicted probabilities match empirical frequencies. Thus if a calibrated model predicts an event with 30% probability, then 30% of the time the event transpires. Prior research <ref type="bibr">(Guo et al., 2017;</ref><ref type="bibr" target="#b18">Nguyen &amp; O'Connor, 2015;</ref><ref type="bibr" target="#b4">Kuleshov &amp; Liang, 2015)</ref> considers calibrating systems where test-time queries are samples from D in , but systems also encounter samples from D test out and should also ascribe low confidence to these samples. Hence, we use OE to control the confidence on these samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1 METRICS</head><p>In order to evaluate a multiclass classifier's calibration, we present three metrics. First we establish context. For input example X ? X , let Y ? Y = {1, 2, . . . , k} be the ground truth class. Let Y be the model's class prediction, and let C be the corresponding model confidence or prediction probability. Denote the set of prediction-label pairs made by the model with S = {( y 1 , c 1 ), ( y 2 , c 2 ), . . . , ( y n , c n )}. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RMS and MAD Calibration</head><formula xml:id="formula_6">b i=1 |B i | n 1 |B i | k?Bi 1(y k = y k ) ? 1 |B i | k?Bi c k 2 .</formula><p>Along similar lines, the MAD Calibration Error-which is an improper scoring rule due to its use of absolute differences rather than squared differences-is estimated with</p><formula xml:id="formula_7">b i=1 |B i | n 1 |B i | k?Bi 1(y k = y k ) ? 1 |B i | k?Bi c k .</formula><p>Soft F1 Score. If a classifier makes only a few mistakes, then most examples should have high confidence. But if the classifier gives all predictions high confidence, including its mistakes, then the previous metrics will indicate that the model is calibrated on the vast majority of instances, despite having systematic miscalibration. The Soft F1 score <ref type="bibr" target="#b19">(Pastor-Pellicer et al., 2013;</ref><ref type="bibr" target="#b0">Hendrycks &amp; Gimpel, 2017)</ref> is suited for measuring the calibration of a system where there is an acute imbalance between mistaken and correct decisions. Since we treat mistakes a positive examples, we can write the model's confidence that the examples are anomalous with c a = (1 ? c 1 , 1 ? c 2 , . . . , 1 ? c n ). To indicate that an example is positive (mistaken), we use the vector m ? {0, 1} n such that m i = 1(y i = y i ) for 1 ? i ? n. Then the Soft F1 score is c T a m 1 T (c a + m)/2 .  <ref type="table" target="#tab_2">Table 12</ref>: Calibration results for the temperature tuned baseline and temperature tuning + OE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.2 SETUP AND RESULTS</head><p>There are many ways to estimate a classifier's confidence. One way is to bind a logistic regression branch onto the network, so that confidence values are in [0, 1]. Other confidence estimates use the model's logits l ? R k , such as the estimate ?(max i l i ) ? [0, 1], where ? is the logistic sigmoid. Another common confidence estimate is max i exp (l i )/ k j=1 exp (l j ) . A modification of this estimate is our baseline.</p><p>Softmax Temperature Tuning. <ref type="bibr">Guo et al. (2017)</ref> show that good calibration can be obtained by including a tuned temperature parameter into the softmax: p(y = i | x) = exp(l i /T )/ k j=1 exp(l j /T ). We tune T to maximize log likelihood on a validation set after the network has been trained on the training set.</p><p>Results. In this calibration experiment, the baseline is confidence estimation with softmax temperature tuning. Therefore, we train SVHN, CIFAR-10, CIFAR-100, and Tiny ImageNet classifiers with 5000, 5000, 5000, and 10000 training examples held out, respectively. A copy of this classifier is fine-tuned with Outlier Exposure. Then we determine the optimal temperatures of the original and OE-fine-tuned classifiers on the held-out examples. To measure calibration, we take equally many examples from a given in-distribution dataset D test in and OOD dataset D test out . Out-of-distribution points are understood to be incorrectly classified since their label is not in the model's output space, so calibrated models should assign these out-of-distribution points low confidence. Results are in <ref type="table" target="#tab_2">Table 12</ref>. Outlier Exposure noticeably improves model calibration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.3 POSTERIOR RESCALING</head><p>While temperature tuning improves calibration, the confidence estimate p(y = i | x) cannot be less than 1/k, k the number of classes. For an out-of-distribution example like Gaussian Noise, a good model should have no confidence in its prediction over k classes. One possibility is to add a reject option, or a (k + 1)st class, which we cover in Section 5. A simpler option we found is to perform an affine transformation of p(y = i | x) ? [1/k, 1] with the formula ( p(y = i | x) ? 1/k)/(1 ? 1/k) ? [0, 1]. This simple transformation makes it possible for a network to express no confidence on an out-of-distribution input and improves calibration performance. As <ref type="table" target="#tab_3">Table 13</ref> shows, this simple 0-1 posterior rescaling technique consistently improves calibration, and the model fine-tuned with OE using temperature tuning and posterior rescaling achieved large calibration improvements.   In <ref type="figure" target="#fig_4">Figure 4</ref>, we show additional PR and ROC Curves using the Tiny ImageNet dataset and various anomalous distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RMS</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: ROC curve with Tiny Im-ageNet (D in ) and Textures (D test out ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>OOD scores from PixelCNN++ on images from CIFAR-10 and SVHN. Density estimators learn a probability density function over the data distribution D in . Anomalous examples should have low probability density, as they are scarce in D in by definition</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>to refine a scraped D OE out auxiliary dataset to be appropriately close to D test in .SV HN CI FA R-10 CI FA RRoot Mean Square Calibration Error values with temperature tuning and temperature tuning + OE across various datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Error. The Root Mean Square Calibration Error measures the square root of the expected squared difference between confidence and accuracy at a confidence level. It has the formula E C [(P(Y = Y |C = c) ? c) 2 ] . A similar formulation which less severely penalizes large confidence-accuracy deviations is the Mean Absolute Value Calibration error, written E C [|P(Y = Y |C = c) ? c|]. The MAD Calibration Error is a lower bound of the RMS Calibration Error. To empirically estimate these miscalibration measures, we partition the n samples of S into b bins {B 1 , B 2 , . . . , B b } with approximately 100 samples in each bin. Unlike Guo et al. (2017), bins are not equally spaced since the distribution of confidence values is not uniform but dynamic. Concretely, the RMS Calibration Error is estimated with the numerically stable formula</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>ROC curves with Tiny ImageNet as D in and Textures, Places365, LSUN, and ImageNet as D test out . Figures show the curves corresponding to the maximum softmax probability (MSP) baseline detector and the MSP detector with Outlier Exposure (OE).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparisons between the MSP baseline and the MSP of the natural language classifier fine-tuned with OE. Results are percentages and averaged over 10 runs.Confidence Branch. A recently proposed OOD detection technique(DeVries &amp; Taylor, 2018)   involves appending an OOD scoring branch b : X ? [0, 1] onto a deep network. Trained with samples from only D in , this branch estimates the network's confidence on any input. The creators of this technique made their code publicly available, so we use their code to train new 40-4 Wide Residual Network classifiers. We fine-tune the confidence branch with Outlier Exposure by adding 0.5E x?D OE out[log b(x)] to the network's original optimization objective. InTable 3, the baseline values are derived from the maximum softmax probabilities produced by the classifier trained with DeVries &amp; Taylor (2018)'s publicly available training code. The confidence branch improves over this MSP detector, and after OE, the confidence branch detects anomalies more effectively.</figDesc><table><row><cell></cell><cell></cell><cell>FPR95 ?</cell><cell></cell><cell></cell><cell>AUROC ?</cell><cell></cell><cell></cell><cell>AUPR ?</cell><cell></cell></row><row><cell>D in</cell><cell cols="3">MSP Branch +OE</cell><cell cols="3">MSP Branch +OE</cell><cell cols="3">MSP Branch +OE</cell></row><row><cell>CIFAR-10</cell><cell>49.3</cell><cell>38.7</cell><cell>20.8</cell><cell>84.4</cell><cell>86.9</cell><cell>93.7</cell><cell>51.9</cell><cell>48.6</cell><cell>66.6</cell></row><row><cell>CIFAR-100</cell><cell>55.6</cell><cell>47.9</cell><cell>42.0</cell><cell>77.6</cell><cell>81.2</cell><cell>85.5</cell><cell>36.5</cell><cell>44.4</cell><cell>54.7</cell></row><row><cell>Tiny ImageNet</cell><cell>64.3</cell><cell>66.9</cell><cell>20.1</cell><cell>65.3</cell><cell>63.4</cell><cell>90.6</cell><cell>30.3</cell><cell>25.7</cell><cell>75.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Comparison among the maximum softmax probability, Confidence Branch, and Confidence Branch + OE OOD detectors. The same network architecture is used for all three detectors. All results are percentages, and averaged across all D test out datasets.Synthetic Outliers. Outlier Exposure leverages the simplicity of downloading real datasets, but it is possible to generate synthetic outliers. Note that we made an attempt to distort images with noise and use these as outliers for OE, but the classifier quickly memorized this statistical pattern and did not detect new OOD examples any better than before(Hafner et al., 2018). A method with better success is from<ref type="bibr" target="#b6">Lee et al. (2018)</ref>. They carefully train a GAN to generate synthetic examples near the classifier's decision boundary. The classifier is encouraged to have a low maximum softmax probability on these synthetic examples. For CIFAR classifiers, they mention that a GAN can be a better source of anomalies than datasets such as SVHN. In contrast, we find that the simpler approach of drawing anomalies from a diverse dataset is sufficient for marked improvements in OOD detection.We train a 40-4 Wide Residual Network using<ref type="bibr" target="#b6">Lee et al. (2018)</ref>'s publicly available code, and use the network's maximum softmax probabilities as our baseline. Another classifier trains concurrently with a GAN so that the classifier assigns GAN-generated examples a high OOD score. We want each D test out to be novel. Consequently we use their code's default hyperparameters, and exactly one model encounters all tested D test out distributions. This is unlike their work since, for each D test out distribution, they train and tune a new network. We do not evaluate on Tiny ImageNet, Places365, nor text, since DCGANs cannot stably generate such images and text reliably. Lastly, we take the network trained in tandem with a GAN and fine-tune it with OE.Table 4shows the large gains from using OE with a real and diverse dataset over using synthetic samples from a GAN.</figDesc><table><row><cell></cell><cell></cell><cell>FPR95 ?</cell><cell></cell><cell></cell><cell>AUROC ?</cell><cell></cell><cell></cell><cell>AUPR ?</cell><cell></cell></row><row><cell>D in</cell><cell cols="3">MSP +GAN +OE</cell><cell cols="3">MSP +GAN +OE</cell><cell cols="3">MSP +GAN +OE</cell></row><row><cell>CIFAR-10</cell><cell>32.3</cell><cell>37.3</cell><cell>11.8</cell><cell>88.1</cell><cell>89.6</cell><cell>97.2</cell><cell>51.1</cell><cell>59.0</cell><cell>88.5</cell></row><row><cell>CIFAR-100</cell><cell>66.6</cell><cell>66.2</cell><cell>49.0</cell><cell>67.2</cell><cell>69.3</cell><cell>77.9</cell><cell>27.4</cell><cell>33.0</cell><cell>44.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison among the maximum softmax probability (MSP), MSP + GAN, and MSP + GAN + OE OOD detectors. The same network architecture is used for all three detectors. All results are percentages and averaged across all D test out datasets.</figDesc><table><row><cell>4.4 DENSITY ESTIMATION</cell><cell></cell><cell></cell><cell></cell></row><row><cell>In-Distribution</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">3.06 3.08</cell><cell>3.0 3.1 3.2 3.3 3.4 Anomaly Score (BPP)</cell></row><row><cell>Out-of-Distribution</cell><cell>2.98</cell><cell>+OE 3.43</cell><cell>3.0 3.1 3.2 3.3 3.4 Anomaly Score (BPP)</cell></row><row><cell></cell><cell></cell><cell>+OE</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>OOD detection results with a PixelCNN++ density estimator, and the same estimator after applying OE. The model's bits per pixel (BPP) scores each sample. All results are percentages. Test distributions D test out are described in Appendix A.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6</head><label>6</label><figDesc>; expanded results and D test out descriptions are in Appendix F. In all cases, OE improves over the baseline, and the improvement is especially large for the word-level model.</figDesc><table><row><cell></cell><cell cols="2">FPR90 ?</cell><cell cols="2">AUROC ?</cell><cell cols="2">AUPR ?</cell></row><row><cell>D in</cell><cell cols="2">BPC/BPW +OE</cell><cell cols="2">BPC/BPW +OE</cell><cell cols="2">BPC/BPW +OE</cell></row><row><cell>PTB Characters</cell><cell>99.0</cell><cell>89.4</cell><cell>77.5</cell><cell>86.3</cell><cell>76.0</cell><cell>86.7</cell></row><row><cell>PTB Words</cell><cell>48.5</cell><cell>0.98</cell><cell>81.2</cell><cell>99.2</cell><cell>44.0</cell><cell>97.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table /><note>OOD detection results on Penn Treebank language models. Results are percentages aver- aged over the D test out datasets. Expanded results are in Appendix F.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table><row><cell>are in</cell></row></table><note>Vision OOD example detection for the maximum softmax probability (MSP) baseline de- tector and the MSP detector after fine-tuning with Outlier Exposure (OE). All results are percentages and the result of 10 runs. Values are rounded so that 99.95% rounds to 100%. More results</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>NLP OOD example detection for the maximum softmax probability (MSP) baseline detector and the MSP detector after fine-tuning with Outlier Exposure (OE). All results are percentages and the result of 10 runs. Values are rounded so that 99.95% rounds to 100%.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 :</head><label>11</label><figDesc>OOD detection results on Penn Treebank examples and English Web Treebank outliers. All results are percentages. The D test out datasets come from the English Web Treebank (Bies et al., 2012), which contains text from five different domains: Yahoo! Answers, emails, newsgroups, product reviews, and weblogs. Other NLP D test out datasets we consider do not satisfy the language modeling assumption of continuity in the examples, so we do not evaluate on them.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 13 :</head><label>13</label><figDesc>Calibration results for the softmax temperature tuning baseline, the same baseline after adding Posterior Rescaling, and temperature tuning + Posterior Rescaling + OE.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank NVIDIA for donating GPUs used in this research. This research was supported by a grant from the Future of Life Institute.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A baseline for detecting misclassified and out-of-distribution examples in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Tiny imagenet visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnson</forename></persName>
		</author>
		<ptr target="https://tiny-imagenet.herokuapp.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Calibrated structured prediction. Neural Information Processing Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Kuleshov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning local image descriptors with deep siamese and triplet convolutional networks by minimizing global loss functions. Computer Vision and Pattern Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Training confidence-calibrated classifiers for detecting out-of-distribution samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Enhancing the reliability of out-of-distribution image detection in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Open category detection with PAC guarantees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risheek</forename><surname>Garrepalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Ashwin Bharambe, and Laurens van der Maaten. Exploring the limits of weakly supervised pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Predictive uncertainty estimation via prior networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Malinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Gales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Foundations of Statistical Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<title level="m">Regularizing and Optimizing LSTM Language Models. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">An Analysis of Neural Language Modeling at Multiple Scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Do deep generative models know what they don</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiro</forename><surname>Matsukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilan</forename><surname>Gorur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep neural networks are easily fooled: High confidence predictions for unrecognizable images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Posterior calibration and exploratory analysis for natural language processing models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Connor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">F-measure as the error function to train neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Pastor-Pellicer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Zamora-Mart?nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvador</forename><surname>Espa?a-Boquera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mar?a Jos?</forename><surname>Castro-Bleda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Work-Conference on Artificial Neural Networks (IWANN)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning to generate reviews and discovering sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to learn with compound hd models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik P</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshayvarun</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suraj</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Babu</surname></persName>
		</author>
		<title level="m">Confidence estimation in deep neural networks via density modelling</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Large scale fine-grained categorization and the effectiveness of domain-specific transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<editor>Yin Cui and Yang Song and Chen Sun and Andrew Howard and Serge Belongie</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">80 million tiny images: A large data set for nonparametric object and scene recognition. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Freeman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">LSUN: construction of a large-scale image dataset using deep learning with humans in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Wide residual networks. British Machine Vision Conference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Places: A 10 million image database for scene recognition. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep autoencoding gaussian mixture model for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Martin Renqiang Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daeki</forename><surname>Lumezanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
