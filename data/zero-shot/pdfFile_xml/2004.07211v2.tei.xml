<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dark Experience for General Continual Learning: a Strong, Simple Baseline</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Buzzega</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">AImageLab -University of Modena and Reggio Emilia</orgName>
								<address>
									<settlement>Modena</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Boschini</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">AImageLab -University of Modena and Reggio Emilia</orgName>
								<address>
									<settlement>Modena</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelo</forename><surname>Porrello</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">AImageLab -University of Modena and Reggio Emilia</orgName>
								<address>
									<settlement>Modena</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Abati</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">AImageLab -University of Modena and Reggio Emilia</orgName>
								<address>
									<settlement>Modena</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Calderara</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">AImageLab -University of Modena and Reggio Emilia</orgName>
								<address>
									<settlement>Modena</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dark Experience for General Continual Learning: a Strong, Simple Baseline</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Continual Learning has inspired a plethora of approaches and evaluation settings; however, the majority of them overlooks the properties of a practical scenario, where the data stream cannot be shaped as a sequence of tasks and offline training is not viable. We work towards General Continual Learning (GCL), where task boundaries blur and the domain and class distributions shift either gradually or suddenly. We address it through mixing rehearsal with knowledge distillation and regularization; our simple baseline, Dark Experience Replay, matches the network's logits sampled throughout the optimization trajectory, thus promoting consistency with its past. By conducting an extensive analysis on both standard benchmarks and a novel GCL evaluation setting (MNIST-360), we show that such a seemingly simple baseline outperforms consolidated approaches and leverages limited resources. We further explore the generalization capabilities of our objective, showing its regularization being beneficial beyond mere performance. Code is available at https://github.com/aimagelab/mammoth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Rehearsal-based methods tackle catastrophic forgetting by replaying a subset of the training data stored in a memory buffer. Early works <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b35">35]</ref> proposed Experience Replay (ER), that is interleaving old samples with current data in training batches. Several recent studies directly expand on this idea: Meta-Experience Replay (MER) [34] casts replay as a meta-learning problem to maximize transfer from past tasks while minimizing interference; Gradient based Sample Selection (GSS) [1] introduces a variation on ER to store optimally chosen examples in the memory buffer; Hindsight Anchor Learning (HAL) [8] complements replay with an additional objective to limit forgetting on pivotal learned data-points. On the other hand, Gradient Episodic Memory (GEM) [28] and its lightweight counterpart Averaged-GEM (A-GEM) [9] leverage old training data to build optimization constraints to be satisfied by the current update step. These works show improvements over ER when confining the learning to a small portion of the training set (e.g., 1k examples per task). However, we believe that this setting rewards sample efficiencyi.e., making good use of the few shown examples -which represents a potential confounding factor for assessing catastrophic forgetting. Indeed, Section 4 reveals that the above-mentioned approaches are not consistently superior to ER when lifting these restrictions, which motivates our research in this kind of methods.</p><p>Knowledge Distillation. Several approaches exploit Knowledge Distillation [17] to mitigate forgetting by appointing a past version of the model as a teacher. Learning Without Forgetting (LwF) [25] computes a smoothed version of the current responses for the new examples at the beginning of each task, minimizing their drift during training. A combination of replay and distillation can be found in iCaRL <ref type="bibr" target="#b33">[33]</ref>, which employs a buffer as a training set for a nearest-mean-of-exemplars classifier while preventing the representation from deteriorating in later tasks via a self-distillation loss term.</p><p>Other Approaches. Regularization-based methods extend the loss function with a term that prevents network weights from changing, as done by Elastic Weight Consolidation (EWC) <ref type="bibr" target="#b20">[21]</ref>, online EWC (oEWC) [37], Synaptic Intelligence (SI) <ref type="bibr" target="#b43">[43]</ref> and Riemmanian Walk (RW) <ref type="bibr" target="#b6">[7]</ref>. Architectural methods, on the other hand, devote distinguished sets of parameters to distinct tasks. Among these, Progressive Neural Networks (PNN) <ref type="bibr" target="#b36">[36]</ref> instantiates new networks incrementally as novel tasks occur, resulting in a linearly growing memory requirement. To mitigate this issue, PackNet <ref type="bibr" target="#b29">[29]</ref> and Hard Attention to the Task (HAT) <ref type="bibr" target="#b38">[38]</ref> share the same architecture for subsequent tasks, employing a heuristic strategy to prevent intransigence by allocating additional units when needed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Practical applications of neural networks may require to go beyond the classical setting where all data are available at once: when new classes or tasks emerge, such models should acquire new knowledge on-the-fly, incorporating it with the current one. However, if the learning focuses on the current set of examples solely, a sudden performance deterioration occurs on the old data, referred to as catastrophic forgetting <ref type="bibr" target="#b30">[30]</ref>. As a trivial workaround, one could store all incoming examples and re-train from scratch when needed, but this is impracticable in terms of required resources. Continual Learning (CL) methods aim at training a neural network from a stream of non i.i.d. samples, relieving catastrophic forgetting while limiting computational costs and memory footprint <ref type="bibr" target="#b33">[33]</ref>.</p><p>It is not always easy to have a clear picture of the merits of these works: due to subtle differences in the way methods are evaluated, many state-of-the-art approaches only stand out in the setting where they were originally conceived. Several recent papers <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b40">40]</ref> address this issue and conduct a critical review of existing evaluation settings, leading to the formalization of three main experimental settings <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b40">40]</ref>. By conducting an extensive comparison on them, we surprisingly observe that a simple Experience Replay baseline (i.e. interleaving old examples with ones from the current task) consistently outperforms cutting-edge methods in the considered settings.</p><p>Also, the majority of the compared methods are unsuited for real-world applications, where memory is bounded and tasks intertwine and overlap. Recently, <ref type="bibr" target="#b10">[11]</ref> introduced a series of guidelines that CL methods should realize to be applicable in practice: i) no task boundaries: do not rely on boundaries between tasks during training; ii) no test time oracle: do not require task identifiers at inference time; iii) constant memory: have a bounded memory footprint throughout the entire training phase.  <ref type="table">Table 1</ref>: Continual learning approaches and their compatibility with the General Continual Learning major requirements <ref type="bibr" target="#b10">[11]</ref>. For an exhaustive discussion, please refer to supplementary materials.</p><p>These requirements outline the General Continual Learning (GCL), of which Continual Learning is a relaxation. As reported in <ref type="table">Table 1</ref>, ER also stands out being one of the few methods that are fully compliant with GCL. MER <ref type="bibr" target="#b34">[34]</ref> and GSS <ref type="bibr" target="#b0">[1]</ref> fulfill the requirements as well, but they suffer from a very long running time which hinders their applicability to non-trivial datasets.</p><p>In this work, we propose a novel CL baseline that improves on ER while maintaining a very simple formulation. We call it Dark Experience Replay (DER) as it relies on dark knowledge <ref type="bibr" target="#b15">[16]</ref> for distilling past experiences, sampled over the entire training trajectory. Our proposal satisfies the GCL guidelines and outperforms the current state-of-the-art approaches in the standard CL experiments we conduct. With respect to ER, we empirically show that our baseline exhibits remarkable qualities: it converges to flatter minima, achieves better model calibration at the cost of a limited memory and training time overhead. Eventually, we propose a novel GCL setting (MNIST-360); it displays MNIST digits sequentially and subject to a smooth increasing rotation, thus generating both sudden and gradual changes in their distribution. By evaluating the few GCL-compatible methods on MNIST-360, we show that DER also qualifies as a state-of-the-art baseline for future studies on this setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dark Experience Replay</head><p>Formally, a CL classification problem is split in T tasks; during each task t ? {1, ..., T } input samples x and their corresponding ground truth labels y are drawn from an i.i.d. distribution D t . A function f , with parameters ?, is optimized on one task at a time in a sequential manner. We indicate the output logits with h ? (x) and the corresponding probability distribution over the classes with f ? (x) softmax(h ? (x)). The goal is to learn how to correctly classify, at any given point in training, examples from any of the observed tasks up to the current one t ? {1, . . . , t c }:</p><formula xml:id="formula_0">argmin ? tc t=1 L t , where L t E (x,y)?Dt (y, f ? (x)) .<label>(1)</label></formula><p>This is especially challenging as data from previous tasks are assumed to be unavailable, meaning that the best configuration of ? w.r.t. L 1...tc must be sought without D t for t ? {1, . . . , t c ? 1}. Ideally, we look for parameters that fit the current task well while approximating the behavior observed in the old ones: effectively, we encourage the network to mimic its original responses for past samples. To preserve the knowledge about previous tasks, we seek to minimize the following objective:</p><formula xml:id="formula_1">L tc + ? tc?1 t=1 E x?Dt D KL (f ? * t (x) || f ? (x)) ,<label>(2)</label></formula><p>where ? * t is the optimal set of parameters at the end of task t, and ? is a hyper-parameter balancing the trade-off between the terms. This objective, which resembles the teacher-student approach, would require the availability of D t for previous tasks. To overcome such a limitation, we introduce a replay buffer M t holding past experiences for task t. Differently from other rehearsal-based methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b34">34]</ref>, we retain the network's logits z h ?t (x), instead of the ground truth labels y.</p><formula xml:id="formula_2">L tc + ? tc?1 t=1 E (x,z)?Mt D KL (softmax(z) || f ? (x)) .<label>(3)</label></formula><p>As we focus on General Continual Learning, we intentionally avoid relying on task boundaries to populate the buffer as the training progresses. Therefore, in place of the common task-stratified sampling strategy, we adopt reservoir sampling <ref type="bibr" target="#b41">[41]</ref>: this way, we select |M| random samples from the input stream, guaranteeing that they have the same probability |M| /|S| of being stored in the buffer, without knowing the length of the stream S in advance. We can rewrite Eq. 3 as follows:</p><formula xml:id="formula_3">L tc + ? E (x,z)?M D KL (softmax(z) || f ? (x)) .</formula><p>(4) Such a strategy implies picking logits z during the optimization trajectory, so potentially different from the ones that can be observed at the task's local optimum. Even if counter-intuitive, we empirically observed that this strategy does not hurt performance, while still being suitable without task boundaries. Furthermore, we observe that the replay of sub-optimal logits has beneficial effects in terms of flatness of the attained minima and calibration (see <ref type="bibr">Section 5)</ref>.</p><p>Under mild assumptions <ref type="bibr" target="#b16">[17]</ref>, the optimization of the KL divergence in Eq. 4 is equivalent to minimizing the Euclidean distance between the corresponding pre-softmax responses (i.e. logits). In this work we opt for matching logits, as it avoids the information loss occurring in probability space due to the squashing function (e.g., softmax) <ref type="bibr" target="#b26">[27]</ref>. With these considerations in hands, Dark Experience Replay (DER, algorithm 1) optimizes the following objective:</p><formula xml:id="formula_4">L tc + ? E (x,z)?M z ? h ? (x) 2 2 .<label>(5)</label></formula><p>We approximate the expectation by computing gradients on batches sampled from the replay buffer.</p><p>Dark Experience Replay++. It is worth noting that the reservoir strategy may weaken DER under some specific circumstances. Namely, when a sudden distribution shift occurs in the input stream, logits that are highly biased by the training on previous tasks might be sampled for later replay: leveraging the ground truth labels as well -as done by ER -could mitigate such a shortcoming. On these grounds, we also propose Dark Experience Replay++ (DER++, algorithm 2), which equips the objective of Eq. 5 with an additional term on buffer datapoints, promoting higher conditional likelihood w.r.t. their ground truth labels with a minimal memory overhead:</p><formula xml:id="formula_5">L tc + ? E (x ,y ,z )?M z ? h ? (x ) 2 2 + ? E (x ,y ,z )?M (y , f ? (x )) ,<label>(6)</label></formula><p>where ? is an additional coefficient balancing the last term 1 (DER++ collapses to DER when ? = 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 -Dark Experience Replay</head><p>Input: dataset D, parameters ?, scalar ?, learning rate ?</p><formula xml:id="formula_6">M ? {} for (x, y) in D do (x , z , y ) ? sample(M) xt ? augment(x) x t ? augment(x ) z ? h ? (xt) reg ? ? z ? h ? (x t ) 2 2 ? ? ? + ? ? ? ? [ (y, f ? (xt)) + reg] M ? reservoir(M, (x, z)) end for Algorithm 2 -Dark Experience Replay ++ Input: dataset D, parameters ?, scalars ? and ?, learning rate ? M ? {} for (x, y) in D do (x , z , y ) ? sample(M) (x , z , y ) ? sample(M) xt ? augment(x) x t , x t ? augment(x ), augment(x ) z ? h ? (xt) reg ? ? z ? h ? (x t ) 2 2 + ? (y , f ? (x t )) ? ? ? + ? ? ? ? [ (y, f ? (xt)) + reg] M ? reservoir(M, (x, z, y)) end for</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Relation with previous works</head><p>While both our proposal and LWF <ref type="bibr" target="#b24">[25]</ref> leverage knowledge distillation in Continual Learning, they adopt remarkably different approaches. The latter does not replay past examples, so it only encourages the similarity between teacher and student responses w.r.t. to data points of the current task. Alternatively, iCaRL <ref type="bibr" target="#b33">[33]</ref> distills knowledge for past outputs w.r.t. past exemplars, which is more akin to our proposal. However, the former exploits the network appointed at the end of each task as the sole teaching signal. On the contrary, our methods store logits sampled throughout the optimization trajectory, which resembles having several different teacher parametrizations.</p><p>A close proposal to ours is given by Function Distance Regularization (FDR) for combatting catastrophic forgetting (Sec. 3.1 of <ref type="bibr" target="#b3">[4]</ref>). Like FDR, we use past exemplars and network outputs to align past and current outputs. However, similarly to the iCaRL discussion above, FDR stores network responses at task boundaries and thus cannot be employed in a GCL setting. Instead, the experimental analysis we present in Sec. 5 reveals that the need of task boundaries can be relaxed through reservoir without experiencing a drop in performance; on the contrary we empirically observe that DER and DER++ achieve significantly superior results and remarkable properties. We finally highlight that the motivation behind <ref type="bibr" target="#b3">[4]</ref> lies chiefly in studying how the training trajectory of NNs can be characterized in a functional L 2 Hilbert space, whereas the potential of function-space regularization for Continual Learning problems is only coarsely addressed with a single experiment on MNIST. In this respect, we present extensive experiments on multiple CL settings as well as a detailed analysis (Sec. 5) providing a deeper understanding on the effectiveness of this kind of regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We adhere to <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b40">40]</ref> and model the sequence of tasks according to the following three settings:</p><p>Task Incremental Learning (Task-IL) and Class Incremental Learning (Class-IL) split the training samples into partitions of classes (tasks). Although similar, the former provides task identities to select the relevant classifier for each example, whereas the latter does not; this difference makes Task-IL and Class-IL the easiest and hardest scenarios among the three <ref type="bibr" target="#b40">[40]</ref>. In practice, we follow <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b43">43]</ref> by splitting CIFAR-10 <ref type="bibr" target="#b21">[22]</ref> and Tiny ImageNet <ref type="bibr" target="#b39">[39]</ref> in 5 and 10 tasks, each of which introduces 2 and 20 classes respectively. We show all the classes in the same fixed order across different runs.</p><p>Domain Incremental Learning (Domain-IL) feeds all classes to the network during each task, but applies a task-dependent transformation to the input; task identities remain unknown at test time. For this setting, we leverage two common protocols built upon the MNIST dataset <ref type="bibr" target="#b23">[24]</ref>, namely Permuted MNIST <ref type="bibr" target="#b20">[21]</ref> and Rotated MNIST <ref type="bibr" target="#b28">[28]</ref>. They both require the learner to classify all MNIST digits for 20 subsequent tasks, but the former applies a random permutation to the pixels, whereas the latter rotates the images by a random angle in the interval [0, ?).</p><p>As done in previous works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b42">42]</ref>, we provide task boundaries to the competitors demanding them at training time (e.g. oEWC or LwF). This choice is meant to ensure a fair comparison between our proposal -which does not need boundaries -and a broader class of methods in literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Protocol</head><p>Architecture. For tests we conducted on variants of the MNIST dataset, we follow <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b34">34]</ref> by employing a fully-connected network with two hidden layers, each one comprising of 100 ReLU units. For CIFAR-10 and Tiny ImageNet, we follow <ref type="bibr" target="#b33">[33]</ref> and rely on ResNet18 <ref type="bibr" target="#b14">[15]</ref> (not pre-trained).</p><p>Augmentation. For CIFAR-10 and Tiny ImageNet, we apply random crops and horizontal flips to both stream and buffer examples. We propagate this choice to competitors for fairness. It is worth noting that combining data augmentation with our regularization objective enforces an implicit consistency loss <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, which aligns predictions for the same example subjected to small data transformations.</p><p>Hyperparameter selection. We select hyperparameters by performing a grid-search on a validation set, the latter obtained by sampling 10% of the training set. For the Domain-IL scenario, we make use of the final average accuracy as the selection criterion. Differently, we perform a combined grid-search for Class-IL and Task-IL, choosing the configuration that achieves the highest final accuracy averaged on the two settings. Please refer to the supplementary materials for a detailed characterization of the hyperparameter grids we explored along with the chosen configurations.</p><p>Training. To provide a fair comparison among CL methods, we train all the networks using the Stochastic Gradient Descent (SGD) optimizer. Despite being interested in an online scenario, with no additional passages on the data, we reckon it is necessary to set the number of epochs per task in relation to the dataset complexity. Indeed, if even the pure-SGD baseline fails at fitting a single task with adequate accuracy, we could not properly disentangle the effects of catastrophic forgetting from those linked to underfitting -we refer the reader to the supplementary material for an experimental discussion regarding this issue. For MNIST-based settings, one epoch per task is sufficient. Conversely, we increase the number of epochs to 50 for Sequential CIFAR-10 and 100 for Sequential Tiny ImageNet respectively, as commonly done by works that test on harder datasets <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b43">43]</ref>. We deliberately hold batch size and minibatch size out from the hyperparameter space, thus avoiding the flaw of a variable number of update steps for different methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Results</head><p>In this section, we compare DER and DER++ against two regularization-based methods (oEWC, SI), two methods leveraging Knowledge Distillation (iCaRL, LwF 2 ), one architectural method (PNN) and six rehearsal-based methods (ER, GEM, A-GEM, GSS, FDR <ref type="bibr" target="#b3">[4]</ref>, HAL) <ref type="bibr" target="#b2">3</ref> We further provide a lower bound, consisting of SGD without any countermeasure to forgetting and an upper bound given by training all tasks jointly (JOINT). <ref type="table">Table 2</ref> reports performance in terms of average accuracy at the end of all tasks (we refer the reader to supplementary materials for other metrics as forward and backward transfer <ref type="bibr" target="#b28">[28]</ref>). Results are averaged across ten runs, each one involving a different initialization.</p><p>DER and DER++ achieve state-of-the-art performance in almost all settings. When compared to oEWC and SI, the gap appears unbridgeable, suggesting that regularization towards old sets of parameters does not suffice to prevent forgetting. We argue that this is due to local information modeling weights importance: as it is computed in earlier tasks, it could become untrustworthy in later ones. While being computationally more efficient, LWF performs worse than SI and oEWC on average. PNN, which achieves the strongest results among non-rehearsal methods, attains lower accuracy than replay-based ones despite its memory footprint being much higher at any buffer size.</p><p>When compared to rehearsal methods, DER and DER++ show strong performance in the majority of benchmarks, especially in the Domain-IL scenario. For these problems, a shift occurs within the input domain, but not within the classes: hence, the relations among them also likely persist. As an example, if it is true that during the first task number 2's visually look like 3's, this still holds when applying rotations or permutations, as it is done in the following tasks. We argue that leveraging soft-targets in place of hard ones (ER) carries more valuable information <ref type="bibr" target="#b16">[17]</ref>, exploited by DER and DER++ to preserve the similarity structure through the data-stream. Additionally, we observe that methods resorting to gradients (GEM, A-GEM, GSS) seem to be less effective in this setting.</p><p>The gap in performance we observe in Domain-IL is also found in the Class-IL setting, as DER is remarkably capable of learning how classes from different tasks are related to each other. This is not  <ref type="table">Table 2</ref>: Classification results for standard CL benchmarks, averaged across 10 runs. '-' indicates experiments we were unable to run, because of compatibility issues (e.g. between PNN, iCaRL and LwF in Domain-IL) or intractable training time (e.g. GEM, HAL or GSS on Tiny ImageNet). so relevant in Task-IL, where DER performs on par with ER on average. In it, classes only need to be compared in exclusive subsets, and maintaining an overall vision is not especially rewarding. In such a scenario, DER++ manages to effectively combine the strengths of both methods, resulting in generally better accuracy. Interestingly, iCaRL appears valid when using a small buffer; we believe that this is due to its helpful herding strategy, ensuring that all classes are equally represented in memory. As a side note, other ER-based methods (HAL and GSS) show weaker results than ER itself on such challenging datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MNIST-360</head><p>To address the General Continual Learning desiderata, we propose a novel protocol: MNIST-360. It models a stream of data presenting batches of two consecutive MNIST digits at a time (e.g. {0, 1}, {1, 2}, {2, 3} etc.), as depicted in <ref type="figure" target="#fig_0">Fig. 1</ref>. We rotate each example of the stream by an increasing angle and, after a fixed number of steps, switch the lesser of the two digits with the following one. As it is impossible to distinguish 6's and 9's upon rotation, we do not use 9's in MNIST-360. The stream visits the nine possible couples of classes three times, allowing the model to leverage positive transfer when revisiting a previous task. In the implementation, we guarantee that: i) each example is shown once during the overall training; ii) two digits of the same class are never observed under the same rotation. We provide a detailed description of training and test sets in supplementary materials.   It is worth noting that such a setting presents both sharp (change in class) and smooth (rotation) distribution shifts; therefore, for the algorithms that rely on explicit boundaries, it would be hard to identify them. As outlined in Section 1, just ER, MER, and GSS are suitable for GCL. However, we also explore a variant of A-GEM equipped with a reservoir memory buffer (A-GEM-R). We compare these approaches with DER and DER++, reporting the results in <ref type="table" target="#tab_3">Table 3</ref> (we keep the same fully-connected network we used on MNIST-based datasets). As can be seen, DER and DER++ outperform other approaches in such a challenging scenario, supporting the effectiveness of the proposed baselines against alternative replay methods. Due to space constraints, we refer the reader to supplementary materials for an additional evaluation regarding the memory footprint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Model Analysis</head><p>In this section, we provide an in depth analysis of DER and DER++ by comparing them against FDR and ER. By so doing, we gather insights on the employment of logits sampled throughout the optimization trajectory, as opposed to ones at task boundaries and ground truth labels.</p><p>DER converges to flatter minima. Recent studies <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref> link Deep Network generalization to the geometry of the loss function, namely the flatness of the attained minimum. While these works link flat minima to good train-test generalization, here we are interested in examining their weight in Continual Learning. Let us suppose that the optimization converges to a sharp minimum w.r.t. L 1...tc (Eq. 1): in that case, the tolerance towards local perturbations is quite low. As a side effect, the drift we will observe in parameter space (due to the optimization of L 1...t for t &gt; t c ) will intuitively lead to an even more serious drop in performance.</p><p>On the contrary, reaching a flat minimum for L 1...tc could give more room for exploring neighbouring regions of the parameter space, where one may find a new optimum for task t without experiencing a severe failure on tasks 1, . . . , t c . We conjecture that the effectiveness of the proposed baseline is linked to its ability to attain flatter and robust minima, which generalizes better to unseen data and, additionally, favors adaptability to incoming tasks. To validate this hypothesis, we compare the flatness of the training minima of FDR, ER, DER and DER++ utilizing two distinct metrics.</p><p>Firstly, as done in <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b45">45]</ref>, we consider the model at the end of training and add independent Gaussian noise with growing ? to each parameter. This allows us to evaluate its effect on the average loss across all training examples. As shown in <ref type="figure" target="#fig_2">Fig. 2(a)</ref> (S-CIFAR-10, buffer size 500), ER and especially FDR reveal higher sensitivity to perturbations than DER and DER++. Furthermore, <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref> propose measuring flatness by evaluating the eigenvalues of ? 2 ? L: sharper minima correspond to larger Hessian eigenvalues. At the end of training on S-CIFAR-10, we compute the empirical Fisher Information Matrix F = ? ? L ? ? L T /N w.r.t. the whole training set (as an approximation of the intractable Hessian <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21]</ref>). <ref type="figure" target="#fig_2">Fig. 2(b)</ref> reports the sum of its eigenvalues Tr(F ): as one can see, DER and especially DER++ produce the lowest eigenvalues, which translates into flatter minima following our intuitions. It is worth noting that FDR's large Tr(F ) for buffer size 5120 could be linked to its failure case in S-CIFAR-10, Class-IL.  DER converges to more calibrated networks. Calibration is a desirable property for a learner, measuring how much the confidence of its predictions corresponds to its accuracy. Ideally, we expect output distributions whose shapes mirror the probability of being correct, thus quantifying how much one can trust a specific prediction. Recent works find out that modern Deep Networks -despite largely outperforming the ones from a decade ago -are less calibrated <ref type="bibr" target="#b13">[14]</ref>, as they tend to yield overconfident predictions <ref type="bibr" target="#b22">[23]</ref>. In real-world applications, AI tools should support decisions in a continuous and online fashion (e.g. weather forecasting <ref type="bibr" target="#b4">[5]</ref> or econometric analysis <ref type="bibr" target="#b12">[13]</ref>); therefore, calibration represents an appealing property for any CL system aiming for employment outside of a laboratory environment. <ref type="figure" target="#fig_2">Fig. 2(c, d)</ref> shows, for TinyImageNet, the value of the Expected Calibration Error (ECE) <ref type="bibr" target="#b31">[31]</ref> during the training and the reliability diagram at the end of it respectively. It can be seen that DER and DER++ achieve a lower ECE than ER and FDR without further application of a posteriori calibration methods (e.g., Temperature Scaling, Dirichlet Calibration, ...). This means that models trained using Dark Experience are less overconfident and, therefore, easier to interpret. As a final remark, Liu et al. link this property to the capability to generalize to novel classes in a zero-shot scenario <ref type="bibr" target="#b25">[26]</ref>, which could translate into an advantageous starting point for the subsequent tasks for DER and DER++.</p><p>On the informativeness of DER's buffer. Network responses provide a rich description of the corresponding data point. Following this intuition, we posit that the merits of DER also result from the knowledge inherent in its memory buffer: when compared to the one built by ER, the former represents a more informative summary of the overall (full) CL problem. If that were the case, a new learner trained only on the buffer would yield an accuracy that is closer to the one given by jointly training on all data. To validate this idea, we train a network from scratch using the memory buffer as the training set: we can hence compare how memories produced by DER, ER, and FDR summarize well the underlying distribution. <ref type="figure" target="#fig_2">Fig. 2(e)</ref> shows the accuracy on the test set: as can be seen, DER delivers the highest performance, surpassing ER, and FDR. This is particularly evident for smaller buffer sizes, indicating that DER's buffer should be especially preferred in scenarios with severe memory constraints.</p><p>Further than its pure performance, we assess whether a model trained on the buffer can be specialized to an already seen task: this would be the case of new examples from an old distribution becoming available on the stream. We simulate it by sampling 10 samples per class from the test set and then fine-tuning on them with no regularization; <ref type="figure" target="#fig_2">Fig. 2</ref> reports the average accuracy on the remainder of the test set of each task: here too, DER's buffer yields better performance than ER and FDR, thus providing additional insight regarding its representation capabilities.</p><p>On training time. When facing up with a data-stream, one often cares about reducing the overall processing time: otherwise, training would not keep up with the rate at which data are made available to the stream. In this regard, we assess the performance of both DER and DER++ and other rehearsal methods in terms of wall-clock time (seconds) at the end of the last task. To guarantee a fair comparison, we conduct all tests under the same conditions, running each benchmark on a Desktop Computer equipped with an NVIDIA Titan X GPU and an Intel i7-6850K CPU. <ref type="figure" target="#fig_2">Fig. 2(f</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we introduce Dark Experience Replay: a simple baseline for Continual Learning, which leverages Knowledge Distillation for retaining past experience and therefore avoiding catastrophic forgetting. We show the effectiveness of our proposal through an extensive experimental analysis, carried out on top of standard benchmarks. Also, we argue that the recently formalized General Continual Learning provides the foundation for advances in diverse applications; for this reason, we propose MNIST-360 as an experimental protocol for this setting. We recommend DER as a starting point for future studies on both CL and GCL in light of its strong results on all evaluated settings and of the properties observed in Sec. 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>We hope that this work will prove useful to the Continual Learning (CL) scientific community as it is fully reproducible and includes:</p><p>? a clear and extensive comparison of the state of the art on multiple datasets;</p><p>? Dark Experience Replay (DER), a simple baseline that outperforms all other methods while maintaining a limited memory footprint.</p><p>As revealed by the analysis in Section 5, DER also proves to be better calibrated than a simple Experience Replay baseline, which means that it could represent a useful starting point for the study of CL decision-making applications where an overconfident model would be detrimental.</p><p>We especially hope that the community will benefit from the introduction of MNIST-360, the first evaluation protocol adhering to the General Continual Learning scenario. The latter has been recently proposed to describe the requirement of a CL system that can be applied to real-world problems. Widespread adoption of our protocol (or new ones of similar design) can close the gap between the current CL studies and practical AI systems. Due to the abstract nature of MNIST-360 (it only contains digits), we believe that ethical and bias concerns are not applicable. <ref type="table">Table 1</ref> Below we provide a justification for each mark of <ref type="table">Table 1</ref>:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Justification of</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Constant Memory</head><p>? Distillation methods need to accommodate a teacher model along with the current learner, at a fixed memory cost. While iCaRL maintains a snapshot of the network as teacher, LWF stores teacher responses to new task data at the beginning of each task. ? Rehearsal methods need to store a memory buffer of a fixed size. This also affects iCaRL.</p><p>? Architectural methods increase the model size linearly with respect to the number of tasks.</p><p>In more detail, PackNet and HAT need a Boolean and float mask respectively, while PNN devotes a whole new network to each task. ? Regularization methods usually require to store up to two parameters sets, thus respecting the constant memory constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 No Task Boundaries</head><p>? Distillation methods depend on task boundaries to appoint a new teacher. iCaRL also depends on them to update its memory buffer, in accordance with the herding sampling strategy. ? Architectural methods require to know exactly when the task finishes to update the model.</p><p>PackNet also re-trains the network at this time. ? Regularization methods exploit the task change to take a snapshot of the network, using it to constrain drastic changes for the most important weights (oEWC, SI). Online EWC also needs to pass over the whole training set to compute the weights importance. ? Rehearsal methods can operate in the absence of task boundaries if their memory buffer exploits to the reservoir sampling strategy. This applies to ER, GSS, MER, DER and DER++ and can easily be extended to A-GEM (by replacing ring sampling with reservoir as discussed in Sec. 4.3). Other rehearsal approaches, however, rely on boundaries to perform specific steps: HAL hallucinates new anchors that synthesize the task it just completed, whereas FDR needs them to record converged logits to replay.</p><p>GEM does not strictly depend on task boundaries, but rather on task identities to associate every memorized input with its original task (as described in Sec. 3 of <ref type="bibr" target="#b28">[28]</ref>). This is meant to let GEM set up a separate QP for each past task (notice that this is instead unnecessary for A-GEM, which only solves one generic constraint w.r.t. the average gradient of all buffer items). We acknowledge that reliance on task boundaries and reliance on task identities are logically equivalent: indeed, i) the availability of task identities straightforwardly allows any method to recognize and exploit task boundaries; ii) vice versa, by relying on task boundaries and maintaining a task counter, one can easily associate task identities to incoming input points (under the assumption that tasks are always shown in a sequence without repetitions). This explains why <ref type="table">Table 1</ref> indicates that GEM depends on task boundaries. This is also in line with what argued by the authors of <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 No test time oracle</head><p>? Architectural methods need to know the task label to modify the model accordingly before they make any prediction. ? LWF is designed as a multi-head method, which means that its prediction head must be chosen in accordance with the task label. ? Regularization methods, rehearsal methods and iCaRL can perform inference with no information about the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Details on the Implementation of MNIST-360</head><p>MNIST-360 presents the evaluated method with a sequence of MNIST digits from 0 to 8 shown at increasing angles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Training</head><p>For Training purposes, we build batches using exemplars that belong to two consequent classes at a time, meaning that 9 pairs of classes are possibly encountered: (0, 1), <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b1">2)</ref>, <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b2">3)</ref>, <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b3">4)</ref>, <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b4">5)</ref>, <ref type="bibr" target="#b4">(5,</ref><ref type="bibr" target="#b5">6)</ref>, (6, 7), <ref type="bibr" target="#b6">(7,</ref><ref type="bibr" target="#b7">8)</ref>, <ref type="figure">and (8, 0)</ref>. Each pair is shown in this order in R rounds (R = 3 in our experiments) at changing rotations. This means that MNIST-360 consists of 9 ? R pseudo-tasks, whose boundaries are not signaled to the tested method. We indicate them with ? (d1,d2) r where r ? {1, . . . , R} is the round number and d 1 , d 2 are digits forming one of the pairs listed above.</p><p>As every MNIST digit d appears in 2 ? R pseudo-tasks, we randomly split its example images evenly in 6 groups G d i where i ? {1, . . . , 2 ? R}. The set of exemplars that are shown in ? (d1,d2) r is given as</p><formula xml:id="formula_7">G d1 [r/2] ? G d2 [r/2]+1 , where [r/2] is an integer division.</formula><p>At the beginning of ? </p><formula xml:id="formula_8">N d1 = min |G d1 [r/2] | ? C d1 |G d1 [r/2] | ? C d1 + |G d2 [r/2]+1 | ? C d2 ? B, |G d1 [r/2] | ? C d1 (7) N d2 = min B ? N d1 , |G d2 [r/2]+1 | ? C d2<label>(8)</label></formula><p>This allows us to produce balanced batches, in which the proportion of exemplars of d 1 and d 2 is maintained the same. Pseudo-task ? (d1,d2) r ends when the entirety of G d1 [r/2] ? G d2 [r/2]+1 has been shown, which does not necessarily happen after a fixed number of batches.</p><p>Each digit d is also associated with a counter C r d that is never reset during training and is increased every time an exemplar of d is shown to the evaluated method. Before its showing, every exemplar is rotated by</p><formula xml:id="formula_9">2? |d| C r d + O d<label>(9)</label></formula><p>where |d| is the number of total examples of digit d in the training set and O d is a digit-specific angular offset, whose value for the ith digit is given by</p><formula xml:id="formula_10">O i = (i ? 1) ? 2?R (O 0 = ? ? 2?R , O 1 = 0, O 2 = ? 2?R</formula><p>, etc.). By so doing, every digit's exemplars are shown with an increasing rotation spanning an entire 2? angle throughout the entire procedure. Rotation changes within each pseudo-task, resulting into a gradually changing distribution. <ref type="figure" target="#fig_0">Fig. 1</ref> in the main paper shows the first batch of the initial 11 pseudo-tasks with B = 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Test</head><p>As no task boundaries are provided, evaluation on MNIST-360 can only be carried out after the training is complete. For test purposes, digits are still shown with an increasing rotation as per Eq. 9, with |d| referring to the test-set digit cardinality and no offset applied (O d = 0).</p><p>The order with which digits are shown is irrelevant, therefore no specific batching strategy is necessary and we simply show one digit at a time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Accuracy vs. Memory Occupation</head><p>In <ref type="figure" target="#fig_6">Fig. 3</ref>, we show how the accuracy results for the experiments in Section 4.2 and F.1 relate to the total memory usage of the evaluated methods. We maintain that having a reduced memory footprint is especially important for a CL method. This is usually fairly easy to assess for rehearsal-based methods, as they clearly specify the number of items that must be saved in the memory buffer. While this could lead to the belief that they have higher memory requirements than other classes of solutions <ref type="bibr" target="#b8">[9]</ref>, it should be noted that architectural, distillation-and regularization-based methods can instead be characterized by non-negligible fixed overheads, making them less efficient and harder to scale.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Reservoir Sampling Algorithm</head><p>In the following, we provide the buffer insertion algorithm (3) for the Reservoir Sampling strategy <ref type="bibr" target="#b41">[41]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Details on the Implementation of iCaRL</head><p>Although iCaRL <ref type="bibr" target="#b33">[33]</ref> was initially proposed for the Class-IL setting, we make it possible to use it for Task-IL as well by introducing a modification of its classification rule. Let ? y be the average feature vector of the exemplars for class y and ?(x) be the feature vector computed on example x, iCaRL predicts a label y * as</p><formula xml:id="formula_11">y * = argmin y=1,...,t ?(x) ? ? y .<label>(10)</label></formula><p>Instead, given the tensor of average feature vectors for all classes ?, we formulate iCaRL's network response h(x) as h(x) = ? ?(x) ? ? . (11) Considering the argmax for h(x), without masking (Class-IL setting), results in the same prediction as Eq. 10.</p><p>It is also worth noting that iCaRL exploits a weight-decay regularization term (wd_reg), as suggested in <ref type="bibr" target="#b33">[33]</ref>, in order to make its performance competitive with the other proposed approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1 Sequential-MNIST</head><p>Similarly to Sequential CIFAR-10, the Sequential MNIST protocol split the whole training set of the MNIST Digits dataset in 5 tasks, each of which introduces two new digits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Class-IL <ref type="table">Task</ref>    <ref type="figure">Figure 4</ref>: A comparison between our proposal (DER++) and the variants of Experience Replay presented in <ref type="bibr" target="#b9">[10]</ref>.</p><p>In the main paper we already draw a thorough comparison with Experience Replay (ER), showing that DER and DER++ often result in better performance and more remarkable capabilities. It is worth noting that the ER we compared with was equipped with the reservoir strategy; therefore, it would be interesting to see whether the same experimental conclusions also hold for other variants of naive replay (e.g. ER with ring-buffer). For this reason, <ref type="figure">Fig. 4</ref> provides further analysis in the setting of <ref type="bibr" target="#b9">[10]</ref>, which investigates what happens when varying the number of samples that are retained for later replay. Interestingly, while reservoir weakens ER when very few past memories are available, it does not bring DER++ to the same flaw. In the low-memory regime, indeed, the probability of leaving a class out from the buffer increases: while ER would not have any chance to retain the knowledge underlying these "ghost" classes, we conjecture that DER++ could recover this information from the non-argmax outputs of the past predicted distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3 Single-Epoch Setting</head><p>Buffer ER FDR DER++ JOINT JOINT  Several Continual Learning works present experiments even on fairly complex datasets (e.g.: CIFAR-10, CIFAR-100, Mini ImageNet) in which the model is only trained for one epoch for each task <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b28">28]</ref>. As showing the model each example only once could be deemed closer to real-world CL scenarios, this is a very compelling setting and somewhat close in spirit to the reasons why we focus on General Continual Learning.</p><p>However, we see that committing to just one epoch (hence, few gradient steps) makes it difficult to disentangle the effects of catastrophic forgetting (the focus of our work) from those of underfitting. This is especially relevant when dealing with complex datasets and deserves further investigation: for this reason, we conduct a single-epoch experiment on Seq. CIFAR-10 and Seq. Tiny ImageNet. We include in Tab. 5 the performance of different rehearsal methods; additionally, we report the results of joint training when limiting the number of epochs to one and, vice versa, when such limitation is removed (see last two columns). While the multi-epoch joint training learns to classify with a satisfactory accuracy, the single-epoch counterpart (which is the upper bound to all other methods in this experiment) yields a much lower accuracy and underfits dramatically. In light of this, it is hard to evaluate the merits of other CL methods, whose evaluation is severely undermined by this confounding factor. Although DER++ proves reliable even in this difficult setting, we feel that future CL works should strive for realism by designing experimental settings which are fully in line with the guidelines of GCL <ref type="bibr" target="#b10">[11]</ref> rather than adopting the single-epoch protocol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.4 Forward and Backward Transfer</head><p>In this section, we present additional results for the experiments presented in Sec. 4.2 and F.1, reporting Forward Transfer (FWT), Backward Transfer (BWT) <ref type="bibr" target="#b28">[28]</ref> and Forgetting (FRG) <ref type="bibr" target="#b6">[7]</ref>. The first one assesses whether a model is capable of improving on unseen tasks w.r.t. random guessing, whereas the second and third ones measure the performance degradation in subsequent tasks. Despite their popularity in recent CL works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b28">28]</ref>, we did not report them in the main paper because we believe that the average accuracy represents an already exhaustive measure of CL performance.</p><p>FWT is computed as the difference between the accuracy just before starting training on a given task and the one of the random-initialized network; it is averaged across all tasks. While one can argue that learning to classify unseen classes is desirable, the meaning of such a measure is highly dependent on the setting. Indeed, Class-IL and Task-IL show distinct classes in distinct tasks, which makes transfer impossible. On the contrary, FWT can be relevant for Domain-IL scenarios, provided that the input transformation is not disruptive (as it is the case with Permuted-MNIST). In conclusion, as CL settings sooner or later show all classes to the network, we are primarily interested in the accuracy at the end of the training, not the one before seeing any example.</p><p>FRG and BWT compute the difference between the current accuracy and its best value for each task. It is worth noting that any method that restrains the learning of the current task could exhibit high backward transfer but low final accuracy. This is as easy as increasing the weight of the regularization term: this way, the past knowledge is well-preserved but the current task is not learned properly. Moreover, BWT makes the assumption that the highest value of the accuracy on a task is the one yielded at the end of it. This is not always true, as rehearsal-based methods can exploit the memory buffer in a subsequent task, even enhancing their performance on a previous one if they start from low accuracy.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FORWARD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Hyperparameter Search</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1 Best values</head><p>In <ref type="table">Table 9</ref>, we show the best hyperparameter combination that we chose for each method for the experiments in the main paper, according to the criteria outlined in Section 4.1. We denote the learning rate with lr, the batch size with bs and the minibatch size (i.e. the size of the batches drawn from the buffer in rehearsal-based methods) with mbs, while other symbols refer to the respective methods. We hold batch size and minibatch size out of the hyperparameter search space for all Continual Learning benchmarks. Their values are fixed as follows: Sequential MNIST: 10; Sequential CIFAR-10, Sequential Tiny ImageNet: 32; Permuted MNIST, Rotated MNIST: 128.</p><p>Conversely, batch size and minibatch size belong to the hyperparameter search space for experiments on the novel MNIST-360 dataset. It must be noted that MER does not depend on batch size, as it internally always adopts a single-example forward pass.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Example batches of the MNIST-360 stream.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Training Times [ ? ] (S-CIFAR-10, buffer 500)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Results for the model analysis.[?] higher is better, [?] lower is better (best seen in color).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>) reports the execution time we measured on S-CIFAR10, indicating the time necessary for each of 5 tasks. We draw the following remarks: i) DER has a comparable running time w.r.t. other replay methods such as ER, FDR, and A-GEM; ii) the time complexity for GEM grows linearly w.r.t. the number of previously seen tasks; iii) GSS is extremely slow (0.73 examples per second on average, while DER++ processes 3.71 examples per second), making it hardly viable in practical scenarios.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>(</head><label></label><figDesc>d1,d2) r , we initialize two counters C d1 and C d2 to keep track of how many exemplars of d 1 and d 2 are shown respectively. Given batch size B (B = 16 in our experiments), each batch is made up of N d1 samples from G d1 [r/2] and N d2 samples from G d2 [r/2]+1 , where:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Performance vs. memory allocation for the experiments of Section 4 and F.1. Successive points of the same method indicate increasing buffer size. Methods with lower accuracy or excessive memory consumption may be omitted (best viewed in color).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Algorithm 3 -</head><label>3</label><figDesc>Reservoir Sampling Input: memory buffer M, number of seen examples N , example x, label y. if M &gt; N then M[N ] ? (x, y) else j = randomInteger (min = 0, max = N ) if j &lt; |M| then M[j] ? (x, y) end if end if return M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>:2004.07211v2 [stat.ML] 22 Oct 2020 Methods PNN PackNet HAT ER MER GSS GEM A-GEM HAL iCaRL FDR LwF SI oEWC DER DER++ [36] [29] [38] [32, 34] [34] [1] [28] [9] [8] [33] [4] [25] [43] [21] (ours) (ours)</figDesc><table><row><cell>Constant memory</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>No task boundaries</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>No test time oracle</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell></row></table><note>34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.arXiv</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>JOINT 92.20?0.15 98.31?0.12 59.99?0.19 82.04?0.10 94.33?0.17 95.76?0.04 SGD 19.62?0.05 61.02?3.33 7.92?0.26 18.31?0.68 40.70?2.33 67.66?8.53 oEWC [37] 19.49?0.12 68.29?3.92 7.58?0.10 19.20?0.31 75.79?2.25 77.35?5.77 -SI [43] 19.48?0.17 68.05?5.91 6.58?0.31 36.32?0.13 65.86?1.57 71.91?5.83 LwF [25] 19.61?0.05 63.29?2.35 8.46?0.22 15.85?0.58 79?1.86 91.19?0.94 8.49?0.16 38.17?2.00 72.37?0.87 85.01?1.90 GEM [28] 25.54?0.76 90.44?0.94 --66.93?1.25 80.80?1.15 A-GEM [9] 20.04?0.34 83.88?1.49 8.07?0.08 22.77?0.03 66.42?4.00 81.91?0.76 iCaRL [33] 49.02?3.20 88.99?2.13 7.53?0.79 28.19?1.47 --200 FDR [4] 30.91?2.74 91.01?0.68 8.70?0.19 40.36?0.68 74.77?0.83 85.22?3.35 93?1.79 91.40?0.92 11.87?0.78 40.22?0.67 81.74?1.07 90.04?2.61 DER++ (ours) 64.88?1.17 91.92?0.60 10.96?1.17 40.87?1.16 83.58?0.59 90.43?1.87 DER++ (ours) 72.70?1.36 93.88?0.50 19.38?1.41 51.91?0.68 88.21?0.39 92.77?1.05 70?0.07 94.32?0.97 28.97?0.41 68.01?0.42 90.87?0.16 94.19?0.44 81?0.33 95.43?0.33 36.73?0.64 69.50?0.26 91.66?0.11 94.14?0.31 DER++ (ours) 85.24?0.49 96.12?0.21 39.02?0.97 69.84?0.63 92.26?0.17 94.65?0.33</figDesc><table><row><cell>Buffer Method</cell><cell cols="2">S-CIFAR-10 Class-IL Task-IL</cell><cell cols="2">S-Tiny-ImageNet Class-IL Task-IL</cell><cell cols="2">P-MNIST R-MNIST Domain-IL Domain-IL</cell></row><row><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-</cell><cell>-</cell></row><row><cell>PNN [36]</cell><cell>-</cell><cell>95.13?0.72</cell><cell>-</cell><cell>67.84?0.29</cell><cell>-</cell><cell>-</cell></row><row><cell cols="3">ER [34] 44.GSS [1] 39.07?5.59 88.80?2.89</cell><cell>-</cell><cell>-</cell><cell cols="2">63.72?0.70 79.50?0.41</cell></row><row><cell>HAL [8]</cell><cell cols="2">32.36?2.70 82.51?3.20</cell><cell>-</cell><cell>-</cell><cell cols="2">74.15?1.65 84.02?0.98</cell></row><row><cell cols="3">DER (ours) 61.GSS [1] 67.27?4.27 94.19?1.15</cell><cell>-</cell><cell>-</cell><cell cols="2">82.22?1.14 85.24?0.59</cell></row><row><cell>HAL [8]</cell><cell cols="2">59.12?4.41 88.51?3.32</cell><cell>-</cell><cell>-</cell><cell cols="2">89.20?0.14 91.17?0.31</cell></row><row><cell>DER (ours)</cell><cell>83.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>ER [34] 57.74?0.27 93.61?0.27 9.99?0.29 48.64?0.46 80.60?0.86 88.91?1.44 GEM [28] 26.20?1.26 92.16?0.69 - - 76.88?0.52 81.15?1.98 A-GEM [9] 22.67?0.57 89.48?1.45 8.06?0.04 25.33?0.49 67.56?1.28 80.31?6.29 iCaRL [33] 47.55?3.95 88.22?2.62 9.38?1.53 31.55?3.27 - - 500 FDR [4] 28.71?3.23 93.29?0.59 10.54?0.21 49.88?0.71 83.18?0.53 89.67?1.63 GSS [1] 49.73?4.78 91.02?1.57 - - 76.00?0.87 81.58?0.58 HAL [8] 41.79?4.46 84.54?2.36 - - 80.13?0.49 85.00?0.96 DER (ours) 70.51?1.67 93.40?0.39 17.75?1.14 51.78?0.88 87.29?0.46 92.24?1.12ER [34] 82.47?0.52 96.98?0.17 27.40?0.31 67.29?0.23 89.90?0.13 93.45?0.56 GEM [28] 25.26?3.46 95.55?0.02 - - 87.42?0.95 88.57?0.40 A-GEM [9] 21.99?2.29 90.10?2.09 7.96?0.13 26.22?0.65 73.32?1.12 80.18?5.52 iCaRL [33] 55.07?1.55 92.23?0.84 14.08?1.92 40.83?3.11 - - 5120 FDR [4] 19.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Accuracy on the test set for MNIST-360.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>43?1.89 86.12?1.89 93.40?1.29 97.86?0.35 99.04?0.18 99.33?0.22 MER 81.47?1.56 88.35?0.41 94.57?0.18 98.05?0.25 98.43?0.11 99.27?0.09 GEM 80.11?1.54 85.99?1.35 95.11?0.87 97.78?0.25 98.71?0.20 99.44?0.12 A-GEM 45.72?4.26 46.66?5.85 54.24?6.49 98.61?0.24 98.93?0.21 98.93?0.20 iCaRL 70.51?0.53 70.10?1.08 70.60?1.03 98.28?0.09 98.32?0.07 98.32?0.11 FDR 79.43?3.26 85.87?4.04 87.47?3.15 97.66?0.18 97.54?1.90 97.79?1.33 GSS 38.90?2.49 49.76?4.73 89.39?0.75 95.02?1.85 97.71?0.53 98.33?0.17 HAL 84.70?0.87 87.21?0.49 89.52?0.96 97.96?0.21 98.03?0.22 98.35?0.17 DER (ours) 84.55?1.64 90.54?1.18 94.90?0.57 98.80?0.15 98.84?0.13 99.29?0.11 DER++ (ours) 85.61?1.40 91.00?1.49 95.30?1.20 98.76?0.28 98.94?0.27 99.47?0.07</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-IL</cell><cell></cell></row><row><cell>JOINT</cell><cell></cell><cell>95.57?0.24</cell><cell></cell><cell></cell><cell>99.51?0.07</cell><cell></cell></row><row><cell>SGD</cell><cell></cell><cell>19.60?0.04</cell><cell></cell><cell></cell><cell>94.94?2.18</cell><cell></cell></row><row><cell>oEWC</cell><cell></cell><cell>20.46?1.01</cell><cell></cell><cell></cell><cell>98.39?0.48</cell><cell></cell></row><row><cell>SI</cell><cell></cell><cell>19.27?0.30</cell><cell></cell><cell></cell><cell>96.00?2.04</cell><cell></cell></row><row><cell>LwF</cell><cell></cell><cell>19.62?0.01</cell><cell></cell><cell></cell><cell>94.11?3.01</cell><cell></cell></row><row><cell>PNN</cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>99.23?0.20</cell><cell></cell></row><row><cell>Buffer</cell><cell>200</cell><cell>500</cell><cell>5120</cell><cell>200</cell><cell>500</cell><cell>5120</cell></row><row><cell>ER</cell><cell>80.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Results for the Sequential-MNIST dataset.</figDesc><table /><note>F.2 Additional Comparisons with Experience Replay</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note>Single-epoch evaluation setting (Class-IL).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>09?0.11 ?1.46?1.17 0.32?0.85 48.94?0.10 oEWC ?7.44?4.18 ?0.13?8.12 ?12.51?0.02 ?4.09?7.97 0.69?0.97 52.45?8.75 -SI ?9.50?5.27 ?1.34?5.42 ?12.64?0.20 ?2.33?2.29 0.71?1.89 53.09?0.73 LwF ?12.39?4.06 1.30?5.40 ?10.63?5.12 0.73?4.36 12?2.21 ?0.86?3.24 ?11.02?2.77 2.10?1.27 1.37?0.48 66.79?0.05 26?3.08 ?0.16?5.89 ?7.50?7.05 0.13?3.54 0.42?0.35 54.06?4.35 A-GEM ?10.04?3.11 2.39?6.96 ?11.37?0.08 ?0.34?0.13 0.83?0.57 54.84?10.45 06?2.22 ?0.81?3.89 ?12.75?0.30 ?2.42?0.86 ?1.24?0.06 60.71?8.17 GSS ?11.31?2.58 2.99?6.61 ?7.08?10.01 6.17?2.06 0.04?0.85 57.28?4.47 HAL ?11.15?3.56 ?0.20?3.99 ?11.94?0.80 ?0.02?0.10 1.72?0.08 59.95?3.71 DER (ours) ?10.16?3.78 3.23?5.24 ?11.89?0.88 0.27?7.12 1.23?0.26 64.69?2.02 DER++ (ours) ?12.42?1.84 ?2.33?5.69 ?4.88?6.90 2.68?0.11 0.91?0.45 67.21?2.13 73?5.08 ?6.23?8.79 3.71?2.70 ?0.32?0.43 65.97?1.02 GSS ?10.16?3.48 0.17?5.32 ?7.84?4.43 2.11?3.31 0.89?0.94 58.19?4.42 HAL ?9.02?5.06 0.79?7.26 ?7.15?7.57 3.06?1.03 1.33?0.23 64.21?3.16 DER (ours) ?7.96?2.57 1.17?6.37 ?13.26?1.08 ?4.52?2.39 0.21?1.21 72.45?0.14 DER++ (ours) ?10.90?4.88 ?2.92?5.32 ?6.29?8.89 ?0.31?1.86 ?0.35?0.01 67.05?0.11 ER ?10.97?3.70 0.17?3.46 ?8.45?10.75 ?1.05?5.87 1.46?1.15 73.03?1.59 51?3.83 ?0.28?9.16 ?9.18?4.27 ?1.24?0.83 1.03?0.89 62.06?3.01 A-GEM ?11.31?3.44 1.14?7.08 ?8.01?6.31 ?3.94?0.82 0.43?0.39 51.05?1.34 25?4.65 ?1.30?5.90 ?7.69?5.95 ?0.52?0.54 ?0.13?0.54 72.54?0.35 GSS ?10.89?3.52 ?2.19?6.64 ?9.88?2.21 ?0.13?5.24 0.34?1.49 63.39?4.55 HAL ?10.06?4.46 0.16?7.43 ?10.34?3.22 0.32?1.09 0.52?0.47 66.00?0.09 DER (ours) ?11.59?4.34 ?2.42?5.22 ?5.98?8.44 2.37?3.98 0.32?0.18 71.12?0.53 DER++ (ours) ?10.71?2.95 0.20?9.44 ?11.23?2.67 4.56?0.02 0.06?0.22 72.11?1.81</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>TRANSFER</cell><cell></cell></row><row><cell cols="2">Buffer Method</cell><cell cols="3">S-MNIST Class-IL Task-IL</cell><cell cols="3">S-CIFAR-10 Class-IL Task-IL Domain-IL Domain-IL P-MNIST R-MNIST</cell></row><row><cell>-</cell><cell>SGD</cell><cell cols="3">?11.06?2.90 2.33?4.71</cell><cell cols="3">?9.-</cell><cell>-</cell></row><row><cell></cell><cell>PNN</cell><cell></cell><cell>-</cell><cell>N/A</cell><cell>-</cell><cell>N/A</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell cols="4">ER ?12.MER ?11.03?3.40 ?2.18?3.51</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="5">GEM iCaRL ?10.200 N/A FDR ?12.ER ?10.42?3.42 1.02?5.55 N/A</cell><cell cols="3">N/A ?8.42?4.83 ?3.12?4.02 0.56?2.52 65.52?1.56 N/A --</cell></row><row><cell></cell><cell>MER</cell><cell cols="3">?10.59?3.83 0.89?5.03</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>GEM</cell><cell cols="6">?10.59?3.26 0.11?5.66 ?12.53?0.65 1.36?3.05 0.17?0.59 54.19?2.37</cell></row><row><cell></cell><cell>A-GEM</cell><cell cols="2">?9.74?3.60</cell><cell>1.10?7.30</cell><cell cols="3">?6.38?8.64 6.36?3.88 0.03?1.20 52.50?0.51</cell></row><row><cell>500</cell><cell cols="4">iCaRL FDR 4.MER N/A ?9.27?2.80 ?10.50?3.35 ?0.33?5.81 N/A</cell><cell>N/A -</cell><cell>N/A -</cell><cell>--</cell><cell>--</cell></row><row><cell cols="3">GEM iCaRL ?9.5120 FDR ?9.</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>-</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Forward Transfer results for the Experiments of Sec. 4.2 and F.1. 10?0.55 ?4.98?2.58 ?96.39?0.12 ?46.24?2.12 ?57.65?4.32 ?20.34?2.50 oEWC ?97.79?1.24 ?0.38?0.19 ?91.64?3.07 ?29.13?4.11 ?36.69?2.34 ?24.59?5.37 -SI ?98.89?0.86 ?3.46?1.69 ?95.78?0.64 ?38.76?0.89 ?27.91?0.31 ?22.91?0.26 LwF ?99.30?0.11 ?6.21?3.67 ?96.69?0.25 ?32.56?0.56 32?2.04 ?1.14?0.48 ?82.61?1.60 ?9.27?2.07 ?29.38?2.56 ?11.51?4.75 A-GEM ?66.15?6.84 ?0.06?2.95 ?95.73?0.20 ?16.39?0.86 ?31.69?3.92 ?19.32?1.17 15?4.18 ?0.50?0.19 ?86.40?2.67 ?7.36?0.03 ?20.62?0.65 ?13.31?2.60 GSS ?74.10?3.03 ?4.29?2.31 ?75.25?4.07 ?8.56?1.78 ?47.85?1.82 ?20.19?6.45 HAL ?14.54?1.49 ?0.48?0.20 ?69.11?4.21 ?11.91?0.52 ?15.24?1.33 ?11.71?0.26 DER (ours) ?17.66?2.10 ?0.56?0.18 ?40.76?0.42 ?6.21?0.71 ?13.79?0.80 ?5.99?0.46 DER++ (ours) ?16.27?1.73 ?0.55?0.37 ?32.59?2.32 ?5.16?0.21 ?11.47?0.33 ?5.27?0.26 ER ?15.97?2.46 ?0.36?0.20 ?45.35?0.07 ?3.54?0.35 ?14.90?0.39 ?7.52?1.44 47?2.03 ?0.27?0.98 ?74.31?4.62 ?9.12?0.21 ?18.76?0.91 ?7.19?1.40 A-GEM ?65.84?7.24 ?0.54?0.20 ?94.01?1.16 ?14.26?4.18 ?28.53?2.01 ?19.36?3.18 500 iCaRL ?11.84?0.73 ?0.25?0.09 ?25.71?1.10 ?1.06?4.21 --FDR ?13.90?5.19 ?1.27?2.43 ?85.62?0.36 ?4.80?0.30 ?12.80?1.28 ?6.70?1.93 GSS ?60.35?6.03 ?0.77?0.62 ?62.88?2.67 ?7.73?3.99 ?23.68?1.35 ?17.45?9.92 HAL ?9.97?1.62 ?0.30?0.26 ?62.21?4.34 ?5.41?1.10 ?11.58?0.49 ?6.78?0.87 DER (ours) ?9.58?1.52 ?0.39?0.18 ?26.74?0.15 ?4.56?0.45 ?8.04?0.42 ?3.41?2.18 DER++ (ours) ?8.85?1.86 ?0.34?0.16 ?22.38?4.41 ?4.66?1.15 ?7.62?1.02 ?3.18?0.14 ER ?6.07?1.84 0.03?0.36 ?13.99?1.12 0.08?0.06 ?5.24?0.13 ?2.55?0.53 MER ?3.22?0.33 0.05?0.11 16?0.85 ?75.27?4.41 ?6.91?2.33 ?6.74?0.49 ?0.06?0.29 A-GEM ?55.04?10.93 0.78?4.16 ?84.49?3.08 ?9.89?0.40 ?23.73?2.22 ?17.70?1.28 5120 iCaRL ?11.64?0.72 ?0.22?0.08 ?24.94?0.14 ?0.99?1.41 --FDR ?11.58?3.97 ?0.87?1.66 ?96.64?0.19 ?1.89?0.51 ?3.81?0.13 ?2.81?0.47 GSS ?7.90?1.21 ?0.09?0.15 ?58.11?9.12 ?6.38?1.71 ?19.82?1.31 ?17.05?2.31 HAL ?6.55?1.63 0.02?0.20 ?27.19?7.53 ?4.51?0.54 ?4.27?0.22 ?2.25?0.01 DER (ours) ?4.53?0.83 ?0.31?0.08 ?10.12?0.80 ?2.59?0.08 ?3.49?0.02 ?1.73?0.10 DER++ (ours) ?4.19?1.63 ?0.13?0.09 ?6.89?0.50 ?1.16?0.22 ?2.93?0.15 ?1.18?0.53</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">BACKWARD TRANSFER</cell><cell></cell></row><row><cell cols="2">Buffer Method</cell><cell cols="2">S-MNIST Class-IL Task-IL</cell><cell cols="2">S-CIFAR-10 Class-IL Task-IL</cell><cell>P-MNIST Domain-IL</cell><cell>R-MNIST Domain-IL</cell></row><row><cell>-</cell><cell>SGD</cell><cell cols="5">?99.-</cell><cell>-</cell></row><row><cell></cell><cell>PNN</cell><cell>-</cell><cell>0.00?0.00</cell><cell>-</cell><cell>0.00?0.00</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>ER</cell><cell cols="6">?21.36?2.46 ?0.82?0.41 ?61.24?2.62 ?7.08?0.64 ?22.54?0.95 ?8.24?1.56</cell></row><row><cell></cell><cell>MER</cell><cell cols="2">?20.38?1.97 ?0.81?0.20</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="6">GEM iCaRL ?22.200 ?11.73?0.73 ?0.23?0.06 ?28.72?0.49 ?1.01?4.15 FDR ?21.MER ?11.52?0.56 ?0.44?0.17 --</cell><cell>--</cell><cell>--</cell></row><row><cell></cell><cell>GEM</cell><cell cols="3">?15.-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>GEM</cell><cell>?4.14?1.43</cell><cell>0.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Backward Transfer results for the Experiments of Sec. 4.2 and F.1. IL Domain-IL Domain-IL -SGD 99.10?0.55 5.15?2.74 96.39?0.12 46.24?2.12 57.65?4.32 20.82?2.47 oEWC 97.79?1.24 0.44?0.16 91.64?3.07 29.33?3.84 36.69?2.34 36.44?1.44 -SI 98.89?0.86 5.15?2.74 95.78?0.64 38.76?0.89 27.91?0.31 23.41?0.49 LwF 99.30?0.11 5.15?2.74 96.69?0.25 32.56?0.56 36?2.46 0.84?0.41 61.24?2.62 7.08?0.64 22.54?0.95 8.87?1.44 MER 20.38?1.97 0.82?0.21 ----GEM 22.32?2.04 1.19?0.38 82.61?1.60 9.27?2.07 29.38?2.56 12.97?4.82 A-GEM 66.15?6.84 0.96?0.28 95.73?0.20 16.39?0.86 31.69?3.92 20.05?1.12 200 iCaRL 11.73?0.73 0.28?0.08 28.72?0.49 2.63?3.48 --FDR 21.15?4.18 0.52?0.18 86.40?2.67 7.36?0.03 20.62?0.65 13.66?2.52 GSS 74.10?3.03 4.30?2.31 75.25?4.07 8.56?1.78 47.85?1.82 20.71?6.50 HAL 14.54?1.49 0.53?0.19 69.11?4.21 12.26?0.02 79.00?1.17 83.59?0.04 DER (ours) 17.66?2.10 0.57?0.18 40.76?0.42 6.57?0.20 14.00?0.73 6.53?0.32 DER++ (ours) 16.27?1.73 0.66?0.28 32.59?2.32 5.16?0.21 11.49?0.31 6.08?0.43 ER 15.97?2.46 0.39?0.20 45.35?0.07 3.54?0.35 14.90?0.39 8.02?1.56 57?1.77 0.54?0.15 74.31?4.62 9.12?0.21 18.76?0.91 8.79?1.44 A-GEM 65.84?7.24 0.64?0.20 94.01?1.16 14.26?4.18 28.53?2.01 19.70?3.14 500 iCaRL 11.84?0.73 0.30?0.09 25.71?1.10 2.66?2.47 --FDR 13.90?5.19 1.35?2.40 85.62?0.36 4.80?0.00 12.80?1.28 7.21?1.89 GSS 60.35?6.03 0.89?0.40 62.88?2.67 7.73?3.99 23.68?1.35 18.05?9.89 HAL 9.97?1.62 0.35?0.21 62.21?4.34 5.41?1.10 82.53?0.36 88.53?0.77 DER (ours) 9.58?1.52 0.45?0.13 26.74?0.15 4.56?0.45 8.07?0.43 3.96?2.08 DER++ (ours) 8.85?1.86 0.35?0.15 22.38?4.41 4.66?1.15 7.67?1.05 3.57?0.09 ER 6.08?1.84 0.25?0.23 13.99?1.12 0.27?0.06 5.24?0.13 3.10?0.42 30?1.16 0.16?0.09 75.27?4.41 6.91?2.33 6.74?0.49 2.49?0.17 A-GEM 55.10?10.79 0.63?0.21 84.49?3.08 11.36?1.68 23.74?2.23 18.10?1.44 5120 iCaRL 11.64?0.72 0.26?0.06 24.94?0.14 1.59?0.57 --FDR 11.58?3.97 0.95?1.61 96.64?0.19 1.93?0.48 3.82?0.12 3.31?0.56 GSS 7.90?1.21 0.18?0.11 58.11?9.12 7.71?2.31 89.76?0.39 92.66?0.02 HAL 6.55?1.63 0.13?0.07 27.19?7.53 5.21?0.50 19.97?1.33 17.62?2.33 DER (ours) 4.53?0.83 0.32?0.08 10.12?0.80 2.59?0.08 3.51?0.03 2.17?0.11 DER++ (ours) 4.19?1.63 0.23?0.06 7.27?0.84 1.18?0.19 2.96?0.14 1.62?0.50</figDesc><table><row><cell></cell><cell></cell><cell cols="2">FORGETTING</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Buffer Method</cell><cell cols="2">S-MNIST Class-IL Task-IL</cell><cell cols="4">S-CIFAR-10 Class-IL Task--P-MNIST R-MNIST -</cell></row><row><cell>PNN</cell><cell>-</cell><cell>0.00?0.00</cell><cell>-</cell><cell>0.00?0.00</cell><cell>-</cell><cell>-</cell></row><row><cell cols="3">ER 21.MER 11.52?0.56 0.45?0.17</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="3">GEM 15.MER 3.22?0.33 0.07?0.06</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>GEM</cell><cell>4.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Forgetting results for the Experiments of Sec. 4.2 and F.1.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The model is not overly sensitive to ? and ?: setting them both to 0.5 yields stable performance.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In Class-IL, we adopted a multi-class implementation as done in<ref type="bibr" target="#b33">[33]</ref>.<ref type="bibr" target="#b2">3</ref> We omit MER as we experienced an intractable training time on these benchmarks (e.g. while DER takes approximately 2.5 hours on Seq. CIFAR-10, MER takes 300 hours -see Sec. 5 for further comparisons).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments and Disclosure of Funding</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.2 All values</head><p>In the following, we provide a list of all the parameter combinations that were considered (  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Gradient based sample selection for online continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahaf</forename><surname>Aljundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baptiste</forename><surname>Goujaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning with pseudo-ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ouais</forename><surname>Alsharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Self-organizing neural network that discovers surfaces in randomdot stereograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanna</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">355</biblScope>
			<biblScope unit="issue">6356</biblScope>
			<biblScope unit="page" from="161" to="163" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Measuring and regularizing networks in function space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><forename type="middle">S</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rolnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><forename type="middle">P</forename><surname>Kording</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reliability, sufficiency, and the decomposition of proper scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jochen</forename><surname>Br?cker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of the Royal Meteorological Society</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Entropy-sgd: Biasing gradient descent into wide valleys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Choromanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Baldassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Borgs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Chayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levent</forename><surname>Sagun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Zecchina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Riemannian walk for incremental learning: Understanding forgetting and intransigence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslan</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Puneet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thalaiyasingam</forename><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Using hindsight to anchor past knowledge in continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslan</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Puneet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08165</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient lifelong learning with a-gem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslan</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elhoseiny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslan</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thalaiyasingam</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Puneet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ranzato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.10486</idno>
		<title level="m">On tiny episodic memories in continual learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A continual learning survey: Defying forgetting in classification tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahaf</forename><surname>Aljundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Masana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Parisot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ales</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Slabaugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.08383</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.09733</idno>
		<title level="m">Towards robust evaluations of continual learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Probabilistic forecasts, calibration and sharpness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tilmann</forename><surname>Gneiting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fadoua</forename><surname>Balabdaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. JMLR. org</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Dark knowledge. Presented as the keynote in BayLearn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Re-evaluating continual learning scenarios: A categorization and case for strong baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chang</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anita</forename><surname>Ramasamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Continual learning Workshop</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Three factors influencing minima in sgd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanis?aw</forename><surname>Jastrz?bski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Kenton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devansh</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asja</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Newtorks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On large-batch training for deep learning: Generalization gap and sharp minima</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheevatsa</forename><surname>Nitish Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Mudigere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping Tak Peter</forename><surname>Smelyanskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kieran</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">13</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meelis</forename><surname>Kull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miquel</forename><forename type="middle">Perello</forename><surname>Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>K?ngsepp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Telmo</forename><surname>Silva Filho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Flach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Hoiem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generalized zero-shot learning with deep calibration network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shichen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Improving the interpretability of deep neural networks with knowledge distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Data Mining Workshops (ICDMW)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Gradient episodic memory for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Packnet: Adding multiple tasks to a single network by iterative pruning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Mallya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Catastrophic interference in connectionist networks: The sequential learning problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Psychology of learning and motivation</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1989" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="109" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Obtaining well calibrated probabilities using bayesian binning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Mahdi Pakdaman Naeini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milos</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hauskrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Ninth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Connectionist models of recognition memory: constraints imposed by learning and forgetting functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">285</biblScope>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">icarl: Incremental classifier and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Sylvestre-Alvise Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Sperl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to learn without forgetting by maximizing transfer and minimizing interference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Riemer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Cases</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ajemian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Rish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhai</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting, rehearsal and pseudorehearsal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Robins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="146" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Andrei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04671</idno>
		<title level="m">Razvan Pascanu, and Raia Hadsell. Progressive neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Progress &amp; compress: A scalable framework for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jelena</forename><surname>Luketina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting with hard attention to the task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Serra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Didac</forename><surname>Suris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Miron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. PMLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stanford</surname></persName>
		</author>
		<ptr target="http://tiny-imagenet.herokuapp.com/" />
	</analytic>
	<monogr>
		<title level="j">Tiny ImageNet Challenge</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Three continual learning scenarios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">S</forename><surname>Gido M Van De Ven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tolias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS Continual Learning Workshop</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Random sampling with a reservoir</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software (TOMS)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="57" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Large scale incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuancheng</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Continual learning through synaptic intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Friedemann</forename><surname>Zenke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Be your own teacher: Improve the performance of convolutional neural networks via self distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anni</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglong</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep mutual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huchuan</forename><surname>Lu</surname></persName>
		</author>
		<idno>MER 200 lr: 0.1 ?: 1 ?: 1 nb: 1 bs: 1 500 lr: 0.1 ?: 1 ?: 1 nb: 1 bs: 1 5120 lr: 0.03 ?: 1 ?: 1 nb: 1 bs: 1 GEM 200 lr: 0.01 ?: 1.0 200 lr: 0.03 ?: 0.5 500 lr: 0.03 ?: 0.5 500 lr: 0.03 ?: 0.5 5120 lr: 0.1 ?: 1.0 5120 lr: 0.03 ?: 0.5</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<idno>MNIST-360 FDR 200 lr: 0.03 ?: 0.3 500 lr: 0.03 ?: 1.0 5120 lr: 0.03 ?: 0.3 GSS 200 lr: 0.2 bs: 1 mbs: 16 500 lr: 0.2 bs: 1 mbs: 16 1000 lr: 0.2 bs: 4 mbs: 16 DER 200 lr: 0.03 ?: 0.1 200 lr: 0.1 bs: 16 mbs: 64 ?: 0.5 500 lr: 0.03 ?: 0.1 500 lr: 0.2 bs: 16 mbs: 16 ?: 0.5 5120 lr: 0.03 ?: 0.1 1000 lr: 0.1 bs: 8 mbs: 16 ?: 0.5 DER++ 200 lr: 0.03 ?: 0.1 ?: 1.0 200 lr: 0.2 bs: 16 mbs: 16 ?: 0.5 ?: 1.0 500 lr: 0.03 ?: 0.2 ?: 0.5 500 lr: 0.2 bs: 16 mbs: 16 ?: 0.5 ?: 1.0 5120 lr: 0.03 ?: 0.1 ?: 0.5 1000 lr: 0.2 bs: 16 mbs: 128 ?: 0.2 ?: 1.0</idno>
		<title level="m">Method Buffer Sequential Tiny Imagenet Buffer</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
