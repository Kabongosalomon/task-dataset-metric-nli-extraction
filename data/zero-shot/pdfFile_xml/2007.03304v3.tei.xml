<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to Generate Novel Domains for Domain Generalization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
							<email>k.zhou@surrey.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Surrey</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
							<email>yongxin.yang@surrey.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
							<email>t.hospedales@ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Surrey</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Samsung AI Center</orgName>
								<address>
									<settlement>Cambridge</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
							<email>t.xiang@surrey.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Surrey</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Samsung AI Center</orgName>
								<address>
									<settlement>Cambridge</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to Generate Novel Domains for Domain Generalization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper focuses on domain generalization (DG), the task of learning from multiple source domains a model that generalizes well to unseen domains. A main challenge for DG is that the available source domains often exhibit limited diversity, hampering the model's ability to learn to generalize. We therefore employ a data generator to synthesize data from pseudo-novel domains to augment the source domains. This explicitly increases the diversity of available training domains and leads to a more generalizable model. To train the generator, we model the distribution divergence between source and synthesized pseudo-novel domains using optimal transport, and maximize the divergence. To ensure that semantics are preserved in the synthesized data, we further impose cycle-consistency and classification losses on the generator. Our method, L2A-OT (Learning to Augment by Optimal Transport) outperforms current state-of-the-art DG methods on four benchmark datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Humans effortlessly generalize prior knowledge to novel scenarios, a capability that machines still struggle to reproduce. Typically, machine-learning models perform poorly when deployed on test data with a different data distribution than the training data, which is known as the domain shift problem <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b34">35]</ref>. One line of research towards alleviating the domain shift problem is unsupervised domain adaptation (UDA), which exploits unlabeled target domain data for model adaptation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b43">44]</ref>. Although UDA methods avoid costly data annotation processes from target domains, data collection and per-domain model updates are still required. Meanwhile, UDA's assumption that target data can be collected in advance is not always met in practice <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b9">10]</ref>. This motivates another line of research, namely domain generalization (DG) <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10]</ref>, which is the main focus in this paper.</p><p>DG methods aim to learn models capable of good direct generalization to unseen target domains without data collection or model updating <ref type="bibr" target="#b36">[37]</ref>. They usually, but not always <ref type="bibr" target="#b51">[52]</ref>, leverage multiple source domains to train a generalizable model. Most existing DG methods focus on aligning available source domains <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b27">28]</ref>, which is mainly inspired by UDA methods that seek to  <ref type="figure">Fig. 1</ref>. Motivation of our approach. We improve generalization by increasing the diversity of training domains by learning a generator network G to map images of a source distribution, e.g., PMNIST, to a novel distribution, i.e. G(PMNIST). We then combine both source and novel domains for model learning.</p><p>minimize the divergence between source data and unlabeled target data <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b49">50]</ref>. As proved in <ref type="bibr" target="#b3">[4]</ref>, minimizing the domain divergence can lead to a smaller target error in the UDA setting. However, since DG methods focus on aligning source domains and do not have access to the target data, this theoretical proof does not apply to the DG setting. Recently, meta-learning has been exploited for DG where the key idea is to simulate domain shift by splitting the training data into meta-train and meta-test sets with non-overlapping domains <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b9">10]</ref>. During learning, models are optimized on the meta-train domains in a way that the error is reduced on the meta-test domains. Nevertheless, similar to the alignment-based methods, meta-learning optimizes for reducing the domain gap among source domains, and thus still has the risk of overfitting to seen domains.</p><p>In this paper, we address DG from a different perspective, i.e., the most straightforward way to improve model generalization is increasing the diversity of available source domains <ref type="bibr" target="#b48">[49]</ref> (see <ref type="figure">Fig. 1</ref>). To this end, we propose L2A-OT (Learning to Augment by Optimal Transport). The core idea is to learn a conditional generator network that maps source domain images to pseudo-novel domains, and then combine both source and pseudo-novel domain images for training the actual task model. To train the generator, we maximize the distance between source domains and the generated pseudo-novel domains, as measured by optimal transport (OT) <ref type="bibr" target="#b40">[41]</ref>. This leads to the generated images having a very different distribution from the source domains ( <ref type="figure">Fig. 1</ref>). However, this objective alone does not guarantee that the semantic content of the generated images is preserved. Therefore, we further impose two losses on the generator, namely a cycle-consistency loss <ref type="bibr" target="#b64">[65]</ref> and a classification loss, for maintaining the structural and semantic consistency respectively.</p><p>Our contributions are as follows.</p><p>(1) For the first time, DG is tackled from a perspective of pseudo-novel domain synthesis. (2) A novel image generator is formulated which differs from existing generators in the objective (synthesizing pseudo-novel domain images vs. natural photo images). More importantly it has a unique OT-based formulation of objective functions that allow the generator to explore novel domain space and generate diverse data with distributions different from any of the original source domains. We evaluate L2A-OT on three homogeneous DG benchmark datasets 4 including digit recognition <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b37">38]</ref>, PACS <ref type="bibr" target="#b24">[25]</ref> and Office-Home [51] and a heterogeneous DG task in the form of cross-domain person re-identification (re-ID) <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b21">22]</ref>. The results show that L2A-OT surpasses the current state-of-the-art on all datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Domain generalization. Many DG methods are based on the idea of domain alignment popularized from the UDA literature <ref type="bibr" target="#b11">[12]</ref>, with a goal to learn a domain-invariant representation by minimizing the domain discrepancy between sources <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b27">28]</ref>. As mentioned earlier, aligning domain distributions is mainly motivated by the theory <ref type="bibr" target="#b3">[4]</ref> developed for UDA, which does not apply to DG due to the absence of target data. Therefore, the models learned with domain alignment risk overfitting to source domains and as a result generalize poorly to unseen domains. In recent years, meta-learning <ref type="bibr" target="#b20">[21]</ref> has seen increasing interest for DG where the objective is to expose a model to domain shift during training. This can be achieved by dividing source domains into meta-train and meta-test sets without overlapping, and training a model on the meta-train set such that the error on the meta-test set is reduced <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b9">10]</ref>. Similar to domain alignment methods, meta-learning methods still risk overfitting since the training data remains unchanged. Moreover, these methods work at feature-level, which is difficult for diagnosis and lacks visual interpretation. We refer readers to <ref type="bibr" target="#b59">[60]</ref> for a comprehensive DG survey.</p><p>Most related to our work are data augmentation methods, especially those based on adversarial gradients <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b51">52]</ref>. For instance, <ref type="bibr" target="#b46">[47]</ref> proposed CrossGrad to perturb input images with adversarial gradients generated by a domain classifier. Different from adversarial gradient-based methods which only produce imperceptible and simple pixel-wise effects (due to the nature of adversarial attack <ref type="bibr" target="#b47">[48]</ref>), our approach learns a full CNN generator to map source images to unseen domains and optimizes it via OT -based distribution divergence to make the new domains as dissimilar as possible to source distributions.</p><p>Domain randomization. Our approach shares a similar high-level intuition with domain randomization (DR) <ref type="bibr" target="#b48">[49]</ref>, which was originally introduced in the</p><formula xml:id="formula_0">G X a 0 X b 0 ! ! G ! ! max G d(X a 0 , X a ) X a ! ! X b ! ! max G d(X b 0 , X b ) ! ! max G d(X a 0 , X b 0 ) G X a 0 ! ! G ! ! X b 0 G ! ! G ! ! ! ! X a 0 ! ! X b 0 a, b: source domain labels a 0 , b 0 : novel domain labels (a) (b) (c) X ? X b min G ||X a X a || 1 min G ||X b X b || 1 min G L CE (? (X a 0 ), Y ? (X a )) min G L CE (? (X b 0 ), Y ? (X b )) Y (X a 0 ) Y (X b 0 ) [X a , a 0 ] [X b , b 0 ] [X a , a 0 ] [X b , b 0 ] [X a 0 , a] [X b 0 , b] Fig. 2.</formula><p>Overview of our approach. (a) The conditional generator network G is learned to map input X to novel domains whose distributions are drastically different from the source domains, while keeping the distance between the novel domains as far as possible.</p><p>(b) A cycle-consistency loss is imposed on G to maintain the structural consistency.</p><p>(c) The cross-entropy loss is minimized with respect to G, using a pre-trained classifier Y , for maintaining the semantic consistency.</p><p>context of robotic learning to improve generalization from simulation to real world. DR aims to diversify the training domains by changing the color and texture of objects, background scenes, lighting conditions, etc. via a computer simulator <ref type="bibr" target="#b48">[49]</ref>. Recently, DR has been successfully used in some computer vision applications, such as semantic segmentation <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref> and vehicle detection for autonomous driving <ref type="bibr" target="#b41">[42]</ref>. However, our approach is significantly different from the DR-based methods because we learn a CNN generator network from real images rather than using programmatic simulators. Thus our method is more scalable to a wider range of image recognition tasks.</p><p>Image-to-image translation. Our work is also related to multi-domain imageto-image translation methods such as CycleGAN <ref type="bibr" target="#b64">[65]</ref> and StarGAN <ref type="bibr" target="#b5">[6]</ref>, which use GAN losses <ref type="bibr" target="#b16">[17]</ref> to generate realistic images and cycle-consistency losses <ref type="bibr" target="#b64">[65]</ref> to achieve translation without using paired training images. Our method is fundamentally different from CycleGAN/StarGAN in that our generator model is learned to map source images to unseen domains rather than performing mapping between source domains as did in CycleGAN/StarGAN. We show by experiments that simply doing source-to-source mapping for data augmentation offers little help to DG (see <ref type="figure" target="#fig_2">Fig. 5a</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generating Novel-Domain Data</head><p>Setup. We are provided with K s source domains with indices D s = {1, 2, ..., K s }.</p><p>The goal is to learn a model which can generalize well on an unseen target domain. Without having access to the target data, we propose to improve the model's generalization by synthesizing novel data domains D n = {1, 2, ..., K n } to augment the original source domains.</p><p>Conditional generator. We learn a conditional generator G (see Sec. 3.4 for detailed architecture design), that maps a source distribution P k with k ? D s to a novel distribution Pk withk ? D n by conditioning on the novel domain labelk, i.e. Pk = G(P k ,k). Here P denotes an empirical distribution rather than the real distribution, which is inaccessible. In practice, we use sampled mini-batches X k instead of the full empirical distribution P k . Therefore, the domain translation function is defined as:</p><formula xml:id="formula_1">Xk = G(X k ,k).<label>(1)</label></formula><p>Objective functions. For each training iteration, we randomly sample for each source domain k a mini-batch X k , which is transformed to a randomly selected novel domaink ? D n . The objective is to force the novel distribution to be as dissimilar as possible to any source distribution, thus creating new domains to augment the existing source domains. We have</p><formula xml:id="formula_2">max G L Novel = d(G(X k ,k), X k ),<label>(2)</label></formula><p>where d(?, ?) is a distribution divergence measure (its design will be detailed in Sec. 3.5). Note that Eq.</p><p>(2) will be summed over all source domains k, and each independently draws a novel domain labelk. In addition to maximizing the difference between source and novel distributions, we also maximize the difference between the generated novel distributions, i.e. max</p><formula xml:id="formula_3">G L Diversity = d(Xk 1 , Xk 2 ),<label>(3)</label></formula><p>wherek 1 ,k 2 ? D n andk 1 =k 2 . Eq. <ref type="formula" target="#formula_3">(3)</ref> is summed over all possible pairs of novel distributions generated in one iteration. This diversity constraint diversifies the generated distributions, ensuring that the model benefits from generating K n &gt; 1 novel distributions. It is analogous to the diversity term in some image generation tasks, such as style transfer <ref type="bibr" target="#b29">[30]</ref> where the pixel/feature difference between style-transferred instances is maximized. Differently, our formulation focuses on the divergence between data distributions. See <ref type="figure">Fig. 2a</ref> for a graphical illustration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Maintaining Semantic Consistency</head><p>The model so far is optimizing a powerful CNN generator G for the novelty of the generated distribution (Eq. (2) &amp; <ref type="formula" target="#formula_3">(3)</ref>). This produces diverse images, but may not preserve their semantic content.</p><p>Cycle-consistency loss. First, to guarantee structural consistency, we apply a cycle-consistency constraint <ref type="bibr" target="#b64">[65]</ref> to the generator,</p><formula xml:id="formula_4">min G L Cycle = ||G(G(X k ,k), k) ? X k || 1 ,<label>(4)</label></formula><p>where the outer G aims to reconstruct the original X k given as input the domaintranslated G(X k ,k) and the original domain label k. Both G's in the cycle share the same parameters <ref type="bibr" target="#b5">[6]</ref>. This is illustrated in <ref type="figure">Fig. 2b</ref>.</p><formula xml:id="formula_5">Algorithm 1 Full training algorithm. 1: Require: Source domain Ds = {1, 2, ..., Ks}, novel domain Dn = {1, 2, ..., Kn}, task model F , generator G, max iteration T , pre-trained classifier? . 2: for t = 1 to T do 3:</formula><p>Sample a mini-batch X k from each source domain k ? Ds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Generate Xk = G(X k ,k) withk ? Dn for each source k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Compute LG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Perform one step gradient update for G using ?GLG. 7:</p><p>Compute LF . 8:</p><p>Perform one step gradient update for F using ?F LF . 9: end for Cross-entropy loss. Second, to maintain the category label and thus enforce semantic consistency, we further require that the generated data Xk is classified into the same category as the original data X k , i.e.</p><formula xml:id="formula_6">min G L CE (? (Xk), Y * (X k )),<label>(5)</label></formula><p>where L CE denotes cross-entropy loss,? (Xk) the labels of Xk predicted by a pretrained classifier and Y * (X k ) the ground-truth labels of X k . This is illustrated in <ref type="figure">Fig. 2c</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>Generator training. The full objective for G is the weighted combination of Eq. (2), (3), (4), &amp; (5),</p><formula xml:id="formula_7">min G L G = ? ? Domain (L Novel + L Diversity ) + ? Cycle L Cycle + ? CE L CE ,<label>(6)</label></formula><p>where ? Domain , ? Cycle and ? CE are weighting hyper-parameters.</p><p>Task model training. The task model F is trained from scratch using both the original data X k and the synthetic data Xk generated as described above.</p><p>The objective for F is</p><formula xml:id="formula_8">min F L F = (1 ? ?)L CE + ?L CE ,<label>(7)</label></formula><p>where ? is a balancing weight, which is fixed to 0.5 throughout this paper; L CE andL CE are the cross-entropy losses computed using X k and Xk respectively. The full training algorithm is shown in Alg. 1. Note that each source domain k ? D s will be assigned a unique novel domaink ? D n as target in each iteration. We set K n = K s as default.</p><formula xml:id="formula_9">+ ! ! Source-domain image Novel-domain image + ! ! Novel-domain image Source-domain image [1, 0, 0 | {z } Source , 0, 0, 0 | {z } Novel ] [0, 0, 0 | {z } Source , 1, 0, 0 | {z } Novel ]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Forward cycle</head><p>Backward cycle <ref type="figure">Fig. 3</ref>. Architecture of the conditional generator network. Left and right images exemplify the forward cycle and backward cycle respectively in cycle-consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Design of Conditional Generator Network</head><p>Our generator model has a conv-deconv structure <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b5">6]</ref> which is shown in <ref type="figure">Fig. 3</ref>.</p><p>Specifically, the generator model consists of two down-sampling convolution layers with stride 2, two residual blocks <ref type="bibr" target="#b18">[19]</ref> and two transposed convolution layers with stride 2 for up-sampling. Following StarGAN <ref type="bibr" target="#b5">[6]</ref>, the domain indicator is encoded as a one-hot vector with length K s +K n (see <ref type="figure">Fig. 3</ref>). During the forward pass, the one-hot vector is first spatially expanded and then concatenated with the image to form the input to G.</p><p>Discussion. Though the design of G is similar to the StarGAN model, their learning objectives are totally different: We aim to generate images that are different from the existing source domain distributions while the StarGAN model is trained to generate images from the existing source domains. In the experiment part we justify that adding novel-domain data is much more effective than adding seen-domain data for DG (see <ref type="figure" target="#fig_2">Fig. 5a</ref>). Compared with the gradient-based perturbation method in <ref type="bibr" target="#b46">[47]</ref>, our generator is allowed to model more sophisticated domain shift such as image style changes due to its learnable nature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Design of Distribution Divergence Measure</head><p>Two common families for estimating the divergence between probability distributions are f-divergence (e.g., KL divergence) and integral probability metrics (e.g., Wasserstein distance). In contrast to most work that minimizes the divergence, we need to maximize it, as shown in Eq. (2) &amp; (3). This strongly suggests to avoid f-divergence because of the near-zero denominators (they tend to generate large but numerically unstable divergence values). Therefore, we choose the second type, specifically the Wasserstein distance, which has been widely used in recent generative modeling methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46]</ref>. The Wasserstein distance, also known as optimal transport (OT) distance, is defined as</p><formula xml:id="formula_10">W c (P a , P b ) = inf ???(Pa,P b ) E xa,x b ?? [c(x a , x b )],<label>(8)</label></formula><p>where ?(P a , P b ) denotes the set of all joint distributions ?(x a , x b ) and c(?, ?) the transport cost function. Intuitively, the OT metric computes the minimum cost of transporting masses between distributions in order to turn P b into P a . As the sampling over ?(P a , P b ) is intractable, we resort to using the entropyregularized Sinkhorn distance <ref type="bibr" target="#b6">[7]</ref>. Moreover, to obtain unbiased gradient estimators when using mini-batches, we adopt the generalized (squared) energy distance <ref type="bibr" target="#b44">[45]</ref>, leading to</p><formula xml:id="formula_11">d(P a , P b ) = 2E[W c (X a , X b )] ? E[W c (X a , X a )] ? E[W c (X b , X b )],<label>(9)</label></formula><p>where X a and X a are independent mini-batches from distribution P a ; X b and X b are independent mini-batches from distribution P b ; W c is the Sinkhorn distance defined as</p><formula xml:id="formula_12">W c (?, ?) = inf M ?M i,j [M C] i,j ,<label>(10)</label></formula><p>where the soft-matching matrix M represents the coupling distribution ? in Eq. (8) and can be efficiently computed using the Sinkhorn algorithm <ref type="bibr" target="#b13">[14]</ref>; C is the pairwise distance matrix computed over two sets of samples. Following <ref type="bibr" target="#b44">[45]</ref>, we define the cost function as the cosine distance between instances,</p><formula xml:id="formula_13">c(x a , x b ) = 1 ? ?(x a ) T ?(x b ) ||?(x a )|| 2 ||?(x b )|| 2 ,<label>(11)</label></formula><p>where ? is constructed by a CNN (also called critic in <ref type="bibr" target="#b44">[45]</ref>), which maps images into a latent space. In practice, ? is a fixed CNN that was trained with domain classification loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation on Homogeneous DG</head><p>Datasets. (1) We use four different digit datasets including MNIST <ref type="bibr" target="#b23">[24]</ref>, MNIST-M <ref type="bibr" target="#b11">[12]</ref>, SVHN <ref type="bibr" target="#b37">[38]</ref> and SYN <ref type="bibr" target="#b11">[12]</ref>, which differ drastically in font style, stroke color and background. We call this new dataset Digits-DG hereafter. See <ref type="figure" target="#fig_1">Fig. 4a</ref>  Evaluation protocol. For fair comparison with prior work, we follow the leaveone-domain-out protocol in <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b26">27]</ref>. Specifically, one domain is chosen as the test domain while the remaining domains are used as source domains for model training. The top-1 classification accuracy is used as performance measure. All results are averaged over three runs with different random seeds.</p><p>Baselines. We compare L2A-OT with the recent state-of-the-art DG methods that report results on the same dataset or have code publicly available for reproduction. These include (1) CrossGrad <ref type="bibr" target="#b46">[47]</ref>, the most related work that perturbs input using adversarial gradients from a domain classifier; (2) CCSA <ref type="bibr" target="#b35">[36]</ref>, which learns a domain-invariant representation using a contrastive semantic alignment loss; (3) MMD-AAE <ref type="bibr" target="#b27">[28]</ref>, which imposes a MMD loss on the hidden layers of an autoencoder. (4) JiGen <ref type="bibr" target="#b4">[5]</ref>, which has an auxiliary self-supervision loss to solve the Jigsaw puzzle task <ref type="bibr" target="#b38">[39]</ref>; (5) Epi-FCR <ref type="bibr" target="#b26">[27]</ref>, which designs an episodic training strategy; (6) A vanilla model trained by aggregating all source domains, which serves as a strong baseline.</p><p>Implementation details. For Digits-DG, the CNN backbone is constructed with four 64-kernel 3 ? 3 convolution layers and a softmax layer. ReLU and 2 ? 2 max-pooling are inserted after each convolution layer. F is trained with SGD, initial learning rate of 0.05 and batch size of 126 (42 images per source) for 50 epochs. The learning rate is decayed by 0.1 every 20 epochs. For all experiments, G is trained with Adam <ref type="bibr" target="#b22">[23]</ref> and a constant learning rate of 0.0003. For both PACS and Office-Home, we use ResNet-18 <ref type="bibr" target="#b18">[19]</ref> pretrained on ImageNet <ref type="bibr" target="#b7">[8]</ref> as the CNN backbone, following <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b26">27]</ref>. On PACS, F is trained with SGD, initial learning rate of 0.00065 and batch size of 24 (8 images per source) for 40 epochs. The learning rate is decayed by 0.1 after 30 epochs. On Office-Home, the optimization parameters are similar to those on PACS except that the maximum epoch is 25 and the learning rate decay step is 20. For all datasets, as target data is unavailable during training, the values of hyper-parameters ? Domain , ? Cycle and ? CE are set based on the performance on source validation set, 5 which is a strategy commonly adopted in the DG literature <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b26">27]</ref>. Our implementation is based on Dassl.pytorch <ref type="bibr" target="#b63">[64]</ref>.</p><p>Results on Digits-DG. large margin. Compared with CrossGrad, L2A-OT performs clearly better on MNIST-M, SVHN and SYN, with clear improvements of 2.8%, 3.3% and 3%, respectively. It is worth noting that these three domains are very challenging with large domain variations compared with their source domains (see <ref type="figure" target="#fig_1">Fig. 4a</ref>). The huge advantage over CrossGrad can be attributed to L2A-OT's unique generation of unseen-domain data using a fully learnable CNN generator, and using optimal transport to explicitly encourage domain divergence. Compared with the domain alignment methods, L2A-OT surpasses MMD-AAE and CCSA by more than 3.5% on average. The is because L2A-OT enriches the domain diversity of training data, thus reducing overfitting in source domains. L2A-OT clearly beats JiGen because the Jigsaw puzzle transformation does not work well on digit images with sparse pixels <ref type="bibr" target="#b38">[39]</ref>.</p><p>Results on PACS. The results are shown in <ref type="table">Table 2</ref>. Overall, L2A-OT achieves the best performance on all test domains. L2A-OT clearly beats the latest DG methods, JiGen and Epi-FCR. This is because our classifier benefits from the generated unseen-domain data while JiGen and Epi-FCR, like the domain alignment methods, are prone to overfitting to the source domains. L2A-OT beats CrossGrad on all domains, mostly with a large margin. This again justifies our design of learnable CNN generator over adversarial gradient.</p><p>Results on Office-Home. The results are reported in <ref type="table">Table 3</ref>. Again, L2A-OT achieves the best overall performance, and other conclusions drawn previously also hold. Notably, the simple vanilla model obtains strong results on this benchmark, which are even better than most existing DG methods. This is because the dataset is relatively large, and the domain shift is less severe compared with the style changes on PACS and the font variations on Digits-DG. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation on Heterogeneous DG</head><p>In this section, we evaluate L2A-OT on a more challenging DG task with disjoint label space between training and test data, namely cross-domain person re-identification (re-ID).</p><p>Datasets. We use Market1501 <ref type="bibr" target="#b55">[56]</ref> and DukeMTMC-reID (Duke) <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b56">57]</ref>. Mar-ket1501 has 32,668 images of 1,501 identities captured by 6 cameras (domains). Duke has 36,411 images of 1,812 identities captured by 8 cameras.</p><p>Evaluation protocol. We follow the recent unsupervised domain adaptation (UDA) methods in the person re-ID literature <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b31">32]</ref> and experiment with Market1501?Duke and Duke?Market1501. Different from the UDA setting, we directly test the source-trained model on the target dataset without adaptation. Note that the cross-domain re-ID evaluation involves training a person classifier on source dataset identities. This is then transferred and used to recognize a disjoint set of people in the target domain of unseen camera views via nearest neighbor. Since the label space is disjoint, this is a heterogeneous DG problem. For performance measure, we adopt CMC ranks and mAP <ref type="bibr" target="#b55">[56]</ref>.</p><p>Implementation details. For the CNN backbone, we employ the state-of-theart re-ID model, OSNet-IBN <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b61">62]</ref>. Following <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b61">62]</ref>, OSNet-IBN is trained using the standard classification paradigm, i.e. each identity is considered as a class. Therefore, the entire L2A-OT framework remains unchanged. At test time, feature vectors extracted from OSNet-IBN are used to compute 2 distance for image matching. Our implementation is based on Torchreid <ref type="bibr" target="#b60">[61]</ref>.</p><p>Results. In <ref type="table" target="#tab_2">Table 4</ref>, we compare L2A-OT with the vanilla model and Cross-Grad, as well as state-of-the-art UDA methods for re-ID. As a result, CrossGrad barely improves the vanilla model while L2A-OT achieves clear improvements on both settings. Notably, L2A-OT is highly competitive with the UDA methods, though the latter make the significantly stronger assumption of having access to the target domain data (thus gaining an unfair advantage). In contrast, L2A-OT generates images of unseen styles (domains) for data augmentation, and such more diverse data leads to learning a better generalizable re-ID model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation Study</head><p>Importance of generating novel domains. To verify that our improvement is brought by the increase in training data distributions by the generated novel domains (i.e. Eq. (2) &amp; (3)), we compare L2A-OT with StarGAN <ref type="bibr" target="#b5">[6]</ref>, which generates data from the existing source domains by performing source-to-source mapping. The experiment is conducted on Digits-DG and the average performance over all test domains is used for comparison. <ref type="figure" target="#fig_2">Fig. 5a</ref> shows that Star-GAN performs only similarly to the vanilla model (StarGAN's 73.8% vs. vanilla's 73.7%) while L2A-OT obtains a clear improvement of 4.3% over StarGAN. This confirms that increasing domains is far more important than increasing data (of seen domains) for DG. Note that this 4.3% gap is attributed to the combination of the OT-based domain novelty loss (Eq. (2)) and the diversity loss (Eq. <ref type="formula" target="#formula_3">(3)</ref>). <ref type="figure" target="#fig_2">Fig. 5a</ref> shows that the diversity loss contributes around 1% to the performance, and the rest improvement comes from the diversity loss.</p><p>Importance of semantic constraint. The cycle-consistency and cross-entropy losses (Eq. (4) &amp; (5)) are essential in the L2A-OT framework for maintaining the semantic content when performing domain translation. <ref type="figure" target="#fig_2">Fig. 5b</ref> shows that without the semantic constraint, the content is completely missing (we found that using these images reduced the result from 78.1% to 73.9%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Further Analysis</head><p>How many novel domains to generate? Our approach can generate an arbitrary number of novel domains, although we have always doubled the number of domains (set K s = K n ) so far. <ref type="figure">Fig. 6</ref> investigates the significance on the choice of number of novel domains. In principle, synthesizing more domains provides opportunity for more diverse data, but also increases optimization difficulty and is dependent on the source domains. The result shows that the performance is not very sensitive to the choice of novel domain number, with K n = K s being a good rule of thumb.</p><p>Do more source domains lead to a better result? In general, yes. The evidence is shown in <ref type="table" target="#tab_3">Table 5</ref> where the result of using three sources is generally better than using two as we might expect due to the additional diversity. The detailed results show that when using two sources, performance is sensitive to the choice of sources among the available three. This is expected since different sources will vary in transferrability to a given target. However, for both vanilla and L2A-OT the performance of using three sources is better than the performance of using two averaged across the 2-source choices.</p><p>Visualizing domain distributions. We employ t-SNE <ref type="bibr" target="#b33">[34]</ref> to visualize the domain feature embeddings using the validation set of Digits-DG (see <ref type="figure">Fig. 7a</ref>). We have the following observations. (1) The generated distributions are clearly separated from the source domains and evenly fill the unseen domain space.</p><p>(2) The generated distributions form independent clusters (due to our diversity term in Eq. (3)). (3) G has successfully learned to flexibly transform one source domain to any of the discovered novel domains.</p><p>Visualizing novel-domain images. <ref type="figure">Fig. 8</ref> visualizes the output of G. In general, we observe that the generated images from different novel domains manifest different properties and more importantly, are clearly different from the source images. For example, in Digits-DG <ref type="figure">(Fig. 8a)</ref>, G tends to generate images with different background patterns/textures and font colors. In PACS <ref type="figure">(Fig. 8b)</ref>, G focuses on contrast and color. <ref type="figure">Fig. 8</ref> seems to suggest that the synthesized domains are not drastically different from each other. However, a seemingly limited diversity in the image space to human eyes can be significant to a CNN classifier: both <ref type="figure">Fig. 1 and Fig. 7a</ref> show clearly that the synthesized data points have very different distributions from both the original ones and each other in a feature embedding space, making them useful for learning a domain-generalizable classifier.</p><p>L2A-OT vs. CrossGrad. It is clear from <ref type="figure">Fig. 7b</ref> that the new domains generated by CrossGrad largely overlap with the original domains. This is because CrossGrad is based on adversarial attack methods <ref type="bibr" target="#b17">[18]</ref>, which are designed to make imperceptible changes. This is further verified in <ref type="figure">Fig. 9</ref> where the images generated by CrossGrad have only subtle differences in contrast to the original images. On the contrary, L2A-OT can model much more complex domain variations that can materially benefit the classifier, thanks to the full CNN image generator and OT-based domain divergence losses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented L2A-OT, a novel data augmentation-based DG method that boosts classifier's robustness to domain shift by learning to synthesize images from diverse unseen domains through a conditional generator network. The generator is trained by maximizing the OT distance between source domains and pseudonovel domains. Cycle-consistency and classification losses are imposed on the generator to further maintain the structural and semantic consistency during domain translation. Extensive experiments on four DG benchmark datasets cov-CrossGrad Ours CrossGrad Ours <ref type="figure">Fig. 9</ref>. Comparison between L2A-OT and CrossGrad <ref type="bibr" target="#b46">[47]</ref> on image generation.</p><p>ering a wide range of visual recognition tasks demonstrate the effectiveness and versatility of L2A-OT.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>arXiv:2007.03304v3 [cs.CV] 9 Mar 2021G(P SYN ) G(P MNIST ) G(P MNIST-M ) P MNIST-M P MNIST P SYN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Example images from different DG datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Ablation study.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>T-SNE visualization of domain embeddings of (a) L2A-OT and (b) Cross-Grad<ref type="bibr" target="#b46">[47]</ref>. X (G) indicates novel data when using the domain X as a source. Visualization of generated images. x: source image. G(x, i): generated image of the i-th novel domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Leave-one-domain-out results on Digits-DG.</figDesc><table><row><cell>for</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 Table 2 .Table 3 .</head><label>123</label><figDesc>shows that L2A-OT achieves the best performance on all domains and consistently outperforms the vanilla baseline by a Leave-one-domain-out results on PACS dataset. Leave-one-domain-out results on Office-Home.</figDesc><table><row><cell>Method</cell><cell>Art</cell><cell>Cartoon</cell><cell>Photo</cell><cell>Sketch</cell><cell>Avg.</cell></row><row><cell>Vanilla</cell><cell>77.0</cell><cell>75.9</cell><cell>96.0</cell><cell>69.2</cell><cell>79.5</cell></row><row><cell>CCSA [36]</cell><cell>80.5</cell><cell>76.9</cell><cell>93.6</cell><cell>66.8</cell><cell>79.4</cell></row><row><cell>MMD-AAE [28]</cell><cell>75.2</cell><cell>72.7</cell><cell>96.0</cell><cell>64.2</cell><cell>77.0</cell></row><row><cell>CrossGrad [47]</cell><cell>79.8</cell><cell>76.8</cell><cell>96.0</cell><cell>70.2</cell><cell>80.7</cell></row><row><cell>JiGen [5]</cell><cell>79.4</cell><cell>75.3</cell><cell>96.0</cell><cell>71.6</cell><cell>80.5</cell></row><row><cell>Epi-FCR [27]</cell><cell>82.1</cell><cell>77.0</cell><cell>93.9</cell><cell>73.0</cell><cell>81.5</cell></row><row><cell>L2A-OT (ours)</cell><cell>83.3</cell><cell>78.2</cell><cell>96.2</cell><cell>73.6</cell><cell>82.8</cell></row><row><cell>Method</cell><cell cols="5">Artistic Clipart Product Real World Avg.</cell></row><row><cell>Vanilla</cell><cell>58.9</cell><cell>49.4</cell><cell>74.3</cell><cell>76.2</cell><cell>64.7</cell></row><row><cell>CCSA [36]</cell><cell>59.9</cell><cell>49.9</cell><cell>74.1</cell><cell>75.7</cell><cell>64.9</cell></row><row><cell>MMD-AAE [28]</cell><cell>56.5</cell><cell>47.3</cell><cell>72.1</cell><cell>74.8</cell><cell>62.7</cell></row><row><cell>CrossGrad [47]</cell><cell>58.4</cell><cell>49.4</cell><cell>73.9</cell><cell>75.8</cell><cell>64.4</cell></row><row><cell>JiGen [5]</cell><cell>53.0</cell><cell>47.5</cell><cell>71.5</cell><cell>72.8</cell><cell>61.2</cell></row><row><cell>L2A-OT (ours)</cell><cell>60.6</cell><cell>50.1</cell><cell>74.8</cell><cell>77.0</cell><cell>65.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .</head><label>4</label><figDesc>Results on cross-domain person re-ID benchmarks.</figDesc><table><row><cell>Method</cell><cell>Market1501?Duke mAP R1 R5 R10 mAP Duke?Market1501 R1 R5 R10</cell></row><row><cell></cell><cell>UDA methods</cell></row><row><cell>ATNet [32]</cell><cell>24.9 45.1 59.5 64.2 25.6 55.7 73.2 79.4</cell></row><row><cell>CamStyle [59]</cell><cell>25.1 48.4 62.5 68.9 27.4 58.8 78.2 84.3</cell></row><row><cell>HHL [58]</cell><cell>27.2 46.9 61.0 66.7 31.4 62.2 78.8 84.0</cell></row><row><cell></cell><cell>DG methods</cell></row><row><cell>Vanilla</cell><cell>26.7 48.5 62.3 67.4 26.1 57.7 73.7 80.0</cell></row><row><cell>CrossGrad [47]</cell><cell>27.1 48.5 63.5 69.5 26.3 56.7 73.5 79.5</cell></row><row><cell cols="2">L2A-OT (ours) 29.2 50.1 64.5 70.1 30.2 63.8 80.2 84.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 .</head><label>5</label><figDesc>Fig. 6. Results of varying Kn. Here Ks = 3. Using two vs. three source domains on Digits-DG where the size of training data is kept identical for all settings for fair comparison.</figDesc><table><row><cell>Accuracy (%)</cell><cell>76.5 77.0 77.5 78.0</cell><cell>Ks 2</cell><cell cols="3">Ks 1 Number of novel domains Kn Ks Ks + 1</cell><cell>Ks + 2</cell></row><row><cell cols="2">MNIST</cell><cell>Source SVHN</cell><cell>SYN</cell><cell>Target</cell><cell>L2A-OT</cell><cell>Vanilla</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>MNIST-M</cell><cell>60.9</cell><cell>54.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>MNIST-M</cell><cell>62.1</cell><cell>59.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>MNIST-M</cell><cell>49.7</cell><cell>45.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>MNIST-M</cell><cell>62.5</cell><cell>57.1</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Following<ref type="bibr" target="#b30">[31]</ref>, homogeneous DG shares the same label space between training and test data while heterogeneous DG has disjoint label space.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The searching space is: ?Domain ? {0.5, 1, 2}, ? Cycle ? {10, 20} and ?CE ? {1}.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Metareg: Towards domain generalization using meta-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The cramer distance as a solution to biased wasserstein gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dabney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10743</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
		<title level="m">A theory of learning from different domains. ML</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Stargan: Unified generative adversarial networks for multi-domain image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Sinkhorn distances: Lightspeed computation of optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cuturi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Domain generalization with domain-specific aggregation modules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>GCPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Domain generalization via model-agnostic learning of semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning attributes equals multi-source domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Lempitsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<title level="m">Domain-adversarial training of neural networks</title>
		<imprint>
			<publisher>JMLR</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning generative models with sinkhorn divergences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Genevay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Peyr?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cuturi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>AISTATS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Scatter component analysis: A unified framework for domain adaptation and domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Generative adversarial nets</title>
		<imprint>
			<publisher>NeurIPS</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Micaelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05439</idno>
		<title level="m">Meta-learning in neural networks: A survey</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Style normalization and restitution for generalizable person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Learning to generalize: Metalearning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Episodic training for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Kot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Deep domain generalization via conditional invariant adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tiana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Diversified texture synthesis with feed-forward networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Feature-critic networks for heterogeneous domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Adaptive transfer network for cross-domain person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">J</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A unifying view on dataset shift in classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Moreno-Torres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Alaiz-Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>PR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">ICML</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS-W</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Moment matching for multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Peyr?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cuturi</surname></persName>
		</author>
		<title level="m">Computational optimal transport. Foundations and Trends? in Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Structured domain randomization: Bridging the reality gap by context-aware synthetic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boochoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brophy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Acuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cameracci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>State</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Shapira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Birchfield</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICRA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Performance measures and a data set for multi-target, multi-camera tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Solera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<editor>ECCV-W</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Semi-supervised domain adaptation via minimax entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Improving gans using optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Singan: Learning a generative model from a single natural image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Michaeli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Generalizing across domains via cross-gradient training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Domain randomization for transferring deep neural networks from simulation to the real world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tobin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IROS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Deceptionnet: Network-driven domain randomization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zakharov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ilic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Scalable person reidentification: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Unlabeled samples generated by gan improve the person re-identification baseline in vitro</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Generalizing a person retrieval model heteroand homogeneously</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Camstyle: A novel data augmentation method for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.02503</idno>
		<title level="m">Domain generalization: A survey</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Torchreid: A library for deep learning person re-identification in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10093</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.06827</idno>
		<title level="m">Learning generalisable omni-scale representations for person re-identification</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Omni-scale feature learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.07325</idno>
		<title level="m">Domain adaptive ensemble learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
