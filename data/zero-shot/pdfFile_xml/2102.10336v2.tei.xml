<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Physical Reasoning Using Dynamics-Aware Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eltayeb</forename><surname>Ahmed</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Girdhar</surname></persName>
						</author>
						<title level="a" type="main">Physical Reasoning Using Dynamics-Aware Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A common approach to solving physicalreasoning tasks is to train a value learner on example tasks. A limitation of such an approach is that it requires learning about object dynamics solely from reward values assigned to the final state of a rollout of the environment. This study aims to address this limitation by augmenting the reward value with self-supervised signals about object dynamics. Specifically, we train the model to characterize the similarity of two environment rollouts, jointly with predicting the outcome of the reasoning task. This similarity can be defined as a distance measure between the trajectory of objects in the two rollouts, or learned directly from pixels using a contrastive formulation. Empirically, we find that this approach leads to substantial performance improvements on the PHYRE benchmark for physical reasoning <ref type="bibr" target="#b1">(Bakhtin et al., 2019)</ref>, establishing a new state-of-the-art.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Many open problems in artificial intelligence require agents to reason about physical interactions between objects. Spurred by the release of benchmarks such as Tools <ref type="bibr">(Allen et al., 2020)</ref> and PHYRE <ref type="bibr" target="#b1">(Bakhtin et al., 2019)</ref>, such physical reasoning tasks have become a popular subject of study <ref type="bibr" target="#b2">(Girdhar et al., 2020;</ref><ref type="bibr" target="#b9">Qi et al., 2021;</ref><ref type="bibr">Whitney et al., 2020)</ref>. Specifically, physical-reasoning tasks define an initial state and a goal state of the world, and require selecting an action that comprises placing one or more additional objects in the world. After the action is performed, the world simulator is unrolled to determine whether or not the goal state is attained. Despite their simplicity, benchmarks like PHYRE are surprisingly difficult to solve due to the chaotic nature of the dynamics of physical objects. Current approaches for physical reasoning problems can be subdivided Copyright 2021 by the author(s). into two main types:</p><p>1. Dynamics-agnostic approaches treat the problem as a "standard" contextual bandit that tries to learn the value of taking a particular action given an initial state, without using the simulator rollout in any way <ref type="bibr" target="#b1">(Bakhtin et al., 2019)</ref>. An advantage of such approaches is that they facilitate the use of popular learning algorithms for this setting, such as deep Q-networks (DQNs; <ref type="bibr" target="#b6">Mnih et al. (2013)</ref>) However, the approaches do not use information from the simulator rollout as learning signal, which limits their efficacy.</p><p>2. Dynamics-modeling approaches learn models that explicitly aim to capture the dynamics of objects in the world, and use those models to perform forward prediction <ref type="bibr" target="#b2">(Girdhar et al., 2020;</ref><ref type="bibr" target="#b9">Qi et al., 2021;</ref><ref type="bibr">Whitney et al., 2020)</ref>. Such forward predictions can then be used, for example, in a search algorithm to find an action that is likely to be successful. An advantage of such approaches is that they use learning signal obtained from the simulator rollout. However, despite recent progress <ref type="bibr" target="#b10">(Sanchez-Gonzalez et al., 2020)</ref>, high-fidelity dynamics prediction in environments like PHYRE remains an unsolved problem <ref type="bibr" target="#b2">(Girdhar et al., 2020)</ref>. Moreover, current approaches do not use the uncertainty in the dynamics model to select actions that are most likely to solve the task.</p><p>In this paper, we develop a dynamics-aware approach for physical reasoning that is designed to combine the strengths of the current two approaches. Our approach incorporates information on simulator rollout into the learning signal used to train DQNs. The resulting models outperforms all prior work on the PHYRE benchmark, including full dynamics-modeling approaches, achieving a new state-ofthe-art of 86.2 in the one-ball (1B), within-template setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dynamics-Aware Deep Q-Networks</head><p>The basis of the model we develop for physical reasoning is a standard deep Q-network (DQN; <ref type="bibr" target="#b1">Bakhtin et al. (2019)</ref>; <ref type="bibr" target="#b6">Mnih et al. (2013)</ref> Our backbone model is a ResNet <ref type="bibr" target="#b3">(He et al., 2016)</ref> that takes an image depicting the initial scene, s, of the task as input. The action, a, parameterized as a (x, y, r)-vector 1 , is processed by a multilayer perceptron with one hidden layer to construct an action embedding. The action embedding is fused with the output of the third ResNet block using FiLM modulation <ref type="bibr" target="#b8">(Perez et al., 2018)</ref>. This fused representation is input into the fourth block of the ResNet to obtain a sceneaction embedding, e s,a . We score action a by applying a linear layer with weights w 1 and bias b 1 on e s,a . At training time, we evaluate this score using a logistic loss that compares it against a label, y s,a , that indicates whether or not action a solves task s:</p><formula xml:id="formula_0">y s,a = w 1 e s,a + b 1 (1) L = ? (y s,a log (? s,a ) + (1 ? y s,a ) log (1 ?? s,a )) . (2)</formula><p>We study two approaches to incorporate a dynamics-aware loss that encourages scene-action embeddings e s,a that lead to similar rollouts to be similar: 1) A hand-crafted loss that leverages the object-state information from the simulator to determine which rollouts are similar and tries to match them; and 2) A self-supervised loss that does not rely on object-state information but, instead, operates on a pixellevel embedding that it matches to an embedding computed from a random portion of its own rollout, contrasting against other rollouts in the batch. We now describe both in detail.</p><p>Hand-crafted dynamics-aware loss. Given a pair of actions (a, a ) for task s, we compute a joint embedding of the two actions j s,a,a for that task as follows: p s,a = MLP(e s,a ; ?); p s,a = MLP(e s,a ; ?) (3) j s,a,a = p s,a p s,a .</p><p>Herein, refers to a combination function: we use the outer product by default but we also experiment with elementwise products and concatenation in Section 3.2. We pass j s,a,a through another linear layer to predict the similarity of the two actions applied on scene s. The model is trained to minimize a loss that compares the predicted similarity to a "ground-truth" similarity. Specifically, we bin the groundtruth similarity into K bins and minimize the cross-entropy loss of predicting the right bin:</p><formula xml:id="formula_2">u s,a,a = W 2 j s,a,a + b 2 (5) L aux = ?y s u s,a,a + log ? ? y s exp y s u s,a,a ? ? .<label>(6)</label></formula><p>1 For the PHYRE-2B tier, the action is parametrized via a (x1, y1, r1, x2, y2, r2)-vector.</p><p>Herein, y s is a one-hot vector of length K indicating the bin in which the ground-truth similarity falls.</p><p>To measure the ground-truth similarity, v a,a , between two actions a and a on task s, we run the simulator on the two scenes obtained after applying the actions. We track all objects throughout the simulator roll-outs, and measure the Euclidean distance between each object in one roll-out and its counterpart in the other roll-out. This results in distance functions, d a,a (o, t), for all objects o ? O (where t represents time). We convert the distance function into a similarity functions and aggregate all similarities over time and over all objects:</p><formula xml:id="formula_3">q a,a (o, t) = 1 ? min(d a,a (o, t), ?) ? (7) v a,a = o?O T t=1 q a,a (o, t) T |O| ,<label>(8)</label></formula><p>where ? is a hyperparameter that clips the distance at a maximum value, and T is the number of time steps in the roll-out. The similarity v a,a is binned to construct y s . See Appendix A for details.</p><p>Self-supervised Dynamics-Aware loss. Since the previous similarity metric relies on access to the ground truth (GT) object states through the rollout-an unreasonable assumption in most real-world scenarios-we propose a modification of the proposed auxiliary loss, by learning the distance between rollouts using a contrastive formulation.</p><p>To that end, we start by representing a scene-action pair by rendering the action onto the scene and passing it through a vanilla ResNet-18 to obtain the embedding e s,a , instead of the FiLM approach used earlier. This allows for a common representation space for different parts of the rollout without relying on GT object positions. This embedding is then used for two objectives. First, as before, we predict whether the task will be solved or not using a linear layer as in Equation 1. Second, we embed K consecutive frames from a random point in the rollout using the same encoder to obtain e 1 s,a ? ? ? e K s,a , concatenate these embeddings and pass the result through an MLP to reduce it to the same dimensions as e s,a . We refer to the resulting "rollout embedding" as e roll s,a . We then incur a contrastive loss <ref type="bibr" target="#b7">(Oord et al., 2018)</ref> to match the initial embedding action embedding to its corresponding rollout embedding after passing them through another MLP: , with e roll s,a the rollout embeddings, and ? the temperature. Training. In both cases, the model is trained to minimize L + L aux , assigning equal weight to both losses. We follow <ref type="bibr" target="#b1">Bakhtin et al. (2019)</ref> and train the model using minibatch SGD. We balance the training batches to contain an  equal number of positive and negative task-action pairs. To facilitate computation of L aux , we sample t tasks uniformly at random in a batch. For each task, we sample n actions that solve the task and n actions that do not solve the task. We compute the similarity in hand-crafted case, v a,a , for all 4n 2 action pairs for a task. To evaluate L aux , we average over these 4tn 2 action pairs. Simultaneously, we average L over the 2tn task-action pairs. For the self-supervised case, we use similar optimization and batch composition as above.</p><formula xml:id="formula_4">z s,a = MLP(e s,a )<label>(9</label></formula><p>For computing L aux we use as negatives all other rollout embeddings on the same GPU. See the appendix for more details on our training procedure and hyperparameters.</p><p>Inference. At inference time, for both our models, the agent scores a set of A randomly selected actions using the scoring function? t,ai . The agent proposes the highestscoring action as a solution. If that action does not solve the task, the agent submits the subsequent highest-scoring action until the task is solved or until the agent has exhausted its attempts (whichever happens first).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>Dataset. We test our dynamics-aware deep Q-network (DQN) on the PHYRE benchmark on both tiers (1B and 2B) and both generalization settings: within-template and cross-template. Following <ref type="bibr" target="#b1">Bakhtin et al. (2019)</ref>, we use all 10 folds and evaluate on the test splits in our final evaluation; see the results in <ref type="table">Table 1</ref>. For all ablation studies, we use the 4 folds on the validation splits; see <ref type="table" target="#tab_3">Table 2</ref> and 3.</p><p>Implementation details. We train our models on 100,000 batches with 512 samples per batch. Each batch contains 64 unique tasks with 8 actions per task, such that half of them solve the task (positives) and half of them do not (negatives).</p><p>Training is performed using Adam <ref type="bibr" target="#b4">(Kingma &amp; Ba, 2015)</ref> with an initial learning rate of 3 ? 10 ?4 and a cosine learning rate schedule <ref type="bibr" target="#b5">(Loshchilov &amp; Hutter, 2016)</ref>. We set K = 20, we set the maximum possible distance in a PHYRE scene ? = ? 2, and we set the dimensionality of p s,a to 256. We train and test all models in both the within-template and the cross-template generalization settings. Following <ref type="bibr" target="#b1">Bakhtin et al. (2019)</ref>, we also study the effect of online updates during inference time in the cross-template setting. <ref type="table">Table 1</ref> presents the AUCCESS of our best dynamics-aware DQNs, and compares it to results reported in prior work. The results show the strong performance of our models compared to both dynamics-agnostic <ref type="bibr" target="#b1">(Bakhtin et al., 2019)</ref> and dynamics-modeling <ref type="bibr" target="#b2">(Girdhar et al., 2020;</ref><ref type="bibr" target="#b9">Qi et al., 2021)</ref> approaches. In the cross-template setting our selfsupervised model improves over the DQN baseline and the Dec[Joint] forward model and almost matches the performance of RPIN. The results suggest dynamics-aware DQNs have the potential to improve physical-reasoning models. <ref type="figure">Figure 1</ref> illustrates how our dynamics-aware DQN model better eliminates parts of the action space in its predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Comparison to SOTA and Qualitative Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Ablation Study</head><p>We ablate various components of our architecture for handcrafted and self-supervised losses in Tables 2 and 3. In each subtable, we vary only one component of the model and keep all the other components to fixed. The values that we used to produce our final results in <ref type="table">Table 1</ref> are underlined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">HAND-CRAFTED DYNAMICS-AWARE LOSS</head><p>Effect of Auxiliary loss. We evaluate in <ref type="table" target="#tab_3">Table 2a</ref>. To control for all other factors we train another network with identical parameters to using only L which results in a DQN agent and we compare it an agent trained with both  <ref type="figure">Figure 1: In (a) and (b)</ref>, we visualize all the ground truth (GT) and top 10 predicted actions' positions (x, y) that solves the above two tasks, with darker color representing higher confidence. On Task A, our method (hand-crafted) performs similarly to a dynamics-agnostic baseline. In Task B where the incline is slanted the other way, however, the baseline model is confused between two possible sets of positions of the action. By contrast, our dynamics-aware DQN model is able to solve this task correctly. In (c), we visualize all actions with &gt; 0.9 cosine similarity to any action that solves the task (darker color =? higher similarity). Our dynamics-aware DQN model rules out more incorrect actions than the baseline DQN.  L and L + L aux . We see that our method outperforms the DQN baseline in the within-template setup and matches the baseline in the cross-template setup.</p><p>Effect of projection layer. In Equation 3, we described an MLP to project the embedding from the backbone network.</p><p>In <ref type="table" target="#tab_3">Table 2b</ref>, we test replacing it with a linear layer or directly using the backbone embeddings. We find a that a linear layer works slightly better and adopt it in our final model.</p><p>Effect of number of bins, K. We evaluate its effect in classifying action similarity values in L aux . The results in <ref type="table" target="#tab_3">Table 2c</ref> show that K = 20 performs well but using fewer bins works fine, too. We also compare the bin-classification approach to a regressor that minimizes mean-squared error (MSE) on the action similarities, but find it performs worse.</p><p>Effect of combination function. We compare different combination functions for computing the representations j s,a,a . <ref type="table" target="#tab_3">Table 2d</ref> presents the results of this comparison. We find that element-wise multiplication works better than concatenation, but combination by bilinear layer works best.</p><p>Effect of frames considered in action similarity measure.</p><p>We evaluate the effect of changing the frames of the simulator roll-out used to compute the action similarity, v a,a . The results of this evaluation in <ref type="table" target="#tab_3">Table 2e</ref> show that using the entire rollout or the last 10 frames works best, with using the first 10 frames or the last 5 frames trail closely behind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">SELF-SUPERVISED DYNAMICS-AWARE LOSS</head><p>We also ablate components of our self-supervised loss.</p><p>Action representation. Since we render actions onto frames before computing the action-scene embedding instead of using FiLM, we evaluate the effect of using that representation in <ref type="table" target="#tab_6">Table 3a</ref>. We find that the representation slightly improves slightly over the FiLM representation.</p><p>Adding contrastive loss. We vary the relative weight of the contrastive loss in <ref type="table" target="#tab_6">Table 3b</ref>. The results show that adding the contrastive loss improves over the baseline DQN model.</p><p>Other contrastive parameters. We also ablate the projection layer, number of negatives, temperature (?) for the loss, and the number of frames (K). We find that the contrastive loss deteriorates performance when no projection layer is used, and a linear projection works best. We also find that our method is relatively sensitive to the temperature hyperparameter, and that there is a positive correlation between performance and number of negative samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We have presented a dynamics-aware DQN model for efficient physical reasoning that better captures object dynamics than baseline DQNs by leveraging self-supervised learning on simulator roll-outs. Our model does not require explicit forward prediction at inference time. Our best models outperform prior work on the challenging PHYRE benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Action Similarity Metric</head><p>The similarity between two actions is computed from the object feature representation of the actions' rollouts provided by the PHYRE API. For two rollouts of two actions (a, a ) we use the notation that (x(o, t), y(o, t)) and (x (o, t), y (o, t)) are the locations of the object o at the timestep t in the rollouts of a and a respectively then:</p><formula xml:id="formula_5">T = min(t 1 , t 2 ) (10) q a,a (o, t) = 1 ? min(d a,a (o, t), ?) ? (11) v a,a = o?O T t=1 q a,a (o, t) T |O| ,<label>(12)</label></formula><p>where O is the set of moving objects in the scene, t 1 and t 2 are the lengths of the first and second rollouts respectively and ? is a hyperparameter that clips the distance at a maximum value. When computing the metric using only "last n" frames the frames we consider are the frames from time (T ? n + 1) to T . The similarity v a,a is binned to construct y s as follows:</p><formula xml:id="formula_6">y s = v a,a (K ? 1) ,<label>(13)</label></formula><p>where ? is an operator that rounds continuous numbers to the nearest integer and K is the number of bins used.</p><p>In <ref type="table">Table 1</ref>, we take ? = ? 2. This value is suggested by the PHYRE environment since the coordinates of locations in the scene fall in the square limited by the corner points (0, 0) and (1, 1) with the maximum possible Euclidean distance between two objects being ? 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Qualitative Study</head><p>We break down the AUCCESS improvement by template in <ref type="figure">Figure 2</ref> and try to characterize the the templates in which our method improves most over the baseline and we find in <ref type="figure">Figure 3</ref> that our method introduces the highest gains in templates which the performance of the baseline was lower. This holds even when comparing across templates where the baseline has still not reached maximum performance.</p><p>In <ref type="figure">Figure 4</ref>, we show all actions for the given task, color coded by their similarity to GT actions for ours and baseline model. We find our dynamics-aware model is able to rule out incorrect actions much more effectively than the baseline, at all different levels of similarity thresholds considered.</p><p>Physical Reasoning Using Dynamics-Aware Models  <ref type="figure">Figure 2</ref>: Here we break down the AUCCESS by template in 2a and number of moving objects in 2b. We see our agents biggest gains are on templates where the baseline performs worst, while the baseline marginally outperforms our models in the templates where baseline was already performing well. We aggregate the templates by the number of moving objects in where we see our model outperforming the baseline across all numbers of moving objects.  <ref type="figure">Figure 1 (c)</ref>, showing action space embeddings color coded by similarity to GT actions, at different similarity thresholds. We observe our method leads to actions is able to rule out actions incapable of solving the task at all thresholds, and at 0.98 the selected actions are almost indistinguishable from GT.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Here we show baseline AUCCESS vs ?AUCCESS from our method and find a statistically significant correlation with a Pearson correlation factor of -0.54. This shows we get highest gains on templates where the baseline performs poorly. Here we show an extended version of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Sep 2021 rate dynamics of the environment at training time, without having to do accurate dynamics prediction at inference time.</figDesc><table /><note>). We augment the loss function used to train this model with a dynamics-aware loss function. This allows the model-free DQN learner to explicitly incorpo- arXiv:2102.10336v2 [cs.AI] 1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc><ref type="bibr" target="#b1">Bakhtin et al., 2019)</ref> 13.7?0.5 13.0?5.0 3.6?0.6 2.6?1.5 MEM<ref type="bibr" target="#b1">(Bakhtin et al., 2019)</ref> 2.4?0.3 18.5?5.1 3.2?0.2 3.7?2.3 DQN<ref type="bibr" target="#b1">(Bakhtin et al., 2019)</ref> 77.6?1.1 36.8?9.7 67.8?1.5 23.2?9.1 Dec [Joint]<ref type="bibr" target="#b2">(Girdhar et al., 2020)</ref> 80.0?1.2 40.Table 1: AUCCESS of dynamics-aware DQNs compared to state-of-the-art models on the PHYRE-1B and 2B tiers in the within-template and cross-template generalization settings. Results reported are averaged over 10 test folds.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Physical Reasoning Using Dynamics-Aware Models</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>PHYRE-1B</cell><cell>PHYRE-2B</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Within</cell><cell>Cross</cell><cell>Within</cell><cell>Cross</cell></row><row><cell cols="5">RAND (3?8.0</cell><cell>-</cell><cell>-</cell></row><row><cell cols="4">RPIN (Qi et al., 2021)</cell><cell>85.2?0.7 42.2?7.1</cell><cell>-</cell><cell>-</cell></row><row><cell cols="4">Ours (Hand-crafted)</cell><cell>85.0?1.1 38.6?8.4 74.0?1.5 23.3?8.8</cell></row><row><cell cols="4">Ours (Self-supervised)</cell><cell>86.2?0.9 41.9?8.8 77.6?1.4 24.3?10.0</cell></row><row><cell cols="3">Model Within</cell><cell>Cross</cell><cell>AUCCESS</cell></row><row><cell cols="4">DQN 81.7?0.6 36.4?11.1</cell><cell>Multiplication</cell><cell>82.6?1.4</cell></row><row><cell>Ours</cell><cell cols="3">83.1?1.0 36.3?9.3</cell><cell>Concatenation</cell><cell>81.8?1.4</cell></row><row><cell cols="4">(a) Auxiliary loss.</cell><cell>Bilinear</cell><cell>83.3?1.1</cell></row><row><cell></cell><cell></cell><cell cols="2">AUCCESS</cell><cell>(d) Combination function.</cell></row><row><cell>None</cell><cell></cell><cell></cell><cell>82.9?0.5</cell><cell>Frames</cell><cell>AUCCESS</cell></row><row><cell>Linear</cell><cell></cell><cell></cell><cell>83.0?1.0</cell></row><row><cell cols="3">2-Layer MLP</cell><cell>82.6?0.9</cell><cell>First 1</cell><cell>81.4?0.7</cell></row><row><cell cols="3">3-Layer MLP</cell><cell>82.8?1.3</cell><cell>First 3</cell><cell>81.9?1.1</cell></row><row><cell cols="4">(b) Projection layer.</cell><cell>First 5</cell><cell>82.7?1.4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>First 10</cell><cell>82.9?0.9</cell></row><row><cell>k</cell><cell></cell><cell cols="2">AUCCESS</cell><cell>Last 1</cell><cell>82.8?1.0</cell></row><row><cell>2</cell><cell></cell><cell cols="2">81.9?0.9</cell><cell>Last 3</cell><cell>82.6?1.0</cell></row><row><cell>5</cell><cell></cell><cell cols="2">82.8?0.6</cell><cell>Last 5</cell><cell>82.6?1.0</cell></row><row><cell>10</cell><cell></cell><cell cols="2">82.8?1.3</cell><cell>Last 10</cell><cell>83.0?0.9</cell></row><row><cell cols="2">20 MSE</cell><cell cols="2">83.0?0.6 81.4?0.5</cell><cell>Entire Rollout</cell><cell>83.0?1.0</cell></row><row><cell cols="4">(c) Number of bins.</cell></row></table><note>(e) Frames used in v a,a .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Hand-crafted loss ablations. AUCCESS on PHYRE-1B validation folds in within-template setting.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Self-supervised loss ablations. AUCCESS on PHYRE-1B validation folds in within-template setting.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Facebook AI Research, New York. Correspondence to: Eltayeb Ahmed &lt;eltayeb.k.ahmed@gmail.com&gt;, Rohit Girdhar &lt;rgirdhar@fb.com&gt;.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Tools challenge: Rapid trial-and-error learning in physical problem solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CogSci</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">PHYRE: A new benchmark for physical reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gustafson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Forward prediction for physical reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girdhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gustafson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10734</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sgdr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Playing atari with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Film: Visual reasoning with a general conditioning layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning long-term visual dynamics with region proposal interaction networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning to simulate complex physics with graph networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Godwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pfaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Battaglia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.09405</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dynamics-aware embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">F</forename><surname>Whitney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
