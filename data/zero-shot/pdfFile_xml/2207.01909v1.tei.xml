<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">StyleFlow For Content-Fixed Image to Image Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weichen</forename><surname>Fan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sensetime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinghuan</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sensetime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabin</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sensetime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Hou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sensetime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sensetime Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">StyleFlow For Content-Fixed Image to Image Translation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Image-to-image (I2I) translation is a challenging topic in computer vision. We divide this problem into three tasks: strongly constrained translation, normally constrained translation, and weakly constrained translation. The constraint here indicates the extent to which the content or semantic information in the original image is preserved. Although previous approaches have achieved good performance in weakly constrained tasks, they failed to fully preserve the content in both strongly and normally constrained tasks, including photo-realism synthesis, style transfer, and colorization, .etc. To achieve content-preserving transfer in strongly constrained and normally constrained tasks, we propose Style-Flow, a new I2I translation model that consists of normalizing flows and a novel Style-Aware Normalization (SAN) module. With the invertible network structure, StyleFlow first projects input images into deep feature space in the forward pass, while the backward pass utilizes the SAN module to perform content-fixed feature transformation and then projects back to image space. Our model supports both image-guided translation and multi-modal synthesis. We evaluate our model in several I2I translation benchmarks, and the results show that the proposed model has advantages over previous methods in both strongly constrained and normally constrained tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Fig. 1</ref><p>. Given two images in different visual domains, our model learns to translate from one to the other in various tasks.(1. Summer to Winter <ref type="bibr" target="#b63">[64]</ref>; 2. Gray to Color <ref type="bibr" target="#b5">[6]</ref>; 3. Sim to Real <ref type="bibr" target="#b65">[66]</ref>; 4. Apple to Orange <ref type="bibr" target="#b63">[64]</ref>; 5. Dark to Light <ref type="bibr" target="#b60">[61]</ref>; 6. Photo to Monnet <ref type="bibr" target="#b49">[50]</ref>; 7. GTA <ref type="bibr" target="#b53">[54]</ref> to Cityscapes <ref type="bibr" target="#b13">[14]</ref>; 8. Photo to Photo <ref type="bibr" target="#b47">[48]</ref>; 9. Hazy to Clear <ref type="bibr">[3,4])</ref> back to the original images during training. Although these methods have achieved impressive visual results in most applications, the cycle-consistency constraint failed to reproduce rich and complex semantic information, thus resulting in different levels of content distortion in translated images, especially in normally and strongly constrained translation settings.</p><p>In this work, we propose StyleFlow to address the problem of content distortion in I2I translation. Unlike previous methods which follow encoder-decoder scheme, StyleFlow utilizes the design of normalizing flow models <ref type="bibr" target="#b15">[16]</ref>, which consists of a series of fully invertible basic blocks, to achieve lossless image reconstruction. In addition, a novel Style-Aware Normalization (SAN) module is introduced to perform context-fixed feature transformation. Given source image features and target image features, SAN adjusts mean and variance of source features with learnable content-guided affine parameters to match the style of target input while preserve the content of source input. Considering that our model only consists of fully reversible transformation during feature extraction and reconstruction, pixel-level reconstruction loss is not required. Following most I2I translation tasks especially in style transfer <ref type="bibr" target="#b19">[20]</ref>, content loss and style loss calculated based on a pre-trained VGG encoder <ref type="bibr" target="#b57">[58]</ref> are adopted. We further extend the idea of style loss and introduce its simple extension named aligned-style loss, which takes the trade-off between content preservation and stylization into consideration, to further improve translation results especially when unpaired training images are provided.</p><p>We apply the proposed framework to a wide range of applications, plausible results (see <ref type="figure">Figure 1</ref>) indicate the significance and effectiveness of the designed modules in our method. We summarize the contributions of this work as below: 1) We divide image-to-image translation tasks into three subsets: strongly, normally and weakly constrained translation, according to the requirement of content preservation. 2) We propose StyleFlow, a novel model based on invertible network structure for content-fixed image-to-image translation, which is capable for unpair, multi-modal and multi-domain translation settings. 3) We design a novel Style-Aware Normalization module for efficient content-fixed feature transformation. 4) We demonstrate that StyleFlow outperforms previous methods with high content preservation and admirable stylization in extensive experiments. Generic Image-to-Image Translation: The previous generic I2I models can be divided into two categories: VAE-based <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b61">62]</ref> and GAN-based <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b10">11]</ref>. However, both of them surfer from the problem of content distortion, even though a lot of regularization methods have been proposed to reduce the impact, including cyclic consistency, self-reconstruction, etc. For weakly constrained translations, where the content can be heavily modified, these methods are appropriate, while for strongly constrained and normally constrained translations, they do not perform well. Our proposed model can be applied to both strongly constrained and normally constrained translations without the problem of content distortion.</p><p>Strongly Constrained Translation: Strongly constrained I2I translation means the content of the source image should be preserved to a great extent. Photorealism <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b12">13]</ref>, Colorization <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b7">8]</ref>, and Image Enhancement <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b31">32]</ref> belong to the strongly constrained setting. These problems require the translated images to retain the exact rich and complex content information in source images. To achieve high content preservation, previous methods require paired training images or auxiliary inputs such as semantic segmentation masks.</p><p>Normally Constrained Translation: Normally constrained I2I translation contains style transfer <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b1">2]</ref>, season and weather transfer <ref type="bibr" target="#b41">[42]</ref>, raindrop removal <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b55">56]</ref>, haze removal <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b18">19]</ref>, and image denoising <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b40">41]</ref>. In this setting, the source and target domains usually show different visual effects, such as weather conditions and artistic styles, but share similar structural information, the primary objective is to transfer the overall visual effects of source domains to match those in target domains. Previous work have shown plausible overall visual results in these tasks, while certain level of content distortion can be found when we zoom in to the details of translated images.</p><p>Weakly Constrained Translation: Weakly constrained I2I translation refers to problems where the source and target images may lie in completely different domains or modals, the translation is to be performed on a high semantic level, which means the content information of source images can be modified a lot. Label to image <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b30">31]</ref> and object to object translation <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b50">51]</ref> belong to this type of problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Normalizing Flow</head><p>Normalizing flow is a type of generative model that uses a sequence of invertible mappings to transform from distribution to distribution, and it is accurate and efficient in both density estimation and sampling <ref type="bibr" target="#b34">[35]</ref>. Dinh et al. <ref type="bibr" target="#b15">[16]</ref> first propose a flow-based generative model, NICE. After that, GLOW <ref type="bibr" target="#b33">[34]</ref>, RealNVP <ref type="bibr" target="#b16">[17]</ref>, FLOW++ <ref type="bibr" target="#b25">[26]</ref> are proposed to improve the sample efficiency and density estinmation performance. More recently, BeautyGLOW <ref type="bibr" target="#b8">[9]</ref> is proposed for makeup transfer. Besides, ArtFlow <ref type="bibr" target="#b0">[1]</ref> proves that the normalizing flow is unbiased in neural style transfer compared with the previous work. Our model is based on GLOW <ref type="bibr" target="#b33">[34]</ref> to achieve invertible transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>As shown in the <ref type="figure">Figure 2</ref>, we present StyleFlow, which consists of invertible normalizing flows and a novel Style-Aware Normalization (SAN) module to achieve content-fixed image-to-image translation. Following previous works, a pretrained and fixed VGG-19 encoder E V GG is utilized in our method for feature extraction and loss computation. As our model is invertible, we denote the forward pass as E, and the backward pass as E ?1 . Taking a source domain X and a target domain Y as an example. The forward pass of StyleFlow maps images from source domain into deep features, i.e. E : X ? F X , where F X is source feature space. The pretrained VGG encoder would map the target domain into a shared style space, i.e. E V GG : Y ? F S . Taking F X and F S as inputs, SAN module performs content-fixed feature transformation to obtain features in the stylized spaceF X . And the backward pass of StyleFlow generates translated images by mapping the stylized features back to the image space, i.e. E ?1 :F X ?X, whereX is assumed to share the style properties of Y while retain the content information of X.</p><p>In this section, we will first give a analysis on invertible mapping in section 3.1, then discuss the details of our proposed method in 3.2, and lastly, the loss function design in 3.3. The summary of components used in StyleFlow is shown in <ref type="table" target="#tab_2">Table 2</ref>.  </p><formula xml:id="formula_0">? ? ? ? w/o SAN ? ? w/o Flow ? ? w/o Aligned-Style Loss ? ? ?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Invertible Analysis</head><p>As shown in <ref type="figure" target="#fig_0">Figure 3</ref>, given source domain X and target domain Y , previous works (CycleGAN <ref type="bibr" target="#b63">[64]</ref>, MUNIT <ref type="bibr" target="#b29">[30]</ref>, DRIT <ref type="bibr" target="#b38">[39]</ref>, .etc.) use cycle consistency to regularize the forward-pass generator G and backward-pass generator F to become invertible in ideal situation. However, these models could not achieve fullyrevertible mapping. To achieve bijective mapping, Behrmann <ref type="bibr" target="#b6">[7]</ref> et al. has proposed an invertible resnet under Lipschitz constrain. Other works <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b33">34]</ref> create invertible architecture based on carefully-designed coupling or auto-regressive structures.</p><p>Based on nomalizing flow, in order to achieve a bijective mapping f : X ? Y , with a probability distribution p, we have the forward and backward transformation based on change of variable theory: where x ? X, y ? Y , and ?f (x) ?x is the jacobian of f at x. To achieve invertible transformation, the determinant of the jacobian matrix should not be zero. Given a set of invertible transformation g 1 , g 2 , ..., g n , the det| ?gi</p><formula xml:id="formula_1">p X (x) = p Y (f (x))|det ?f (x) ?x | (1) p Y (x) = p X (f (x))|det ?f (x) ?x | ?1 (2) cycle-consistency (a) (b)</formula><formula xml:id="formula_2">?x | (?i ? [1, n]) is non- zero. Therefore, n i=1 det| ?gi</formula><p>?x | is non-zero, which means the composition of g 1 to g n will form a more complex invertible transformation. Further explanations are out of the scope of this work, we refer readers to previous works <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref> for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">StyleFlow</head><p>Based on the effective invertible model GLOW <ref type="bibr" target="#b33">[34]</ref>, we proposed a novel model named StyleFlow for image to image translation. As shown in the <ref type="figure">Fig 2,</ref> our proposed model consists M blocks, each block is made up of a squeeze operation, N Flow Modules, and a novel Style-Aware Normalization (SAN) module. According to Sec 3.1, if each block is invertible, we can cascade multiple blocks for more complex reversible transformation.</p><p>A. Squeeze Operation serves as the inter-connection between blocks for feature reorganization. It reduces spatial size of feature map by first splitting input feature into smaller patches along spatial dimension and then concatenating patches along channel dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Flow Module consists of three reversible transformations: Actnorm layer, 1x1 Convolution layer and Coupling layer.</head><p>Actnorm refers to the activation normalization layer introduced in GLOW <ref type="bibr" target="#b33">[34]</ref>, which performs feature normalization along channel dimension. The forward and backward function can be written as:</p><formula xml:id="formula_3">y i,j = s ? x i,j + b (3) x i,j = (y i,j ? b)/s<label>(4)</label></formula><p>where i, j represents the spatial position of input tensor, s and b refer to the learnable affine parameters scale and bias.</p><p>Coupling layer is first proposed in NICE <ref type="bibr" target="#b15">[16]</ref> to achieve efficient invertible transformation. Given an input feature x ? R D , output feature y ? R D can be obtained with:</p><formula xml:id="formula_4">y 1:d = x 1:d (5) y d+1:D = g(x d+1:D , m(x 1:d ))<label>(6)</label></formula><p>where d splits x into two disjoint partitions along channel dimension, and g is called coupling function. In our model, we define g as a simple subtractive function:</p><formula xml:id="formula_5">y d+1:D = x d+1:D ? m(x 1:d )<label>(7)</label></formula><p>where m could be any neural network with input channel d and output channel D ? d, as m itself is not required to be invertible. With this design, the backward pass of the coupling layer can be easily derived as:</p><formula xml:id="formula_6">x 1:d = y 1:d (8) x d+1:D = y d+1:D + m(x 1:d )<label>(9)</label></formula><p>In despite of the simplicity of coupling layer, extensive experiments show that this subtractive coupling function is sufficient to produce favourable performance in our case.</p><p>Since the coupling layer splits input feature into two partitions, only one part of the feature is modified during transformation. To avoid this, we use the invertible 1x1 convolution layer in GLOW <ref type="bibr" target="#b33">[34]</ref> for channel permutation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Style-Aware Normalization Module</head><p>We proposed a novel Style-Aware Normalization (SAN) module to achieve content-fixed feature transformation. As the results shown in <ref type="bibr" target="#b28">[29]</ref>, in I2I translation, content and style are both spatial statistical information of images. To be more specific, content is the information that we would like to preserve during the transformation (e.g. shape, semantic information), while style is what we need to change to make the source image 'similar' to the target image (e.g. color, illumination, clarity). Content-fixed transfer means the content information before and after transformation should be retained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Content &amp; Style:</head><p>Following conventional definitions, given the extracted features in latent space of an image, content is defined as the channel-wise normalized term, while style can be expressed with its mean (?) and variance (?). In this work, we use normalizing flows to extract source images features and pre-trained VGG encoder to extract target image features. Thus, given source image x and target image y, content features f c and style features f s can be expressed as below:</p><formula xml:id="formula_7">f c = f x ? ?(f x ) ?(f x ) = E(x) ? ?(E(x)) ?(E(x))<label>(10)</label></formula><p>f s = concat(?(? 1 (y)), .., ?(? 4 (y)), ?(? 1 (y)), .., ?(? 4 (y)))</p><p>where E represents the forward pass of StyleFlow, ? 1 to ? 4 are middle layers (relu1 1, relu2 1, relu3 1, relu4 1) of pre-trained VGG19 encoder.</p><p>Module Details: Unlike AdaIN <ref type="bibr" target="#b28">[29]</ref> which directly computes ? and ? from the target image to transfer source features, our affine parameters are based on both source and target images. We argue that even for the same reference target image, different source images should use different affine parameters to help transferred images retain special content features of source images, we name them contentguided affine (CGA) parameters. As shown in <ref type="figure">Figure 2</ref>-A, mean (CGA ? ) and variance (CGA ? ) are obtained from source features and style features through a learnable network.</p><p>To summarize, given source image feature f x , and style feature f s , we have the transferred image featuref x :</p><formula xml:id="formula_9">f x = SAN (f x , f s ) = f x ? ?(f x ) ?(f x ) CGA(f x , f s ) ? + CGA(f x , f s ) ? (12)</formula><p>Proof of Fixed-Content: According to Eq 12, we have the following equation:</p><formula xml:id="formula_10">f x ? CGA(f x , f s ) ? CGA(f x , f s ) ? = f x ? ?(f x ) ?(f x )<label>(13)</label></formula><p>Since content is defined as the normalized term of image features, we hav?</p><formula xml:id="formula_11">f c =f x ? CGA(f x , f s ) ? CGA(f x , f s ) ? = f x ? ?(f x ) ?(f x ) = f c<label>(14)</label></formula><p>Therefore, the content of the transferred image featuref c is equal to the content of source image feature f c , which proves that our SAN module performs contentfixed feature transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Loss Function</head><p>Our loss function can be expressed as:</p><formula xml:id="formula_12">L = L c + ?L as + L smooth<label>(15)</label></formula><p>where L c is the content loss, L as is our proposed aligned-style loss, and ? is a weighting factor used to trade-off between content and style. L smooth is used to make the generated images smoother.</p><p>Content Loss: Following <ref type="bibr" target="#b28">[29]</ref>, the content loss is defined as the Euclidean distance between the channel-wise normalization of VGG features for the generated imagex and the source image x.</p><formula xml:id="formula_13">L c = ?norm(?(x)) ? norm(?(x))? 2<label>(16)</label></formula><p>where ? refers to the layer relu 4 1 of a pre-trained VGG-19 encoder, norm denotes the channel-wise normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aligned-Style Loss:</head><p>Considering that the semantic information extracted from VGG-19 of the source image and the target image are not exactly matched in unpaired translation, we extend the style loss in <ref type="bibr" target="#b28">[29]</ref> to be aligned-style loss by setting a parameter k to adjust the percentage of extracted tensors that are used for loss computation. We define S as an ascending sort function. Given a source image x, a target image y, and the transferred imagex, with an energy function</p><formula xml:id="formula_14">E(? i (x), ? i (y)) = ??(? i (x)) ? ?(? i (y))? 2 , where ? i (i ? L = {1, 2, 3}</formula><p>) represents a set of pre-trained VGG-19 layers {relu1 1, relu2 1, relu3 1}, we could have the chosen index:</p><formula xml:id="formula_15">C = {c ? N S |c ? kN, 0 &lt; k ? 1}<label>(17)</label></formula><p>where N S is the set of indexes of the sorted tensor S(E(? i (x), ? i (y))), N denotes its total length, and k is the weighting parameter. Therefore,</p><formula xml:id="formula_16">L as = L i=1 j?C ??(? i (x) j ) ? ?(? i (y) j )? 2 + L i=1 j?C ??(? i (x) j ) ? ?(? i (y) j )? 2<label>(18)</label></formula><p>where ? i (x) j denotes the j th channel of the output tensor of the i th layer from the set {relu1 1, relu2 1, relu3 1} of a pre-trained VGG-19 encoder.</p><p>Smooth Loss: To make the generated imagex smooth and natural as the target image y, we use the Structure-Aware Smoothness Loss proposed in Retinex-Net <ref type="bibr" target="#b60">[61]</ref> to improve visual coherence during translation.</p><p>L smooth = ||?x exp(?? smooth ?y)|| <ref type="bibr" target="#b18">(19)</ref> where ? indicates the gradients in both horizontal and vertical axes. ? smooth is the weight to adjust the smoothness. During the experiments, ? smooth is set to 10 by default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>To demonstrate the effectiveness of our method in strongly and normally constrained tasks, we use style transfer and photo-realism synthesis to show comparison between our proposed StyleFlow and other state-of-the-art methods of respective fields in this section. More results of various tasks can be found in supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>As shown in the <ref type="figure">Figure 2</ref>, our model consists of M blocks, each block consists of N flows. We use 2 blocks, and 15 flows in each block in the following experiments. The loss weight ? is set to 0.1. For style transfer task, the model was trained on single GTX 1080Ti 11G, with an Adam optimizer , an initial learning rate of 5e-5, and a batch size of 1, and k = {0.7, 0.8, 0.9}, for 100k iterations. For photo-realism task, the model was trained on two Tesla V100 32G, with an Adam optimizer , an initial learning rate of 5e-5, and a batch size of 1, and k = {0.6, 0.7, 0.8, 0.9}, for 100k iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Style Transfer [Normally Constrained]</head><p>Style transfer aims at transferring the artistic style from a reference image to a content image. This task provides a direct measure of the network's translation capability. We compare our method with the state-of-the-art universal style transfer algorithms, i.e. AdaIN <ref type="bibr" target="#b28">[29]</ref>, WCT <ref type="bibr" target="#b42">[43]</ref>, StyleSwap <ref type="bibr" target="#b11">[12]</ref> and ArtFlow <ref type="bibr" target="#b0">[1]</ref>.</p><p>Dataset: Following previous art-style transfer works, we use MS-COCO <ref type="bibr" target="#b44">[45]</ref> dataset and Wiki-Art <ref type="bibr" target="#b49">[50]</ref> dataset in our experiment. The MS-COCO is used as the source domain, while the Wiki-Art is used as the target domain. For training, the images are resized to 300?400. While for evaluation, all synthesized images are resized to 256?256.</p><p>Qualitative Evaluation: We show visual comparisons among different methods in <ref type="figure">Figure 4</ref>. WCT and StyleSwap can generate stylized images but with severe content distortion. AdaIN preserves content information to a certain extent but content distortion still exist when zoom into details. ArtFlow uses an invertible architecture similar to ours, but it directly perform feature transformation with AdaIN or WCT, which results in certain level of content loss in texture details. Our proposed SAN module performs content-fixed stylization to avoid this problem. As shown in the <ref type="figure">Figure 4</ref>, our results not only have great stylistic effects, but also achieve the best retention of content information.</p><p>Quantitative Evaluation: Following <ref type="bibr" target="#b27">[28]</ref>, we evaluates the stylized images quantitatively using SSIM and style loss, where Structural Similarity Index (SSIM) indicates the performance of content preservation, style loss measures  the similarity between the transferred image and the target image. As shown in the <ref type="figure">Figure 5</ref>, our model with k = 0.9 achieves the best performance. As the k increases, our model could have better style loss score, but would have a trade-off in content preservation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Photo-Realism [Strongly Constrained]</head><p>Simulation environments have been widely used in many fields. Synthesizing realistic images from simulated environments is a very challenging task. Photorealism synthesis aims to translate simulated images to realistic images. In this task, we select several state-of-the-art generic I2I models and a specific photorealism model EPE <ref type="bibr" target="#b52">[53]</ref> for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset:</head><p>We use GTA V dataset <ref type="bibr" target="#b53">[54]</ref> as the source images, and use Cityscapes <ref type="bibr" target="#b13">[14]</ref> and KITTI <ref type="bibr" target="#b21">[22]</ref> for real images. For translation from GTA to Cityscapes, all the images are resized to 800?1000. For translation from GTA to KITTI, images from KITTI are croped with 300?400, and then resized to 800?1000, in order to get better alignment in image resolution.</p><p>Qualitative Evaluation: As shown in the <ref type="figure">Figure 6</ref>, all previous I2I models fail to retain full content information, different levels of content distortion exist. EPE uses an auxiliary segmentation task to help keep the content. However, it still hallucinates trees on building/sky. Our model achieves content-fixed translation without extra information. (More details are shown in the orange box and blue box in the <ref type="figure">Figure 6</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 6.</head><p>Our results compared with several baselines. As shown in the orange and blue box, our method greatly preserves the content information. (a) Translation from GTA to Cityscapes. EPE <ref type="bibr" target="#b52">[53]</ref>, CycleGAN <ref type="bibr" target="#b17">[18]</ref>, and CUT <ref type="bibr" target="#b50">[51]</ref> turn the color of the vehicle from white to black and generate trees in the sky. (b) Translation from GTA to KITTI. Both DRIT++ <ref type="bibr" target="#b39">[40]</ref> and UNIT <ref type="bibr" target="#b45">[46]</ref> fail to keep the semantic information. MUNIT <ref type="bibr" target="#b64">[65]</ref> makes everything blurry. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Inference. As shown in the <ref type="figure">Figure 7,</ref>   <ref type="figure">Fig. 7</ref>. Inference Overview.</p><p>GTA Cityscapes KITTI <ref type="figure">Fig. 8</ref>. Unpaired multi-domain image-to-image translation from GTA <ref type="bibr" target="#b53">[54]</ref> to Cityscapes <ref type="bibr" target="#b13">[14]</ref> and GTA to KITTI <ref type="bibr" target="#b21">[22]</ref>. to the limitation of paper length.</p><p>Multi-domain Image Translation. In section 4.3, our model is trained in a multi-domain image translation manner to perform translation from GTA to Cityscapes and GTA to KITTI at the same time. As shown in <ref type="figure">Figure 8</ref>, our model did learn how to transfer source images to different styles for different domains, while maintaining high content preservation for each output.</p><p>Multi-modal Image Synthesis. <ref type="figure">Figure 9</ref> indicates the ability for multi-modal synthesis of our method. Training only on a single model, our method effectively generates diverse outputs with the same style properties, and keeps photorealistic generation quality in each output. Top line indicates diverse synthesis from summer to winter. Bottom line indicates translation from dark to different level of brightness. Ablation Study. As shown in the <ref type="figure">Figure 10</ref>, we conduct ablation study to verify the effectiveness of our loss functions, using translation from GTA to KITTI as an example. Without smooth loss, the generated images would have gird-like noises. Without the aligned-style loss (L as ), the overall visual effect is reduced, which makes the generated images look unrealistic. Content loss (L c ) is used to preserve the semantic information, without this term, the generated images can become distorted and over-stylized.</p><p>Limitation. Although our model outperforms previous methods in strongly and normally constrained tasks, we failed to achieve admirable results in all weakly constrained translation tasks. Future work includes extending this model to weakly constrained setting. Broader Impact. Our proposed generative model could be used as a tool to further eliminate the gap between simulation and reality, which can be widely used in self-driving and medical areas. The use of image synthesis would not lead to privacy issues, but might create fake news. More efforts are needed in the future to develop regulations to restrict the usage of synthesized data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we categorize image-to-image translation problem into three tasks: strongly constrained translation, normally constrained translation and weakly constrained translation. We proposed an invertible network StyleFlow, with Style-Aware Normalization (SAN) module for content-fixed image-to-image translation. We have proved that our method can achieve full content preservation during translation. Qualitative and quantitative results show that our model is more suitable for strongly and normally constrained translation, while the previous work have better performance on weakly constrained translation.</p><p>Source Output Reference <ref type="figure">Fig. 11</ref>. Image-guided style transfer results from MS-COCO <ref type="bibr" target="#b44">[45]</ref> to WikiArt <ref type="bibr" target="#b49">[50]</ref> Target Source Ours StyleSwap ArtFlow(AdaIN) ArtFlow(WCT) WCT AdaIN <ref type="figure">Fig. 12</ref>. Comparison on style transfer from MS-COCO <ref type="bibr" target="#b44">[45]</ref> to WikiArt <ref type="bibr" target="#b49">[50]</ref> between StyleFlow and the previous methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source</head><p>Output Reference <ref type="figure" target="#fig_0">Fig. 13</ref>. Image guided photo-realism on GTA <ref type="bibr" target="#b53">[54]</ref> to Cityscapes <ref type="bibr" target="#b13">[14]</ref> and GTA to KITTI <ref type="bibr" target="#b21">[22]</ref>.</p><p>Source Output <ref type="figure">Fig. 14.</ref> Results on photo-realism from GTA <ref type="bibr" target="#b53">[54]</ref> to Cityscapes <ref type="bibr" target="#b13">[14]</ref> by sampling-based inference.   Source Output <ref type="figure">Fig. 19</ref>. Translation from summer to winter <ref type="bibr" target="#b63">[64]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dar k Light</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source</head><p>Output Ground Truth <ref type="figure">Fig. 20</ref>. Results on image dehazing. <ref type="bibr" target="#b2">[3]</ref> Source Output Ground Truth <ref type="figure">Fig. 21</ref>. Results on image enhancement <ref type="bibr" target="#b60">[61]</ref>.</p><p>Source Output Ground Truth <ref type="figure">Fig. 22</ref>. Results on colorization <ref type="bibr" target="#b5">[6]</ref>.</p><p>Source Output Reference <ref type="figure" target="#fig_0">Fig. 23</ref>. Results on translation from sim to real <ref type="bibr" target="#b65">[66]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>(a). Previous work try to make mapping G and F inverse to each other by using cycle-consistency loss. (b). Our model use a revertible mapping G to map from X to Y , and its inverted function G ?1 would map from Y back to X exactly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Style transfer results compared with the state-of-the-art style transfer methods. Quantitative results of art-style transfer. SSIM index (higher is better) versus Style Loss (lower is better). Ideal case for art-style transfer is at the top-left corner (green star ?). Red dots indicate our results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>Unpaired diverse image-to-image translation. (Top) Multi-modality image to image translation from summer to winter[64]. (Bottom) Multi-modality image to image translation from dark to light[61] Ablation study of different loss functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 15 .</head><label>15</label><figDesc>Continuous outputs from one single model for dark-to-light translation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 16 .</head><label>16</label><figDesc>Diverse outputs for edges-to-shoes translation. content style o u t p u t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 17 .Fig. 18 .</head><label>1718</label><figDesc>Diverse outputs for arbitrary style transfer. source reference output Translation from edges to shoes[?],[?]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Feature comparison of I2I models.</figDesc><table><row><cell>Method</cell><cell cols="5">Unpaired Multimodal Multi-domain Invertible Parameters</cell></row><row><cell>StyleFlow</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>16.78 M</cell></row><row><cell>DRIT++[40]</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell>18.58 M</cell></row><row><cell>MUNIT[30]</cell><cell>?</cell><cell>?</cell><cell></cell><cell></cell><cell>30.05 M</cell></row><row><cell>UNIT[46]</cell><cell>?</cell><cell></cell><cell></cell><cell></cell><cell>22.28 M</cell></row><row><cell>CycleGAN[64]</cell><cell>?</cell><cell></cell><cell></cell><cell></cell><cell>11.38 M</cell></row><row><cell>CUT[51]</cell><cell>?</cell><cell></cell><cell></cell><cell></cell><cell>11.38 M</cell></row><row><cell cols="2">2 Related Work</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>2.1 Image-to-Image Translation</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Summary of components used in StyleFlow.</figDesc><table /><note>Module Unpaired Multimodal Multi-domain Invertible StyleFlow</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Comparison with the previous work on translation from GTA to Cityscapes and GTA to KITTI. SSIM(higher is better), KID(lower is better), and FID(lower is better) are used for evaluation. Data in bold indicates the best performance. Kernel Inception Distance) as evaluation metrics. Same as the previous experiment, the SSIM is used to measure the performance of content preservation. While FID and KID measure difference between two image distributions. Results intable 3indicate the superiority of our model over previous methods.</figDesc><table><row><cell>Dataset</cell><cell>Method Ours-0.9</cell><cell>Ours-0.8</cell><cell>Ours-0.7</cell><cell>Ours-0.6</cell><cell cols="2">CycleGAN[18] MUNIT[65]</cell><cell cols="2">DRIT++[40] CUT[51]</cell><cell>UNIT[46]</cell><cell>EPE[53]</cell></row><row><cell cols="2">GTA? Cityscapes SSIM? 0.78</cell><cell>0.81</cell><cell>0.84</cell><cell>0.87</cell><cell>0.71</cell><cell>0.60</cell><cell>0.14</cell><cell>0.71</cell><cell>0.22</cell><cell>0.8</cell></row><row><cell></cell><cell cols="10">KID? 0.0432/0.0048 0.0451/0.0053 0.0467/0.0057 0.0566/0.0058 0.0483/0.0044 0.0868/0.0067 0.1113/0.0061 0.0390/0.0044 0.0908/0.0073 0.0409/0.0046</cell></row><row><cell></cell><cell>FID? 0.44</cell><cell>0.47</cell><cell>0.48</cell><cell>0.58</cell><cell>12.51</cell><cell>18.7</cell><cell>3.03</cell><cell>5.04</cell><cell>11.34</cell><cell>0.89</cell></row><row><cell>GTA? KITTI</cell><cell>SSIM? 0.72</cell><cell>0.74</cell><cell>0.78</cell><cell>0.82</cell><cell>0.76</cell><cell>0.58</cell><cell>0.08</cell><cell>0.63</cell><cell>0.11</cell><cell>/</cell></row><row><cell></cell><cell cols="10">KID? 0.0714/0.0056 0.0748/0.0060 0.0775/0.0077 0.0809/0.0070 0.0837/0.0087 0.1015/0.0084 0.1382/0.0102 0.0832/0.0097 0.1352/0.0103 /</cell></row><row><cell></cell><cell>FID? 3.30</cell><cell>3.48</cell><cell>3.86</cell><cell>3.95</cell><cell>11.15</cell><cell>37.52</cell><cell>4.94</cell><cell>5.16</cell><cell>10.82</cell><cell>/</cell></row><row><cell cols="11">ods, we used SSIM (Structural Similarity Index), FID (Frechet Inception Dis-</cell></row><row><cell cols="2">tance) and KID (</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>for inference, our model supports both image-guided image to image translation and sampling-based image to image translation. For sampling-based inference, the style code is sampled from learned latent distribution. Further details are provided in supplementary materials, due</figDesc><table><row><cell></cell><cell>SAN</cell></row><row><cell></cell><cell>Given</cell></row><row><cell></cell><cell>Style</cell></row><row><cell>Image</cell><cell></cell></row><row><cell>Guided</cell><cell>Unseen</cell></row><row><cell></cell><cell>Style</cell></row><row><cell>Sampling</cell><cell></cell></row><row><cell>Based</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Artflow: Unbiased image style transfer via reversible neural flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibing</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejing</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="862" to="871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ultrafast photorealistic style transfer via neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Huan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10443" to="10450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dense haze: A benchmark for image dehazing with dense-haze and haze-free images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Codruta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cosmin</forename><surname>Ancuti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateu</forename><surname>Ancuti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing (ICIP), IEEE ICIP 2019</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ntire 2019 image dehazing challenge report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cosmin</forename><surname>Codruta O Ancuti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Ancuti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, IEEE CVPR 2019</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops, IEEE CVPR 2019</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Dehaze-glcgan: unpaired single image dehazing via adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahra</forename><surname>Anvari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassilis</forename><surname>Athitsos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.06632</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Tahir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajmal</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdul</forename><forename type="middle">Wahab</forename><surname>Muzaffar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.10774</idno>
		<title level="m">Image colorization: A survey and dataset</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Invertible residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rn-Henrik</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jacobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="573" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised diverse colorization via generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European conference on machine learning and knowledge discovery in databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="151" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Beautyglow: On-demand makeup transfer framework with reversible generative network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Jen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ka-Ming</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Szu-Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Wu</forename><surname>Tsao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Han</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Huang</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10042" to="10050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Photographic image synthesis with cascaded refinement networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reusing discriminators for encoding: Towards unsupervised image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runfa</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binghui</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8168" to="8177" />
		</imprint>
	</monogr>
	<note>Fuchun Sun, and Bin Fang</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Fast patch-based style transfer of arbitrary style</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Tian Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.04337</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sem-gan: Semantically-consistent image-toimage translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1797" to="1806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning diverse image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mao-Chuang</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><forename type="middle">Jin</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6837" to="6845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Nice: Non-linear independent components estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.08803</idno>
		<title level="m">Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cycle-dehaze: Enhanced cyclegan for single image dehazing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deniz</forename><surname>Engin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil</forename><surname>Gen?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hazim Kemal</forename><surname>Ekenel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="825" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Single image dehazing using endto-end deep-dehaze network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masud An-Nur Islam</forename><surname>Fahim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><surname>Ho Yub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">817</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Texture synthesis using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">S</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="262" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image style transfer using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><forename type="middle">A</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">S</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The kitti vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Urtasun</surname></persName>
		</author>
		<ptr target="http://www.cvlibs.net/datasets/kitti" />
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Arbitrary style transfer with deep feature reshuffle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8222" to="8231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07208</idno>
		<title level="m">Pixcolor: Pixel recursive colorization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Toward convolutional blind denoising of real photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifei</forename><surname>Shi Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1712" to="1722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Flow++: Improving flow-based generative models with variational dequantization and architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2722" to="2730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1989" to="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Domainaware universal style transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibeom</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seogkyu</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeran</forename><surname>Byun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021-10" />
			<biblScope unit="page" from="14609" to="14617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Arbitrary style transfer in real-time with adaptive instance normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1501" to="1510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multimodal unsupervised image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="172" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1125" to="1134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Enlightengan: Deep light enhancement without paired supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2340" to="2349" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to discover cross-domain relations with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taeksoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moonsu</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunsoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1857" to="1865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhariwal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03039</idno>
		<title level="m">Glow: Generative flow with invertible 1x1 convolutions</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Normalizing flows: An introduction and review of current methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Kobyzev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Brubaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manoj</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.04432</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">Colorization transformer. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep laplacian pyramid networks for fast and accurate super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Sheng</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narendra</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Huszar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Diverse image-to-image translation via disentangled representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maneesh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="35" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Drit++: Diverse image-to-image translation via disentangled representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ding</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maneesh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2402" to="2417" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Munkberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Hasselgren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miika</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.04189</idno>
		<title level="m">Noise2noise: Learning image restoration without clean data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Weather gan: Multi-domain weather translation using generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuelong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Kou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.05422</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08086</idno>
		<title level="m">Universal style transfer via feature transforms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Conditional image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5524" to="5532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised image-to-image translation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="700" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Llnet: A deep autoencoder approach to natural low-light image enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adedotun</forename><surname>Kin Gwn Lore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumik</forename><surname>Akintayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="650" to="662" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep photo style transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fujun</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavita</forename><surname>Bala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4990" to="4998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Exemplar guided unsupervised image-to-image translation with semantic consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqian</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.11145</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Painter by numbers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nichol</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/c/painter-by-numbers" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Contrastive learning for unpaired image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="319" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Attentive generative adversarial network for raindrop removal from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2482" to="2491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Abu Alhaija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.04619</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">Enhancing photorealism enhancement. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Stephan R Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="102" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Residual learning of deep convolutional neural networks for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanhui</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xirong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Ou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent &amp; Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2809" to="2818" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Selective generative adversarial network for raindrop removal from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingwen</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">426</biblScope>
			<biblScope unit="page" from="265" to="273" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Avatar-net: Multi-scale zeroshot style transfer by feature decoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8242" to="8250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">High-resolution image synthesis and semantic manipulation with conditional gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Chun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Diversified arbitrary style transfer via deep feature perturbation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qihang</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sihuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongming</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7789" to="7798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Deep retinex decomposition for low-light enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.04560</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Transgaga: Geometry-aware unsupervised image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8012" to="8021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Dualgan: Unsupervised dual learning for image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zili</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minglun</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2849" to="2857" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Unpaired imageto-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2223" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Multimodal image-to-image translation by enforcing bi-cycle consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="465" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Surgical visual domain adaptation: Results from the miccai 2020 surgvisdom challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aneeq</forename><surname>Zia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiran</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Colleoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Van Amsterdam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razeen</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raabid</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lena</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.13644</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
