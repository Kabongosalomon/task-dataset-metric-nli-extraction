<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Parametric Contrastive Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
							<email>jqcui@cse.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<addrLine>Kong 2 SmartMore</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
							<email>zszhong21@cse.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<addrLine>Kong 2 SmartMore</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<addrLine>Kong 2 SmartMore</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<addrLine>Kong 2 SmartMore</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<addrLine>Kong 2 SmartMore</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Parametric Contrastive Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T19:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose Parametric Contrastive Learning (PaCo) to tackle long-tailed recognition. Based on theoretical analysis, we observe supervised contrastive loss tends to bias on high-frequency classes and thus increases the difficulty of imbalanced learning. We introduce a set of parametric class-wise learnable centers to rebalance from an optimization perspective. Further, we analyze our PaCo loss under a balanced setting. Our analysis demonstrates that PaCo can adaptively enhance the intensity of pushing samples of the same class close as more samples are pulled together with their corresponding centers and benefit hard example learning. Experiments on long-tailed CIFAR, ImageNet, Places, and iNaturalist 2018 manifest the new state-of-the-art for longtailed recognition. On full ImageNet, models trained with PaCo loss surpass supervised contrastive learning across various ResNet backbones, e.g., our ResNet-200 achieves 81.8% top-1 accuracy.</p><p>Our code is available at https://github.com/dvlab-research/ Parametric-Contrastive-Learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Convolutional neural networks (CNNs) have achieved great success in various tasks, including image classification <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b42">43]</ref>, object detection <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b33">34]</ref> and semantic segmentation <ref type="bibr" target="#b54">[55]</ref>. With neural network search <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b3">4]</ref>, performance of CNNs further boosts. Impressive progress highly depends on large-scale and high-quality datasets, such as ImageNet <ref type="bibr" target="#b39">[40]</ref>, MS COCO <ref type="bibr" target="#b31">[32]</ref> and Places <ref type="bibr" target="#b58">[59]</ref>. When dealing with real-world applications, generally we face the long-tailed distribution problem -a few classes contain many instances, while most classes contain only a few instances. Learning in such an imbalanced setting is challenging as the low-frequency classes can be easily overwhelmed by high-frequency ones. Without considering this situation, CNNs will suffer from significant performance degradation.  <ref type="bibr" target="#b34">[35]</ref>. Inference time is calculated with a batch of 64 images on Nvidia GeForce 2080Ti GPU. The same experimental setting is adopted for comparison. ResNet-50, ResNeXt-50, and ResNeXt101 are used for Balanced Softmax <ref type="bibr" target="#b37">[38]</ref>, Decouple <ref type="bibr" target="#b27">[28]</ref>, and PaCo. For RIDE <ref type="bibr" target="#b48">[49]</ref>, various numbers of expert with RIDEResNet and RIDEResNeXt are adopted. PaCo significantly outperforms recent SOTA. Detailed numbers for RIDE is in the supplementary file.</p><p>Contrastive learning <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b6">7]</ref> is a major research topic due to its success in self-supervised representation learning. Khosla et al. <ref type="bibr" target="#b28">[29]</ref> extend non-parametric contrastive loss into non-parametric supervised contrastive loss by leveraging label information, which trains representation in the first stage and learns the linear classifier with the fixed backbone in the second stage. Though supervised contrastive learning works well in a balanced setting, for imbalanced datasets, our theoretical analysis shows that highfrequency classes will have a higher lower bound of loss and contribute much higher importance than low-frequency classes when equipping it in training.</p><p>This phenomenon leads to model bias on high-frequency classes and increases the difficulty of imbalanced learning. As shown in <ref type="figure">Fig. 2</ref>, when the model is trained with supervised contrastive loss on ImageNet-LT, the gradient norm varying from the most frequent class to the least one is rather steep. In particular, the gradient norm dramatically decreases for the top 200 most frequent classes.</p><p>Previous work <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b56">57]</ref>   <ref type="figure">Figure 2</ref>: Rebalance in contrastive learning. We collect the average L2 norm of the gradient of weights in the last classifier layer on ImageNet-LT. Category indices are sorted by their image counts. The gradient norm varying from the most frequent class to the least one is steep for supervised contrastive learning <ref type="bibr" target="#b28">[29]</ref>. In particular, the gradient norm dramatically decreases for the top 200 most frequent classes. Trained with PaCo, the gradient norm is better balanced. entropy learning. In this paper, we tackle the above mentioned imbalance issue in supervised contrastive learning and make use of contrastive learning for long-tailed recognition. To our knowledge, it is the first attempt of using rebalance in contrastive learning.</p><p>To rebalance in supervised contrastive learning, we introduce a set of parametric class-wise learnable centers into supervised contrastive learning. We name our algorithm Parametric Contrastive Learning (PaCo) shown in <ref type="figure">Fig. 3</ref>. With such a simple and yet effective operation, we theoretically prove that the optimal values for the probability that two samples are a true positive pair (belonging to the same class), varying from the most frequent class to the least frequent class, are more balanced. Thus their lower bound of loss values are better organized. This phenomenon means the model takes more care of low-frequency classes, making the PaCo loss benefit imbalanced learning. <ref type="figure">Fig. 2</ref> shows that, with our PaCo loss in training, gradient norm varying from the most frequent class to the least one are moderated better than supervised contrastive learning, which matches our analysis.</p><p>Further, we analyze the PaCo loss under a balanced setting. Our analysis demonstrates that with more samples clustered around their corresponding centers in training, the PaCo loss increases the intensity of pushing samples of the same class close, which benefits hard examples learning.</p><p>Finally, we conduct experiments on long-tailed version of CIFAR <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b4">5]</ref>, ImageNet <ref type="bibr" target="#b34">[35]</ref>, Places <ref type="bibr" target="#b34">[35]</ref> and iNaturalist 2018 <ref type="bibr" target="#b47">[48]</ref>. Experimental results show that we create a new record for long-tailed recognition. We also conduct experiments on full ImageNet <ref type="bibr" target="#b39">[40]</ref> and CIFAR <ref type="bibr" target="#b29">[30]</ref>. ResNet models trained with PaCo also outperform the ones by supervised contrastive learning on such balanced datasets. Our key contributions are as follows.</p><p>? We identify the shortcoming of supervised contrastive learning under an imbalanced setting -it tends to bias towards high-frequency classes.</p><p>? We extend supervised contrastive loss to the PaCo loss, which is more friendly to imbalance learning, by introducing a set of parametric class-wise learnable centers.</p><p>? Equipped with the PaCo loss, we create new record across various benchmarks for long-tailed recognition. Moreover, experimental results on full ImageNet and CIFAR validate the effectiveness of PaCo under a balanced setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Re-sampling/re-weighting. The most classical way to deal with long-tailed datasets is to over-sample lowfrequency class images <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref> or under-sample highfrequency class images <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b1">2]</ref>. However, Oversampling can suffer from heavy over-fitting to low-frequency classes especially on small datasets. For under-sampling, discarding a large portion of high-frequency class data inevitably causes degradation of the generalization ability of CNNs. Re-weighting <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b25">26]</ref> the loss functions is an alternative way to rebalance by either enlarging weights on more challenging and sparse classes or randomly ignoring gradients from high-frequency classes <ref type="bibr" target="#b43">[44]</ref>. However, with large-scale data, re-weighting makes CNNs difficult to optimize during training <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>.</p><p>One/two-stage Methods. Since deferred re-weighting and re-sampling were proposed by Cao et al. <ref type="bibr" target="#b4">[5]</ref>, Kang et al. <ref type="bibr" target="#b27">[28]</ref> and Zhou et al. <ref type="bibr" target="#b57">[58]</ref> observed re-weighting or re-sampling strategies could benefit classifier learning while hurting representation learning. Kang et al. <ref type="bibr" target="#b27">[28]</ref> proposed to decompose representation and classifier learning. It first trains the CNNs with uniform sampling, and then fine-tune the classifier with class-balanced sampling while keeping parameters of representation learning fixed. Zhou et al. <ref type="bibr" target="#b57">[58]</ref> proposed one cumulative learning strategy, with which they bridge representation learning and classifier re-balancing. The two-stage design is not for end-to-end frameworks. Tang et al. <ref type="bibr" target="#b45">[46]</ref> analyzed the reason from the perspective of causal graph and concluded that the bad momentum causal effects played a vital role. Cui et al. <ref type="bibr" target="#b13">[14]</ref> proposed residual learning mechanism to address this issue.</p><p>Non-parametric Contrastive Loss. Contrastive learning <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b6">7</ref>] is a framework that learns similar/dissimilar representations from data that are organized into similar/dissimilar pairs. An effective contrastive loss function, called InfoNCE <ref type="bibr" target="#b46">[47]</ref>, is</p><formula xml:id="formula_0">L q,k + ,{k ? } = ? log exp(q?k + /? ) exp(q?k + /? ) + k ? exp(q?k ? /? ) ,<label>(1)</label></formula><p>where q is a query representation, k + is for the positive (similar) key sample, and {k ? } denotes negative (dissimilar) key samples. ? is a temperature hyper-parameter. In the instance discrimination pretext task <ref type="bibr" target="#b52">[53]</ref> for self-supervised learning, a query and a key form a positive pair if they are data-augmented versions of the same image. It forms a negative pair otherwise.</p><p>Traditional cross-entropy with linear fc layer weight w and true label y among n classes is expressed as</p><formula xml:id="formula_1">L cross?entropy = ? log exp(q?w y ) n i=1 exp(q?w i ) .<label>(2)</label></formula><p>Compared to it, InfoNCE does not get involved with parametric learnable parameters. To distinguish our proposed parametric contrastive learning from previous ones, we treat the InfoNCE as a non-parametric contrastive loss following <ref type="bibr" target="#b53">[54]</ref>.</p><p>Chen et al. <ref type="bibr" target="#b8">[9]</ref> used self-supervised contrastive learning SimCLR to first match the performance of a supervised ResNet-50 with only a linear classifier trained on selfsupervised representation on full ImageNet. He et al. <ref type="bibr" target="#b20">[21]</ref> proposed MoCo and Chen et al. <ref type="bibr" target="#b9">[10]</ref> extended MoCo to MoCo v2, with which small batch size training can also achieve competitive results on full ImageNet <ref type="bibr" target="#b39">[40]</ref>. In addition, many other methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b6">7]</ref> are also proposed to further boost performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Parametric Contrastive Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Supervised Contrastive Learning</head><p>Khosla et al. <ref type="bibr" target="#b28">[29]</ref> extended the self-supervised contrastive loss with label information into supervised contrastive loss. Here we present it in the framework of MoCo <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b9">10]</ref> as</p><formula xml:id="formula_2">L i = ? z+?P (i) log exp(z + ? T (x i )) z k ?A(i) exp(z k ? T (x i ))</formula><p>.</p><p>MoCo framework <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b9">10]</ref> consists of two networks with the same structure, i.e., query network and key network. The key network is driven by a momentum update with the query network in training. For each network, it usually contains one encoder CNN and one two-layer MLP transform.</p><p>During training, for one two-viewed image batch B = (B v1 , B v2 ) and label y, B v1 and B v2 are fed into the query network and key network respectively and we denote their outputs as Z v1 and Z v2 . Especially, Z v2 is used to update the momentum queue. In Eq. (3), x i is the representation for image X i in B v1 obtained by the encoder of query network. The transform T (?) also belongs to the query network. We write</p><formula xml:id="formula_4">A(i) = {z k ? queue ? Z v1 ? Z v2 }\{z k ? Z v1 : k = i}, P (i) = {z k ? A(i) : y k = y i }.</formula><p>In implementation, the loss is usually scaled by 1 |P (i)| and a temperature ? is applied like in Eq. (1). Different from self-supervised contrastive loss, which treats query and key as a positive pair if they are the data-augmented version of the same image, supervised contrastive loss treats them as one positive pair if they belong to the same class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Theoretical Motivation</head><p>Analysis of Supervised Contrastive Learning. Khosla et al. <ref type="bibr" target="#b28">[29]</ref> introduced supervised contrastive learning to encourage more compact representation. We observe that it is not directly applicable to long-tailed recognition. As shown in <ref type="table" target="#tab_0">Table 1</ref>, the performance significantly decreases compared with traditional supervised cross-entropy. From an optimization point of view, supervised contrastive loss concentrates more on high-frequency classes than low-frequency ones, which is unfriendly for imbalanced learning.</p><p>Remark 1 (Optimal value for supervised contrastive learning). When supervised contrastive loss converges, the optimal value for the probability that two samples are a true positive pair with label y is 1 K y , where, q(y) is the frequency of class y over the whole dataset, queue is the momentum queue in MoCo <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b9">10]</ref> and K y ? length(queue) ? q(y).</p><p>Interpretation. As indicated by Remark 1, highfrequency classes have a higher lower bound of loss value and contribute much higher importance than low-frequency classes in training. Thus the training process can be dominated by high-frequency classes. To handle this issue, we introduce a set of parametric class-wise learnable centers for rebalancing in contrastive learning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Rebalance in Contrastive Learning</head><p>As described in <ref type="figure">Fig. 3</ref>, we introduce a set of parametric class-wise learnable centers C = {c 1 , c 2 , ..., c n } into the original supervised contrastive learning, and call this new form Parametric Contrastive Learning (PaCo). Correspondingly, the loss function is changed to</p><formula xml:id="formula_5">L i = z+?P (i)?{cy} ?w(z + ) log exp(z + ? T (x i )) z k ?A(i)?C exp(z k ? T (x i )) ,<label>(4)</label></formula><formula xml:id="formula_6">where w(z + ) = ?, z + ? P (i) 1.0, z + ? {c y } and z ? T (x i ) = z ? G(x i ), z ? A(i) z ? F(x i ), z ? C.</formula><p>Following Chen et al. <ref type="bibr" target="#b9">[10]</ref>, the transform G(?) is a twolayer MLP while F(?) is the identity mapping, i.e., F(x) = x. ? is one hyper-parameter in (0, 1). P (i) and A(i) are the same with supervised contrastive learning in Eq. (3). In implementation, the loss is scaled by 1 z+?P (i)?{cy} w(z + ) and a temperature ? is applied like that in Eq. (3).</p><p>Remark 2 (Optimal value for parametric contrastive learning) When parametric contrastive loss converges, the optimal value for the probability that two samples are a true positive pair with label y is ? 1 + ? ? K y and the optimal value for the probability that a sample is closest to its corresponding center c y among C is</p><formula xml:id="formula_7">1 1 + ? ? K y , where q(y)</formula><p>is the frequency of class y over the whole dataset, queue is the momentum queue in MoCo <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b9">10]</ref> and K y ? length(queue) ? q(y).</p><p>Interpretation. Suppose the most frequent class y h has K y h ? q(y h ) ? length(queue) and the least frequent class y t has K yt ? q(y t ) ? length(queue). As indicated by Remarks 2 and 1, the optimal value for the probability that two samples are a true positive pair varying from the most frequent class to the least one is rebalanced from</p><formula xml:id="formula_8">1 K y h ?? 1 K yt to 1 1 ? + K y h ?? 1 1 ? + K yt .</formula><p>The smaller ? is, the more uniform the optimal value from the most frequent class to the least one is, friendly to low-frequency classes learning.</p><p>However, when ? decreases, the intensity of contrast among samples becomes weaker, the intensity of contrast between samples and centers is stronger. The whole loss becomes closer to supervised cross-entropy. To make good use of contrastive learning and rebalance at the same time, we observe that ?=0.05 is a reasonable choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">PaCo under Balanced Setting</head><p>For balanced datasets, all classes have the same frequency, i.e., q * =q(y i )=q(y j ) and K * =K yi =K yj for any class y i and class y j . In this case, PaCo reduces to an improved version of multi-task with the weighted sum of supervised cross-entropy loss and supervised contrastive loss. The connection between PaCo and multi-task is</p><formula xml:id="formula_9">ExpSum = c k ?C exp(c k ?F(x i )) + z k ?A(i) exp(z k ? G(x i )).</formula><p>We also write the PaCo loss as</p><formula xml:id="formula_10">L i = z+?P (i)?{cy} ?w(z + ) log exp(z + ? T (x i )) z k ?A(i)?C exp(z k ? T (x i )) = ? log exp(c y ? F(x i )) ExpSum ? ? z+?P (i) log exp(z + ? G(x i )) ExpSum = L sup +?L supcon ?(log P sup +?K * log P supcon ) = L sup +?L supcon ?(log P sup +?K * log(1 ? P sup )) , where ? ? ? ? ? ? ? ? ? P sup = c k ?C exp(c k ?F(x i )) ExpSum ; P supcon = z k ?A(i) exp(z k ? G(x i )) ExpSum .<label>(5)</label></formula><p>Multi-task learning combines supervised cross-entropy loss and supervised contrastive loss with a fixed weighted scalar. When these two losses conflict, training can suffer from slow convergence or sub-optimization. Our PaCo contrarily adjusts the intensity of supervised cross-entropy loss and supervised contrastive loss in an adaptive way and potentially avoids conflict as analyzed in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Analysis of PaCo under Balanced Setting</head><p>As indicated by Eq. (5), compared with multi-task, PaCo has an additional loss item of</p><formula xml:id="formula_11">L extra = ? log(P sup ) ? ?K * log(1 ? P sup ).<label>(6)</label></formula><p>Here, we take full ImageNet as an example, i.e., q * = 0.001, length(queue) = 8192, ? = 0.05, and ?K * = 0.41. Then the function curve for L extra is shown in <ref type="figure">Fig. 4</ref>. With P sup increases from 0 to 1.0, the function value decreases until P sup = 0.71 and then goes up, which implies L extra obtains the smallest loss value when P sup = 0.71. Note that, when the whole PaCo loss in Eq. (4) achieves the optimal solution, P sup = 0.71 still holds as demonstrated in Remark 2. With P sup increases during training, we analyze how it affects the intensity of supervised contrastive loss and supervised cross-entropy loss in the following.</p><p>Adaptive Weighting between L sup and L supcon . Note that the optimal value is 0.035 for the probability that two samples are a true positive pair with label y as indicated by Remark 2. We suppose p l , p h ? (0, 0.71) and p l &lt; p h . To achieve the optimal value, when P sup =p, the supervised contrastive loss value L supcon decreases as shown in Eq. <ref type="bibr" target="#b6">(7)</ref>.</p><p>Here P sup increases from p l to p h , L supcon decreases to a much smaller loss value to achieve the optimal solution, which implies the need to make two different class samples</p><formula xml:id="formula_12">L supcon = ? z+?P (i) log exp(z + ? G(x i )) z k ?A(i) exp(z k ? G(x i )) = ? z+?P (i) log exp(z+?G(xi)) ExpSum z k ?A(i) exp(z k ?G(xi)) ExpSum = ? K * log 0.035 1 ? p .<label>(7)</label></formula><p>much more discriminative, i.e., increasing inter-class margins. Thus the intensity of supervised contrastive loss enlarges. An intuition is that as P sup increases, more samples are pulled together with their corresponding centers. Along with stronger intensity of supervised contrastive loss at that time, it is more likely to push hard examples close to those samples that are already around right centers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Center Learning Rebalance</head><p>PaCo balances the contrastive learning (for moderating contrast among samples). However the center learning also needs to be balanced, which has been explored in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b56">57]</ref>. We incorporate Balanced Softmax <ref type="bibr" target="#b37">[38]</ref> into the center learning. Then the PaCo loss is changed from Eq. (4) to</p><formula xml:id="formula_13">L i = z+?P (i)?{cy} ?w(z + ) log ?(z + , T (x i )) z k ?A(i)?C ?(z k , T (x i )) ,<label>(8)</label></formula><formula xml:id="formula_14">where ?(z k , T (x i )) = exp(z k ? G(x i )), z k ? A(i); exp(z k ? F(x i )) ? q(y k ), z k ? C.</formula><p>We emphasize that Balanced Softmax is only a practical remedy for center learning rebalance. Theoretical analysis remains future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Ablation Study</head><p>Data augmentation strategy for PaCo. Data augmentation is the key for success of contrastive learning as indicated by Chen et al. <ref type="bibr" target="#b8">[9]</ref>. For PaCo, we also conduct ablation studies for different augmentation strategies. Several observations are intriguingly different from those of <ref type="bibr" target="#b36">[37]</ref>. We experiment with the following ways of data augmentation.</p><p>? SimAugment: an augmentation policy <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b9">10]</ref> that applies random flips and color jitters followed by Gaussian blur.</p><p>? RandAugment <ref type="bibr" target="#b11">[12]</ref>: A two stage augmentation policy that uses random parameters in place of parameters For the common random resized crop used along with the above two strategies, work of <ref type="bibr" target="#b36">[37]</ref> explains that the optimal hyper-parameter for random resized crop is (0.2,1) in selfsupervised contrastive learning. This setting is also adopted by work of <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>However, in this paper, we observe severe performance degradation on ImageNet-LT with ResNet-50 (55.0% vs 52.2%) for PaCo when we change the hyper-parameter from (0.08,1) to (0.2, 1). This is because PaCo involves center learning while other self-supervised frameworks only apply non-parametric contrastive loss as described in Section 2. Note that the same phenomenon is also observed on traditional supervised learning with cross-entropy loss.</p><p>Another observation is on RandAugment <ref type="bibr" target="#b11">[12]</ref>. The work of <ref type="bibr" target="#b49">[50]</ref> demonstrated that directly applying strong data augmentation in MoCo <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b9">10]</ref> does not work well. Here we observe a similar conclusion with RandAugment <ref type="bibr" target="#b11">[12]</ref>. We experiment with 3 different augmentation strategies of (1) encoder and momentum encoder input both with SimAugment; (2) encoder and momentum encoder input both with RandAugment; and (3) encoder input using RandAugment and momentum encoder input with SimAugment. The experimental results are presented in <ref type="table" target="#tab_1">Table 2</ref>. With strategy (3), PaCo achieves the best performance, showing center learning requires more aggressive data augmentation compared with contrastive learning among samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Baseline Implementation</head><p>Contrastive learning benefits from longer training compared with traditional supervised learning with crossentropy as Chen et al. <ref type="bibr" target="#b8">[9]</ref> concluded, which is also validated by previous work of <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b6">7]</ref>. We run PaCo with 400 epochs on CIFAR-LT, ImageNet-LT, iNaturalist 2018, full CIFAR, and full ImageNet except for Places-LT. With Places-LT, we follow previous work <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b13">14]</ref> by loading the pre-trained model on ImageNet and finely tune 30 epochs on Places-LT. For fair comparison on ImageNet-LT and iNaturalist 2018, we reimplement baselines with the same training time and RandAugment <ref type="bibr" target="#b11">[12]</ref>. Especially, for RIDE, based on model ensemble, we compare with it under comparable inference latency in <ref type="figure" target="#fig_0">Fig. 1.</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Long-tailed Recognition</head><p>We follow the common evaluation protocol <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b27">28]</ref> in long-tailed recognition -that is, training models on the long-tailed source label distribution and evaluating their performance on the uniform target label distribution. We conduct experiments on long-tailed version of CIFAR-100 <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b4">5]</ref>, Places <ref type="bibr" target="#b34">[35]</ref>, ImageNet <ref type="bibr" target="#b34">[35]</ref> and iNaturalist 2018 <ref type="bibr" target="#b47">[48]</ref> datasets.</p><p>CIFAR-100-LT datasets. CIFAR-100 has 60,000 images -50,000 for training and 10,000 for validation with 100 categories. For fair comparison, we use the long-tailed version of CIFAR datasets with the same setting as those used in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b15">16]</ref>. They control the degrees of data imbalance with an imbalance factor ?. ?= Nmax Nmin where N max and N min are the numbers of training samples for the most and least frequent classes respectively. Following <ref type="bibr" target="#b57">[58]</ref>, we conduct experiments with imbalance factors 100, 50, and 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ImageNet-LT and Places-LT. ImageNet-LT and Places-</head><p>LT were proposed in <ref type="bibr" target="#b34">[35]</ref>. ImageNet-LT is a long-tailed version of ImageNet dataset <ref type="bibr" target="#b39">[40]</ref> by sampling a subset following the Pareto distribution with power value ?=6. It contains 115.8K images from 1,000 categories, with class cardinality ranging from 5 to 1,280. Places-LT is a long-tailed version of the large-scale scene classification dataset Places <ref type="bibr" target="#b58">[59]</ref>. It consists of 184.5K images from 365 categories with class cardinality ranging from 5 to 4,980.</p><p>iNaturalist 2018. The iNaturalist 2018 <ref type="bibr" target="#b47">[48]</ref> is one species classification dataset, which is on a large scale and suffers from extremely imbalanced label distribution. It is composed of 437.5K images from 8,142 categories. In addition to the extreme imbalance, the iNaturalist 2018 dataset also confronts the fine-grained problem <ref type="bibr" target="#b51">[52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation details. For image classification on</head><p>ImageNet-LT, we used ResNet-50, ResNeXt-50-32x4d, and ResNeXt-101-32x4d as our backbones for experiments. For iNaturalist 2018, we conduct experiments with ResNet-50 and ResNet-152. All models were trained using SGD optimizer with momentum ? = 0.9. Contrastive learning usually requires long training time to converge. MoCo <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b9">10]</ref>, BYOL <ref type="bibr" target="#b18">[19]</ref> and SWAV <ref type="bibr" target="#b6">[7]</ref> train 800 epochs for model convergence. Supervised contrastive learning <ref type="bibr" target="#b28">[29]</ref> trains 350 epochs for feature learning and another 350 epochs for classifier learning.</p><p>Following MoCo <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b9">10]</ref>, when we train models with PaCo, the learning rate decays by a cosine scheduler from 0.02 to 0 with batch size 128 on 4 GPUs in 400 epochs. The temperature is set to 0.2. ? is 0.05. For fair comparison, we reimplement baselines in the same setting for recent state-of-the-arts of Decouple <ref type="bibr" target="#b27">[28]</ref>, Balanced Softmax <ref type="bibr" target="#b37">[38]</ref> and RIDE <ref type="bibr" target="#b48">[49]</ref> as mentioned in Section 4.2.</p><p>For Places-LT, following previous setting <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b13">14]</ref>, we choose ResNet-152 as the backbone network, pre-train it on the full ImageNet-2012 dataset (provided by torchvision), and finely tune it for 30 epochs on Places-LT. Same as that on ImageNet-LT, the learning rate decays by a cosine scheduler from 0.02 to 0 with batch size 128. The temperature is set to 0.2. ? is 0.05. For CIFAR-100-LT, we strictly follow the setting of <ref type="bibr" target="#b37">[38]</ref> for fair comparison. A smaller temperature of 0.05 and ? = 0.02 are adopted for PaCo.</p><p>Comparison on ImageNet-LT. <ref type="table" target="#tab_2">Table 3</ref> shows extensive experimental results for comparison with recent SOTA methods. We observe that Balanced Softmax <ref type="bibr" target="#b37">[38]</ref> still achieves comparable results with Decouple <ref type="bibr" target="#b27">[28]</ref> across various backbones under such strong training setting on ImageNet-LT, consistent with what is claimed in the original paper. For RIDE that is based on model ensemble, we analyze the real inference speed by calculating inference time with a batch of 64 images on Nvidia GeForce 2080Ti GPU.</p><p>We observe RIDEResNet with 3 experts even has higher inference latency than a standard ResNeXt-50-32x4d (15.3ms vs 13.1ms); RIDEResNeXt with 3 experts yields higher inference latency than a standard ResNeXt-101-32x4d (26ms vs 25ms). This result is in accordance with the conclusion that network fragmentation reduces the degree of parallelism and thus decreases efficiency in <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b12">13]</ref>. For fair comparison, we do not apply knowledge distillation tricks for all these methods. As shown in <ref type="figure" target="#fig_0">Fig. 1</ref> and <ref type="table" target="#tab_2">Table 3</ref>, under comparable inference latency, PaCo significantly surpasses these baselines.</p><p>Comparison on Places-LT. The experimental results on Places-LT are summarized in <ref type="table" target="#tab_3">Table 4</ref>. Due to the architecture change of RIDE, it is not applicable to load the publicly Comparison on iNaturalist 2018. Comparison on CIFAR-100-LT. The experimental results on CIFAR-100-LT are listed in <ref type="table" target="#tab_6">Table 6</ref>. For the CIFAR-100-LT dataset, we mainly compare with the SOTA method Balanced Softmax <ref type="bibr" target="#b37">[38]</ref> with the same training setting where Cutout <ref type="bibr" target="#b16">[17]</ref> and AutoAugment <ref type="bibr" target="#b10">[11]</ref> are used in training. As shown in <ref type="table" target="#tab_6">Table 6</ref>, PaCo consistently outperforms Balanced Softmax across different imbalance factors with such a strong setting. Specifically, PaCo surpasses Balanced Softmax by 1.2%, 1.8% and 1.2% under imbalance factor 100, 50 and 10 respectively, which testify the effectiveness of our PaCo method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Full ImageNet and CIFAR Recognition</head><p>As analyzed in Section 3.4, for balanced datasets, PaCo reduces to an improved version of multi-task learning, which  adaptively adjusts the intensity of supervised cross-entropy loss and supervised contrastive loss. To verify the effectiveness of PaCo under this balanced setting, we conduct experiments on full ImageNet and full CIFAR. They are indicative to compare PaCo with supervised contrastive learning <ref type="bibr" target="#b28">[29]</ref>. Note that, under full ImageNet and CIFAR, we remove the rebalance in center learning, i.e., Balanced Softmax.</p><p>Full ImageNet. In the implementation, we transfer hyperparameters of PaCo on ImageNet-LT to full ImageNet without modification. SGD optimizer with momentum ? = 0.9 is used. ?=0.05, temperature is 0.2 and queue size is 8,192. For multi-task training, the supervised contrastive loss is additional regularization and the loss weight is also set to 0.05. The same data augmentation strategy is applied as PaCo, which is discussed in Section 4.1.</p><p>The experimental results are summarized in <ref type="table" target="#tab_7">Table 7</ref>. With SimAugment, our ResNet-50 model achieves 78.7% top-1 accuracy, which outperforms supervised contrastive learning model by 0.8%. Equipped with strong augmenta-  tion, i.e., RandAugment <ref type="bibr" target="#b11">[12]</ref>, the performance further improves to 79.3%. ResNet-101/200 trained with PaCo consistently surpass supervised contrastive learning.</p><p>Full CIFAR-100. For CIFAR implementation, we follow supervised contrastive learning and train ResNet-50 with only the SimAugment. Compared with full ImageNet, we adopt a smaller temperature of 0.07, ? = 0.008 and batch size 256 with learning rate 0.1. As shown in <ref type="table" target="#tab_8">Table 8</ref>, on CIFAR-100, PaCo outperforms supervised contrastive learning by 2.6%, which validates the advantages of PaCo. Note that, following <ref type="bibr" target="#b12">[13]</ref>, we use a weight-decay of 5e ? 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have proposed Parametric Contrastive Learning (PaCo), which contains a set of parametric classwise learnable centers to tackle the long-tailed recognition. It is based on the theoretical analysis of supervised contrastive learning. For balanced data, our analysis of PaCo demonstrates that it can adaptively enhance the intensity of pushing two samples of the same class close as more samples are pulled together with their corresponding centers, which can potentially benefit hard examples learning in training.</p><p>We conduct experiments on various benchmarks of CIFAR-LT, ImageNet-LT, Places-LT, and iNaturalist 2018. The experimental results show that we create a new stateof-the-art for long-tailed recognition. Further, experimental results on full ImageNet and CIFAR demonstrate that PaCo also benefits balanced datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parametric Contrastive Learning Supplementary Material</head><p>A. Proof to Remark 1</p><p>For an image X i and its label y i , the expectation number of positive pairs with respect to X i will be:</p><formula xml:id="formula_15">K yi = q(y i ) * (length(queue) + batchsize * 2 ? 1) ? length(queue) ? q(y i ),<label>(9)</label></formula><p>q(y i ) is the class frequency over the whole dataset. Here the "?" establishes because batchsize length(queue) in training process. Note that we use such approximation just for simplification. Our analysis holds for the precise K yi . In what follows, we prove the optimal values for supervised contrastive loss.</p><p>Suppose training samples are i.i.d. To minimize the supervised contrastive loss for sample X i , according to Eq. (3), we rewrite:</p><formula xml:id="formula_16">? ? ? ? ? ? ? ? ? ? ? P (i) = {z + 1 , z + 2 , ..., z + Ky i }; p + i = exp(z + i ? T (x i )) z k ?A(i) exp(z k ? T (x i )) ; p + sum = p + 1 + p + 2 + ... + p + Ky i .</formula><p>Then the supervised contrastive loss will be:</p><formula xml:id="formula_17">L i = ? z+?P (i) log exp(z + ? T (x i )) z k ?A(i) exp(z k ? T (x i )) = ?(log p + 1 + log p + 2 + ... + log p + Ky i ).</formula><p>For obtaining its optimal solution, we define the Lagrange multiplier form of L i as:</p><formula xml:id="formula_18">l = ?(log p + 1 + log p + 2 + ... + log p + Ky i ) + ?(p + 1 + p + 2 + ... + p + Ky i ? p + sum ),<label>(10)</label></formula><p>where ? is the Lagrange multiplier. The first order conditions of Eq. (10) w.r.t. ? and p + i can be written as follows:</p><formula xml:id="formula_19">? ? ? ? ? ? ? ?l ?p + i = ? 1 p + i + ? = 0; ?l ?? = p + 1 + p + 2 + ... + p + Ky i ? p + sum = 0.<label>(11)</label></formula><p>From Eq. (11), the optimal solution for p * i will be p + sum K yi . Note that p + sum ? [0, 1], with a specific p + sum , the minimal loss value of L i is:</p><formula xml:id="formula_20">L i = ?K yi log p + sum K yi .<label>(12)</label></formula><p>Thus, when p + sum = 1.0, L i achieves minimum with the optimal value p + i = 1 K yi which is exactly the probability that two samples of the same class are a true positive pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proof to Remark 2</head><p>For the image X i and its label y i , Eq. (9) still establishes for our parametric contrastive loss. To minimize the parametric contrastive loss for sample X i , according to Eq. (4), we similarly rewrite:</p><formula xml:id="formula_21">? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? P (i) = {z + 1 , z + 2 , ..., z + Ky i } p + i = exp(z + i ? T (x i )) z k ?A(i)?C exp(z k ? T (x i )) p + c = exp(c y ? T (x i )) z k ?A(i)?C exp(z k ? T (x i )) p + sum = p + 1 + p + 2 + ... + p + Ky i + p + c .</formula><p>Then the parametric contrastive loss will be:</p><formula xml:id="formula_22">L i = z+?P (i)?{cy} ?w(z + ) log exp(z + ? T (x i )) z k ?A(i)?C exp(z k ? T (x i ))<label>(13)</label></formula><formula xml:id="formula_23">= ? log p + c + ? ? (log p + 1 + log p + 2 + ... + log p + ky i ) .<label>(14)</label></formula><p>For obtaining its optimal solution, we define the Lagrange multiplier form of L i as:</p><formula xml:id="formula_24">l = ? log p + c + ? ? (log p + 1 + log p + 2 + ... + log p + ky i ) + ?(p + 1 + p + 2 + ... + p + Ky i + p + c ? p + sum ),<label>(15)</label></formula><p>where ? is the Lagrange multiplier. The first order conditions of Eq. (15) w.r.t. ?, p + c and p + i can be written as follows: </p><formula xml:id="formula_25">? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?l ?p + i = ? ? p + i + ? = 0; ?l ?p + c = ? 1 p + c + ? = 0; ?l ?? = p + 1 + p + 2 + ... + p + Ky i + p + c ? p + sum = 0.<label>(16)</label></formula><formula xml:id="formula_26">L i = ? log p + sum 1 + ?K yi ? ?K yi log ?p + sum 1 + ?K yi .<label>(17)</label></formula><p>Thus, when p + sum = 1.0, L i achieves minimum with the optimal value p + i = ? 1 + ?K yi , which is the probability that two samples of the same class are a true positive pair, and the optimal value p + c = 1 1 + ?K yi which is the probability that a sample is closest to its corresponding center c yi among C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Gradient Derivation</head><p>In Section 3.4, we analyze PaCo loss under balanced setting, taking full ImageNet as an example. With P sup increases from 0 to 0.71, the intensity of supervised contrastive loss will enlarge. Here we show that more samples will be pulled together with their corresponding centers when P sup increases from 0 to 0.71 from the perspective of gradient derivation.</p><formula xml:id="formula_27">?L ?c k = (?K * + 1)p c k x i , y i = k; {(?K * + 1)p c k ? 1} x i , y i = k.<label>(18)</label></formula><p>It is worthy to note that when p c k ? (0, 0.71), we have</p><formula xml:id="formula_28">? ? ? ? ? ? ? ?L ?c k &gt; 0, y i = k; ?L ?c k &lt; 0, y i = k.<label>(19)</label></formula><p>Eqs. <ref type="bibr" target="#b17">(18)</ref> and <ref type="bibr" target="#b18">(19)</ref> mean that as P sup increases in training process, the probability that a sample is closest to its corresponding center will increase and the probability that a sample is closest to other centers will decrease. Thus, more and more samples will be pulled together with their right centers.</p><p>D. More Experimental Results on Many-shot, Medium-shot, and Few-shot.     E. Implementation details for <ref type="table" target="#tab_0">Table 1</ref> We train models with cross-entropy, parametric contrastive loss 400 epochs without RandAugment respectively. For supervised contrastive loss, following the original paper, we firstly train the model 400 epochs. Then we fix the backbone and train a linear classifier 400 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Ablation Study</head><p>Re-weighting in contrastive learning without center learning rebalance Re-weighting is a classical method for dealing with imbalanced data. Here we directly apply the re-weighting method of Cui et al. <ref type="bibr" target="#b15">[16]</ref> in contrastive learning to compare with PaCo. Moreover, Balanced softmax <ref type="bibr" target="#b37">[38]</ref>, as one state-of-the-art method for traditional cross-entropy in long-tailed recognition, is also applied to contrastive learning rebalance. The experimental results are summarized in <ref type="table" target="#tab_0">Table 13</ref>. It is obvious PaCo significantly surpasses the two baselines.</p><p>Rebalance in center learning PaCo balances the contrastive learning (for moderating contrast among samples). However the center learning also needs to be balanced, which has been explored in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b17">18]</ref>. To compare with state-of-the-art methods in long-tailed recognition, we incorporate Balanced Softmax <ref type="bibr" target="#b37">[38]</ref> into the center <ref type="table" target="#tab_0">Table 14</ref>: Comparison with re-weighting baselines that perform center learning rebalance on ImageNet-LT with ResNeXt-50. Models are all trained with RangAugment in 400 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>loss weight Top-1 Accuracy multi-task (Balanced Softmax+Re-weighting) 0.05 57.0 multi-task (Balanced Softmax+Re-weighting) 0.10 57.1 multi-task (Balanced Softmax+Re-weighting) 0.20 57.1 multi-task (Balanced Softmax+Re-weighting) 0.30 57.0 multi-task (Balanced Softmax+Re-weighting) 0.50 57.2 multi-task (Balanced Softmax+Re-weighting) 0.80 57.2 multi-task (Balanced Softmax+Re-weighting) 1.00 56.9</p><p>PaCo -58.2 learning. As shown in <ref type="table" target="#tab_0">Table 14</ref>, after rebalance in center learning, PaCo boosts performance to 58.2%, surpassing baselines with a large margin.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Comparison with state-of-the-arts on ImageNet-LT</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>explored rebalancing in traditional supervised cross-arXiv:2107.12028v2 [cs.CV] 17 Aug 2021</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Parametric contrastive learning (PaCo). We introduce a set of parametric class-wise learnable centers for rebalancing in contrastive learning. More analysis is in Section 3.3 for PaCo. ) = ? log(p) ? 0.41 ? log(1 ? p) Curve for L extra .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Top-1 accuracy (%) of supervised contrastive learning on ImageNet-LT with ResNet-50. Implementation details are in supplementary file. ?represents that the model is trained with PaCo loss without center learning rebalance.</figDesc><table><row><cell>Method</cell><cell cols="3">Many Medium Few</cell><cell>All</cell></row><row><cell>Cross-Entropy</cell><cell>67.5</cell><cell>42.6</cell><cell cols="2">13.7 48.4</cell></row><row><cell>SupCon</cell><cell>53.4</cell><cell>2.9</cell><cell>0</cell><cell>22.0</cell></row><row><cell>PaCo (ours)  ?</cell><cell>69.6</cell><cell>45.8</cell><cell cols="2">16.0 51.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison with different augmentation strategies for PaCo on ImageNet-LT with ResNet-50. The random parameters do not need to be tuned and hence reduces the search space.</figDesc><table><row><cell cols="3">Methods Aug. strategy Top-1 Accuracy</cell></row><row><cell>PaCo</cell><cell>Strategy (1)</cell><cell>55.0</cell></row><row><cell>PaCo</cell><cell>Strategy (2)</cell><cell>56.5</cell></row><row><cell>PaCo</cell><cell>Strategy (3)</cell><cell>57.0</cell></row><row><cell cols="2">tuned by AutoAugment.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Long-tail recognition accuracy on ImageNet-LT for different backbone architectures. ? denotes models trained with RandAugment<ref type="bibr" target="#b11">[12]</ref> in 400 epochs. More comparisons with RIDE<ref type="bibr" target="#b48">[49]</ref> are inFig. 1.</figDesc><table><row><cell>Method</cell><cell cols="3">ResNet-50 ResNeXt-50 ResNeXt-101</cell></row><row><cell>CE(baseline)</cell><cell>41.6</cell><cell>44.4</cell><cell>44.8</cell></row><row><cell>Decouple-cRT</cell><cell>47.3</cell><cell>49.6</cell><cell>49.4</cell></row><row><cell>Decouple-? -norm</cell><cell>46.7</cell><cell>49.4</cell><cell>49.6</cell></row><row><cell>De-confound-TDE</cell><cell>51.7</cell><cell>51.8</cell><cell>53.3</cell></row><row><cell>ResLT</cell><cell>-</cell><cell>52.9</cell><cell>54.1</cell></row><row><cell>MiSLAS</cell><cell>52.7</cell><cell>-</cell><cell>-</cell></row><row><cell>Decouple-? -norm  ?</cell><cell>54.5</cell><cell>56.0</cell><cell>57.9</cell></row><row><cell>Balanced Softmax  ?</cell><cell>55.0</cell><cell>56.2</cell><cell>58.0</cell></row><row><cell>PaCo ?</cell><cell>57.0</cell><cell>58.2</cell><cell>60.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Performance on Places-LT<ref type="bibr" target="#b34">[35]</ref>, starting from an ImageNet pre-trained ResNet-152 provided by torchvision.?denotes the model trained with RandAugment<ref type="bibr" target="#b11">[12]</ref>.</figDesc><table><row><cell>Method</cell><cell cols="4">Many Medium Few All</cell></row><row><cell>CE(baseline)</cell><cell>45.7</cell><cell>27.3</cell><cell cols="2">8.2 30.2</cell></row><row><cell>OLTR</cell><cell>44.7</cell><cell>37.0</cell><cell cols="2">25.3 35.9</cell></row><row><cell>Decouple-? -norm</cell><cell>37.8</cell><cell>40.7</cell><cell cols="2">31.8 37.9</cell></row><row><cell cols="2">Balanced Softmax 42.0</cell><cell>39.3</cell><cell cols="2">30.5 38.6</cell></row><row><cell>ResLT</cell><cell>39.8</cell><cell>43.6</cell><cell cols="2">31.4 39.8</cell></row><row><cell>MiSLAS</cell><cell>39.6</cell><cell>43.3</cell><cell cols="2">36.1 40.4</cell></row><row><cell>RIDE (2 experts)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PaCo</cell><cell>37.5</cell><cell>47.2</cell><cell cols="2">33.9 41.2</cell></row><row><cell>PaCo  ?</cell><cell>36.1</cell><cell>47.9</cell><cell cols="2">35.3 41.2</cell></row></table><note>pre-trained model on full ImageNet, while PaCo is more flexible where the network architecture is the same as those of [35, 14]. Under fair training setting by finely tuning 30 epochs without RandAugment, PaCo surpasses SOTA Bal- anced Softmax by 2.6%. An interesting observation is that RandAugment has little effect on the Places-LT dataset. A similar phenomenon can be observed on the iNaturalist 2018 dataset. More evaluation numbers are in the supplementary file. They can be intuitively understood since RandAugment is designed for ImageNet classification, which inspires us to explore general augmentations across different domains.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>lists experi-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Top-1 accuracy over all classes on iNaturalist 2018with ResNet-50. Knowledge distillation is not applied to all methods for fair comparison. We compare with RIDE 1 under comparable inference latency. ? denotes models trained with RandAugment<ref type="bibr" target="#b11">[12]</ref> in 400 epochs.</figDesc><table><row><cell>Method</cell><cell>Top-1 Accuracy</cell></row><row><cell>CB-Focal</cell><cell>61.1</cell></row><row><cell>LDAM+DRW</cell><cell>68.0</cell></row><row><cell>Decouple-? -norm</cell><cell>69.3</cell></row><row><cell>Decouple-LWS</cell><cell>69.5</cell></row><row><cell>BBN</cell><cell>69.6</cell></row><row><cell>ResLT</cell><cell>70.2</cell></row><row><cell>MiSLAS</cell><cell>71.6</cell></row><row><cell>RIDE (2 experts)  ?</cell><cell>69.5</cell></row><row><cell>Decouple-? -norm  ?</cell><cell>71.5</cell></row><row><cell>Balanced Softmax  ?</cell><cell>71.8</cell></row><row><cell>PaCo  ?</cell><cell>73.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table><row><cell cols="4">Top-1 accuracy on CIFAR-100-LT with different</cell></row><row><cell cols="4">imbalance factors ( ?: models trained in same setting).</cell></row><row><cell>Dataset</cell><cell cols="3">CIFAR-100 LT</cell></row><row><cell>Imbalance factor</cell><cell>100</cell><cell>50</cell><cell>10</cell></row><row><cell>Focal Loss</cell><cell cols="3">38.4 44.3 55.8</cell></row><row><cell>LDAM+DRW</cell><cell cols="3">42.0 46.6 58.7</cell></row><row><cell>BBN</cell><cell cols="3">42.6 47.0 59.1</cell></row><row><cell>Causal Norm</cell><cell cols="3">44.1 50.3 59.6</cell></row><row><cell>ResLT</cell><cell cols="3">45.3 50.0 60.8</cell></row><row><cell>MiSLAS</cell><cell cols="3">47.0 52.3 63.2</cell></row><row><cell cols="4">Balanced Softmax  ? 50.8 54.2 63.0</cell></row><row><cell>PaCo  ?</cell><cell cols="3">52.0 56.0 64.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Top-1 accuracy on full ImageNet with ResNets. " " denotes supervised contrastive learning with additional operation of image warping before Gaussian blur.</figDesc><table><row><cell>Method</cell><cell>Model</cell><cell>augmentation</cell><cell>Top-1 Acc</cell></row><row><cell>Supcon</cell><cell>ResNet-50</cell><cell>SimAugment</cell><cell>77.9</cell></row><row><cell>Supcon</cell><cell>ResNet-50</cell><cell>RandAugment</cell><cell>78.4</cell></row><row><cell>Supcon</cell><cell>ResNet-101</cell><cell>StackedRandAugment</cell><cell>80.2</cell></row><row><cell cols="2">multi-task RandAugment</cell><cell>ResNet-50</cell><cell>78.1</cell></row><row><cell>PaCo</cell><cell>ResNet-50</cell><cell>SimAugment</cell><cell>78.7</cell></row><row><cell>PaCo</cell><cell>ResNet-50</cell><cell>RandAugment</cell><cell>79.3</cell></row><row><cell>PaCo</cell><cell>ResNet-101</cell><cell>StackedRandAugment</cell><cell>80.9</cell></row><row><cell>PaCo</cell><cell>ResNet-200</cell><cell>StackedRandAugment</cell><cell>81.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Top-1 accuracy on full CIFAR-100 (ResNet-50).</figDesc><table><row><cell>Method</cell><cell>dataset</cell><cell>Top-1 Accuracy</cell></row><row><cell cols="2">CE(baseline) CIFAR-100</cell><cell>77.9</cell></row><row><cell>multi-task</cell><cell>CIFAR-100</cell><cell>78.0</cell></row><row><cell>Supcon</cell><cell>CIFAR-100</cell><cell>76.5</cell></row><row><cell>PaCo</cell><cell>CIFAR-100</cell><cell>79.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Comprehensive results on ImageNet-LT with different backbone networks (ResNet-50, ResNeXt-50 &amp; ResNeXt-101). Models are trained with RandAugment in 400 epochs. Inference time is calculated with a batch of 64 images on Nvidia GeForce 2080Ti GPU, Pytorch1.5, Python3.6.</figDesc><table><row><cell>Backbone</cell><cell>Method</cell><cell cols="4">Inference time (ms) Many Medium Few All</cell></row><row><cell></cell><cell>? -normalize</cell><cell>8.3</cell><cell>65.0</cell><cell>52.2</cell><cell>32.3 54.5</cell></row><row><cell>ResNet-50</cell><cell>Balanced Softmax</cell><cell>8.3</cell><cell>66.7</cell><cell>52.9</cell><cell>33.0 55.0</cell></row><row><cell></cell><cell>PaCo</cell><cell>8.3</cell><cell>65.0</cell><cell>55.7</cell><cell>38.2 57.0</cell></row><row><cell></cell><cell>? -normalize</cell><cell>13.1</cell><cell>66.4</cell><cell>53.4</cell><cell>38.2 56.0</cell></row><row><cell>ResNeXt-50</cell><cell>Balanced Softmax</cell><cell>13.1</cell><cell>67.7</cell><cell>53.8</cell><cell>34.2 56.2</cell></row><row><cell></cell><cell>PaCo</cell><cell>13.1</cell><cell>67.5</cell><cell>56.9</cell><cell>36.7 58.2</cell></row><row><cell></cell><cell>? -normalize</cell><cell>25.0</cell><cell>69.0</cell><cell>55.1</cell><cell>36.9 57.9</cell></row><row><cell>ResNeXt-101</cell><cell>Balanced Softmax</cell><cell>25.0</cell><cell>69.2</cell><cell>55.8</cell><cell>36.3 58.0</cell></row><row><cell></cell><cell>PaCo</cell><cell>25.0</cell><cell>68.2</cell><cell>58.7</cell><cell>41.0 60.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 :</head><label>10</label><figDesc>Comprehensive results on ImageNet-LT with RIDE. Models are trained with RandAugment in 400 epochs. Inference time is calculated with a batch of 64 images on Nvidia GeForce 2080Ti GPU, Pytorch1.5, Python3.6.</figDesc><table><row><cell>Backbone</cell><cell>Method</cell><cell cols="4">Inference time (ms) Many Medium Few All</cell></row><row><cell></cell><cell>1 expert</cell><cell>8.2</cell><cell>64.8</cell><cell>49.8</cell><cell>29.6 52.8</cell></row><row><cell>RIDEResNet</cell><cell>2 experts</cell><cell>12.0</cell><cell>67.7</cell><cell>53.5</cell><cell>31.5 56.0</cell></row><row><cell></cell><cell>3 experts</cell><cell>15.3</cell><cell>69.0</cell><cell>54.7</cell><cell>32.5 57.0</cell></row><row><cell></cell><cell>1 expert</cell><cell>13.0</cell><cell>67.2</cell><cell>49.0</cell><cell>28.1 53.2</cell></row><row><cell>RIDEResNeXt</cell><cell>2 experts</cell><cell>19.0</cell><cell>70.4</cell><cell>52.6</cell><cell>30.3 56.4</cell></row><row><cell></cell><cell>3 experts</cell><cell>26.0</cell><cell>71.8</cell><cell>53.9</cell><cell>32.0 57.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 :</head><label>11</label><figDesc>Comprehensive results on iNaturalist 2018 with ResNet-50 and ResNet-152. ?represents the models are trained without RandAugment. Inference time is calculated with a batch of 64 images on Nvidia GeForce 2080Ti GPU, Pytorch1.5, Python3.6.</figDesc><table><row><cell>Backbone</cell><cell>Method</cell><cell cols="4">Inference time (ms) Many Medium Few All</cell></row><row><cell></cell><cell>? -normalize</cell><cell>8.3</cell><cell>74.1</cell><cell>72.1</cell><cell>70.4 71.5</cell></row><row><cell>ResNet-50</cell><cell>Balanced Softmax</cell><cell>8.3</cell><cell>72.3</cell><cell>72.6</cell><cell>71.7 71.8</cell></row><row><cell></cell><cell>PaCo</cell><cell>8.3</cell><cell>70.3</cell><cell>73.2</cell><cell>73.6 73.2</cell></row><row><cell>ResNet-50  ?</cell><cell>Balanced Softmax PaCo</cell><cell>8.3 8.3</cell><cell>72.5 69.5</cell><cell>72.3 73.4</cell><cell>71.4 71.7 73.0 73.0</cell></row><row><cell cols="2">ResNet-152 PaCo</cell><cell>20.1</cell><cell>75.0</cell><cell>75.5</cell><cell>74.7 75.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 12 :</head><label>12</label><figDesc>Comprehensive results on iNaturalist 2018 with RIDE. Models are trained with RandAugment in 400 epochs without knowledge distillation. Inference time is calculated with a batch of 64 images on Nvidia GeForce 2080Ti GPU, Pytorch1.5, Python3.6.</figDesc><table><row><cell>Backbone</cell><cell>Method</cell><cell cols="4">Inference time (ms) Many Medium Few All</cell></row><row><cell></cell><cell>1 expert</cell><cell>8.2</cell><cell>56.0</cell><cell>66.3</cell><cell>66.0 65.2</cell></row><row><cell>RIDEResNet</cell><cell>2 experts 3 experts</cell><cell>12.0 15.3</cell><cell>62.2 66.5</cell><cell>70.5 72.1</cell><cell>70.0 69.5 71.5 71.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 13 :</head><label>13</label><figDesc>Comparison with re-weighting baselines on ImageNet-LT with ResNet-50. The re-weighting strategy is applied to the supervised contrastive loss. Models are all trained without RandAugment.</figDesc><table><row><cell>Method</cell><cell>Top-1 Accuracy</cell></row><row><cell>CE</cell><cell>48.4</cell></row><row><cell>multi-task (CE+Re-weighting)</cell><cell>49.0</cell></row><row><cell>multi-task (CE+Blance Softmax)</cell><cell>48.6</cell></row><row><cell>PaCo</cell><cell>51.0</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A systematic study of the class imbalance problem in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuto</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><forename type="middle">A</forename><surname>Mazurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A systematic study of the class imbalance problem in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuto</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej A</forename><surname>Mazurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">What is the effect of importance weighting in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Once-for-all: Train one network and specialize it for efficient deployment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhekai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning imbalanced datasets with labeldistribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Ar?chiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<editor>Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d&apos;Alch?-Buc, Emily B. Fox, and Roman Garnett</editor>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning imbalanced datasets with labeldistribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SMOTE: Synthetic minority oversampling technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">W</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">O</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Philip</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Improved baselines with momentum contrastive learning. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Man?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Ekin Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast and practical neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Reslt: Residual learning for long-tailed recognition. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno>abs/1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Elf: An early-exiting framework for longtailed classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Duggal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunny</forename><surname>Dhamnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duen</forename><surname>Horng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.11979</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Bootstrap your own latent -A new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo?vila</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Valko</surname></persName>
		</author>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<imprint>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note>NeurIPS, 2020. 1, 2, 3</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning from imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibo</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Edwardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning deep representation for imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep imbalanced learning for face recognition and attribute prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Change</forename><surname>Loy Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning deep representation for imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Rethinking classbalanced methods for long-tailed visual recognition from a domain adaptation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The class imbalance problem: A systematic study. Intelligent Data Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathalie</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaju</forename><surname>Stephen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prannay</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Microsoft COCO: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">DARTS: differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Path aggregation network for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifang</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Shufflenet V2: practical guidelines for efficient CNN architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningning</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai-Tao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<editor>Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair Weiss</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Factors in finetuning deep model for object detection with long-tail distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Balanced meta-softmax for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunjun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunan</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note>ImageNet large scale visual recognition challenge. IJCV, 2015. 1, 2, 3</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Relay backpropagation for effective learning of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Meta-weight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Equalization loss for long-tailed object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingru</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changbao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Longtailed classification by keeping the good and removing the bad momentum causal effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A?ron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno>abs/1807.03748</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The iNaturalist species classification and detection dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><forename type="middle">Mac</forename><surname>Grant Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Long-tailed recognition by routing diverse distribution-aware experts. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1809" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Contrastive learning with stronger augmentations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Piecewise classifier mappings: Learning fine-grained learners for novel categories with few examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingqiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Towards good practices for recognition &amp; detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR workshops</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Improving calibration for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Min</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.02413</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Places: A 10 million image database for ccene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
