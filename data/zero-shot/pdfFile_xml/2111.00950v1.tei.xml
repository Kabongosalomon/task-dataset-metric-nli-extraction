<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Higher-Order Implicit Fairing Networks for 3D Human Pose Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianning</forename><surname>Quan</surname></persName>
							<email>jianning.quan@mail.concordia.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">Concordia University -CIISE Montreal</orgName>
								<address>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Ben</forename><surname>Hamza</surname></persName>
							<email>hamza@ciise.concordia.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">Concordia University -CIISE Montreal</orgName>
								<address>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Higher-Order Implicit Fairing Networks for 3D Human Pose Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>QUAN, HAMZA: HIGHER-ORDER IMPLICIT FAIRING NETWORKS 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Estimating a 3D human pose has proven to be a challenging task, primarily because of the complexity of the human body joints, occlusions, and variability in lighting conditions. In this paper, we introduce a higher-order graph convolutional framework with initial residual connections for 2D-to-3D pose estimation. Using multi-hop neighborhoods for node feature aggregation, our model is able to capture the long-range dependencies between body joints. Moreover, our approach leverages residual connections, which are integrated by design in our network architecture, ensuring that the learned feature representations retain important information from the initial features of the input layer as the network depth increases. Experiments and ablations studies conducted on two standard benchmarks demonstrate the effectiveness of our model, achieving superior performance over strong baseline methods for 3D human pose estimation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The task of 3D human pose estimation is a fundamental problem in computer vision, robotics, and computer graphics. It refers to the process of predicting the positions of a person's joints (also known as keypoints or landmarks) in images or videos. Application domains of 3D human pose estimation are abundant, and range from activity recognition, surveillance and healthcare to games and sports.</p><p>Tremendous progress has been made in estimating 3D human pose from images or videos thanks to the rapid development of deep neural network solutions, which have been shown to achieve improved performance over classical approaches that use hand-crafted features. Most existing 3D pose estimation methods use an end-to-end pipeline <ref type="bibr" target="#b19">[20]</ref> or a two-stage pipeline <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b29">30]</ref>. The former employs a deep neural network to regress 3D keypoints from images in an end-to-end fashion, whereas the latter is comprised of two main stages, which are usually decoupled from each other. Two-stage approaches for 3D pose estimation have shown great promise <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b37">38]</ref>, outperforming end-to-end models. This better performance is largely attributed to the fact that two-stage methods benefit from intermediate supervision provided, in part, by robust 2D pose detectors <ref type="bibr" target="#b25">[26]</ref>. Martinez el al. <ref type="bibr" target="#b21">[22]</ref> design a simple fully connected network with residual connections for estimating 3D poses from 2D joint detections, outperforming systems trained end-to-end from raw pixels.</p><p>In recent years, there has been a surge of interest in the adoption of graph convolution networks (GCNs) for 3D pose estimation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39]</ref>, achieving state-of-the-art performance. Much of this interest stems from the fact that a 2D human skeleton can naturally be represented as a graph whose nodes are body joints and edges are connections between neighboring joints. Zhao et al. <ref type="bibr" target="#b36">[37]</ref> propose SemGCN, a semantic graph convolutional network, which learns to capture semantic information encoded in a given graph (i.e. local and global relations between nodes), yielding improved performance in 3D pose estimation while using a much smaller number of parameters. While GCN is powerful for learning on graph-structured data, it suffers, however, from the oversmoothing problem <ref type="bibr" target="#b18">[19]</ref>, where the learned node representations become indistinguishable due to repeated graph convolutions as the network depth increases. Several attempts have been made toward remedying this issue of oversmoothing <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36]</ref>. Another issue with GCN is that its aggregation scheme uses one-hop neighbors, and hence lacks the ability to capture long-range dependencies. This issue can be mitigated by skipping connections during feature aggregation using, for example, the jumping knowledge networks <ref type="bibr" target="#b32">[33]</ref> or by concatenating feature representations of multi-hop neighbors via sparsified neighborhood mixing (MixHop) <ref type="bibr" target="#b0">[1]</ref>, which leverages a graph convolutional layer that mixes powers of the adjacency matrix. Building on MixHop, Zou et al. <ref type="bibr" target="#b38">[39]</ref> propose a high-order GCN for 3D pose estimation, with the goal of capturing long-range dependencies between body joints.</p><p>To address the above issues, we introduce a higher-order graph convolutional framework for 3D pose estimation via implicit fairing on graphs <ref type="bibr" target="#b7">[8]</ref>. We follow the two-stage paradigm by employing a state-of-art 2D pose detector, followed by a lifting network for predicting the 3D pose locations from the 2D predictions. The aggregation scheme of the proposed approach leverages residual connections to help alleviate the oversmoothing problem, and uses multi-hop neighborhoods to capture long-range dependencies between body joints. The main contributions of this work can be summarized as follows:</p><p>? We derive an implicit fairing network (IF-Net) with initial residual connection by iteratively solving the implicit fairing equation on graphs via Jacobi method.</p><p>? We propose a higher-order implicit fairing network (HOIF-Net) for 3D human pose estimation by concatenating feature representations from multi-hop neighborhoods, with the aim to capture long-range dependencies.</p><p>? We demonstrate through experiments and ablation studies that our proposed model achieves state-of-the-art performance in comparison with strong baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Graph Convolution Networks. GCNs have recently become the de facto model for learning representations on graphs. However, GCNs are prone to oversmooting as the network depth increases, and also fail to capture important dependencies between distant nodes. To circumvent these limitations, a plethora of GCN variants have been proposed, including jumping knowledge networks (JK-Nets) <ref type="bibr" target="#b32">[33]</ref>, graph convolutional networks with initial residual connection and identity mapping (GCNII) <ref type="bibr" target="#b3">[4]</ref>, and higher-order graph convolutional architectures via MixHop <ref type="bibr" target="#b0">[1]</ref>. The latter learns neighborhood mixing relationships by repeatedly mixing feature representations of neighbors at various distances through powers of the graph adjacency matrix, while requiring no additional memory or computational complexity.</p><p>3D Human Pose Estimation. Most approaches to 3D human pose estimation can generally be classified into two main categories, namely single-stage and two-stage models, with the former using an end-to-end pipeline to predict 3D poses from images; and the latter using a two-stage pipeline, in which 2D joint locations are first extracted using a 2D pose detector and then a lifting network is employed to regress 3D poses from 2D detections. Our approach falls under the category of two-stage models <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref>. Zou et al. <ref type="bibr" target="#b38">[39]</ref> design a high-order GCN model for 3D pose estimation based on MixHop in a bid to capture long-range dependencies between distant body joints using a network architecture comprised of a residual block repeated several times similar to the network design of Martinez et al. <ref type="bibr" target="#b21">[22]</ref>. However, the model inherits the oversmoothing issue of GCNs, where repeated graph convolutions make learned node embeddings indistinguishable; thereby, resulting in performance drop. By contrast, our proposed network architecture has residual connections integrated by design, and hence is able to alleviate the oversmoothing problem. This is in line with existing approaches such as jumping knowledge networks <ref type="bibr" target="#b32">[33]</ref> and graph convolutional networks with initial residual and identity mapping <ref type="bibr" target="#b3">[4]</ref>. In addition, we use a scaled, learnable weight matrix with a layer-dependent scale factor in an effort to ensure that the weight decay adaptively increases as more layers are added <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries and Problem Statement</head><p>Basic Notions. Consider a graph G = (V, E), where V = {1, . . . , N} is the set of N nodes (e.g., body joints) and E ? V ? V is the set of edges (e.g., connections between two body joints). Let A be an N ? N adjacency matrix whose (i, j)-th entry is equal to the weight of the edge between neighboring nodes i and j, and 0 otherwise. We denote by? = A + I the adjacency matrix with self-added loops, where I is the identity matrix. We also denote by X = (x 1 , ..., x N ) an N ? F feature matrix of node attributes, where x i is an F-dimensional row vector for node i. We define the normalized Laplacian matrix as follows:</p><formula xml:id="formula_0">L = I ?D ? 1 2?D ? 1 2 ,<label>(1)</label></formula><p>whereD = diag(?1) is the diagonal degree matrix, and 1 is an N-dimensional vector of all ones. The Laplacian matrix admits an eigendecomposition given by L = U?U , where U is an orthonormal matrix whose columns constitute an orthonormal basis of eigenvectors and ? is a diagonal matrix comprised of the corresponding eigenvalues.</p><p>Graph Convolutional Networks (GCNs). Given an input feature matrix H ( ) ? R N?F of the -th layer with F feature maps, the output feature matrix H ( +1) of GCN is obtained by applying the following layer-wise propagation rule:</p><formula xml:id="formula_1">H ( +1) = ? (D ? 1 2?D ? 1 2 H ( ) W ( ) ), = 0, . . . , L ? 1,<label>(2)</label></formula><p>which is basically a node embedding transformation that projects H ( ) into a trainable weight matrix W ( ) ? R F ?F +1 with F +1 feature maps, followed by an activation function ? (?) such as ReLU(?) = max(0, ?). The input of the first layer is the initial feature matrix H (0) = X.</p><p>Jacobi Method. The Jacobi method <ref type="bibr" target="#b27">[28]</ref> is an iterative approach for solving a matrix equation Mx = b, where the square matrix M has no zeros along its main diagonal, by first decomposing M into a diagonal component and an off-diagonal component, i.e.</p><formula xml:id="formula_2">M = diag(M) + off(M).<label>(3)</label></formula><p>Then, the solution of the matrix equation Mx = b is obtained iteratively as follows:</p><formula xml:id="formula_3">x (t+1) = diag(M) ?1 (b ? off(M)x (t) ),<label>(4)</label></formula><p>where x (t) and x (t+1) are the t-th and (t + 1)-th iterations of x, respectively.</p><formula xml:id="formula_4">Problem Statement. Let D l = {(x i , y i )} N i=1 be a training set of 2D joint positions X = (x 1 , . . . , x N ) ? R N?2 and their associated 3D joint positions Y = (y 1 , . . . , y N ) ? R N?3 .</formula><p>The goal of 3D human pose estimation is to learn the parameters w of a regression model f : X ? Y by minimizing the following loss function</p><formula xml:id="formula_5">w * = arg min w 1 N N ? i=1 L( f (x i ), y i ).<label>(5)</label></formula><p>Since the 3D human pose estimation task is a regression problem, we train the model to minimize the mean squared error as a loss function.</p><p>4 Proposed Method</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Implicit Fairing on Graphs</head><p>Applying a spectral graph filter with transfer function h on the graph signal X yields a filtered graph signal H given by</p><formula xml:id="formula_6">H = h(L)X = Uh(?)U X.<label>(6)</label></formula><p>Spectral graph filters are usually approximated using Chebyshev polynomials <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b30">31]</ref> or rational polynomials <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b31">32]</ref>. The implicit fairing method, which uses implicit integration of a diffusion process for graph filtering, has shown to allow for both efficiency and stability <ref type="bibr" target="#b7">[8]</ref>.</p><p>The implicit fairing filter is an infinite impulse response filter whose transfer function is given by h s (? ) = 1/(1 + s? ), where s is a positive parameter. Substituting h with h s in Eq. <ref type="formula" target="#formula_6">(6)</ref>, we obtain</p><formula xml:id="formula_7">H = (I + sL) ?1 X,<label>(7)</label></formula><p>where I + sL is a symmetric positive definite matrix (all its eigenvalues are positive), and hence admits an inverse. Therefore, performing graph filtering with implicit fairing is equivalent to solving the following sparse linear system:</p><formula xml:id="formula_8">(I + sL)H = X.<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Iterative Solution</head><p>The implicit fairing equation <ref type="formula" target="#formula_8">(8)</ref> can be solved iteratively using Jacobi's method, which uses matrix splitting. We can split the matrix I + sL into the sum of a diagonal matrix and an off-diagonal matrix as follows:</p><formula xml:id="formula_9">I + sL = diag(I + sL) + off(I + sL),<label>(9)</label></formula><p>where</p><formula xml:id="formula_10">diag(I + sL) = (1 + s)I and off(I + sL) = ?sD ? 1 2?D ? 1 2 .</formula><p>Hence, the iterative solution of the implicit fairing equation is given by</p><formula xml:id="formula_11">H (t+1) = ?(diag(I + sL)) ?1 off(I + sL)H (t) + (diag(I + sL)) ?1 X = (s/(1 + s))D ? 1 2?D ? 1 2 H (t) + (1/(1 + s))X,<label>(10)</label></formula><p>which can be rewritten as</p><formula xml:id="formula_12">H (t+1) = (1 ? ?)D ? 1 2?D ? 1 2 H (t) + ?X,<label>(11)</label></formula><p>where the hyperparameter ? = 1/(1 + s) ? (0, 1), and H (t) is the t-th iteration of H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implicit Fairing Network</head><p>Inspired by the Jacobi iterative solution (11) of the implicit fairing equation, we propose a multi-layer implicit fairing network (IF-Net) with the following layer-wise propagation rule:</p><formula xml:id="formula_13">H ( +1) = ? (((1 ? ?)SH ( ) + ?X)W ( ) ),<label>(12)</label></formula><p>where S =D ? 1 2?D ? 1 2 is the normalized adjacency matrix with self-added loops, andW ( ) = ? W ( ) is a scaled, learnable weight matrix with a layer-dependent scale factor defined as ? = log(1 + ? /(1 + )), which ensures that the decay of the weight matrix increases in tandem with the network depth <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Higher-Order Implicit Fairing Network</head><p>Using the feature diffusion rule of GCN is tantamount to applying a weighted sum of the features of neighboring nodes normalized by their degrees, which essentially performs Laplacian smoothing on the graph <ref type="bibr" target="#b18">[19]</ref>, and hence leads to oversmoothing. Also, the aggregation scheme of GCN uses 1-hop neighbors, and hence lacks the ability to capture long-range dependencies. To circumvent these issues, we define a higher-order implicit fairing network (HOIF-Net) with the following layer-wise propagation rule:</p><formula xml:id="formula_14">H ( +1) = ? ( K k=1H ( ) kW ( ) k ),<label>(13)</label></formula><p>whereH ( )</p><formula xml:id="formula_15">k = (1 ? ?)S k H ( ) + ?X,<label>(14)</label></formula><p>and S k is the k-th power of the normalized adjacency matrix with self-added loops. Each  given by Eq. <ref type="formula" target="#formula_0">(14)</ref> is a weighted sum of the transformed feature matrix S k H ( ) for the -layer and the initial feature matrix X. Intuitively, the transformation S k H ( ) yields a smooth hidden representation, and hence encourages similar predictions among k-hop neighboring nodes. The weighting factor ? represents the weight assigned to the initial feature information that needs to be carried over, as the number of layers increase. <ref type="figure" target="#fig_2">Figure 1</ref> shows an illustration of the layer-wise propagation rule of HOIF-Net when K = 3. Long-range dependencies between body joints are captured by high-order graph convolutions, which take into account distant neighbors when updating the learned node features. Note that HOIF-Net uses residual connections between the initial feature matrix and each hidden layer. Residual connections not only allow the model to carry over information from the initial node attributes, but also help facilitate training of multi-layer networks. Model Architecture. The architecture of our proposed model for 3D human pose estimation is illustrated in <ref type="figure" target="#fig_3">Figure 2</ref>. The input consists of 2D keypoints generated via a 2D pose detector. The generated output of the proposed model consists of predicted 3D pose coordinates. We use higher-order graph convolutional layers defined by the layer-wise propagation rule of HOIF-Net to capture long-range structural information between body joints. as output. We use ten higher-order graph convolutional layers, each of which is followed by batch normalization and ReLU activation function, except the last convolutional layer.</p><p>Model Prediction. The output of the last higher-order graph convolutional layer of HOIF-Net contains the final output node embeddings, which are given b?</p><formula xml:id="formula_16">Y = (? 1 , . . . ,? N ) ? R N?3 ,<label>(15)</label></formula><p>where? i is a three-dimensional raw vector of predicted 3D pose coordinates.</p><p>Model Training. The parameters (i.e. weight matrices for different layers) of the proposed HOIF-Net model for 3D human pose estimation are learned by minimizing the loss function</p><formula xml:id="formula_17">L = 1 N N ? i=1 y i ?? i 2 2 ,<label>(16)</label></formula><p>which is the mean squared error between the 3D ground truth poses y i and estimated 3D joint poses? i over a training set consisting of N human poses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>Datasets. We perform quantitative and qualitative evaluations on two standard, large-scale benchmark datasets: Human 3.6M and MPI-INF-3DHP. The Human 3.6M dataset <ref type="bibr" target="#b13">[14]</ref> contains 3.6 million 3D human poses for 11 professional actors and corresponding images captured by a high-speed motion capture system with four different cameras. Each actor performs 15 actions (scenarios), including directions, discussion, eating, greeting, talking on the phone and so on. For data preprocessing, we apply standard normalization to the 2D and 3D poses before feeding the data to the model in line with previous work <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b38">39]</ref>. For the MPI-INF-3DHP dataset <ref type="bibr" target="#b22">[23]</ref>, there are 8 actors performing 8 activities each. These activities range from walking and sitting to complex exercise poses and dynamic actions.</p><p>Evaluation Protocols and Metrics. For the Human 3.6M benchmark, there are two commonly used evaluation protocols, referred to as Protocol #1 and Protocol #2. Both protocols use 5 subjects (S1, S5, S6, S7, S8) for training and 2 subjects (S9, S11) for testing. Under Protocol #1, we report the mean per joint position error (MPJPE), which computes the average Euclidean distance between the predicted 3D joint positions and ground truth after the alignment of the root joint (central hip). Under Protocol #2, we report the Procrustes-aligned mean per joint position error (PA-MPJPE), where MPJPE is computed after rigid alignment of the prediction with respect to the ground truth. Both error metrics are measured in millimeters, and lower values indicate better performance. For MPI-INF-3DHP, we adopt two commonly-used evaluation metrics, namely Percentage of Correct Keypoints (PCK) under 150mm and the Area Under the Curve (AUC), following previous works <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35]</ref>. Higher values of PCK and AUC indicate better performance.</p><p>Implementation Details. We train our model for 50 epochs using the Adam optimizer with a learning rate of 0.001. We set the decay factor to 0.96 per 100,000 steps, and the batch size to 64. We also set the hyperparameters ? and ? to 0.2 and 0.5, respectively, via grid search with cross-validation on the training set. To extract 2D keypoints from input images and following common practices in previous work <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b38">39]</ref>, we employ the cascaded pyramid network (CPN) <ref type="bibr" target="#b4">[5]</ref>, which uses bounding boxes obtained by Mask R-CNN <ref type="bibr" target="#b12">[13]</ref>. For K-hop feature concatenation, we set the value of K to 3, as illustrated in <ref type="figure" target="#fig_2">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results and Analysis</head><p>Quantitative Results. In <ref type="table" target="#tab_0">Tables 1 and 2</ref>, we summarize the performance comparison results of our HOIF-Net model and various state-of-the-art methods for 3D pose estimation.</p><p>As can be seen, our model performs the best in most of the actions and also on average under both Protocol #1 and Protocol #2, indicating that HOIF-Net is very competitive. Under Protocol #1, <ref type="table" target="#tab_0">Table 1</ref> shows that HOIF-Net performs better than high-order GCN [39] on 14 out of 15 actions, yielding an error reduction of approximately 1.44% on average over high-order GCN. Moreover, our model outperforms semGCN <ref type="bibr" target="#b36">[37]</ref> by a relative improvement of 4.86% on average. Under Protocol #2, <ref type="table" target="#tab_1">Table 2</ref> shows that our model performs better than highorder GCN with 1.83% error reduction on average, and also achieves better performance on 11 out of 15 actions.   <ref type="table" target="#tab_2">Table 3</ref> reports the quantitative comparison results of HOIF-Net and baseline methods on the MPI-INF-3DHP dataset. As can be seen, our method achieves the best performance on all evaluation metrics.</p><p>Qualitative Results. <ref type="figure" target="#fig_4">Figure 3</ref> shows the qualitative results obtained by our model for various actions. Notice that the predictions made by HOIF-Net match perfectly the ground truth, indicating the effectiveness of our proposed approach in tackling the 2D-to-3D pose estimation problem.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ablation study</head><p>In our ablation experiments, we use the 2D ground truth as input to our model. We start by investigating the effect of the hyperparameters ? and ? on model performance. We conduct a sensitivity analysis to investigate how the performance of our model changes as we vary these two hyperparameters. In <ref type="figure" target="#fig_5">Figure 4</ref> (left), we analyze the effect of ? by plotting the error values vs. ? for both protocols, where ? varies from 0.1 to 0.5, and ? is set to 1.</p><p>We can see that our model achieves the lowest error values of MPJPE and PA-MPJPE when ? = 0.12 and ? = 0.1, respectively. In <ref type="figure" target="#fig_5">Figure 4</ref> (right), we plot the error values vs. ? for both protocols by varying the value of ? from 0.1 to 1.5, and setting the value of ? to 0.1. Notice that the best performance is generally achieved when ? = 0.7</p><p>We also evaluate our method against SemGCN (Zhao et al. <ref type="bibr" target="#b36">[37]</ref>) and high-order GCN (Zou et al. <ref type="bibr" target="#b38">[39]</ref>), which are state-of-the-art GCN-based methods for 2D-to-3D pose estimation, and we report the results in <ref type="table" target="#tab_3">Table 4</ref>. As can be seen, our approach outperforms both semGCN and High-order GCN under Protocols #1 and #2. Under Protocol #1, our HOIF-Net model outperforms semGCN and high-order GCN by 4.02 mm and 1.4 mm, corresponding to error reductions of 9.54% and 3.54%, respectively. Under Protocol #2, HOIF-Net outperforms semGCN and high-order GCN by 3.79 mm and 1.33 mm, corresponding to error reductions of 11.3% and 4.28%, respectively. In addition, our model offers comparable performance as high-order GCN, while using a much smaller number of filters (64 compared to 96) and also the number of learned parameters is reduced by more than half.  <ref type="figure">Figure 5</ref> shows that the performance of the proposed HOIF-Net model on the Human3.6M dataset remains relatively stable as we increase the number of higher-order graph convolutional layers, demonstrating the robustness of our method against oversmoothing. <ref type="bibr" target="#b9">10</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>44.00</head><p>Average PA-MPJPE (mm) <ref type="figure">Figure 5</ref>: HOIF-Net's performance with increasing higher-order graph convolutional layers on the Human3.6M dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we proposed a higher-order implicit fairing network with initial residual connections for 3D human pose estimation, with the aim to alleviate the oversmoothing problem in graph convolutional networks, and also to capture long-range dependencies between body joints by enabling the model to aggregate multi-hop neighbors through feature concatenation. Empirical experiments and ablation studies showcase the merits of our model and demonstrate its competitive performance in comparison with state-of-the-art methods for 3D human pose estimation. For future work, we plan to apply the proposed framework to other downstream tasks such as semi-supervised node/graph classification and link prediction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(i, j)-th entry of S k counts the number of walks of length k between nodes i and j. For example, the (i, j)-th entry of S 2 gives the number of common neighbors of nodes i and j. The learnable weight matrixW( ) k is associated to the the node feature representationH ( ) k , and denotes concatenation. For each k-hop neighborhood, the node feature representationH</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of HOIF-Net feature concatenation for K = 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Overview of the proposed network architecture for 3D pose estimation. Our model takes 2D pose coordinates (17 joints) as input and generates 3D pose predictions(17 joints)   </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Qualitative results obtained by our model on the Human3.6M test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Parameter sensitivity analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Performance comparison of our model and baseline methods using MPJPE (in millimeters) between the ground truth and estimated pose on Human3.6M under Protocol #1. The last column report the average errors, and boldface numbers indicate the best 3D pose estimation performance. Eat Greet Phone Photo Pose Purch. Sit SitD. Smoke Wait WalkD. Walk WalkT. Avg. 53.7 50.9 52.4 57.8 71.3 50.2 49.1 63.5 76.3 54.1 51.6 56.5 41.7 45.3 54.8</figDesc><table><row><cell></cell><cell>Action</cell></row><row><cell cols="2">Method Dire. Disc. Martinez et al. [22] 51.8 56.2 58.1 59.0 69.5 78.4 55.2 58.1 74.0 94.6 62.3 59.1 65.1 49.5 52.4 62.9</cell></row><row><cell>Sun et al. [30]</cell><cell>52.8 54.8 54.2 54.3 61.8 67.2 53.1 53.6 71.7 86.7 61.5 53.4 61.6 47.1 53.4 59.1</cell></row><row><cell>Yang et al. [35]</cell><cell>51.5 58.9 50.4 57.0 62.1 65.4 49.8 52.7 69.2 85.2 57.4 58.4 43.6 60.1 47.7 58.6</cell></row><row><cell>Fang et al. [9]</cell><cell>50.1 54.3 57.0 57.1 66.6 73.3 53.4 55.7 72.8 88.6 60.3 57.7 62.7 47.5 50.6 60.4</cell></row><row><cell cols="2">Hossain &amp; Little [27] 48.4 50.7 57.2 55.2 63.1 72.6 53.0 51.7 66.1 80.9 59.0 57.3 62.4 46.6 49.6 58.3</cell></row><row><cell cols="2">Pavlakos et al. [25] 48.5 54.4 54.4 52.0 59.4 65.3 49.9 52.9 65.8 71.1 56.6 52.9 60.9 44.7 47.8 56.2</cell></row><row><cell>Sharma et al. [29]</cell><cell>48.6 54.5 54.2 55.7 62.2 72.0 50.5 54.3 70.0 78.3 58.1 55.4 61.4 45.2 49.7 58.0</cell></row><row><cell>Zhao et al. [37]</cell><cell>47.3 60.7 51.4 60.5 61.1 49.9 47.3 68.1 86.2 55.0 67.8 61.0 42.1 60.6 45.3 57.6</cell></row><row><cell cols="2">Li et al. [18] (BH) 62.0 69.7 64.3 73.6 75.1 84.8 68.7 75.0 81.2 104.3 70.2 72.0 75.0 67.0 69.0 73.9</cell></row><row><cell>Banik et al. [2]</cell><cell>51.0 55.3 54.0 54.6 62.4 76.0 51.6 52.7 79.3 87.1 58.4 56.0 61.8 48.1 44.1 59.5</cell></row><row><cell>Xu et al. [34]</cell><cell>47.1 52.8 54.2 54.9 63.8 72.5 51.7 54.3 70.9 85.0 58.7 54.9 59.7 43.8 47.1 58.1</cell></row><row><cell>Zou et al. [39]</cell><cell>49.0 54.5 52.3 53.6 59.2 71.6 49.6 49.8 66.0 75.5 55.1 53.8 58.5 40.9 45.4 55.6</cell></row><row><cell>Ours</cell><cell>47.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison of our model and baseline methods using PA-MPJPE between the ground truth and estimated pose on Human3.6M under Protocol #2. Eat Greet Phone Photo Pose Purch. Sit SitD. Smoke Wait WalkD. Walk WalkT. Avg. Little [27] 35.7 39.3 44.6 43.0 47.2 54.0 38.3 37.5 51.6 61.3 46.5 41.4 47.3 34.2 39.4 44.1 Lee et al. [16] 38.0 39.3 46.3 44.4 49.0 55.1 40.2 41.1 53.2 68.9 51.0 39.1 33.9 56.4 38.5 46.2 Li et al. [18] (BH) 38.5 41.7 39.6 45.2 45.8 46.5 37.8 42.7 52.4 62.9 45.3 40.9 45.3 38.6 38.4 44.3 Banik et al. 40.3 42.1 43.7 52.7 37.9 37.7 51.5 60.3 43.9 39.4 45.4 31.9 37.8 42.9</figDesc><table><row><cell></cell><cell>Action</cell></row><row><cell cols="2">Method Dire. Disc. Pavlakos et al. [24] 47.5 50.5 48.3 49.3 50.7 55.2 46.1 48.0 61.1 78.1 51.1 48.3 52.9 41.5 46.4 51.9</cell></row><row><cell>Zhou et al. [38]</cell><cell>47.9 48.8 52.7 55.0 56.8 49.0 45.5 60.8 81.1 53.7 65.5 51.6 50.4 54.8 55.9 55.3</cell></row><row><cell cols="2">Martinez et al. [22] 39.5 43.2 46.4 47.0 51.0 56.0 41.4 40.6 56.5 69.4 49.2 45.0 49.5 38.0 43.1 47.7</cell></row><row><cell>Sun et al. [30]</cell><cell>42.1 44.3 45.0 45.4 51.5 53.0 43.2 41.3 59.3 73.3 51.0 44.0 48.0 38.3 44.8 48.3</cell></row><row><cell>Fang et al. [9]</cell><cell>38.2 41.7 43.7 44.9 48.5 55.3 40.2 38.2 54.5 64.4 47.2 44.3 47.3 36.7 41.7 45.7</cell></row><row><cell>Hossain &amp; [2]</cell><cell>38.4 43.1 42.9 44.0 47.8 56.0 39.3 39.8 61.8 67.1 46.1 43.4 48.4 40.7 35.1 46.4</cell></row><row><cell>Xu et al. [34]</cell><cell>36.7 39.5 41.5 42.6 46.9 53.5 38.2 36.5 52.1 61.5 45.0 42.7 45.2 35.3 40.2 43.8</cell></row><row><cell>Zou et al. [39]</cell><cell>38.6 42.8 41.8 43.4 44.6 52.9 37.5 38.6 53.3 60.0 44.4 40.9 46.9 32.2 37.9 43.7</cell></row><row><cell>Ours</cell><cell>36.9 42.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Performance comparison of our model and baseline methods on the MPI-INF-3DHP dataset using PCK and AUC as evaluation metrics. Higher values in boldface indicate the best performance. Pavlakos et al. [25] 71.9 35.3 Habibie et al. [11] 70.4 36.0</figDesc><table><row><cell></cell><cell>Method</cell><cell>PCK AUC</cell><cell></cell></row><row><cell></cell><cell>Yang et al. [35]</cell><cell>69.0 32.0</cell><cell></cell></row><row><cell></cell><cell>Ours</cell><cell>72.8 36.5</cell><cell></cell></row><row><cell>Input</cell><cell>Prediction Ground Truth</cell><cell>Input</cell><cell>Prediction Ground Truth</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Performance comparison of our model and GCN-based methods.</figDesc><table><row><cell>Method</cell><cell cols="4">Filters Parameters MPJPE PA-MPJPE</cell></row><row><cell>SemGCN [37]</cell><cell>96</cell><cell>0.43M</cell><cell>42.14</cell><cell>33.53</cell></row><row><cell cols="2">High-order GCN [39] 96</cell><cell>1.20M</cell><cell>39.52</cell><cell>31.07</cell></row><row><cell>Ours</cell><cell>96</cell><cell>1.20M</cell><cell>38.12</cell><cell>29.74</cell></row><row><cell>Ours</cell><cell>64</cell><cell>0.54M</cell><cell>39.78</cell><cell>31.26</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">? 2021. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms. arXiv:2111.00950v1 [cs.CV] 1 Nov 2021</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">MixHop: Higher-order graph convolutional architectures via sparsified neighborhood mixing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amol</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazanin</forename><surname>Alipourfard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrayr</forename><surname>Harutyunyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">Ver</forename><surname>Steeg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aram</forename><surname>Galstyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">3D human pose regression using graph convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soubarna</forename><surname>Banik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><forename type="middle">Mendoza</forename><surname>Gracia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alois</forename><surname>Knoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Image Processing</title>
		<meeting>IEEE International Conference on Image essing</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploiting spatial-temporal relationships for 3D pose estimation via graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuhao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Jen</forename><surname>Cham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadia</forename><forename type="middle">Magnenat</forename><surname>Thalmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2272" to="2281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Simple and deep graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhewei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zengfeng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolin</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaliang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1725" to="1735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cascaded pyramid network for multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Pecognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Pecognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7103" to="7112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Optimizing network structure for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Ci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2262" to="2271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Implicit fairing of irregular meshes using diffusion and curvature flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Mathieu Desbrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">H</forename><surname>Schr?der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="317" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning pose grammar to encode human body configuration for 3D pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlu</forename><surname>Hao-Shu Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conference on Artificial Intelligence</title>
		<meeting>AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">3D hand shape and pose estimation from a single RGB image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuhao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuncheng</forename><surname>Zhou Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10833" to="10842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">In the wild human pose estimation using explicit 2D features and intermediate 3D representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikhsanul</forename><surname>Habibie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10905" to="10914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Wavelets on graphs via spectral graph theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied and Computational Harmonic Analysis</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="150" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mask R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">6M: Large scale datasets and predictive methods for 3D human sensing in natural environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Human3</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1325" to="1339" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Predict then propagate: Graph neural networks meet personalized pagerank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Propagating lstm: 3d pose estimation based on joint interdependency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoungoh</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inwoong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghoon</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European conference on computer vision</title>
		<meeting>European conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="123" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">CayleyNets: Graph convolutional neural networks with complex rational spectral filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Levie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="109" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Weakly supervised generative network for multiple 3D human pose hypotheses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conference</title>
		<meeting>British Machine Vision Conference</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deeper insights into graph convolutional networks for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3538" to="3545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">3D human pose estimation from monocular images with deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Asian Conference on Computer Vision</title>
		<meeting>Asian Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="332" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Comprehensive study of weight sharing in graph networks for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenkun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongqi</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiming</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision</title>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A simple yet effective baseline for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julieta</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayat</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2640" to="2649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Monocular 3D human pose estimation in the wild using improved CNN supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on 3D Vision</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Coarse-to-fine volumetric prediction for single-image 3D human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konstantinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7025" to="7034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Ordinal depth supervision for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7307" to="7316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">3D human pose estimation in video with temporal convolutions and semi-supervised training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Pavllo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7753" to="7762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exploiting temporal information for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imtiaz</forename><surname>Mir Rayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision</title>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="68" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Saad</surname></persName>
		</author>
		<title level="m">Iterative Methods for Sparse Linear Systems. SIAM</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Monocular 3D human pose estimation by generation and ordinal ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><forename type="middle">Teja</forename><surname>Varigonda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashast</forename><surname>Bindal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2325" to="2334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Compositional human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxiang</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2602" to="2611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimal surface smoothing as filter design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Golub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision</title>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">DFNets: Spectral CNNs for graphs with feedbacklooped filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asiri</forename><surname>Wijesinghe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Representation learning on graphs with jumping knowledge networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengtao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomohiro</forename><surname>Sonobe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Ichi Kawarabayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Monocular 3D pose estimation via pose grammar and data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">3D human pose estimation in the wild by adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5255" to="5264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">PairNorm: Tackling oversmoothing in GNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semantic graph convolutional networks for 3D human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubbasir</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3425" to="3435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Towards 3D human pose estimation in the wild: a weakly-supervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="398" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">High-order graph convolutional networks for 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiming</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenkun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conference</title>
		<meeting>British Machine Vision Conference</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
