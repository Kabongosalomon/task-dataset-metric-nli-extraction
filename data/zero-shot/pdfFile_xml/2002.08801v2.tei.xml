<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Guiding attention in Sequence-to-sequence models for Dialogue Act prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Colombo</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LTCI</orgName>
								<orgName type="institution" key="instit1">Telecom Paris</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">IBM GBS France</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emile</forename><surname>Chapuis</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LTCI</orgName>
								<orgName type="institution" key="instit1">Telecom Paris</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Manica</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">IBM Zurich</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Vignon</surname></persName>
							<email>emmanuel.vignon@fr.ibm.com</email>
							<affiliation key="aff1">
								<orgName type="institution">IBM GBS France</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovana</forename><surname>Varni</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LTCI</orgName>
								<orgName type="institution" key="instit1">Telecom Paris</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chloe</forename><surname>Clavel</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LTCI</orgName>
								<orgName type="institution" key="instit1">Telecom Paris</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Guiding attention in Sequence-to-sequence models for Dialogue Act prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The task of predicting dialog acts (DA) based on conversational dialog is a key component in the development of conversational agents. Accurately predicting DAs requires a precise modeling of both the conversation and the global tag dependencies. We leverage seq2seq approaches widely adopted in Neural Machine Translation (NMT) to improve the modelling of tag sequentiality. Seq2seq models are known to learn complex global dependencies while currently proposed approaches using linear conditional random fields (CRF) only model local tag dependencies. In this work, we introduce a seq2seq model tailored for DA classification using: a hierarchical encoder, a novel guided attention mechanism and beam search applied to both training and inference. Compared to the state of the art our model does not require handcrafted features and is trained end-to-end. Furthermore, the proposed approach achieves an unmatched accuracy score of 85% on SwDA, and state-of-the-art accuracy score of 91.6% on MRDA.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In natural language processing research, the dialogue act (DA) concept plays an important role. DAs are semantic labels associated with each utterance in a conversational dialogue that indicate the speaker's intention, e.g., question, backchannel, statement-non-opinion, statement opinion. A key to model dialogue is to detect the intent of the speaker: correctly identifying a question gives an important clue to produce an appropriate response. As can be observed in Table 1, DA classification relies on its conversational aspect, i.e., predicting an utterance's DA requires the knowledge of previous sentences and their associated act labels. For example, if a speaker asks a question, the interlocutor will answer with a response, analogously, a "Greeting" or a "Farwell" will be followed by a similar dialogue act. This means that in a conversation there is a sequential structure in the emitted dialogue acts. This poses the basis for the adoption of a novel perspective on the DA classification problem, i.e., from a multi-classification task to a sequence labeling one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speaker Utterance</head><p>A Is there anyone who doesn't know Nancy? A Do you -Do you know Nancy ? B</p><p>Me? B</p><p>Mm-hmm B I know Nancy Limitations of current models: Current state-of-the-art models rely on the use of linear Conditional Random Field (CRF) combined with a recurrent neural network based encoder <ref type="bibr" target="#b15">(Li et al. 2018a;</ref><ref type="bibr" target="#b3">Chen et al. 2018;</ref><ref type="bibr" target="#b21">Raheja and Tetreault 2019)</ref> to model DA sequential dependencies. Unfortunately such approaches only capture local dependencies between two adjacent dialogue acts. For instance, if we consider the example in <ref type="table" target="#tab_0">Table 1</ref> we can see that the last statement "I know Nancy" is a response to the first question "Is there anyone who doesn't know Nancy" and the knowledge of the previous backchannel does not help the prediction of the last dialogue act. Therefore, we must consider dependencies between labels with a scope that is wider than two successive utterances. In Neural Machine Translation (NMT), the problem of global dependencies has been addressed using seq2seq models (Sutskever, Vinyals, and Le 2014) that follow the encoder-decoder framework. The encoder embeds an input sentence into a single hidden vector which contains both global and local dependencies, and the hidden vector is then decoded to produce an output sequence. In this work, we propose a seq2seq architecture tailored towards DA classification paving the way for further innovations inspired by advances in NMT research.</p><p>Contributions: In this work (1) we formalise the Dialogue Act Prediction problem in a way that emphasises the relations between DA classification and NMT, (2) we demonstrate that the seq2seq architecture suits better to the DA classification task and (3) we present a seq2seq model leveraging NMT techniques that reaches an accuracy of 85%, outperforming the state of the art by a margin of around 2%, on the Switchboard Dialogue Act Cor-pus (SwDA) <ref type="bibr" target="#b24">(Stolcke et al. 1998</ref>) and a state-of-the-art accuracy score of 91,6% on the Meeting Recorder Dialogue Act (MRDA). This seq2seq model exploits a hierarchical encoder with a novel guided attention mechanism that fits with our setting without any handcrafted features. We finetune our seq2seq using a sequence level training objective making use of the beam search algorithm. To our knowledge, this is among the first seq2seq model proposed for DA classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DA classification</head><p>Several approaches have been proposed to tackle the DA classification problem. These methods can be divided into two different categories. The first class of methods relies on the independent classification of each utterance using various techniques, such as HMM <ref type="bibr" target="#b25">(Stolcke et al. 2000)</ref>, SVM <ref type="bibr" target="#b26">(Surendran and Levow 2006)</ref> and Bayesian Network (Keizer, op den Akker, and <ref type="bibr" target="#b8">Nijholt 2002)</ref>. The second class, which achieves better performance, leverages the context, to improve the classifier performance by using deep learning approaches to capture contextual dependencies between input sentences <ref type="bibr" target="#b2">(Bothe et al. 2018;</ref><ref type="bibr" target="#b9">Khanpour, Guntakandla, and Nielsen 2016)</ref>. Another refinement of input contextbased classification is the modelling of inter-tag dependencies. This task is tackled as sequence-based classification where output tags are considered as a DA sequence Two classical benchmarks are adopted to evaluate DA classification systems: the Switchboard Dialogue Act Corpus (SwDA) <ref type="bibr" target="#b24">(Stolcke et al. 1998</ref>) and the Meeting Recorder Dialogue Act (MRDA) <ref type="bibr" target="#b6">(Janin et al. 2003)</ref>. State-of-the-art techniques achieve an accuracy of 82.9% <ref type="bibr" target="#b15">(Li et al. 2018a;</ref><ref type="bibr" target="#b21">Raheja and Tetreault 2019)</ref>. To capture input contextual dependencies they adopt a hierarchical encoder and a CRF to model inter-tag dependencies. The main limitation of the aforementioned architecture is that a linear-CRF model is able to only capture dependencies at a local level and fails to capture non local dependencies. In this paper, we tackle this issue with a sequence-to-sequence using a guided attention mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Seq2seq models</head><p>Seq2seq models have been successfully applied to NMT, where modeling non local dependencies is a crucial challenge. DA classification can be seen as a problem where the goal is to map a sequence of utterances to a sequence of DA. Thus, it can be formulated as sequence to sequence problem very similar to NMT. The general architecture of our seq2seq models (Sutskever, Vinyals, and Le 2014) follows a classical encoder-decoder approach with attention <ref type="bibr" target="#b18">(Luong, Pham, and Manning 2015)</ref>. We use GRU cells , since they are faster to train than LSTM ones (Jozefowicz, Zaremba, and <ref type="bibr" target="#b7">Sutskever 2015)</ref>. Recent advances have improved both the learning and the inference process, producing sequences that are more coherent by means of sequence level losses Wiseman and Rush <ref type="bibr">(2016)</ref> and various beam search settings <ref type="bibr" target="#b29">(Wu et al. 2016;</ref><ref type="bibr">?)</ref>. The closest setting where seq2seq model have been successfully used is dependency parsing <ref type="bibr" target="#b16">(Li et al. 2018b)</ref>, where output dependencies are crucial to achieve state-of-the-art performance. In our work we adjust NMT techniques to the specifics of DA classification.</p><p>3 Problem statement DA classification as an NMT problem First, let's define the mathematical notations we will adopt in this work. We have a set D of conversations, i.e D = (C 1 , C 2 , . . . , C |D| ) with Y = (Y 1 , Y 2 , . . . , Y |D| ) the corresponding set DA labels. A conversation C i is a sequence of utterances, namely C i = (u 1 , u 2 , . . . , u |Ci| ) with Y i = (y 1 , y 2 , . . . , y |Ci| ) the corresponding sequence of DA labels. Thus, each utterance u i is associated with a unique DA label y i ? Y where Y is the set of all the possible dialogue acts. Finally, an utterance u i can be seen as a sequence of words, i.e u i = (? i 1 , ? i 2 , . . . , ? i |ui| ). In NMT, the goal is to associate for any sentence X l1 = (x l1 1 , ..., x l1 |X l 1 | ) in language l 1 a sentence X l2 = (x l2 1 , ..., x l2 |X l 2 | ) in language l 2 where x l k i is the i word in the sentence in language l k . Using this formalism, it is straightforward to notice two main similarities (S 1 , S 2 ) between DA classification and NMT. (S 1 ) In NMT and DA classification, the goal is to maximise the likelihood of the output sequence given the input sequence (P (X l2 |X l1 ) versus P (Y i |C i )). (S 2 ) For the two tasks, there are strong dependencies between units composing both the input and output sequences. In NMT, those units are words (x i and y i ), in DA classification those units are utterances and DA labels (u i and y i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specifics of DA classification</head><p>While NMT and DA classification are similar under some point of views, three differences are immediately apparent (D i ). (D 1 ) In NMT, the input units x i represent words, in DA classification u i are input sequences composed with words. Considering the set of all possible sequences as input (context consideration leads to superior performance) implies that the dimension of the input space several order of magnitude larger than compared to a standard NMT. (D 2 ) In DA, we have a perfect alignment between input and output sequences (hence T = T ). Some languages, e.g., French, English, Italian share a partial alignment, but in DA classification we have a strong mapping between y i and x i . (D 3 ) In NMT, the input space (number of words in l 1 ) is approximately the same size of the output space (number of words in l 2 ). In our case the output space (number of DA tags |Y| &lt; 100 has a limited size, with a dimension that is many order of magnitude smaller than the input space one.</p><p>In the following, we propose an end-to-end seq2seq architecture for DA classification that leverages (D 1 ) using a hierarchical encoder, (D 2 ) through a guided attention mechanism and (D 3 ) using beam search during both training and inference, taking advantage of the limited dimension of the output space.</p><p>In Seq2seq, the encoder takes a sequence of sentences and represents it as a single vector H i ? R d and then pass it to the decoder for tag generations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoders</head><p>In this section we introduce the different encoders we consider in our experiments. We exploit the hierarchical structure of the dialogue to reduce the input space size (D 1 ) and to preserve word/sentence structure. During both training and inference, the context size is fixed to T . Formally, an encoder takes as input a fixed number of utterances (u i?T , .., u i ) and outputs a vector H i ? R d which will serve to initialize the hidden state of the decoder. The first level of the encoder computes E ut , an embedding of u t based on the words composing the utterance, and the next levels compute H i based on E ut . Vanilla RNN encoder: The vanilla RNN encoder (VGRU E ) introduced by Sutskever, Vinyals, and Le <ref type="formula">(2014)</ref> is considered as a baseline encoder. In the vanilla encoder</p><formula xml:id="formula_0">E ui = 1 |ui| |ui| k=1 E w i k where E w i k is an embedding of w i k .</formula><p>To better model dependencies between consecutive utterances, we use a bidirectional GRU :</p><formula xml:id="formula_1">? ?? ? h s i?T = ? ?? ? h s i?T = ? ? 0 ? ? h s t = ? ?? ? GRU (E ut ), t ? [i ? T, i] ? ? h s t = ? ?? ? GRU (E ut ), t ? [i, i ? T ] H i = [ ? ? h s i , ? ? h s i ]</formula><p>(1)</p><p>Hierarchical encoders: The vanilla encoder can be improved by computing E ui using bi-GRU. This hierarchical encoder (HGRU) is in line with the one introduced by Sordoni et al. <ref type="bibr">(2015)</ref>. Formally E ui is defined as it follows:</p><formula xml:id="formula_2">? ? h w 0 = ? ? h w 0 = ? ? 0 ? ? h w t = ? ?? ? GRU (E w i t ), t ? [1, |u i |] ? ? h w t = ? ?? ? GRU (E w i t ), t ? [|u i |, 1] E ui = [ ? ? ? h w |ui| , ? ? ? h w |ui| ]</formula><p>(2) H i is then computed using Equation 1. Intuitively, the first GRU layer (Equation 2) models dependencies between words (the hidden state of the word-level GRU is reset at each new utterance), and the second layer models dependencies between utterances. Persona hierarchical encoders: In SwDA, a speaker turn can be splitted in several utterances. For example, if speaker A is interacting with speaker B we might encounter the sequence (AAABBBAA) 1 . We propose a novel Persona Hierarchical encoder (PersoHGRU) to better model speakerutterance dependencies. We introduce a persona layer be-1 In SwDA arround two third of the sentence have at least a AA or BB tween the word and the sentence levels, see <ref type="figure" target="#fig_1">Figure 1</ref>:</p><formula xml:id="formula_3">? ? h p t = ? ? 0 if t and t ? 1 have different speakers ? ?? ? GRU (E ut?1 ) ? ? h p t = ? ? 0 if t and t + 1 have different speakers ? ?? ? GRU (E ut+1 ) E p u k = [ ? ? h p k , ? ? h p k ] ?k ? [i ? T, i] (3) H i is then obtained following Equation 1 where E ui is re- placed by E p ui .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Decoders</head><p>In this section, we introduce the different decoders we compare in our experiments. We introduce a novel form of attention that we name guided attention. Guided attention leverages the perfect alignment between input and output sequences (D 2 ). The decoder computes the probability of the sequence of output tags based on:</p><formula xml:id="formula_4">p(yi?T , . . . , yi|ui?T , , ui) = i k=i?T p(y k |Hi, y k?1 , . . . , yi?T ) (4) see Equation 1.</formula><p>Vanilla decoder: The vanilla decoder (VGRU D ) is similar to the one introduced by Sutskever, Vinyals, and Le <ref type="bibr">(2014)</ref>.</p><p>Decoders with attention: In NMT, the attention mechanism forces the seq2seq model to learn to focus on specific parts of the sequence each time a new word is generated and let the decoder correctly align the input sequence with output sequence. In our case, we follow the approach described by Bahdanau, Cho, and Bengio <ref type="bibr">(2014)</ref> and we define the context vector as:</p><formula xml:id="formula_5">c k = i j=i?T ? j,k h s j (5)</formula><p>where ? j,k scores how well the inputs around position k and the output at position j match. Since we have a perfect alignment (D 2 ), we know a priori on which sequence the decoder needs to focus more at each time step. Taking into account this aspect of the problem, we propose three different attention mechanisms. Vanilla attention: This attention represents our baseline attention mechanism and it is the one proposed by Bahdanau, Cho, and Bengio <ref type="bibr">(2014)</ref>, where:</p><formula xml:id="formula_6">? j,k = sof tmax(a(h Dec k?1 , h s j ))<label>(6)</label></formula><p>and a is parametrized as a feedforward neural network.</p><p>Hard guided attention: The hard guided attention forces the decoder to focus only on the u i while predicting y i :</p><formula xml:id="formula_7">? j,k = 0, if k = j 1, otherwise<label>(7)</label></formula><p>Soft guided attention: The soft guided attention guides the decoder to mainly focus on the u i while predicting y i , but allows it to have a limited focus on other parts of the input sequence.</p><formula xml:id="formula_8">? j,k = a(h Dec k?1 , h s j ), if k = j 1 + a(h Dec k?1 , h s j ), otherwise (8) ? j,k = sof tmax( ? j,k )<label>(9)</label></formula><p>where a is parametrised as a feedforward neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and inference</head><p>In this section, we describe the training and the inference strategies used for our models. A seq2seq model aims to find the best sentence for a given source sentence. This poses a computational challenge when the output vocabulary size is large, since even by using beam search it's expensive to explore multiple paths. Since our output vocabulary size is limited (D 3 ), we do not incur in this problem and we can use beam search during both training and inference.</p><p>Beam search: In our work we measure the sequence likelihood based on the following formula:</p><formula xml:id="formula_9">s(? k , u i ) = log P (? k |u i ) lp(? k )<label>(10)</label></formula><p>where</p><formula xml:id="formula_10">u i = (u i?T , . . . , u i ) and? k = (? i?T , . . . ,? i?T +k )</formula><p>is the current target, and lp(?) = (5+|?|) ? (5+1) ? is the length normalisation coefficient <ref type="bibr" target="#b29">(Wu et al. 2016)</ref>. At each time step the B most likely sequences are kept (B corresponding to the beam size).</p><p>Training objective: For training we follow Wiseman and Rush <ref type="bibr">(2016)</ref> and train our model until convergence with a token level loss and fine tune it by minimising the expected risk L RISK defined as:</p><formula xml:id="formula_11">L RISK = ??U(C i) cost(?, y i )p(?|u i ) ? ?U(ui) p(?|u i )<label>(11)</label></formula><p>where U (u i ) is the set of the sequences generated by the model using a beam search algorithm for the input u i , and cost(?, y i ) is defined, for a given a candidate sequence? and a target y i , as:</p><formula xml:id="formula_12">cost(?, y i ) = 1 if? i = y i 0 otherwise (12)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GRU/HGRU CRF baseline</head><p>State-of-the-art models use conditional random fields which model dependencies between tags on top of an GRU or a HGRU encoder which computed an embedding of the a variable number of utterances sentences . We have implemented our own CRF (Baseline CRF ) following the work of Kumar et al. <ref type="bibr">(2018)</ref>:</p><formula xml:id="formula_13">p(y i , . . . , y i?T , u i , . . . , u i?T ; ?) = T t=i ?(y t?1 , y t , ?(o t ); ?) Y T t=i ?(y t , y t?1 , ?(o t ); ?)<label>(13)</label></formula><p>Here ? is the set of parameters corresponding to the CRF layer, and ? is the feature function, providing us with unary and pairwise potentials. Let ? : R H ? R |Y| be the dense representation of each utterance's output provided by the encoder. ? can be seen as the unary feature function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Protocol</head><p>In this section we describe the experimental protocols adopted for the evaluation of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>We consider two classical datasets for Dialogue Act Classification: The Switchboard Dialogue Act Corpus and the MRDA. Since our models explicitly generate a sequence of tags we compute the accuracy on the last generated tag. Both datasets are already segmented in utterances and each utterance is segmented in words. For each dataset, we split each conversation C i in sequence of utterances of length T = 5 2 . SwDA: The Switchboard-1 corpus is a telephone speech corpus <ref type="bibr" target="#b24">(Stolcke et al. 1998)</ref>, consisting of about 2.400 two-sided telephone conversation among 543 speakers with about 70 provided conversation topics. The dataset includes information about the speakers and the topics and has 42 different tags. In this dataset global dependency plays a key role due to the large amount of backchannel (19%), abandoned or turn-exit (5%), uninterpretable acts (1%). In this context, any models that only take into account local dependencies will fail at extracting information to distinguish between ambiguous tags.  <ref type="bibr" target="#b17">(Loshchilov and Hutter 2017)</ref> with a learning rate of 0.001, which is updated using a scheduler with a patience of 15 epochs and a decrease rate of 0.5. The gradient norm is clipped to 5.0, weight decay is set to 5e5, and dropout (Le-Cun, Bengio, and Hinton 2015) is set to 0.3. The maximum sequence length is set to 30. Best performing model is an encoder with size of 40 and a decoder with size 400. For VGRU E we use two layers for the BiGRU layer, for hierarchical models we use BiGRU with a single layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments &amp; Results</head><p>In this section we propose a set of experiments in order to investigate the performance of our model compared to existing approaches with respect to the difficulties highlighted in the introduction.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Global dependencies analysis:</head><p>In <ref type="table" target="#tab_5">Table 3</ref> we present two examples where our seq2seq use contextual information to disambiguate the tag and to predict the correct label. In the first example, "It can be a pain" without context can be interpreted both as statement non-opinion (sd) or statement opinion (sv). Our seq2seq uses the surrounding context (two sentences before) to disambiguate and assign the sv label . In the second example, the correct tag assigned to "Oh, okay" is a response acknowledgement (bk) and not backchannel (b). The key difference between bk and b is that an utterance labelled with bk has to be produced within a question-answer context, whereas b is a continuer 4 . In our example, the global context this is a question/reply situation: the first speaker asks a question ("What school is it"), the second replies then, the first speaker answers to the reply. This observation reflects the fact CRF models only handle local dependencies where seq2seq models consider global ones as well.   Experiment 2: What is the best encoder?</p><p>In <ref type="table" target="#tab_6">Table 4</ref>, we present the results of the three encoders presented in Section 4 on both datasets. For SwDA and MRDA, we observe that a seq2seq equipped with a hierarchical encoder outperforms models with Vanilla RNN encoder, while reducing the number of learned parameters.</p><p>The VGRU D does not play well with the PersoHGRU encoder. When combined with a guided attention mechanism, the PersoHGRU exhibits competitive accuracy on SwDA. However on MRDA, adding a personna layer harms the accuracy. This suggests either that the information related to the speaker is irrelevant for our task (no improvement observed while adding persona information) 5 , or that the considered hierarchy is not the optimal structure to leverage this information.</p><p>Our final model makes use of the HGRU encoder since in most of the settings it exhibits superior performance.</p><p>Experiment 3: Which attention mechanism to use?</p><p>The seq2seq encodes a source sentence into a fixed-length vector from which a decoder generates a sequence of tags. Attention forces the decoder to strengthen its focus on the source sentences that are relevant to predicting a label.</p><p>In NMT (Luong, Pham, and Manning 2015), complementing a seq2seq with attention contributes to generate better sentences. In <ref type="table" target="#tab_6">Table 4</ref> we see that in most the case, the use of a simple attention mechanism provides a rather small improvement with VGRU and harms a bit the performances with a HGRU encoder. In case of a seq2seq composed with a PersoHGRU and a decoder without attention the learning fails: the decrease of the training loss is relatively small and seq2seq fails to generalise. It appears that in DA classification where sequences are short (5 tags), Vanilla attention does not have as much as impact as in NMT (that have longer sequences with more complex global dependencies).</p><p>If we consider an HGRU encoder, we observe that our proposed guided attention mechanisms improves dev accuracy which demonstrates the importance of easing the task by using prior knowledge on the alignment between the utterances and the tags. Indeed, while decoding there is a direct correspondence between labels and utterances meaning that y i is associated with u i . The soft guided attention will mainly focus on the current utterance with a small additional focus on the context where hard guided attention will only consider the current utterance. Improvement due to guided attention demonstrates that the alignment between input/output is a key prior to include in our model. Attention analysis: <ref type="figure" target="#fig_2">Figure 2</ref> shows a representative example of the attention weights of the three different mechanisms. The seq2seq with a normal attention mechanism is characterised by a weight matrix far from the identity (especially the lower right part). While decoding the last tags, this lack of focus leads to a wrongly predicted label for a simple utterance: "Uh-Huh" (backchannel). Both guided attention mechanisms focus more on the sentence associated with the tag, at each time step, and predict successfully the last DA.</p><p>Since the hard guided attention decoder exhibit overall the best results (on both SwDA and MRDA) and does not require any additional parameter we will use it for our final model. Compared to NMT, output size is drastically smaller (Y SwDA = 42 while Y MRDA = 5) for DA classification. When considering alternative paths with small output space in imbalanced datasets the beam search is more likely to consider very unlikely sequences as alternatives (eg. "s s s s s"). Fine tuning with a sequence loss: As previously mentioned, using beam search during inference only leads to a limited improvement in accuracy. We finetune a seq2seq composed with a HGRU encoder and a decoder with hard guided attention (this model has been selected in the previous steps) with the introduced sequence level loss describes in Section 4. <ref type="table" target="#tab_8">Table 5</ref> shows that this fine tuning steps improves the performances of 1% on SwDA (84% vs 85%) and 1.2% on RMDA (90.4% vs 91.6%). seq2seq BEST : Our seq2seq BEST model is composed of a HGRU encoder and a decoder with hard guided attention finetuned with B train = 2 and B inf = 5 for SwDA and B train = 5 and B inf = 1 for SwDA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 5: Comparison with state-of-the-art models</head><p>In this section, we compare the performances of seq2seq BEST with other state of the art models and analyse the performances of the models. <ref type="table" target="#tab_9">Table 6</ref> shows the performances of best performing model seq2seq BEST on the test set. seq2seq BEST achieves an accuracy of 85% on the SwDA corpora. This model outperforms Chen et al. <ref type="bibr">(2018)</ref> and <ref type="bibr" target="#b21">Raheja and Tetreault (2019)</ref> which achieve <ref type="bibr">6</ref> The considered beam size are small compared to other applications <ref type="bibr" target="#b13">(Li et al. 2016a)</ref>. While increasing the beam size, we see that the beam search become very conservative <ref type="bibr" target="#b5">(Gimpel et al. 2013</ref>) and tends to output labels highly represented in the training set (e.g., sd for SwDA).   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we have presented a novel approach to the DA classification problem. We have shown that our seq2seq model, using a newly devised guided attention mechanisms, achieves state-of-the-art results thanking its ability to better model global dependencies. Tags in SwDA: SwDA extends the Switchboard-1 corpus with tags from the SWBD-DAMSL tagset. The 220 tags were reduced to 42 tags. The resulting tags include dialogue acts like statement-non-opinion, acknowledge, statementopinion, agree/accept, etc. The average speaker turns per conversation, tokens per conversation, and tokens per utterance are 195.2, 1,237.8, and 7.0, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Full results for Experiment 4: How to leverage beam search to improve the performance?</head><p>Tab 8 shows the influence of the varying number of beam size during inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Error analysis</head><p>The confusion matrix on SwDA (see <ref type="figure" target="#fig_4">Figure 3</ref>) illustrates that our model faces same difficulties as human annotator: sd is often confused with sv, bk with b, qo with qw. Due to high imbalance of SwDA, our system fails to recognise underrepresented labels (e.g. no and ft).</p><p>The confusion Matrix on MRDA shows that, here, the DA classification is easier compared to SwDA with fewer tags and classes that are more easily distinguished. seq2seq BEST reaches a perfect score at recognising questions. One of the reasons for the mislabelling between backchannel (b) and statement (s) is that the MRDA dataset is highly imbalanced, with more than 50% of the utterances labelled as class s. True label 0.88 0.01 0.10 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.98 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.36 0.00 0.64 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.10 0.05 0.00 0.82 0.00 0.00 0.00 0.00 0.00 0.00 0.12 0.00 0.00 0.00 0.82 0.00 0.00 0.00 0.00 0.00 0.00 0.47 0.00 0.00 0.00 0.53 0.00 0.00 0.00 0.00 0.10 0.00 0.20 0.00 0.00 0.00 0.70 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.11 0.00 0.00 0.89 0.00 0.00 0.67 0.00 0.00 0.00 0.00 0.00 0.33 0.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(</head><label></label><figDesc>Li et al. 2018a; Kumar et al. 2018; Stolcke et al. 2000; Chen et al. 2018; Raheja and Tetreault 2019).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Seq2seq model architecture for DA classification. (a) The encoder is composed with three different levels representing a different hierarchical level in the dialogue. The utterances are encoded at: word level (purple), persona level (orange) and sentence level (green). (b) The decoder (blue) is responsible to generate for each utterance a DA exploiting the last state of the encoder as initial hidden state.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Attention matrix visualisation on MRDA for the fixed context of 5 utterances. Green color for predicted label indicates a correct label, orange color indicates a mistake. (a) stands for the HGRU with attention, (b) stands for the HGRU with hard guided attention, (c) is HGRU with soft guided attention.Experiment 4: How to leverage beam search to improve the performance?Beam Search allows the seq2seq model to consider alternative paths in the decoding phase. Beam Search during inference: Using beam search provides a low improvement (maximum absolute improvement of 0.2%) 6 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Confusion Matrix for our best performing seq2seq model on SwDA for 10 out of 42 tags. For label designation see Section 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Confusion Matrix for our best performing seq2seq model on MRDA. For label designation see Section 5. SwDA Encoder Decoder VGRU D GRU att. GRU soft guid. att. GRU hard guid. att. .5 88.5 88.5 88.5 88.5 88.2 88.3 88.3 88 .7 88.8 88.8 HGRU 90.0 90.0 90.0 89.9 90.0 90.3 90.0 90.2 90.2 90.4 90.4 90.4 PersoHGRU 66.2 66.2 66.5 87.7 87.7 87.8 88.2 88.7 88.9 86.9 86.9 86.9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Example of conversation from Switchboard Dialogue Act Corpus. A is speaking with B.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Accuracy of a seq2seq on dev test and Baseline CRF on SwDA and MRDA. Bold results exhibit significant differences (p-value &lt; 0.01) according to the Wilcoxon Mann Whitney test performed on 10 runs using different seeds.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Example of predicted sequence of tags taken from SwDA. seq2seq is our best performing model, CRF stands for Baseline CRF , G. is the groundtruth label.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>SwDA</cell></row><row><cell>Enc.</cell><cell>Dec.</cell><cell>VGRU D</cell><cell cols="3">att. soft guid. hard guid.</cell></row><row><cell cols="2">Beam Size</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell cols="2">VGRU E</cell><cell>81.6</cell><cell>82.1</cell><cell>82.8</cell><cell>82.9</cell></row><row><cell cols="2">HGRU</cell><cell>82.4</cell><cell>82.3</cell><cell>83.1</cell><cell>84.0</cell></row><row><cell cols="2">PersoHGRU</cell><cell>49.8</cell><cell>79.4</cell><cell>84.0</cell><cell>83.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>MRDA</cell></row><row><cell>Enc.</cell><cell>Dec.</cell><cell>VGRU D</cell><cell cols="3">att. soft guid. hard guid.</cell></row><row><cell cols="2">Beam Size</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell cols="2">VGRU E</cell><cell>88.5</cell><cell>88.5</cell><cell>88.5</cell><cell>88.5</cell></row><row><cell cols="2">HGRU</cell><cell>90.0</cell><cell>89.9</cell><cell>90.0</cell><cell>90.2</cell></row><row><cell cols="2">PersoHGRU</cell><cell>66.2</cell><cell>87.7</cell><cell>88.2</cell><cell>86.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Accuracy on the dev set of the different encoder/decoder combination MRDA and SwDA. For SwDA, Wilcoxon test (10 runs with different seeds) has been performed for an HGRU encoder with a decoder with hard guided attention against an HGRU encoder with soft guided attention, soft guided attention, with attention, without attention pairwise tests exhibit p-value &lt; 0.01.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Accuracy on the dev set of seq2seq model trained with sequence level loss. B train stands for the beam size during training, B inf for the one during inference 8 .For SwDA, Wilcoxon test (10 runs with different seeds) has been performed for B train = 2 and B inf = 2 against all other models. For RMDA, Wilcoxon test has been performed (10 runs with different seeds) for B train = 5 and B inf = 1 against all model with B train = 2. an accuracy of 82.9%. On MRDA, our best performing model reaches an accuracy of 91.6% where current state-of-the-art systems, Chen et al.; Kumar et al. (2018; 2018) achieve respectively 92.2% and 91.7%.</figDesc><table><row><cell>Models</cell><cell cols="2">SwDa MRDA</cell></row><row><cell>Li et al. (2018a)</cell><cell>82.9</cell><cell>92.2</cell></row><row><cell>Chen et al. (2018)</cell><cell>81.3</cell><cell>91.7</cell></row><row><cell>Kumar et al. (2018)</cell><cell>79.2</cell><cell>90.9</cell></row><row><cell>Raheja and Tetreault (2019)</cell><cell>82.9</cell><cell>91.1</cell></row><row><cell>seq2seq BEST</cell><cell>85.0</cell><cell>91.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Accuracy of our best models (seq2seq) and Baseline CRF on SwDA and MRDA test sets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Statistics for MRDA and SwDA. |C| is the number of Dialogue Act classes, |V | is the vocabulary size. Training, Validation and Testing indicate the number of conversations (number of utterances) in the respective splits.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Accuracy on the dev set of the different encoder/decoder combination MRDA and SwDA.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">T is an hyperparameter, experiments have shown that 5 leads to the best results.3  In our work we rely on same pretrained embedding word2vect<ref type="bibr" target="#b19">(Mikolov et al. 2013)</ref> instead of GloVe (Pennington, Socher, and Manning 2014).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">This analysis can be supported by 5.1.1 in SwDA coder manual https://web.stanford.edu/ ? jurafsky/ws97/manual.august1.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Further investigations with several persona based model inspired from the work of (Li et al. 2016b) shows the same poor improvement (in terms of accuracy)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was supported by a grant overseen from the French National Research Agency (ANR-17-MAOI).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of ACL</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A context-based approach for dialogue act recognition using simple recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Magg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
		<idno>CoRR abs/1805.06280</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dialogue act recognition via crf-attentive structured network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="225" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>G?l?ehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>CoRR abs/1406.1078</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A systematic exploration of diversity in machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shakhnarovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2013</title>
		<meeting>EMNLP 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1100" to="1111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The icsi meeting corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Janin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gelbart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2003 IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings.(ICASSP&apos;03. I-I. IEEE</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An empirical exploration of recurrent network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2342" to="2350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dialogue act recognition with bayesian networks for dutch dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Op Den Akker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nijholt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third SIGdial Workshop on Discourse and Dialogue</title>
		<meeting>the Third SIGdial Workshop on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Dialogue act classification in domain-independent conversations using a deep recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Khanpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Guntakandla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nielsen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In COLING</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dialogue act sequence labeling using hierarchical encoder with crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A persona-based neural conversation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Spithourakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of ACL</title>
		<meeting>the 54th Annual Meeting of ACL</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="994" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A dual-attention hierarchical recurrent neural network for dialogue act classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Seq2seq dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3203" to="3214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<title level="m">Fixing weight decay regularization in adam</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2015</title>
		<meeting>EMNLP 2015<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2014</title>
		<meeting>EMNLP 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Dialogue act classification with context-aware self-attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raheja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tetreault</surname></persName>
		</author>
		<idno>abs/1904.02594</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The icsi meeting recorder dialog act (mrda) corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Carvey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th SIGdial Workshop on Discourse and Dialogue at HLT-NAACL</title>
		<meeting>the 5th SIGdial Workshop on Discourse and Dialogue at HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A hierarchical recurrent encoder-decoder for generative context-aware query suggestion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Vahabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Grue Simonsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="553" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dialog act modeling for conversational speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Coccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meteer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Ess-Dykema</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium on Applying Machine Learning to Discourse Processing</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="98" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dialogue act modeling for automatic tagging and recognition of conversational speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Coccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Ess-Dykema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meteer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="339" to="373" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dialog act tagging with support vector machines and hidden markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Surendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-A</forename><surname>Levow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth International Conference on Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sequence-tosequence learning as beam-search optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
		<title level="m">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
