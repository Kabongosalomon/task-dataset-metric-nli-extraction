<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MICROSCOPY CELL SEGMENTATION VIA CONVOLUTIONAL LSTM NETWORKS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Assaf</forename><surname>Arbelle</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">The Zlotowski Center for Neuroscience Ben-Gurion University of the Negev</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tammy</forename><forename type="middle">Riklin</forename><surname>Raviv</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">The Zlotowski Center for Neuroscience Ben-Gurion University of the Negev</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MICROSCOPY CELL SEGMENTATION VIA CONVOLUTIONAL LSTM NETWORKS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Live cell microscopy sequences exhibit complex spatial structures and complicated temporal behaviour, making their analysis a challenging task. Considering cell segmentation problem, which plays a significant role in the analysis, the spatial properties of the data can be captured using Convolutional Neural Networks (CNNs). Recent approaches show promising segmentation results using convolutional encoder-decoders such as the U-Net. Nevertheless, these methods are limited by their inability to incorporate temporal information, that can facilitate segmentation of individual touching cells or of cells that are partially visible. In order to exploit cell dynamics we propose a novel segmentation architecture which integrates Convolutional Long Short Term Memory (C-LSTM) with the U-Net. The network's unique architecture allows it to capture multi-scale, compact, spatio-temporal encoding in the C-LSTMs memory units. The method was evaluated on the Cell Tracking Challenge and achieved state-of-the-art results (1st on Fluo-N2DH-SIM+ and 2nd on DIC-C2DL-HeLa datasets) The code is freely available at: https: //github.com/arbellea/LSTM-UNet.git * This study was partially supported by the Negev scholarship at Ben-Gurion University (A.A.); The Kreitman School of Advanced Graduate Studies (A.A) ;</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Live cell microscopy imaging is a powerful tool and an important part of the biological research process. The automatic annotation of the image sequences is crucial for the quantitative analysis of properties such as cell size, mobility, and protein levels. Recent image analysis approaches have shown the strengths of Convolutional Neural Networks (CNNs) which surpass state-of-the-art methods in virtually all fields, such as object classification <ref type="bibr" target="#b0">[1]</ref>, detection <ref type="bibr" target="#b1">[2]</ref>, semantic segmentation <ref type="bibr" target="#b2">[3]</ref>, and many other tasks. Attempts at cell segmentation using CNNs include <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref>. All these methods, however, are trained on independent, non sequential, frames and do not incorporate any temporal information which can potentially facilitate segmentation in cases of neighboring cells that are hard to separate or when a cell partially vanishes. The use of temporal information by combining tracking information from individual cells to support segmentation decisions has been shown to improve results for non deep learning methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref> but have not yet been extensively examined in a deep learning approaches.</p><p>A Recurrent Neural Network (RNN) is an artificial neural network equipped with feed-back connections. This unique architecture makes it suitable for the analysis of dynamic behavior. A special variant of RNNs is Long Short Term Memory (LSTM), which includes an internal memory state vector with gating operations thus stabilizing the training process <ref type="bibr" target="#b10">[11]</ref>. Common LSTM based applications include natural language processing (NLP) <ref type="bibr" target="#b11">[12]</ref>, audio processing <ref type="bibr" target="#b12">[13]</ref> and image captioning <ref type="bibr" target="#b13">[14]</ref>.</p><p>Convolutional LSTMs (C-LSTMs) accommodate locally spatial information in image sequences by replacing matrix multiplication with convolutions <ref type="bibr" target="#b14">[15]</ref>. The C-LSTM has recently been used to address the analysis of both temporal image sequences, such as next frame prediction <ref type="bibr" target="#b15">[16]</ref>, and volumetric data sets <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>. In <ref type="bibr" target="#b17">[18]</ref> C-LSTM is applied in multiple directions for the segmentation of 3D data represented as a stack of 2D slices. Another approach for 3D brain structure segmentation is proposed in <ref type="bibr" target="#b16">[17]</ref>, where each slice is separately fed into a U-Net architecture, and only the output then fed into bi-directional C-LSTMs.</p><p>In this paper we introduce the integration of C-LSTMs into an encoder-decoder structure (U-Net) allowing compact spatio-temporal representations in multiple scales. We note that, unlike <ref type="bibr" target="#b16">[17]</ref> which was designed and evaluated on 3D brain segmentation, the proposed novel architecture is an intertwined composition of the two concepts rather than a pipeline. Furthermore, since our method is designed for image sequence segmentation which can be very long the bi-directional C-LSTM is not computationally feasible. Our framework is assessed using timelapse microscopy data where both cells' dynamics and their spatial properties should be considered. Specifically, we tested our method on the Cell Tracking Challenge: http://www.celltrackingchallenge.net. Our method was ranked in the top three by the challenge or-ganizers on the several submitted data sets, specifically on the fluorescent simulated dataset (Fluo-N2DH-SIM+) and the differential interference contrast (DIC-C2DL-HeLa) sequences which are difficult to segment.</p><p>The rest of the paper is organized as follows. Section 2 presents a probabilistic formulation of the problem and elaborates on the proposed network. Technical aspects are detailed in Section 3. In Section 4 we demonstrate the strength of our method, presenting state-of-the-art cell segmentation results. We conclude in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Network Architecture</head><p>The proposed network incorporates C-LSTM <ref type="bibr" target="#b14">[15]</ref> blocks into the U-Net <ref type="bibr" target="#b5">[6]</ref> architecture. This combination, as suggested here, is shown to be powerful. The U-Net architecture, built as an encoder-decoder with skip connections, enables to extract meaningful descriptors at multiple image scales. However, this alone does not account for the cell specific dynamics that can significantly support the segmentation. The introduction of C-LSTM blocks into the network allows considering past cell appearances at multiple scales by holding their compact representations in the C-LSTM memory units. We propose here the incorporation of C-LSTM layers in every scale of the encoder section of the U-Net. Applying the CLSTM on multiple scales is essential for cell microscopy sequences (as opposed to brain slices as in <ref type="bibr" target="#b16">[17]</ref>) since the frame to frame differences might be at different scales, depending on cells' dynamics. Moreover, in contrast to brain volume segmentation <ref type="bibr" target="#b16">[17]</ref> the microscopy sequence can be of arbitrary length, making the use of bi-directional LSTMs computationally impractical and the cells can move at different speeds and the changes are not normally smooth. The comparison to other alternatives is presented in Section 4.2. The network is fully convolutional and, therefore, can be used with any image size 1 during both training and testing. <ref type="figure">Figure 1</ref> illustrates the network architecture detailed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Formulation</head><p>We address individual cells' segmentation from microscopy sequences. The main challenge in this type of problems is not only foreground-background classification but also the separation of adjacent cells. We adopt the weighted distance loss as suggested by <ref type="bibr" target="#b5">[6]</ref>. The loss is designed to enhance individual cells' delineation by a partitioning of the d dimensional (2 or 3) image domain ? ? R d into two classes: foreground and background, such that pixels which are near the boundaries of two adjacent cells are given higher importance. We set C = {0, 1} to denote these classes, respectively. Let {I t } T t=1 <ref type="bibr" target="#b0">1</ref> In order to avoid artefacts it is preferable to use image sizes which are multiples of eight due to the three max-pooling layers. be the input image sequence of length T , where I t : ? ? R is a grayscale image. The network is composed of two sections of L blocks each, the encoder recurrent block E {l} ? l (?) and the decoder block D {l} ? l (?) where ? l are the network's parameters. The input to the C-LSTM encoder layer l ? [0, . . . , L ? 1] at time t ? T includes the down-sampled output of the previous layer, the output of the current layer at the previous time-step and the C-LSTM memory cell. We denote these three inputs as</p><formula xml:id="formula_0">x {l} t , h {l} t?1 , c {l} t?1 respectively. Formally we define: (h {l} t , c {l} t ) = E {l} ? l (x {l} t , h {l} t?1 , c {l} t?1 )<label>(1)</label></formula><p>where,</p><formula xml:id="formula_1">x {l} t = I t , l = 0 M axP ool(h {l?1} t ), 0 &lt; l &lt; L<label>(2)</label></formula><p>The inputs to the decoder layers l ? [L, . . . , 2L ? 1] are the up-sampled 2 output of the previous layer and the output of the corresponding layer from the encoder denoted by y {l} t and h {2L?1?l} t respectively. We denote the decoder output as z {l} t . Formally,</p><formula xml:id="formula_2">y {l} t = h {l?1} t , l = L U pSample(z {l?1} t ), L &lt; l &lt; 2L ? 1 (3) z {l} t = D ? l (y {l} t , h {2L?1?l} t )<label>(4)</label></formula><p>We define a network f ? with parameters ? as the composition of L encoder blocks followed by L decoder blocks, and denote ? := {? l } 2L?1 l=0 . Note that the encoder blocks, E {l} ? l , encode high-level spatio-temporal features at multiple scales and the decoder blocks, D {l} ? l , refines that information into a full scale segmentation map.</p><formula xml:id="formula_3">o t ? = f ? = z {2L?1} t<label>(5)</label></formula><p>We set the final output as a |C|-dimensional feature vector corresponding to each input pixel v ? ?. We define the segmentation as the pixel label probabilities using the softmax equation:</p><formula xml:id="formula_4">p(c|o t (v)) = exp{[o t (v)] c } c ?C exp{[o t (v)] c } , c ? C<label>(6)</label></formula><p>The final segmentation is defined as follows:</p><formula xml:id="formula_5">? t = arg c?C max p(c|o t (v))<label>(7)</label></formula><p>Each connected component of the foreground class is given a unique label and is considered an individual cell. <ref type="bibr" target="#b1">2</ref> We use bi-linear interpolation  <ref type="figure">Fig. 1</ref>: The U-LSTM network architecture. The downsampling path (left) consists of a C-LSTM layer followed by a convolutional layer with ReLU activation, the output is then down-sampled using max pooling and passed to the next layer. The up-sampling path (right) consists of a concatenation of the input from the lower layer with the parallel layer from the down-sampling path followed by two convolutional layers with ReLU activations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Training and Loss</head><p>During the training phase the network is presented with a full sequence and manual annotations {I t , ? t } T t=1 , where ? t : ? ? [0, 1] are the ground truth (GT) labels. The network is trained using Truncated Back Propagation Through Time (TBPTT) <ref type="bibr" target="#b18">[19]</ref>. At each back propagation step the network is unrolled to ? time-steps. The loss is defined using the distance weighted cross-entropy loss as proposed in the original U-Net paper <ref type="bibr" target="#b5">[6]</ref>. The loss imposes separation of cells by introducing an exponential penalty factor wich is proportional to the distance of a pixel from its nearest and second nearest cells' pixels. Consequently, pixels which are located between two adjacent cells are given significant importance whereas pixels further away from the cells have a minor effect on the loss. A detailed discussion on the weighted loss can be found in the original U-Net paper <ref type="bibr" target="#b5">[6]</ref> 3. IMPLEMENTATION DETAILS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Architecture</head><p>The network comprises L = 4 encoder and decoder blocks. Each block in the encoder section is composed of C-LSTM layer, leaky ReLU, convolutional layer, batch normalization <ref type="bibr" target="#b19">[20]</ref>, leaky ReLU and finally down-sampled using maxpool operation. The decoder blocks consist of a bi-linear interpolation, a concatenation with the parallel encoder block and an followed by two convolutional layer, batch normalization <ref type="bibr" target="#b19">[20]</ref>, and leaky ReLU. All convolutional layers use kernel size 3 ? 3 with layer depths (128, 256, 512, 1024). All maxpool layers use kernel size 2?2 without overlap. All C-LSTM kernels are of size 3 ? 3 and 5 ? 5 respectively with layer depths <ref type="figure">(1024, 512, 256, 128)</ref>. The last convolutional layer uses kernel size 1 ? 1 with depth 2 followed by a softmax layer to produce the final probabilities (see <ref type="figure">Figure 1</ref>).  <ref type="table">Table 1</ref>: Architecture Experiments Comparison of three variants of the proposed network incorporating C-LSTMs in: <ref type="bibr" target="#b0">(1)</ref>. the encoder seuction (EncLSTM) <ref type="bibr" target="#b1">(2)</ref>. the decoder section (DecLSTM) <ref type="bibr" target="#b2">(3)</ref>. both the encoder and decoder sections (Ful-lLSTM). The training procedure was repeated three times, mean and standard deviation are presented</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Training Regime</head><p>We trained the networks for approximately 100K iterations with an RMS-Prop optimizer <ref type="bibr" target="#b20">[21]</ref> with learning rate of 0.0001. The unroll length parameter was set to ? = 5 was set (Section 2.3) and the batch size was set to three sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Data</head><p>The images were annotated using two labels for the background and cell nucleus. In order to increase the variability, the data was randomly augmented spatially and temporally by: 1) random horizontal and vertical flip, 2) random 90 o rotation 3) random crop of size 160 ? 160 4) random sequence reverse ([T, T ? 1, . . . , 2, 1]), 5) random temporal down-sampling by a factor of k ? [0, 4], 6) random affine and elastic transformations.We note that the gray-scale values are not augmented as they are biologically meaningful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluation Method</head><p>The method was evaluated using the scheme proposed in the online version of the Cell Tracking Challenge. Specifically, SEG for segmentation <ref type="bibr" target="#b21">[22]</ref>. The SEG measure is defined as the mean Jaccard index |A?B| |A?B| of a pair of ground truth label A and its corresponding segmentation B. A segmentation is considered a match if |A ? B| &gt; 1 2 |A| .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Architecture Selection:</head><p>We propose integrating the CLSTM into the U-Net by substituting the convolutional layers of the encoder section with C-LSTM layers (referred to as EncLSTM). In this section we compare this architecture with two alternatives by substituting: 1) the convolutional layers of the decoder section (referred to as DecLSTM); 2) the convolutional layers of both the decoder and encoder sections (referred to as FullLSTM). All three networks were trained simultaneously with identical inputs. Due to the limited size of the training set, the networks were trained on the Fluo-N2DH-SIM+ datasets and tested on the similar Fluo-N2DH-GOWT1 datasets from the training set of the Cell Tracking Challenge. The results as   <ref type="bibr" target="#b21">[22]</ref>. Our methods EncLSTM and DecLSTM are referred to here as BGU-IL <ref type="bibr" target="#b3">(4)</ref> and BGU-IL ( 2) respectively. Our method ranked first on the Fluo-N2DH-SIM+ and second on the DIC-C2DL-HeLa dataset. The three columns on the right report the results of the top three methods as named by the challenge organizers. The measure is explained in presented <ref type="table">Table 1</ref> show an advantage for the proposed architecture. Howerver, the dominance of the EncLSTM with respect to the DecLSTM is not conclusive as is demonstrated by the result for the cell tracking challenge discussed next. We further note that a comparison to the original U-Net, without LSTM, is obtained in the challenge results and is referred to by the challenge organizers as FR-Ro-Ge. The method is labelled in <ref type="table" target="#tab_3">Table 2</ref> with the superscript (d).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Cell Tracking Challenge Results:</head><p>Two variants of the method, EncLSTM and DecLSTM, were applied to five data sets: Fluo-N2DH-SIM+, DIC-C2DL-HeLa, PhC-C2DH-U373, Fluo-N2DH-GOWT1, Fluo-N2DL-HeLa. The results were submitted to the Cell Tracking Challenge. The proposed Enc-LSTM and Dec-LSTM were ranked 1st and 3rd, respectively, out of 20, for the Fluo-N2DH-SIM+ data set and 2nd out of 10 (EncLSTM) for the DIC-C2DL-HeLa dataset. We note that for the other three datasets -training data were significantly smaller and this might explain the inferior results we received. A possible solution to this problem is using adversarial loss as suggested in <ref type="bibr" target="#b3">[4]</ref>. In general, 20 different methods have been submitted to the challenge, including the original U-Net (FR-Ro-GE) <ref type="bibr" target="#b5">[6]</ref> and TUG-AT <ref type="bibr" target="#b22">[23]</ref>. The latter independently and simultaneously proposed to utilize the U-Net architecture while introducing C-LSTM layers on the skip connections. <ref type="table" target="#tab_3">Table 2</ref> reports our results in comparison to the three leading methods (including ours) provided by the challenge organizers. Visualizations of the results are presented in <ref type="figure">Fig 2 and</ref> in https://youtu.be/IHULAZBmoIM. The quantitative results for top three leading methods are also publicly available at the Cell Tracking Challenge web site..</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">SUMMARY</head><p>Time-lapse microscopy cell segmentation is, inherently, a spatio-temporal task. Human annotators frequently rely on temporal queues in order to accurately separate neighbouring cells and detect partially visible cells. In this work, we demonstrate the strength of integrating temporal analysis, in the form of C-LSTMs, into a well established network architecture (U-Net) and examined several alternative combinations. The resulting novel architecture is able to extract meaningful features at multiple scales and propagate them through time. This enables the network to accurately segment cells in difficult scenarios where the temporal queues are crucial. Quantitative analysis shows that our method achieves state-of-the-art results ( <ref type="table" target="#tab_3">Table 2</ref>) ranking 1st and 2nd place in the Cell Tracking Challenge 3 . Moreover, the results reported in <ref type="table">Table 1</ref> demonstrate the proposed network ability to generalize from simulated training data to real data. This may imply that one can reduce and even eliminate the need for extensive manually annotated data. We further plan on incorporating adversarial loss to weaken the dependancy on training set size as in <ref type="bibr" target="#b3">[4]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Section 4 . 1 .Fig. 2 :</head><label>412</label><figDesc>The superscript (a-g) represent different methods: (*). EncLSTM ours, (**) DecLSTM ours, (a).TUG-AT, (b). CVUT-CZ, (c). FR-Fa-GE, (d). FR-Ro-GE (Original UNet [6]), (e). KTH-SE, (f) LEID-NL. Full Image Zoom Fluo-N2DH-SIM+ DIC-C2DH-HeLa PhC-C2DH-U373x Examples of the segmentation results for three of the data sets The top and bottom row show the full image and a zoom-in of a specific area respectively. The columns from left to right show the Fluo-N2DH-SIM+, DIC-C2DH-HeLa and PhC C2DH-U373 datasets. Note that 1. even though the cells are touching, they are correctly separated; 2. The complex shape and texture of the cell is correctly segmented.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Quantitative Results: Method evaluation on the submitted dataset (challenge set) as evaluated and published by the Cell Tracking Challenge organizers</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Based on the October 15th, 2018 ranking.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE CVPR</title>
		<meeting>the IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Microscopy cell segmentation via adversarial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arbelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Riklin</forename><surname>Raviv</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.05860</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Classifying and segmenting microscopy images with deep multiple instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">Z</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="52" to="59" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.04597</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast, accurate reconstruction of cell lineages from large-scale fluorescence microscopy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Amat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lemon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Mossing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcdole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Analysis of high throughput microscopy videos: Catching up with cell dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arbelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Drayman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Riklin-Raviv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="218" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Graphical model for joint segmentation and tracking of multiple dividing cells</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schiegg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanslovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Haubold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Koethe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hufnagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="948" to="956" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A probabilistic approach to joint cell tracking and segmentation in high-throughput microscopy videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arbelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lahav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Riklin Raviv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="140" to="152" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2773" to="2781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Long short-term memory recurrent neural network architectures for large scale acoustic modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Beaufays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifteenth annual conference of the international speech communication association</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhudinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convolutional lstm network: A machine learning approach for precipitation nowcasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xingjian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="802" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Deep predictive coding networks for video prediction and unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lotter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kreiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.08104</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Combining fully convolutional and recurrent neural networks for 3d biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3036" to="3044" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Parallel multi-dimensional lstm, with application to fast biomedical volumetric image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Stollenga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Byeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2998" to="3006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An efficient gradient-based algorithm for on-line training of recurrent network trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="490" to="501" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">R m s prop: Coursera lectures slides, lecture 6</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An objective comparison of celltracking algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1141</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Instance segmentation and tracking with cosine embeddings and recurrent hourglass networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Payer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>?tern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Neff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Urschler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02070</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
