<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Robust Semantic Segmentation of Accident Scenes via Multi-Source Mixed Sampling and Meta-Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CV:HCI Lab</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CV:HCI Lab</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CV:HCI Lab</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alina</forename><surname>Roitberg</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CV:HCI Lab</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunyu</forename><surname>Peng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CV:HCI Lab</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CV:HCI Lab</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Robust Semantic Segmentation of Accident Scenes via Multi-Source Mixed Sampling and Meta-Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Autonomous vehicles utilize urban scene segmentation to understand the real world like a human and react accordingly. Semantic segmentation of normal scenes has experienced a remarkable rise in accuracy on conventional benchmarks. However, a significant portion of real-life accidents features abnormal scenes, such as those with object deformations, overturns, and unexpected traffic behaviors. Since even small mis-segmentation of driving scenes can lead to serious threats to human lives, the robustness of such models in accident scenarios is an extremely important factor in ensuring safety of intelligent transportation systems.</p><p>In this paper, we propose a Multi-source Meta-learning Unsupervised Domain Adaptation (MMUDA) framework, to improve the generalization of segmentation transformers to extreme accident scenes. In MMUDA, we make use of Multi-Domain Mixed Sampling to augment the images of multiple-source domains (normal scenes) with the target data appearances (abnormal scenes). To train our model, we intertwine and study a meta-learning strategy in the multi-source setting for robustifying the segmentation results. We further enhance the segmentation backbone (SegFormer) with a HybridASPP decoder design, featuring large window attention spatial pyramid pooling and strip pooling, to efficiently aggregate long-range contextual dependencies. Our approach achieves a mIoU score of 46.97% on the DADA-seg benchmark, surpassing the previous state-of-the-art model by more than 7.50%. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the rapid development of computer vision algorithms in Intelligent Transportation Systems (ITS), road safety for Intelligent Vehicles (IV) has gradually become one of the most concerning issues in this community. The Advanced Driver Assistance Systems (ADAS) are required * The first two authors contribute equally to this work. ? Corresponding author (e-mail: kailun.yang@kit.edu). <ref type="bibr" target="#b0">1</ref> Code will be made publicly available at https://github.com/ xinyu-laura/MMUDA. to correctly handle both, normal driving scenes, which are addressed by most of the published datasets, and abnormal situations (i.e., edge cases) that may unexpectedly appear in real-world scenes. Fueled by rapid improvements in general semantic segmentation research, great progress has been made in the field of autonomous driving <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b32">33]</ref> in recent years. However, these segmentation models are mainly designed for normal driving scenes, while real-life accidents often encounter abnormalities and critical situations, such as overturned vehicles in front of the ego-vehicle or distorted shots caused by motion blur. Several examples of such abnormal cases taken from accident scenes are presented in <ref type="figure" target="#fig_0">Fig. 1</ref>. If a standard semantic segmentation model, which does not see any abnormal samples during training, is deployed in real world, it can hardly obtain correct results when encountering an unusual accident-or near-accident scene, resulting in a failure of driving assistance. The large domain gap between the normal-and accident scenes negatively impacts segmentation performance <ref type="bibr" target="#b59">[60]</ref>, greatly limiting applications of autonomous driving in practice.</p><p>Despite its high relevance for applications, only a few works address the task of accident scenes segmentation, which aims to adapt models trained in normal scenarios to the abnormal ones. <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b60">61]</ref> introduced DADA-seg -a new traffic accidents dataset covering labelled and unla-arXiv:2203.10395v1 [cs.CV] <ref type="bibr" target="#b18">19</ref> Mar 2022 belled images from real-world abnormal driving scenes. The event-aware ISSAFE architecture <ref type="bibr" target="#b59">[60]</ref> was proposed to fuse RGB images and event data and therefore to capture the dynamic context. The Trans4Trans model <ref type="bibr" target="#b57">[58]</ref> leveraged transformer-based encoder and decoder and was simply transferred, without any adaptation design, from multiple source datasets, i.e., Cityscapes <ref type="bibr" target="#b7">[8]</ref> and ACDC <ref type="bibr" target="#b34">[35]</ref>. However, mixing data only in a dataset-wise manner is limited in terms of balancing the data distribution and further data diversification remains an important milestone. To the best of our knowledge, only the single-source Unsupervised Domain Adaptation (UDA) <ref type="bibr" target="#b59">[60]</ref> and the multi-source transfer-learning method <ref type="bibr" target="#b57">[58]</ref> from normal-to abnormal domain were investigated. Multi-source normal-to-abnormal UDA, yet, remains unexplored. We believe, that leveraging multiple data origins has strong potential for robustifying accident scene segmentation, as such extreme scenarios often contain diverse abnormal factors and composite scenes, that could be better addressed by exploiting rich ontologies covered in diverse sources.</p><p>To improve the robustness of semantic segmentation in accident scenarios, we propose a novel Multi-source Metalearning UDA framework to help the transformer models in generalization to the unusual target scenes (MMUDA for short). Our framework learns from the label-rich datasets of conventional driving scenes (source), and then automatically adapts to the target domain of abnormal accident scenes with only unlabelled training data (target). To effectively learn from the entire unlabelled target domain dataset, we put forward a Multi-Domain Mixed Sampling (MDMS) strategy, which is inspired by the cross-domain mixing approach in DACS <ref type="bibr" target="#b40">[41]</ref> and augments the training samples of multiple source domains. Two major differences compared to the normal-to-normal DACS are that i) we adapt the single-source method to a multi-source setup, and ii) we further investigate the multi-source mixing technique in our normal-to-abnormal setting. More precisely, in the case of single-domain mixed sampling, the augmented sample is formed by mixing the source normal image and the target abnormal image. In the case of the multi-domain mixing, some marks from each source domain image are extracted and then pasted onto the target domain image. The pseudolabels for the augmented image are mixed by the source ground-truth labels and the target pseudo labels.</p><p>In the training phase, we use the meta-learning for domain generalization (MLDG) strategy <ref type="bibr" target="#b21">[22]</ref>, which was adapted in <ref type="bibr" target="#b56">[57]</ref> to model the domain transfer problem with an episodic training paradigm, leading to superior performance in image classification. MLDG can be viewed as a regularization mechanism that prevents the model from overfitting. Different from the original MLDG, our MMUDA framework performs meta-learning across multiple source domains and jointly with the target domain, after which we apply it to the normal-to-abnormal UDA setting. In addition, we enhance the segmentation backbone (Seg-Former) with a HybridASPP decoder design, which leverages large window attention spatial pyramid pooling <ref type="bibr" target="#b45">[46]</ref> and strip pooling <ref type="bibr" target="#b17">[18]</ref> with a long but narrow kernel. The HybridASPP decoder replaces the vanilla MLP-based decoder of SegFormer, and this helps to efficiently extract large regions of global context and long-range dependencies. Comprehensive experiments demonstrate the effectiveness of our proposed methods. On the challenging DADA-seg benchmark <ref type="bibr" target="#b59">[60]</ref>, our approach achieves a mIoU score of 46.97%, surpassing the previous state-of-the-art transformer model <ref type="bibr" target="#b57">[58]</ref> by more than +7.50%.</p><p>Our contributions are summarized as follows:</p><p>? We propose a novel Multi-source Meta-learning UDA (MMUDA) framework for better adaptation from multi-source domains of normal driving scenes to the domain of abnormal accident scenes. ? We develop a Multi-Domain Mixed Sampling (MDMS) approach to augment the training data from multiple labelled source domains with data appearances from the unlabelled target domain data. ? We employ meta-learning and analyze its effects under different combinations of multiple source datasets. ? We introduce an enhanced HybridASPP to replace the vanilla MLP-based decoder of SegFormer, which makes the framework more efficient and effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Semantic segmentation. Semantic segmentation has experienced a great breakthrough since the emergence of FCN <ref type="bibr" target="#b24">[25]</ref> classifying pixels end-to-end. Subsequent networks, e.g., <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b63">64]</ref> improved FCN in different aspects, significantly pushing segmentation performance, but also raising computational cost. To alleviate this issue, compact segmentation models <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref> are designed to hold a better accuracy-efficiency trade-off. Disentangled non-local blocks <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b66">67]</ref> have also been explored to efficiently collect omni-range dependencies. Recently, the semantic segmentation field has been driven by the newly emerged and highly effective transformer-based architectures <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b64">65]</ref>. Compared to FCN-based approaches, such models are able to handle long-range dependencies by design and have quickly climbed to the top of segmentation benchmarks. Furthermore, MLP-like architectures <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b58">59]</ref> alternate token-and channelmixing to enhance global reasoning. The recently proposed SegFormer architecture <ref type="bibr" target="#b44">[45]</ref> leverages a hierarchical transformer encoder with a lightweight All-MLP decoder, generating powerful representations without complex and computationally demanding modules. In this work, we build on SegFormer and introduce multiple building blocks for its improvement specifically for accident scene segmentation.</p><p>Domain adaptation and generalization. While current semantic segmentation models achieve excellent performance on standard benchmarks, the performance drops sharply if the training and test images come from different domains.</p><p>To counter this effect, multiple methods based on Domain Adaptation (DA) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63]</ref> were proposed for automatic adjustment to adverse conditions. In <ref type="bibr" target="#b35">[36]</ref>, effective usage of synthetic data was explored to better handle domain shifts, with results indicating that the foreground objects should rather be addressed in a detection-based manner. Domain Generalization (DG) is more challenging than DA since DG methods can only access source domain data for training. Target images during the training process cannot be used or observed (while classical DA allows access to unlabelled target domain data). Currently, most DG methods focus on image classification, and only a few <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b56">57]</ref> are developed to solve semantic segmentation tasks. Another recent group of approaches <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b52">53]</ref> raised the technique of domain randomization to improve DG. Moreover, open compound domain adaptation approaches <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b29">30]</ref> have been developed to adapt to a group of unknown heterogeneous domains like scenes in adverse environmental conditions. In this work, we also develop a domain transfer system based on meta-learning and design a multi-source mixed sampling method for enhancing semantic segmentation in accident scenarios.</p><p>Meta learning. Meta-learning aims at figuring out how to learn and has been effectively applied in different fields, with Model-Agnostic Meta-Learning (MAML) <ref type="bibr" target="#b10">[11]</ref> and HyperNetworks <ref type="bibr" target="#b13">[14]</ref> being popular approches for image classification. MAML simulates the domain gap between train and test domains by synthesizing virtual testing domains within each mini-batch during training. As of late, meta-learning has likewise been effectively applied to domain adaptation and domain generalization. Meta-online <ref type="bibr" target="#b20">[21]</ref> introduces a strategy to improve the results by learning the underlying circumstances (e.g., model boundary) of the existing domain adaptation strategies. MLDG <ref type="bibr" target="#b21">[22]</ref> follows the MAML <ref type="bibr" target="#b10">[11]</ref> system and has been effectively used in the DG task. Similar to MAML, the DG task expects that the learned models in seen domains are able to generalize well to novel unseen domains. As a consequence, meta learning has been recently explored for domain adaptation and generalization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b56">57]</ref>. In this work, we leverage meta learning to better make use of multi-source data in order to boost generalization of semantic segmentation models in extreme accident scenes.</p><p>Mixing. Mixing is a kind of augmentation technique and has successfully been used for both classification and semantic segmentation as suggested in <ref type="bibr" target="#b54">[55]</ref>. Mixing has been further developed in the class mixing algorithm <ref type="bibr" target="#b26">[27]</ref>, where the masks used for mixing are dynamically created based on the predictions of the network. In DACS <ref type="bibr" target="#b40">[41]</ref>, the concept of self-training is extended and combined with ClassMix. Their proposed method fine-tunes models with mixed labels by combining ground-truth annotations from the source domain and pseudo-labels from the target domain. Further, context-aware mixing <ref type="bibr" target="#b65">[66]</ref> and bi-mix <ref type="bibr" target="#b46">[47]</ref> methods are developed to better guide the domain mixup and bridge the distribution gap. In this work, we assemble a multi-source mixed sampling method within our system for robust semantic understanding of accident scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>In this Section, we describe our Multi-source Metalearning UDA (MMUDA) framework in detail. First, we explain the proposed Multi-Domain Mixed Sampling (MDMS) in Sec. 3.1. Then, the meta-learning strategy for multisource UDA in Sec. 3.2 is explained in detail. Finally, Sec. 3.3 provides an overview of the proposed architectural changes and the enhanced HybridASPP decoder design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">MDMS: Multi-Domain Mixed Sampling</head><p>Our proposed method builds upon the idea of domain adaptation via cross-domain mixed sampling (DACS) <ref type="bibr" target="#b40">[41]</ref>. Unlike DACS, which has only one source domain, our augmented samples are created by mixing pixels from the target domain image with pixels from each source domain image. Before being mixed, the unlabelled target domain images first need to be run through the model to generate pseudolabels for them. Then, half of the classes in the image from source domain are randomly selected, and the pixels of the corresponding classes are cut from the source domain image and pasted onto the target domain image. For labels, the pseudo-labels of unlabelled target image are mixed with the corresponding ground-truth labels of the source domain image in the same way as the mixed images. The above mixing approach is applied to each source domain. For brevity, the mixed sampling process will be described with only one source domain below.</p><p>A source domain is defined by a set of image and label pairs</p><formula xml:id="formula_0">{(X i S , Y i S )} N S ?D S , where X i S ?R H?W ?3 is the image, Y i</formula><p>S ?R H?W ?C is the C-class label, and N S is the number of samples in the source domain D S . From the target domain D T with a number of N T =N L +N U samples, the N U unlabelled image and pseudo label pairs {(X i T ,? i T )} N U ?D T are selected for the mixing approach, where? T is generated by the segmentation transformer f seg in <ref type="figure">Fig. 2</ref>. The labelled N L images in the target domain are only used in the testing stage. In the augmented set D M with the same N U samples, an augmented image X M is generated by mixing a source image X S and a target image X T , and the pseudo label? M by combining the corresponding ground-truth label Y S and the pseudo label? T . However, in our case, there is not one but K </p><formula xml:id="formula_1">{(X i M k ,? i M k )} N U ?D M .</formula><p>These new samples are then used to train the segmentation transformer model f seg . The process of MDMS is presented as gray arrows in <ref type="figure">Fig. 2</ref>, where an example of mixing image-label pairs from source-and target domain is shown. Pixels cut from the source are marked in yellow dotted boxes. In this way, we obtain a set of augmented samples from multiple source domains, which are then passed to the subsequent meta-learning-based network together with the original source domain images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Meta-Learning in UDA</head><p>During the training phase, we adapt MLDG <ref type="bibr" target="#b21">[22]</ref> (i.e., meta-learning for domain generalization) to train our model. Different from MLDG, we perform meta-learning across multiple source domains and together with the target domain, intertwined via mixing sampling to obtain augmented images which instills the knowledge from the target scenes. Besides, instead of addressing image classification, we apply it to the normal-to-abnormal UDA setting for robustifying dense accident scene segmentation.</p><p>As shown in the training stage of our framework in <ref type="figure">Fig. 2</ref>, we use the images from sources for meta-training while the augmented images produced via MDMS are used for meta-testing. The cross-entropy is selected as the loss function L for our semantic segmentation task. First, the domain-specific loss L ds is computed from the metatraining data though the network f seg . The gradient ?L ds is then used to update a new network f seg , i.e., the green block in <ref type="figure">Fig. 2</ref>, which has the same backbone as the blue one. As we want the model to adapt well in the unseen target domain, the domain adaptation loss L da is calculated from f seg with the updated parameters using the meta-test data. Finally, we employ the total loss L total =L da +?L ds to update the original f seg , so that the network is optimized to perform well in the source and target domains. During the update for f seg , we use the inner learning rate ?, while updating the original network f seg after a meta-train and subsequent meta-test process, the outer learning rate ? is used. The parameters can then be updated with SGD (i.e., Stochastic Gradient Descent).</p><p>In our segmentation task, the statistics in the source domain (i.e., the normal driving scenes) are different from the target domain of traffic accident scenes. Therefore, normalizing the test data with the accumulated mean and variance during the training phase can be problematic. Considering this fact, we adopt target-specific normalization introduced by [57] to normalize features directly using statistics from the target domain in the testing stage. In the experiments, we further investigate different combinations of datasets for meta-learning, aiming for an optimal path to follow towards robust accident scene understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">HybridASPP</head><p>Next, we propose multiple improvements to the original SegFormer architecture in order to efficiently extract large regions of the global context and long-range dependencies. To this intent, our enhanced HybridASPP decoder replaces the vanilla MLP-based decoder of SegFormer. As shown in <ref type="figure" target="#fig_1">Fig. 3</ref>, in the first yellow branch, HybridASPP inherits the large window attention blocks of Large Window Attention Spatial Pyramid Pooling (LawinASPP) <ref type="bibr" target="#b45">[46]</ref> to exploit global context information. By adjusting the ratio of the context regions to the query regions with {2, 4, 8} as illustrated in <ref type="figure" target="#fig_1">Fig. 3</ref>, large-window attention is able to cap- ture contextual information at multiple scales. The offered receptive fields are of sizes {16, 32, 64}, when setting the patch size of the local window to 8. Further, the study in <ref type="bibr" target="#b17">[18]</ref> found that the standard spatial pooling operation with a shape of H?W makes the long-range context likely to contain many unrelated regions. In the bottom branch, we intertwine strip pooling modules, which encode long-range context along the horizontal and vertical spatial dimension based on long, narrow kernels (1?W and H?1).</p><p>As shown in <ref type="figure" target="#fig_1">Fig. 3</ref>, we concatenate an aggregated feature from the last three stages of the encoder, the large window attended features, the strip pooling augmented feature, after which a learned linear transformation performs dimensionality reduction for producing the final segmentation map. The output of HybridASPP feature is upsampled to the size of a quarter of input image, then it is fused with the lowlevel feature coming from the first stage of the segmentation transformer (i.e., SegFormer) via a linear layer. Last, dense semantic predictions, i.e., the segmentation logits, are obtained from the final representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>The statistics of the five source datasets (normal scenes) and the target dataset (abnormal accident scenes) that are used in our experiments are listed in <ref type="table" target="#tab_1">Table 1</ref>. Source datasets. For training, we leverage five semantic segmentation datasets as our multi-origin source domains: WildDash2 (W) <ref type="bibr" target="#b53">[54]</ref>, ACDC (A) <ref type="bibr" target="#b34">[35]</ref>, BDD10K (B) <ref type="bibr" target="#b49">[50]</ref>, IDD (I) <ref type="bibr" target="#b41">[42]</ref>, and Cityscapes (C) <ref type="bibr" target="#b7">[8]</ref>. The datasets A and B and C are annotated with the same label set of 19 categories. Compared to these datasets, W has 5 five additional classes, including van, pickup, street light, billboard, and ego-vehicle. Following the setting of <ref type="bibr" target="#b56">[57]</ref>, we merge the additional categories of W by mapping the added new Ids to the original Ids of A, B, and C. Although I also contains more classes, we use the provided public code 2 to directly generate the masks with the same label Ids as C. W has a large collection of road scenes from different countries, weather and lighting conditions, including 2, 979 training-and 1, 277 validation images of size 1, 920?1, 080. A includes four common adverse conditions, i.e., fog, nighttime, rain, and snow. Each of these conditions has 1, 000 images: 400 for training, 100 for validation and 500 for testing (resolution 1, 920?1, 080). B has geographic, environmental, and weather diversity and provides 7, 000 training images and 1, 000 validation images, with a resolution of 1, 280?720. I features a higher diversity of within-class appearance compared to C. A total of 10, 004 images with 6, 993 training-and 981 validation examples are captured from Indian roads with a resolution of 1, 280?964. The C dataset contains street scenes of 50 different cities and 19 categories with high resolution of 2, 048?1, 080. The 5, 000 images are divided into 2, 975 training-, 500 validation-, and 1, 525 test samples. Target dataset. We utilize DADA-seg (D) <ref type="bibr" target="#b59">[60]</ref> as our target dataset used for testing our approach, which covers 313 evaluation images. Following <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b60">61]</ref>  <ref type="table">Table 2</ref>. Comparison of state-of-art methods. The source-only models are trained on the Cityscapes dataset, while the other models are domain-transferred using a single source <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b25">26]</ref>, multiple sources <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b60">61]</ref> or a different modality <ref type="bibr" target="#b59">[60]</ref>. While our baseline model has no mixed sampling and performs normal supervised learning based on ResNet101 only using the source domain, our MMUDA framework based on the SegFormer backbone uses MDMS and meta-learning (Meta for short) across the source and target domain.</p><p>are captured in abnormal driving scenes, i.e., traffic accident scenes. The images of D are labelled with 19 classes, which are consistent with the classes of the C dataset (Cityscapes). The resolution of the images is 1, 584?660.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>Our approach leverages the ImageNet1K-pretrained MiT-B2 SegFormer <ref type="bibr" target="#b44">[45]</ref> as the encoder backbone, and the public mmsegmentation framework implementation <ref type="bibr" target="#b2">3</ref> . The meta-learning inner and outer learning rates (i.e. ? and ?) are set to 1e ?3 and 5e ?3 , respectively, with Polynomial learning rate decay with the power 0.9. The network is trained for 120 epochs, unless otherwise specified. The weight ? of the L ds loss is set to 1. We train the model with a mini-batch size of 1 using stochastic gradient descent (SGD), momentum of 0.9 and weight decay of 5e ?4 . For training data augmentation, we use random resizing with ratio 0.5 to 2.0, random flipping, random Gaussian blur, and random cropping with a size of 600?600. Mean Intersection over Union (mIoU) is our main evaluation metric. <ref type="table">Table 2</ref> compares the mean IoU and the per-class IoU scores achieved by our proposed approach to the stateof-the-art methods on DADA-seg. The source-only models trained on Cityscapes experience a considerable performance degradation and achieve a rather low accuracy when deployed in abnormal accident scenes. For example, the ResNet101 <ref type="bibr" target="#b15">[16]</ref>, whose results are illustrated in <ref type="figure" target="#fig_0">Fig. 1, only</ref>  with a vision transformer and multi-source training. Our proposed MMUDA model surpasses all previous results, yielding a significantly higher recognition rate of 46.97% in mIoU, which is &gt;7.50% higher than the past state-ofthe-art. For per-class IoU, our approach achieves the best scores in 16 out of all 19 categories. The improvements over Trans4Trans are compelling (&gt;10.00% performance gain) on categories which are safety-critical for accidental scene understanding, in particular, for road, sidewalk, rider, car, truck, and motorcycle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results of Accident Scenes Segmentation</head><p>The ablation results of our proposed modules are also depicted in <ref type="table">Table 2</ref>, where all experiments are based on all five multi-origin source datasets described in Sec. 4.1. Our baseline model with ResNet101 uses only the normal source-supervised learning by aggregating multiple source domains and obtains a mIoU of 40.76%, whereas the model with meta-learning (+Meta) leads to a further 4.26% improvement. In addition, our proposed MDMS and transformer model with HyrbidASPP further elevate mIoU to 46.11% and 46.97%, respectively. Overall, these results demonstrate the effectiveness of the proposed framework and clear benefits of the MDMS module and the transformer model with HybridASPP, as well as the importance of our multi-source meta-learning training strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study of Meta-learning</head><p>Effect of meta-learning. The previously described <ref type="table">Table 2</ref> indicates clear advantages of meta-learning over the baseline. Next, we study the impact of our meta-learning strategy in more detail though an ablation study featuring a variety of source datasets ( <ref type="table">Table 3</ref>). All of these experiments employ the target-specific normalization and ResNet101 pretained on ImageNet1K <ref type="bibr" target="#b8">[9]</ref> as the backbone.    <ref type="table">Table 3</ref>. Ablation of meta-learning with different source domains and their combinations.</p><p>The baseline models are trained with traditional learning on different single sources, respectively. When using multiple sources, meta-learning-based approaches (e.g., 43.74% with W+I+C) are evidently more effective than the common aggregated-source-supervised learning (e.g., 40.01%).</p><p>Influence of multi-source combination. In <ref type="table">Table 3</ref>, we investigate the impact of combining different datasets on the segmentation performance. In single-source studies, training with WildDash2, BDD, and IDD, respectively, yields the top three mIoU scores thanks to their especially diverse examples. For example, WildDash2 leads to a decent performance, as it offers many composite scenes and various visual hazards. As a result, when these three sources are used together, the combination of W+B+I yields the highest accuracy. In general, leaning with more sources improves the performance for accident scene segmentation, and our five-source meta-learning model attains 45.03% in mIoU, clearly standing out in front of all other models.  <ref type="table">Table 4</ref>. Ablation of decoders. GFLOPs are calculated with a size of 2, 048?1, 024. We train all models on C on a single GPU with a batch size of 1 for 80k iterations and an input size of 768?768.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Ablation Study on HybridASPP</head><p>To analyze the efficiency and effectiveness of our Hy-bridASPP module, we replace the decoder of SegFormer-B2 <ref type="bibr" target="#b44">[45]</ref>, and compare it to LawinASPP <ref type="bibr" target="#b45">[46]</ref> and the proposed decoder in <ref type="table">Table 4</ref>. In terms of computation costs, HybridASPP reduces the GFLOPs of LawinASPP by 15.8 after introducing strip pooling to capture long-range context instead of using traditional image pooling. Looking at the performance, our decoder on D is evidently more reliable than Vanilla MLP. Meanwhile, our HybridASPP achieves higher mIoU scores than LawinASPP with less GFLOPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Model Efficiency Analysis</head><p>To investigate the efficiency of MMUDA, we compare it with state-of-the-art approaches evaluated on DADA-seg following <ref type="bibr" target="#b57">[58]</ref>. Our model employs MiT-B2 <ref type="bibr" target="#b44">[45]</ref> as the encoder and the proposed HybridASPP as the decoder. The comparison of mIoU, GFLOPs, and #Params is shown in <ref type="table" target="#tab_7">Table 5</ref>. Compared to DeepLabV3+ <ref type="bibr" target="#b2">[3]</ref> and HRNet <ref type="bibr" target="#b42">[43]</ref>, our model largely improves the performance, while saving a great amount of computation demands. In comparison with the previous state-of-the-art Trans4Trans-M, we obtain a significant gain of 7.8% in mIoU with 19.1M less parameters and an increase in GFLOPs. Capturing rich contextual cues requires more computation but also ensures the robustness of the model. While our model achieves high efficiency in general, in future work, we will consider a more lightweight encoder to further reduce the computational cost.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Qualitative Analysis</head><p>Effect of MMUDA. In our final study, we showcase multiple examples of representative qualitative results in <ref type="figure" target="#fig_3">Fig. 4</ref>, which corresponds to the numerical results in <ref type="table">Table 2</ref>. Our baseline model produces relatively noisy segmentation results, such that the rushing person in the third row can not be completely segmented, whereas the model using metalearning method makes more accurate predictions in this regard. When a collision happens, the model with the additive MDMS module is better at distinguishing between the motorcyclist and the motorcycle. Furthermore, the segmentation of sidewalk is also improved. In comparison, the noise of the predictions made by our MMUDA model with HyridASPP is much lower and the model segments the sidewalks well even under low light and with occlusion. Overall, our model adapts well to the accident scenario and is capable of providing robustness-improved semantic segmentation for the safety of autonomous driving. Effect of source data. <ref type="figure" target="#fig_4">Fig. 5</ref> visualizes the performance of our model when using different numbers of source domains. The images contain distortion and blur of foreground objects. It can be seen that the Cityscapes-trained model yields fragmented segmentation that disqualifies its application in self-driving scenarios, as it poses great threats in potential accident scenes. Comparing the predictions in the dashed box, our MMUDA provides more robust segmentation results when intertwining more sources. Since DADA-seg is a complex driving scenario, the model will be more ef-fective when the sources provide more diverse information.</p><p>The five-source meta-learned model clearly robustifies and improves semantic segmentation of accident scenes, and we believe that the high-quality predictions can be propagated to the upper-level driving applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Semantic segmentation of road scenes is a key ingredient for safe autonomous driving, but requires models that reliably operate under unusual circumstances. In this work, we specifically focus on segmentation of abnormal accident scenes since unexpected objects or traffic scenarios forms one of the common cause of dangerous situations. To tackle this challenge, we introduce a new framework which transfers knowledge from the well-studied domain of standard image segmentation to our target domain of abnormal scenes. Our Multi-source Meta-learning UDA (MMUDA) framework leverages multi-domain mixed sampling targeting at a better adaptation to the unknown accident scenes and is optimized using meta-learning. We further introduce a HybridASPP decoder design to improve the SegFormer segmentation backbone, which proved to be effective for our task. We verify the robustness of our model through extensive quantitative and qualitative experiments on the public DADA-seg benchmark, demonstrating superior generalization ability to abnormal accident scenes and surpassing previous state-of-the-art by a large margin. Limitation and broader impact. The model training is limited by not using the augmented set as the meta-train set. To address this issue, a potential approach is to combine multiple source domains and target domain into a fusion set, and then to conduct a cross-combination meta-learning process. We leave it to our further research. Besides, the current experiments are conducted based on the referred datasets, thus there are still data biases when the model is applied in real-world test fields.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Semantic segmentation of accident scenes. Compared to the source-only model (e.g., a ResNet), our model generalizes better in the abnormal cases. From top to bottom are dash-crossing pedestrians, overturned motorcycles, collisions, and motion blur.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>The structure of HybirdASPP consists of large window attention and strip pooling to capture long-range context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Qualitative ablation study of different modules used in our framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Qualitative analysis of the effect of using different numbers of source domains in our multi-source meta-learning framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>Datasets</cell><cell cols="3">WildDash2 ACDC BDD</cell><cell cols="3">IDD Cityscapes DADA-seg</cell></row><row><cell>#training</cell><cell>2,979</cell><cell>1,600</cell><cell cols="2">7,000 6,993</cell><cell>2,975</cell><cell>12,207</cell></row><row><cell>#evaluation</cell><cell>1,277</cell><cell>406</cell><cell>1,000</cell><cell>981</cell><cell>500</cell><cell>313</cell></row></table><note>. Statistics of datasets for experiments.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>, 12, 207 unlabelled images are used for unsupervised adaptation. All images MobileNetV2 [37] 16.05 31.87 8.50 26.55 3.60 5.38 13.96 19.51 10.87 44.99 11.09 67.05 8.11 5.23 28.58 11.77 2.17 -1.90 3.86 PSPNet [64] 17.07 31.62 11.42 32.48 4.16 8.52 12.38 17.93 13.39 50.82 13.85 67.19 9.86 3.13 31.54 6.97 34.19 8.24 31.05 4.56 7.39 19.04 27.05 15.35 33.30 12.40 61.52 10.04 3.95 42.59 14.15 27.41.68 13.26 30.45 6.17 11.04 21.91 28.03 17.99 40.05 14.13 56.06 10.75 5.41 34.78 8.01 28.46.49 10.17 42.20 3.81 10.65 13.46 18.69 22.59 55.76 22.22 83.84 6.68 11.75 39.59 7.96 12.42.13 11.54 34.49 6.63 12.70 22.76 29.03 22.28 42.41 15.15 85.43 14.31 6.65 53.94 20.65 34.[58] 39.20 71.10 15.57 70.39 10.34 16.53 31.63 37.16 37.38 71.88 19.61 93.04 21.27 14.97 64.04 53.76 81.53 -24.63 10.07 Our Baseline 40.73 84.93 23.66 68.34 16.27 20.58 25.96 31.25 28.20 71.89 22.39 93.16 17.92 26.84 73.89 55.09 69.26 -34.77 9.49 +Meta 45.03 86.20 25.44 70.63 14.21 19.75 26.56 28.01 29.23 74.45 25.29 93.18 20.40 31.53 75.02 64.73 76.84 -38.05 10.95 +Meta+MDMS 46.11 87.10 27.71 71.11 22.94 20.64 32.25 29.49 34.34 75.48 24.02 92.18 20.65 33.33 74.64 63.35 71.14 -39.08 12.04 Our MMUDA 46.97 87.51 27.97 74.76 16.16 21.93 29.94 29.43 31.62 75.67 26.69 93.57 24.40 29.57 77.35 68.24 84.02 -36.96 10.44</figDesc><table><row><cell></cell><cell>Method</cell><cell>mIoU</cell><cell>road</cell><cell>sidewalk</cell><cell>building</cell><cell>wall</cell><cell>fence</cell><cell>pole</cell><cell>traffic light</cell><cell>traffic sign</cell><cell>vegetation</cell><cell>terrain</cell><cell>sky</cell><cell>person</cell><cell>rider</cell><cell>car</cell><cell>truck</cell><cell>bus</cell><cell>train</cell><cell>motorcycle</cell><cell>bicycle</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3.15</cell><cell>-</cell><cell>2.97</cell><cell>2.89</cell></row><row><cell></cell><cell>ResNet50 [16]</cell><cell cols="18">18.96 02 -</cell><cell>3.72</cell><cell>4.72</cell></row><row><cell>Source-only</cell><cell>SemFPN [20] DNLNet [49] ResNeSt [56] DANet [12]</cell><cell cols="18">19.59 37.90 10.12 23.80 3.74 19.72 01 -9.64 22.06 28.64 15.55 40.95 12.13 51.93 9.24 5.93 52.08 13.89 26.54 -19.99 39.63 11.38 33.68 2.81 9.73 22.76 27.35 18.09 45.24 14.22 71.23 13.34 5.03 36.45 6.91 13.08 -22.24 64 -</cell><cell>3.66 3.55 3.94 7.98</cell><cell>4.36 3.39 4.87 6.12</cell></row><row><cell></cell><cell>ResNet101 [16]</cell><cell cols="5">23.60 57.96 11.16 39.94 6.43</cell><cell cols="13">9.46 23.67 27.37 17.32 45.65 16.47 69.21 13.19 4.51 47.29 13.75 30.44 -</cell><cell>6.64</cell><cell>8.01</cell></row><row><cell></cell><cell>OCRNet [52]</cell><cell cols="18">24.85 86 -</cell><cell>9.30</cell><cell>7.87</cell></row><row><cell></cell><cell>FastSCNN [32]</cell><cell cols="5">26.32 69.91 16.30 52.53 6.09</cell><cell cols="12">9.63 19.98 19.30 22.58 57.04 22.95 90.81 11.19 13.95 46.16 22.65 9.74</cell><cell>-</cell><cell>4.49</cell><cell>4.75</cell></row><row><cell></cell><cell>CLAN [26]</cell><cell cols="13">28.76 79.80 18.61 51.56 8.32 13.60 15.51 17.15 21.51 63.20 21.99 80.53 8.37</cell><cell cols="5">6.32 63.47 33.43 33.12 -</cell><cell>3.69</cell><cell>6.21</cell></row><row><cell></cell><cell>BDL [23]</cell><cell cols="18">29.66 81.44 19.18 57.18 8.61 16.26 14.65 8.78 16.77 66.60 26.83 85.87 10.51 7.16 65.45 35.18 34.78 -</cell><cell>2.71</cell><cell>5.57</cell></row><row><cell>Cross-source</cell><cell>ISSAFE [60] EDCNet [61] Trans4Trans-M</cell><cell cols="18">29.97 80.23 19.51 52.02 6.43 14.68 16.19 17.03 19.50 65.39 21.69 79.84 9.95 32.04 73.03 19.47 57.31 11.60 14.30 20.70 12.27 27.22 70.54 18.98 88.64 10.69 8.70 68.14 49.80 50.86 -8.82 65.60 39.51 39.73 -</cell><cell>6.09 9.02</cell><cell>7.03 4.12</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>reaches 23.60% in mIoU. The previous stateof-the-art Trans4Trans model [58] attains 39.20% in mIoU</figDesc><table /><note>3 https://github.com/open-mmlab/mmsegmentation</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 .</head><label>5</label><figDesc>Model efficiency analysis. GFLOPs are calculated with the input size of 768?768.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/AutoNUE/public-code</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">MetaReg: Towards domain generalization using metaregularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">CycleMLP: A MLP-like architecture for dense prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoufa</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongjian</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2022</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Blending-target domain adaptation by adversarial metaadaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyu</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Perpixel classification is not all you need for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">RobustNet: Improving domain generalization in urban-scene segmentation via instance selective whitening</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungha</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghun</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiwon</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanne</forename><forename type="middle">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungryong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Domain generalization via model-agnostic learning of semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Coelho De Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dual attention network for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijie</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cluster, split, fuse, and update: Meta-learning for open compound domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danda</forename><surname>Pani Paudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajad</forename><surname>Chhatkuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hypernetworks</surname></persName>
		</author>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-source domain adaptation with collaborative learning for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuaijun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhuang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Vision permutator: A permutable MLP-like architecture for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Strip pooling: Rethinking spatial pooling for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">FSDR: Frequency space domain randomization for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayan</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoran</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijian</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Panoptic feature pyramid networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Online meta-learning for multi-source and semi-supervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Open compound domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">ClassMix: Segmentation-based data augmentation for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilhelm</forename><surname>Tranheden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliano</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lennart</forename><surname>Svensson</surname></persName>
		</author>
		<idno>WACV, 2021. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">In defense of pre-trained ImageNet architectures for realtime semantic segmentation of road-driving images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marin</forename><surname>Orsic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Kreso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petra</forename><surname>Bevandic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinisa</forename><surname>Segvic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Two at once: Enhancing learning and generalization capacities via IBN-net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Inkyu Shin, and In So Kweon. Discover, hallucinate, and adapt: Open compound domain adaptation for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwanyong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyun</forename><surname>Woo</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">MASS: Multi-attentional semantic segmentation of LiDAR data for dense top-view understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunyu</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncong</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alina</forename><surname>Roitberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Bieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Heidenreich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<idno>2022. 1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fast-SCNN: Fast semantic segmentation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Poudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">ERFNet: Efficient residual factorized ConvNet for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Romera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><forename type="middle">Miguel</forename><surname>Bergasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Arroyo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">T-ITS</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Bridging the day and night domain gap for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Romera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><forename type="middle">Miguel</forename><surname>Bergasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Barea</surname></persName>
		</author>
		<editor>IV</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">ACDC: The adverse conditions dataset with correspondences for semantic driving scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Sakaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV, 2021</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Effective use of synthetic data for urban scene semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fatemeh Sadat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Sadegh Aliakbarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Petersson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alvarez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MobilenetV2: Inverted residuals and linear bottlenecks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Segmenter: Transformer for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Strudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">See clearer at night: Towards robust nighttime semantic segmentation through day-night image conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaite</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">MLP-mixer: An all-MLP architecture for vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ilya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Tolstikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dosovitskiy</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">DACS: Domain adaptation via crossdomain mixed sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilhelm</forename><surname>Tranheden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliano</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lennart</forename><surname>Svensson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV, 2021</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">IDD: A dataset for exploring problems of autonomous navigation in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anbumani</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><forename type="middle">M</forename><surname>Namboodiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Deep high-resolution representation learning for visual recognition. TPAMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaorui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Dual-flattening transformers through decomposed row and column queries for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiuman</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenju</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.09139</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">SegFormer: Simple and efficient design for semantic segmentation with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2021</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Lawin transformer: Improving semantic segmentation transformer with multi-scale representations via large window attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotian</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.01615</idno>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Bi-mix: Bidirectional mixing for domain adaptive nighttime semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanglei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingli</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.10339</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Capturing omni-range context for omnidirectional segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Rei?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Disentangled non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuliang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Vashisht Madhavan, and Trevor Darrell. BDD100K: A diverse driving dataset for heterogeneous multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haofeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangchen</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">MetaFormer is actually what you need for vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyang</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Objectcontextual representations for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sicheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">WildDash -Creating hazard-aware benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Zendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Honauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Murschitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Steininger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><forename type="middle">Fernandez</forename><surname>Dominguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Ciss?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongruo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08955</idno>
		<title level="m">ResNeSt: Splitattention networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Generalizable model-agnostic semantic segmentation via targetspecific normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Trans4Trans: Efficient transformer for transparent object and semantic scene segmentation in real-world navigation assistance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Constantinescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunyu</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note>T-ITS, 2022. 2, 6</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Bending reality: Distortion-aware transformers for adapting to panoramic semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoxiang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Rei?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunyu</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">IS-SAFE: Improving semantic segmentation in accidents by fusing event-based data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Exploring event-driven dynamic context for accident scene segmentation. T-ITS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Prototypical pseudo label denoising and target structure learning for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Curriculum domain adaptation for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sixiao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zekun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yabiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Context-aware mixup for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiqi</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangliang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuequan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhuang</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.03557</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Asymmetric non-local neural networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengde</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengteng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
