<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">N-pad : Neighboring Pixel-based Industrial Anomaly Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junkyu</forename><surname>Jang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Hwang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung-Hyuk</forename><surname>Park</surname></persName>
							<email>sunghyuk.park@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">N-pad : Neighboring Pixel-based Industrial Anomaly Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Identifying defects in the images of industrial products has been an important task to enhance quality control and reduce maintenance costs. In recent studies, industrial anomaly detection models were developed using pre-trained networks to learn nominal representations. To employ the relative positional information of each pixel, we present Npad, a novel method for anomaly detection and segmentation in a one-class learning setting that includes the neighborhood of the target pixel for model training and evaluation. Within the model architecture, pixel-wise nominal distributions are estimated by using the features of neighboring pixels with the target pixel to allow possible marginal misalignment. Moreover, the centroids from clusters of nominal features are identified as a representative nominal set. Accordingly, anomaly scores are inferred based on the Mahalanobis distances and Euclidean distances between the target pixel and the estimated distributions or the centroid set, respectively. Thus, we have achieved state-of-the-art performance in MVTec-AD with AUROC of 99.37 for anomaly detection and 98.75 for anomaly segmentation, reducing the error by 34% compared to the next best performing model. Experiments in various settings further validate our model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Humans have the inherent ability to recognize unusual or abnormal patterns that deviate from what is considered the norm. This trait is essential for various tasks in which inappropriate states must be detected. In particular, identifying defects in the images of industrial products is essential for enhancing quality control and reducing unnecessary maintenance costs. Therefore, artificial intelligence models for industrial anomaly detection have been developed to more precisely identify anomalous images and segments.</p><p>In the industrial field, most products are nominal with a rare occurrence of anomalous production. Here, an out-ofdistribution classification is performed by training the distribution of nominal features using only a nominal dataset and by evaluating how the nominal and anomalous images in the test set deviate from the nominal distribution. Industrial anomaly detection has been challenging because some small-scale anomalous regions in products are often too small to distinguish. Moreover, anomalies in the industrial field vary from minor flaws, such as cracks, scratches, and holes, to significant irregularities, such as missing components, flips, and colors. To detect these anomalies well, various models based on autoencoders (AE), semi-supervised learning, generative adversarial networks (GAN), and normalizing flows have been developed. Recently, image representations were extracted from pre-trained models using ImageNet to learn the pixel-wise distributions of features without adaptation through transfer learning, which demonstrated state-of-the-art performances. To successfully use pre-trained models for anomaly detection, the assumption that nominal images are perfectly aligned is necessary for accurate pixel-wise distributions. In this sense, attempts have been made to disregard positional information during detection. Nevertheless, because the inherent properties of industrial products exist primarily in their unique shapes, the positional information of each pixel cannot be overlooked.</p><p>Thus, we propose Neighboring Pixel-based industrial Anomaly Detection (N-pad), which is the first attempt to employ the features of neighboring pixels to acquire positional information and minimize errors caused by misalignment. Here, two novel modules for weight application and feature aggregation of neighboring pixels are devised to estimate two nominal distributions by fully leveraging the features of neighboring pixels. Specifically, weights are applied to neighboring pixels according to the similarity values between the target pixel and its neighborhood, which are computed using the Bhattacharyya distance. By integrating the two estimated distributions for the computation of the final anomaly score, we achieved state-of-the-art performance in multiple classes of the industrial dataset with a pixel-wise area under the receiver operating characteristic curve (AUROC) of 98.75, which is a 34% improvement compared to the existing state-of-the-art model . Various experiments are performed to demonstrate the robust-ness of the model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">General Anomaly detection</head><p>Conventional models for anomaly detection have been developed to accurately learn the representative attributes of nominal data. In this sense, existing studies have primarily implemented reconstruction-and embedding-similaritybased methods. In terms of reconstruction-based methods, models are trained to learn features that reconstruct the original data, which identifies poorly reconstructed samples as anomalies. Accordingly, extensions based on AEs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b30">31]</ref> or GANs <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b35">36]</ref> have been proposed. In terms of embedding similarity-based methods, the latent features of nominal data were learned from the model to identify samples distinct from the nominal distribution as anomalies. As a reference for the nominal features, the center of constrained latent feature spaces <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b38">39]</ref>, geometric transformations <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref>, estimation of the probability density function using Gaussian mixture models <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b41">42]</ref>, and kernel density estimations <ref type="bibr" target="#b16">[17]</ref> have been employed. Hence, distance-based metrics <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b34">35]</ref> have been applied to assign distant samples with high anomaly scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Industrial anomaly detection</head><p>Industrial anomaly detection has developed differently from general anomaly detection because learning the unique nominal features of an industrial object or texture is essential <ref type="bibr" target="#b4">[5]</ref>. A recent trend in industrial anomaly detection is to use a model pre-trained on an external image dataset, such as ImageNet, to learn the distribution or features of the nominal dataset without transfer learning <ref type="bibr" target="#b2">[3]</ref>. One of the first successful applications was SPADE <ref type="bibr" target="#b7">[8]</ref>, which obtains a global feature set from the given network of the nominal data and applies a Euclidean distance-based measure of the k-nearest neighbor <ref type="bibr" target="#b11">[12]</ref> to the feature set for image-wise anomaly detection. Another pre-trained network-based model, PaDiM <ref type="bibr" target="#b8">[9]</ref> learned the distribution of local features at every pixel and obtained a pixel-wise anomaly map by computing the Mahalanobis distance between the pixel and its distribution <ref type="bibr" target="#b20">[21]</ref>. Similarly, Patch-Core <ref type="bibr" target="#b25">[26]</ref> proposed an algorithm for storing a subsampled coreset <ref type="bibr" target="#b0">[1]</ref> of the pre-trained features in a memory bank to obtain the patch-level distance between the coreset and a sample for detecting anomalies. In addition, attempts have been made to adapt the weights of the pre-trained model to identify the distribution of nominal data. FastFlow <ref type="bibr" target="#b39">[40]</ref>, FEFM <ref type="bibr" target="#b36">[37]</ref>, and CFLOW-AD <ref type="bibr" target="#b14">[15]</ref> reported good performances by estimating the distribution of network-based features by normalizing the flow, and CFA <ref type="bibr" target="#b18">[19]</ref> implemented feature adaption through Coupled-hypersphere to better ex-plain the distribution of nominal features.</p><p>However, there are some limitations in existing pretrained feature-based models without the adaptation of pretrained features. In particular, because PADiM utilized only the nominal data of the target pixel location to compute its anomaly score, the scores may be overestimated if all nominal industrial images are not perfectly aligned. PatchCore was developed to disregard the positional information of the pixel because the anomaly scores were computed based on the distance from the core patch-level local features that were stored in a memory bank as a whole. Nevertheless, considering the positional information of each pixel is essential for anomaly detection. When augmentations of rotated images were included for prediction in CSI <ref type="bibr" target="#b33">[34]</ref>, the predictive performance degraded, indicating that the change in position was not constructive for anomaly detection.</p><p>Thus, to overcome these limitations, the proposed model is devised to employ the information of neighboring pixels to estimate the nominal distribution of each pixel because the method of integrating the relationship between neighboring nodes with features has long been utilized in graph neural networks. Specifically, the similarities between the target pixel and its neighborhood are applied as weights to appropriately consider the information of neighboring pixels along with the target pixel. Consequently, we aim to design a model that is less affected by perfect image alignment but utilizes the positional information of pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Calculation of pixel-wise neighborhood similarity</head><p>Feature extraction In this study, a model architecture which implemented a pre-trained network on ImageNet as the backbone is designed for the out-of-distribution task of anomaly detection. Herein, the training set X train = {x k | y k = 0} consists of |X train | = N nominal images, and the test set X test = {x k | y k = 0 or 1} consists of |X test | = N test images that are either nominal or anomalous, where x k denotes a single image from a set of all images X train , and y k ? {0, 1} denotes image x k as nominal with 0 and anomalous with 1. As in previous studies <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b25">26]</ref>, ResNet-like architectures, such as ResNet50 and WideResnet-50, were employed to extract feature maps. Within the given network ? h , feature maps are extracted from the final output of the spatial resolution block at a specific hierarchy level (h = 1, 2, 3). Because the feature map extracted from the lowest hierarchy level (h = 1) has the largest size, the feature maps of higher hierarchy levels (h = 2, 3) are interpolated to this size. Consequently, the pre-trained feature set ?(x k ) = [? h (x k ) , h = {1, 2, 3}] is constructed by concatenating all channels from each level.</p><p>Dimension Reduction Before estimating the nominal distributions, dimension reduction is performed on the total set of concatenated features ?(x k ) because features extracted from the pre-trained network may infer redundant information. Although the concatenated channels at each pixel are assumed to follow a multivariate Gaussian distribution, not every channel may follow a Gaussian distribution. In this sense, when reducing the number of channels, we aim to select the channels with an approximate Gaussian distribution form. We believe that the normal distribution may be distorted when all channels with values below zero are set to zero after applying ReLU function at the end of most pre-trained networks. Accordingly, the nonzero values in the nominal features are counted for each channel, and the top-d channels with the least nonzero values are selected. Consequently, the final nominal feature set reduced from ?(x k ) is identified and denoted as e x k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Estimation of weighted similarity distribution</head><p>Calculation of pixel-wise neighbor Bhattacharyya distance To estimate the nominal distribution at each pixel, we propose a novel method for computing the pixel-wise similarity between a pixel and its neighborhood. In this study, we aim to calibrate possible misalignments by including information from neighboring pixels, whereas the perfect alignment of pixels was essential for position-based estimations in existing methods. Specifically, the neighborhood of a pixel is defined as the set of p pixels that were adjacent to the target pixel:</p><formula xml:id="formula_0">N (h,w) p = {(h , w ) | h ? [h ? p/2 , h + p/2 ], w ? [w ? p/2 , w + p/2 ]}<label>(1)</label></formula><p>First, based on the assumption that every pixel (h, w) in a feature map e (h,w) i of a nominal image i follows a multivariate Gaussian distribution, the sample mean ? (h,w) and covariance ? (h,w) of the nominal distribution are estimated. In addition, a regularization term I is added to ? (h,w) to ensure full rank and invertibility.</p><formula xml:id="formula_1">? (h,w) = 1 N N i=1 e (h,w) i (2) ? (h,w) = 1 N?1 N i=1 e (h,w) i ? ? (h,w) e (h,w) i ? ? (h,w) T + I<label>(3)</label></formula><p>Next, the Bhattacharyya distance m, which indicates the distance between two probability distributions, is computed between the target pixel and all pixels within the neighborhood. Because the Bhattacharyya coefficient BC measures the overlapping degree of the two distributions, the negative exponential value of the coefficient is accepted as the similarity value. Consequently, the Bhattacharyya distance set ? (h,w) p between the estimated distribution of pixels (h, w), and N (h,w) p is computed as follows:</p><formula xml:id="formula_2">? (h,w) p = {m a |a ? N (h,w) p } m a = Batt(N (? (h,w) ,? (h,w) ) , N (? a ,? a ) ), Batt = e ? BC ? BC(N (? 1 , ? 1 ), N (? 2 , ? 2 )) = 1 8 (? 1 ? ? 2 ) T ? (?1) (? 1 ? ? 2 ) + 1 2 log( det? ? det? 1 det? 2 )<label>(4)</label></formula><p>where ? 1 and ? 2 denote a pair of mean values obtained from the estimated distributions and ? denotes the average of ? 1 and ? 2 . Herein, a balancing parameter ? is employed to modulate the degree to which the neighboring pixels are used to estimate the distributions. A ? of 1 is equal to the original formulation of the Bhattacharyya distance, and larger values of ? imply that more information is used from the neighborhood. Moreover, by assuming that the inherent information of pixels within a neighborhood, denoted as the sample covariances of (h, w) and (h , w ), are similar, the logarithm of the ratio of the determinant terms in Eq. (4) is negligible. Consequently, the final similarity with the reduced computational cost is calculated as follows:</p><formula xml:id="formula_3">BC(N (?1,?1) , N (?2,?2) ) 1 8 (? 1 ? ? 2 ) T ? (?1) (? 1 ? ? 2 ) (5)</formula><p>Learning the normality based on similarity As the last step for learning the nominal distribution of each pixel, we aim to accentuate the features at specific locations that may infer more relevant information about the target pixel (h, w). In this sense, weights are applied to the neighboring pixels according to their similarity to the target pixel. Accordingly, the similarity values calculated within N (h,w) p are utilized to estimate the weighted sample mean ? (h,w) and covariance ? (h,w) to accurately train the distribution of each pixel from the nominal images. The weighted sample mean and covariance are defined as follows:</p><formula xml:id="formula_4">? (h,w) = 1 N N i=1 a?N (h,w) p m a e a i , m a = m a a?N (h,w) p m a ? (h,w) = 1 N ? a?N (h,w) p (m a ) 2 ? N i=1 a?N (h,w) p m a (e a i ? ? (h,w) )(e a i ? ? (h,w) ) T<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Estimation of aggregated feature distribution</head><p>Learning the normality based on neighborhood aggregate features To best use the information of neighboring pixels, the normality based on aggregating neighborhood features (B in <ref type="figure" target="#fig_0">Fig. 1</ref>) is learned, in addition to the normality learned with weights (A in <ref type="figure" target="#fig_0">Fig. 1</ref>). Because neighboring pixels infer unseen information from the target pixel, an anomaly map for a receptive field with higher resolution is identified by aggregating the features within a neighborhood as follows:</p><formula xml:id="formula_5">?(e (h,w) ) = f agg (e a |a ? N (h,w) p )<label>(7)</label></formula><p>where f agg is the aggregation function for the neighborhood N (h,w) p . In N-pad, we use adaptive average pooling for f agg . Accordingly, the pixel-wise nominal distribution is learned by computing the sample mean and variance of the aggregated features at each pixel.</p><p>Because utilizing the Euclidean distance between the test feature and aggregated features has been effective in imagelevel anomaly detection in existing studies, we aim to construct a memory bank consisting of a group of essential features. In this sense, the aggregated features from the nominal set are clustered using k-means, and the features identified as the centroid of each cluster are grouped into a representative set of features denoted as C. In fact, the method of retrieving centroids as key features has been highly robust for outliers and noisy features within the nominal set and reported significant performance as opposed to arbitrary feature selection <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b40">41]</ref>. Thus, within the memory bank of all cluster centroids C, a group of centroids near the target feature is retrieved for image-level anomaly detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Inference: computation of anomaly score</head><p>Pixel-wise anomaly map The anomaly score of a pixel (h, w) is computed using the Mahalanobis distance between the target pixel and distributions estimated by the two modules, in which features highly deviated from the nominal distributions reported higher anomaly scores.</p><p>First, because the information of neighboring pixels at (h, w) is involved in estimating the weighted distribution of N (?, ?), features extracted at (h, w) affect the values in N (h,w) p . In this sense, we also employ the distributions of neighboring pixels when computing the anomaly score of the targeted position. Accordingly, Mahalanobis distances are computed between the target feature e (h,w) and its neighborhood, which is defined as a collection of estimated distributions P q (e (h,w) ) identified from N (h,w) q . By applying a minimum aggregation function f to the set of Mahalanobis distances, D 1 is obtained for each pixel and used to calculate the anomaly score. The computation of D 1 proceeds as follows:</p><formula xml:id="formula_6">P q (e (h,w) ) = {N (? a , ? a ) | a ? N (h,w) q } (8) D 1 (e (h,w) , P q (e (h,w) )) = f ( (e (h,w) ) ? ? a ) T (? a ) ?1 ((e (h,w) ) ? ? a ) | a ? N (h,w) q )<label>(9)</label></formula><p>Next, the Mahalanobis distance D 2 between aggregated features ?(e (h,w) ) of pixel (h, w) and N (? (h,w) agg , ? h,w agg ) is defined as follows:</p><formula xml:id="formula_7">D 2 (?(e (h,w) ), N (? (h,w) agg , ? h,w agg )) = (?(e (h,w) ) ? ? (h,w) agg ) T (? (h,w) agg ) ?1 (?(e (h,w) ) ? ? (h,w) agg )<label>(10)</label></formula><p>Finally, to equalize the effects of the two pixel-wise anomaly maps D 1 and D 2 obtained from all pixels using Eq. (9) and Eq. <ref type="formula" target="#formula_0">(10)</ref>, the geometric mean of the two maps is used as the final anomaly score M (h,w) :</p><formula xml:id="formula_8">M (h,w) = D 1 D 2<label>(11)</label></formula><p>Image-wise anomaly score The image-level anomaly score based on the Euclidean distance between the aggregated features of a test image and refined set of aggregated nominal features has been effective in existing studies. Herein, a combination of Euclidean and Mahalanobis distances is employed to detect image-level anomalies more accurately. First, the top-k Mahalanobis distances D 1 between the target feature e (h,w) and estimated distribution collection of P q (e (h,w) ) are identified as a set Q k . Next, for all pixels included in Q k , the minimum Euclidean distance d between the aggregated feature of a pixel ?(e v ) and the centroids in set C is calculated for all pixels and denoted as set E k . Consequently, the image-level anomaly score is defined as follows:</p><formula xml:id="formula_9">Q k = max (h,w) k(D 1 (e (h,w) , P q (e (h,w) )))<label>(12)</label></formula><formula xml:id="formula_10">E k = {min C d(?(e v ), C) f or ? v ? arg max k D 1 } (13) M image = k i=1 sort(E k )[i]sort(Q k )[i]<label>(14)</label></formula><p>where E k and Q k are sorted in ascending order because the sizes of the two distance values at each pixel are not in accordance. Consequently, employing both the top-k Euclidean and Mahalanobis distances is demonstrated to be robust for computing image-level anomalies. Image-shifting As the final inference step, target image x k is shifted by the pixel level from size 1 to r to compute the final image-wise anomaly score and pixel-wise anomaly map based on the anomaly scores of the shifted images. By aggregating the scores from all shifted images of x k denoted as a set I r k , we expect the marginal misalignment in the images to be negligible. Set I r k is defined as follows:</p><formula xml:id="formula_11">I r k = {x k | x k [h ? a, w ? b] = x k [h, w] ?(a, b) ? [ ?r/2, r/2 , ?r/2, r/2 ]}<label>(15)</label></formula><p>4. Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset and experimental setup</head><p>In this study, the proposed model is trained and evaluated on MVTec Anomaly Detection dataset (MVTec-AD) <ref type="bibr" target="#b4">[5]</ref>, which has been widely used for industrial anomaly detection tasks in existing studies. MVTec-AD consists of ten object and five texture classes with 3,629 nominal-only images for training and 1,725 nominal and anomalous images for evaluation. Moreover, we perform additional experiments Magnetic Tile Defects (MTD) in the Appendix to further validate our model. All images are center-cropped from 256 ? 256 to 224 ? 224 before model training and evaluation. The proposed model with a neighborhood size p of 3 for model training, neighborhood size q of 2 for inference, shift size r of 4, balancing parameter ? of 0.25, dimension reduction to 550, and 10% use of the centroids from C reported the best predictive performance.</p><p>To evaluate the performance of the proposed model, the image and pixel levels of the AUROC are measured. In addition to the AUROC, the per-region-overlap score (PROscore), which has been widely used in existing studies to measure anomaly detection performance, is measured for pixel-level anomaly segmentation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Herein, a PROcurve is plotted using the average rates of correctly classified pixels for all connected anomalous components, with the false positive rates set between 0 and 0.3. Accordingly, the PRO-score is computed by normalizing the area under the PRO-curve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison with baseline methods</head><p>To validate the predictive performance of the proposed model, we have benchmarked methods from general anomaly detection, pre-trained feature-based models, and existing models with state-of-the-art performance on MVTec-AD dataset. Since some existing models, such as Cflow-AD and PEFM, reported ensembled results with different image resolutions or without the 224 X 224 crop, we standardize the image size of all models prior to model training for objective comparison.</p><p>Tab. 1 presents the AUROC of image-level anomaly detection and pixel-level anomaly segmentation for all 15 classes of MVTec-AD. Herein, the proposed model consistently outperforms existing models with state-of-the-artperformance in both tasks. Specifically, the reduction of We believe that the proposed method of applying similarity between the target pixel and its neighborhood as weights successfully trained the underlying relationship within the pixels. In addition, we believe that the shifting module also contributed greatly to the predictive performance by inferring the distributions of neighboring pixels when computing anomaly score. Considering that identifying ill-produced samples is highly essential and demanding in industrial fields, our experiments have demonstrated that the proposed model may be effective in industrial anomaly detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation study</head><p>Evaluation of the effectiveness of key design components The effectiveness of the four modules comprising the proposed model architecture (A, B, C, and D in <ref type="figure" target="#fig_0">Fig. 1)</ref> is evaluated by removing certain modules and comparing their predictive performances. Herein, five experiments are performed, as follows. Experiment 1: Inference only using the weighted simi-larity distribution of the target pixel without the aggregated feature distribution (A). Experiment 2: Inference only using the aggregated feature distribution without the weighted similarity distributions (B). Experiment 3: Inference using both the weighted similarity distribution of the target pixel and aggregated feature distribution (A+B). Experiment 4: Inference using the distributions from neighboring pixels to estimate the weighted similarity distribution (A+C).</p><p>Experiment 5: Inference using the distributions from neighboring pixels to estimate the weighted similarity and aggregated feature distributions without shifting (A+B+C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Exper1 <ref type="formula">Exper2</ref>   Tab. 3 shows that all modules significantly contribute to the performance of anomaly detection. First, the degraded performance in Experiment 5 compared with the result of N-pad proves that shifting the aggregated anomaly maps is superior to the sole use of the original images. Next, 0.19 increase in the AUROC from Experiment 1 to Experiment 4 demonstrates that using the distributions from the neighboring pixels was effective in estimating the weighted similarity distribution. This result suggests that aggregating the anomaly scores computed from the distributions of neighboring pixels is effective. Finally, the improved performance in Experiment 3, which integrated both modules from Experiments 1 and 2, demonstrates that the inference that uses both weighted similarity and aggregated feature distributions was effective. Verification of parameter efficiency in model architecture Various parameters within the modules were tested to determine the optimal design of the proposed model. First, different neighborhood sizes (p) for estimating the distributions of weighted similarity or aggregated features are tested. <ref type="figure" target="#fig_1">Fig. 2a</ref> demonstrates that the performance improves as the neighborhood size increases from 1, reaches the optimal level at a size of 3, and degrades with larger sizes. Thus, we believe that acquiring information from considerably close neighbors is the best, whereas distant neighbors infer excessive information with no greater relevance to the target pixel.</p><p>Second, the different numbers of distributions on neighboring pixels (q) used to compute the anomaly map in module A <ref type="figure" target="#fig_0">(Fig. 1)</ref> are tested. <ref type="figure" target="#fig_1">Fig. 2b</ref> shows a neighbor size of 2 as the optimal value. Because applying a large neighborhood size may affect numerous pixels of the original image during interpolation, we believe that a relatively small number is optimal.</p><p>Third, different shifting sizes (r) are tested, as shown in <ref type="figure" target="#fig_1">Fig. 2c</ref>, resulting in a shifting size of 4 being the most optimal. This approach demonstrates that calibrating imperfectly aligned industrial images through the aggregation of slightly shifted versions of the images can significantly contribute to improved performance. Fourth, the number of channels following the dimension reduction is tested by first using 50 channels and increasing the number up to 550 in units of 50. As shown in <ref type="figure" target="#fig_1">Fig. 2d</ref>, the proposed model outperforms PatchCore, a stateof-the-art model, with an pixel-wise AUROC of 98.1, when the number reaches 150 channels, which is only 8.37% of the total number of channels. Because the computational cost reduces quadratically with fewer channels, this result demonstrates that the proposed model can be effective with minimal computation. Finally, additional experiments are performed with different image sizes because a few existing models have reported benchmark scores by extensively reshaping the image size or excluding image crops. Because the cropped area is mostly the edge of the image background, which may be easily identified as nominal pixels, the better predictive performance is recorded with larger image sizes without cropping. Consequently, an ensemble of models which employed images cropped by 224 and 336 reported the best pixel-wise AUROC of 98.98, as shown in Tab. 4.</p><p>Evaluation of the effectiveness of Bhattacharyya distance for estimating weighted similarity distributions To demonstrate the effectiveness of the Bhattacharyya distance calculation for estimating the weighted similarity distribu-    <ref type="table">Table 4</ref>. AUROC comparison of different image sizes and crops tions in this study, uniform and random weights are tested for comparison, as presented in Tab. 5. First, weights that are randomly applied resulted in poor performance because the relationships within the pixels were not considered. Moreover, uniformly applied weights also have a minimal effect on the estimated mean and covariance of the distributions, because features from neighboring pixels may not infer significantly different information from the target pixel. Consequently, the proposed method of weighted sampling based on similarity is reported as the most effective for predictive performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sampling Method 1/n Random Ours</head><p>Pixel-wise AUROC 98.42 98.42 98.45 <ref type="table">Table 5</ref>. AUROC comparison of different sampling methods</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison of methods for reducing dimensions with various backbones</head><p>To evaluate the proposed distribution-based method for dimension reduction, results based on a random dimension reduction with different backbones are reported for comparison. First, the random selection of dimensions in the proposed model achieves an AU-ROC decrease of 0.34. Next, a random dimension reduction in features extracted at the batch normalization layer prior to ReLU scores AUROC that is 0.23 lower than that of the proposed model. This result demonstrates that because the channels activated greater than 0 by the activation function are more relevant for ImageNet classification, the pre-trained network features extracted from those channels may have been more effective. Furthermore, various model architectures other than the WideResNet-50 of the proposed model, such as ResNet18, ResNext50, WideResNet-101, and ResNext-101, are tested for comparison. As shown in <ref type="figure" target="#fig_1">Fig. 2e</ref>, the proposed method reports a better performance than random reduction in all architectures, demonstrating the consistency of its superiority.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Few-shot Anomaly Detection</head><p>Few-shot anomaly detection In the industrial field, anomaly detection can be required for initial production, where only a small set of nominal sample data is available. Accordingly, few-shot anomaly detection is performed to test the proposed model with limited nominal data by testing the number of training images from 1 to 50. Consequently, the proposed model achieves better performance than the previous state-of-the-art model using only 8% of the total dataset. Because the proposed model employs information from neighboring pixels to train the distribution of the target pixel, the augmented information from the neighborhood may have significantly contributed to few-shot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose a novel model for industrial anomaly detection and segmentation that utilizes features from the neighborhood of the target pixel. We estimate the nominal distribution of each pixel inferring the the information in the neighborhood by applying the similarity between the neighboring pixels and target pixel as weights. Moreover, another estimation of the nominal distribution based on aggregated features is proposed to employ information from various receptive fields. Various experiments evaluate the model in multiple settings and achieved state-of-theart performances on the 15 classes of an industrial anomaly dataset. Thus, we believe that learning nominal distributions with the pre-trained features of neighboring pixels is useful and effective for improving predictive performances in industrial anomaly detection.</p><p>In addition to the MVTec-AD dataset, we performed additional experiments with MTD (Magnetic Tile Defects) dataset which has also been used for industrial anomaly detection in previous studies <ref type="bibr" target="#b15">[16]</ref>. MTD dataset consists of magnetic tile images in various shapes and patterns, of which 925 are nominal and 392 are anomalous. As in previous studies, 80% of the nominal data were employed for model training and the remaining 20% and the anomalous data were employed for evaluation. Accordingly, the results were compared to existing pre-trained network-based models and DifferNet <ref type="bibr" target="#b26">[27]</ref>, which reported good performance. The results are reported as follows: Since the shapes of nominal data are not consistent, the images may not be clearly aligned, which makes the predictions on MTD dataset challenging. Nevertheless, we have achieved superior performance by employing neighboring pixels to calculate anomaly score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation on various ratios of k-means centroids</head><p>We have tested various ratios of the K-means centroids included for model evaluation and compared their AU-ROCs. In fact, the decrease in the number of clusters did not significantly affect the results because a highly robust set of centroids was employed.</p><p>K-means ratio 0.25 0.1 0.05 0.01 0.005 Image-wise AUROC 99.39 99.37 99.34 99.31 99.10 <ref type="table">Table 7</ref>. Evaluation of image-wise AUROC on various ratios of k-means centroids C. Details in PRO-score PRO-scores of each class in the MVTec-AD, which have not been listed in detail in Sec. 4.2, are reported in Tab. <ref type="bibr">8.</ref> Here, N-pad reported the best performance in terms of PRO score for 11 out of 15 classes of MVTec-AD. Specifically, previous models reported higher scores only for carpet, grid, screw, and zipper. Thus, we may suggest that the proposed model has been developed with superior performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Visual result</head><p>We present pixel-wise anomaly maps of several anomalous images for all classes in MVTec-AD that were computed by PaDiM, PatchCore and N-pad in Figs. 4 to 6. Herein, pixel-wise anomaly maps were visualized by normalizing the anomaly scores from 20% to 80% to eliminate relatively nominal pixels and emphasize the anomalous regions. The results are as follows:     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Overall model architecture. Two nominal distributions are estimated by applying the similarity between the target pixel and its neighboring pixels as weights (A) and by aggregating features of its neighborhood (B). Also, the k-means centroids of the aggregated features are identified as a set of representative nominal features for image-level detection (B). Next, the pixel-wise anomaly map and image-wise anomaly score are computed by Mahalonobis distances between the estimated distributions and test features and Euclidean distance between the centroids of train features and test features (C). Lastly, a shifting technique is applied to enhance the predictive performance (D).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>(a) AUROC comparison of different neighborhood sizes (p) for estimating distribution (b) AUROC comparison of different neighborhood sizes (q) for inference (c) AUROC comparison of different image shift sizes (r) (d) AUROC comparison of different dimension reduction (e) AUROC comparison of different backbones Verification of parameter efficiency with various sizes and backbones.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) Image-wise AUROC comparison of different models.(b) Pixel-wise AUROC comparison of different models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Few shot anomaly detection performance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Visualization anomalies from top to bottom: bottle, cable, capsule, carpet, and grid.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Visualization anomalies from top to bottom: hazelnut, leather, metalnut, pill, and screw.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Visualization anomalies from top to bottom: tile, toothbrush, transistor, wood and zipper.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Table 2. PRO-score of different approaches on the MVTec-AD dataset error for image-level detection is 37% compared to the pretrained feature-based model of PatchCore. Moreover, the proposed model achieves state-of-the-art performance in pixel-wise AUROC for 12 out of 15 classes with an average AUROC of 98.75 and PRO-score of 95.1 (Tab. 2), reducing the error by 34% and 25%, respectively, compared to the next best performing model.</figDesc><table><row><cell>Method</cell><cell></cell><cell cols="3">Normalizing Flow Based</cell><cell></cell><cell cols="3">Pre-trained Feature Based</cell></row><row><cell>Class/Model</cell><cell cols="2">FastFlow</cell><cell>PEFM</cell><cell cols="4">CFLOW-AD SPADE PaDiM PatchCore</cell><cell>N-pad</cell></row><row><cell>Bottle</cell><cell cols="2">100/98.10</cell><cell>100/98.11</cell><cell>100/98.14</cell><cell>-/98.4</cell><cell>-/98.3</cell><cell>100/98.6</cell><cell>100/98.91</cell></row><row><cell>Cable</cell><cell cols="3">97.58/96.98 98.95/96.58</cell><cell>97.41/96.70</cell><cell>-/97.2</cell><cell>-/96.7</cell><cell>99.4/98.5</cell><cell>99.54/98.88</cell></row><row><cell>Capsule</cell><cell cols="3">98.52/98.84 91.90/97.94</cell><cell>97.69/98.64</cell><cell>-/99.0</cell><cell>-/98.5</cell><cell>97.8/98.9</cell><cell>99.40/98.96</cell></row><row><cell>Carpet</cell><cell cols="2">99.15/98.95</cell><cell>100/99.00</cell><cell>99.04/98.99</cell><cell>-/97.5</cell><cell>-/99.1</cell><cell>98.7/99.1</cell><cell>99.27/99.03</cell></row><row><cell>Grid</cell><cell cols="3">99.68/99.24 96.57/98.48</cell><cell>96.24/96.76</cell><cell>-/93.7</cell><cell>-/97.3</cell><cell>97.9/98.7</cell><cell>98.67/98.13</cell></row><row><cell>Hazelnut</cell><cell cols="3">97.96/97.62 99.89/98.78</cell><cell>100/98.35</cell><cell>-/99.1</cell><cell>-/98.2</cell><cell>100/98.7</cell><cell>100/99.03</cell></row><row><cell>Leather</cell><cell cols="2">100/99.41</cell><cell>100/99.24</cell><cell>100/99.36</cell><cell>-/97.6</cell><cell>-/99.2</cell><cell>100/99.3</cell><cell>100/99.43</cell></row><row><cell>Metalnut</cell><cell cols="3">99.51/98.36 99.85/96.89</cell><cell>98.92/98.32</cell><cell>-/98.1</cell><cell>-/97.2</cell><cell>100/98.4</cell><cell>100/99.19</cell></row><row><cell>Pill</cell><cell cols="3">98.22/97.64 97.51/96.67</cell><cell>96.92/98.70</cell><cell>-/96.5</cell><cell>-/95.7</cell><cell>96.0/97.6</cell><cell>98.00/99.04</cell></row><row><cell>Screw</cell><cell cols="3">86.34/98.48 96.43/98.93</cell><cell>83.95/97.74</cell><cell>-/98.9</cell><cell>-/98.5</cell><cell>97.0/99.4</cell><cell>97.40/98.80</cell></row><row><cell>Tile</cell><cell cols="2">100/96.45</cell><cell>99.49/95.19</cell><cell>100/97.30</cell><cell>-/87.4</cell><cell>-/94.1</cell><cell>98.9/95.9</cell><cell>100/97.62</cell></row><row><cell cols="4">Toothbrush 89.16/97.87 96.38/98.28</cell><cell>92.78/98.27</cell><cell>-/97.9</cell><cell>-/98.8</cell><cell>99.7/98.7</cell><cell>100/99.00</cell></row><row><cell>Transistor</cell><cell cols="3">98.58/97.07 97.83/96.58</cell><cell>97.38/93.15</cell><cell>-/94.1</cell><cell>-/98.5</cell><cell>100/96.4</cell><cell>99.58/98.55</cell></row><row><cell>Wood</cell><cell cols="3">99.56/96.23 99.19/95.27</cell><cell>99.30/94.80</cell><cell>-/88.5</cell><cell>-/94.9</cell><cell>99.0/95.1</cell><cell>99.56/97.49</cell></row><row><cell>Zipper</cell><cell cols="3">98.55/99.04 98.03/98.29</cell><cell>99.03/98.38</cell><cell>-/96.5</cell><cell>-/98.5</cell><cell>99.5/98.9</cell><cell>99.34/99.16</cell></row><row><cell>Average</cell><cell cols="3">97.52/98.03 98.13/97.61</cell><cell>97.24/97.57</cell><cell>-/96.0</cell><cell>-/97.5</cell><cell>99.0/98.1</cell><cell>99.37/98.75</cell></row><row><cell cols="2">Model</cell><cell cols="7">FastFlow PEFM CFLOW-AD SPADE PaDiM PatchCore N-pad</cell></row><row><cell cols="2">PRO-score</cell><cell>93.0</cell><cell>92.4</cell><cell>91.7</cell><cell>91.7</cell><cell>92.1</cell><cell>93.5</cell><cell>95.1</cell></row><row><cell>Error</cell><cell></cell><cell>7.0</cell><cell>7.6</cell><cell>8.3</cell><cell>8.3</cell><cell>7.9</cell><cell>6.5</cell><cell>4.9</cell></row></table><note>Table 1. Image-and pixel-wise AUROC comparison of various models on MVTec-AD dataset</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Evaluation of the effectiveness of key design components</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Model/Class Bottle Cable Capsu. Carpet Grid Hazel. Leat. Metal. Pill Screw Tile Tooth. Trans. Wood Zip.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Average</cell></row><row><cell>FastFlow</cell><cell>91.9</cell><cell>89.6</cell><cell>92.7</cell><cell>96.3</cell><cell>97.4</cell><cell>94.5</cell><cell>99.1</cell><cell>93.4</cell><cell>92.4</cell><cell>92.6</cell><cell>89.1</cell><cell>83.6</cell><cell>91.7</cell><cell>93.0</cell><cell>96.7</cell><cell>93.0</cell></row><row><cell>CFLOW</cell><cell>93.2</cell><cell>92.6</cell><cell>93.9</cell><cell>95.3</cell><cell>89.5</cell><cell>95.3</cell><cell>98.5</cell><cell>90.2</cell><cell>94.4</cell><cell>91.7</cell><cell>86.8</cell><cell>85.7</cell><cell>84.7</cell><cell>90.4</cell><cell>93.1</cell><cell>91.7</cell></row><row><cell>PEFM</cell><cell>95.4</cell><cell>93.7</cell><cell>93.4</cell><cell>96.3</cell><cell>94.8</cell><cell>95.5</cell><cell>98.3</cell><cell>93.1</cell><cell>95.2</cell><cell>94.7</cell><cell>81.5</cell><cell>89.0</cell><cell>79.9</cell><cell>90.3</cell><cell>95.1</cell><cell>92.4</cell></row><row><cell>SPADE</cell><cell>95.5</cell><cell>90.9</cell><cell>93.7</cell><cell>94.7</cell><cell>86.7</cell><cell>95.4</cell><cell>97.2</cell><cell>94.4</cell><cell>94.6</cell><cell>96.0</cell><cell>75.6</cell><cell>93.5</cell><cell>87.4</cell><cell>87.4</cell><cell>92.6</cell><cell>91.7</cell></row><row><cell>PaDIM</cell><cell>94.8</cell><cell>88.8</cell><cell>93.5</cell><cell>96.2</cell><cell>94.6</cell><cell>92.6</cell><cell>97.8</cell><cell>85.6</cell><cell>92.7</cell><cell>94.4</cell><cell>86.0</cell><cell>93.1</cell><cell>84.5</cell><cell>91.1</cell><cell>95.9</cell><cell>92.1</cell></row><row><cell>PatchCore</cell><cell>96.1</cell><cell>92.6</cell><cell>95.5</cell><cell>96.6</cell><cell>95.9</cell><cell>93.9</cell><cell>98.9</cell><cell>91.3</cell><cell>94.1</cell><cell>97.9</cell><cell>87.4</cell><cell>91.4</cell><cell>83.5</cell><cell>89.6</cell><cell>97.1</cell><cell>93.5</cell></row><row><cell>N-pad</cell><cell>96.3</cell><cell>97.2</cell><cell>95.7</cell><cell>95.6</cell><cell>94.2</cell><cell>95.6</cell><cell>97.2</cell><cell>95.1</cell><cell>97.1</cell><cell>94.9</cell><cell>89.8</cell><cell>93.7</cell><cell>94.5</cell><cell>93.4</cell><cell>97.1</cell><cell>95.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 .</head><label>8</label><figDesc></figDesc><table /><note>PRO Score comparison of various models on MVTec-AD dataset</note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Evalution on MTD dataset</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Geometric approximation via coresets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pankaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Har-Peled</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kasturi R Varadarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorial and computational geometry</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ganomaly: Semi-supervised anomaly detection via adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samet</forename><surname>Akcay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Atapour-Abarghouei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toby</forename><forename type="middle">P</forename><surname>Breckon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="622" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liron</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yedid</forename><surname>Hoshen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.10445</idno>
		<title level="m">Deep nearest neighbor anomaly detection</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Classification-based anomaly detection for general data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liron</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yedid</forename><surname>Hoshen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.02359</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mvtec ad-a comprehensive real-world dataset for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Uninformed students: Student-teacher anomaly detection with discriminative latent embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improving unsupervised defect segmentation by applying structural similarity to autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sindy</forename><surname>L?we</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VISIGRAPP (5: VISAPP)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Sub-image anomaly detection with deep pyramid correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yedid</forename><surname>Hoshen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.02357</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Padim: a patch distribution modeling framework for anomaly detection and localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Defard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><surname>Setkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelique</forename><surname>Loesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romaric</forename><surname>Audigier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="475" to="489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Anomaly detection via reverse distillation from one-class embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqiu</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="9737" to="9746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A theoretically sound upper bound on the triplet loss for improving the efficiency of deep distance metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh-Toan</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toan</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10404" to="10413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A geometric framework for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleazar</forename><surname>Eskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Prerau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Portnoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sal</forename><surname>Stolfo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of data mining in computer security</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="77" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Deep anomaly detection using geometric transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Izhak</forename><surname>Golan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>El-Yaniv</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
	<note>Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Moussa Reda Mansour, Svetha Venkatesh, and Anton van den Hengel. Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingqiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vuong</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Budhaditya</forename><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1705" to="1714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cflow-ad: Real-time unsupervised anomaly detection with localization via conditional normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Gudovskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shun</forename><surname>Ishizaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuki</forename><surname>Kozuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="98" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Surface defect saliency of magnetic tile. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congying</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Yuan</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="85" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Outlier detection with kernel density functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Longin Jan Latecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragoljub</forename><surname>Lazarevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pokrajac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Machine Learning and Data Mining in Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="61" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A simple unified framework for detecting out-of-distribution samples and adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
	<note>Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Cfa: Coupled-hypersphere-based feature adaptation for target-oriented anomaly localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwook</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghyun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byung Cheol</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.04325</idno>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Towards visually explaining variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runze</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikrishna</forename><surname>Karanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bir</forename><surname>Bhanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Octavia</forename><surname>Radke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Camps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8642" to="8651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">On the generalized distance in statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasanta</forename><surname>Chandra Mahalanobis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1936" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Science of India</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ocgan: One-class novelty detection using gans with constrained latent representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pramuditha</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2898" to="2906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generative probabilistic novelty detection with adversarial autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislav</forename><surname>Pidhorskyi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranya</forename><surname>Almohsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Panda: Adapting pretrained features for anomaly detection and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Reiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liron</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yedid</forename><surname>Hoshen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2806" to="2814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Modeling the distribution of normal data in pre-trained deep features for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Rippel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dorit</forename><surname>Merhof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 25th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6726" to="6733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards total recall in industrial anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Latha</forename><surname>Pemula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joaquin</forename><surname>Zepeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="14318" to="14328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Same same but differnet: Semi-supervised defect detection with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF winter conference on applications of computer vision</title>
		<meeting>the IEEE/CVF winter conference on applications of computer vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1907" to="1916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep one-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nico</forename><surname>Goernitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Shoaib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kloft</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4393" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep semi-supervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nico</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>G?rnitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adversarially learned one-class classifier for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Khalooei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmood</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3379" to="3388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Anomaly detection using autoencoders with nonlinear dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayu</forename><surname>Sakurada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takehisa</forename><surname>Yairi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the MLSDA 2014 2nd workshop on machine learning for sensory data analysis</title>
		<meeting>the MLSDA 2014 2nd workshop on machine learning for sensory data analysis</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Unsupervised anomaly detection with generative adversarial networks to guide marker discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Schlegl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Seeb?ck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ursula</forename><surname>Sebastian M Waldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Schmidt-Erfurth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Langs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on information processing in medical imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="146" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning and evaluating representations for deep one-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsung</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minho</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Csi: Novelty detection via contrastive learning on distributionally shifted instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihoon</forename><surname>Tack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangwoo</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongheon</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="11839" to="11852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-scale patch-based representation learning for image anomaly detection and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Chia</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shang-Hong</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="3992" to="4000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Attention guided anomaly localization in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashanka</forename><surname>Venkataramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuan-Chuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rajat Vikram Singh, and Abhijit Mahalanobis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="485" to="503" />
		</imprint>
	</monogr>
	<note>European Conference on Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Position encoding enhanced feature mapping for image anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cao</forename><surname>Yunkang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Weiming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Li</surname></persName>
		</author>
		<idno>2022. 2</idno>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE 18th International Conference on Automation Science and Engineering</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Centroid-based deep metric learning for speaker recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Rudzicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brudno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3652" to="3656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Patch svdd: Patch-level svdd for anomaly detection and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihun</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asian Conference on Computer Vision</title>
		<meeting>the Asian Conference on Computer Vision</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Fastflow: Unsupervised anomaly detection and localization via 2d normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.07677</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">In defense of the triplet loss again: Learning robust person re-identification with fast approximated triplet loss and label distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="354" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep autoencoding gaussian mixture model for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Martin Renqiang Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daeki</forename><surname>Lumezanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on learning representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
