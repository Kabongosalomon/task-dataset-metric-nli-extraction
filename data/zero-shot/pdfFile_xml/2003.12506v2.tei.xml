<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hybrid Models for Open Set Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongjie</forename><surname>Zhang</surname></persName>
							<email>hjzhang@smail.nju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ang</forename><surname>Li</surname></persName>
							<email>anglili@google.com</email>
							<affiliation key="aff1">
								<orgName type="department">DeepMind, Mountain View</orgName>
								<address>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwen</forename><surname>Guo</surname></persName>
							<email>ywguo@nju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Hybrid Models for Open Set Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Flow-based model</term>
					<term>density estimation</term>
					<term>image classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Open set recognition requires a classifier to detect samples not belonging to any of the classes in its training set. Existing methods fit a probability distribution to the training samples on their embedding space and detect outliers according to this distribution. The embedding space is often obtained from a discriminative classifier. However, such discriminative representation focuses only on known classes, which may not be critical for distinguishing the unknown classes. We argue that the representation space should be jointly learned from the inlier classifier and the density estimator (served as an outlier detector). We propose the OpenHybrid framework, which is composed of an encoder to encode the input data into a joint embedding space, a classifier to classify samples to inlier classes, and a flow-based density estimator to detect whether a sample belongs to the unknown category. A typical problem of existing flow-based models is that they may assign a higher likelihood to outliers. However, we empirically observe that such an issue does not occur in our experiments when learning a joint representation for discriminative and generative components. Experiments on standard open set benchmarks also reveal that an end-to-end trained OpenHybrid model significantly outperforms state-of-the-art methods and flow-based baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Image classification is a core problem in computer vision. However, most of the existing research is based on the closed-set assumption, i.e., training set is assumed to cover all classes that appear in the test set. This is an unrealistic assumption. Even with a large-scale image dataset, such as ImageNet <ref type="bibr" target="#b14">[15]</ref>, it is impossible to cover all scenarios in the real world. When a closed-set model encounters an out-of-distribution sample, it is forced to identify it as a known class, which can cause issues in many real-world applications. We instead study the "open-set" problem where the test set is assumed to contain both known and unknown classes. So the model has to classify samples into either known (inlier) classes or the unknown (outlier) category. <ref type="figure" target="#fig_0">Figure 1</ref>   Identifying unknown samples is naturally challenging because they are not observed during training. Existing approaches fit a probability distribution of the training samples at their embedding space, and detect unknown samples according to such distribution. Since the feature representation of unknown classes is unknown, most of the methods operate on a discriminative feature space obtained from a supervised classifier trained on known classes. A thresholding on this probability distribution is then used to detect samples from unknown classes. A common approach along this direction is to threshold on SoftMax responses, but <ref type="bibr" target="#b1">[2]</ref> has conducted experiments to show that it reachs only sub-optimal solutions to open set recognition. Some variants have been proposed to better utilize the SoftMax scores <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b32">33]</ref>. These methods modify the SoftMax scores to perform both unknown detection while maintaining its classification accuracy. It is extremely challenging to find a single score measure on the SoftMax layer, that can perform well on both the generative and discriminative tasks. We believe the discriminative feature space learned by classification of inlier classes may not be sufficiently effective for identifying outlier classes. So we propose to employ a flow-based generative model for outlier detection, and learn a joint feature space in an end-to-end manner from both the classifier and the density estimator.</p><p>Flow-based models have recently emerged <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">13]</ref>, allowing a neural network to be invertible. They can fit a probability distribution to training samples in an unsupervised manner via maximum likelihood estimation. The flow models can predict the probability density of each example. When the probability density of an input sample is large, it is likely to be part of the training distribution (known classes). And the outlier samples (unknown class) usually have a small probability density value. The advantage of flow-based models is that they do not require the intervention of a classifier when fitting a probability dis-tribution, and one can directly apply a thresholding model on these probability values without modifying the scores of any known classes.</p><p>Flow-based models have been adopted to solve out-of-distribution detection <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b9">10]</ref>, but have not yet been considered the open set recognition problem. Most related to our approach, <ref type="bibr" target="#b19">[20]</ref> proposed a deep invertible generalized linear model (DIGLM), which is comprised of a generalized linear model (GLM) stacked on top of flow-based model. They use the model's natural rejection rule based on the probability generated by flow-based model to detect unknown inputs, and directly classify known samples with the features used to fit the probability distribution. Our work differs in that instead of adding a classifier on top of flow model's embedding, we propose to learn a joint embedding for both the flow model and the classifier. Our insight is that the embedding space learned from only flow-based model may not have sufficient discriminative expressiveness.</p><p>We empirically observe in our experiments that learning a joint embedding space resolves a common issue in flow-based model that the flow-based model may assign higher likelihood to OOD inputs (mentioned in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b18">19]</ref>). This issue was considered in <ref type="bibr" target="#b11">[12]</ref>, the underlying factor of which is believed to be to the inconsistency between a uni-modal prior distribution and a multi-modal data distribution. In our framework, the deep network can well represent the multi-modal distribution of the input data, which is probably the reason for the improved performance of flow models.</p><p>We perform extensive experiments on various benchmarks including MNIST, SVHN, CIFAR10 and TinyImageNet. The proposed OpenHybrid model outperforms both state-of-the-art methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b36">37]</ref> and hybrid model baselines <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b9">10]</ref> in these benchmarks. We further compare our method with an additional baseline which uses a pre-trained encoder and the result suggests the importance of jointly training both the classifier and the flow-based model.</p><p>Contribution. The contribution of this paper can be summarized as follows:</p><p>1. To the best of our knowledge, we are the first to incorporate a generative flowbased model with a discriminative classifier to address open set recognition, while most of the existing open set approaches focus on either using the softmax logits or adversarial training. 2. We propose the OpenHybrid model that learns a joint representation between the classifier and flow density estimator. Our approach ensures that the inlier classification is unaffected by outlier detection. We find joint training an important contributing factor, according to the ablation study. 3. A known issue of flow-based models is that they may assign higher likelihood to unknown inputs. However, we do not observe such phenomenon in Open-Hybrid, possibly because our encoder fits the multi-modal input distribution to a latent space suitable to the unimodal assumption of flow models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">We conducted extensive experiments on various open set image classifica-</head><p>tion datasets and compared our approach against state-of-the-art open set methods and flow-based baseline models. Our approach achieves significant improvement over these baseline methods.</p><p>2 Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Open Set Recognition</head><p>Open set recognition has been surprisingly overlooked, though it has more practical value than the common closed set setting. Existing methods on this topic can be broadly classified into two categories: discriminative and generative models.</p><p>Discriminative methods. Before the deep learning era, most of the approaches <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b37">38]</ref> are based on traditional classification models such as Support Vector Machines (SVMs), Nearest Neighbors, Sparse Representation, etc. These methods usually do not scale well without careful feature engineering.Recently, deep learning based models have shown more appealing results. The first among them is probably <ref type="bibr" target="#b1">[2]</ref>, which introduced Weibull-based calibration to augment the SoftMax layer of a deep network, called OpenMax. Since then, the Open-Max is further developed in <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b6">7]</ref>. <ref type="bibr" target="#b36">[37]</ref> presented the classification-reconstruction learning algorithm for open set recognition (CROSR), which utilizes latent representations for reconstruction and enables robust unknown detection without harming the known classification accuracy. <ref type="bibr" target="#b23">[24]</ref> proposed the C2AE model for open set recognition, using class conditioned auto-encoders with novel training and testing methodology. Open set recognition principles have been applied to text classification <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b32">33]</ref>, and semantic segmentation <ref type="bibr" target="#b2">[3]</ref>.</p><p>Generative methods. Unlike discriminative models, generative approaches generate unknown samples based on Generative Adversarial Network (GAN) <ref type="bibr" target="#b8">[9]</ref> to help the classifier learn decision boundary between known and unknown samples. <ref type="bibr" target="#b6">[7]</ref> proposed the Generative OpenMax (G-OpenMax) algorithm, which uses a conditional GAN to synthesize mixtures of known classes and finetune the closed-set classification model. G-OpenMax improves the performance of both SoftMax and OpenMax based deep network. Although G-OpenMax effectively detects unknowns in monochrome digit datasets, it fails to produce significant performance improvement on natural images. Different from G-OpenMax, <ref type="bibr" target="#b21">[22]</ref> introduced a novel dataset augmentation technique, called counterfactual image generation (OSRCI). OSRCI adopts an encoder-decoder GAN architecture to generate the synthetic open set examples which are close to knowns. They further reformulated the open set problem as classification with one additional class containing those newly generated samples. GAN-based methods also have been used to solve open set domain adaptation problem recently <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b28">29]</ref>.</p><formula xml:id="formula_0">Out-of-distribution detection.</formula><p>The open set recognition is naturally related to some other problem settings such as out-of-distribution detection <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b17">18]</ref>, outlier detection <ref type="bibr" target="#b27">[28]</ref>, and novelty detection <ref type="bibr" target="#b24">[25]</ref>, etc. They can be incorporated in the concept of open set classification as an unknown detector. However, they do not require open-set classifiers because those models does not have discriminative power within known classes. We focus in this paper on the broader open set recognition problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Flow-Based Methods</head><p>Flow-Based (also called invertible) models have shown promises in density estimation. The original representative models are NICE <ref type="bibr" target="#b4">[5]</ref>, RealNVP <ref type="bibr" target="#b5">[6]</ref> and Glow <ref type="bibr" target="#b12">[13]</ref>. The design ideas of these flow-based models are similar. Through the ingenious design, the inverse transformation of each layer of the model is relatively simple, and the Jacobian matrix is a triangular matrix, so the Jacobian determinant is easy to be calculated. Such models are elegant in theory, but there exists an issue in practice, i.e., the nonlinear transformation ability of each layer becomes weak. Apart from these flow-based models, <ref type="bibr" target="#b0">[1]</ref> proposed an Invertible Residual Network (I-ResNet), which adds some constraints to the ordinary ResNet structure to make the model invertible. The I-ResNet model still retains the basic structure of a ResNet and most of its original fitting ability. So previous experience in ResNet design can basically be re-used. Unfortunately, the density evaluation requires computing an infinite series. The choice of a fixed truncation estimator used by <ref type="bibr" target="#b0">[1]</ref> leads to substantial bias which is tightly coupled with the expressiveness of the network. It cannot be used to perform maximum likelihood because the bias is introduced in the objective and gradients. <ref type="bibr" target="#b3">[4]</ref> improved I-ResNet, and introduced the Residual Flows, a flow-based generative model that produces an unbiased estimate of the log density. Residual Flows allows memory-efficient backpropagation through the log density computation. This allows model to use expressive architectures and train via maximum likelihood in many tasks, such as classification, density estimation and generation, etc. Our work differs from existing flow-based models in that we explicitly address a broader open-set problem, where the flow model is a sub-component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Flow-Based Methods for Out-of-Distribution Detection</head><p>Flow based models have been applied to out-of-distribution (OOD) detection, which is relevant to open set problem. Nalisnick et al. <ref type="bibr" target="#b19">[20]</ref> presented a neural hybrid model created by combining deep invertible features and GLMs to filter out-of-distribution (OOD) inputs, using the model's natural "reject" rule based on the density estimation of the flow-based component. However, this rejection rule is not guaranteed to work in all settings. The main reason is that deep generative models can assign higher likelihood to OOD inputs. Nalisnick et al. <ref type="bibr" target="#b18">[19]</ref> find that the density learned by flow-based models cannot distinguish images of common objects such as dogs, trucks, and horses (i.e. CIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher likelihood to the latter when the model is trained on the former. <ref type="bibr" target="#b25">[26]</ref> also observed that likelihood learned from deep generative models can be confounded by background statistics (e.g. OOD input with the same background but different semantic component). <ref type="bibr" target="#b9">[10]</ref> proposed a simple technique that uses out-of-distribution samples to teach a network heuristics to detect out-of-distribution examples, namely Outlier Exposure (OE). But this improvement is limited and sensitive to the selection of OE dataset. <ref type="bibr" target="#b11">[12]</ref> showed that a factor underlying this phenomenon is a mismatch between the nature of the prior distribution and that of the data distribution.</p><p>... , images are mapped into a latent feature space by the encoder, then the encoded features are fed into two branches for learning: One is typical classification learning with a classifier via cross entropy loss, and the other is density estimation with a flowbased model via its log likelihood. The whole architecture is trained in an end-to-end manner. In testing phase (right), the log p(x) of each image is computed and then compared with the lowest log p(x) taken over the training set. If it is greater than the threshold ? , it is sent to the classifier to identify its specific known class, otherwise it is rejected as an unknown sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Flow-based Model Encoder</head><p>They proposed the use of a mixture distribution as a prior to make likelihoods assigned by deep generative models sensitive to out-of-distribution inputs. <ref type="bibr" target="#b20">[21]</ref> explained the phenomenon through typicality and proposed a typicality test based on batches of inputs which solves many of the failure modes. While we also follow the same hybrid modeling direction, our work differs from <ref type="bibr" target="#b19">[20]</ref> in that we choose to share a common visual representation for both the classifier and the flow model and <ref type="bibr" target="#b19">[20]</ref> uses the output of the flow model as the input to the classifier. It is observed from our experiments that the proposed representation sharing approach is effective in our setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head><p>We start this section by defining the open set problem and introducing the notations. Following this is an overview of our proposed approach which we call "OpenHybrid". After an explanation to details of each module, we introduce how to achieve open set recognition using OpenHybrid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Statement and Notation</head><p>For open set recognition, given a labeled training set of instances X ? R m?n and their corresponding labels y ? {1, . . . , k} n where k is the number of known classes, n is the total number of instances and m is the dimension of each instance, we learn a model f : X ? {1, . . . , k + 1} n such that the model accurately classify an unseen instance (in test set, not in X) to one of the k classes or an unknown class (or the "none of the above" class) indexed using k + 1. <ref type="figure">Figure 2</ref> overviews the training and testing procedures for the proposed method. The OpenHybrid framework consists of three modules: an encoder F for learning latent representations with parameters ? f , a classifier C for classifying known classes with parameters ? c , and a flow-based module D for density estimation with parameters ? d . Existing flow-based models and their hybrid variants, which directly feed as input the original image data into the flow-based model for density estimation. Different from these works, our OpenHybrid framework directly uses the latent representation (the output of encoder F) as the input to the flow model D. The reason for this is that density estimation directly on the original image is susceptible to the population level background statistics (e.g., in MNIST, the background pixels that account for most of the image are similar), which makes it hard to detect unknown samples via exact marginal likelihood. Even in some settings with different backgrounds, unknown samples are assigned higher likelihoods than known samples, and this behavior still exists and has not been explained so far. We propose to estimate the density of latent representations instead of the original input. We find our method to be effective in all of our experimental benchmarks and we do not observe the "higher outlier likelihood" issue using such framework. For classification, the classifier C is directly connected to the output of the encoder F instead of the output of the invertible transformation D. We choose to remove the dependency of the classifier on the flow model because we believe the output of the invertible transform loses the discriminative power. We find this approach allows both the detection of unknown classes and the classification of known classes are effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Overview</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>We define the training loss function in this section.</p><p>Classification Loss. Given images in a batch {X 1 , X 2 , . . . , X N } and their corresponding labels {y 1 , y 2 , . . . , y N }. Here N is the batch size and ?y i ? {1, 2, . . . , k}. Encoder F and classifier C are trained using the following cross entropy loss.</p><formula xml:id="formula_1">L C ({? f , ? c }) = ? 1 N N i=1 k j=1 I yi (j) log p(y j |x i ; ? f , ? c )<label>(1)</label></formula><p>where I yi is an indicator function for label y i , and p(y j |x i ; ? f , ? c ) is the probability of the j th class from the probability score vector predicted by C(F(x i )).</p><p>Density Estimation Loss. For unknown detection, unlike general open set methods, flow-based models directly fit the distribution of the training set, and compute the probability p(x i ; ? d ) of each training sample from the training distribution (also can be treated as the distribution of known classes) through the maximum likelihood estimation. Then, they use the model's natural reject rule based on p(x i ; ? d ) to filter unknown inputs. Although this is intuitively feasible, there are still problems as mentioned above. We suspect the problems come from the difficulty of flow models representing the original input space. So we instead estimate the density of learned latent representations F(x i ). Flow-based model are the first key building block in our approach. These are simply high-capacity, bijective transformations with a tractable Jacobian matrix and inverse. The bijective nature of these transforms is crucial as it allows us to employ the change-of-variables formula for exact density evaluation:</p><formula xml:id="formula_2">log p(x i ; ? f , ? d ) = log p(F(x i ; ? f ); ? d ) = log p(D(F(x i ; ? f ); ? d )) + log det ?D(F(x i ; ? f ); ? d ) ?F(x i ; ? f ) .<label>(2)</label></formula><p>Please note here we slightly abuse the notation for simplicity since the output of the flow model is not exactly the density of input x but instead the density of its latent embedding F(x; ? f ). A simple base distribution such as a standard normal distribution is often used for p(D(F(x i ; ? f ); ? d )). Tractable evaluation of Equation 2 allows flow-based models to be trained using the maximum likelihood with the loss function:</p><formula xml:id="formula_3">L D ({? f , ? d }) = ? 1 N N i=1 log p(x i ; ? f , ? d ) .<label>(3)</label></formula><p>In training, we map the loss L D ({? f , ? d }) to bits per dimension results by normalizing the loss by the dimensionality of the flow input. In our OpenHybrid framework, there are multiple choices for the flow-based module. Considering the stability of the density estimation, we use a tractable unbiased estimate of the log density, called residual flow <ref type="bibr" target="#b3">[4]</ref>.</p><p>Full Loss. The complete loss function of our method is:</p><formula xml:id="formula_4">L({? f , ? c , ? d }) = L C ({? f , ? c }) + ?L D ({? f , ? d })<label>(4)</label></formula><p>where ? is a scaling factor on the contribution of p(x). In all of our experiments in this paper, we empirically set it to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Inference</head><p>Outlier Threshold. At test time, we use the probability density estimated by flow-based module to detect unknown samples from probability distributions. This value corresponds to the probability of a sample being generated from the distribution of the training classes (known classes). Theoretically, the minimum boundary of this probability distribution in the training set is the maximum value of the outlier threshold. We assume that the known samples of the training set and the test set are from the same domain, then the outlier threshold is calculated as ? = min xi?X log p(x i ; ? f , ? d ) + s, where s is a free parameter providing slack in the margin. We estimate the outlier threshold using training samples without data augmentation.</p><p>Open Set Recognition. Open set recognition is a classification over k + 1 class labels, where the first k labels are from the known classes the classifier C is trained on, and the k + 1-st label represents the unknown class that signifies that an instance does not belong to any of the known classes. This is performed using the outlier threshold ? and the score estimated in Equation 2. The outlier threshold is first calculated on training data. If the estimated probability is smaller than outlier threshold, the test instance is classified as k + 1, which in our case corresponds to the unknown class, otherwise the appropriate class label is assigned to the instance from among the known classes. More formally, the prediction of a sample x is define as</p><formula xml:id="formula_5">pred(x) = k + 1, D(F(x i ; ? f ); ? d ) &lt; ?, arg max j?{1,...,k} p(y j |x; ? f , ? c ), otherwise .<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate our OpenHybrid framework and compare it with the state-of-theart non-flow-based and flow-based open set methods. We follow other methods' protocols for fair comparisons. That is, we compare with non-flow-based open set methods without considering operating threshold while we set an unified threshold value during the comparison with flow-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Setups</head><p>Implementation. In our experiments, the encoder, decoder, and classifier architectures are similar to those used in <ref type="bibr" target="#b21">[22]</ref>. The last layer of encoder in <ref type="bibr" target="#b21">[22]</ref> maps 512d to 100d. We moved this layer in our model to the classifier since we do not want the input dimension of flow model to be too small. So the output of our encoder is 512d instead. For flow-based model, we use the standard setup of passing the data through a logit transform <ref type="bibr" target="#b5">[6]</ref>, followed by 10 residual blocks. We use activation normalization <ref type="bibr" target="#b12">[13]</ref> before and after every residual block. Each residual connection consists of 6 layers (i.e., LipSwish <ref type="bibr" target="#b3">[4]</ref> ? InducedNormLinear ? LipSwish ? InducedNormLinear ? LipSwish ? InducedNormLinear) with hidden dimensions of 256 (the first 6 blocks) and 128 (the next 4 blocks) <ref type="bibr" target="#b19">[20]</ref>. We use the Adam optimizer with a learning rate 0.0001 for the encoder and flow-based module to learn log probability distribution. For training classification, we use the Stochastic Gradient Descent (SGD) with momentum 0.9 and learning rate 0.01 for TinyImageNet data, 0.1 for other data. Gradients are updated alternatively between the flow model and the classifier. The parameter s is empirically set to 80. Another important factor affecting open-set performance is openness of the problem. we define the openness based on the ratio of the numbers of unique classes in training and test sets, i.e., openness = 1 ? k train /k test where k train and k test are the number of classes in the training set and the test set, respectively. In following experiments, we will evaluate performance over multiple openness values depending on different dataset settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets.</head><p>We evaluate open set classification using multiple common benchmarks, such as MNIST <ref type="bibr" target="#b16">[17]</ref>, SVHN <ref type="bibr" target="#b22">[23]</ref>, CIFAR10 <ref type="bibr" target="#b13">[14]</ref>, CIFAR+10, CIFAR+50 and TinyImageNet <ref type="bibr" target="#b15">[16]</ref> datasets. We reuse the data splits provided by <ref type="bibr" target="#b21">[22]</ref>.</p><p>-MNIST, SVHN, CIFAR10 : All three datasets contain 10 categories. MNIST are monochrome images with hand-written digits, and it has 60k 28?28 gray images for training and 10k for testing. SVHN are street view house numbers, consisting of ten digit classes each with between 9981 and 11379 32?32 color images. To validate our method on non-digital images, we apply the CIFAR10 dataset, which has 50k 32?32 natural color images for training and 10k for testing. Each dataset is partitioned at random into 6 known and 4 unknown classes. In these settings, the openness score is fixed to 22.54%. -CIFAR+10, CIFAR+50 : To test the method in a range of greater openness scores, we perform CIFAR+U experiments using CIFAR10 and CIFAR100 <ref type="bibr" target="#b13">[14]</ref>. 4 known classes are sampled from CIFAR10 and U unknown classes are drawn randomly from the more diverse CIFAR100 dataset. Openness scores of CIFAR+10 and CIFAR+50 are 46.54% and 72.78%, respectively. -TinyImageNet: For the larger TinyImagenet dataset, which is a 200-class subset of ImageNet, we randomly sampled 20 classes as known and the remaining classes as unknown. In this setting, the openness score is 68.37%.</p><p>The out-of-distribution (OOD) detection community often evaluates methods on cross-dataset setups <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26]</ref>, such as training on CIFAR10 and testing on CIFAR100. So we perform extra experiments on two such settings between CIFAR10 and CIFAR100 and report results comparable to OOD literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics.</head><p>Open set classification performance can be characterized by F-score or AUROC (Area Under ROC Curve) <ref type="bibr" target="#b7">[8]</ref>. AUROC is commonly reported by both open set recognition and out-of-distribution detection literature. So we mainly use AUROC to compare with existing methods. We adopt F-score in some of our experiments as it also measures the in-distribution classification performance. For both metrics, higher values are better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Comparison with Non-flow-based Methods. We compare OpenHybrid against the following non-flow-based baselines:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">SoftMax : A standard confidence-based method for open-set recognition by</head><p>using SoftMax score of a predicted class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">OpenMax [2]: This approach augments the baseline classifier with a new</head><p>OpenMax layer replacing the SoftMax at the final layer of the network. 3. G-OpenMax <ref type="bibr" target="#b6">[7]</ref>: A direct extension of OpenMax method, which trains networks with synthesized unknown data by using a Conditional GAN. 4. OSRCI <ref type="bibr" target="#b21">[22]</ref>: An improved version of G-OpenMax work, which uses a specific data augmentation technique called counterfactual image generation to train the classifier for the k + 1-st class.  <ref type="table" target="#tab_2">Table 1</ref> presents the open set recognition performance of our method and non-flow-based baselines on six datasets. Our approach OpenHybrid outperforms all of the baseline methods, which demonstrates the effectiveness of our approach. It is interesting to note that our method on MNIST dataset produces a minor improvement compared to the other methods. The main reason is that the MNIST is relatively simple, and the results of all methods on it are almost saturated. But for other relatively complex databases, our method performs significantly better than the the baseline methods, especially for natural images, such as CIFAR (6% better than the second best) and TinyImageNet (5% better than the second best).</p><p>Comparison with Flow-based Methods. We compare our approach against our implementations of the following flow-based approaches:</p><p>1. DIGLM <ref type="bibr" target="#b19">[20]</ref>: A neural hybrid model consisting of a linear model defined on a set of features computed by a deep invertible transformation. It uses the models natural reject rule based on the generative component p(x) to detect unknown inputs. The threshold is setted as min x?X p(x; ?) ? c, where the minimum is taken over the training set and c is a free parameter providing slack in the margin. 2. OE <ref type="bibr" target="#b9">[10]</ref>: A training method leveraging an auxiliary dataset of unknown samples to improve unknown detection. The framework is the same as DIGLM, except that during training, a margin ranking loss on the log probabilities of training and outlier exposure samples is used to update the flow-based model. In this experiment, we use counterfactual images generated by <ref type="bibr" target="#b21">[22]</ref> from training samples as its outlier exposure dataset. <ref type="table" target="#tab_3">Table 2</ref> shows the AUROC of our method and the flow-based baselines in different datasets. We observe that our method consistently outperforms the baseline methods significantly under all open set benchmarks. The same trend is observed for the f-score metric, e.g., we achieved 0.865 in CIFAR10 while DIGLM achieves only 0.673 and DIGLM+OE achieves 0.701).</p><p>Cross-dataset OOD settings. We further evaluate our approach on two crossdataset settings: training on CIFAR10 and testing on CIFAR100 and vice versa. We compare the AUROC of our method directly with the numbers reported in <ref type="bibr" target="#b9">[10]</ref>. The results suggest that our approach is still competitive in such settings. It is worth noting that training on CIFAR100 and testing on CIFAR10 is a harder task, probably due to the higher number of training classes. Our approach achieves higher gains (+10%) in this setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>The benefit of joint training. We further compare the end-to-end trained OpenHybrid with a different training strategy based on alternative training. The framework is still the same. However, during training, the encoder and classifier are pretrained first on the training data. The flow-based model was then trained separately with both encoder and classifier being frozen. <ref type="table">Table 4</ref> shows a comparison between the two methods using F-score. The slack parameter s is chosen to be 80 for all datasets. We observe that joint training consistently outperforms OpenHybrid with a fixed pretrained encoder.</p><p>A study on the parameters. Our loss function contains a trade-off parameter ?. We varied this value among 0.5, 1 and 2 in the MNIST dataset and observed AUROC scores 0.993, 0.995, and 0.998, respectively. The model seems not sensitive to this variable but it is a parameter that can be tuned to further improve performance. Another important parameter is the number of residual blocks in the flow model. We varied this value among 4, 8, 10 and 16 in CIFAR10 benchmark. Surprisingly, we still observe stable AUROC results (0.945, 0.948, 0.950, 0.958). So, for practitioners who may have resource constraints, it is advised to consider a smaller flow-based network when using the OpenHybrid framework.</p><p>A visualization of the estimated density. <ref type="figure" target="#fig_1">Figure 3 (left)</ref> shows the histograms of log-likelihoods for MNIST (0-5 as known classes and 6-9 as unknown classes) made by DIGLM, OE, OpenHybrid with pretrained encoder and Open-Hybrid with joint training. For DIGLM (a), the three histograms almost overlap so it is impossible to detect the unknown class by setting a threshold. The density estimation is improved with the help of OE (b), however, there is still a large area of overlap. The distribution overlap becomes further smaller but still not ideal when using OpenHybrid with pretrained encoder (c). In contrast, we observed the end-to-end OpenHybrid (d) produces the histogram of unknown samples well separated from those of known samples.</p><p>A visualization of the latent space. <ref type="figure" target="#fig_1">Figure 3</ref>(e) shows a t-SNE <ref type="bibr" target="#b33">[34]</ref> plot of the latent space learned by end-to-end OpenHybrid. The brown color represents the unkonwn classes (digit <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9)</ref> which is well separated from other color (known classes from 0 to 5). Interestingly, the model also learns to separate digits 6-9, which is in an unsupervised fashion. Although the MNIST dataset is simple compared to other real datasets, this result shows the potential of representation learning using hybrid models as a promising research direction.</p><p>A disappeared issue of flow-based models. Nalisnick et al. <ref type="bibr" target="#b18">[19]</ref> raised the issue that the flow-based model trained on CIFAR10 will assign a higher log- likelihood value to SVHN. So we further conduct an experiment on this setting, where we use the full 10 classes of the CIFAR10 as known classes, and the SVHN as an unknown class. Our approach achieves 0.998 AUROC on this setting. <ref type="figure" target="#fig_2">Figure 4</ref> shows the histograms of log-likelihoods under this setting. Similar to the observation made by <ref type="bibr" target="#b18">[19]</ref>, in <ref type="figure" target="#fig_2">Figure 4(a)</ref>, the histogram of unknown samples (green) is shifted more to the right than that of known samples (blue and pink), i.e., unknown samples are assigned a larger log-likelihood value than known samples. In <ref type="figure" target="#fig_2">Figure 4</ref>(b), OE seems to help but it does not fully address the problem as well. Our method is shown in <ref type="figure" target="#fig_2">Figure 4</ref>(c) which clearly distinguish the two distributions. The histogram of unknown samples is almost entirely to the left of known samples. We believe a potential reason is that the original input space is a multimodal distribution and our method projects the input data into a latent space which is probably more suitable to the unimodal assumption of flow-based models. While we are unable to prove this theoretically, we hope our results could inspire future works on deeper understanding of flow-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented the OpenHybrid framework for open set recognition. Our approach is built upon a flow-based model for density estimation and a discriminative classifier, with a shared latent space. Extensive experiments show that our approach achieves the state of the art. A common issue of flow-based models is that they often assign larger likelihood to out-of-distribution samples. We empirically observe on various datasets that this issue disappear by learning a joint feature space. Ablation study also suggests that joint training is another key contributing factor to the superior open set recognition performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>?Fig. 1 .</head><label>1</label><figDesc>Decision boundaries of a closed set classifier (a) and an open set classifier (b). Green symbols indicate known samples (different shapes represent different classes), and orange question marks indicate unknown samples. Dashed lines indicate the decision boundaries. (a) Closed set leads to unbounded decision boundaries of a typical 4-class classifier. Unknown samples are forced to be classified into one of known classes. (b) open set results in bounded decision boundaries for a 5-class classifier, which can classify both known and unknown samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Left: Histograms of log-likelihoods for MNIST (0-5 as known classes and 6-9 as unknown classes) made by (a) DIGLM, (b) DIGLM + OE, (c) OpenHybrid with pretrained encoder and end-to-end OpenHybrid. The blue color indicates training samples, the pink indicates known samples in the test, and the green is unknown samples. Right (e): t-SNE visualization of the latent space by end-to-end OpenHybrid. Different colors represent different classes. Brown color represents the unkown digits (6-9).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Histograms of log-likelihoods for CIFAR10 (known samples) and SVHN (unknown samples) made by (a) DIGLM, (b) DIGLM + OE and (c) the proposed Open-Hybrid. The blue color indicates training samples, the pink indicates known samples in the test, and the green is unknown samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>illustrates the difference of classification decision boundaries under open set and closed set assumptions.</figDesc><table><row><cell cols="2">? ? ? ?</cell><cell>? ?</cell><cell>? ?</cell><cell></cell><cell cols="2">? ?</cell><cell cols="2">? ? ? ?</cell><cell cols="2">? ?</cell><cell>? ?</cell><cell>?</cell><cell>? ?</cell></row><row><cell>? ? ?</cell><cell>?</cell><cell>? ?</cell><cell>?</cell><cell>?</cell><cell>? ?</cell><cell>? ?</cell><cell>? ?</cell><cell>? ?</cell><cell>?</cell><cell>?</cell><cell cols="3">? ? ? ?</cell><cell>? ?</cell></row><row><cell></cell><cell></cell><cell cols="2">(a) Closed set</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) Open set</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>based Model Encoder Classifier logP(x) Test images &gt;? True Known Classes Known Classes False Unknown Class Training Testing</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>L bits_per_dimension</cell><cell></cell></row><row><cell>Training images</cell><cell>logP(x)</cell><cell>...</cell></row><row><cell></cell><cell>Classifier L cross_entropy</cell><cell></cell></row><row><cell cols="3">Fig. 2. Proposed architecture for open set recognition. During the training phase</cell></row><row><cell>(left)</cell><cell></cell><cell></cell></row></table><note>Flow-</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>AUROC for comparisons of our method with recent open set methods. Results averaged over 5 random class partitions. The best results are highlighted in bold.</figDesc><table><row><cell>Method</cell><cell cols="6">MNIST SVHN CIFAR10 CIFAR+10 CIFAR+50 TinyImageNet</cell></row><row><cell>SoftMax</cell><cell>0.978</cell><cell>0.886</cell><cell>0.677</cell><cell>0.816</cell><cell>0.805</cell><cell>0.577</cell></row><row><cell>OpenMax [2]</cell><cell>0.981</cell><cell>0.894</cell><cell>0.695</cell><cell>0.817</cell><cell>0.796</cell><cell>0.576</cell></row><row><cell>G-OpenMax [7]</cell><cell>0.984</cell><cell>0.896</cell><cell>0.675</cell><cell>0.827</cell><cell>0.819</cell><cell>0.580</cell></row><row><cell>OSRCI [22]</cell><cell>0.988</cell><cell>0.910</cell><cell>0.699</cell><cell>0.838</cell><cell>0.827</cell><cell>0.586</cell></row><row><cell>C2AE [24]</cell><cell>0.989</cell><cell>0.922</cell><cell>0.895</cell><cell>0.955</cell><cell>0.937</cell><cell>0.748</cell></row><row><cell>CROSR [37]</cell><cell>0.991</cell><cell>0.899</cell><cell>0.883</cell><cell>0.912</cell><cell>0.905</cell><cell>0.589</cell></row><row><cell>OpenHybrid (ours)</cell><cell>0.995</cell><cell>0.947</cell><cell>0.950</cell><cell>0.962</cell><cell>0.955</cell><cell>0.793</cell></row><row><cell cols="7">5. C2AE [24]: This approach uses class conditioned auto-encoders with novel</cell></row><row><cell cols="6">training and testing methodologies for open set recognition.</cell><cell></cell></row><row><cell cols="7">6. CROSR [37]: A deep open set classifier augmented by latent representation</cell></row><row><cell cols="6">learning which jointly classifies and reconstructs the input data.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>AUROC for our methods and flow-based baselines. Results are averaged over 5 random class partitions. The best results are highlighted in bold.</figDesc><table><row><cell>Method</cell><cell cols="7">MNIST SVHN CIFAR10 CIFAR+10 CIFAR+50 TinyImageNet</cell></row><row><cell>DIGLM</cell><cell>0.643</cell><cell>0.559</cell><cell>0.583</cell><cell>0.590</cell><cell>0.594</cell><cell></cell><cell>0.520</cell></row><row><cell>DIGLM + OE</cell><cell>0.721</cell><cell>0.643</cell><cell>0.655</cell><cell>0.670</cell><cell>0.671</cell><cell></cell><cell>0.596</cell></row><row><cell>OpenHybrid (ours)</cell><cell>0.995</cell><cell>0.947</cell><cell>0.950</cell><cell>0.962</cell><cell>0.955</cell><cell></cell><cell>0.793</cell></row><row><cell cols="4">Table 3. AUROC for cross-dataset</cell><cell cols="4">Table 4. F-scores 4 of the proposed</cell></row><row><cell cols="4">out-of-distribution detection between</cell><cell cols="4">OpenHybrid models using pretrained</cell></row><row><cell cols="3">CIFAR-10 and CIFAR-100.</cell><cell></cell><cell cols="3">encoder and joint training.</cell></row><row><cell cols="2">Train ? Test (OOD)</cell><cell>OE [10]</cell><cell>Ours</cell><cell>Method</cell><cell cols="3">MNIST SVHN CIFAR10</cell></row><row><cell cols="2">CIFAR10 ? CIFAR100</cell><cell>0.933</cell><cell>0.951</cell><cell cols="2">Pretrained encoder 0.847</cell><cell>0.842</cell><cell>0.791</cell></row><row><cell cols="2">CIFAR100 ? CIFAR10</cell><cell>0.757</cell><cell>0.856</cell><cell>Joint training</cell><cell cols="2">0.942 0.912</cell><cell>0.865</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">For readers who are interested in classification accuracy: Our approach achieves overall accuracy 0.947 in MNIST, 0.929 in SVHN and 0.868 in CIFAR10. However, we believe F-score is a better measurement which considers data imbalance.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgement. We would like to thank Balaji Lakshminarayanan and Olaf Ronneberger for meaningful discussions. This research was supported by the National Science Foundation of China under Grants 61772257 and the Fundamental Research Funds for the Central Universities 020914380080.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Jacobsen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.00995</idno>
		<title level="m">Invertible residual networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards open set deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1563" to="1572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Simultaneous semantic segmentation and outlier detection in presence of domain shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bevandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kreo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Egvi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Residual flows for invertible generative modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Jacobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9913" to="9923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Nice: Non-linear independent components estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.08803</idno>
		<title level="m">Density estimation using real nvp</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Generative openmax for multi-class open set classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Demyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnavi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07418</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.08581</idno>
		<title level="m">Recent advances in open set recognition: A survey</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.04606</idno>
		<title level="m">Deep anomaly detection with outlier exposure</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Nearest neighbors distance ratio open-set classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R M</forename><surname>J?nior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D O</forename><surname>Werneck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Pazinato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>De Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename><surname>Penatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D S</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="359" to="386" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Likelihood assignment for out-of-distribution inputs in deep generative models is sensitive to prior distribution choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kamoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kobayashi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.06515</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<title level="m">Glow: Generative flow with invertible 1x1 convolutions</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10215" to="10224" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Learning multiple layers of features from tiny images</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tiny imagenet visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CS</title>
		<imprint>
			<biblScope unit="volume">231</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<title level="m">Mnist handwritten digit database</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Training confidence-calibrated classifiers for detecting out-of-distribution samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matsukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gorur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.09136</idno>
		<title level="m">Do deep generative models know what they don&apos;t know</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matsukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gorur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.02767</idno>
		<title level="m">Hybrid models with deep and invertible features</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Detecting outof-distribution inputs to deep generative models using typicality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matsukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02994</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Open set learning with counterfactual images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="613" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<title level="m">Reading digits in natural images with unsupervised feature learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">C2ae: Class conditioned auto-encoder for open-set recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Oza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2307" to="2316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Ocgan: One-class novelty detection using gans with constrained latent representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2898" to="2906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Likelihood ratios for out-of-distribution detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fertig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Poplin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Depristo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14680" to="14691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>G?nther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.01697</idno>
		<title level="m">Adversarial robustness: Softmax versus openmax</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep one-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goernitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4393" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Open set domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="153" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Probability models for open set recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Scheirer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="2317" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Support vector method for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="582" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Input complexity and out-of-distribution detection with likelihood-based generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Serr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gmez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Slizovskaia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luque</surname></persName>
		</author>
		<idno>abs/1909.11480</idno>
		<ptr target="http://dblp.uni-trier.de/db/journals/corr/corr1909.html#abs-1909-11480" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.08716</idno>
		<title level="m">Doc: Deep open classification of text documents</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Accelerating t-sne using tree-based algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">32213245</biblScope>
			<date type="published" when="2014-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Open Set Text Classification Using Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Venkataram</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>University of Colorado Colorado Springs. Kraemer Family Library</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Out-of-distribution detection in classifiers via generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vernekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaurav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Abdelzad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Denouden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Czarnecki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.04241</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Classification-reconstruction learning for open-set recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yoshihashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Naemura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4016" to="4025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Sparse representation-based open set recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1690" to="1696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Improving open set domain adaptation using image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1258" to="1263" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
