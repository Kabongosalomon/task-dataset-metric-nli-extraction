<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Forecasting directional movements of stock prices for intraday trading using LSTM and random forests</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-06">Jun 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpendu</forename><surname>Ghosh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Information Systems</orgName>
								<orgName type="institution">BITS Pilani K.K.Birla Goa campus</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Neufeld</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Division of Mathematical Sciences</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jajati</forename><forename type="middle">Keshari</forename><surname>Sahoo</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">BITS Pilani K.K.Birla Goa campus</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Forecasting directional movements of stock prices for intraday trading using LSTM and random forests</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-06">Jun 2021</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Random forest</term>
					<term>LSTM</term>
					<term>Forecasting</term>
					<term>Statistical Arbitrage</term>
					<term>Machine learning</term>
					<term>Intraday trading</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We employ both random forests and LSTM networks (more precisely CuDNNLSTM) as training methodologies to analyze their effectiveness in forecasting out-of-sample directional movements of constituent stocks of the S&amp;P 500 from January 1993 till December 2018 for intraday trading. We introduce a multi-feature setting consisting not only of the returns with respect to the closing prices, but also with respect to the opening prices and intraday returns. As trading strategy, we use Krauss et al. <ref type="formula">(2017)</ref> and Fischer &amp; Krauss (2018) as benchmark. On each trading day, we buy the 10 stocks with the highest probability and sell short the 10 stocks with the lowest probability to outperform the market in terms of intraday returns -all with equal monetary weight. Our empirical results show that the multi-feature setting provides a daily return, prior to transaction costs, of 0.64% using LSTM networks, and 0.54% using random forests. Hence we outperform the single-feature setting in <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> and <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> consisting only of the daily returns with respect to the closing prices, having corresponding daily returns of 0.41% and of 0.39% with respect to LSTM and random forests, respectively. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the last decade, machine learning methods have exhibited distinguished development in financial time series prediction. <ref type="bibr" target="#b9">Huck (2009)</ref> and <ref type="bibr" target="#b10">Huck (2010)</ref> construct statistical arbitrage strategies using Elman neural networks and a multi-criteria-decision method. <ref type="bibr" target="#b24">Takeuchi &amp; Lee (2013)</ref> evolve a momentum trading strategy. <ref type="bibr" target="#b15">Papaioannou et al. (2017)</ref> develop a trend following trading strategy to forecast and trade S&amp;P 500 futures contracts. <ref type="bibr" target="#b25">Tran et al. (2018)</ref>, <ref type="bibr" target="#b20">Sezer &amp; Ozbayoglu (2018)</ref>, and Singh et al.</p><p>(2020) use neural networks for predicting time series data, whereas <ref type="bibr" target="#b2">Borovykh et al. (2018)</ref> and <ref type="bibr" target="#b26">Xue et al. (2018)</ref> employ convolutional neural networks. Moreover, <ref type="bibr" target="#b13">Mallqui &amp; Fernandes (2019)</ref> employ artificial neural networks, support vector machines, and ensemble algorithms to predict the direction as well as the maximum, minimum and closing prices of Bitcoin. We also refer to <ref type="bibr" target="#b7">Harikrishnan et al. (2021)</ref> for a survey paper regarding the application of various machine learning algorithms for the prediction of stock prices.</p><p>In this paper, we focus on the application of long short-term memory networks (LSTM) and random forests to forecast directional movements of stock prices. <ref type="bibr" target="#b22">Siami-Namini &amp; Namin (2018)</ref> compare LSTM with an autoregressive integrated moving Email addresses: f20150366@goa.bits-pilani.ac.in (Pushpendu Ghosh), ariel.neufeld@ntu.edu.sg (Ariel Neufeld), jksahoo@goa.bits-pilani.ac.in (Jajati Keshari Sahoo) Acknowledgment: The first author gratefully acknowledges the NTU-India Connect Research Internship Programme which allowed him to carry out part of this research project while visiting the Nanyang Technological University, Singapore. The second author gratefully acknowledges financial support by his Nanyang Assistant Professorship Grant (NAP Grant) Machine Learning based Algorithms in Finance and Insurance. <ref type="bibr">1 Fischer &amp; Krauss (2018)</ref> and <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> obtain 0.46% and 0.43%, as the period from November 2015 until December 2018 was not included in their backtesting.</p><p>average (ARIMA) model. Their empirical results applied to financial data show that LSTM outperforms ARIMA in terms of lower forecast errors and higher accuracy. The empirical results in <ref type="bibr" target="#b17">Qiu et al. (2020)</ref> using LSTM demonstrate an improvement for stock price predictions when an attention mechanism is employed. <ref type="bibr" target="#b21">Sharma et al. (2021)</ref> observe that for both LSTM and autoregressive integrated moving average with exogenous variables (ARIMAX) models a considerable improvement of the prediction of stock price movements can be achieved when including a sentiment analysis. <ref type="bibr" target="#b14">Moritz &amp; Zimmermann (2014)</ref> employ random forests to predict returns of stocks using US CRSP data. As trading strategy, the top decile is bought, whereas the bottom one is sold short. <ref type="bibr" target="#b12">Lohrmann &amp; Luukka (2019)</ref> construct a classification model using random forest to predict open-toclose returns of stocks in the S&amp;P 500. <ref type="bibr" target="#b1">Basak et al. (2019)</ref> use random forests and gradient boosted decision trees (XGBoost), together with a selection of technical indicators, to analyze the performance for medium to long-run prediction of stock price returns, and Sadorsky (2021) employs random forests to forecast the directions of stock prices of clean energy exchange traded funds.</p><p>Moreover, <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> compare different deep learning methods such as deep neural networks, gradient-boostedtrees and random forests. In a single-feature setting, the daily returns with respect to the closing prices of the S&amp;P 500 from December 1992 until October 2015 are provided to forecast one-day-ahead for every stock the probability of outperforming the market. As trading strategy, the 10 stocks with the highest probability are bought and the 10 stocks with the lowest probability are sold short -all with equal monetary weight. It turns out that random forests achieve the highest return of each of the above deep learning methods with returns of 0.43% per day, prior to transaction costs. <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> continue the study of <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> by employing LSTM networks as deep-learning methodology and obtain returns of 0.46% per day prior to transaction costs, therefore outperforming all the memory-free methods in <ref type="bibr" target="#b11">Krauss et al. (2017)</ref>.</p><p>In our work, we use the results in <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> and <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> as benchmark for the ease of comparison.</p><p>We introduce a multi-feature setting consisting not only of the returns with respect to the closing prices, but also with respect to the opening prices and intraday returns to predict for each stock, at the beginning of each day, the probability to outperform the market in terms of intraday returns. As data set we use all stocks of the S&amp;P 500 from the period of January 1990 until December 2018. We employ both random forests on the one hand and LSTM networks (more precisely CuDNNLSTM) on the other hand as training methodology and apply the same trading strategy as in <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> and <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref>. Our empirical results show that the multi-feature setting provides a daily return, prior to transaction costs, of 0.64% for the LSTM network, and 0.54% for the random forest, hence outperforming the single-feature setting in <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> and <ref type="bibr" target="#b11">Krauss et al. (2017)</ref>, having corresponding daily returns of 0.41% and of 0.39%, respectively. 2</p><p>The remainder of this paper is organized as follows. In Section 2 we explain the data sample as well as the software and hardware we use. In Section 3 we discuss the methodology we employ. The empirical results are then presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data and technology</head><p>We collected adjusted closing prices and opening prices of all constituent stocks of the S&amp;P 500 from the period of January 1990 until December 2018 using Bloomberg. For each day, stocks with zero volume were not considered for trading at this day.</p><p>All experiments were executed in a NVIDIA Tesla V100 with 30 GB memory. The codes and simulations were implemented using Python 3.6.5 with a dependency of TensorFlow 1.14.0 and scikit-learn 0.20.4. Visualization and statistical values were produced and calculated using the financial toolbox of MATLAB R2016b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>Our methodology is composed of five steps. In the first step, we divide our raw data into study periods, where each study period is divided into a training part (for in-sample trading), and a trading part (for out-of-sample predictions). In the second step, we introduce our features, whereas in the third step we set up our targets. In the forth step, we define the setup of our two machine learning methods we employ, namely random forest and CuDNNLSTM. Finally, in the fifth step, we establish a trading strategy for the trading part.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset creation with non-overlapping testing period</head><p>We follow the procedure of <ref type="bibr" target="#b11">Krauss et al. (2017</ref><ref type="bibr" target="#b6">) &amp; Fischer &amp; Krauss (2018</ref> and divide the dataset consisting of 29 years starting from January 1990 till December 2018, using a 4-year window and 1-year stride, where each study period is divided into a training period of approximately 756 days (? 3 years) and a trading period of approximately 252 days (? 1 year). As a consequence, we obtain 26 study periods with non-overlapping trading part. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Features selection</head><p>Let T study denote the amount of days in a study period and let n i be the number of stocks 3 s in S having complete historical data available at the end of each study period i. Moreover, we define the adjusted closing price and opening price of any stock</p><formula xml:id="formula_0">s ? S at time t by cp (s) t and op (s) t respectively.</formula><p>Given a prediction day t := ? , we have the following inputs and prediction tasks:</p><p>Input : We have the historical opening prices, op  Task : Out of all n stocks, predict k stocks with the highest and k stocks with the lowest intraday return ir ?,0 := cp? op? ? 1.</p><p>3 We include stock prices of all S&amp;P500 constituents at the last day of the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Feature generation for Random Forest</head><p>For any stock s ? S and any time t ? {241, 242, . . . , T study }, the feature set we provide to the random forest comprises of the following three signals:</p><p>1. Intraday returns: ir</p><formula xml:id="formula_1">(s) t,m := cp (s) t?m op (s) t?m ? 1,</formula><p>2. Returns with respect to last closing price: cr</p><formula xml:id="formula_2">(s) t,m := cp (s) t?1 cp (s) t?1?m ? 1,</formula><p>3. Returns with respect to opening price: or </p><formula xml:id="formula_3">(s) t,m := op (s) t cp (s) t?m ? 1, where m ? {1, 2, 3, ..., 20} ? {40,</formula><formula xml:id="formula_4">t,m = cp (s) t?1 cp (s) t?1?m ? 1. By the choice of m ? {1, 2, 3, ..., 20} ? {40</formula><p>, 60, 80, ..., 240}, we consider in the first month the corresponding returns of each trading day, whereas for the subsequent 11 months we only consider the corresponding multi-period returns of each month. No time series transformation such as, e.g., scaling or centering, is performed for the random forest. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Feature generation for LSTM</head><p>Following the approach of <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref>, but in a multi-feature setting rather than their single feature approach, we input the model with 240 timesteps and 3 features, and train it to predict the direction of the 241 st intraday return.</p><p>More precisely, for each stock s at time t, we first consider the following three features, ir     The Robust Scaler standardization <ref type="bibr" target="#b16">(Pedregosa et al. (2011)</ref>) first subtracts (and hence removes) the median and then scales the data using the inter-quantile range, making it robust to outliers.</p><formula xml:id="formula_6">t,1 := f (s) t,1 ?Q 2 (f (s) ?,1 ) Q 3 (f (s) ?,1 )?Q 1 (f (s) ?,1 ) , where Q 1 (f (s) ?,1 ), Q 2 (f</formula><p>Next, for each time t ? {241, 242, . . . , T study }, we generate overlapping sequences of 240 consecutive, three-dimensional standardized features F  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Train-test split</head><p>For each stock s ? S , we create a matrix with M columns and T study rows, where M is the number of features. Hence M is equal to 93 and (240, 3) when using random forest and LSTM, respectively. We fill the matrix with respective M features as defined above. Since by definition, ir t,m is not defined when t ? m, columns of the top 240 rows are partially filled and are hence removed. This removal leaves T study ? 240 rows (i.e. for t = {241, 242, 243, ..., T study }) which is split into two parts, namely approximately from t = 241 to t = 756, and from t = 757 to t = T study , for training and testing purposes, respectively.</p><p>Note that typically T study = 1008.</p><p>At the end, we concatenate the training data of all stocks in S to get the collective training set. Hence the training set is a matrix with approximate size of 500 ? 516 = 258000 rows (instances) and M columns (features), along with their corresponding target, whereas the trading set is a matrix with approximate size of 500 ? 252 = 126000 rows (instances) and M columns (features). t,0 of stock s is smaller than the cross-sectional median intraday return of all stocks at time t, whereas Class 1 is realized if ir (s) t,0 of stock s is bigger than the cross-sectional median intraday return of all stocks at time t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Model training specification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">Model specification for Random forest</head><p>As first model, we use random forests introduced by <ref type="bibr" target="#b8">Ho (1995)</ref> and expanded by <ref type="bibr" target="#b4">Breiman (2001)</ref>, with the following parameters:</p><p>? Number of decision trees in the forest = 1000</p><p>? Maximum depth of each tree 4 = 10</p><p>? For every split, we select m := ? ? p? features randomly from the p = 93 features in the data, see <ref type="bibr" target="#b16">Pedregosa et al. (2011)</ref>.</p><p>We refer to <ref type="bibr">(Krauss et al., 2017, Subsection 4.3</ref>.3) and <ref type="bibr" target="#b6">(Fischer &amp; Krauss, 2018</ref>, Subsection 3.4) for further details regarding random forests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Model specification for LSTM</head><p>LSTM is a recurrent neural network introduced by <ref type="bibr" target="#b19">Schmidhuber &amp; Hochreiter (1997)</ref>; we refer to <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> for a detailed description. Since the training of LSTMs is very time consuming, and also to efficiently utilize the power of GPUs, we perform our experiments using CuDNNLSTMs <ref type="bibr" target="#b5">(Chetlur et al. (2014)</ref>). CUDA Deep Neural Network library (cuDNN) is a GPU-accelerated library for deep neural networks. We gain immense speedup (up to 7.2x, see <ref type="bibr" target="#b3">Braun (2018)</ref>) in training and predicting time. For the ease of comparison 5 we follow the network architecture used in <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref>. We create a model with 25 cells of CuDNNLSTM, followed by a dropout layer of 0.1 and then a dense layer of 2 output nodes with softmax activation function.</p><p>? Loss function: categorical cross-entropy</p><p>? Optimizer: RMSProp (with the keras default learning rate of 0.001)</p><p>? Batch size: 512</p><p>? Early stopping: patience of 10 epochs, monitoring the validation loss</p><p>? Validation split: 0.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Prediction and trading methodology</head><p>We forecast the probability P (s) t for each stock s to outperform the median intraday return ir (s) t,0 . Next, as trading strategy, we follow <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> and <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> and go long the top k = 10 stocks with highest P (s) t and go short the worst k = 10 stocks with lowest P (s) t -all with equal monetary weight. Each long and short transaction are subjected to 0.05% slippage cost on each half-turn, as suggested by <ref type="bibr" target="#b0">Avellaneda &amp; Lee (2010)</ref>, so each day's transaction is penalized with a total of 0.2%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Discussion</head><p>The empirical results 6 show that our multi-feature setting consisting not only of the returns with respect to the closing prices, but also with respect to the opening prices and intraday returns, outperforms the single feature setting of <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> and <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref>, both with respect to random forests and LSTM. We refer to "IntraDay" for our setting and "NextDay" for the setting in <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> and <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> in <ref type="table" target="#tab_3">Tables 1-3 and Figures 5-7.</ref> Indeed, our setting involving LSTM obtains, prior to transaction costs, a daily return of 0.64%, compared to the setting in <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> obtaining a 0.41% daily return. Also for random forests, our setting obtains a higher daily return of 0.54%, compared to 0.39% when using the setting as in <ref type="bibr" target="#b11">Krauss et al. (2017)</ref>. The share of positive returns is at 69.67% and 65.85% for LSTM and random forests. In addition, our setting obtains higher sharpe ratio and lower standard deviation (i.e. typical annualized risk-return metrics) in comparison with the one in <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> and <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref>.</p><p>Furthermore, our setting produces a lower maximum drawdown and lower daily value at risk (VaR); we refer to Tables 2 &amp; 3.</p><p>We also see that in our setting LSTM outperforms random forests, which is in line with the results of <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> showing that LSTM has an advantage compared to the memory-free methods analyzed in <ref type="bibr" target="#b11">Krauss et al. (2017)</ref>.</p><p>In <ref type="figure">Figures 5-7</ref>, we have divided the time period from January 1993 until December 2018 into three time-periods, analog to <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> and similar to <ref type="bibr" target="#b11">Krauss et al. (2017)</ref>. Roughly speaking, the first time-period corresponds to a strong performance caused by, among others, the dot-com-bubble, followed by the time-period of moderation with the bursting of the dot-com bubble and the financial crisis of 2008, ending with the time-period of deterioration; probably since by that time on, machine learning algorithms are broadly available and hence diminishes the opportunity of creating statistical arbitrage having a technological advantage. We refer to <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> and <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> for a detailed discussion of these sub-periods. We see in Figures 5-7 that in each of these sub-periods, our setting outperforms the one in <ref type="bibr" target="#b11">Krauss et al. (2017)</ref> and <ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref>.</p><p>To show the importance of using three features instead of having a single feature, we additionally analyze in <ref type="table" target="#tab_4">Tables 2 &amp; 3</ref>  As an outlook for future research, we remark that the problem of forecasting directional movements of stocks (or currencies) can be formulated as a reinforcement learning problem, both model-free and model-based. An interesting analysis would be to compare these different reinforcement learning methodologies to both LSTM and random forests, particularly applied to cryptocurrencies. We leave this open for future studies.      <ref type="bibr">1993 1994 1995 1996 1997 1998 1999 2000 2001</ref> Year  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Dataset creation with non-overlapping testing period</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>? {0, 1, ..., ? ? 1, ? }, (including the prediction day's opening price op (s) ? ) as well as the historical adjusted closing prices cp</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>? {0, 1, ..., ? ? 1}, (excluding the prediction day's closing price, cp (s) ? ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Feature generation for random forest</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>are the first, second, and third quartile of f</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>t?238,1 , . . . , F (s) t,1 , where F (s) t?i,1 := ir (s) t?i,1 , cr (s) t?i,1 , or (s) t?i,1 , i ? {239, 238, . . . , 0}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 3 :</head><label>3</label><figDesc>Feature generation for LSTM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 4 :</head><label>4</label><figDesc>Train-test split matrix 3.3. Target selection Following Takeuchi &amp; Lee (2013) and Fischer &amp; Krauss (2018) we divide each stock at time t into 2 classes of equal size, based on their intraday returns ir (s) t,0 . Class 0 is realized if ir (s)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>the performance in the case of intraday-trading, but where only intraday returns ir (s) t,m as a single feature is used. The experimental results show massive improvement in all metrics when using the three features introduced in Subsection 3.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 5 :Figure 7 :</head><label>57</label><figDesc>Cumulative money growth with US$1 initial investment, after deducting transaction cost Figure 6: Average of daily mean returns, after deducting transaction cost Annualised sharpe ratio, after deducting transaction cost</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>60, 80, ..., 240}, obtaining 93 features, similar to Takeuchi &amp; Lee (2013) &amp; Krauss et al. (2017), who considered the single feature case consisting of the simple return cr</figDesc><table><row><cell>(s)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Time comparison</figDesc><table><row><cell>Metric</cell><cell>3-Feature</cell><cell>3-Feature</cell><cell>1-Feature</cell><cell>1-Feature</cell><cell>1-Feature</cell><cell>1-Feature</cell><cell>SP500</cell></row><row><cell>of daily returns</cell><cell>IntraDay</cell><cell>IntraDay</cell><cell>NextDay</cell><cell>NextDay</cell><cell>IntraDay</cell><cell>IntraDay</cell><cell>Index</cell></row><row><cell></cell><cell>LSTM</cell><cell>RF</cell><cell>LSTM</cell><cell>RF</cell><cell>LSTM</cell><cell>RF</cell><cell></cell></row><row><cell>Mean (long)</cell><cell>0.00332</cell><cell>0.00273</cell><cell>0.00257</cell><cell>0.00259</cell><cell>0.00094</cell><cell>0.00104</cell><cell>0.00033</cell></row><row><cell>Mean (short)</cell><cell>0.00312</cell><cell>0.00266</cell><cell>0.00158</cell><cell>0.00130</cell><cell>0.00180</cell><cell>0.00187</cell><cell>0.00000</cell></row><row><cell>Mean return</cell><cell>0.00644</cell><cell>0.00539</cell><cell>0.00414</cell><cell>0.00389</cell><cell>0.00274</cell><cell>0.00290</cell><cell>0.00033</cell></row><row><cell>Standard error</cell><cell>0.00019</cell><cell>0.00020</cell><cell>0.00024</cell><cell>0.00023</cell><cell>0.00021</cell><cell>0.00021</cell><cell>0.00014</cell></row><row><cell>Minimum</cell><cell>-0.1464</cell><cell>-0.1046</cell><cell>-0.1713</cell><cell>-0.1342</cell><cell>-0.1565</cell><cell>-0.1487</cell><cell>-0.0903</cell></row><row><cell>Quartile 1</cell><cell>-0.0017</cell><cell>-0.0028</cell><cell>-0.0052</cell><cell>-0.0051</cell><cell>-0.0054</cell><cell>-0.0050</cell><cell>-0.0044</cell></row><row><cell>Median</cell><cell>0.00559</cell><cell>0.00462</cell><cell>0.00352</cell><cell>0.00287</cell><cell>0.00242</cell><cell>0.00221</cell><cell>0.00056</cell></row><row><cell>Quartile 3</cell><cell>0.01433</cell><cell>0.01306</cell><cell>0.01294</cell><cell>0.01161</cell><cell>0.01086</cell><cell>0.01036</cell><cell>0.00560</cell></row><row><cell>Maximum</cell><cell>0.14101</cell><cell>0.14153</cell><cell>0.19884</cell><cell>0.28139</cell><cell>0.13896</cell><cell>0.16064</cell><cell>0.11580</cell></row><row><cell>Share &gt; 0</cell><cell>0.69663</cell><cell>0.65857</cell><cell>0.60598</cell><cell>0.59479</cell><cell>0.58405</cell><cell>0.58937</cell><cell>0.53681</cell></row><row><cell>Std. deviation</cell><cell>0.01572</cell><cell>0.01597</cell><cell>0.01961</cell><cell>0.01831</cell><cell>0.01713</cell><cell>0.01683</cell><cell>0.01133</cell></row><row><cell>Skewness</cell><cell>0.15599</cell><cell>0.28900</cell><cell>0.36822</cell><cell>1.41199</cell><cell>-0.1828</cell><cell>0.12051</cell><cell>-0.1007</cell></row><row><cell>Kurtosis</cell><cell>9.71987</cell><cell>8.32627</cell><cell>10.8793</cell><cell>19.8349</cell><cell>10.1893</cell><cell>11.7758</cell><cell>11.9396</cell></row><row><cell>1-percent VaR</cell><cell>-0.0352</cell><cell>-0.0364</cell><cell>-0.0492</cell><cell>-0.0432</cell><cell>-0.0461</cell><cell>-0.0448</cell><cell>-0.0313</cell></row><row><cell>1-percent CVaR</cell><cell>-0.0519</cell><cell>-0.0528</cell><cell>-0.0712</cell><cell>-0.0592</cell><cell>-0.0678</cell><cell>-0.0660</cell><cell>-0.0451</cell></row><row><cell>5-percent VaR</cell><cell>-0.0157</cell><cell>-0.0170</cell><cell>-0.0234</cell><cell>-0.0208</cell><cell>-0.0214</cell><cell>-0.0197</cell><cell>-0.0177</cell></row><row><cell>5-percent CVaR</cell><cell>-0.0284</cell><cell>-0.0297</cell><cell>-0.0401</cell><cell>-0.0345</cell><cell>-0.0377</cell><cell>-0.0357</cell><cell>-0.0270</cell></row><row><cell>Max. drawdown</cell><cell>0.22345</cell><cell>0.19779</cell><cell>0.42551</cell><cell>0.23155</cell><cell>0.35645</cell><cell>0.43885</cell><cell>0.56775</cell></row><row><cell>Avg return p.a.</cell><cell>3.84750</cell><cell>2.75103</cell><cell>1.68883</cell><cell>1.53806</cell><cell>0.91483</cell><cell>1.00281</cell><cell>0.06975</cell></row><row><cell>Std dev. p.a.</cell><cell>0.24957</cell><cell>0.25358</cell><cell>0.31135</cell><cell>0.29071</cell><cell>0.27193</cell><cell>0.26719</cell><cell>0.17990</cell></row><row><cell>Down dev. p.a.</cell><cell>0.17144</cell><cell>0.17301</cell><cell>0.21204</cell><cell>0.18690</cell><cell>0.19270</cell><cell>0.18530</cell><cell>0.12970</cell></row><row><cell>Sharpe ratio</cell><cell>6.34253</cell><cell>5.20303</cell><cell>3.22732</cell><cell>3.23339</cell><cell>2.39560</cell><cell>2.59188</cell><cell>0.24867</cell></row><row><cell>Sortino ratio</cell><cell>62.7403</cell><cell>49.6764</cell><cell>27.8835</cell><cell>30.0753</cell><cell>19.0217</cell><cell>21.2964</cell><cell>1.77234</cell></row></table><note>6 All the codes are available on https://github.com/pushpendughosh/Stock-market-forecasting</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Average performance metrics of daily returns before transaction cost</figDesc><table><row><cell>Metric</cell><cell>3-Feature</cell><cell>3-Feature</cell><cell>1-Feature</cell><cell>1-Feature</cell><cell>1-Feature</cell><cell>1-Feature</cell><cell>SP500</cell></row><row><cell>of daily returns</cell><cell>IntraDay</cell><cell>IntraDay</cell><cell>NextDay</cell><cell>NextDay</cell><cell>IntraDay</cell><cell>IntraDay</cell><cell>Index</cell></row><row><cell></cell><cell>LSTM</cell><cell>RF</cell><cell>LSTM</cell><cell>RF</cell><cell>LSTM</cell><cell>RF</cell><cell></cell></row><row><cell>Mean (long)</cell><cell>0.00232</cell><cell>0.00173</cell><cell>0.00157</cell><cell>0.00159</cell><cell>-0.0000</cell><cell>0.00004</cell><cell>0.00033</cell></row><row><cell>Mean (short)</cell><cell>0.00212</cell><cell>0.00166</cell><cell>0.00058</cell><cell>0.00030</cell><cell>0.00080</cell><cell>0.00087</cell><cell>0.00000</cell></row><row><cell>Mean return</cell><cell>0.00444</cell><cell>0.00339</cell><cell>0.00214</cell><cell>0.00189</cell><cell>0.00074</cell><cell>0.00090</cell><cell>0.00033</cell></row><row><cell>Standard error</cell><cell>0.00019</cell><cell>0.00020</cell><cell>0.00024</cell><cell>0.00023</cell><cell>0.00021</cell><cell>0.00021</cell><cell>0.00014</cell></row><row><cell>Minimum</cell><cell>-0.1484</cell><cell>-0.1066</cell><cell>-0.1733</cell><cell>-0.1362</cell><cell>-0.1585</cell><cell>-0.1507</cell><cell>-0.0903</cell></row><row><cell>Quartile 1</cell><cell>-0.0037</cell><cell>-0.0048</cell><cell>-0.0072</cell><cell>-0.0071</cell><cell>-0.0074</cell><cell>-0.0070</cell><cell>-0.0044</cell></row><row><cell>Median</cell><cell>0.00359</cell><cell>0.00262</cell><cell>0.00152</cell><cell>0.00087</cell><cell>0.00042</cell><cell>0.00021</cell><cell>0.00056</cell></row><row><cell>Quartile 3</cell><cell>0.01233</cell><cell>0.01106</cell><cell>0.01094</cell><cell>0.00961</cell><cell>0.00886</cell><cell>0.00836</cell><cell>0.00560</cell></row><row><cell>Maximum</cell><cell>0.13901</cell><cell>0.13953</cell><cell>0.19684</cell><cell>0.27939</cell><cell>0.13696</cell><cell>0.15864</cell><cell>0.11580</cell></row><row><cell>Share &gt; 0</cell><cell>0.63129</cell><cell>0.59319</cell><cell>0.54279</cell><cell>0.53006</cell><cell>0.51534</cell><cell>0.50810</cell><cell>0.53681</cell></row><row><cell>Std. deviation</cell><cell>0.01572</cell><cell>0.01597</cell><cell>0.01961</cell><cell>0.01831</cell><cell>0.01713</cell><cell>0.01683</cell><cell>0.01133</cell></row><row><cell>Skewness</cell><cell>0.15599</cell><cell>0.28900</cell><cell>0.36822</cell><cell>1.41199</cell><cell>-0.1828</cell><cell>0.12051</cell><cell>-0.1007</cell></row><row><cell>Kurtosis</cell><cell>9.71987</cell><cell>8.32627</cell><cell>10.8793</cell><cell>19.8349</cell><cell>10.1893</cell><cell>11.7758</cell><cell>11.9396</cell></row><row><cell>1-percent VaR</cell><cell>-0.0372</cell><cell>-0.0384</cell><cell>-0.0512</cell><cell>-0.0452</cell><cell>-0.0481</cell><cell>-0.0468</cell><cell>-0.0313</cell></row><row><cell>1-percent CVaR</cell><cell>-0.0539</cell><cell>-0.0548</cell><cell>-0.0732</cell><cell>-0.0612</cell><cell>-0.0698</cell><cell>-0.0680</cell><cell>-0.0451</cell></row><row><cell>5-percent VaR</cell><cell>-0.0177</cell><cell>-0.0190</cell><cell>-0.0254</cell><cell>-0.0228</cell><cell>-0.0234</cell><cell>-0.0217</cell><cell>-0.0177</cell></row><row><cell>5-percent CVaR</cell><cell>-0.0304</cell><cell>-0.0317</cell><cell>-0.0421</cell><cell>-0.0365</cell><cell>-0.0397</cell><cell>-0.0377</cell><cell>-0.0270</cell></row><row><cell>Max. drawdown</cell><cell>0.39227</cell><cell>0.40139</cell><cell>0.87232</cell><cell>0.92312</cell><cell>0.97263</cell><cell>0.87123</cell><cell>0.56775</cell></row><row><cell>Avg return p.a.</cell><cell>1.94325</cell><cell>1.27179</cell><cell>0.63060</cell><cell>0.53901</cell><cell>0.16046</cell><cell>0.21146</cell><cell>0.06975</cell></row><row><cell>Std dev. p.a.</cell><cell>0.24957</cell><cell>0.25358</cell><cell>0.31135</cell><cell>0.29071</cell><cell>0.27193</cell><cell>0.26719</cell><cell>0.17990</cell></row><row><cell>Down dev. p.a.</cell><cell>0.17144</cell><cell>0.17301</cell><cell>0.21204</cell><cell>0.18690</cell><cell>0.19270</cell><cell>0.18530</cell><cell>0.12970</cell></row><row><cell>Sharpe ratio</cell><cell>4.32307</cell><cell>3.21553</cell><cell>1.60856</cell><cell>1.49969</cell><cell>0.54218</cell><cell>0.70557</cell><cell>0.24867</cell></row><row><cell>Sortino ratio</cell><cell>39.0873</cell><cell>27.9810</cell><cell>12.9274</cell><cell>12.7950</cell><cell>3.98288</cell><cell>5.34773</cell><cell>1.77234</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Average performance metrics of daily returns after transaction cost</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2"><ref type="bibr" target="#b6">Fischer &amp; Krauss (2018)</ref> and<ref type="bibr" target="#b11">Krauss et al. (2017)</ref> obtain 0.46% and 0.43%, as the period from November 2015 until December 2018 was not included in their backtesting.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Our empirical study from hyperparameter tuning suggests that forests with maximum depth of 10 give the highest accuracy.5  We tested several values for the amount of cells, as well as several LSTM architectures. They only marginally influence the empirical results.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Statistical arbitrage in the us equities market</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Avellaneda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quantitative Finance</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="761" to="782" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Predicting the direction of stock market prices using tree-based classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Basak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Khaidem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Dey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The North American Journal of Economics and Finance</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="552" to="567" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dilated convolutional neural networks for time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borovykh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bohte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Oosterlee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Finance, Forthcoming</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Braun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01818</idno>
		<title level="m">LSTM benchmarks for deep learning frameworks. preprint</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Random forests. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chetlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Woolley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandermersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.0759</idno>
		<title level="m">Efficient primitives for deep learning. preprint</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep learning with long short-term memory networks for financial market predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Krauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">270</biblScope>
			<biblScope unit="page" from="654" to="669" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Harikrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tadanki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bardae</surname></persName>
		</author>
		<title level="m">Machine Learning Based Model to Predict Stock Prices: A Survey. IOP Conference Series: Materials Science and Engineering</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1084</biblScope>
			<biblScope unit="page">12019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Random decision forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd international conference on document analysis and recognition</title>
		<meeting>3rd international conference on document analysis and recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="278" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Pairs selection and outranking: An application to the S&amp;P 100 index</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Huck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">196</biblScope>
			<biblScope unit="page" from="819" to="825" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pairs trading and outranking: The multi-step-ahead forecasting case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Huck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page" from="1702" to="1716" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep neural networks, gradient-boosted trees, random forests: Statistical arbitrage on the S&amp;P 500</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Krauss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">A</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Huck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">259</biblScope>
			<biblScope unit="page" from="689" to="702" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Classification of intraday S&amp;P500 returns with a Random Forest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lohrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luukka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="390" to="407" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predicting the direction, maximum, minimum and closing prices of daily Bitcoin exchange rate using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mallqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fernandes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="596" to="606" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Deep conditional portfolio sorts: The relation between past and future stock returns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zimmermann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>LMU Munich and Harvard University Working paper</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">S&amp;P500 Forecasting and trading using convolution analysis of major asset classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Papaioannou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dionysopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Giannino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janetzko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Siettos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia computer science</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scikit-learn: machine learning in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Forecasting stock prices with long-short term memory neural network based on attention mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">227222</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Random Forests Approach to Predicting Clean Energy Stock Prices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sadorsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Risk and Financial Management</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">48</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Algorithmic financial trading with deep convolutional neural networks: Time series to image conversion approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">B</forename><surname>Sezer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Ozbayoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="525" to="538" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Use of LSTM and ARIMAX Algorithms to Analyze Impact of Sentiment Analysis in Stock Market Prediction. Intelligent Data Communication Technologies and Internet of Things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Garg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICICI 2020</title>
		<meeting>ICICI 2020</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="377" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Forecasting economics and financial time series: ARIMA vs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Siami-Namini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Namin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.06386</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">LSTM. preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Feature Selection and Hyper-parameter Tuning Technique using Neural Network for Stock Market Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Johri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elngar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information Technology Management</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="89" to="108" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Applying deep learning to enhance momentum trading strategies in stocks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Takeuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Y</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Temporal attention-augmented bilinear network for financial time-series data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kanniainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1407" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Financial time series prediction using ? 2,1 RF-ELM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">277</biblScope>
			<biblScope unit="page" from="176" to="186" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
