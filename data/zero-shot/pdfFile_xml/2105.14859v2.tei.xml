<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Consistency Regularization for Variational Auto-Encoders</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samarth</forename><surname>Sinha</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vector Institute University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adji</forename><forename type="middle">B</forename><surname>Dieng</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Brain</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Consistency Regularization for Variational Auto-Encoders</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Variational auto-encoders ( s) are a powerful approach to unsupervised learning.</p><p>They enable scalable approximate posterior inference in latent-variable models using variational inference ( ). A posits a variational family parameterized by a deep neural network-called an encoder-that takes data as input. This encoder is shared across all the observations, which amortizes the cost of inference. However the encoder of a has the undesirable property that it maps a given observation and a semantics-preserving transformation of it to different latent representations. This "inconsistency" of the encoder lowers the quality of the learned representations, especially for downstream tasks, and also negatively affects generalization. In this paper, we propose a regularization method to enforce consistency in s. The idea is to minimize the Kullback-Leibler ( ) divergence between the variational distribution when conditioning on the observation and the variational distribution when conditioning on a random semantic-preserving transformation of this observation. This regularization is applicable to any . In our experiments we apply it to four different variants on several benchmark datasets and found it always improves the quality of the learned representations but also leads to better generalization. In particular, when applied to the nouveau variational auto-encoder ( ), our regularization method yields state-of-the-art performance on , -10, and . We also applied our method to 3D data and found it learns representations of superior quality as measured by accuracy on a downstream classification task. Finally, we show our method can even outperform the triplet loss, an advanced and popular contrastive learning-based method for representation learning. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Variational auto-encoders ( s) have significantly impacted research on unsupervised learning. They have been used in several areas, including density estimation <ref type="bibr" target="#b18">(Kingma &amp; Welling, 2013;</ref><ref type="bibr" target="#b30">Rezende et al., 2014)</ref>, image generation <ref type="bibr" target="#b11">(Gregor et al., 2015)</ref>, text generation <ref type="bibr" target="#b3">(Bowman et al., 2015;</ref><ref type="bibr" target="#b8">Fang et al., 2019)</ref>, music generation <ref type="bibr" target="#b32">(Roberts et al., 2018)</ref>, topic modeling <ref type="bibr" target="#b27">(Miao et al., 2016;</ref><ref type="bibr" target="#b7">Dieng et al., 2019)</ref>, and recommendation systems <ref type="bibr" target="#b25">(Liang et al., 2018)</ref>. V s have also been used for different representation learning problems such as semi-supervised learning , anomaly detection <ref type="bibr" target="#b1">(An &amp; Cho, 2015;</ref><ref type="bibr" target="#b46">Zimmerer et al., 2018)</ref>, language modeling <ref type="bibr" target="#b3">Bowman et al. (2015)</ref>, active learning <ref type="bibr" target="#b36">(Sinha et al., 2019)</ref>, continual learning <ref type="bibr" target="#b0">(Achille et al., 2018)</ref>, and motion prediction of agents <ref type="bibr" target="#b41">(Walker et al., 2016)</ref>. This widespread application of representations makes it critical that we focus on improving them. s extend deterministic auto-encoders to probabilistic generative modeling. The encoder of a parameterizes an approximate posterior distribution over latent variables of a generative model. The encoder is shared between all observations, which amortizes the cost of posterior inference. Once fitted, the encoder of a can be used to obtain low-dimensional representations of data, (e.g. for downstream tasks.) The quality of these representations is therefore very important to a successful application of s.</p><p>Researchers have looked at ways to improve the quality of the latent representations of s, often tackling the so-called latent variable collapse problem-in which the approximate posterior distribution induced by the encoder collapses to the prior over the latent variables <ref type="bibr" target="#b3">(Bowman et al., 2015;</ref><ref type="bibr" target="#b16">Kim et al., 2018;</ref><ref type="bibr" target="#b6">Dieng et al., 2018;</ref><ref type="bibr" target="#b13">He et al., 2019;</ref><ref type="bibr" target="#b9">Fu et al., 2019)</ref>.</p><p>In this paper, we focus on a different problem pertaining to the latent representations of s for image data. Indeed, the encoder of a fitted tends to map an image and a semantics-preserving transformation of that image to different parts in the latent space. This "inconsistency" of the encoder affects the quality of the learned representations and generalization. We propose a method to enforce consistency in s. The idea is simple and consists in maximizing the likelihood of the images while minimizing the Kullback-Leibler ( ) divergence between the approximate posterior distribution induced by the encoder when conditioning on the image, on one hand, and its transformation, on the other hand. This regularization technique can be applied to any variant to improve the quality of the learned representations and boost generalization performance. We call a with this form of regularization, a consistency-regularized variational auto-encoder ( -). <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the inconsistency problem of s and how -s address this problem on . The red dots are representations of a few images and the blue dots are the representations of their transformations. We applied semantics-preserving transformations: rotation, translation, and scaling. The maps each image and its transformation to different parts in the latent space as evidenced by the long arrows connecting each pair (a). Even when we include the transformed images to the data and fit the the inconsistency problem still occurs (b). Thedoes not suffer from the inconsistency problem; it maps each image and its transformation to nearby areas in the latent space, as evidenced by the short arrows connecting each pair (c).</p><p>In our experiments (see Section 4), we apply the proposed technique to four variants, the original <ref type="bibr" target="#b18">(Kingma &amp; Welling, 2013)</ref>, the importance-weighted auto-encoder ( ) <ref type="bibr" target="#b4">(Burda et al., 2015)</ref>, the ?- <ref type="bibr" target="#b14">(Higgins et al., 2017)</ref>, and the nouveau variational auto-encoder ( ) <ref type="bibr" target="#b38">(Vahdat &amp; Kautz, 2020)</ref>. We found, on four different benchmark datasets, that -s always yield better representations and generalize better than their base s. In particular, consistency-regularized nouveau variational auto-encoders ( -s) yield state-of-the-art performance on and -10. We also applied -s to 3D data where these conclusions still hold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>We consider a latent-variable model p ? (x, z) = p ? (x|z) ? p(z), where x denotes an observation and z is its associated latent variable. The marginal p(z) is a prior over the latent variable and p ? (x|z)</p><p>is an exponential family distribution whose natural parameter is a function of z parameterized by ?, e.g. through a neural network. Our goal is to learn the parameters ? and a posterior distribution over the latent variables. The approach of s is to maximize the evidence lower bound ( ), a lower bound on the log marginal likelihood of the data,</p><formula xml:id="formula_0">L = = E q ? (z|x) log p ? (x, z) q ? (z|x)<label>(1)</label></formula><p>where q ? (z|x) is an approximate posterior distribution over the latent variables. The idea of a is to let the parameters of the distribution q ? (z|x) be given by the output of a neural network, with parameters ?, that takes x as input. The parameters ? and ? are then jointly optimized by maximizing a Monte Carlo approximation of the using the reparameterization trick <ref type="bibr" target="#b18">(Kingma &amp; Welling, 2013)</ref>.</p><p>Consider a semantics-preserving transformation t(x|x) of data x (e.g. rotation or translation for images.) A good representation learning algorithm should provide similar latent representations for x andx. This is not the case for the that maximizes Equation 1 and its variants. Once fit to data, the encoder of a is unable to yield similar latent representations for a data x and its tranformatio? x (see <ref type="figure" target="#fig_0">Figure 1</ref>). This is because there is nothing in Equation 1 that forces this desideratum.</p><p>We now propose a regularization method that ensures consistency of the encoder of a . We call a with such a regularization a -. The regularization proposed is applicable to many variants of the such as the <ref type="bibr" target="#b4">(Burda et al., 2015)</ref>, the ?- <ref type="bibr" target="#b14">(Higgins et al., 2017)</ref>, and the <ref type="bibr" target="#b38">(Vahdat &amp; Kautz, 2020)</ref>. In what follows, we use the standard , the one that maximizes Equation 1, as the base to regularize to illustrate the method.</p><p>Consider an image x. Denote by t(x|x) the random process by which we generatex, a semanticspreserving transformation of x. We drawx from t(x|x) as follows:</p><formula xml:id="formula_1">x ? t(x|x) ?? ? p( ) andx = g(x, ).<label>(2)</label></formula><p>Here g(x, ) is a semantics-preserving transformation of the image x, e.g. translation with random length drawn from p( ) = U[??, ?] for some threshold ?. Athen maximizes</p><formula xml:id="formula_2">L -(x) = L (x) + E t(x|x) [L (x)] ? ? ? R(x, ?)<label>(3)</label></formula><p>where the regularization term R(x, ?) is</p><formula xml:id="formula_3">R(x, ?) = E t(x|x) [ (q ? (z|x)||q ? (z|x))] .<label>(4)</label></formula><p>Maximizing the objective in Equation 3 maximizes the likelihood of the data and their augmentations while enforcing consistency through R(x, ?). Minimizing R(x, ?), which only affects the encoder (with parameters ?), forces each observation and the corresponding augmentations to lie close to each other in the latent space. The hyperparameter ? ? 0 controls the strength of this constraint.</p><p>The objective in Equation 3 is intractable but we can easily approximate it using Monte Carlo with the reparameterization trick. In particular, we approximate the regularization term with one sample from t(x|x) and make the dependence to this sample explicit using the notation R(x,x, ?). Algorithm 1 illustrates this in greater detail. Although we show the application of consistency regularization using the that maximizes the , L (?) in Equation 3 can be replaced with any objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Applying consistency regularization to s, as we do in this paper, has not been previously explored.</p><p>Consistency regularization is a widely used technique for semi-supervised learning <ref type="bibr" target="#b2">(Bachman et al., 2014;</ref><ref type="bibr" target="#b33">Sajjadi et al., 2016;</ref><ref type="bibr" target="#b22">Laine &amp; Aila, 2016;</ref><ref type="bibr" target="#b28">Miyato et al., 2018;</ref><ref type="bibr" target="#b43">Xie et al., 2019)</ref>. The core idea behind consistency regularization for semi-supervised learning is to force classifiers to learn representations that are insensitive to semantics-preserving changes to images, so as to improve classification of unlabeled images. Examples of semantics-preserving changes used in the literature include rotation, zoom, translation, crop, or adversarial attacks. Consistency is often enforced by minimizing the L 2 distance between a classifier's logit output for an image and the logit output for its semantics-preserving transformation <ref type="bibr" target="#b33">(Sajjadi et al., 2016;</ref><ref type="bibr" target="#b22">Laine &amp; Aila, 2016)</ref>, or by minimizing for n = 1, . . . , B do Transform the data: n ? p( n ) andx n = T (x n , n ) Get variational mean and variance for the data: ? n = W NN(x n ; ?) + a and ? n = softplus(Q NN(x n ; ?) + b) Get S samples from the variational distribution when conditioning on x n : ? (s) ? N (0, I) and z (s) n = ? n + ? (s) ? ? n for s = 1, . . . , S Get variational mean and variance for the transformed data:</p><formula xml:id="formula_4">? n = W NN(x n ; ?) + a and? n = softplus(Q NN(x n ; ?) + b) Get S samples from the variational distribution when conditioning onx n : ? (s) ? N (0, I) andz (s) n =? n + ? (s) ?? n for s = 1, . . . , S end Compute L (x): L (x) ? 1 B B n=1 1 S S s=1 log p ? (x n , z (s) n ) ? log q ? (z (s) n |x n ) Compute L (x): L (x) ? 1 B B n=1 1 S S s=1 log p ? (x n ,z (s) n ) ? log q ? (z (s) n |x n ) Compute KL consistency regularizer: R(x,x, ?) = 1 2 K k=1 ? 2 nk +(? nk ?? nk ) 2 ? 2 nk ? 1 + 2 ? log ? nk ? nk Compute final loss: L -(x) = L (x) + L (x) ? ? ? R(x,x, ?) Backpropagate through L(x, ?, ?) = ?L -(x)</formula><p>and take a gradient step for ? and ? end the divergence between the classifier's label distribution induced by the image and that of its tranformation <ref type="bibr" target="#b28">(Miyato et al., 2018;</ref><ref type="bibr" target="#b43">Xie et al., 2019)</ref>.</p><p>More recently, consistency regularization has been applied to generative adversarial networks ( s) <ref type="bibr" target="#b10">(Goodfellow et al., 2014)</ref>. Indeed <ref type="bibr" target="#b42">Wei et al. (2018)</ref> and <ref type="bibr" target="#b45">Zhang et al. (2020)</ref> show that applying consistency regularization on the discriminator of a -also a classifier-can substantially improve its performance.</p><p>The idea we develop in this paper differs from the works above in two ways. First, it applies consistency regularization to s for image data. Second, it leverages consistency regularization, not in the label or logit space, as done in the works mentioned above, but in the latent space.</p><p>Although different, consistency regularization for s relates to works that study ways to constrain the sensitivity of encoders to various perturbations. For example, denoising auto-encoders ( s) and their variants <ref type="bibr" target="#b39">(Vincent et al., 2008</ref><ref type="bibr" target="#b40">(Vincent et al., , 2010</ref> corrupt an image x into x , typically using Gaussian noise, and then minimize the distance between the reconstruction of x and the un-corrupted image x. The motivation is to learn representations that are insensitive to the added noise. Our work differs in that we do not constrain the decoder to recover the original image from the corrupted image but, rather, to constrain the encoder to recover the latent representation of the original image from the corrupted image via a divergence minimization constraint.</p><p>Contractive auto-encoders ( s) <ref type="bibr" target="#b31">(Rifai et al., 2011)</ref> share a similar goal with -s. A is an auto-encoder whose encoder is constrained by minimizing the norm of the Jacobian of the output of the encoder with respect to the input image. This norm constraint on the Jacobian forces the representations learned by the encoder to be insensitive to changes in the input. Our work differs in several main ways. First, -s are not deterministic auto-encoders, contrary to s. We can easily sample from a -, as for any , which is not the case for a . Second, a does Although fitting the base with augmentations does improve the representations, adding the consistency regularization further improves the quality of these learned representations. The value of ? for the ?is inside the parentheses.</p><p>Method MI AU MI AU MI AU 124.5 ? 1.1 36 ? 0.8 105.4 ? 1.2 50 ? 0.0 33.8 ? 0.2 32 ? 0.9 + Aug 125.9 ? 0.2 42 ? 0.5 105.9 ? 0.7 50 ? 0.0 34.1 ? 0.8 33 ? 0.9 -126.3 ? 0.9 47 ? 0.5 107.8 ? 1.1 50 ? 0.0 34.9 ? 0.5 33 ? 1.2 127.1 ? 0.7 39 ? 0.5 110.3 ? 1.1 50 ? 0.0 36.9 ? 0.5 36 ? 1.6 +Aug 129.0 ? 0.9 45 ? 0.8 112.9 ? 0.7 50 ? 0.0 37.0 ? 0. </p><p>6.3 ? 0.6 8 ? 1.7 1.4 ? 0.2 4 ? 0.9 3.6 ? 0.3 7 ? 0.8 ?-</p><p>(10) + Aug 6.5 ? 0.5 9 ? 1.1 1.6 ? 0.2 4 ? 0.5 3.7 ? 0.1 7 ? 0.0 ?--(10) 6.9 ? 0.6 10 ? 0.5 1.6 ? 0.1 4 ? 0.5 3.7 ? 0.4 9 ? 0.9</p><p>not apply transformations to the input image, which limits the sensitivities it can learn to limit to those exhibited in the training set. Finally, s use the Jacobian to impose a consistency constraint, which are not as easy to compute as the divergence we use on the variational distribution induced by the encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Empirical Study</head><p>In this section we show that aimproves the learned representations of its base and positively affects generalization performance We also show that the proposed regularization method is amenable to different variants by applying it not only to the original but also to the , the ?-, and the . We showcase the importance of the KL regularization term by conducting an ablation study. We found that only regularizing with data augmentation improves performance but that accounting for the term (? &gt; 0) further improves the quality of the learned representations and generalization.</p><p>We will conduct three sets of experiments. In the first experiment, we will apply the regularization method proposed in this paper to standard s such as the original , the , and the ?-. We use , , and as datasets for this experiment. For , we choose the 32x32 resolution for this experiment. Our results show that adding consistency regularization always improves upon the base , both in terms of the quality of the learned representations and generalization. We conduct an ablation study and also report performance of the different variants above when they are fitted with the original data and their augmentations. The results from this ablation highlight the importance of setting ? &gt; 0.</p><p>In the second set of experiments we apply our method to a large-scale , the latest <ref type="bibr" target="#b38">(Vahdat &amp; Kautz, 2020)</ref>. We use , -10, and as datasets for this experiment. We increased the resolution for the dataset for this experiment to 64x64. We reach the same conclusions as for the first sets of experiments; -s improve the learned representations and generalization of their base s. In this particular setting, theachieves state-of-the-art generalization performance on both and -10. This state-of-the-art performance couldn't be reach simply by training the with augmentations, as our results show.</p><p>Finally, in a third set of experiments, we apply our regularization technique to a 3D point-cloud dataset called ShapeNet <ref type="bibr" target="#b5">(Chang et al., 2015)</ref>. We adapt a high-performing auto-encoding method called FoldingNet <ref type="bibr" target="#b44">(Yang et al., 2018)</ref> to its counterpart and apply the method we described in this paper to that variant on the ShapeNet dataset. We found that adding consistency regularization yields better learned representations.</p><p>We next describe in great detail the set up for each of these experiments and the results showcasing the usefulness of the regularization method we propose in this paper.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Application to standard s on benchmark datasets</head><p>We apply consistency regularization, as described in this paper, to the original , the , and the ?-. We now describe the set up and results for this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets.</head><p>We study three benchmark datasets that we briefly describe below. We first consider . is a handwritten digit recognition dataset with 60, 000 images in the training set and 10, 000 images in the test set <ref type="bibr" target="#b24">(LeCun, 1998)</ref>. We form a validation set of 10, 000 images randomly sampled from the training set.</p><p>We also consider , a handwritten alphabet recognition dataset <ref type="bibr" target="#b23">(Lake et al., 2011)</ref>. This dataset is composed of 19, 280 images. We use 16, 280 randomly sampled images for training and 1, 000 for validation and the remaining 2, 000 samples for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Finally we consider</head><p>. It is a dataset of faces, consisting of 162, 770 images for training, 19, 867 images for validation, and 19, 962 images for testing . We set the resolution to 32x32 for this experiment.</p><p>Transformations t(x|x). We consider three transformations variants for image data t(x|x). The first randomly translates an image [?2, 2] pixels in any direction. The second transformation randomly  Evaluation metrics. The regularization method we propose in this paper is mainly aimed at improving the learned representations of s. To assess these representations we use three metrics: mutual information, number of active latent units, and accuracy on a downstream classification task. We also evaluate the effect of the proposed method on generalization to unseen data. For that we also report negative log-likelihood. We define each of these metrics next.</p><p>Mutual information <ref type="bibr">(MI)</ref>. The first quality metric is the mutual information I(z; x) between the observations and the latents under the joint distribution induced by the encoder,</p><formula xml:id="formula_6">I(z; x) = E p d (x) [KL(q ? (z|x)||p(z)) ? (q ? (z)||p(z))]<label>(5)</label></formula><p>where p d (x) is the empirical data distribution and q ? (z) is the aggregated posterior, the marginal over z induced by the joint distribution defined by p d (x) and q ? (z|x). The mutual information is intractable but we can approximate it with Monte Carlo. Higher mutual information corresponds to more interpretable latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of active latent units (AU).</head><p>The second quality metrics we consider is the number of active latent units (AU). It is defined in <ref type="bibr" target="#b4">Burda et al. (2015)</ref> and measures the "activity" of a dimension of the latent variables z. A latent dimension is "active" if</p><formula xml:id="formula_7">Cov x (E u?q ? (u|x) ) &gt; ?<label>(6)</label></formula><p>where ? is a threshold defined by the user. For our experiments we set ? = 0.01. The higher the number of latent active units, the better the learned representations. Accuracy on downstream classification. This metric is calculated by fitting a given , taking the learned representations for each data in the test set and computing the accuracy from the prediction of the labels of the images in that same test set by a classifier fitted on the training set. This metric is only applicable to labelled datasets. Negative log-likelihood. We use negative held-out log-likelihood to assess generalization. Consider an unseen data x * , its negative held-out log-likelihood under the fitted model is This is intractable and we approximate it using Monte Carlo,</p><formula xml:id="formula_8">log p ? (x * ) = ? log E q ? (z|x * ) p ? (x * , z) q ? (z|x * ) .<label>(7)</label></formula><formula xml:id="formula_9">log p ? (x * ) ? ? log 1 S S s=1 p ? (x * , z (s) ) q ? (z (s) |x * )<label>(8)</label></formula><p>where z (1) , . . . , z (S) ? q ? (z|x * ).</p><p>Settings. The s are built on the same architecture as <ref type="bibr" target="#b37">Tolstikhin et al. (2017)</ref>. The networks are trained with the Adam optimizer with a learning rate of 10 ?4 <ref type="bibr" target="#b17">(Kingma &amp; Ba, 2014)</ref> and trained for 100 epochs with a batch size of 64. We set the dimensionality of the latent variables to 50, therefore the maximum number of active latent units in the latent space is 50. We found ? = 0.1 to be best according to cross-validation using held-out log-likelihood and exploring the range [1e ?4 , 1.0] datasets. In an ablation study we explore ? = 0. For the ?we set ? = 0.1 ? ? and study both ? = 0.1 and ? = 10, two regimes under which the ?performs qualitatively very differently <ref type="bibr" target="#b14">(Higgins et al., 2017)</ref>. All experiments were done on a GPU cluster consisting of Nvidia P100 and RTX. The training took approximately 1 day for most experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>. <ref type="table" target="#tab_1">Table 1</ref> shows that on all the three benchmark datasets all the different variants we studied, consistency regularization as developed in this paper always improves the quality of the learned representations as measured by mutual information and the number of active latent units.</p><p>These results are confirmed by the numbers shown in <ref type="table" target="#tab_2">Table 2</ref> where -s always lead to better accuracy on downstream classification.</p><p>We proposed consistency regularization as a way to improve the quality of the learned representations. Incidentally, <ref type="table" target="#tab_3">Table 3</ref> also shows that it can improve generalization as measured by negative loglikelihood.</p><p>Ablation Study. We now look at the impact of each factor that goes into the regularization method we introduced in this paper using . We test the impact of the regularization term ? and the impact of the choice of augmentation on all metrics. <ref type="table" target="#tab_4">Table 4</ref> and <ref type="table" target="#tab_5">Table 5</ref> show the results. <ref type="table" target="#tab_4">Table 4</ref> shows that even small consistency regularization (a small ? value) results in improvement over the base but that a large enough ? value can hurt performance. <ref type="table" target="#tab_5">Table 5</ref> shows that rotations and translations are more important than scaling, but the combination of all three augmentations works best for -s. Comparison to Contrastive Learning. We look at how -s compare against a popular and advanced contrastive-learning-based technique, the triplet loss <ref type="bibr" target="#b34">(Schroff et al., 2015)</ref> using . <ref type="table" target="#tab_6">Table 6</ref> shows that theoutperforms the triplet loss on both generalization performance and quality of learned representations. <ref type="table" target="#tab_6">Table 6</ref> also confirms existing literature showing simply applying augmentations can outperform complex contrastive learning-based methods such as the triplet loss <ref type="bibr" target="#b20">(Kostrikov et al., 2020;</ref><ref type="bibr" target="#b35">Sinha &amp; Garg, 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Application to the large-scale on benchmark datasets</head><p>Along with standard VAE variants, we also experiment with a large scale state-of-the-art , the <ref type="bibr" target="#b38">(Vahdat &amp; Kautz, 2020)</ref>. Similar to before, we simply add consistency regularization using the image-based augmentations techniques to the NVAE model and experiment on benchmark datasets: <ref type="bibr" target="#b24">(LeCun, 1998</ref><ref type="bibr">), -10 (Krizhevsky et al., 2009</ref>) and .</p><p>The results for large scale generative modeling are tabulated in <ref type="table" target="#tab_7">Table 8 and Table 7</ref>, where we see that usingwe are able to learn representations that yield better accuracy on downstream </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Application to the FoldingNet on 3D point-cloud data</head><p>Along with working with image data, we additionally experiment with 3D point cloud data using a FoldingNet <ref type="bibr" target="#b44">Yang et al. (2018)</ref> and the ShapeNet dataset <ref type="bibr" target="#b5">Chang et al. (2015)</ref> which consists of 55 distinct object classes. FoldingNet learns a deep AutoEncoder to learn unsupervised representations from the point cloud data. To add consistency regularization, we first substitute the AutoEncoder to a <ref type="table">Table 9</ref>: The FoldingNet yields higher accuracy when paired with consistency regularization on the ShapeNet dataset. The results shown here correspond to a FoldingNet that was trained with augmented data, the same used to apply consistency regularization. As can be seen from these results, enforcing consistency through KL as we do in this paper leads to representations that perform well on a downstream classification. Here the classifier used is a linear SVM. We also report mean reconstruction error through Chamfer distance where the same conclusion holds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Accuracy Reconstruction Loss</head><p>Folding Net (Aug) 82.5% 0.0355 CR-Folding Net 84.6% 0.0327 by adding the KL term from the ELBO to the baseline FoldingNet. We then add the additional consistency regularization KL term to the latent space of FoldingNet.</p><p>For the ShapeNet point cloud data, we perform data augmentation using a similar scheme to what we did for the previous experiments, we randomly translate, rotate and add jitter to the (x, y, z) coordinates of the point cloud data. We follow the same scheme detailed in FoldingNet <ref type="bibr" target="#b44">(Yang et al., 2018)</ref>.</p><p>We train both the FoldingNet turned in a and the CR-FoldingNet with these augmentations. To train CR-FoldingNet, we additionally apply the consistency regularization term as proposed in Equation 3. The results on the validation set for reconstruction (as measured by Chamfer distance) and accuracy are shown in <ref type="table">Table 9</ref>.</p><p>We also visualize the point clouds reconstructions and interpolations between 3 different object classes using a CR-FoldingNet in <ref type="figure">Figure 2</ref>. We perform 4 interpolation steps for each of the objects, to highlight the interpretable learned latent space. Additionally, we perform the same interpolation on the baseline FoldingNet model. We show these interpolations in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We proposed a simple regularization technique to constrain encoders of s to learn similar latent representations for an image and a semantics-preserving transformation of the image. The idea consists in maximizing the likelihood of the pair of images while minimizing the divergence between the variational distribution induced by the encoder when conditioning on the image on one hand, and its transformation, on the other hand. We applied this technique to several variants on several datasets, including a 3D dataset. We found it always leads to better learned representations and also better generalization to unseen data. In particular, when applied to the , the regularization technique we developed in this paper yields state-of-the-art results on and -10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>In this paper, we propose a simple method that performs a KL-based consistency regularization scheme using data augmentation for s. The broader impact of the study includes practical applications such as graphics and computer vision applications. The method we propose improves the learned representations of s, and as an artifact, also improves their generalization to unseen data. In this regard, any implications of s also apply to this work. For example, the generative model fit by a may be used to generate artificial data such as images, text, and 3D objects. Biases may arise as a result of poor data selection. Furthermore, text generated from generative systems may amplify harmful speech contained in the data. However, the method we propose can also improve the performance of s when used in certain practical domains as we discussed in the introduction of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>We thank Kevin Murphy, Ben Poole, and Augustus Odena for their comments on this work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of the inconsistency problem in s and how -s address this problem. The red dots correspond to the representations of few images from . The blue dots correspond to the representations of the transformed images. The transformations used here are rotations, translations, and scaling; they are semantics-preserving. The arrows connect the representations of any two pairs of an image and its transformation. The shorter the arrow, the better. (a): The maps the two sets of images to different areas in the latent space. (b): Even when trained with the original dataset augmented with the transformed images, the still maps the two sets of images to different parts in the latent space. (c): Themaps an image and its transformation to nearby areas in the latent space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>1.1 50 ? 0.0 143.4 ? 1.0 50 ? 0.0 75.8 ? 0.5 49 ? 0.5 ?-(0.5) + Aug 289.3 ? 1.0 50 ? 0.0 159.6 ? 1.3 50 ? 0.0 75.7 ? 0.3 49 ? 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>-</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>-s learn better representations than their base s on all three benchmark datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>-s learn representations that yield higher accuracy on downstream classification than their base s. These results correspond to the accuracy from a linear classifier that was fitted on the training. We fed this classifier with the representations learned by each method. On both and -10, -s yield higher accuracy.</figDesc><table><row><cell>Method</cell><cell></cell><cell></cell><cell>-10</cell></row><row><cell></cell><cell></cell><cell>98.5</cell><cell>32.6</cell></row><row><cell cols="2">+Aug</cell><cell>98.9</cell><cell>40.1</cell></row><row><cell>-</cell><cell></cell><cell>99.4</cell><cell>44.7</cell></row><row><cell></cell><cell></cell><cell>98.6</cell><cell>35.8</cell></row><row><cell cols="2">+Aug</cell><cell>99.9</cell><cell>37.1</cell></row><row><cell>-</cell><cell></cell><cell>99.9</cell><cell>44.8</cell></row><row><cell>?-</cell><cell>(0.5)</cell><cell>97.6</cell><cell>27.0</cell></row><row><cell>?-</cell><cell>(0.5)+Aug</cell><cell>98.7</cell><cell>27.6</cell></row><row><cell>?--</cell><cell>(0.5)</cell><cell>98.9</cell><cell>30.0</cell></row><row><cell>?-</cell><cell>(10)</cell><cell>99.4</cell><cell>36.5</cell></row><row><cell>?-</cell><cell>(10)+Aug</cell><cell>99.6</cell><cell>42.1</cell></row><row><cell>?--</cell><cell>(10)</cell><cell>99.6</cell><cell>46.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>:</cell><cell cols="2">-s generalize better than their base</cell><cell>s on almost all cases; they achieve lower</cell></row><row><cell cols="3">negative log-likelihoods. Although training the base</cell><cell>s with the augmented data improves general-</cell></row><row><cell cols="4">ization, adding the consistency regularization term further improves generalization performance.</cell></row><row><cell></cell><cell>Method</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">83.7 ? 0.3 128.2 ? 0.8 66.1 ? 0.2</cell></row><row><cell></cell><cell>+ Aug</cell><cell cols="2">82.8 ? 0.4 125.7 ? 0.2 66.0 ? 0.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>The regularization term ? affects both generalization performance and the quality of the learned representations. Many values of ? perform better than the base . However a large enough value of ?, e.g. ? = 1, can lead to worse performance than the base because for large values of ? the regularization term takes over the data-term in the objective function.</figDesc><table><row><cell></cell><cell>?</cell><cell>MI</cell><cell cols="2">AU NLL</cell></row><row><cell></cell><cell>??</cell><cell cols="2">124.5 36</cell><cell>83.7</cell></row><row><cell>-</cell><cell cols="3">0.001 125.0 38</cell><cell>83.5</cell></row><row><cell>-</cell><cell>0.01</cell><cell cols="2">125.9 41</cell><cell>82.4</cell></row><row><cell>-</cell><cell>0.1</cell><cell cols="2">126.3 47</cell><cell>81.2</cell></row><row><cell>-</cell><cell>1</cell><cell cols="2">124.3 47</cell><cell>83.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>The choice of augmentation affects both generalization performance and the quality of the learned representations. Jointly using all augmentations works best.</figDesc><table><row><cell>Augmentation</cell><cell>MI</cell><cell cols="2">AU NLL</cell></row><row><cell>Rotations only</cell><cell cols="2">125.8 45</cell><cell>82.1</cell></row><row><cell cols="3">Translations only 126.1 45</cell><cell>81.9</cell></row><row><cell>Scaling only</cell><cell cols="2">125.1 42</cell><cell>82.7</cell></row><row><cell>All</cell><cell cols="2">126.3 47</cell><cell>81.2</cell></row></table><note>rotates an image uniformly in [?15, 15] degrees clockwise. Finally the third transformation randomly scales an image by a factor uniformly sampled from [0.9, 1.1].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Theoutperforms a popular and advanced contrastive learning technique called triplet loss on both generalization performance and quality of learned representations.</figDesc><table><row><cell>Method</cell><cell>MI</cell><cell cols="2">AU NLL</cell></row><row><cell></cell><cell cols="2">124.5 36</cell><cell>83.7</cell></row><row><cell cols="3">+ augmentations 125.9 42</cell><cell>82.8</cell></row><row><cell>+ triplet loss</cell><cell cols="2">124.9 39</cell><cell>83.1</cell></row><row><cell>-</cell><cell cols="2">126.3 47</cell><cell>81.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>The -s learns better representations than the base as measured by accuracy on a downstream classification on both and -10. We get to this same conclusion when looking at the number of active units as an indicator for the quality of the learned latent representations; recovers 226 units whereas recovers 211 units. Interpolation between two samples of a lamp, airplane and table using a trained CR-FoldingNet trained on the ShapeNet dataset. The CR-FoldingNet is able to learn an interpretable latent space. classification and set new state-of-the-art values on each of the datasets, improving upon the baseline log-likelihood values. This shows the ability of consistency regularization to work at scale on challenging generative modeling tasks.</figDesc><table><row><cell></cell><cell>Method</cell><cell></cell><cell></cell><cell>-10</cell></row><row><cell></cell><cell></cell><cell></cell><cell>99.9</cell><cell>57.9</cell></row><row><cell></cell><cell cols="2">+Aug</cell><cell>99.9</cell><cell>66.4</cell></row><row><cell></cell><cell>-</cell><cell></cell><cell>99.9</cell><cell>71.4</cell></row><row><cell cols="2">Table 8: Large-scale experiments with</cell><cell></cell><cell cols="2">s with and without consistency-regularization on 3</cell></row><row><cell cols="3">benchmark datasets: dynamically binarized</cell><cell>,</cell><cell>-10 and</cell><cell>. We report generalization</cell></row><row><cell cols="2">using negative log-likelihood on</cell><cell cols="3">and bits per dim on</cell><cell>-10 and</cell><cell>. On all datasets</cell></row><row><cell cols="5">consistency regularization improves generalization performance. In particular -</cell><cell>achieves</cell></row><row><cell>state-of-the-art performance on</cell><cell cols="2">and</cell><cell>-10.</cell></row><row><cell></cell><cell cols="2">(28 ? 28)</cell><cell cols="2">-10 (32 ? 32)</cell><cell>(64 ? 64)</cell></row><row><cell></cell><cell>78.19</cell><cell></cell><cell></cell><cell>2.91</cell><cell>2.03</cell></row><row><cell>+Aug</cell><cell>77.53</cell><cell></cell><cell></cell><cell>2.70</cell><cell>1.96</cell></row><row><cell>-</cell><cell>76.93</cell><cell></cell><cell></cell><cell>2.51</cell><cell>1.86</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Code for this work can be found at https://github.com/sinhasam/CRVAE 35th Conference on Neural Information Processing Systems (NeurIPS 2021). arXiv:2105.14859v2 [cs.LG] 6 Jun 2022</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Life-long disentangled representation learning with cross-domain latent homologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eccles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Watters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.06508</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Variational autoencoder based anomaly detection using reconstruction probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Special Lecture on IE</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning with pseudo-ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Alsharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3365" to="3373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Generating sentences from a continuous space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06349</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00519</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Importance weighted autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03012</idno>
		<title level="m">An information-rich 3d model repository</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Avoiding latent variable collapse with generative skip models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Dieng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.04863</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Topic modeling in embedding spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Dieng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.04907</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Implicit deep latent variable models for text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1908.11527</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Cyclical annealing schedule: A simple approach to mitigating kl vanishing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10145</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Draw: A recurrent neural network for image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.04623</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Glsr-vae: Geodesic latent space regularization for variational autoencoder architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hadjeres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pachet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Symposium Series on Computational Intelligence (SSCI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Spokoyny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.05534</idno>
		<title level="m">T. Lagging inference networks and posterior collapse in variational autoencoders</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerchner</surname></persName>
		</author>
		<title level="m">Learning basic visual concepts with a constrained variational framework. Iclr</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distribution augmentation for generative modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5006" to="5019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.02550</idno>
		<title level="m">Semi-amortized variational autoencoders</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.5298</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Image augmentation is all you need: Regularizing deep reinforcement learning from pixels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kostrikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fergus</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13649</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02242</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">One shot learning of simple visual concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the annual meeting of the cognitive science society</title>
		<meeting>the annual meeting of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Variational autoencoders for collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jebara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference</title>
		<meeting>the 2018 World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="689" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Large-scale celebfaces attributes (celeba) dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-08" />
			<biblScope unit="volume">15</biblScope>
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Neural variational inference for text processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1727" to="1736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-I</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Regularization with latent space virtual adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Osada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ahsan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Bora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nishide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="565" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.4082</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Contractive auto-encoders: Explicit invariance during feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A hierarchical latent vector model for learning long-term structure in music</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hawthorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05428</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Surprisingly simple self-supervision for offline reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.06326</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Variational adversarial active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5972" to="5981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tolstikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schoelkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.01558</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Wasserstein auto-encoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nvae</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.03898</idno>
		<title level="m">A deep hierarchical variational autoencoder</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">An uncertain future: Forecasting from static images using variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="835" to="851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Improving the improved training of wasserstein gans: A consistency term and its dual effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01541</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12848</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Point cloud auto-encoder via deep grid deformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Foldingnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="206" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Consistency regularization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Context-encoding variational autoencoder for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zimmerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.05941</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
