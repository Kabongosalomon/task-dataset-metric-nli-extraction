<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ming</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Huawei Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Huawei Inc</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Boundary discontinuity and its inconsistency to the final detection metric have been the bottleneck for rotating detection regression loss design. In this paper, we propose a novel regression loss based on Gaussian Wasserstein distance as a fundamental approach to solve the problem. Specifically, the rotated bounding box is converted to a 2-D Gaussian distribution, which enables to approximate the indifferentiable rotational IoU induced loss by the Gaussian Wasserstein distance (GWD) which can be learned efficiently by gradient back-propagation. GWD can still be informative for learning even there is no overlapping between two rotating bounding boxes which is often the case for small object detection. Thanks to its three unique properties, GWD can also elegantly solve the boundary discontinuity and square-like problem regardless how the bounding box is defined. Experiments on five datasets using different detectors show the effectiveness of our approach. Codes are made public available 12 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Arbitrary-oriented objects are ubiquitous for detection across visual datasets, such as aerial images <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b68">69]</ref>, scene text <ref type="bibr" target="#b82">[83,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b26">27]</ref>, faces <ref type="bibr" target="#b46">[47]</ref> and 3D objects <ref type="bibr" target="#b78">[79]</ref>, retail scenes <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b40">41]</ref>, etc. Compared with the large literature on horizontal object detection <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b5">6]</ref>, research in oriented object detection is relatively in its earlier stage, with many open problems to solve.</p><p>The dominant line of works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b66">67</ref>] take a regression methodology to predict the rotation angle, which has achieved state-of-the-art performance. However, compared with traditional horizontal detectors, the angle regression model will bring new issues, as summarized as follows: i) * Work done during an internship at Huawei Inc. ? Corresponding author is Junchi Yan. <ref type="bibr" target="#b0">1</ref>  the inconsistency between metric and loss, ii) boundary discontinuity, and iii) square-like problem. In fact, these issues remain open without a unified solution, and they can largely hurt the final performance especially at the boundary position, as shown in the left of <ref type="figure" target="#fig_0">Fig. 1</ref>. In this paper, we use a two-dimensional Gaussian distribution to model an arbitrary-oriented bounding box for object detection, and approximate the indifferentiable rotational Intersection over Union (IoU) induced loss between two boxes by calculating their Gaussian Wasserstein Distance (GWD) <ref type="bibr" target="#b2">[3]</ref>. GWD elegantly aligns model learning with the final detection accuracy metric, which has been a bottleneck and not achieved in existing rotation detectors. Our GWD based detectors are immune from both boundary discontinuity and square-like problem, and this immunity is independent with how the bounding box protocol is defined, as shown on the right of <ref type="figure" target="#fig_0">Fig. 1</ref>. The highlights of this paper are four-folds: i) We summarize three flaws in state-of-the-art rotation detectors, i.e. inconsistency between metric and loss, boundary discontinuity, and square-like problem, due to their regression based angle prediction nature.</p><p>ii) We propose to model the rotating bounding box distance by Gaussian Wasserstein Distance (GWD) which leads to an approximate and differentiable IoU induced loss. It resolves the loss inconsistency by aligning model learning with accuracy metric and thus naturally improves the model. iii) Our GWD-based loss can elegantly resolve boundary discontinuity and square-like problem, regardless how the rotating bounding box is defined. In contrast, the design of most peer works <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b63">64]</ref> are coupled with the parameterization of bounding box. iv) Extensive experimental results on five public datasets and two popular detectors show the effectiveness of our approach. The source codes <ref type="bibr" target="#b69">[70,</ref><ref type="bibr" target="#b83">84]</ref> are made public available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In this paper, we mainly discuss the related work on rotating object detection. Readers are referred to <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref> for more comprehensive literature review on horizontal object detection.</p><p>Rotated object detection. As an emerging direction, advance in this area try to extend classical horizontal detectors to the rotation case by adopting the rotated bounding boxes. Compared with the few works <ref type="bibr" target="#b65">[66]</ref> that treat the rotation detection tasks an angle classification problem, regression based detectors still dominate which have been applied in different applications. For aerial images, ICN <ref type="bibr" target="#b1">[2]</ref>, ROI-Transformer <ref type="bibr" target="#b7">[8]</ref>, SCRDet <ref type="bibr" target="#b68">[69]</ref> and Gliding Vertex <ref type="bibr" target="#b61">[62]</ref> are two-stage representative methods whose pipeline comprises of object localization and classification, while DRN <ref type="bibr" target="#b40">[41]</ref>, R 3 Det <ref type="bibr" target="#b66">[67]</ref> and RSDet <ref type="bibr" target="#b41">[42]</ref> are singlestage methods. For scene text detection, RRPN <ref type="bibr" target="#b34">[35]</ref> employ rotated RPN to generate rotated proposals and further perform rotated bounding box regression. TextBoxes++ <ref type="bibr" target="#b25">[26]</ref> adopts vertex regression on SSD. RRD <ref type="bibr" target="#b26">[27]</ref> further improves TextBoxes++ by decoupling classification and bounding box regression on rotation-invariant and rotation sensitive features, respectively. We discuss the specific challenges in existing regressors for rotation detection.</p><p>Boundary discontinuity and square-like problems. Due to the periodicity of angle parameters and the diversity of bounding box definitions, regression-based rotation detectors often suffer from boundary discontinuity and squarelike problem. Many existing methods try to solve part of the above problems from different perspectives. For instance, SCRDet <ref type="bibr" target="#b68">[69]</ref> and RSDet <ref type="bibr" target="#b41">[42]</ref> propose IoU-smooth L1 loss and modulated loss to smooth the the boundary loss jump. CSL <ref type="bibr" target="#b65">[66]</ref> transforms angular prediction from a regression problem to a classification one. DCL <ref type="bibr" target="#b63">[64]</ref> further solves square-like object detection problem introduced by the long edge definition, which refers to rotation insensitivity issue for instances that are approximately in square shape, which will be detailed in Sec. 3.</p><p>Approximate differentiable rotating IoU loss. It has been shown in classic horizontal detectors that the use of IoU induced loss e.g. GIoU <ref type="bibr" target="#b44">[45]</ref>, DIoU <ref type="bibr" target="#b79">[80]</ref> can ensure the consistency of the final detection metric and loss. However, these IoU loss cannot be applied directly in rotation detec- tion because the rotating IoU is indifferentiable. Many efforts have been made to finding an approximate IoU loss for gradient computing. PIoU <ref type="bibr" target="#b4">[5]</ref> is realized by simply counting the number of pixels. To tackle the uncertainty of convex caused by rotation, <ref type="bibr" target="#b78">[79]</ref> proposes a projection operation to estimate the intersection area. SCRDet <ref type="bibr" target="#b68">[69]</ref> combines IoU and smooth L1 loss to develop an IoU-smooth L1 loss, which partly circumvents the need for differentiable rotating IoU loss.</p><p>So far, there exists no truly unified solution to all the above problems which are in fact interleaved to each other. Our method addresses all these issues in a unified manner. It is also decoupled from the specific definition of bounding box. All these merits make our approach elegant and effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Rotated Object Regression Detector Revisit</head><p>To motivate this work, in this section, we introduce and analyze some deficiencies in state-of-the-art rotating detectors, which are mostly based on angle regression. <ref type="figure" target="#fig_1">Fig. 2</ref> gives two popular definitions for parameterizing rotating bounding box based angles: OpenCV protocol denoted by D oc , and long edge definition by D le . Note ? ? [?90 ? , 0 ? ) of the former denotes the acute or right angle between the w oc of bounding box and x-axis. In contrast, ? ? [?90 ? , 90 ? ) of the latter definition is the angle between the long edge w le of bounding box and x-axis. The two kinds of parameterization can be converted to each other:  The main difference refers to the edge and angle (w, h, ?): when the same bounding box takes different representations by the two definitions, the order of the edges is exchanged and the angle difference is 90 ? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Bounding Box Definition</head><formula xml:id="formula_0">D le (w le ,</formula><formula xml:id="formula_1">D oc (w oc , h oc , ? oc ) = D le (w le , h le , ? le ), ? le ? [?90 ? , 0 ? ) D le (h le , w le , ? le ? 90 ? ), otherwise</formula><p>In many works, the pipeline design are tightly coupled with the choice of the bounding box definition to avoid specific problems: SCRDet <ref type="bibr" target="#b68">[69]</ref>, R 3 Det <ref type="bibr" target="#b66">[67]</ref> are based on D oc to avoid the square-like problem, while CSL <ref type="bibr" target="#b65">[66]</ref>, DCL <ref type="bibr" target="#b63">[64]</ref> resort to D le to avoid the exchangeability of edges (EoE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Inconsistency between Metric and Loss</head><p>Intersection over Union (IoU) has been the standard metric for both horizontal detection and rotation detection. However, there is an inconsistency between the metric and regression loss (e.g. l n -norms), that is, a smaller training loss cannot guarantee a higher performance, which has been extensively discussed in horizontal detection <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b79">80]</ref>. This misalignment becomes more prominent in rotating object detection due to the introduction of angle parameter in regression based models. To illustrate this, we use <ref type="figure" target="#fig_2">Fig. 3</ref> to compare IoU induced loss and smooth L1 loss <ref type="bibr" target="#b12">[13]</ref>:</p><p>Case 1: <ref type="figure" target="#fig_2">Fig. 3a</ref> depicts the relation between angle difference and loss functions. Though they all bear monotonicity, only smooth L1 curve is convex while the others are not.</p><p>Case 2: <ref type="figure" target="#fig_2">Fig. 3b</ref> shows the changes of the two loss functions under different aspect ratio conditions. It can be seen that the smooth L1 loss of the two bounding box are constant (mainly from the angle difference), but the IoU loss will change drastically as the aspect ratio varies.</p><p>Case 3: <ref type="figure" target="#fig_2">Fig. 3c</ref> explores the impact of center point shifting on different loss functions. Similarly, despite the same monotonicity, there is no high degree of consistency.</p><p>Seeing the above flaws of classic smooth L1 loss, IoUinduced loss has become recently popular for horizontal detection e.g. GIoU <ref type="bibr" target="#b44">[45]</ref>, DIoU <ref type="bibr" target="#b79">[80]</ref>. It can help fill the gap between metric and regression loss for rotating object detection. However, different from horizontal detection, the IoU of two rotating boxes is indifferentiable for learning. In this paper, we propose a differentiable loss based on Wasserstein distance of two rotating boxes to replace the hard IoU loss. It is worth mentioning that the Wasserstein distance function has some unique properties to solve boundary discontinuity and square-like problem, which will be detailed later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Boundary Discontinuity and Square-Like Problem</head><p>As a standing issue for regression-based rotation detectors, the boundary discontinuity <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b65">66]</ref> in general refers to the sharp loss increase at the boundary induced by the angle and edge parameterization.</p><p>Specifically, Case 1-2 in <ref type="figure" target="#fig_3">Fig. 4</ref> summarize the boundary discontinuity. Take Case 2 as an example, we assume that there is a red anchor/proposal (0, 0, 70, 10, ?90 ? ) and a green ground truth (0, 0, 10, 70, ?25 ? ) at the boundary position <ref type="bibr" target="#b2">3</ref> , both of which are defined in OpenCV definition D oc . The upper right corner of <ref type="figure" target="#fig_3">Fig. 4</ref> shows two ways to regress from anchor/proposal to ground truth. The way1 achieves the goal by only rotating anchor/proposal by an angle counterclockwise, but a very large smooth L1 loss occurs at this time due to the periodicity of angle (PoA) and the exchangeability of edges (EoE). As discussed in CSL <ref type="bibr" target="#b65">[66]</ref>, this is because the result of the prediction box (0, 0, 70, 10, ?115 ? ) is outside the defined range. As a result, the model has to make predictions in other complex regression forms, such as rotating anchor/proposal by an large angle clockwise to the blue box while scaling w and h (way2 in Case 2). A similar problem (only PoA) also occurs in the long edge definition D le , as shown in Case 1.</p><p>In fact, when the predefined anchor/proposal and ground truth are not in the boundary position, way1 will not produce a large loss. Therefore, there exists inconsistency between the boundary position and the non-boundary position regression, which makes the model very confused about in which way it should perform regression. Since non-boundary cases account for the majority, the regression results of models, especially those with weaker learning capacity, are fragile in boundary cases, as shown in the left of <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>In addition, there is also a square-like object detection problem in the D le -based method <ref type="bibr" target="#b63">[64]</ref>. First of all, the D le cannot uniquely define a square bounding box. For square-like objects <ref type="bibr" target="#b3">4</ref> , D le -based method will encounter high IoU but high loss value similar to the boundary discontinuity, as shown by the upper part of Case 3 in <ref type="figure" target="#fig_3">Fig. 4</ref>. In way1, the red anchor/proposal (0, 0, 45, 44, 0 ? ) rotates a small angle clockwise to get the blue prediction box. The IoU of ground truth (0, 0, 45, 43, ?60 ? ) and the prediction box (0, 0, 45, 44, 30 ? ) is close to 1, but the regression loss is high due to the inconsistency of angle parameters. Therefore, the model will rotate a larger angle counterclockwise to make predictions, as described by way2. The reason for the square-like problem in D le -based method is not the above-mentioned PoA and EoE, but the inconsistency of evaluation metric and loss. In contrast, the negative impact of EoE will be weakened when we use D oc -based method to detect square-like objects, as shown in the comparison between Case 2 and the lower part of Case 3. Therefore, there is no square-like problem in the D oc -based method.</p><p>Recent methods start to address these issues. SCRDet <ref type="bibr" target="#b68">[69]</ref> combines IoU and smooth L1 loss to propose a IoU-smooth L1 loss, which does not require the rotating IoU being differentiable. It also solves the problem of inconsistency between loss and metric by eliminating the discontinuity of loss at the boundary. However, SCRDet still needs to determine whether the predicted bounding box result conforms to the current bounding box definition method before calculating the IoU. In addition, the gradient direction of IoU-Smooth L1 Loss is still dominated by smooth L1 loss. RSDet <ref type="bibr" target="#b41">[42]</ref> devises modulated loss to smooth the loss mutation at the boundary, but it needs to calculate the loss of as many parameter combinations as possible. CSL <ref type="bibr" target="#b65">[66]</ref> transforms angular prediction from a regression problem to a classification problem. CSL needs to carefully design their method according to the bounding box definition (D le ), and is limited by the classification granularity with theoretical limitation for high-precision angle prediction. On the basis of CSL, DCL <ref type="bibr" target="#b63">[64]</ref> further solves the problem of square-like object detection introduced by D le .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The Proposed Method</head><p>In this section we introduce a new rotating object detector whose regression loss fulfills the following requirements:</p><p>Requirement 1: highly consistent with the IoU induced metrics (which also solves the square-like object problem); Requirement 2: differentiable allowing for direct learning;</p><p>Requirement 3: smooth at angle boundary case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Wasserstein Distance for Rotating Box</head><p>Most of the IoU-based loss can be considered as a distance function. Inspired by this, we propose a new regression loss based on Wasserstein distance. First, we convert a rotating bounding box B(x, y, w, h, ?) into a 2-D Gaussian distribution N (m, ?) (see <ref type="figure" target="#fig_4">Fig. 5</ref>) by the following formula:</p><formula xml:id="formula_2">? 1/2 =RSR = cos ? ? sin ? sin ? cos ? w 2 0 0 h 2 cos ? sin ? ? sin ? cos ? = w 2 cos 2 ? + h 2 sin 2 ? w?h 2 cos ? sin ? w?h 2 cos ? sin ? w 2 sin 2 ? + h 2 cos 2 ? m =(x, y)<label>(1)</label></formula><p>where R represents the rotation matrix, and S represents the diagonal matrix of eigenvalues. The Wasserstein distance W between two probability measures ? and ? on R n expressed as <ref type="bibr" target="#b2">[3]</ref>:</p><formula xml:id="formula_3">W(?; ?) := inf E( X ? Y 2 2 ) 1/2<label>(2)</label></formula><p>where the inferior runs over all random vectors (X, Y) of R n ? R n with X ? ? and Y ? ?. It turns out that we have d := W(N (m 1 , ? 1 ); N (m 2 , ? 2 )) and it writes as:</p><formula xml:id="formula_4">d 2 = m1 ? m2 2 2 + Tr ?1 + ?2 ? 2(? 1/2 1 ?2? 1/2 1 ) 1/2<label>(3)</label></formula><p>This formula has interested several works <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b8">9]</ref>. Note in particular we have:</p><formula xml:id="formula_5">Tr (? 1/2 1 ?2? 1/2 1 ) 1/2 = Tr (? 1/2 2 ?1? 1/2 2 ) 1/2<label>(4)</label></formula><p>In the commutative case (horizontal detection task)</p><formula xml:id="formula_6">? 1 ? 2 = ? 2 ? 1 , Eq. 3 becomes: d 2 = m1 ? m2 2 2 + ? 1/2 1 ? ? 1/2 2 2 F =(x1 ? x2) 2 + (y1 ? y2) 2 + (w1 ? w2) 2 + (h1 ? h2) 2 4 =l2-norm x1, y1, w1 2 , h1 2 , x2, y2, w2 2 , h2 2 (5)</formula><p>where F is the Frobenius norm. Note that both boxes are horizontal here, and Eq. 5 is approximately equivalent to the l 2 -norm loss (note the additional denominator of 2 for w and h), which is consistent with the loss commonly used in horizontal detection. This also partly proves the correctness of using Wasserstein distance as the regression loss. See appendix for the detailed proof <ref type="bibr" target="#b2">[3]</ref> of Eq. 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Gaussian Wasserstein Distance Regression Loss</head><p>Note that GWD alone can be sensitive to large errors. We perform a nonlinear transformation f and then convert GWD into an affinity measure 1 ? +f (d 2 ) similar to IoU between two bounding boxes. Then we follow the standard IoU based loss form in detection literature <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b79">80]</ref>, as written by:</p><formula xml:id="formula_7">L gwd = 1 ? 1 ? + f (d 2 )</formula><p>, ? ? 1 <ref type="bibr" target="#b5">(6)</ref> where f (?) denotes a non-linear function to transform the Wasserstein distance d 2 to make the loss more smooth and expressive. The hyperparameter ? modulates the entire loss. <ref type="figure" target="#fig_2">Fig. 3a</ref> plots the function curve under different different combinations of f (?) and ? . Compared with the smooth L1 loss, the curve of Eq. 6 is more consistent with the IoU loss curve. Furthermore, we can find in <ref type="figure" target="#fig_2">Fig. 3c</ref> that GWD still can measure the distance between two non-overlapping bounding boxes (IoU=0), which is exactly the problem that GIoU and DIoU try to solve in horizontal detection. However, they cannot be applied for rotating detection.</p><p>Obviously, GWD has met the first two requirements in terms of consistency and differentiability with IoU loss. To analyze Requirement 3, we first give basic properties of Eq. 1:</p><formula xml:id="formula_8">Property 1: ? 1/2 (w, h, ?) = ? 1/2 (h, w, ? ? ? 2 ); Property 2: ? 1/2 (w, h, ?) = ? 1/2 (w, h, ? ? ?); Property 3: ? 1/2 (w, h, ?) ? ? 1/2 (w, h, ? ? ? 2 ), if w ? h.</formula><p>From the two bounding box definitions recall that the conversion between two definitions is, the two sides are exchanged and the angle difference is 90 ? . Many methods are designated inherently according to the choice of definition in advance to solve some problems, such as D le for EoE and D oc for square-like problem. It is interesting to note that according to Property 1, definition D oc and D le are equivalent for the GWD-based loss, which makes our method free from the choice of box definitions. This does not mean that the final performance of the two definition methods will be the same. Different factors such as angle definition and angle regression range will still cause differences in model learning, but the GWD-based method does not need to bind a certain definition method to solve the problem.</p><p>GWD can also help resolve the boundary discontinuity and square-like problem. The prediction box and ground truth in way1 of Case 1 in <ref type="figure" target="#fig_3">Fig. 4</ref> satisfy the following relation: x p = x gt , y p = y gt , w p = h gt , h p = w gt , ? p = ? gt ? ? 2 . According to Property 1, the Gaussian distribution corresponding to these two boxes are the same (in the sense of same mean m and covariance ?), so it naturally eliminates the ambiguity in box representation. Similarly, according to Properties 2-3, the ground truth and prediction box in way1 of Case 1 and Case 3 in <ref type="figure" target="#fig_3">Fig. 4</ref> are also the same or nearly the same (note the approximate equal symbol for w ? h for square-like boxes) Gaussian distribution. Through the above analysis, we know GWD meets Requirement 3.</p><p>Overall, GWD is a unified solution to all the requirements and its advantages in rotating detection can be summarized:</p><p>i) GWD makes the two bounding box definition methods equivalent, which enables our method to achieve significant improvement regardless how the bounding box is defined.</p><p>ii) GWD is a differentiable IoU loss approximation for rotating bounding box, which maintains a high consistency with the detection metric. GWD can also measure the distance between non-overlapping rotating bounding boxes and has properties similar to GIoU and DIoU for the horizontal case.</p><p>iii) GWD inherently avoids the interference of boundary discontinuity and square-like problem, so that the model can learn in more diverse forms of regression, eliminate the inconsistency of regression under boundary and nonboundary positions, and reduce the learning cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Overall Loss Function Design</head><p>In line with <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b66">67]</ref>, we use the one-stage detector RetinaNet <ref type="bibr" target="#b28">[29]</ref> as the baseline. Rotated rectangle is represented by five parameters (x, y, w, h, ?). In our experiments we mainly follow D oc , and the regression equation is as follows:</p><formula xml:id="formula_9">tx = (x ? xa)/wa, ty = (y ? ya)/ha tw = log(w/wa), t h = log(h/ha), t ? = ? ? ?a t * x = (x * ? xa)/wa, t * y = (y * ? ya)/ha t * w = log(w * /wa), t * h = log(h * /ha), t * ? = ? * ? ?a<label>(7)</label></formula><p>where x, y, w, h, ? denote the box's center coordinates, width, height and angle, respectively. Variables    <ref type="table">Table 3</ref>: Ablation study for GWD on two scene text datasets.</p><formula xml:id="formula_10">x, x a , x * 1 ? 1 (?+f(d 2 )) ? = 1 ? = 2 ? = 3 ? = 5 d 2 f (?) =</formula><p>are for the ground-truth box, anchor box, and predicted box, respectively (likewise for y, w, h, ?). The multi-task loss is:</p><formula xml:id="formula_11">L = ?1 N N n=1 objn ? L gwd (bn, gtn) + ?2 N N n=1</formula><p>L cls (pn, tn) <ref type="bibr" target="#b7">(8)</ref> where N indicates the number of anchors, obj n is a binary value (obj n = 1 for foreground and obj n = 0 for background, no regression for background). b n denotes the n-th predicted bounding box, gt n is the n-th target ground-truth. t n represents the label of n-th object, p n is the n-th probability distribution of various classes calculated by sigmoid function. The hyper-parameter ? 1 , ? 2 control the trade-off and are set to {1, 2} by default. The classification loss L cls is set as the focal loss <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We use Tensorflow <ref type="bibr" target="#b0">[1]</ref> for implementation on a server with Tesla V100 and 32G memory. <ref type="table" target="#tab_2">ID   MOETHOD  BACKBONE SCHED. DA MS MSC SWA ME  PL  BD  BR  GTF  SV  LV  SH  TC  BC  ST  SBF  RA  HA  SP  HC   MAP50   #1   RETINANET-GWD   R-50  20</ref> 88. <ref type="bibr" target="#b48">49</ref>    <ref type="table">Table 5</ref>: High-precision detection experiment on HRSC206 data set. The image resolution is 512, and data augmentation is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Datasets and Implementation Details</head><p>DOTA <ref type="bibr" target="#b56">[57]</ref> is comprised of 2,806 large aerial images from different sensors and platforms. Objects in DOTA exhibit a wide variety of scales, orientations, and shapes. These images are then annotated by experts using 15 object categories. The short names for categories are defined as (abbreviation-full name): PL-Plane, BD-Baseball diamond, BR-Bridge, GTF-Ground field track, SV-Small vehicle, LV-Large vehicle, SH-Ship, TC-Tennis court, BC-Basketball court, ST-Storage tank, SBF-Soccer-ball field, RA-Roundabout, HA-Harbor, SP-Swimming pool, and HC-Helicopter. The fully annotated DOTA benchmark contains 188,282 instances, each of which is labeled by an arbitrary quadrilateral. Half of the original images are randomly selected as the training set, 1/6 as the validation set, and 1/3 as the testing set. We divide the images into 600 ? 600 subimages with an overlap of 150 pixels and scale it to 800 ? 800. With all these processes, we obtain about 20,000 training and 7,000 validation patches.</p><p>UCAS-AOD [85] contains 1,510 aerial images of about 659 ? 1, 280 pixels, with 2 categories of 14,596 instances. In line with <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b56">57]</ref>, we sample 1,110 images for training and 400 for testing.</p><p>HRSC2016 <ref type="bibr" target="#b32">[33]</ref> contains images from two scenarios including ships on sea and ships close inshore. The training, validation and test set include 436, 181 and 444 images, respectively.</p><p>ICDAR2015 <ref type="bibr" target="#b20">[21]</ref> is commonly used for oriented scene text detection and spotting. This dataset includes 1,000 training images and 500 testing images.</p><p>ICDAR 2017 MLT <ref type="bibr" target="#b37">[38]</ref> is a multi-lingual text dataset, which includes 7,200 training images, 1,800 validation images and 9,000 testing images. The dataset is composed of complete scene images in 9 languages, and text regions in this dataset can be in arbitrary orientations, being more diverse and challenging.</p><p>Experiments are initialized by ResNet50 <ref type="bibr" target="#b15">[16]</ref> by default unless otherwise specified. We perform experiments on three aerial benchmarks and two scene text benchmarks to verify the generality of our techniques. Weight decay and momentum are set 0.0001 and 0.9, respectively. We employ MomentumOptimizer over 8 GPUs with a total of 8 images per mini-batch (1 image per GPU). All the used datasets are trained by 20 epochs in total, and learning rate is reduced tenfold at 12 epochs and 16 epochs, respectively. The initial learning rates for RetinaNet is 5e-4. The number of image <ref type="table">Table 6</ref>: Comparison between different solutions for inconsistency between metric and loss (IML), boundary discontinuity (BD) and square-like problem (SLP) on DOTA dataset. The indicates that the method has corresponding problem. ? and ? represent the large aspect ratio object and the square-like object, respectively. The bold red and blue fonts indicate the top two performances respectively. <ref type="bibr">BASE</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Ablation Study</head><p>Ablation test of GWD-based regression loss form and hyperparameter: Tab. 1 compares two different forms of GWD-based loss. The performance of directly using GWD METHOD BACKBONE MAP50 (07) <ref type="bibr">MAP50</ref>   <ref type="table">Table 8</ref>: Detection accuracy on HRSC2016.</p><p>(d 2 ) as the regression loss is extremely poor, only 49.11%, due to its rapid growth trend. In other words, the regression loss d 2 is too sensitive to large errors. In contrast, Eq. 6 achieves a significant improvement by fitting IoU loss. Eq. 6 introduces two new hyperparameters, the non-linear function f (?) to transform the Wasserstein distance, and the constant ? to modulate the entire loss. From Tab. 1, the overall performance of using sqrt outperforms that using log, about 0.98?0.3% higher. For f (?) = sqrt with ? = 2, the model achieves the best performance, about 68.93%. All the subsequent experiments follow this setting for hyperparameters unless otherwise specified. Ablation test with different rotating box definitions: As mentioned above, definition D oc and D le are equivalent for the GWD-based loss according to Property 1, which makes our method free from the choice of box definitions. This does not mean that the final performance of the two definition methods will be the same, but that the GWDbased method does not need to bind a certain definition method to solve the boundary discontinuity or square-like problem. Tab. 2 compares the performance of RetinaNet under different regression loss on DOTA, and both rotating box definitions: D le and D oc are tested. For the smooth L1 loss, the accuracy of D le -based method is 1.56% lower than D le -based, at 64.17% and 65.73%, respectively. GWDbased method does not need to be coupled with a certain definition to solve boundary discontinuity or square-like problem, it has increased by 2.14% and 3.20% under above two definitions.</p><p>Ablation test across datasets and detectors: We use two detectors on five datasets to verify the effectiveness of GWD. When RetinaNet is used as the base detector in Tab.</p><p>2, the GWD-based detector is improved by 1.28%, 0.88%, 3.20%, 2.14% under three different aerial image datasets of HRSC206, UCAS-AOD and DOTA, respectively. Note that to increase the reliability of the results from small dataset, the experiments of the first two datasets have involved additional data augmentation, including random graying and random rotation. The rotation detector R 3 Net [67] achieves the state-of-the-art performance on large-scale DOTA. It can be seen that GWD further improves the performance by 0.90%. Tab. 3 also gives ablation test on two scene text datasets. There are a large number of objects in the boundary position in scene text, so the GWD-based RetinaNet has obtained a notable gain -increased by 6.16% and 4.51% on the MLT and ICDAR2015 datasets, respectively. Even with the use of data augmentation or a stronger detector R 3 Det, GWD can still obtain a stable gain, with an improvement range from 1.31% to 1.56%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Training Strategies and Tricks</head><p>In order to further improve the performance of the model on DOTA, we verified many commonly used training strategies and tricks, including backbone, training schedule, data augmentation (DA), multi-scale training and testing (MS), stochastic weights averaging (SWA) <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b75">76]</ref> Training schedule: When data augmentation and multiscale training are added, it is necessary to appropriately lengthen the training time. From the experimental groups {#3,#5} and {#16,#29}, we can find that the performance respectively increases by 0.77% and 1.22% when the training schedule is increased from 40 or 30 epochs to 60 epochs.</p><p>Stochastic weights averaging (SWA): SWA technique has been proven to be an effective tool for improving object detection. In the light of <ref type="bibr" target="#b75">[76]</ref>, we train our detector for an extra 12 epochs using cyclical learning rates and then average these 12 checkpoints as the final detection model. It can be seen from experimental groups {#1, #2}, {#20, #21} and {#25, #26} in Tab. 4 that we get 0.99%, 1.20% and 1.13% improvement on the challenging DOTA benchmark.</p><p>Multi-scale image cropping: Large-scene object de-tection often requires image sliding window cropping before training. During testing, sliding window cropping testing is required before the results are merged. Two adjacent sub-images often have an overlapping area to ensure that the truncated object can appear in a certain sub-image completely. The cropping size needs to be moderate, too large is not conducive to the detection of small objects, and too small will cause large objects to be truncated with high probability. Multi-scale cropping is an effective detection technique that is beneficial to objects of various scales. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Further Comparison</head><p>High precision detection: The advantage of aligning detection metric and loss is that a higher precision prediction box can be learned. Object with large aspect ratios are more sensitive to detection accuracy, so we conduct high-precision detection experiments on the ship dataset HRSC2016. It can be seen in Tab. 5 that our GWD-based detector exhibits clear advantages under high IoU thresholds. Taking AP 75 as an example, GWD has achieved improvement by 11.89% and 22.46% on the two detectors, respectively. We also compares the peer techniques, mainly including IoU-Smooth L1 Loss <ref type="bibr" target="#b68">[69]</ref>, CSL <ref type="bibr" target="#b65">[66]</ref>, and DCL [64] on DOTA validation set. As shown on the right of Tab. 6, the GWD-based method achieves the highest performance on mAP 75 and mAP 50:95 , at 38.68% and 38.71%.</p><p>Comparison of techniques to solve the regression issues: For the three issues of inconsistency between metric and loss, boundary discontinuity and square-like problem, Tab. 6 compares the five peer techniques, including IoU-Smooth L1 Loss, Modulated loss, CSL, and DCL on DOTA test set. For fairness, these methods are all implemented on the same baseline method, and are trained and tested under the same environment and hyperparameters.</p><p>In particular, we detail the accuracy of the seven categories, including large aspect ratio (e.g. BR, SV, LV, SH, HA) and square-like object (e.g. ST, RD), which contain many corner cases in the dataset. These categories are assumed can better reflect the real-world challenges and advantages of our method. Many methods that solve the boundary discontinuity have achieved significant improvements in the large aspect ratio object category, and the methods that take into account the square-like problem perform well in the square-like object, such as GWD, DCL and Modulated loss.</p><p>However, there is rarely a unified method to solve all problems, and most methods are proposed for part of problems. Among them, the most comprehensive method is IoU-Smooth L1 Loss. However, the gradient direction of IoU-Smooth L1 Loss is still dominated by smooth L1 loss, so the metric and loss cannot be regarded as truly consistent. Besides, IoU-Smooth L1 Loss needs to determine whether the prediction box is within the defined range before calculating IoU at the boundary position, Otherwise, it needs to convert to the same definition as ground truth. In contrast, due to the three unique properties of GWD, it need to make additional judgments to elegantly solve all problems. From Tab. 6, GWD outperforms on most categories. For the seven listed categories (7-mAP) and overall performance (mAP), GWD-based methods are also the best. <ref type="figure" target="#fig_0">Fig. 1</ref> visualizes the comparison between Smooth L1 loss-based and GWDbased detector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Comprehensive Overall Comparison</head><p>Results on DOTA: Due to the complexity of the aerial image and the large number of small, cluttered and rotated objects, DOTA is a very challenging dataset. We compare the proposed approach with other state-of-the-art methods on DOTA, as shown in Tab. 7. As far as I know, this is the most comprehensive statistical comparison of methods on the DOTA dataset. Since different methods use different image resolution, network structure, training strategies and various tricks, we cannot make absolutely fair comparisons. In terms of overall performance, our method has achieved the best performance so far, at around 80.23%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results on HRSC2016:</head><p>The HRSC2016 contains lots of large aspect ratio ship instances with arbitrary orientation, which poses a huge challenge to the positioning accuracy of the detector. Experimental results at Tab. 8 shows that our model achieves state-of-the-art performances, about 89.85% and 97.37% in term of 2007 and 2012 evaluation metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper has presented a Gaussian Wasserstain distance based loss to model the deviation between two rotating bounding boxes for object detection. The designated loss directly aligns with the detection accuracy and the model can be efficiently learned via back-propagation. More importantly, thanks to its three unique properties, GWD can also elegantly solve the boundary discontinuity and square-like problem regardless how the bounding box is defined. Experimental results on extensive public benchmarks show the state-of-the-art performance of our detector.</p><p>The entire proof process refers to this blog <ref type="bibr" target="#b2">[3]</ref>. The Wasserstein coupling distance W between two probability measures ? and ? on R n expressed as follows:</p><formula xml:id="formula_12">W(?; ?) := inf E( X ? Y 2 2 ) 1/2<label>(9)</label></formula><p>where the infimum runs over all random vectors (X, Y) of R n ? R n with X ? ? and Y ? ?. It turns out that we have the following formula for d := W(N (m 1 , ? 1 ); N (m 2 , ? 2 )):</p><formula xml:id="formula_13">d 2 = m 1 ? m 2 2 2 + Tr ? 1 + ? 2 ? 2(? 1/2 1 ? 2 ? 1/2 1 ) 1/2</formula><p>(10) This formula interested several works <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b8">9]</ref>. Note in particular we have:</p><formula xml:id="formula_14">Tr (? 1/2 1 ? 2 ? 1/2 1 ) 1/2 = Tr (? 1/2 2 ? 1 ? 1/2 2 ) 1/2</formula><p>(11) In the commutative case ? 1 ? 2 = ? 2 ? 1 , Eq. 10 becomes:</p><formula xml:id="formula_15">d 2 = m 1 ? m 2 2 2 + ? 1/2 1 ? ? 1/2 2 2 F =(x 1 ? x 2 ) 2 + (y 1 ? y 2 ) 2 + (w 1 ? w 2 ) 2 + (h 1 ? h 2 ) 2 4</formula><p>=l 2 -norm x 1 , y 1 , w 1 2 , h 1 2 , x 2 , y 2 , w 2 2 , h 2 2 (12) where F is the Frobenius norm. Note that both boxes are horizontal at this time, and Eq. 12 is approximately equivalent to the l 2 -norm loss (note the additional denominator of 2 for w and h), which is consistent with the loss commonly used in horizontal detection. This also partly proves the correctness of using Wasserstein distance as the regression loss.</p><p>To prove Eq. 10, one can first reduce to the centered case m 1 = m 2 = 0. Next, if (X, Y) is a random vector (Gaussian or not) of R n ? R n with covariance matrix</p><formula xml:id="formula_16">? = ? 1 C C ? 2<label>(13)</label></formula><p>then the quantity E( X, Y 2 2 ) = Tr(? 1 + ? 2 ? 2C)</p><p>depends only on ?. Also, when ? = N (0, ? 1 ) and ? = N (0, ? 2 ), one can restrict the infimum which defines W to run over Gaussian laws N (0, ?) on R n ? R n with covariance matrix ? structured as above. The sole constrain on C is the Schur complement constraint: </p><formula xml:id="formula_18">? 1 ? C? ?1 2 C 0<label>(15)</label></formula><p>under the constraint above leads to Eq. 10. A detailed proof is given by <ref type="bibr" target="#b13">[14]</ref>. Alternatively, one may find an optimal transportation map as <ref type="bibr" target="#b21">[22]</ref>. It turns out that N (m 2 , ? 2 ) is the image law of N (m 1 , ? 1 ) with the linear map</p><formula xml:id="formula_20">x m 2 + A(xm 1 )<label>(17)</label></formula><p>where</p><formula xml:id="formula_21">A = ? ?1/2 1 (? 1/2 1 ? 2 ? 1/2 1 ) 1/2 ? ?1/2 1 = A<label>(18)</label></formula><p>To check that this maps N (m 1 , ? 1 ) to N (m 2 , ? 2 ), say in the case m 1 = m 2 = 0 for simplicity, one may define the random column vectors X ? N (m 1 , ? 1 ) and Y = AX and write E(YY ) =AE(XX )A =? </p><p>To check that the map is optimal, one may use,</p><formula xml:id="formula_23">E( X ? Y 2 2 ) =E( X 2 2 ) + E( Y 2 2 ) ? 2E(&lt; X, Y &gt;) =Tr(? 1 ) + Tr(? 2 ) ? 2E(&lt; X, AX &gt;)</formula><p>=Tr(? 1 ) + Tr(? 2 ) ? 2Tr(? 1 A) <ref type="bibr" target="#b19">(20)</ref> and observe that by the cyclic property of the trace, Tr(? 1 A) = Tr((? 1/2</p><formula xml:id="formula_24">1 ? 2 ? 1/2 1 ) 1/2 )<label>(21)</label></formula><p>The generalizations to elliptic families of distributions and to infinite dimensional Hilbert spaces is probably easy. Some more "geometric" properties of Gaussians with respect to such distances where studied more recently by <ref type="bibr" target="#b49">[50]</ref> and <ref type="bibr" target="#b49">[50]</ref>.  <ref type="table">Table 9</ref>: Ablation test of GWD-based regression loss form and hyperparameter on DOTA. The based detector is Reti-naNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Improved GWD-based Regression Loss</head><p>In Tab. 9, we compare three different forms of GWDbased regression loss, including d 2 , 1? 1 (? +f (d 2 )) and f (d 2 ). The performance of directly using GWD (d 2 ) as the regression loss is extremely poor, only 49.11%, due to its rapid growth trend (as shown on the left of <ref type="figure" target="#fig_5">Fig. 6</ref>). In other words, the regression loss d 2 is too sensitive to large errors. In contrast, 1 ? 1 (? +f (d 2 )) achieves a significant improvement by fitting IoU loss. This loss form introduces two new hyperparameters, the non-linear function f (?) to transform the Wasserstein distance, and the constant ? to modulate the entire loss. From Tab. 9, the overall performance of using sqrt outperforms that using log, about 0.98?0.3% higher. For f (?) = sqrt with ? = 2, the model achieves the best performance, about 68.93%. In order to further reduce the number of hyperparameters of the loss function, we directly use the GWD after nonlinear transformation (f (d 2 )) as the regression loss. As shown in the red box in <ref type="figure" target="#fig_1">Fig. 6, f (d 2 )</ref> still has a nearly linear trend after transformation using the nonlinear function sqrt and only achieves 54.27%. In comparison, the log function can better make the f (d 2 ) change value close to IoU loss (see green box in <ref type="figure" target="#fig_5">Fig. 6</ref>) and achieve the highest performance, about 69.82%. In general, we do not need to strictly fit the IoU loss, and the regression loss should not be sensitive to large errors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>https://github.com/yangxue0827/RotationDetection 2 https://github.com/open-mmlab/mmrotate Comparison of the detection results between Smooth L1 loss-based (left) and the proposed GWD-based (right) detector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Two definitions of bounding boxes. Left: OpenCV Definition D oc , Right: Long Edge Definition D le .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Behavior comparison of different loss in different cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Boundary discontinuity under two bounding box definitions (top), and illustration of the square-like problem (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>A schematic diagram of modeling a rotating bounding box by a two-dimensional Gaussian distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Different forms of GWD-based regression loss curve. The minimization of the function C ?2Tr(C)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>sqrt 68.56 68.93 68.37 67.77 49.11 f (?) = log 67.87 68.09 67.48 66.49</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Ablation test of GWD-based regression loss form and hyperparameter on DOTA. The based detector is Reti-naNet.</figDesc><table><row><cell>METHOD</cell><cell>BOX DEF.</cell><cell>REG. LOSS</cell><cell>DATASET</cell><cell>DATA AUG.</cell><cell>MAP50</cell></row><row><cell>RETINANET</cell><cell>Doc Doc Doc Doc Doc</cell><cell cols="2">SMOOTH L1 GWD SMOOTH L1 UCAS-AOD HRSC2016 GWD SMOOTH L1</cell><cell>R+F+G</cell><cell>84.28 85.56 (+1.28) 94.56 95.44 (+0.88) 65.73</cell></row><row><cell></cell><cell>Doc</cell><cell>GWD</cell><cell></cell><cell></cell><cell>68.93 (+3.20)</cell></row><row><cell></cell><cell>Dle Dle</cell><cell>SMOOTH L1 GWD</cell><cell>DOTA</cell><cell>F</cell><cell>64.17 66.31 (+2.14)</cell></row><row><cell>R 3 DET</cell><cell>Doc Doc</cell><cell>SMOOTH L1 GWD</cell><cell></cell><cell></cell><cell>70.66 71.56 (+0.90)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Ablation study for GWD on three datasets. 'R', 'F' and 'G' indicate random rotation, flipping, and graying, respectively.</figDesc><table><row><cell>METHOD</cell><cell>REG. LOSS</cell><cell>DATASET</cell><cell cols="3">DATA AUG. RECALL PRECISION</cell><cell>HMEAN</cell></row><row><cell>RETINANET</cell><cell>SMOOTH L1 GWD SMOOTH L1 GWD</cell><cell>MLT</cell><cell>F</cell><cell>37.88 44.01 71.55 73.95</cell><cell>67.07 71.83 68.10 74.64</cell><cell>48.42 54.58 (+6.16) 69.78 74.29 (+4.51)</cell></row><row><cell>R 3 DET</cell><cell>SMOOTH L1 GWD SMOOTH L1 GWD SMOOTH L1 GWD</cell><cell>ICDAR2015</cell><cell>R+F F R+F</cell><cell>69.43 72.17 69.09 70.00 71.69 73.95</cell><cell>81.15 80.59 80.30 82.15 79.80 80.50</cell><cell>74.83 76.15 (+1.32) 74.28 75.59 (+1.31) 75.53 77.09 (+1.56)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>77.88 44.07 66.08 71.92 62.56 77.94 89.75 81.43 79.64 52.30 63.52 60.25 66.51 51.63 68.93 #2 88.60 78.59 44.10 67.24 70.77 62.54 79.78 88.86 81.92 80.46 57.44 64.02 62.64 66.52 55.29 69.92 #3 R-152 40 89.06 83.48 49.84 65.34 74.64 67.63 82.39 88.39 84.19 84.80 63.74 61.32 66.47 70.94 67.52 73.32 #4 87.47 83.77 52.30 68.24 73.24 65.14 80.18 89.63 84.39 85.53 65.79 66.02 69.57 72.21 69.79 74.22 #5 60 88.88 80.47 52.94 63.85 76.95 70.28 83.56 88.54 83.51 84.94 61.24 65.13 65.45 71.69 73.90 74.09 #6 87.12 81.64 54.79 68.74 76.17 68.39 83.93 89.06 84.51 85.99 63.33 66.68 72.60 70.63 74.17 75.18 #7 86.14 81.59 55.33 75.57 74.20 67.34 81.75 87.48 82.80 85.46 69.47 67.20 70.97 70.91 74.07 75.35 #8 87.63 84.32 54.83 69.99 76.17 70.12 83.13 88.96 83.19 86.06 67.72 66.17 73.47 74.57 72.80 75.94 #9 86.96 83.88 54.36 77.53 74.41 68.48 80.34 86.62 83.41 85.55 73.47 67.77 72.57 75.76 73.40 76.30 #10 --89.06 84.32 55.33 77.53 76.95 70.28 83.95 89.75 84.51 86.06 73.47 67.77 72.60 75.76 74.17 81.18 52.89 70.37 77.73 82.42 86.99 89.31 83.06 85.97 64.07 65.14 68.05 70.95 58.45 75.08 #12 89.64 81.70 52.52 72.96 76.02 82.60 87.17 89.57 81.25 86.09 62.24 65.74 68.05 74.96 64.38 75.66 #13 89.66 82.11 52.74 71.64 75.95 83.09 86.97 89.28 85.04 86.17 65.52 63.29 72.18 74.88 63.17 76.11 #14 89.56 81.23 53.38 79.38 75.12 82.14 86.86 88.87 81.21 86.28 65.36 65.06 72.88 73.04 62.97 76.22 #15 89.33 80.86 53.28 78.29 75.40 82.69 87.09 89.35 82.64 86.41 69.85 64.71 74.19 76.18 59.85 76.67 #16 R-152 89.51 82.68 51.92 69.51 78.97 83.38 87.53 89.67 85.65 86.17 63.90 67.44 68.27 76.43 64.22 76.35 #17 89.55 82.28 52.39 68.30 77.86 83.40 87.48 89.56 84.27 86.14 65.38 63.25 71.33 72.36 69.21 76.18 #18 89.62 82.27 52.35 77.30 76.95 82.53 87.20 89.08 84.58 86.21 65.21 64.46 74.99 76.30 65.19 76.95 #19 R-18 40 86.63 80.12 51.98 49.67 75.73 77.54 86.10 90.05 83.22 82.31 56.05 58.86 63.30 69.06 55.07 71.05 #20 87.88 81.73 51.76 69.21 73.78 77.78 86.46 90.05 84.47 84.33 59.82 59.74 66.54 69.15 60.42 73.54 #21 88.94 84.10 53.04 67.78 75.29 79.21 86.89 89.90 86.43 84.30 63.22 59.96 67.16 70.55 64.39 74.74 #22 87.27 82.59 51.90 76.58 72.74 77.04 85.59 89.18 83.91 84.81 63.34 59.46 66.41 69.79 59.03 73.98 #23 88.38 84.75 52.63 77.35 74.29 78.53 86.32 89.12 85.73 85.13 67.84 59.48 66.88 71.59 62.58 75.37 #24 R-50 60 88.82 82.94 55.63 72.75 78.52 83.10 87.46 90.21 86.36 85.44 64.70 61.41 73.46 76.94 57.38 76.34 #25 89.09 84.13 55.77 74.48 77.71 82.99 87.57 89.46 84.89 85.67 66.09 64.17 75.13 75.35 62.78 77.02 #26 89.04 84.99 57.14 76.13 77.79 84.03 87.70 89.53 83.83 85.64 69.60 63.75 76.10 79.22 67.80 78.15 #27 88.89 83.58 55.54 80.46 76.86 83.07 86.85 89.09 83.09 86.17 71.38 64.93 76.21 73.23 64.39 77.58 #28 88.43 84.33 56.91 82.19 76.69 83.23 86.78 88.90 83.93 85.73 72.07 65.67 76.76 78.37 65.31 78.35 #29 R-152 88.74 82.63 54.88 70.11 78.87 84.59 87.37 89.81 84.79 86.47 66.58 64.11 75.31 78.43 70.87 77.57 #30 89.59 84.19 56.53 75.69 77.67 84.48 87.52 90.05 84.29 86.85 68.61 64.73 76.59 77.92 71.88 78.44 #31 89.59 82.96 58.83 75.04 77.63 84.83 87.31 89.89 86.54 86.82 69.45 65.94 76.55 77.50 74.92 78.92 #32 88.99 82.26 56.62 81.40 77.04 83.90 86.56 88.97 83.63 86.48 70.45 65.58 76.41 77.30 69.21 78.32 #33 89.28 83.70 59.26 79.85 76.42 83.87 86.53 89.06 85.53 86.50 73.04 67.56 76.92 77.09 71.58 79.08 #34 --89.66 84.99 59.26 82.19 78.97 84.83 87.70 90.21 86.54 86.85 73.04 67.56 76.92 79.22 74.92 80.19 #35 ---89.66 84.99 59.26 82.19 78.97 84.83 87.70 90.21 86.54 86.85 73.47 67.77 76.92 79.22 74.92 80.23</figDesc><table><row><cell></cell><cell>77.43</cell></row><row><cell>#11</cell><cell>89.59</cell></row><row><cell>R-101</cell><cell></cell></row><row><cell>30</cell><cell></cell></row><row><cell>R 3 DET-GWD</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell>METHOD</cell><cell>REG. LOSS</cell><cell>AP50</cell><cell>AP60</cell><cell>AP75</cell><cell>AP85</cell><cell>AP50:95</cell></row><row><cell>RETINANET</cell><cell cols="6">SMOOTH L1 84.28 74.74 48.42 12.56 GWD 85.56 84.04 60.31 17.14 52.89 +(5.13) 47.76</cell></row><row><cell>R 3 DET</cell><cell cols="6">SMOOTH L1 88.52 79.01 43.42 GWD 89.43 88.89 65.88 15.02 56.07 +(9.89) 4.58 46.18</cell></row></table><note>Ablation experiment of training strategies and tricks. R-101 denotes ResNet-101 (likewise for R-18, R-50, R- 152). MS, MSC, SWA, and ME represent data augmentation, multi-scale training and testing, stochastic weights averaging, multi-scale image cropping, and model ensemble, respectively.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>78.52 43.44 75.92 68.81 73.68 83.59 90.74 77.27 81.46 58.39 53.54 62.83 58.93 47.67 80.65 52.09 68.36 68.36 60.32 72.41 90.85 87.94 86.86 65.02 66.68 66.25 68.24 65.21 84.11 54.19 72.04 68.41 61.18 66.00 90.82 87.79 86.59 65.65 64.04 66.68 68.84 68.03 77.40 51.20 71.03 73.30 72.16 84.68 90.87 80.43 85.38 58.33 62.27 67.58 70.69 60.42 79.58 45.49 76.41 73.18 68.27 79.56 90.83 83.40 84.68 53.40 65.42 74.17 69.69 64.86 84.03 52.41 70.30 70.13 67.64 77.81 90.85 85.40 86.22 63.21 64.14 68.31 70.21 62.11 73.49 GLIDING VERTEX [62] R-101 89.64 85.00 52.26 77.34 73.01 73.14 86.82 90.74 79.02 86.81 59.55 70.91 72.94 70.86 57.32 75.02 SAR [34] R-152 89.67 79.78 54.17 68.29 71.70 77.90 84.63 90.91 88.22 87.07 60.49 66.95 75.13 75.28 64.29 75.28 MASK OBB [52] RX-101 89.56 85.95 54.21 72.90 76.52 74.16 85.63 89.85 83.81 86.48 54.89 69.64 73.94 69.06 63.32 83.62 53.42 76.03 74.01 77.16 79.45 90.83 87.15 84.51 67.72 60.33 74.61 71.84 65.55 75.75 F 3 -NET [72] R-152 88.89 78.48 54.62 74.43 72.80 77.52 87.54 90.78 87.64 85.63 63.80 64.53 78.06 72.36 63.19 76.02 CENTERMAP [54] R-101 89.83 84.41 54.60 70.25 77.66 78.32 87.19 90.66 84.89 85.27 56.46 69.23 74.13 71.56 66.06 76.03 CSL [66] R-152 90.25 85.53 54.64 75.31 70.44 73.51 77.62 90.84 86.15 86.69 69.60 68.04 73.83 71.10 68.93 76.17 MRDET [43] R-101 89.49 84.29 55.40 66.68 76.27 82.13 87.86 90.81 86.92 85.00 52.34 65.98 76.22 76.78 67.49 84.45 53.77 74.35 71.52 78.31 78.12 91.14 87.35 86.93 65.64 65.17 75.35 79.74 63.31 85.82 54.10 79.58 75.00 75.13 86.92 90.88 86.42 86.62 62.46 68.41 73.98 68.11 63.69 84.39 55.44 73.99 77.54 71.11 86.05 90.67 87.32 87.08 69.62 68.90 73.74 71.29 65.08 86.23 56.12 80.59 77.52 73.26 83.78 90.80 87.19 85.67 69.08 72.02 76.98 72.50 67.96 85.21 55.40 77.70 80.26 83.78 87.59 90.81 87.66 86.93 65.60 68.74 71.64 79.99 66.20 64.54 39.82 32.07 49.71 65.01 52.58 81.45 44.66 78.51 46.54 56.73 64.40 64.24 36.75 65.59 39.82 39.95 49.71 65.01 53.58 81.45 44.66 78.51 48.85 56.73 64.40 64.24 36.75 77.15 38.59 61.15 67.53 70.49 76.30 89.66 79.07 83.53 47.27 61.01 56.28 66.06 36.05 77.89 46.37 56.47 75.86 74.83 86.07 90.58 81.09 83.71 50.21 60.94 65.29 69.77 50.93 70.64 O 2 -DNET [56] H-104 89.31 82.14 47.33 61.21 71.32 74.03 78.62 90.76 82.23 81.36 60.93 60.17 58.21 66.98 61.03 77.83 50.44 69.29 71.10 75.79 78.66 90.88 80.10 81.71 57.92 63.03 66.30 69.77 63.13 79.96 50.69 62.18 78.43 78.98 87.94 90.85 83.58 84.35 54.13 60.24 65.22 64.28 55.70 82.82 54.47 69.65 69.23 70.78 75.78 90.84 86.13 84.76 66.52 63.71 67.13 68.38 46.09 72.42 HRP-NET [17] HRNET-W48 89.33 81.64 48.33 75.21 71.39 74.82 77.62 90.86 81.23 81.96 62.93 62.17 66.27 66.98 62.13 82.34 47.22 64.10 76.22 74.43 85.84 90.57 86.18 84.89 57.65 61.93 69.30 69.63 58.48 80.41 52.41 70.02 76.28 78.11 87.21 90.89 84.47 85.64 60.51 61.52 67.82 68.02 50.09 73.50 R 4 DET [49] R-152 88.96 85.42 52.91 73.84 74.86 81.52 80.29 90.79 86.95 85.25 64.05 60.93 69.00 70.55 67.76 75.84 R 3 DET [67] R-152 89.80 83.77 48.11 66.77 78.76 83.27 87.84 90.82 85.38 85.51 65.67 62.68 67.53 78.56 72.62 87.07 48.14 70.97 78.53 80.34 87.45 90.76 85.63 86.87 61.64 70.32 71.92 73.09 67.15 76.64 S 2 A-NET-DAL [37] R-50 89.69 83.11 55.03 71.00 78.30 81.90 88.46 90.89 84.97 87.46 64.41 65.65 76.86 72.09 64.35 76.95 R 3 DET-DCL [64] R-152 89.26 83.60 53.54 72.76 79.04 82.56 87.31 90.67 86.59 86.98 67.49 66.88 73.29 70.56 69.99 83.92 52.51 73.06 77.81 79.00 87.08 90.62 86.72 87.15 63.96 70.29 76.98 75.79 72.15 77.75 S 2 A-NET [15] R-101 89.28 84.11 56.95 79.21 80.18 82.93 89.21 90.86 84.66 87.61 71.66 68.23 78.58 78.20 65.55 84.99 59.26 82.19 78.97 84.83 87.70 90.21 86.54 86.85 73.47 67.77 76.92 79.22 74.92 80.23</figDesc><table><row><cell></cell><cell>DETECTOR</cell><cell cols="2">METHOD</cell><cell cols="2">BOX DEF. IML</cell><cell cols="2">BD EOE POA</cell><cell>SLP</cell><cell>BR  ?</cell><cell>SV  ?</cell><cell>LV  ?</cell><cell>SH  ?</cell><cell cols="2">TRANVAL/TEST HA  ? ST  ?</cell><cell>RA  ?</cell><cell cols="4">TRAIN/VAL 7-MAP50 MAP50 MAP50 MAP75 MAP50:95</cell></row><row><cell></cell><cell></cell><cell>-</cell><cell></cell><cell>Doc</cell><cell></cell><cell></cell><cell></cell><cell>?</cell><cell cols="7">42.17 65.93 51.11 72.61 53.24 78.38 62.00</cell><cell cols="2">60.78</cell><cell>65.73</cell><cell>64.70</cell><cell>32.31</cell><cell>34.50</cell></row><row><cell></cell><cell></cell><cell>-</cell><cell></cell><cell>Dle</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">38.31 60.48 49.77 68.29 51.28 78.60 60.02</cell><cell cols="2">58.11</cell><cell>64.17</cell><cell>62.21</cell><cell>26.06</cell><cell>31.49</cell></row><row><cell></cell><cell cols="3">IOU-SMOOTH L1 LOSS</cell><cell>Doc</cell><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell cols="7">44.32 63.03 51.25 72.78 56.21 77.98 63.22</cell><cell cols="2">61.26</cell><cell>66.99</cell><cell>64.61</cell><cell>34.17</cell><cell>36.23</cell></row><row><cell></cell><cell>RETINANET</cell><cell cols="2">MODULATED LOSS</cell><cell>Doc</cell><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell cols="7">42.92 67.92 52.91 72.67 53.64 80.22 58.21</cell><cell cols="2">61.21</cell><cell>66.05</cell><cell>63.50</cell><cell>33.32</cell><cell>34.61</cell></row><row><cell></cell><cell></cell><cell cols="2">CSL</cell><cell>Dle</cell><cell></cell><cell>?</cell><cell>?</cell><cell></cell><cell cols="7">42.25 68.28 54.51 72.85 53.10 75.59 58.99</cell><cell cols="2">60.80</cell><cell>67.38</cell><cell>64.40</cell><cell>32.58</cell><cell>35.04</cell></row><row><cell></cell><cell></cell><cell cols="2">DCL (BCL)</cell><cell>Dle</cell><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell cols="7">41.40 65.82 56.27 73.80 54.30 79.02 60.25</cell><cell cols="2">61.55</cell><cell>67.39</cell><cell>65.93</cell><cell>35.66</cell><cell>36.71</cell></row><row><cell></cell><cell></cell><cell cols="2">GWD</cell><cell>Doc</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell cols="7">44.07 71.92 62.56 77.94 60.25 79.64 63.52</cell><cell cols="2">65.70</cell><cell>68.93</cell><cell>65.44</cell><cell>38.68</cell><cell>38.71</cell></row><row><cell></cell><cell></cell><cell>-</cell><cell></cell><cell>Doc</cell><cell></cell><cell></cell><cell></cell><cell>?</cell><cell cols="7">44.15 75.09 72.88 86.04 56.49 82.53 61.01</cell><cell cols="2">68.31</cell><cell>70.66</cell><cell>67.18</cell><cell>38.41</cell><cell>38.46</cell></row><row><cell></cell><cell>R 3 DET</cell><cell cols="2">DCL (BCL)</cell><cell>Dle</cell><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell cols="7">46.84 74.87 74.96 85.70 57.72 84.06 63.77</cell><cell cols="2">69.70</cell><cell>71.21</cell><cell>67.45</cell><cell>35.44</cell><cell>37.54</cell></row><row><cell></cell><cell></cell><cell cols="2">GWD</cell><cell>Doc</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell cols="7">46.73 75.84 78.00 86.71 62.69 83.09 61.12</cell><cell cols="2">70.60</cell><cell>71.56</cell><cell>69.28</cell><cell>43.35</cell><cell>41.56</cell></row><row><cell></cell><cell>METHOD</cell><cell></cell><cell>BACKBONE</cell><cell>MS</cell><cell>PL</cell><cell>BD</cell><cell>BR</cell><cell>GTF</cell><cell>SV</cell><cell>LV</cell><cell>SH</cell><cell></cell><cell>TC</cell><cell>BC</cell><cell>ST</cell><cell>SBF</cell><cell>RA</cell><cell>HA</cell><cell>SP</cell><cell>HC</cell><cell>MAP50</cell></row><row><cell></cell><cell>FR-O [57]</cell><cell></cell><cell>R-101</cell><cell></cell><cell cols="11">79.09 69.12 17.17 63.49 34.20 37.16 36.20 89.19 69.60 58.96</cell><cell>49.4</cell><cell cols="3">52.52 46.69 44.80 46.30</cell><cell>52.93</cell></row><row><cell></cell><cell>ICN [2]</cell><cell></cell><cell>R-101</cell><cell></cell><cell cols="15">81.40 74.30 47.70 70.30 64.90 67.80 70.00 90.80 79.10 78.20 53.60 62.90 67.00 64.20 50.20</cell><cell>68.20</cell></row><row><cell></cell><cell>KARNET [51]</cell><cell></cell><cell>R-50</cell><cell></cell><cell cols="15">89.33 83.55 44.79 71.61 63.05 67.06 69.53 90.47 79.46 77.84 51.04 60.97 65.38 69.46 49.53</cell><cell>68.87</cell></row><row><cell></cell><cell>RADET [25]</cell><cell></cell><cell>RX-101</cell><cell></cell><cell cols="15">79.45 76.99 48.05 65.83 65.46 74.40 68.86 89.70 78.14 74.97 49.92 64.63 66.14 71.58 62.16</cell><cell>69.09</cell></row><row><cell></cell><cell>ROI-TRANS. [8]</cell><cell></cell><cell>R-101</cell><cell></cell><cell cols="15">88.64 69.56</cell></row><row><cell></cell><cell>CAD-NET [75]</cell><cell></cell><cell>R-101</cell><cell></cell><cell>87.8</cell><cell>82.4</cell><cell>49.4</cell><cell>73.5</cell><cell>71.1</cell><cell>63.5</cell><cell cols="2">76.7</cell><cell>90.9</cell><cell>79.2</cell><cell>73.3</cell><cell>48.4</cell><cell>60.9</cell><cell>62.0</cell><cell>67.0</cell><cell>62.2</cell><cell>69.9</cell></row><row><cell></cell><cell>AOOD [87]</cell><cell></cell><cell>DPN-92</cell><cell></cell><cell cols="15">89.99 81.25 44.50 73.20 68.90 60.33 66.86 90.89 80.99 86.23 64.98 63.88 65.24 68.36 62.13</cell><cell>71.18</cell></row><row><cell></cell><cell cols="2">CASCADE-FF [18]</cell><cell>R-152</cell><cell></cell><cell>89.9</cell><cell>80.4</cell><cell>51.7</cell><cell>77.4</cell><cell>68.2</cell><cell>75.2</cell><cell cols="2">75.6</cell><cell>90.8</cell><cell>78.8</cell><cell>84.4</cell><cell>62.3</cell><cell>64.6</cell><cell>57.7</cell><cell>69.4</cell><cell>50.1</cell><cell>71.8</cell></row><row><cell></cell><cell>SCRDET [69]</cell><cell></cell><cell>R-101</cell><cell></cell><cell cols="15">89.98 72.61</cell></row><row><cell>TWO-STAGE METHODS</cell><cell cols="2">SARD [55] GLS-NET [23] FADET [24] MFIAR-NET [63] FFA [12] APE [86]</cell><cell>R-101 R-101 R-101 R-152 R-101 RX-101</cell><cell></cell><cell cols="15">89.93 72.95 88.65 72.96 90.21 73.28 89.62 75.33 90.1 82.7 54.2 75.2 71.0 79.9 83.5 90.7 83.9 84.6 61.2 68.0 70.7 76.0 63.7 75.7 89.96 76.24</cell></row><row><cell></cell><cell>RSDET-II [42]</cell><cell></cell><cell>R-152</cell><cell></cell><cell cols="15">89.93 76.34</cell></row><row><cell></cell><cell>OPLD [48]</cell><cell></cell><cell>R-101</cell><cell></cell><cell cols="15">89.37 76.43</cell></row><row><cell></cell><cell cols="2">SCRDET++ [68]</cell><cell>R-101</cell><cell></cell><cell cols="15">90.05 76.81</cell></row><row><cell></cell><cell>HSP [61]</cell><cell></cell><cell>R-101</cell><cell></cell><cell cols="15">90.39 78.01</cell></row><row><cell></cell><cell>FR-EST [11]</cell><cell></cell><cell>R-101-DCN</cell><cell></cell><cell cols="15">89.78 78.49</cell></row><row><cell></cell><cell>IENET [30]</cell><cell></cell><cell>R-101</cell><cell></cell><cell cols="15">80.20 57.14</cell></row><row><cell></cell><cell>TOSO [10]</cell><cell></cell><cell>R-101</cell><cell></cell><cell cols="15">80.17 57.92</cell></row><row><cell></cell><cell>PIOU [5]</cell><cell></cell><cell>DLA-34</cell><cell></cell><cell>80.9</cell><cell>69.7</cell><cell>24.1</cell><cell>60.2</cell><cell>38.3</cell><cell>64.4</cell><cell cols="2">64.8</cell><cell>90.9</cell><cell>77.2</cell><cell>70.4</cell><cell>46.5</cell><cell>37.1</cell><cell>57.1</cell><cell>61.9</cell><cell>64.0</cell><cell>60.5</cell></row><row><cell></cell><cell cols="2">AXIS LEARNING [58]</cell><cell>R-101</cell><cell></cell><cell cols="15">79.53 65.98</cell></row><row><cell>SINGLE-STAGE METHODS</cell><cell cols="2">A 2 S-DET [59] P-RSDET [82] BBAVECTORS [73] ROPDET [71] DRN [41] CFC-NET [36] POLARDET [78]</cell><cell>R-101 R-101 R-101 R-101-DCN H-104 R-101 R-101</cell><cell></cell><cell cols="15">89.59 71.04 88.58 72.30 88.35 72.32 90.01 72.83 89.71 73.23 89.08 76.47 89.65 77.37</cell></row><row><cell></cell><cell>RDD [81]</cell><cell></cell><cell>R-101</cell><cell></cell><cell cols="15">89.15 79.15</cell></row><row><cell></cell><cell>GWD (OURS)</cell><cell></cell><cell>R-152</cell><cell></cell><cell>89.66</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table><row><cell>AP on different objects and mAP on DOTA. R-101 denotes ResNet-101 (likewise for R-50, R-152), RX-101 and</cell></row><row><cell>H-104 stands for ResNeXt101 [60] and Hourglass-104 [39]. Other backbone include DPN-92 [4], DLA-34 [74], DCN [7],</cell></row><row><cell>HRNet-W48 [53], U-Net [46]. MS indicates that multi-scale training or testing is used.</cell></row><row><cell>iterations per epoch for DOTA, UCAS-AOD, HRSC2016,</cell></row><row><cell>ICDAR2015, and MLT are 54k, 5k, 10k, 10k and 10k re-</cell></row><row><cell>spectively, and increase exponentially if data augmentation</cell></row><row><cell>and multi-scale training are used.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>#6} and {#11,#12} show the its effectiveness, increased by 0.9%, 1.09%, and 0.58%, respectively.</figDesc><table><row><cell>, multi-scale</cell></row><row><cell>image cropping (MSC), model ensemble (ME), as shown in</cell></row><row><cell>Tab. 4.</cell></row><row><cell>Backbone: Under the conditions of different detectors</cell></row><row><cell>(RetinaNet and R 3 Det), different training schedules (exper-</cell></row><row><cell>imental groups {#11,#16}, {#24,#29}), and different tricks</cell></row><row><cell>(experimental groups {#26,#31}, {#28,#33}), large back-</cell></row><row><cell>bone can bring stable performance improvement.</cell></row><row><cell>Multi-scale training and testing: Multi-scale training</cell></row><row><cell>and testing is an effective means to improve the perfor-</cell></row><row><cell>mance of aerial images with various object scales. In this</cell></row><row><cell>paper, training and testing scale set to [450, 500, 640,</cell></row><row><cell>700, 800, 900, 1,000, 1,100, 1,200]. Experimental groups</cell></row><row><cell>{#3,#4}, {#5,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>(?+f(d 2 )) ? = 1 ? = 2 ? = 3 ? = 5 f (d 2 ) d 2 f (?) =sqrt 68.56 68.93 68.37 67.77 54.27 49.11 f (?) = log 67.87 68.09 67.48 66.49 69.82</figDesc><table><row><cell>1 ?</cell></row></table><note>1</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The angle of the bounding box is close to the maximum and minimum values of the angle range. For more clearly visualization, the ground truth has been rendered with a larger angle inFig. 4.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Many instances are in square shape. For instance, two categories of storage-tank (ST) and roundabout (RA) in DOTA dataset.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>The author Xue Yang is supported by Wu Wen Jun Honorary Doctoral Scholarship, AI Institute, Shanghai Jiao Tong University. The authors would like to thank Gefan Zhang and Minghuan Liu for their helpful discussion.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} symposium on operating systems design and implementation ({OSDI} 16)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards multi-class object detection in unconstrained remote sensing imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleonora</forename><surname>Seyed Majid Azimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Vig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Bahmanyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>K?rner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reinartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="150" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Wasserstein distance between two gaussians. Website</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djalil</forename><surname>Chafa?</surname></persName>
		</author>
		<ptr target="https://djalil.chafai.net/blog/2010/04/30/wasserstein-distance-between-two-gaussians/" />
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dual path networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4467" to="4475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Piou loss: Towards accurate oriented object detection in complex environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kean</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">R-fcn: Object detection via region-based fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="379" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="764" to="773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning roi transformer for oriented object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qikai</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2849" to="2858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The fr?chet distance between multivariate normal distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dc Dowson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Landau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of multivariate analysis</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="450" to="455" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Toso: Student&apos;st distribution aided one-stage orientation target detection in remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengming</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youtian</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huifeng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Chambers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4057" to="4061" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pointbased estimator for arbitrary-oriented object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rotation-aware and multi-scale convolutional neural network for object detection in remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangluan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keshu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">161</biblScope>
			<biblScope unit="page" from="294" to="308" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A class of wasserstein metrics for probability distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rae</forename><forename type="middle">Michael</forename><surname>Clark R Givens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shortt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Michigan Mathematical Journal</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="240" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.09397</idno>
		<title level="m">Align deep features for oriented object detection</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">High-resolution polar network for object detection in remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiping</forename><surname>Xu He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linyuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cascade detector with feature fusion for arbitrary-oriented objects in remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liping</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Multimedia and Expo</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitrii</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timur</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05407</idno>
		<title level="m">Averaging weights leads to wider optima and better generalization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">R2cnn: rotational region cnn for orientation robust scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuli</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenbo</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.09579</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Icdar 2015 competition on robust reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimosthenis</forename><surname>Karatzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluis</forename><surname>Gomez-Bigorda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anguelos</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suman</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masakazu</forename><surname>Iwamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><forename type="middle">Ramaseshan</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijian</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 13th International Conference on Document Analysis and Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1156" to="1160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the optimal mapping of distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Knott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><forename type="middle">S</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Optimization Theory and Applications</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="49" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Object detection based on global-local saliency constraint in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailong</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhai</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">1435</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Feature-attentioned object detection in remote sensing imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengzheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3886" to="3890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Radet: Refine feature pyramid network and multi-layer attention network for arbitrary-oriented object detection of remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Licheng</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronghua</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">389</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Textboxes++: A single-shot oriented scene text detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghui</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoguang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3676" to="3690" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Rotation-sensitive regression for oriented scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghui</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoguang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5909" to="5918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Ienet: Interacting embranchment one stage anchor free detector for orientation aerial object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youtian</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengming</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Guan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00969</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fots: Fast oriented text spotting with a unified network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuebo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dagui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5676" to="5685" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Omnidirectional scene text detection with sequential-free box discretization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianwen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lele</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaqiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhepeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02371</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A high resolution optical satellite image dataset for ship recognition and some new baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zikun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubin</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Pattern Recognition Applications and Methods</title>
		<meeting>the International Conference on Pattern Recognition Applications and Methods</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="324" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sar: Single-stage anchor-free rotating object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuqiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongguang</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="205902" to="205912" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Arbitrary-oriented scene text detection via rotation proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyuan</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingbin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3111" to="3122" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Cfc-net: A critical feature capturing network for arbitrary-oriented object detection in remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjuan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06849</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Dynamic anchor learning for arbitraryoriented object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjuan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhao</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.04150</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Icdar2017 robust reading challenge on multi-lingual scene text detection and script identification-rrc-mlt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nibal</forename><surname>Nayef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imen</forename><surname>Bizid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunsoo</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimosthenis</forename><surname>Karatzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenbo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umapada</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Rigaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Chazalon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 14th IAPR International Conference on Document Analysis and Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1454" to="1459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="483" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The distance between two random vectors with given dispersion matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingram</forename><surname>Olkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Friedrich</forename><surname>Pukelsheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear Algebra and its Applications</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="257" to="263" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dynamic refinement network for oriented and densely packed object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjia</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kekai</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haolei</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongyang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changsheng</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11207" to="11216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning modulated loss for rotated object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silong</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Mrdet: A multi-head network for accurate oriented object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingjie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangshuai</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.13135</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Generalized intersection over union: A metric and a loss for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unet: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Real-time rotation-invariant face detection with progressive calibration networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuepeng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meina</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuzhe</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2295" to="2303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning point-guided localization for detection in remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lurui</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">R4det: Refined single-stage detector with feature recursion and refinement for rotating object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongtan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanying</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page">104036</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Cone structure of l2-wasserstein spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asuka</forename><surname>Takatsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takumi</forename><surname>Yokota</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Topology and Analysis</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="237" to="253" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Rotating objects detection in aerial images via attention denoising and angle loss refining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiguang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyu</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DEStech Transactions on Computer Science and Engineering</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Mask obb: A semantic attentionbased mask oriented bounding box representation for multicategory object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haowen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wensheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page">2930</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Deep high-resolution representation learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaorui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning center probability map for detecting objects in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng-Chao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Sard: Towards scale-aware rotated object detection in aerial imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangjin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="173855" to="173865" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Oriented objects as pairs of middle lines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="268" to="279" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Dota: A large-scale dataset for object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Datcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Pelillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangpei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3974" to="3983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Axis learning for orientated objects detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjun</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiping</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">908</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A2s-det: Efficiency anchor matching in aerial image oriented object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiao</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanfan</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Hierarchical semantic propagation for object detection in remote sensing imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengzheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4353" to="4364" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Gliding vertex on the horizontal bounding box for multi-oriented object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongchao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingtao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qimeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Multi-scale feature integrated attention-based rotation network for object detection in vhr aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiwei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1686</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Dense label encoding for boundary discontinuity free rotation detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liping</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.09670</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Automatic ship detection in remote sensing images from google earth of complex scenes based on multiscale rotation dense feature pyramid networks. Remote Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jirui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">132</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Arbitrary-oriented object detection with circular smooth label</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="677" to="694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">R3det: Refined single-stage detector with feature refinement for rotating object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziming</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Scrdet++: Detecting small, cluttered and rotated objects via instance-level feature denoising and rotation loss smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenlong</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Scrdet: Towards more robust detection for small, cluttered and rotated objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jirui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8232" to="8241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Alpharotate: A rotation detection benchmark using tensorflow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.06677</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Ropdet: real-time anchor-free detector based on point set representation for rotating object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunkun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuhao</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanhua</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyun</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuntao</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Real-Time Image Processing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2127" to="2138" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">F3-net: Feature fusion and filtration network for object detection in optical remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhai</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengchao</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntao</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page">4027</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Oriented object detection in aerial images with box boundary-aware vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingru</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoying</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.07043</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Deep layer aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2403" to="2412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Cad-net: A context-aware detection network for objects in remote sensing imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gongjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijian</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="10015" to="10024" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feras</forename><surname>Dayoub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>S?nderhauf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.12645</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">Swa object detection. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Toward arbitrary-oriented ship detection with rotated region proposal and discrimination networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zenghui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxian</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1745" to="1749" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Polardet: A fast, more precise detector for rotated target in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenshen</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingjia</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenming</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiliang</forename><surname>Pu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.08720</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Rotation-robust intersection over union for 3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="464" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Distance-iou loss: Faster and better learning for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinze</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongguang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwei</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12993" to="13000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Single-stage rotation-decoupled detector for oriented object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Ao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page">3262</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Arbitrary-oriented object detection in remote sensing images based on polar coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="223373" to="223384" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">East: an efficient and accurate scene text detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuchang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5551" to="5560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Mmrotate: A rotated object detection benchmark using pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gefan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liping</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingzhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Orientation robust object detection in aerial images using deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haigang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiqun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3735" to="3739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Adaptive period embedding for representing oriented objects in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqing</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Arbitraryoriented object detection via dense feature fusion and attention model for remote sensing super-resolution image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuhao</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanting</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunkun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingkuan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Computing and Applications</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
