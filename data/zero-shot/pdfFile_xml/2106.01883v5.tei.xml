<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jirui</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ming</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Beijing Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Huawei Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing rotated object detectors are mostly inherited from the horizontal detection paradigm, as the latter has evolved into a well-developed area. However, these detectors are difficult to perform prominently in high-precision detection due to the limitation of current regression loss design, especially for objects with large aspect ratios. Taking the perspective that horizontal detection is a special case for rotated object detection, in this paper, we are motivated to change the design of rotation regression loss from induction paradigm to deduction methodology, in terms of the relation between rotation and horizontal detection. We show that one essential challenge is how to modulate the coupled parameters in the rotation regression loss, as such the estimated parameters can influence to each other during the dynamic joint optimization, in an adaptive and synergetic way. Specifically, we first convert the rotated bounding box into a 2-D Gaussian distribution, and then calculate the Kullback-Leibler Divergence (KLD) between the Gaussian distributions as the regression loss. By analyzing the gradient of each parameter, we show that KLD (and its derivatives) can dynamically adjust the parameter gradients according to the characteristics of the object. It will adjust the importance (gradient weight) of the angle parameter according to the aspect ratio. This mechanism can be vital for high-precision detection as a slight angle error would cause a serious accuracy drop for large aspect ratios objects. More importantly, we have proved that KLD is scale invariant. We further show that the KLD loss can be degenerated into the popular l n -norm loss for horizontal detection. Experimental results on seven datasets using different detectors show its consistent superiority, and codes are made public available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As a fundamental building block for visual analysis across aerial images, scene text etc., rotated object detection has recently been developed rapidly <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref>, which benefit themselves from the well-established horizontal detection approaches <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref>. Specifically, many works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref> build themselves upon the previously established horizontal box detection pipeline from an inductive perspective, as shown in <ref type="figure">Figure 1</ref>(a). However, these detectors are often unable to cope with challenging scenes well due to the limitations of current regression loss, such as large aspect ratio objects, dense scenes, etc., resulting in obvious disadvantages in high-precision detection.</p><p>(a) Previous methods follow the induction paradigm from special horizontal to general rotated detection.</p><p>(b) Our proposed method adopts a deduction methodology from general rotated to special horizontal detection. <ref type="figure">Figure 1</ref>: Methodological road-map difference between horizontal detection (special case) and rotation detection (general case) in the previous methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref> and the proposed method.</p><p>In this paper, we take a step back, and aim to develop (from a deductive perspective) a unified regression framework for rotation detection and its special case: horizontal detection. In fact, our new framework enjoys a coherent property that it can be degenerated into the current commonly used regression loss (e.g. l n -norm) in special cases (horizontal detection), as shown in <ref type="figure">Figure 1(b)</ref>.</p><p>For a devising a rotation regression loss for high-precision rotation detection, one important observation is that the importance of different parameters to different types of objects can vary. For example, the angle parameter (?) and the center point parameter (x, y) are important for large aspect ratio objects and small objects, respectively. In another word, it is conjectured that regression loss should be self-modulated during the learning process and calls for more dynamic optimization strategy. Inspired by the above ideas, we first convert the rotated bounding box B(x, y, w, h, ?) into a 2-D Gaussian distribution N (?, ?). As a standard distance metric, we then use the Kullback-Leibler Divergence (KLD) <ref type="bibr" target="#b15">[16]</ref> to calculate the distribution distance between the predicted bounding box and ground truth as the regression loss. We compare KLD with Smooth L1 loss <ref type="bibr" target="#b6">[7]</ref> and another distance metric, Gaussian Wasserstein Distance (GWD) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17]</ref>, and find that KLD has a more complete parameter optimization mechanism. In particular, by analyzing the gradient of the parameters during learning, we show that the optimization of one parameter will be affected by other parameters (as the gradient weight). It means that the model will adaptively adjust the optimization strategy given a specific configuration of an object for detection, as shown can lead to excellent performance in high-precision detection. In addition, KLD is proven scale invariant, which is an important property that Smooth L1 loss and GWD do not possess. As the horizontal bounding box is a special case of the rotated bounding box, we show that KLD can also be degenerated into the l n -norm loss as commonly used in existing horizontal detection pipeline. The highlights of this paper are four-folds: 1) Differing from the dominant existing practices that build rotation detectors heavily upon the horizontal detectors, we develop new rotation detection loss from scratch and show that it is coherent with existing horizontal detection protocol in its degenerated case for horizontal detection.</p><p>2) To achieve a more principled measurement between the prediction and ground truth, instead of computing the difference for each physically-meaningful parameter related to the bounding box which are in different scales and units, we innovatively convert the regression loss of rotation detection into the KLD of two 2-D Gaussian distributions, leading to a clean and coherent regression loss.</p><p>3) Through the gradient analysis of each parameter in KLD, we further find that the self-modulated optimization mechanism of KLD greatly promotes the improvement of high-precision detection, which verify the advantage of our loss design. More importantly, we have theoretically shown (in appendix) that KLD is scale invariant for detection, which is crucial for the rotation cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4)</head><p>Extensive experimental results on seven public datasets and two popular detectors show the effectiveness of our approach, which achieves new state-of-the-art performance for rotation detection. The source codes <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> are made public available <ref type="bibr" target="#b33">34</ref> . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>We first generally discuss the related works on both horizontal and rotated object detection. Then we summarize the current design paradigm of rotation regression loss from two kinds of methodologies, as shown in <ref type="figure">Figure 1</ref>: one is inductive that tries to develop the general rotation detection from the special and classic horizontal detection pipeline. While the other is deductive that aims to devise a general rotation detection pipeline with horizontal detection as its special case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Related Works</head><p>Horizontal object detection. Horizontal object detection which covers most existing detection literature, normally uses a horizontal bounding box to represent the object. The mainstream classical object detection algorithms can be roughly divided according to the following standards: Two- <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11]</ref> or Single-stage <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref> object detection, Anchor-free <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref> or Anchor-based <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref> object detection and CNN <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b21">22]</ref> or Transformer-based <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> object detection. Although the pipelines may vary, the mainstream regression loss often uses the popular l n -norm loss (such as smooth L1 loss) or IoU-based loss (such as GIoU <ref type="bibr" target="#b26">[27]</ref>, and DIoU <ref type="bibr" target="#b27">[28]</ref>). These abovementioned detectors have also been widely used in other scenarios and have achieved satisfactory performance. However, horizontal detectors do not provide accurate orientation and scale information. <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b28">29]</ref> are mainly driven by adapting the horizontal object detectors with rotated bounding boxes to represent multi-oriented objects. To accurately predict the rotated bounding box, most rotation detection methods extend the l n -norm <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32]</ref> used in horizontal detection, or construct a differentiable approximate IoU loss <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b32">33]</ref>. From scratch, we try to change the design of rotation regression loss from induction paradigm to deduction methodology, which in fact is a generalization to the horizontal case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rotated object detection. Recent advances in rotation detection</head><p>In the following, we describe the existing works from the induction and deduction methodologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Inductive Thinking of Loss Design: from Special Horizon to General Rotation Detection</head><p>Regression loss is a vital part of most current object detection algorithms. For horizontal bounding box regression, the model <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref> mainly outputs four items for location and size:</p><formula xml:id="formula_0">t p x = xp ? xa wa , t p y = yp ? ya ha , t p w = ln wp wa , t p h = ln hp ha<label>(1)</label></formula><p>to match the four targets from the ground truth</p><formula xml:id="formula_1">t t x = xt ? xa wa , t t y = yt ? ya ha , t t w = ln wt wa , t t h = ln ht ha<label>(2)</label></formula><p>where x, y, w, h denote the center coordinates, width and height, respectively. Variables x t , x a , x p are for the ground-truth box, anchor box, and predicted box, respectively (likewise for y, w, h).</p><p>Extending the above horizontal case, existing rotation detection models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref> also use regression loss which simply involves an extra angle parameter ?:</p><formula xml:id="formula_2">t p ? = f (?p ? ?a), t t ? = f (?t ? ?a)<label>(3)</label></formula><p>where f (?) is used to deal with angular periodicity, such as trigonometric functions, modulo, etc.</p><p>The overall regression loss for rotation detection is:</p><formula xml:id="formula_3">Lreg = ln-norm (?tx, ?ty, ?tw, ?t h , ?t ? )<label>(4)</label></formula><p>where ?t</p><formula xml:id="formula_4">x = t p x ? t t x = ?x wa , ?t y = t p y ? t t y = ?y ha , ?t w = t p w ? t t w = ln(w p /w t ), ?t h = t p h ? t t h = ln(h p /h t ), and ?t ? = t p ? ? t t ? = ??.</formula><p>It can be seen that parameters are optimized independently, making the loss (or detection accuracy) sensitive to the under-fitting of any of the parameters. This mechanism is fatal to high-precision detection. Taking the left side of <ref type="figure" target="#fig_0">Figure 2</ref> as an example, the detection result based on the Smooth L1 loss often shows the deviation of the center point or angle. Moreover, different types of objects have different sensitivity to these five parameters. For example, the angle parameter is very important for detecting objects with large aspect ratios. This requires to select an appropriate set of weights given a specific single object sample during the training, which is nontrivial or even unrealistic. To break the original inductive design paradigm, we adopt deductive paradigm to construct more accurate rotation regression loss. Here we rephrase the main idea in the recent work <ref type="bibr" target="#b4">[5]</ref>, which converts a arbitrary-oriented bounding box B(x, y, w, h, ?) into a 2-D Gaussian N (?, ?), as illustracted in <ref type="figure" target="#fig_1">Figure 3</ref>. Then the distance between two Gaussian is calculated as the final loss. Specifically, the conversion is:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Deductive Thinking of Loss Design: from General Rotation to Special Horizon Detection</head><formula xml:id="formula_5">? =(x, y) ? 1/2 =R?R = cos ? ? sin ? sin ? cos ? w 2 0 0 h 2 cos ? sin ? ? sin ? cos ? = w 2 cos 2 ? + h 2 sin 2 ? w?h 2 cos ? sin ? w?h 2 cos ? sin ? w 2 sin 2 ? + h 2 cos 2 ?<label>(5)</label></formula><p>where R represents the rotation matrix, and ? represents the diagonal matrix of eigenvalues.</p><p>The recent work <ref type="bibr" target="#b4">[5]</ref> analyzes that the introduction of N (?, ?) can solve the inconsistency between metric and loss, boundary discontinuity and square-like problem. On this basis, we further studies how to design high-precision detection regression loss through new parameter space. Our view is that the self-modulated mechanism is positively correlated with the final high-precision performance.</p><p>Gaussian Wasserstein Distance. The Wasserstein distance <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17]</ref> between two probability measures X p ? N p (? p , ? p ) and X t ? N t (? t , ? t ) expressed as:</p><formula xml:id="formula_6">Dw(Np, Nt) 2 = ?p ? ?t 2 2 center distance + Tr(?p + ?t ? 2(? 1/2 p ?t? 1/2 p ) 1/2 )</formula><p>coupling terms about hp, wp and ?p <ref type="bibr" target="#b5">(6)</ref> Eq. 6 shows that the Gaussian Wasserstein Distance (GWD) is mainly divided into two parts: the distance between the center points (x, y) and the coupling terms about h, w and ?. Accordingly, the regression loss based on GWD can be regarded as a semi-coupled loss. Although GWD can greatly improve the performance of high-precision rotation detection due to the coupling between part of the parameters, the independent optimization of the center point make the detection result slightly shifted (see <ref type="figure" target="#fig_0">Figure 2</ref>). Note that GWD is not scale invariant, which is not detection friendly.</p><p>When all the boxes are horizontal (? = 0 ? ), Eq. 6 can be further simplified:</p><formula xml:id="formula_7">D h w (Np, Nt) 2 = ?p ? ?t 2 2 + ? 1/2 p ? ? 1/2 t 2 F =(xp ? xt) 2 + (yp ? yt) 2 + (wp ? wt) 2 + (hp ? ht) 2 /4</formula><p>=l2-norm(?x, ?y, ?w/2, ?h/2)</p><p>where ? F is the Frobenius norm. Although Eq. 7 can still be used as the regression loss of horizontal detection, Eq. 4 and 7 are not completely consistent.</p><p>Although GWD scheme has played a preliminary exploration of the deductive paradigm, it does not focus on achieving high-precision detection and scale invariance. In the following, we will propose our new approach based on the Kullback-Leibler divergence (KLD) <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Approach</head><p>Kullback-Leibler Divergence . To explore the more appropriate regression loss, we adopt the Kullback-Leibler divergence (KLD) <ref type="bibr" target="#b15">[16]</ref>. Similarly, the KLD between two 2-D Gaussian is:</p><formula xml:id="formula_9">D kl (Np||Nt) = 1 2 (?p ? ?t) ? ?1 t (?p ? ?t)</formula><p>term about xp and yp</p><formula xml:id="formula_10">+ 1 2 Tr(? ?1 t ?p) + 1 2 ln |?t| |?p|</formula><p>coupling terms about hp, wp and ?p ?1 <ref type="bibr" target="#b7">(8)</ref> or</p><formula xml:id="formula_11">D kl (Nt||Np) = 1 2 (?p ? ?t) ? ?1 p (?p ? ?t) + 1 2 Tr(? ?1 p ?t) + 1 2 ln |?p| |?t| chain coupling of all parameters ?1<label>(9)</label></formula><p>It can be seen that each item in D kl (N t ||N p ) is composed of partial parameter coupling, which makes all parameters form a chain coupling relationship. In the optimization process of the KLD-based detector, the parameters influence each other and are jointly optimized which make optimization mechanism of the model is self-modulated. In contrast, D kl (N p ||N t ) and GWD are both semicoupled, but D kl (N p ||N t ) has a better central point optimization mechanism.</p><p>Although KLD is asymmetric, we find that the optimization principles of these two forms are similar by analyzing the gradients of various parameters and experimental results. Take the relatively simple D kl (N p ||N t ) as an example, according to Eq. 5, each item of Eq. 8 can be expressed as</p><formula xml:id="formula_12">(?p ? ?t) ? ?1 t (?p ? ?t) = 4 (?x cos ?t + ?y sin ?t) 2 w 2 t + 4 (?y cos ?t ? ?x sin ?t) 2 h 2 t (10) Tr(? ?1 t ?p) = h 2 p w 2 t sin 2 ?? + w 2 p h 2 t sin 2 ?? + h 2 p h 2 t cos 2 ?? + w 2 p w 2 t cos 2 ?? (11) ln |?t| |?p| = ln h 2 t h 2 p + ln w 2 t w 2 p (12) where ?x = x p ? x t , ?y = y p ? y t , ?? = ? p ? ? t .</formula><p>Analysis of high-precision detection. Without loss of generality, we set ? t = 0 ? , then</p><formula xml:id="formula_13">?D kl (?p) ??p = 4 w 2 t ?x, 4 h 2 t ?y<label>(13)</label></formula><p>The weights 1/w 2 t and 1/h 2 t will make the model dynamically adjust the optimization of the object position according to the scale. For example, when the object scale is small or an edge is too short, the model will pay more attention to the optimization of the offset of the corresponding direction. For this kind of object, a slight deviation on the corresponding direction will often cause a sharp drop in IoU. When ? t = 0 ? , the gradient of the object offset (?x and ?y) will be dynamically adjusted according to the ? t for better optimization. In contrast, the gradient of the center point in GWD and L 2 -norm are ?Dw(?p) ??p = (2?x, 2?y) and</p><formula xml:id="formula_14">?D L 2 (?p) ??p = ( 2 w 2 a ?x, 2 h 2 a ?y)</formula><p>. The former cannot adjust the dynamic gradient according to the length and width of the object. The latter is based on the length and width of the anchor (w a , h a ) to adjust the gradient instead of the target object (w t , h t ), which is almost ineffective for those detectors <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref> that use horizontal anchors for rotation detection. More importantly, they are not related to the angle of the target object. Therefore, the detection result of the GWD-based and L n -norm models will show a slight deviation, while the detection result of the KLD-based model is quite accurate, as shown in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>For h p and w p , we have</p><formula xml:id="formula_15">?D kl (?p) ? ln hp = h 2 p h 2 t cos 2 ?? + h 2 p w 2 t sin 2 ?? ? 1, ?D kl (?p) ? ln wp = w 2 p w 2 t cos 2 ?? + w 2 p h 2 t sin 2 ?? ? 1<label>(14)</label></formula><p>On the one hand, the optimization of the h p and w p is affected by the ??. When ?? = 0 ? ,</p><formula xml:id="formula_16">?D kl (?p) ? ln hp = h 2 p h 2 t ? 1, ?D kl (?p) ? ln wp = w 2 p w 2 t ? 1,</formula><p>which means that the smaller targeted height or width leads to heavier penalty on its matching loss. This is desirable, as smaller height or width needs higher matching precision. On the other hand, the optimization of ?? is also affected by h p and w p :</p><formula xml:id="formula_17">?D kl (?p) ??p = h 2 p ? w 2 p w 2 t + w 2 p ? h 2 p h 2 t sin 2??<label>(15)</label></formula><p>when w p = w t , h p = h t , then</p><formula xml:id="formula_18">?D kl (?p) ??p = h 2 t w 2 t + w 2 t h 2 t ? 2 sin 2?? ? sin 2??</formula><p>, the condition for the equality sign is h t = w t . This shows that the larger the aspect ratio of the object, the model will pay more attention to the optimization of the angle. This is the main reason why the KLD-based model has a huge advantage in high-precision detection indicators as a slight angle error would cause a serious accuracy drop for large aspect ratios objects. Through the above analysis, we find that when one of the parameters is optimized, the other parameters will be used as its weight to dynamically adjust the optimization rate. In other words, the optimization of parameters is no longer independent, that is, optimizing one parameter will also promote the optimization of other parameters. The optimization of this virtuous circle is the key to KLD as an excellent rotation regression loss. In addition, D kl (N t ||N p ) has similar properties, refer to appendix for details.</p><formula xml:id="formula_19">Scale invariance. For a full-rank matrix M, |M| = 0, we have D kl (N p ||N t ) = D kl (N p ||N t ), where X p = MX p ? N p (M? p , M? p M ), X t = MX t ? N t (M? t , M? t M )</formula><p>. Therefore, the affine invariance (including scale invariance when M = kI, where I denotes identity matrix) of KLD can be proven (see proof in appendix). Compared with L n -norm and GWD, KLD is more suitable for replacing the non-differentiable rotated IoU loss for its consistency with detection metric.</p><p>Horizontal special case. For horizontal detection, combine Eq. 8 to Eq. 12, we have</p><formula xml:id="formula_20">D h kl (Np||Nt) = 1 2 w 2 p w 2 t + h 2 p h 2 t + 4? 2 x w 2 t + 4? 2 y h 2 t + ln w 2 t w 2 p + ln h 2 t h 2 p ? 2 =2l2-norm(?tx, ?ty) + l1-norm(?tw, ?t h ) + 1 2 l2-norm( 1 ?tw , 1 ?t h ) ? 1<label>(16)</label></formula><p>where the first two terms of Eq. 16 are very similar to Eq. 4, and the divisor part of the two terms x and y is the main difference ( ?x wt vs. ?x wa ). Variants of KLD. We have also introduced some variants <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref> of KLD to further verify the influence of asymmetry on rotation detection can be ignored. The variants mainly including</p><formula xml:id="formula_21">D kl_min(max) (Np||Nt) = min(max) (D kl (Np||Nt), D kl (Nt||Np)) Djs(Np||Nt) = 1 2 D kl Nt|| Np + Nt 2 + D kl Np|| Np + Nt 2 D jef (Np||Nt) =D kl (Nt||Np) + D kl (Np||Nt)<label>(17)</label></formula><p>Rotation regression loss. The whole training process of detector is as follows: i) predict offset (t p x , t p y , t p w , t p h , t p ? ); ii) decode prediction box; iii) convert prediction box and target ground-truth into Gaussian distribution; iv) calculate KLD of two Gaussian distributions. Therefore, the inference time remains unchanged. We normalize the distance function as our final regression loss L reg :</p><formula xml:id="formula_22">Lreg = 1 ? 1 ? + f (D) , ? ? 1<label>(18)</label></formula><p>where f (?) denotes a non-linear function to transform the distance D to make the loss more smooth and expressive. In this paper, we mainly use two nonlinear functions, sqrt(D) and ln(D + 1). The hyperparameter ? modulates the entire loss. The multi-task loss is:</p><formula xml:id="formula_23">L = ?1 Npos Npos n=1 Lreg(bn, gtn) + ?2 N N n=1 L cls (pn, tn)<label>(19)</label></formula><p>where N pos and N indicate the number of positive and all anchors. b n denotes the n-th bounding box, gt n is the n-th target ground-truth. t n denotes the label of n-th object, p n is the n-th probability distribution of various classes calculated by sigmoid function. The hyper-parameter ? 1 , ? 2 control the trade-off and are set to {2, 1} by default. The classification loss L cls is set as focal loss <ref type="bibr" target="#b9">[10]</ref>. <ref type="table">Table 1</ref>: Ablation study of the loss form and hyperparameter on HRSC2016.</p><p>Loss  <ref type="table">Table 2</ref>: Ablation of different KLD-based regression loss form. The based detector is RetinaNet.  Our experiments are conducted over a variety of datasets, including three large-scale public datasets for aerial images i.e. DOTA <ref type="bibr" target="#b37">[38]</ref>, UCAS-AOD <ref type="bibr" target="#b38">[39]</ref>, HRSC2016 <ref type="bibr" target="#b39">[40]</ref>, as well as scene text dataset ICDAR2015 <ref type="bibr" target="#b40">[41]</ref>, MLT <ref type="bibr" target="#b41">[42]</ref> and MSRA-TD500 <ref type="bibr" target="#b42">[43]</ref>.</p><formula xml:id="formula_24">D kl f (D kl ) L G (f (D kl ), ? ) ? = 1 ? = 2 ? = 3 ? = 5 f (D kl ) = sqrt(D kl ) 0.</formula><formula xml:id="formula_25">Dataset D kl (N p ||N t ) D kl (N t ||N p ) D kl_min (N p ||N t ) D kl_max (N p ||N t ) D js (N p ||N t ) D jef f reys (N p ||N t ) DOTA-v1.</formula><p>DOTA is one of the largest dataset for oriented object detection in aerial images with three released versions: UCAS-AOD contains 1,510 aerial images of approximately 659 ? 1, 280 pixels, with two categories of 14,596 instances in total. In line with <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b37">38]</ref>, we randomly select 1,110 for training and 400 for testing. HRSC2016 contains images from two scenarios including ships on sea and ships close inshore. The training, validation and test set include 436, 181 and 444 images.</p><p>ICDAR2015, MLT and MSRA-TD500 are commonly used for oriented scene text detection and spotting. ICDAR2015 includes 1,000 training images and 500 testing images. ICDAR2017 MLT is a multi-lingual text dataset, which includes 7,200 training images, 1,800 validation images and 9,000 testing images. MSRA-TD500 dataset consists of 300 training images and 200 testing images.</p><p>We use Tensorflow <ref type="bibr" target="#b43">[44]</ref> to implement the proposed methods on a server with Tesla V100 and 32G memory. The experiments are all initialized by ResNet50 <ref type="bibr" target="#b44">[45]</ref> by default unless otherwise specified. Weight decay and momentum are set 0.0001 and 0.9, respectively. We employ MomentumOptimizer over 8 GPUs with a total of 8 images per minibatch (1 image per GPU).</p><p>All the used datasets are trained by 20 epochs in total, and the learning rate is reduced tenfold at 12 epochs and 16 epochs, respectively. The initial learning rate is set to 5e-4. The number of image iterations per epoch for DOTA-v1.0, DOTA-v1.5, DOTA-v2.0, UCAS-AOD, HRSC2016, ICDAR2015, MLT and MSRA-TD500 are 54k, 64k, 80k, 5k, 10k, 10k, 10k and 5k respectively, and doubled if data augmentation (include random rotation, flipping, and graying) or multi-scale training is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablation Study and Further Comparison</head><p>Regression loss form and hyperparameter. <ref type="table">Table 1</ref> compares three forms of KLD-based regression loss on HRSC2016, including D kl , f (D kl ) and L reg (f (D kl ), ? ). Due to extreme sensitivity to large errors, the performance of D kl is extremely poor, only 0.20%. Through a simple nonlinear linear transformation, the performance can be increased to 82.96% and 83.23% corresponding to sqrt and log. We further perform a detailed hyperparameter experiment on the loss L reg proposed in this paper, and the performance reaches the optimal when ? = 1, f (D kl ) = log(D kl + 1), about 85.25%. Keeping the same loss pattern, we compare six KLD-based distance functions in <ref type="table">Table 2</ref>, and conclude that the asymmetry of KLD does not have much impact on performance. In subsequent experiments, we use L reg (log(D kl (N p ||N t )), 1) as the basic setting.</p><p>Ablation study of normalization. As mentioned above, the use of Eq. 18 is to smooth its excessively rapid growth trend and play a role of normalization. This extra normalization questions if the KLD is actually contributing or simply produces noise in the results. In order to further prove that our method is indeed effective, we also perform a normalization operation on the Smooth L1 loss to eliminate the interference caused by normalization. As shown in <ref type="table" target="#tab_2">Table 3</ref>, there is a significant drop in performance after using the normalization. The above experimental results prove that the effectiveness of KLD does not come from Eq. 18.</p><p>High-precision detection experiment. We expect that the designed rotation regression loss can show advantages in high-precision detection. <ref type="table" target="#tab_3">Table 4</ref> shows the comparison of the high-precision detection results of three different regression losses using Smooth L1, GWD and KLD on different datasets and different detectors. For the HRSC2016 dataset containing a large number of ship with large aspect ratios, GWD-based RetinaNet has a 11.89% improvement over Smooth L1 on AP 75 , KLD even gets a 23.97% gain. Even with a stronger R 3 Det detector, KLD and GWD still increased by 33.96% and 22.46% in AP 75 , and 15.22% and 9.89% in AP 50:95 . The same experimental conclusion are also reflected in the other two scene text datasets MASR-TF500 and ICDAR2015, which is KLD &gt; GWD &gt; Smooth L1. In general, the self-modulation optimization mechanism has a significant help for high-precision detection. For a more intuitive comparison, we visually compare these three regression losses, as shown in <ref type="figure" target="#fig_0">Figure 2</ref> Ablation study on more datasets. To make the results more credible, we continue to verify on the other five datasets, as shown in <ref type="table" target="#tab_4">Table 5</ref>. The improvement of KLD on the three data sets of MLT, UCAS-AOD and DOTA-v1.0 is still considerable, with an increase of 9.17%, 1.58%, and 5.55% respectively. Note that for DOTA-v1.5 and DOTA-v2.0, which contain a large number of small objects (less than 10 pixels), KLD has achieved significant gains of 3.63% and 3.53%.</p><p>Comparison of peer methods. <ref type="table" target="#tab_5">Table 6</ref> compares the six peer techniques, including IoU-Smooth L1 Loss <ref type="bibr" target="#b2">[3]</ref>, Modulated loss <ref type="bibr" target="#b45">[46]</ref>, RIL <ref type="bibr" target="#b34">[35]</ref>, CSL <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b47">48]</ref>, DCL <ref type="bibr" target="#b46">[47]</ref>, and GWD <ref type="bibr" target="#b4">[5]</ref> on DOTA-v1.0. For fairness, these methods are all implemented on the same baseline method, and are trained and tested under the same environment and hyperparameters. We detail the accuracy of the seven categories,  including large aspect ratio (e.g. BR, SV, LV, SH, HA) and square-like object (e.g. ST, RD), which can better reflect the real-world challenges and advantages of our method. Without bells and whistles, the combination of RetinaNet and KLD directly surpasses R 3 Det (71.28% vs. 70.66% in AP 50 and 69.41% vs. 68.31% in 7-AP 50 ). Even combined with R 3 Det, KLD can still further improve performance of the large aspect ratio object (2.82% in 7-AP 50 ) and high-precision detection (6.07% in AP 75 and 3.65% AP 50:95 ). KLD-based method shows the best performer in almost all indicators. Similar conclusions can still be drawn on the more challenging datasets (DOTA-v1.5 and DOTA-v2.0), which contain more data and tiny object (less than 10 pixels).</p><p>Horizontal detection verification. As analyzed by Eq. 16, KLD can be degenerated into the common regression loss in horizontal detection task. <ref type="table" target="#tab_6">Table 7</ref> compares the regression loss Smooth L1 and IoU/GIoU for horizontal detection with the proposed regression loss KLD on MS COCO <ref type="bibr" target="#b48">[49]</ref> dataset.</p><p>The results show that our KLD is not worse than other losses on the Faster RCNN <ref type="bibr" target="#b7">[8]</ref>, RetinaNet <ref type="bibr" target="#b9">[10]</ref> and FCOS <ref type="bibr" target="#b21">[22]</ref>, and even has an improvement of 0.6% on RetinaNet. The ground truth for rotation detection is the minimum circumscribed rectangle, which means that ground truth can well reflect the true scale and direction information of the object. The "horizontal special case" described in this paper also meets the above requirements, the horizontal circumscribed rectangle is equal to the minimum circumscribed rectangle at this time. Although the ground truth of the COCO is a horizontal box, it is not the minimum circumscribed rectangle, which means that it loses the direction information and accurate scale information of the object. For example, a baseball bat placed obliquely in the image, the height and width of its horizontal circumscribed rectangle do not represent the height and width of the object itself. This causes that when KLD is applied to the COCO, the optimization mechanism of KLD that dynamically adjusts the angle gradient according to the aspect ratio is meaningless, which affects the improvement of the final performance. In general, this is a defect in the dataset annotation itself, not that KLD is not good enough. In fact, it is inappropriate to use the COCO to discuss ? = 0 ? , because the COCO discards ? parameter. In addition, ? = 0 ? describes the instances in the horizontal position, but not mean all instances of the dataset are in a horizontal position. This paper uses COCO to discuss the "horizontal special case" to express that even if the dataset has certain labeling defects, KLD can have certain effects. After all, it is difficult to observe the performance improvement of all horizontal objects on the rotating dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparisons with the State-of-the-Art Methods</head><p>The evaluation is performed on the DOTA, which contains a considerable number of categories, complexity scenes. Our single-scale model RetinaNet-KLD-R50 and R 3 Det-KLD-R50 achieve 75.28% and 77.36% respectively. They outperform multi-scale models as shown in <ref type="table" target="#tab_7">Table 8</ref>. With large backbone and multi-scale testing, our method further achieves state-of-the-art accuracy 80.63%.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussions</head><p>Limitations. Despite the theoretical grounds and the promising experimental justifications, our method has an obvious limitation that it cannot be directly applied to quadrilateral detection <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b45">46]</ref>.</p><p>Potential negative societal impacts. Our findings provides a simple regression loss for highprecision rotation detection. However, our research may be applied to some sensitive fields, such as remote sensing, aviation, and unmanned aerial vehicles.</p><p>Conclusion. Departure from the vast existing literature in object detection, in this paper we have designed a new regression loss for rotation detection from scratch and consider the popular horizontal detection as its special case. Specifically, we calculate the KLD between the Gaussian distributions corresponding to the rotated bounding box as the regression loss, and we find that in the learning procedure guided by the KLD loss, the gradient of the parameters can be dynamically adjusted according to the characteristics of the object which is a desirable property for robust object detection, regardless its rotation, size and aspect ratio etc. We also proved that KLD has scale invariance, which is crucial for detection tasks. Interestingly, we have shown that KLD can be degenerated into the currently commonly used l n -norm loss in the horizontal detection task. Extensive experimental results across different detectors and datasets show the effectiveness of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>A.1 Proof of Scale Invariance of KLD Suppose there are two Gaussian distributions, denoted as X p ? N p (? p , ? p ) and X t ? N t (? t , ? t ).</p><p>Then, for a full-rank matrix M, |M| = 0, we have X p = MX p ? N p (M? p , M? p M ), X t = MX t ? N t (M? t , M? t M ), denoted as N p and N t . The Kullback-Leibler Divergence (KLD) <ref type="figure">Figure 4</ref>: L 2 -norm, GWD and KLD versus scaling factor. between N p and N t is:</p><formula xml:id="formula_26">D kl (N p ||N t ) = 1 2 (?p ? ?t) M (M ) ?1 ? ?1 t M ?1 M(?p ? ?t) + 1 2 Tr (M ) ?1 ? ?1 t M ?1 M?pM + 1 2 ln |M||?t||M | |M||?p||M | ? 1 = 1 2 (?p ? ?t) ? ?1 t (?p ? ?t) + 1 2 Tr M (M ) ?1 ? ?1 t M ?1 M?p + 1 2 ln |?t| |?p| ? 1 =D kl (Np||Nt)<label>(20)</label></formula><p>Therefore, KLD has affine invariance. Especially when M = kI (I denotes identity matrix), the scale invariance of KLD is proved. <ref type="figure">Figure 5</ref>: L 2 -norm, GWD and KLD versus parameters when the targeted height varies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 The Visualization of KLD's Advantages</head><p>This section aims to visually show the advantages of KLD, including its scale invariance and ability of high-precision detection. To this end, we compare KLD with L 2 -norm and GWD, pointing out that these advantages are characteristics of KLD.</p><p>To visualize the scale invariance of KLD, we consider the KLD of two given boxes, and investigate the variation of KLD when the two boxes are enlarged with a scaling factor s. Specifically, the parameters of the two boxes are (0, 0, s, 2s, 5 ? ) and (s, s, 1.1s, 2.2s, 5 ? ), respectively. As shown in <ref type="figure">Figure 4</ref>, the value of KLD is invariant to the scaling factor s. Compareed with this, the values of L 2 -norm and GWD change when s increases, and hence they have no advantage of scale invariance. Note that IoU is also invariant to the scaling of boxes, and hence to some degree, KLD is a better substitute of IoU than L 2 -norm and GWD.</p><p>The ability of high-precision detection of KLD means it do well in object detection with large aspect ratio. Specifically, for bounding box with larger aspect ratio, KLD gives heavier penalties to matching of shorter edge's length and the center point's position along the shorter edge's direction, as well as the matching of angle. These characteristics are desirable, as when matching bounding box with large aspect ratio, IoU is intuitively sensitive to the shorter edge's length, the center point's position along the shorter edge's direction and the angle. To visualize these characteristics of KLD, we consider a target box with x = 0, y = 0, w = 1, ? = 0, and set h = {1, 2, 3, 4} to control the aspect ratio, and plot KLD versus the variation of parameters. L 2 -norm and GWD are also included for comparisons. As shown in <ref type="figure">Figure 5</ref>, when h increases, KLD is more sensitive to the variation of x, w and ?, meaning it has desirable advantages for object detection with large aspect ratio. Compared with this, both L 2 -norm and GWD pay no more attention to the matching of x and w when h increases, and L 2 -norm is even unchanged when the difference of angle ?? is fixed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Visual comparison between Smooth L1 loss (left), GWD (middle) and KLD (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Top: rotated box B(x, y, w, h, ?). Bottom: 2-D Gaussian dist. N (?, ?).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>DOTA-v1.0, DOTA-v1.5 and DOTA-v2.0. DOTA-v1.0 contains 15 common categories, 2,806 images and 188,282 instances. The proportions of the training set, validation set, and testing set in DOTA-v1.0 are 1/2, 1/6, and 1/3, respectively. In contrast, DOTA-v1.5 uses the same images as DOTA-v1.0, but extremely small instances (less than 10 pixels) are also annotated. Moreover, a new category, containing 402,089 instances in total is added in this version. While DOTA-v2.0 contains 18 common categories, 11,268 images and 1,793,658 instances. Compared to DOTA-v1.5, it further includes the new categories. The 11,268 images in DOTA-v2.0 are split into training, validation, test-dev, and test-challenge sets. We divide the images into 600 ? 600 subimages with an overlap of 150 pixels and scale it to 800 ? 800, in line with the cropping protocol in literature<ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b28">29]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>. Since the center point (x, y) parameters in Smooth L1 Loss and GWD are independently optimized, their prediction results are slightly shifted. In contrast, the KLD-based prediction results are closer to the object boundary and show strong robustness in dense scenes. Similarly, GWD-based or KLD-based model has more accurate angle prediction capabilities than Smooth L1-based model due to their angle parameters (?) are not independently optimized.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>20 82.96 84.85 84.15 75.23 73.32 f (D kl ) = log(D kl + 1) 83.23 85.25 83.63 80.79 73.44</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Ablation study of normalization. The based detector is RetinaNet.</figDesc><table><row><cell>Loss</cell><cell>Norm by Eq. 18</cell><cell cols="3">HRSC2016 Hmean 50 Hmean 75 Hmean 50:95</cell><cell>DOTA-v1.0 AP 50</cell></row><row><cell>Smooth L1</cell><cell>w/ w/o</cell><cell>78.99 84.80</cell><cell>43.12 48.42</cell><cell>43.47 47.76</cell><cell>64.95 65.73</cell></row><row><cell>4 Experiment</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>4.1 Datasets and Implementation Details</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>High-precision detection experiment under different regression loss. 'R', 'F' and 'G' indicate random rotation, flipping, and graying, respectively. The resolution of HRSC2016, MSRA-TD500 and ICDAR2015 are 500 ? 500, 800 ? 1, 000 and 800 ? 1, 000, respectively.</figDesc><table><row><cell>Method</cell><cell>Dataset</cell><cell cols="7">Data Aug. Reg. Loss Hmean50/AP50 Hmean60/AP60 Hmean75/AP75 Hmean85/AP85 Hmean50:95/AP50:95</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Smooth L1</cell><cell>84.28</cell><cell>74.74</cell><cell>48.42</cell><cell>12.56</cell><cell>47.76</cell></row><row><cell>RetinaNet</cell><cell></cell><cell></cell><cell>GWD</cell><cell>85.56 (+1.28)</cell><cell>84.04 (+9.30)</cell><cell>60.31 (+11.89)</cell><cell>17.14 (+4.58)</cell><cell>52.89 (+5.13)</cell></row><row><cell></cell><cell>HRSC2016</cell><cell>R+F+G</cell><cell>KLD Smooth L1</cell><cell>87.45 (+3.17) 88.52</cell><cell>86.72 (+11.98) 79.01</cell><cell>72.39 (+23.97) 43.42</cell><cell>27.68 (+15.12) 4.58</cell><cell>57.80 (+10.04) 46.18</cell></row><row><cell>R 3 Det</cell><cell></cell><cell></cell><cell>GWD</cell><cell>89.43 (+0.91)</cell><cell>88.89 (+9.88)</cell><cell>65.88 (+22.46)</cell><cell>15.02 (+10.44)</cell><cell>56.07 (+9.89)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>KLD</cell><cell>89.97 (+1.45)</cell><cell>89.73 (+10.72)</cell><cell>77.38 (+33.96)</cell><cell>25.12 (+20.54)</cell><cell>61.40 (+15.22)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Smooth L1</cell><cell>70.98</cell><cell>62.42</cell><cell>36.73</cell><cell>12.56</cell><cell>37.89</cell></row><row><cell></cell><cell>MSRA-TD500</cell><cell>R+F</cell><cell>GWD</cell><cell>76.76 (+5.78)</cell><cell>68.58 (+6.16)</cell><cell>44.21 (+7.48)</cell><cell>17.75 (+5.19)</cell><cell>43.62 (+5.73)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>KLD</cell><cell>76.96 (+5.98)</cell><cell>70.08 (+7.66)</cell><cell>46.95 (+10.22)</cell><cell>19.59 (+7.03)</cell><cell>45.24 (+7.35)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Smooth L1</cell><cell>69.78</cell><cell>64.15</cell><cell>36.97</cell><cell>8.71</cell><cell>37.73</cell></row><row><cell>RetinaNet</cell><cell></cell><cell>F</cell><cell>GWD</cell><cell>74.29 (+4.51)</cell><cell>68.34 (+4.19)</cell><cell>43.39 (+6.42)</cell><cell>10.50 (+1.79)</cell><cell>41.68 (+3.95)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>KLD</cell><cell>75.32 (+5.54)</cell><cell>69.94 (+5.79)</cell><cell>44.46 (+7.49)</cell><cell>10.70 (+1.99)</cell><cell>42.68 (+4.95)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Smooth L1</cell><cell>74.83</cell><cell>69.46</cell><cell>42.02</cell><cell>11.59</cell><cell>41.98</cell></row><row><cell></cell><cell></cell><cell>R+F</cell><cell>GWD</cell><cell>76.15 (+1.32)</cell><cell>71.26 (+1.80)</cell><cell>45.59 (+3.57)</cell><cell>11.65 (+0.06)</cell><cell>43.58 (+1.60)</cell></row><row><cell></cell><cell>ICDAR2015</cell><cell></cell><cell>KLD Smooth L1</cell><cell>77.92 (+3.09) 74.28</cell><cell>72.77 (+3.31) 68.12</cell><cell>43.27 (+1.25) 35.73</cell><cell>11.09 (-0.50) 8.01</cell><cell>43.65 (+1.67) 39.10</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell>GWD</cell><cell>75.59 (+1.31)</cell><cell>68.36 (+0.24)</cell><cell>40.24 (+4.51)</cell><cell>9.15 (+1.14)</cell><cell>40.80 (+1.70)</cell></row><row><cell>R 3 Det</cell><cell></cell><cell></cell><cell>KLD Smooth L1</cell><cell>77.72 (+2.43) 75.53</cell><cell>71.99 (+3.87) 69.69</cell><cell>43.95 (+8.22) 37.69</cell><cell>10.43 (+2.42) 9.03</cell><cell>43.29 (+4.19) 40.56</cell></row><row><cell></cell><cell></cell><cell>R+F</cell><cell>GWD</cell><cell>77.09 (+1.56)</cell><cell>71.52 (+1.83)</cell><cell>41.08 (+3.39)</cell><cell>10.10 (+1.07)</cell><cell>42.17 (+1.61)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>KLD</cell><cell>79.63 (+4.63)</cell><cell>73.30 (+3.61)</cell><cell>43.51 (+5.82)</cell><cell>10.61 (+1.58)</cell><cell>43.61 (+3.05)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>More ablation experiments on other datasets. +6.16) 95.44 (+0.88) 68.93 (+3.20) 60.03 (+1.16) 46.65 (+2.49) KLD 57.59 (+9.17) 96.14 (+1.58) 71.28 (+5.55) 62.50 (+3.63) 47.69 (+3.53)</figDesc><table><row><cell>Method</cell><cell>Reg. Loss</cell><cell>MLT</cell><cell cols="2">UCAS-AOD DOTA-v1.0</cell><cell>DOTA-v1.5</cell><cell>DOTA-v2.0</cell></row><row><cell></cell><cell>Smooth L1</cell><cell>48.42</cell><cell>94.56</cell><cell>65.73</cell><cell>58.87</cell><cell>44.16</cell></row><row><cell>RetinaNet</cell><cell>GWD</cell><cell>54.58 (</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Accuracy comparison between different rotation detectors on DOTA dataset. ? and ? represent the large aspect ratio object and the square-like object, respectively. The bold red and blue fonts indicate the top two performances respectively. D oc and D le represent OpenCV Definition (? ? [?90 ? , 0 ? )) and Long Edge Definition (? ? [?90 ? , 90 ? )) of RBox.</figDesc><table><row><cell>Baseline</cell><cell>Method</cell><cell>Box Def.</cell><cell>BR  ?</cell><cell>SV  ?</cell><cell>LV  ?</cell><cell>v1.0 tranval/test SH  ? HA  ? ST  ?</cell><cell cols="2">v1.0 train/val RA  ? 7-AP50 AP50 AP50 AP75 AP50:95 AP50 AP50 v1.5 v2.0</cell></row><row><cell></cell><cell>-</cell><cell>Doc</cell><cell cols="5">42.17 65.93 51.11 72.61 53.24 78.38 62.00</cell><cell>60.78</cell><cell>65.73 64.70 32.31</cell><cell>34.50</cell><cell>58.87 44.16</cell></row><row><cell></cell><cell>-</cell><cell>Dle</cell><cell cols="5">38.31 60.48 49.77 68.29 51.28 78.60 60.02</cell><cell>58.11</cell><cell>64.17 62.21 26.06</cell><cell>31.49</cell><cell>56.10 43.06</cell></row><row><cell></cell><cell>IoU-Smooth L1 [3]</cell><cell>Doc</cell><cell cols="5">44.32 63.03 51.25 72.78 56.21 77.98 63.22</cell><cell>61.26</cell><cell>66.99 64.61 34.17</cell><cell>36.23</cell><cell>59.16 46.31</cell></row><row><cell></cell><cell>Modulated Loss [46]</cell><cell>Doc</cell><cell cols="5">42.92 67.92 52.91 72.67 53.64 80.22 58.21</cell><cell>61.21</cell><cell>66.05 63.50 33.32</cell><cell>34.61</cell><cell>57.75 45.17</cell></row><row><cell>RetinaNet</cell><cell>Modulated Loss [46] RIL [35]</cell><cell>Quad. Quad.</cell><cell cols="5">43.21 70.78 54.70 72.68 60.99 79.72 62.08 40.81 67.63 55.45 72.42 55.49 78.09 64.75</cell><cell>63.45 62.09</cell><cell>67.20 65.15 40.59 66.06 64.07 40.98</cell><cell>39.12 39.05</cell><cell>61.42 46.71 58.91 45.35</cell></row><row><cell></cell><cell>CSL [4]</cell><cell>Dle</cell><cell cols="5">42.25 68.28 54.51 72.85 53.10 75.59 58.99</cell><cell>60.80</cell><cell>67.38 64.40 32.58</cell><cell>35.04</cell><cell>58.55 43.34</cell></row><row><cell></cell><cell>DCL (BCL) [47]</cell><cell>Dle</cell><cell cols="5">41.40 65.82 56.27 73.80 54.30 79.02 60.25</cell><cell>61.55</cell><cell>67.39 65.93 35.66</cell><cell>36.71</cell><cell>59.38 45.46</cell></row><row><cell></cell><cell>GWD [5]</cell><cell>Doc</cell><cell cols="5">44.07 71.92 62.56 77.94 60.25 79.64 63.52</cell><cell>65.70</cell><cell>68.93 65.44 38.68</cell><cell>38.71</cell><cell>60.03 46.65</cell></row><row><cell></cell><cell>KLD</cell><cell>Doc</cell><cell cols="5">44.00 74.45 72.48 84.30 65.54 80.03 65.05</cell><cell>69.41</cell><cell>71.28 68.14 44.48</cell><cell>42.15</cell><cell>62.50 47.69</cell></row><row><cell></cell><cell>-</cell><cell>Doc</cell><cell cols="5">44.15 75.09 72.88 86.04 56.49 82.53 61.01</cell><cell>68.31</cell><cell>70.66 67.18 38.41</cell><cell>38.46</cell><cell>62.91 48.43</cell></row><row><cell>R 3 Det [29]</cell><cell>DCL (BCL) [47] GWD [5]</cell><cell>Dle Doc</cell><cell cols="5">46.84 74.87 74.96 85.70 57.72 84.06 63.77 46.73 75.84 78.00 86.71 62.69 83.09 61.12</cell><cell>69.70 70.60</cell><cell>71.21 67.45 35.44 71.56 69.28 43.35</cell><cell>37.54 41.56</cell><cell>61.98 48.71 63.22 49.25</cell></row><row><cell></cell><cell>KLD</cell><cell>Doc</cell><cell cols="5">48.34 75.09 78.88 86.52 65.48 82.08 61.51</cell><cell>71.13</cell><cell>71.73 68.87 44.48</cell><cell>42.11</cell><cell>65.18 50.90</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Performance evaluation of KLD on classic horizontal detection.DetectorRegression Loss AP AP 50 AP 75 AP s AP m AP l</figDesc><table><row><cell></cell><cell>Smooth L1</cell><cell>37.2 56.6</cell><cell>39.7 21.4 41.1 48.0</cell></row><row><cell>RetinaNet [10]</cell><cell>GIoU</cell><cell>37.4 56.7</cell><cell>39.7 22.2 41.7 48.1</cell></row><row><cell></cell><cell>KLD</cell><cell>38.0 56.4</cell><cell>40.6 23.3 43.2 49.3</cell></row><row><cell></cell><cell>Smooth L1</cell><cell>37.9 58.8</cell><cell>41.0 22.4 41.4 49.1</cell></row><row><cell>Faster RCNN [8]</cell><cell>GIoU</cell><cell>38.3 58.7</cell><cell>41.5 22.5 41.7 49.7</cell></row><row><cell></cell><cell>KLD</cell><cell>38.2 58.7</cell><cell>41.7 22.6 41.8 49.3</cell></row><row><cell>FCOS [22]</cell><cell>IoU KLD</cell><cell>36.6 56.0 36.8 56.3</cell><cell>38.8 21.0 40.6 47.0 39.1 21.7 40.8 47.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8</head><label>8</label><figDesc>Red and blue indicate the top two performances. .<ref type="bibr" target="#b44">45</ref> 53.77 74.35 71.52 78.31 78.12 91.14 87.35 86.93 65.64 65.17 75.35 79.74 63.31 76.34 SCRDet++ [55] R-101 90.05 84.39 55.44 73.99 77.54 71.11 86.05 90.67 87.32 87.08 69.62 68.90 73.74 71.29 65.08 76.81 ReDet [56] ReR-50 88.81 82.48 60.83 80.82 78.34 86.06 88.31 90.87 88.77 87.03 68.65 66.90 79.26 79.71 74.67 80.10 69.70 24.10 60.20 38.30 64.40 64.80 90.90 77.20 70.40 46.50 37.10 57.10 61.90 64.00 60.50 O 2 -DNet [58] H-104 89.31 82.14 47.33 61.21 71.32 74.03 78.62 90.76 82.23 81.36 60.93 60.17 58.21 66.98 61.03 71.04 DAL [15] R-101 88.61 79.69 46.27 70.37 65.89 76.10 78.53 90.84 79.98 78.41 58.71 62.02 69.23 71.32 60.65 71.78 P-RSDet [59] R-101 88.58 77.83 50.44 69.29 71.10 75.79 78.66 90.88 80.10 81.71 57.92 63.03 66.30 69.77 63.13 72.30 BBAVectors [60] R-101 88.35 79.96 50.69 62.18 78.43 78.98 87.94 90.85 83.58 84.35 54.13 60.24 65.22 64.28 55.70 72.32 DRN [14] H-104 89.71 82.34 47.22 64.10 76.22 74.43 85.84 90.57 86.18 84.89 57.65 61.93 69.30 69.63 58.48 73.23 PolarDet [61] R-101 89.65 87.07 48.14 70.97 78.53 80.34 87.45 90.76 85.63 86.87 61.64 70.32 71.92 73.09 67.84.32 55.33 77.53 76.95 70.28 83.95 89.75 84.51 86.06 73.47 67.77 72.60 75.76 74.17 77.43 KLD R-50 88.91 83.71 50.10 68.75 78.20 76.05 84.58 89.41 86.15 85.28 63.15 60.90 75.06 71.51 67.45 75.28 R-50 88.91 85.23 53.64 81.23 78.20 76.99 84.58 89.50 86.84 86.38 71.69 68.06 75.95 72.23 75.42 78.32 80.41 52.41 70.02 76.28 78.11 87.21 90.89 84.47 85.64 60.51 61.52 67.82 68.02 50.09 73.50 R 3 Det [29] R-152 89.80 83.77 48.11 66.77 78.76 83.27 87.84 90.82 85.38 85.51 65.67 62.68 67.53 78.56 72.62 76.47 DAL [15] R-50 89.69 83.11 55.03 71.00 78.30 81.90 88.46 90.89 84.97 87.46 64.41 65.65 76.86 72.09 64.35 76.95 DCL [47] R-152 89.26 83.60 53.54 72.76 79.04 82.56 87.31 90.67 86.59 86.98 67.49 66.88 73.29 70.56 69.99 77.37 RIDet [35] R-50 89.31 80.77 54.07 76.38 79.81 81.99 89.13 90.72 83.58 87.22 64.42 67.56 78.08 79.17 62.07 77.62 S 2 A-Net [13] R-101 89.28 84.11 56.95 79.21 80.18 82.93 89.21 90.86 84.66 87.61 71.66 68.23 78.58 78.20 65.55 79.15 R 3 Det-GWD [5] R-152 89.66 84.99 59.26 82.19 78.97 84.83 87.70 90.21 86.54 86.85 73.04 67.56 76.92 79.22 74.92 80.19 R 3 Det-KLD R-50 88.90 84.17 55.80 69.35 78.72 84.08 87.00 89.75 84.32 85.73 64.74 61.80 76.62 78.49 70.89 77.36 R-50 89.90 84.91 59.21 78.74 78.82 83.95 87.41 89.89 86.63 86.69 70.47 70.87 76.96 79.40 78.62 80.17 R-152 89.92 85.13 59.19 81.33 78.82 84.38 87.50 89.80 87.33 87.00 72.57 71.35 77.12 79.34 78.68 80.63</figDesc><table><row><cell></cell><cell cols="12">: AP on different objects on DOTA-v1.0. Here R-101 denotes ResNet-101 (likewise for R-50,</cell></row><row><cell cols="13">R-152), and RX-101 and H-104 represent ResNeXt101 [50] and Hourglass-104 [51], respectively. MS</cell></row><row><cell cols="4">indicates that multi-scale training/testing is used. Method Backbone MS PL BD BR GTF SV</cell><cell>LV</cell><cell>SH</cell><cell>TC</cell><cell>BC</cell><cell>ST</cell><cell>SBF</cell><cell>RA</cell><cell>HA</cell><cell>SP</cell><cell>HC</cell><cell>AP50</cell></row><row><cell></cell><cell>ICN [32]</cell><cell>R-101</cell><cell cols="10">81.40 74.30 47.70 70.30 64.90 67.80 70.00 90.80 79.10 78.20 53.60 62.90 67.00 64.20 50.20 68.20</cell></row><row><cell></cell><cell>RoI-Trans. [12]</cell><cell>R-101</cell><cell cols="10">88.64 78.52 43.44 75.92 68.81 73.68 83.59 90.74 77.27 81.46 58.39 53.54 62.83 58.93 47.67 69.56</cell></row><row><cell></cell><cell>SCRDet [3]</cell><cell>R-101</cell><cell cols="10">89.98 80.65 52.09 68.36 68.36 60.32 72.41 90.85 87.94 86.86 65.02 66.68 66.25 68.24 65.21 72.61</cell></row><row><cell>Two-stage</cell><cell>Gliding Vertex [52] Mask OBB [53] CenterMap OBB [54] FPN-CSL [4]</cell><cell>R-101 RX-101 R-101 R-152</cell><cell cols="10">89.64 85.00 52.26 77.34 73.01 73.14 86.82 90.74 79.02 86.81 59.55 70.91 72.94 70.86 57.32 75.02 89.56 85.95 54.21 72.90 76.52 74.16 85.63 89.85 83.81 86.48 54.89 69.64 73.94 69.06 63.32 75.33 89.83 84.41 54.60 70.25 77.66 78.32 87.19 90.66 84.89 85.27 56.46 69.23 74.13 71.56 66.06 76.03 90.25 85.53 54.64 75.31 70.44 73.51 77.62 90.84 86.15 86.69 69.60 68.04 73.83 71.10 68.93 76.17</cell></row><row><cell cols="13">RSDet-II [46] PIoU [33] 89.93 84Single-stage R-152 DLA-34 [57] 80.90 15 76.64 RDD [62] R-101 89.15 83.92 52.51 73.06 77.81 79.00 87.08 90.62 86.72 87.15 63.96 70.29 76.98 75.79 72.15 77.75</cell></row><row><cell cols="4">GWD [5] 89.06 Refine-stage R-152 CFC-Net [34] R-101 89.08</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/yangxue0827/RotationDetection 4 https://github.com/open-mmlab/mmrotate</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">w 2 p (?x cos ?p + ?y sin ?p) sin ?p + 4 h 2 p (??x sin ?p + ?y cos ?p) cos ?p(25)</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A.2 Analysis of D kl (N t ||N p )'s High-Precision Detection The D kl (N t ||N p ) between two 2-D Gaussian is:</p><p>each item of Eq. 21 can be expressed as</p><p>where</p><p>For the parameter ? p , we have ?f kl (?p) ??p = It is assumed that except for ? p , other parameters have been optimized to the best. In other words, h p = h t , w p = w t , and ? p = ? t . Without loss of generality, we set ? t = 0 ? , then</p><p>The weights 1/w 2 t and 1/h 2 t will make the model dynamically adjust the optimization of the object position according to the scale.</p><p>For h p and w p , we have</p><p>Similarly, suppose ?x = ?y = ?? = 0,</p><p>, which means that the smaller targeted height or width leads to heavier penalty on its matching loss. This is desirable, as smaller height or width needs higher matching precision.</p><p>Similarly, suppose ?x = ?y = ? = 0 and w p = w t , h p = h t , we have</p><p>the condition for the equality sign is h t = w t . This shows that the larger the aspect ratio of the object, the model will pay more attention to the optimization of the angle.</p><p>Compared with D kl (N p ||N t ), D kl (N t ||N p ) has a similar gradient optimization strategy. The difference is that the relationship between the parameters of D kl (N t ||N p ) is tighter.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic ship detection in remote sensing images from google earth of complex scenes based on multiscale rotation dense feature pyramid networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">132</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Position detection and direction prediction for arbitrary-oriented ships via multitask rotation region convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="50" to="839" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scrdet: Towards more robust detection for small, cluttered and rotated objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8232" to="8241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Arbitrary-oriented object detection with circular smooth label</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="677" to="694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rethinking rotated object detection with gaussian wasserstein distance loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiaopeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sparse label assignment for oriented object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page">2664</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">R-fcn: Object detection via region-based fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="379" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning roi transformer for oriented object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2849" to="2858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Align deep features for oriented object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-S</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dynamic refinement network for oriented and densely packed object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dynamic anchor learning for arbitrary-oriented object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2355" to="2363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On information and sufficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The annals of mathematical statistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Optimal transport: old and new</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Villani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">338</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Alpharotate: A rotation detection benchmark using tensorflow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.06677</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Mmrotate: A rotated object detection benchmark using pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fcos: Fully convolutional one-stage object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9627" to="9636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Objects as points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07850</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Reppoints: Point set representation for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9657" to="9666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">End-to-end object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="213" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deformable detr: Deformable transformers for end-to-end object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Generalized intersection over union: A metric and a loss for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Distance-iou loss: Faster and better learning for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">0</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">R3det: Refined single-stage detector with feature refinement for rotating object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="3163" to="3171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">R2cnn: rotational region cnn for orientation robust scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.09579</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Arbitrary-oriented scene text detection via rotation proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3111" to="3122" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Towards multi-class object detection in unconstrained remote sensing imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Azimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bahmanyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>K?rner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Reinartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="150" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Piou loss: Towards accurate oriented object detection in complex environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="195" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Cfc-net: A critical feature capturing network for arbitraryoriented object detection in remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06849</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Optimization for arbitrary-oriented object detection via representation invariance loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An invariant form for the prior probability in estimation problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jeffreys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society of London. Series A. Mathematical and Physical Sciences</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="issue">1007</biblScope>
			<biblScope unit="page" from="453" to="461" />
			<date type="published" when="1946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Foundations of statistical natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schutze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dota: A large-scale dataset for object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Datcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pelillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3974" to="3983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Orientation robust object detection in aerial images using deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3735" to="3739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A high resolution optical satellite image dataset for ship recognition and some new baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Pattern Recognition Applications and Methods</title>
		<meeting>the International Conference on Pattern Recognition Applications and Methods</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="324" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Karatzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gomez-Bigorda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iwamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<title level="m">2015 13th International Conference on Document Analysis and Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1156" to="1160" />
		</imprint>
	</monogr>
	<note>Icdar 2015 competition on robust reading</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Icdar2017 robust reading challenge on multi-lingual scene text detection and script identification-rrc-mlt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nayef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bizid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Karatzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rigaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chazalon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 14th IAPR International Conference on Document Analysis and Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1454" to="1459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Detecting texts of arbitrary orientations in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1083" to="1090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} symposium on operating systems design and implementation</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning modulated loss for rotated object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2458" to="2466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dense label encoding for boundary discontinuity free rotation detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">On the arbitrary-oriented object detection: Classification based approaches revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.05597</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="483" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Gliding vertex on the horizontal bounding box for multi-oriented object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1452" to="1459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Mask obb: A semantic attention-based mask oriented bounding box representation for multi-category object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page">2930</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning center probability map for detecting objects in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-S</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="4307" to="4323" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Scrdet++: Detecting small, cluttered and rotated objects via instance-level feature denoising and rotation loss smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Redet: A rotation-equivariant detector for aerial object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-S</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2786" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deep layer aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2403" to="2412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Oriented objects as pairs of middle lines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="268" to="279" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Arbitrary-oriented object detection in remote sensing images based on polar coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="223" to="373" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Oriented object detection in aerial images with box boundary-aware vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2150" to="2159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Polardet: A fast, more precise detector for rotated target in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="5821" to="5851" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Single-stage rotation-decoupled detector for oriented object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page">3262</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
